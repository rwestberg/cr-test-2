<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.media/src/main/native/jfxmedia/platform/osx/avf/AVFAudioProcessor.mm</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AVFAudioProcessor.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AVFAudioSpectrumUnit.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.media/src/main/native/jfxmedia/platform/osx/avf/AVFAudioProcessor.mm</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,7 ***</span>
  /*
<span class="line-modified">!  * Copyright (c) 2014, 2016, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.  Oracle designates this
<span class="line-new-header">--- 1,7 ---</span>
  /*
<span class="line-modified">!  * Copyright (c) 2014, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   *
   * This code is free software; you can redistribute it and/or modify it
   * under the terms of the GNU General Public License version 2 only, as
   * published by the Free Software Foundation.  Oracle designates this
</pre>
<hr />
<pre>
<span class="line-old-header">*** 27,62 ***</span>
  #import &quot;AVFMediaPlayer.h&quot;
  
  #import &lt;AVFoundation/AVFoundation.h&gt;
  #import &lt;MediaToolbox/MediaToolbox.h&gt;
  
<span class="line-removed">- #import &quot;AVFKernelProcessor.h&quot;</span>
  #import &lt;CoreFoundation/CoreFoundation.h&gt;
  
  #import &lt;pthread.h&gt;
  #import &lt;objc/message.h&gt;
  
  static void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut);
  static void FinalizeAudioTap(MTAudioProcessingTapRef tapRef);
  static void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">!                             CMItemCount maxFrames,</span>
<span class="line-modified">!                             const AudioStreamBasicDescription *processingFormat);</span>
  static void UnprepareAudioTap(MTAudioProcessingTapRef tapRef);
  static void ProcessAudioTap(MTAudioProcessingTapRef tapRef, CMItemCount numberFrames,
<span class="line-modified">!                             MTAudioProcessingTapFlags flags,</span>
<span class="line-modified">!                             AudioBufferList *bufferListInOut,</span>
<span class="line-modified">!                             CMItemCount *numberFramesOut,</span>
<span class="line-modified">!                             MTAudioProcessingTapFlags *flagsOut);</span>
<span class="line-removed">- </span>
  static OSStatus AVFTapRenderCallback(void *inRefCon,
                                       AudioUnitRenderActionFlags *ioActionFlags,
                                       const AudioTimeStamp *inTimeStamp,
                                       UInt32 inBusNumber,
                                       UInt32 inNumberFrames,
                                       AudioBufferList *ioData);
  
<span class="line-removed">- class AVFTapContext {</span>
<span class="line-removed">- public:</span>
<span class="line-removed">-     AVFTapContext(AVFSoundLevelUnitPtr slu, AVFAudioSpectrumUnitPtr spectrum, AVFAudioEqualizerPtr eq) :</span>
<span class="line-removed">-         audioSLU(slu),</span>
<span class="line-removed">-         audioSpectrum(spectrum),</span>
<span class="line-removed">-         audioEQ(eq)</span>
<span class="line-removed">-     {</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
<span class="line-removed">-     ~AVFTapContext() {</span>
<span class="line-removed">-         // AudioUnits have already been deallocated by now</span>
<span class="line-removed">-         // shared_ptrs get freed automatically</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
<span class="line-removed">-     AudioUnit spectrumUnit;</span>
<span class="line-removed">-     AudioUnit volumeUnit;</span>
<span class="line-removed">-     AudioUnit eqUnit;</span>
<span class="line-removed">- </span>
<span class="line-removed">-     AudioUnit renderUnit; // the last unit in our chain</span>
<span class="line-removed">-     CMItemCount totalFrames;</span>
<span class="line-removed">-     </span>
<span class="line-removed">-     // Hold on to these while we&#39;re running</span>
<span class="line-removed">-     AVFSoundLevelUnitPtr audioSLU;</span>
<span class="line-removed">-     AVFAudioSpectrumUnitPtr audioSpectrum;</span>
<span class="line-removed">-     AVFAudioEqualizerPtr audioEQ;</span>
<span class="line-removed">- };</span>
<span class="line-removed">- </span>
  @implementation AVFAudioProcessor
  
  - (id) init {
      if ((self = [super init]) != nil) {
          _soundLevelUnit = AVFSoundLevelUnitPtr(new AVFSoundLevelUnit());
<span class="line-new-header">--- 27,33 ---</span>
  #import &quot;AVFMediaPlayer.h&quot;
  
  #import &lt;AVFoundation/AVFoundation.h&gt;
  #import &lt;MediaToolbox/MediaToolbox.h&gt;
  
  #import &lt;CoreFoundation/CoreFoundation.h&gt;
  
  #import &lt;pthread.h&gt;
  #import &lt;objc/message.h&gt;
  
  static void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut);
  static void FinalizeAudioTap(MTAudioProcessingTapRef tapRef);
  static void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">!         CMItemCount maxFrames,</span>
<span class="line-modified">!         const AudioStreamBasicDescription *processingFormat);</span>
  static void UnprepareAudioTap(MTAudioProcessingTapRef tapRef);
  static void ProcessAudioTap(MTAudioProcessingTapRef tapRef, CMItemCount numberFrames,
<span class="line-modified">!         MTAudioProcessingTapFlags flags,</span>
<span class="line-modified">!         AudioBufferList *bufferListInOut,</span>
<span class="line-modified">!         CMItemCount *numberFramesOut,</span>
<span class="line-modified">!         MTAudioProcessingTapFlags *flagsOut);</span>
  static OSStatus AVFTapRenderCallback(void *inRefCon,
                                       AudioUnitRenderActionFlags *ioActionFlags,
                                       const AudioTimeStamp *inTimeStamp,
                                       UInt32 inBusNumber,
                                       UInt32 inNumberFrames,
                                       AudioBufferList *ioData);
  
  @implementation AVFAudioProcessor
  
  - (id) init {
      if ((self = [super init]) != nil) {
          _soundLevelUnit = AVFSoundLevelUnitPtr(new AVFSoundLevelUnit());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 94,55 ***</span>
          _audioDelay = 0LL;
      }
      return self;
  }
  
<span class="line-modified">! - (void) dealloc {</span>
      _soundLevelUnit = nullptr;
      _audioSpectrum = nullptr;
      _audioEqualizer = nullptr;
  }
  
<span class="line-modified">! - (void) setAudioTrack:(AVAssetTrack *)track {</span>
      if (track != _audioTrack) {
          // reset the audio mixer if it&#39;s already been created
          // this theoretically should never happen...
          _mixer = nil;
      }
      _audioTrack = track;
  }
  
<span class="line-modified">! - (AVAudioMix*) mixer {</span>
      if (!self.audioTrack) {
          return nil;
      }
  
      if (!_mixer) {
          AVMutableAudioMix *mixer = [AVMutableAudioMix audioMix];
          if (mixer) {
              AVMutableAudioMixInputParameters *audioMixInputParameters =
<span class="line-modified">!                 [AVMutableAudioMixInputParameters audioMixInputParametersWithTrack:self.audioTrack];</span>
              if (audioMixInputParameters &amp;&amp;
<span class="line-modified">!                 [audioMixInputParameters respondsToSelector:@selector(setAudioTapProcessor:)]) {</span>
                  MTAudioProcessingTapCallbacks callbacks;
  
                  callbacks.version = kMTAudioProcessingTapCallbacksVersion_0;
<span class="line-modified">!                 callbacks.clientInfo = (__bridge void *)self;</span>
                  callbacks.init = InitAudioTap;
                  callbacks.finalize = FinalizeAudioTap;
                  callbacks.prepare = PrepareAudioTap;
                  callbacks.unprepare = UnprepareAudioTap;
                  callbacks.process = ProcessAudioTap;
  
                  MTAudioProcessingTapRef audioProcessingTap;
                  if (noErr == MTAudioProcessingTapCreate(kCFAllocatorDefault, &amp;callbacks,
<span class="line-modified">!                                              kMTAudioProcessingTapCreationFlag_PreEffects,</span>
<span class="line-modified">!                                              &amp;audioProcessingTap))</span>
<span class="line-modified">!                 {</span>
<span class="line-removed">-                     objc_msgSend(audioMixInputParameters,</span>
<span class="line-removed">-                                  @selector(setAudioTapProcessor:),</span>
<span class="line-removed">-                                  audioProcessingTap);</span>
  
                      CFRelease(audioProcessingTap); // owned by the mixer now
                      mixer.inputParameters = @[audioMixInputParameters];
  
                      _mixer = mixer;
<span class="line-new-header">--- 65,52 ---</span>
          _audioDelay = 0LL;
      }
      return self;
  }
  
<span class="line-modified">! -(void) dealloc {</span>
      _soundLevelUnit = nullptr;
      _audioSpectrum = nullptr;
      _audioEqualizer = nullptr;
  }
  
<span class="line-modified">! -(void) setAudioTrack : (AVAssetTrack *) track {</span>
      if (track != _audioTrack) {
          // reset the audio mixer if it&#39;s already been created
          // this theoretically should never happen...
          _mixer = nil;
      }
      _audioTrack = track;
  }
  
<span class="line-modified">! -(AVAudioMix*) mixer {</span>
      if (!self.audioTrack) {
          return nil;
      }
  
      if (!_mixer) {
          AVMutableAudioMix *mixer = [AVMutableAudioMix audioMix];
          if (mixer) {
              AVMutableAudioMixInputParameters *audioMixInputParameters =
<span class="line-modified">!                     [AVMutableAudioMixInputParameters audioMixInputParametersWithTrack : self.audioTrack];</span>
              if (audioMixInputParameters &amp;&amp;
<span class="line-modified">!                     [audioMixInputParameters respondsToSelector : @selector(setAudioTapProcessor :)]) {</span>
                  MTAudioProcessingTapCallbacks callbacks;
  
                  callbacks.version = kMTAudioProcessingTapCallbacksVersion_0;
<span class="line-modified">!                 callbacks.clientInfo = (__bridge void *) self;</span>
                  callbacks.init = InitAudioTap;
                  callbacks.finalize = FinalizeAudioTap;
                  callbacks.prepare = PrepareAudioTap;
                  callbacks.unprepare = UnprepareAudioTap;
                  callbacks.process = ProcessAudioTap;
  
                  MTAudioProcessingTapRef audioProcessingTap;
                  if (noErr == MTAudioProcessingTapCreate(kCFAllocatorDefault, &amp;callbacks,
<span class="line-modified">!                         kMTAudioProcessingTapCreationFlag_PreEffects,</span>
<span class="line-modified">!                         &amp;audioProcessingTap)) {</span>
<span class="line-modified">!                     [audioMixInputParameters setAudioTapProcessor:audioProcessingTap];</span>
  
                      CFRelease(audioProcessingTap); // owned by the mixer now
                      mixer.inputParameters = @[audioMixInputParameters];
  
                      _mixer = mixer;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 151,42 ***</span>
          }
      }
      return _mixer;
  }
  
<span class="line-modified">! - (void) setVolume:(float)volume {</span>
      _volume = volume;
      if (_soundLevelUnit != nullptr) {
          _soundLevelUnit-&gt;setVolume(volume);
      }
  }
  
<span class="line-modified">! - (void) setBalance:(float)balance {</span>
      _balance = balance;
      if (_soundLevelUnit != nullptr) {
          _soundLevelUnit-&gt;setBalance(balance);
      }
  }
  
  @end
  
<span class="line-modified">! void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut)</span>
<span class="line-modified">! {</span>
      // retain the AU kernels so they don&#39;t get freed while we&#39;re running
<span class="line-modified">!     AVFAudioProcessor *processor = (__bridge AVFAudioProcessor *)clientInfo;</span>
      if (processor) {
          AVFTapContext *context = new AVFTapContext(processor.soundLevelUnit,
<span class="line-modified">!                                                    processor.audioSpectrum,</span>
<span class="line-modified">!                                                    processor.audioEqualizer);</span>
          *tapStorageOut = context;
      }
  }
  
<span class="line-modified">! void FinalizeAudioTap(MTAudioProcessingTapRef tapRef)</span>
<span class="line-modified">! {</span>
<span class="line-removed">-     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-removed">- </span>
      if (context) {
          delete context;
      }
  }
  
<span class="line-new-header">--- 119,53 ---</span>
          }
      }
      return _mixer;
  }
  
<span class="line-modified">! -(void) setVolume : (float) volume {</span>
      _volume = volume;
      if (_soundLevelUnit != nullptr) {
          _soundLevelUnit-&gt;setVolume(volume);
      }
  }
  
<span class="line-modified">! -(void) setBalance : (float) balance {</span>
      _balance = balance;
      if (_soundLevelUnit != nullptr) {
          _soundLevelUnit-&gt;setBalance(balance);
      }
  }
  
  @end
  
<span class="line-modified">! AVFTapContext::AVFTapContext(AVFSoundLevelUnitPtr slu, AVFAudioSpectrumUnitPtr spectrum,</span>
<span class="line-modified">!                              AVFAudioEqualizerPtr eq) : audioSLU(slu),</span>
<span class="line-added">+                                                         audioSpectrum(spectrum),</span>
<span class="line-added">+                                                         audioEQ(eq),</span>
<span class="line-added">+                                                         // Some reasonable defaults</span>
<span class="line-added">+                                                         mSampleRate(48000),</span>
<span class="line-added">+                                                         mChannels(2) {</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ AVFTapContext::~AVFTapContext() {</span>
<span class="line-added">+     // AudioUnits have already been deallocated by now</span>
<span class="line-added">+     // shared_ptrs get freed automatically</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
<span class="line-added">+ void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut) {</span>
      // retain the AU kernels so they don&#39;t get freed while we&#39;re running
<span class="line-modified">!     AVFAudioProcessor *processor = (__bridge AVFAudioProcessor *) clientInfo;</span>
      if (processor) {
          AVFTapContext *context = new AVFTapContext(processor.soundLevelUnit,
<span class="line-modified">!                 processor.audioSpectrum,</span>
<span class="line-modified">!                 processor.audioEqualizer);</span>
          *tapStorageOut = context;
      }
  }
  
<span class="line-modified">! void FinalizeAudioTap(MTAudioProcessingTapRef tapRef) {</span>
<span class="line-modified">!     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);</span>
      if (context) {
          delete context;
      }
  }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 216,222 ***</span>
          status = AudioUnitInitialize(unit);
      }
      return status;
  }
  
<span class="line-removed">- static OSStatus ConnectAudioUnits(AudioUnit source, AudioUnit sink) {</span>
<span class="line-removed">-     AudioUnitConnection connection;</span>
<span class="line-removed">-     connection.sourceAudioUnit = source;</span>
<span class="line-removed">-     connection.sourceOutputNumber = 0;</span>
<span class="line-removed">-     connection.destInputNumber = 0;</span>
<span class="line-removed">-     return AudioUnitSetProperty(sink, kAudioUnitProperty_MakeConnection,</span>
<span class="line-removed">-                                 kAudioUnitScope_Input, 0,</span>
<span class="line-removed">-                                 &amp;connection, sizeof(connection));</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- AudioUnit FindAudioUnit(OSType type, OSType subType, OSType manu) {</span>
<span class="line-removed">-     AudioUnit audioUnit = NULL;</span>
<span class="line-removed">- </span>
<span class="line-removed">-     AudioComponentDescription audioComponentDescription;</span>
<span class="line-removed">-     audioComponentDescription.componentType = type;</span>
<span class="line-removed">-     audioComponentDescription.componentSubType = subType;</span>
<span class="line-removed">-     audioComponentDescription.componentManufacturer = manu;</span>
<span class="line-removed">-     audioComponentDescription.componentFlags = 0;</span>
<span class="line-removed">-     audioComponentDescription.componentFlagsMask = 0;</span>
<span class="line-removed">- </span>
<span class="line-removed">-     AudioComponent audioComponent = AudioComponentFindNext(NULL, &amp;audioComponentDescription);</span>
<span class="line-removed">-     if (audioComponent) {</span>
<span class="line-removed">-         AudioComponentInstanceNew(audioComponent, &amp;audioUnit);</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     return audioUnit;</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
  void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">!                      CMItemCount maxFrames,</span>
<span class="line-modified">!                      const AudioStreamBasicDescription *processingFormat)</span>
<span class="line-modified">! {</span>
<span class="line-removed">-     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
  
      // Validate the audio format before we enable the processor
<span class="line-removed">- </span>
      // Failures here should rarely, if ever, happen so leave the NSLogs in for
      // easier diagnosis in the field
      if (processingFormat-&gt;mFormatID != kAudioFormatLinearPCM) {
          NSLog(@&quot;AVFAudioProcessor needs linear PCM&quot;);
          return;
      }
  
      // Use the convenient kAudioFormatFlagsNativeFloatPacked to check if we can
      // process the incoming audio
      if ((processingFormat-&gt;mFormatFlags &amp; kAudioFormatFlagsNativeFloatPacked)
<span class="line-modified">!         != kAudioFormatFlagsNativeFloatPacked) {</span>
          NSLog(@&quot;AVFAudioProcessor needs native endian packed float samples!!&quot;);
          return;
      }
  
<span class="line-modified">!     // Get an instance of our sound level unit</span>
<span class="line-modified">!     context-&gt;eqUnit = NULL;</span>
      if (context-&gt;audioEQ != nullptr) {
<span class="line-modified">!         context-&gt;eqUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioEQ));</span>
<span class="line-modified">!         if (context-&gt;eqUnit) {</span>
<span class="line-modified">!             OSStatus status = SetupAudioUnit(context-&gt;eqUnit,</span>
<span class="line-removed">-                                              processingFormat,</span>
<span class="line-removed">-                                              (UInt32)maxFrames);</span>
<span class="line-removed">-             if (noErr != status) {</span>
<span class="line-removed">-                 NSLog(@&quot;Error creating audio equalizer unit: %d&quot;, status);</span>
<span class="line-removed">-                 AudioComponentInstanceDispose(context-&gt;eqUnit);</span>
<span class="line-removed">-                 context-&gt;eqUnit = NULL;</span>
<span class="line-removed">-             }</span>
<span class="line-removed">-         }</span>
      }
  
<span class="line-modified">!     context-&gt;spectrumUnit = NULL;</span>
      if (context-&gt;audioSpectrum != nullptr) {
<span class="line-modified">!         context-&gt;spectrumUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioSpectrum));</span>
<span class="line-modified">!         if (context-&gt;spectrumUnit) {</span>
<span class="line-modified">!             OSStatus status = SetupAudioUnit(context-&gt;spectrumUnit,</span>
<span class="line-removed">-                                              processingFormat,</span>
<span class="line-removed">-                                              (UInt32)maxFrames);</span>
<span class="line-removed">-             if (noErr != status) {</span>
<span class="line-removed">-                 NSLog(@&quot;Error creating audio spectrum unit: %d&quot;, status);</span>
<span class="line-removed">-                 AudioComponentInstanceDispose(context-&gt;spectrumUnit);</span>
<span class="line-removed">-                 context-&gt;spectrumUnit = NULL;</span>
<span class="line-removed">-             }</span>
<span class="line-removed">-         }</span>
      }
  
<span class="line-removed">-     context-&gt;volumeUnit = NULL;</span>
      if (context-&gt;audioSLU != nullptr) {
<span class="line-modified">!         context-&gt;volumeUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioSLU));</span>
<span class="line-removed">-         if (context-&gt;volumeUnit) {</span>
<span class="line-removed">-             OSStatus status = SetupAudioUnit(context-&gt;volumeUnit,</span>
<span class="line-removed">-                                              processingFormat,</span>
<span class="line-removed">-                                              (UInt32)maxFrames);</span>
<span class="line-removed">-             if (noErr != status) {</span>
<span class="line-removed">-                 NSLog(@&quot;Error setting up Sound Level Unit: %d&quot;, status);</span>
<span class="line-removed">-                 AudioComponentInstanceDispose(context-&gt;volumeUnit);</span>
<span class="line-removed">-                 context-&gt;volumeUnit = NULL;</span>
<span class="line-removed">-             }</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
<span class="line-removed">-     /*</span>
<span class="line-removed">-      * Use AudioUnitConnections to build a processing graph</span>
<span class="line-removed">-      * The last unit in the chain will be the unit we call to render, it will</span>
<span class="line-removed">-      * pull through the graph until we get to the first, which will fetch samples</span>
<span class="line-removed">-      * via the render proc we install.</span>
<span class="line-removed">-      *</span>
<span class="line-removed">-      * The graph will look like this:</span>
<span class="line-removed">-      *    (render proc) -&gt; eqUnit -&gt; spectrumUnit -&gt; volUnit</span>
<span class="line-removed">-      *</span>
<span class="line-removed">-      * This will allow the EQ settings to affect the spectrum output, but not</span>
<span class="line-removed">-      * the volume or balance.</span>
<span class="line-removed">-      */</span>
<span class="line-removed">-     AudioUnit firstUnit = NULL;</span>
<span class="line-removed">-     context-&gt;renderUnit = NULL;</span>
<span class="line-removed">- </span>
<span class="line-removed">-     // Set initial settings</span>
<span class="line-removed">-     if (context-&gt;eqUnit) {</span>
<span class="line-removed">-         if (context-&gt;renderUnit) {</span>
<span class="line-removed">-             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;eqUnit);</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-         context-&gt;renderUnit = context-&gt;eqUnit;</span>
<span class="line-removed">-         if (!firstUnit) {</span>
<span class="line-removed">-             firstUnit = context-&gt;eqUnit;</span>
<span class="line-removed">-         }</span>
      }
<span class="line-removed">-     if (context-&gt;spectrumUnit) {</span>
<span class="line-removed">-         if (context-&gt;renderUnit) {</span>
<span class="line-removed">-             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;spectrumUnit);</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-         context-&gt;renderUnit = context-&gt;spectrumUnit;</span>
<span class="line-removed">-         if (!firstUnit) {</span>
<span class="line-removed">-             firstUnit = context-&gt;spectrumUnit;</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     if (context-&gt;volumeUnit) {</span>
<span class="line-removed">-         if (context-&gt;renderUnit) {</span>
<span class="line-removed">-             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;volumeUnit);</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-         context-&gt;renderUnit = context-&gt;volumeUnit;</span>
<span class="line-removed">-         if (!firstUnit) {</span>
<span class="line-removed">-             firstUnit = context-&gt;volumeUnit;</span>
<span class="line-removed">-         }</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
<span class="line-removed">-     // Set up a render callback on our first unit</span>
<span class="line-removed">-     if (firstUnit) {</span>
<span class="line-removed">-         AURenderCallbackStruct renderCB;</span>
<span class="line-removed">-         renderCB.inputProc = (AURenderCallback)AVFTapRenderCallback;</span>
<span class="line-removed">-         renderCB.inputProcRefCon = (void*)tapRef;</span>
<span class="line-removed">-         AudioUnitSetProperty(firstUnit,</span>
<span class="line-removed">-                              kAudioUnitProperty_SetRenderCallback,</span>
<span class="line-removed">-                              kAudioUnitScope_Input, 0,</span>
<span class="line-removed">-                              &amp;renderCB, sizeof(renderCB));</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     context-&gt;totalFrames = 0;</span>
  }
  
<span class="line-modified">! void UnprepareAudioTap(MTAudioProcessingTapRef tapRef)</span>
<span class="line-modified">! {</span>
<span class="line-removed">-     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-removed">-     context-&gt;renderUnit = NULL;</span>
<span class="line-removed">- </span>
<span class="line-removed">-     if (context-&gt;spectrumUnit) {</span>
<span class="line-removed">-         AudioUnitUninitialize(context-&gt;spectrumUnit);</span>
<span class="line-removed">-         AudioComponentInstanceDispose(context-&gt;spectrumUnit);</span>
<span class="line-removed">-         context-&gt;spectrumUnit = NULL;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     if (context-&gt;volumeUnit) {</span>
<span class="line-removed">-         AudioUnitUninitialize(context-&gt;volumeUnit);</span>
<span class="line-removed">-         AudioComponentInstanceDispose(context-&gt;volumeUnit);</span>
<span class="line-removed">-         context-&gt;volumeUnit = NULL;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     if (context-&gt;eqUnit) {</span>
<span class="line-removed">-         AudioUnitUninitialize(context-&gt;eqUnit);</span>
<span class="line-removed">-         AudioComponentInstanceDispose(context-&gt;eqUnit);</span>
<span class="line-removed">-         context-&gt;eqUnit = NULL;</span>
<span class="line-removed">-     }</span>
  }
  
  void ProcessAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">!                      CMItemCount numberFrames,</span>
<span class="line-modified">!                      uint32_t flags,</span>
<span class="line-modified">!                      AudioBufferList *bufferListInOut,</span>
<span class="line-modified">!                      CMItemCount *numberFramesOut,</span>
<span class="line-modified">!                      uint32_t *flagsOut)</span>
<span class="line-modified">! {</span>
<span class="line-modified">!     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-modified">!     OSStatus status = noErr;</span>
  
<span class="line-modified">!     if (context-&gt;renderUnit) {</span>
<span class="line-modified">!         AudioTimeStamp audioTimeStamp;</span>
<span class="line-modified">!         audioTimeStamp.mSampleTime = context-&gt;totalFrames;</span>
<span class="line-removed">-         audioTimeStamp.mFlags = kAudioTimeStampSampleTimeValid;</span>
<span class="line-removed">- </span>
<span class="line-removed">-         status = AudioUnitRender(context-&gt;renderUnit,</span>
<span class="line-removed">-                                  0,</span>
<span class="line-removed">-                                  &amp;audioTimeStamp,</span>
<span class="line-removed">-                                  0,</span>
<span class="line-removed">-                                  (UInt32)numberFrames,</span>
<span class="line-removed">-                                  bufferListInOut);</span>
<span class="line-removed">-         if (noErr != status) {</span>
              return;
          }
<span class="line-removed">-         context-&gt;totalFrames += numberFrames;</span>
<span class="line-removed">-         *numberFramesOut = numberFrames;</span>
<span class="line-removed">-     } else {</span>
<span class="line-removed">-         MTAudioProcessingTapGetSourceAudio(tapRef, numberFrames, bufferListInOut,</span>
<span class="line-removed">-                                 flagsOut, NULL, numberFramesOut);</span>
      }
<span class="line-removed">- }</span>
  
<span class="line-modified">! static OSStatus AVFTapRenderCallback(void *inRefCon,</span>
<span class="line-modified">!                                      AudioUnitRenderActionFlags *ioActionFlags,</span>
<span class="line-modified">!                                      const AudioTimeStamp *inTimeStamp,</span>
<span class="line-modified">!                                      UInt32 inBusNumber,</span>
<span class="line-modified">!                                      UInt32 inNumberFrames,</span>
<span class="line-modified">!                                      AudioBufferList *ioData)</span>
<span class="line-modified">! {</span>
<span class="line-modified">!     MTAudioProcessingTapRef tapRef = static_cast&lt;MTAudioProcessingTapRef&gt;(inRefCon);</span>
<span class="line-modified">!     return MTAudioProcessingTapGetSourceAudio(tapRef, inNumberFrames, ioData, NULL, NULL, NULL);</span>
  }
<span class="line-new-header">--- 195,88 ---</span>
          status = AudioUnitInitialize(unit);
      }
      return status;
  }
  
  void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">!         CMItemCount maxFrames,</span>
<span class="line-modified">!         const AudioStreamBasicDescription *processingFormat) {</span>
<span class="line-modified">!     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);</span>
  
      // Validate the audio format before we enable the processor
      // Failures here should rarely, if ever, happen so leave the NSLogs in for
      // easier diagnosis in the field
      if (processingFormat-&gt;mFormatID != kAudioFormatLinearPCM) {
          NSLog(@&quot;AVFAudioProcessor needs linear PCM&quot;);
          return;
      }
  
      // Use the convenient kAudioFormatFlagsNativeFloatPacked to check if we can
      // process the incoming audio
      if ((processingFormat-&gt;mFormatFlags &amp; kAudioFormatFlagsNativeFloatPacked)
<span class="line-modified">!             != kAudioFormatFlagsNativeFloatPacked) {</span>
          NSLog(@&quot;AVFAudioProcessor needs native endian packed float samples!!&quot;);
          return;
      }
  
<span class="line-modified">!     context-&gt;mSampleRate = processingFormat-&gt;mSampleRate;</span>
<span class="line-modified">!     context-&gt;mChannels = processingFormat-&gt;mChannelsPerFrame;</span>
<span class="line-added">+     context-&gt;mMaxFrames = maxFrames;</span>
<span class="line-added">+ </span>
<span class="line-added">+     // Configure audio equalizer</span>
      if (context-&gt;audioEQ != nullptr) {
<span class="line-modified">!         context-&gt;audioEQ.get()-&gt;SetSampleRate(context-&gt;mSampleRate);</span>
<span class="line-modified">!         context-&gt;audioEQ.get()-&gt;SetChannels(context-&gt;mChannels);</span>
<span class="line-modified">!         context-&gt;audioEQ.get()-&gt;ResetBandParameters();</span>
      }
  
<span class="line-modified">!     // Configure spectrum</span>
      if (context-&gt;audioSpectrum != nullptr) {
<span class="line-modified">!         context-&gt;audioSpectrum.get()-&gt;SetSampleRate(context-&gt;mSampleRate);</span>
<span class="line-modified">!         context-&gt;audioSpectrum.get()-&gt;SetChannels(context-&gt;mChannels);</span>
<span class="line-modified">!         context-&gt;audioSpectrum.get()-&gt;SetMaxFrames(context-&gt;mMaxFrames);</span>
      }
  
      if (context-&gt;audioSLU != nullptr) {
<span class="line-modified">!         context-&gt;audioSLU.get()-&gt;SetChannels(context-&gt;mChannels);</span>
      }
  }
  
<span class="line-modified">! void UnprepareAudioTap(MTAudioProcessingTapRef tapRef) {</span>
<span class="line-modified">!     // We do not need it anymore</span>
  }
  
  void ProcessAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">!         CMItemCount numberFrames,</span>
<span class="line-modified">!         uint32_t flags,</span>
<span class="line-modified">!         AudioBufferList *bufferListInOut,</span>
<span class="line-modified">!         CMItemCount *numberFramesOut,</span>
<span class="line-modified">!         uint32_t *flagsOut) {</span>
<span class="line-modified">!     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-modified">!     OSStatus status = MTAudioProcessingTapGetSourceAudio(tapRef, numberFrames, bufferListInOut,</span>
<span class="line-modified">!             flagsOut, NULL, numberFramesOut);</span>
<span class="line-added">+     if (status != noErr) {</span>
<span class="line-added">+         NSLog(@&quot;MTAudioProcessingTapGetSourceAudio failed: %d&quot;, status);</span>
<span class="line-added">+         return;</span>
<span class="line-added">+     }</span>
  
<span class="line-modified">!     if (context-&gt;audioEQ != nullptr) {</span>
<span class="line-modified">!         if (!context-&gt;audioEQ.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {</span>
<span class="line-modified">!             NSLog(@&quot;audioEQ ProcessBufferLists() failed&quot;);</span>
              return;
          }
      }
  
<span class="line-modified">!     if (context-&gt;audioSpectrum != nullptr) {</span>
<span class="line-modified">!         if (!context-&gt;audioSpectrum.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {</span>
<span class="line-modified">!             NSLog(@&quot;audioSpectrum ProcessBufferLists() failed&quot;);</span>
<span class="line-modified">!             return;</span>
<span class="line-modified">!         }</span>
<span class="line-modified">!     }</span>
<span class="line-modified">! </span>
<span class="line-modified">!     if (context-&gt;audioSLU != nullptr) {</span>
<span class="line-modified">!         if (!context-&gt;audioSLU.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {</span>
<span class="line-added">+             NSLog(@&quot;audioSLU ProcessBufferLists() failed&quot;);</span>
<span class="line-added">+             return;</span>
<span class="line-added">+         }</span>
<span class="line-added">+     }</span>
  }
</pre>
<center><a href="AVFAudioProcessor.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AVFAudioSpectrumUnit.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>