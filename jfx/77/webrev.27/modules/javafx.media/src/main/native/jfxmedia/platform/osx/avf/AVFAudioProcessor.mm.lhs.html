<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.media/src/main/native/jfxmedia/platform/osx/avf/AVFAudioProcessor.mm</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (c) 2014, 2016, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.  Oracle designates this
  8  * particular file as subject to the &quot;Classpath&quot; exception as provided
  9  * by Oracle in the LICENSE file that accompanied this code.
 10  *
 11  * This code is distributed in the hope that it will be useful, but WITHOUT
 12  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 13  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 14  * version 2 for more details (a copy is included in the LICENSE file that
 15  * accompanied this code).
 16  *
 17  * You should have received a copy of the GNU General Public License version
 18  * 2 along with this work; if not, write to the Free Software Foundation,
 19  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 20  *
 21  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 22  * or visit www.oracle.com if you need additional information or have any
 23  * questions.
 24  */
 25 
 26 #import &quot;AVFAudioProcessor.h&quot;
 27 #import &quot;AVFMediaPlayer.h&quot;
 28 
 29 #import &lt;AVFoundation/AVFoundation.h&gt;
 30 #import &lt;MediaToolbox/MediaToolbox.h&gt;
 31 
<a name="2" id="anc2"></a><span class="line-removed"> 32 #import &quot;AVFKernelProcessor.h&quot;</span>
 33 #import &lt;CoreFoundation/CoreFoundation.h&gt;
 34 
 35 #import &lt;pthread.h&gt;
 36 #import &lt;objc/message.h&gt;
 37 
 38 static void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut);
 39 static void FinalizeAudioTap(MTAudioProcessingTapRef tapRef);
 40 static void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<a name="3" id="anc3"></a><span class="line-modified"> 41                             CMItemCount maxFrames,</span>
<span class="line-modified"> 42                             const AudioStreamBasicDescription *processingFormat);</span>
 43 static void UnprepareAudioTap(MTAudioProcessingTapRef tapRef);
 44 static void ProcessAudioTap(MTAudioProcessingTapRef tapRef, CMItemCount numberFrames,
<a name="4" id="anc4"></a><span class="line-modified"> 45                             MTAudioProcessingTapFlags flags,</span>
<span class="line-modified"> 46                             AudioBufferList *bufferListInOut,</span>
<span class="line-modified"> 47                             CMItemCount *numberFramesOut,</span>
<span class="line-modified"> 48                             MTAudioProcessingTapFlags *flagsOut);</span>
<span class="line-removed"> 49 </span>
 50 static OSStatus AVFTapRenderCallback(void *inRefCon,
 51                                      AudioUnitRenderActionFlags *ioActionFlags,
 52                                      const AudioTimeStamp *inTimeStamp,
 53                                      UInt32 inBusNumber,
 54                                      UInt32 inNumberFrames,
 55                                      AudioBufferList *ioData);
 56 
<a name="5" id="anc5"></a><span class="line-removed"> 57 class AVFTapContext {</span>
<span class="line-removed"> 58 public:</span>
<span class="line-removed"> 59     AVFTapContext(AVFSoundLevelUnitPtr slu, AVFAudioSpectrumUnitPtr spectrum, AVFAudioEqualizerPtr eq) :</span>
<span class="line-removed"> 60         audioSLU(slu),</span>
<span class="line-removed"> 61         audioSpectrum(spectrum),</span>
<span class="line-removed"> 62         audioEQ(eq)</span>
<span class="line-removed"> 63     {</span>
<span class="line-removed"> 64     }</span>
<span class="line-removed"> 65 </span>
<span class="line-removed"> 66     ~AVFTapContext() {</span>
<span class="line-removed"> 67         // AudioUnits have already been deallocated by now</span>
<span class="line-removed"> 68         // shared_ptrs get freed automatically</span>
<span class="line-removed"> 69     }</span>
<span class="line-removed"> 70 </span>
<span class="line-removed"> 71     AudioUnit spectrumUnit;</span>
<span class="line-removed"> 72     AudioUnit volumeUnit;</span>
<span class="line-removed"> 73     AudioUnit eqUnit;</span>
<span class="line-removed"> 74 </span>
<span class="line-removed"> 75     AudioUnit renderUnit; // the last unit in our chain</span>
<span class="line-removed"> 76     CMItemCount totalFrames;</span>
<span class="line-removed"> 77     </span>
<span class="line-removed"> 78     // Hold on to these while we&#39;re running</span>
<span class="line-removed"> 79     AVFSoundLevelUnitPtr audioSLU;</span>
<span class="line-removed"> 80     AVFAudioSpectrumUnitPtr audioSpectrum;</span>
<span class="line-removed"> 81     AVFAudioEqualizerPtr audioEQ;</span>
<span class="line-removed"> 82 };</span>
<span class="line-removed"> 83 </span>
 84 @implementation AVFAudioProcessor
 85 
 86 - (id) init {
 87     if ((self = [super init]) != nil) {
 88         _soundLevelUnit = AVFSoundLevelUnitPtr(new AVFSoundLevelUnit());
 89         _audioSpectrum = AVFAudioSpectrumUnitPtr(new AVFAudioSpectrumUnit());
 90         _audioEqualizer = AVFAudioEqualizerPtr(new AVFAudioEqualizer());
 91 
 92         _volume = 1.0f;
 93         _balance = 0.0f;
 94         _audioDelay = 0LL;
 95     }
 96     return self;
 97 }
 98 
<a name="6" id="anc6"></a><span class="line-modified"> 99 - (void) dealloc {</span>
100     _soundLevelUnit = nullptr;
101     _audioSpectrum = nullptr;
102     _audioEqualizer = nullptr;
103 }
104 
<a name="7" id="anc7"></a><span class="line-modified">105 - (void) setAudioTrack:(AVAssetTrack *)track {</span>
106     if (track != _audioTrack) {
107         // reset the audio mixer if it&#39;s already been created
108         // this theoretically should never happen...
109         _mixer = nil;
110     }
111     _audioTrack = track;
112 }
113 
<a name="8" id="anc8"></a><span class="line-modified">114 - (AVAudioMix*) mixer {</span>
115     if (!self.audioTrack) {
116         return nil;
117     }
118 
119     if (!_mixer) {
120         AVMutableAudioMix *mixer = [AVMutableAudioMix audioMix];
121         if (mixer) {
122             AVMutableAudioMixInputParameters *audioMixInputParameters =
<a name="9" id="anc9"></a><span class="line-modified">123                 [AVMutableAudioMixInputParameters audioMixInputParametersWithTrack:self.audioTrack];</span>
124             if (audioMixInputParameters &amp;&amp;
<a name="10" id="anc10"></a><span class="line-modified">125                 [audioMixInputParameters respondsToSelector:@selector(setAudioTapProcessor:)]) {</span>
126                 MTAudioProcessingTapCallbacks callbacks;
127 
128                 callbacks.version = kMTAudioProcessingTapCallbacksVersion_0;
<a name="11" id="anc11"></a><span class="line-modified">129                 callbacks.clientInfo = (__bridge void *)self;</span>
130                 callbacks.init = InitAudioTap;
131                 callbacks.finalize = FinalizeAudioTap;
132                 callbacks.prepare = PrepareAudioTap;
133                 callbacks.unprepare = UnprepareAudioTap;
134                 callbacks.process = ProcessAudioTap;
135 
136                 MTAudioProcessingTapRef audioProcessingTap;
137                 if (noErr == MTAudioProcessingTapCreate(kCFAllocatorDefault, &amp;callbacks,
<a name="12" id="anc12"></a><span class="line-modified">138                                              kMTAudioProcessingTapCreationFlag_PreEffects,</span>
<span class="line-modified">139                                              &amp;audioProcessingTap))</span>
<span class="line-modified">140                 {</span>
<span class="line-removed">141                     objc_msgSend(audioMixInputParameters,</span>
<span class="line-removed">142                                  @selector(setAudioTapProcessor:),</span>
<span class="line-removed">143                                  audioProcessingTap);</span>
144 
145                     CFRelease(audioProcessingTap); // owned by the mixer now
146                     mixer.inputParameters = @[audioMixInputParameters];
147 
148                     _mixer = mixer;
149                 }
150             }
151         }
152     }
153     return _mixer;
154 }
155 
<a name="13" id="anc13"></a><span class="line-modified">156 - (void) setVolume:(float)volume {</span>
157     _volume = volume;
158     if (_soundLevelUnit != nullptr) {
159         _soundLevelUnit-&gt;setVolume(volume);
160     }
161 }
162 
<a name="14" id="anc14"></a><span class="line-modified">163 - (void) setBalance:(float)balance {</span>
164     _balance = balance;
165     if (_soundLevelUnit != nullptr) {
166         _soundLevelUnit-&gt;setBalance(balance);
167     }
168 }
169 
170 @end
171 
<a name="15" id="anc15"></a><span class="line-modified">172 void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut)</span>
<span class="line-modified">173 {</span>













174     // retain the AU kernels so they don&#39;t get freed while we&#39;re running
<a name="16" id="anc16"></a><span class="line-modified">175     AVFAudioProcessor *processor = (__bridge AVFAudioProcessor *)clientInfo;</span>
176     if (processor) {
177         AVFTapContext *context = new AVFTapContext(processor.soundLevelUnit,
<a name="17" id="anc17"></a><span class="line-modified">178                                                    processor.audioSpectrum,</span>
<span class="line-modified">179                                                    processor.audioEqualizer);</span>
180         *tapStorageOut = context;
181     }
182 }
183 
<a name="18" id="anc18"></a><span class="line-modified">184 void FinalizeAudioTap(MTAudioProcessingTapRef tapRef)</span>
<span class="line-modified">185 {</span>
<span class="line-removed">186     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-removed">187 </span>
188     if (context) {
189         delete context;
190     }
191 }
192 
193 static OSStatus SetupAudioUnit(AudioUnit unit,
194                                const AudioStreamBasicDescription *processingFormat,
195                                UInt32 maxFrames) {
196     OSStatus status = noErr;
197     if (noErr == status) {
198         status = AudioUnitSetProperty(unit,
199                                       kAudioUnitProperty_StreamFormat,
200                                       kAudioUnitScope_Input, 0,
201                                       processingFormat, sizeof(AudioStreamBasicDescription));
202     }
203     if (noErr == status) {
204         status = AudioUnitSetProperty(unit,
205                                       kAudioUnitProperty_StreamFormat,
206                                       kAudioUnitScope_Output, 0,
207                                       processingFormat, sizeof(AudioStreamBasicDescription));
208     }
209     if (noErr == status) {
210         status = AudioUnitSetProperty(unit,
211                                       kAudioUnitProperty_MaximumFramesPerSlice,
212                                       kAudioUnitScope_Global, 0,
213                                       &amp;maxFrames, sizeof(UInt32));
214     }
215     if (noErr == status) {
216         status = AudioUnitInitialize(unit);
217     }
218     return status;
219 }
220 
<a name="19" id="anc19"></a><span class="line-removed">221 static OSStatus ConnectAudioUnits(AudioUnit source, AudioUnit sink) {</span>
<span class="line-removed">222     AudioUnitConnection connection;</span>
<span class="line-removed">223     connection.sourceAudioUnit = source;</span>
<span class="line-removed">224     connection.sourceOutputNumber = 0;</span>
<span class="line-removed">225     connection.destInputNumber = 0;</span>
<span class="line-removed">226     return AudioUnitSetProperty(sink, kAudioUnitProperty_MakeConnection,</span>
<span class="line-removed">227                                 kAudioUnitScope_Input, 0,</span>
<span class="line-removed">228                                 &amp;connection, sizeof(connection));</span>
<span class="line-removed">229 }</span>
<span class="line-removed">230 </span>
<span class="line-removed">231 AudioUnit FindAudioUnit(OSType type, OSType subType, OSType manu) {</span>
<span class="line-removed">232     AudioUnit audioUnit = NULL;</span>
<span class="line-removed">233 </span>
<span class="line-removed">234     AudioComponentDescription audioComponentDescription;</span>
<span class="line-removed">235     audioComponentDescription.componentType = type;</span>
<span class="line-removed">236     audioComponentDescription.componentSubType = subType;</span>
<span class="line-removed">237     audioComponentDescription.componentManufacturer = manu;</span>
<span class="line-removed">238     audioComponentDescription.componentFlags = 0;</span>
<span class="line-removed">239     audioComponentDescription.componentFlagsMask = 0;</span>
<span class="line-removed">240 </span>
<span class="line-removed">241     AudioComponent audioComponent = AudioComponentFindNext(NULL, &amp;audioComponentDescription);</span>
<span class="line-removed">242     if (audioComponent) {</span>
<span class="line-removed">243         AudioComponentInstanceNew(audioComponent, &amp;audioUnit);</span>
<span class="line-removed">244     }</span>
<span class="line-removed">245     return audioUnit;</span>
<span class="line-removed">246 }</span>
<span class="line-removed">247 </span>
248 void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<a name="20" id="anc20"></a><span class="line-modified">249                      CMItemCount maxFrames,</span>
<span class="line-modified">250                      const AudioStreamBasicDescription *processingFormat)</span>
<span class="line-modified">251 {</span>
<span class="line-removed">252     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
253 
254     // Validate the audio format before we enable the processor
<a name="21" id="anc21"></a><span class="line-removed">255 </span>
256     // Failures here should rarely, if ever, happen so leave the NSLogs in for
257     // easier diagnosis in the field
258     if (processingFormat-&gt;mFormatID != kAudioFormatLinearPCM) {
259         NSLog(@&quot;AVFAudioProcessor needs linear PCM&quot;);
260         return;
261     }
262 
263     // Use the convenient kAudioFormatFlagsNativeFloatPacked to check if we can
264     // process the incoming audio
265     if ((processingFormat-&gt;mFormatFlags &amp; kAudioFormatFlagsNativeFloatPacked)
<a name="22" id="anc22"></a><span class="line-modified">266         != kAudioFormatFlagsNativeFloatPacked) {</span>
267         NSLog(@&quot;AVFAudioProcessor needs native endian packed float samples!!&quot;);
268         return;
269     }
270 
<a name="23" id="anc23"></a><span class="line-modified">271     // Get an instance of our sound level unit</span>
<span class="line-modified">272     context-&gt;eqUnit = NULL;</span>



273     if (context-&gt;audioEQ != nullptr) {
<a name="24" id="anc24"></a><span class="line-modified">274         context-&gt;eqUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioEQ));</span>
<span class="line-modified">275         if (context-&gt;eqUnit) {</span>
<span class="line-modified">276             OSStatus status = SetupAudioUnit(context-&gt;eqUnit,</span>
<span class="line-removed">277                                              processingFormat,</span>
<span class="line-removed">278                                              (UInt32)maxFrames);</span>
<span class="line-removed">279             if (noErr != status) {</span>
<span class="line-removed">280                 NSLog(@&quot;Error creating audio equalizer unit: %d&quot;, status);</span>
<span class="line-removed">281                 AudioComponentInstanceDispose(context-&gt;eqUnit);</span>
<span class="line-removed">282                 context-&gt;eqUnit = NULL;</span>
<span class="line-removed">283             }</span>
<span class="line-removed">284         }</span>
285     }
286 
<a name="25" id="anc25"></a><span class="line-modified">287     context-&gt;spectrumUnit = NULL;</span>
288     if (context-&gt;audioSpectrum != nullptr) {
<a name="26" id="anc26"></a><span class="line-modified">289         context-&gt;spectrumUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioSpectrum));</span>
<span class="line-modified">290         if (context-&gt;spectrumUnit) {</span>
<span class="line-modified">291             OSStatus status = SetupAudioUnit(context-&gt;spectrumUnit,</span>
<span class="line-removed">292                                              processingFormat,</span>
<span class="line-removed">293                                              (UInt32)maxFrames);</span>
<span class="line-removed">294             if (noErr != status) {</span>
<span class="line-removed">295                 NSLog(@&quot;Error creating audio spectrum unit: %d&quot;, status);</span>
<span class="line-removed">296                 AudioComponentInstanceDispose(context-&gt;spectrumUnit);</span>
<span class="line-removed">297                 context-&gt;spectrumUnit = NULL;</span>
<span class="line-removed">298             }</span>
<span class="line-removed">299         }</span>
300     }
301 
<a name="27" id="anc27"></a><span class="line-removed">302     context-&gt;volumeUnit = NULL;</span>
303     if (context-&gt;audioSLU != nullptr) {
<a name="28" id="anc28"></a><span class="line-modified">304         context-&gt;volumeUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioSLU));</span>
<span class="line-removed">305         if (context-&gt;volumeUnit) {</span>
<span class="line-removed">306             OSStatus status = SetupAudioUnit(context-&gt;volumeUnit,</span>
<span class="line-removed">307                                              processingFormat,</span>
<span class="line-removed">308                                              (UInt32)maxFrames);</span>
<span class="line-removed">309             if (noErr != status) {</span>
<span class="line-removed">310                 NSLog(@&quot;Error setting up Sound Level Unit: %d&quot;, status);</span>
<span class="line-removed">311                 AudioComponentInstanceDispose(context-&gt;volumeUnit);</span>
<span class="line-removed">312                 context-&gt;volumeUnit = NULL;</span>
<span class="line-removed">313             }</span>
<span class="line-removed">314         }</span>
<span class="line-removed">315     }</span>
<span class="line-removed">316 </span>
<span class="line-removed">317     /*</span>
<span class="line-removed">318      * Use AudioUnitConnections to build a processing graph</span>
<span class="line-removed">319      * The last unit in the chain will be the unit we call to render, it will</span>
<span class="line-removed">320      * pull through the graph until we get to the first, which will fetch samples</span>
<span class="line-removed">321      * via the render proc we install.</span>
<span class="line-removed">322      *</span>
<span class="line-removed">323      * The graph will look like this:</span>
<span class="line-removed">324      *    (render proc) -&gt; eqUnit -&gt; spectrumUnit -&gt; volUnit</span>
<span class="line-removed">325      *</span>
<span class="line-removed">326      * This will allow the EQ settings to affect the spectrum output, but not</span>
<span class="line-removed">327      * the volume or balance.</span>
<span class="line-removed">328      */</span>
<span class="line-removed">329     AudioUnit firstUnit = NULL;</span>
<span class="line-removed">330     context-&gt;renderUnit = NULL;</span>
<span class="line-removed">331 </span>
<span class="line-removed">332     // Set initial settings</span>
<span class="line-removed">333     if (context-&gt;eqUnit) {</span>
<span class="line-removed">334         if (context-&gt;renderUnit) {</span>
<span class="line-removed">335             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;eqUnit);</span>
<span class="line-removed">336         }</span>
<span class="line-removed">337         context-&gt;renderUnit = context-&gt;eqUnit;</span>
<span class="line-removed">338         if (!firstUnit) {</span>
<span class="line-removed">339             firstUnit = context-&gt;eqUnit;</span>
<span class="line-removed">340         }</span>
341     }
<a name="29" id="anc29"></a><span class="line-removed">342     if (context-&gt;spectrumUnit) {</span>
<span class="line-removed">343         if (context-&gt;renderUnit) {</span>
<span class="line-removed">344             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;spectrumUnit);</span>
<span class="line-removed">345         }</span>
<span class="line-removed">346         context-&gt;renderUnit = context-&gt;spectrumUnit;</span>
<span class="line-removed">347         if (!firstUnit) {</span>
<span class="line-removed">348             firstUnit = context-&gt;spectrumUnit;</span>
<span class="line-removed">349         }</span>
<span class="line-removed">350     }</span>
<span class="line-removed">351     if (context-&gt;volumeUnit) {</span>
<span class="line-removed">352         if (context-&gt;renderUnit) {</span>
<span class="line-removed">353             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;volumeUnit);</span>
<span class="line-removed">354         }</span>
<span class="line-removed">355         context-&gt;renderUnit = context-&gt;volumeUnit;</span>
<span class="line-removed">356         if (!firstUnit) {</span>
<span class="line-removed">357             firstUnit = context-&gt;volumeUnit;</span>
<span class="line-removed">358         }</span>
<span class="line-removed">359     }</span>
<span class="line-removed">360 </span>
<span class="line-removed">361     // Set up a render callback on our first unit</span>
<span class="line-removed">362     if (firstUnit) {</span>
<span class="line-removed">363         AURenderCallbackStruct renderCB;</span>
<span class="line-removed">364         renderCB.inputProc = (AURenderCallback)AVFTapRenderCallback;</span>
<span class="line-removed">365         renderCB.inputProcRefCon = (void*)tapRef;</span>
<span class="line-removed">366         AudioUnitSetProperty(firstUnit,</span>
<span class="line-removed">367                              kAudioUnitProperty_SetRenderCallback,</span>
<span class="line-removed">368                              kAudioUnitScope_Input, 0,</span>
<span class="line-removed">369                              &amp;renderCB, sizeof(renderCB));</span>
<span class="line-removed">370     }</span>
<span class="line-removed">371     context-&gt;totalFrames = 0;</span>
372 }
373 
<a name="30" id="anc30"></a><span class="line-modified">374 void UnprepareAudioTap(MTAudioProcessingTapRef tapRef)</span>
<span class="line-modified">375 {</span>
<span class="line-removed">376     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-removed">377     context-&gt;renderUnit = NULL;</span>
<span class="line-removed">378 </span>
<span class="line-removed">379     if (context-&gt;spectrumUnit) {</span>
<span class="line-removed">380         AudioUnitUninitialize(context-&gt;spectrumUnit);</span>
<span class="line-removed">381         AudioComponentInstanceDispose(context-&gt;spectrumUnit);</span>
<span class="line-removed">382         context-&gt;spectrumUnit = NULL;</span>
<span class="line-removed">383     }</span>
<span class="line-removed">384     if (context-&gt;volumeUnit) {</span>
<span class="line-removed">385         AudioUnitUninitialize(context-&gt;volumeUnit);</span>
<span class="line-removed">386         AudioComponentInstanceDispose(context-&gt;volumeUnit);</span>
<span class="line-removed">387         context-&gt;volumeUnit = NULL;</span>
<span class="line-removed">388     }</span>
<span class="line-removed">389     if (context-&gt;eqUnit) {</span>
<span class="line-removed">390         AudioUnitUninitialize(context-&gt;eqUnit);</span>
<span class="line-removed">391         AudioComponentInstanceDispose(context-&gt;eqUnit);</span>
<span class="line-removed">392         context-&gt;eqUnit = NULL;</span>
<span class="line-removed">393     }</span>
394 }
395 
396 void ProcessAudioTap(MTAudioProcessingTapRef tapRef,
<a name="31" id="anc31"></a><span class="line-modified">397                      CMItemCount numberFrames,</span>
<span class="line-modified">398                      uint32_t flags,</span>
<span class="line-modified">399                      AudioBufferList *bufferListInOut,</span>
<span class="line-modified">400                      CMItemCount *numberFramesOut,</span>
<span class="line-modified">401                      uint32_t *flagsOut)</span>
<span class="line-modified">402 {</span>
<span class="line-modified">403     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-modified">404     OSStatus status = noErr;</span>




405 
<a name="32" id="anc32"></a><span class="line-modified">406     if (context-&gt;renderUnit) {</span>
<span class="line-modified">407         AudioTimeStamp audioTimeStamp;</span>
<span class="line-modified">408         audioTimeStamp.mSampleTime = context-&gt;totalFrames;</span>
<span class="line-removed">409         audioTimeStamp.mFlags = kAudioTimeStampSampleTimeValid;</span>
<span class="line-removed">410 </span>
<span class="line-removed">411         status = AudioUnitRender(context-&gt;renderUnit,</span>
<span class="line-removed">412                                  0,</span>
<span class="line-removed">413                                  &amp;audioTimeStamp,</span>
<span class="line-removed">414                                  0,</span>
<span class="line-removed">415                                  (UInt32)numberFrames,</span>
<span class="line-removed">416                                  bufferListInOut);</span>
<span class="line-removed">417         if (noErr != status) {</span>
418             return;
419         }
<a name="33" id="anc33"></a><span class="line-removed">420         context-&gt;totalFrames += numberFrames;</span>
<span class="line-removed">421         *numberFramesOut = numberFrames;</span>
<span class="line-removed">422     } else {</span>
<span class="line-removed">423         MTAudioProcessingTapGetSourceAudio(tapRef, numberFrames, bufferListInOut,</span>
<span class="line-removed">424                                 flagsOut, NULL, numberFramesOut);</span>
425     }
<a name="34" id="anc34"></a><span class="line-removed">426 }</span>
427 
<a name="35" id="anc35"></a><span class="line-modified">428 static OSStatus AVFTapRenderCallback(void *inRefCon,</span>
<span class="line-modified">429                                      AudioUnitRenderActionFlags *ioActionFlags,</span>
<span class="line-modified">430                                      const AudioTimeStamp *inTimeStamp,</span>
<span class="line-modified">431                                      UInt32 inBusNumber,</span>
<span class="line-modified">432                                      UInt32 inNumberFrames,</span>
<span class="line-modified">433                                      AudioBufferList *ioData)</span>
<span class="line-modified">434 {</span>
<span class="line-modified">435     MTAudioProcessingTapRef tapRef = static_cast&lt;MTAudioProcessingTapRef&gt;(inRefCon);</span>
<span class="line-modified">436     return MTAudioProcessingTapGetSourceAudio(tapRef, inNumberFrames, ioData, NULL, NULL, NULL);</span>




437 }
<a name="36" id="anc36"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="36" type="hidden" />
</body>
</html>