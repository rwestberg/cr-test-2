<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.media/src/main/native/jfxmedia/platform/osx/avf/AVFAudioProcessor.mm</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AVFAudioProcessor.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AVFAudioSpectrumUnit.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.media/src/main/native/jfxmedia/platform/osx/avf/AVFAudioProcessor.mm</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2014, 2016, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.  Oracle designates this
  8  * particular file as subject to the &quot;Classpath&quot; exception as provided
  9  * by Oracle in the LICENSE file that accompanied this code.
 10  *
 11  * This code is distributed in the hope that it will be useful, but WITHOUT
 12  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 13  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 14  * version 2 for more details (a copy is included in the LICENSE file that
 15  * accompanied this code).
 16  *
 17  * You should have received a copy of the GNU General Public License version
 18  * 2 along with this work; if not, write to the Free Software Foundation,
 19  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 20  *
 21  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 22  * or visit www.oracle.com if you need additional information or have any
 23  * questions.
 24  */
 25 
 26 #import &quot;AVFAudioProcessor.h&quot;
 27 #import &quot;AVFMediaPlayer.h&quot;
 28 
 29 #import &lt;AVFoundation/AVFoundation.h&gt;
 30 #import &lt;MediaToolbox/MediaToolbox.h&gt;
 31 
<span class="line-removed"> 32 #import &quot;AVFKernelProcessor.h&quot;</span>
 33 #import &lt;CoreFoundation/CoreFoundation.h&gt;
 34 
 35 #import &lt;pthread.h&gt;
 36 #import &lt;objc/message.h&gt;
 37 
 38 static void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut);
 39 static void FinalizeAudioTap(MTAudioProcessingTapRef tapRef);
 40 static void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified"> 41                             CMItemCount maxFrames,</span>
<span class="line-modified"> 42                             const AudioStreamBasicDescription *processingFormat);</span>
 43 static void UnprepareAudioTap(MTAudioProcessingTapRef tapRef);
 44 static void ProcessAudioTap(MTAudioProcessingTapRef tapRef, CMItemCount numberFrames,
<span class="line-modified"> 45                             MTAudioProcessingTapFlags flags,</span>
<span class="line-modified"> 46                             AudioBufferList *bufferListInOut,</span>
<span class="line-modified"> 47                             CMItemCount *numberFramesOut,</span>
<span class="line-modified"> 48                             MTAudioProcessingTapFlags *flagsOut);</span>
<span class="line-removed"> 49 </span>
 50 static OSStatus AVFTapRenderCallback(void *inRefCon,
 51                                      AudioUnitRenderActionFlags *ioActionFlags,
 52                                      const AudioTimeStamp *inTimeStamp,
 53                                      UInt32 inBusNumber,
 54                                      UInt32 inNumberFrames,
 55                                      AudioBufferList *ioData);
 56 
<span class="line-removed"> 57 class AVFTapContext {</span>
<span class="line-removed"> 58 public:</span>
<span class="line-removed"> 59     AVFTapContext(AVFSoundLevelUnitPtr slu, AVFAudioSpectrumUnitPtr spectrum, AVFAudioEqualizerPtr eq) :</span>
<span class="line-removed"> 60         audioSLU(slu),</span>
<span class="line-removed"> 61         audioSpectrum(spectrum),</span>
<span class="line-removed"> 62         audioEQ(eq)</span>
<span class="line-removed"> 63     {</span>
<span class="line-removed"> 64     }</span>
<span class="line-removed"> 65 </span>
<span class="line-removed"> 66     ~AVFTapContext() {</span>
<span class="line-removed"> 67         // AudioUnits have already been deallocated by now</span>
<span class="line-removed"> 68         // shared_ptrs get freed automatically</span>
<span class="line-removed"> 69     }</span>
<span class="line-removed"> 70 </span>
<span class="line-removed"> 71     AudioUnit spectrumUnit;</span>
<span class="line-removed"> 72     AudioUnit volumeUnit;</span>
<span class="line-removed"> 73     AudioUnit eqUnit;</span>
<span class="line-removed"> 74 </span>
<span class="line-removed"> 75     AudioUnit renderUnit; // the last unit in our chain</span>
<span class="line-removed"> 76     CMItemCount totalFrames;</span>
<span class="line-removed"> 77     </span>
<span class="line-removed"> 78     // Hold on to these while we&#39;re running</span>
<span class="line-removed"> 79     AVFSoundLevelUnitPtr audioSLU;</span>
<span class="line-removed"> 80     AVFAudioSpectrumUnitPtr audioSpectrum;</span>
<span class="line-removed"> 81     AVFAudioEqualizerPtr audioEQ;</span>
<span class="line-removed"> 82 };</span>
<span class="line-removed"> 83 </span>
 84 @implementation AVFAudioProcessor
 85 
 86 - (id) init {
 87     if ((self = [super init]) != nil) {
 88         _soundLevelUnit = AVFSoundLevelUnitPtr(new AVFSoundLevelUnit());
 89         _audioSpectrum = AVFAudioSpectrumUnitPtr(new AVFAudioSpectrumUnit());
 90         _audioEqualizer = AVFAudioEqualizerPtr(new AVFAudioEqualizer());
 91 
 92         _volume = 1.0f;
 93         _balance = 0.0f;
 94         _audioDelay = 0LL;
 95     }
 96     return self;
 97 }
 98 
<span class="line-modified"> 99 - (void) dealloc {</span>
100     _soundLevelUnit = nullptr;
101     _audioSpectrum = nullptr;
102     _audioEqualizer = nullptr;
103 }
104 
<span class="line-modified">105 - (void) setAudioTrack:(AVAssetTrack *)track {</span>
106     if (track != _audioTrack) {
107         // reset the audio mixer if it&#39;s already been created
108         // this theoretically should never happen...
109         _mixer = nil;
110     }
111     _audioTrack = track;
112 }
113 
<span class="line-modified">114 - (AVAudioMix*) mixer {</span>
115     if (!self.audioTrack) {
116         return nil;
117     }
118 
119     if (!_mixer) {
120         AVMutableAudioMix *mixer = [AVMutableAudioMix audioMix];
121         if (mixer) {
122             AVMutableAudioMixInputParameters *audioMixInputParameters =
<span class="line-modified">123                 [AVMutableAudioMixInputParameters audioMixInputParametersWithTrack:self.audioTrack];</span>
124             if (audioMixInputParameters &amp;&amp;
<span class="line-modified">125                 [audioMixInputParameters respondsToSelector:@selector(setAudioTapProcessor:)]) {</span>
126                 MTAudioProcessingTapCallbacks callbacks;
127 
128                 callbacks.version = kMTAudioProcessingTapCallbacksVersion_0;
<span class="line-modified">129                 callbacks.clientInfo = (__bridge void *)self;</span>
130                 callbacks.init = InitAudioTap;
131                 callbacks.finalize = FinalizeAudioTap;
132                 callbacks.prepare = PrepareAudioTap;
133                 callbacks.unprepare = UnprepareAudioTap;
134                 callbacks.process = ProcessAudioTap;
135 
136                 MTAudioProcessingTapRef audioProcessingTap;
137                 if (noErr == MTAudioProcessingTapCreate(kCFAllocatorDefault, &amp;callbacks,
<span class="line-modified">138                                              kMTAudioProcessingTapCreationFlag_PreEffects,</span>
<span class="line-modified">139                                              &amp;audioProcessingTap))</span>
<span class="line-modified">140                 {</span>
<span class="line-removed">141                     objc_msgSend(audioMixInputParameters,</span>
<span class="line-removed">142                                  @selector(setAudioTapProcessor:),</span>
<span class="line-removed">143                                  audioProcessingTap);</span>
144 
145                     CFRelease(audioProcessingTap); // owned by the mixer now
146                     mixer.inputParameters = @[audioMixInputParameters];
147 
148                     _mixer = mixer;
149                 }
150             }
151         }
152     }
153     return _mixer;
154 }
155 
<span class="line-modified">156 - (void) setVolume:(float)volume {</span>
157     _volume = volume;
158     if (_soundLevelUnit != nullptr) {
159         _soundLevelUnit-&gt;setVolume(volume);
160     }
161 }
162 
<span class="line-modified">163 - (void) setBalance:(float)balance {</span>
164     _balance = balance;
165     if (_soundLevelUnit != nullptr) {
166         _soundLevelUnit-&gt;setBalance(balance);
167     }
168 }
169 
170 @end
171 
<span class="line-modified">172 void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut)</span>
<span class="line-modified">173 {</span>













174     // retain the AU kernels so they don&#39;t get freed while we&#39;re running
<span class="line-modified">175     AVFAudioProcessor *processor = (__bridge AVFAudioProcessor *)clientInfo;</span>
176     if (processor) {
177         AVFTapContext *context = new AVFTapContext(processor.soundLevelUnit,
<span class="line-modified">178                                                    processor.audioSpectrum,</span>
<span class="line-modified">179                                                    processor.audioEqualizer);</span>
180         *tapStorageOut = context;
181     }
182 }
183 
<span class="line-modified">184 void FinalizeAudioTap(MTAudioProcessingTapRef tapRef)</span>
<span class="line-modified">185 {</span>
<span class="line-removed">186     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-removed">187 </span>
188     if (context) {
189         delete context;
190     }
191 }
192 
193 static OSStatus SetupAudioUnit(AudioUnit unit,
194                                const AudioStreamBasicDescription *processingFormat,
195                                UInt32 maxFrames) {
196     OSStatus status = noErr;
197     if (noErr == status) {
198         status = AudioUnitSetProperty(unit,
199                                       kAudioUnitProperty_StreamFormat,
200                                       kAudioUnitScope_Input, 0,
201                                       processingFormat, sizeof(AudioStreamBasicDescription));
202     }
203     if (noErr == status) {
204         status = AudioUnitSetProperty(unit,
205                                       kAudioUnitProperty_StreamFormat,
206                                       kAudioUnitScope_Output, 0,
207                                       processingFormat, sizeof(AudioStreamBasicDescription));
208     }
209     if (noErr == status) {
210         status = AudioUnitSetProperty(unit,
211                                       kAudioUnitProperty_MaximumFramesPerSlice,
212                                       kAudioUnitScope_Global, 0,
213                                       &amp;maxFrames, sizeof(UInt32));
214     }
215     if (noErr == status) {
216         status = AudioUnitInitialize(unit);
217     }
218     return status;
219 }
220 
<span class="line-removed">221 static OSStatus ConnectAudioUnits(AudioUnit source, AudioUnit sink) {</span>
<span class="line-removed">222     AudioUnitConnection connection;</span>
<span class="line-removed">223     connection.sourceAudioUnit = source;</span>
<span class="line-removed">224     connection.sourceOutputNumber = 0;</span>
<span class="line-removed">225     connection.destInputNumber = 0;</span>
<span class="line-removed">226     return AudioUnitSetProperty(sink, kAudioUnitProperty_MakeConnection,</span>
<span class="line-removed">227                                 kAudioUnitScope_Input, 0,</span>
<span class="line-removed">228                                 &amp;connection, sizeof(connection));</span>
<span class="line-removed">229 }</span>
<span class="line-removed">230 </span>
<span class="line-removed">231 AudioUnit FindAudioUnit(OSType type, OSType subType, OSType manu) {</span>
<span class="line-removed">232     AudioUnit audioUnit = NULL;</span>
<span class="line-removed">233 </span>
<span class="line-removed">234     AudioComponentDescription audioComponentDescription;</span>
<span class="line-removed">235     audioComponentDescription.componentType = type;</span>
<span class="line-removed">236     audioComponentDescription.componentSubType = subType;</span>
<span class="line-removed">237     audioComponentDescription.componentManufacturer = manu;</span>
<span class="line-removed">238     audioComponentDescription.componentFlags = 0;</span>
<span class="line-removed">239     audioComponentDescription.componentFlagsMask = 0;</span>
<span class="line-removed">240 </span>
<span class="line-removed">241     AudioComponent audioComponent = AudioComponentFindNext(NULL, &amp;audioComponentDescription);</span>
<span class="line-removed">242     if (audioComponent) {</span>
<span class="line-removed">243         AudioComponentInstanceNew(audioComponent, &amp;audioUnit);</span>
<span class="line-removed">244     }</span>
<span class="line-removed">245     return audioUnit;</span>
<span class="line-removed">246 }</span>
<span class="line-removed">247 </span>
248 void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">249                      CMItemCount maxFrames,</span>
<span class="line-modified">250                      const AudioStreamBasicDescription *processingFormat)</span>
<span class="line-modified">251 {</span>
<span class="line-removed">252     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
253 
254     // Validate the audio format before we enable the processor
<span class="line-removed">255 </span>
256     // Failures here should rarely, if ever, happen so leave the NSLogs in for
257     // easier diagnosis in the field
258     if (processingFormat-&gt;mFormatID != kAudioFormatLinearPCM) {
259         NSLog(@&quot;AVFAudioProcessor needs linear PCM&quot;);
260         return;
261     }
262 
263     // Use the convenient kAudioFormatFlagsNativeFloatPacked to check if we can
264     // process the incoming audio
265     if ((processingFormat-&gt;mFormatFlags &amp; kAudioFormatFlagsNativeFloatPacked)
<span class="line-modified">266         != kAudioFormatFlagsNativeFloatPacked) {</span>
267         NSLog(@&quot;AVFAudioProcessor needs native endian packed float samples!!&quot;);
268         return;
269     }
270 
<span class="line-modified">271     // Get an instance of our sound level unit</span>
<span class="line-modified">272     context-&gt;eqUnit = NULL;</span>



273     if (context-&gt;audioEQ != nullptr) {
<span class="line-modified">274         context-&gt;eqUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioEQ));</span>
<span class="line-modified">275         if (context-&gt;eqUnit) {</span>
<span class="line-modified">276             OSStatus status = SetupAudioUnit(context-&gt;eqUnit,</span>
<span class="line-removed">277                                              processingFormat,</span>
<span class="line-removed">278                                              (UInt32)maxFrames);</span>
<span class="line-removed">279             if (noErr != status) {</span>
<span class="line-removed">280                 NSLog(@&quot;Error creating audio equalizer unit: %d&quot;, status);</span>
<span class="line-removed">281                 AudioComponentInstanceDispose(context-&gt;eqUnit);</span>
<span class="line-removed">282                 context-&gt;eqUnit = NULL;</span>
<span class="line-removed">283             }</span>
<span class="line-removed">284         }</span>
285     }
286 
<span class="line-modified">287     context-&gt;spectrumUnit = NULL;</span>
288     if (context-&gt;audioSpectrum != nullptr) {
<span class="line-modified">289         context-&gt;spectrumUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioSpectrum));</span>
<span class="line-modified">290         if (context-&gt;spectrumUnit) {</span>
<span class="line-modified">291             OSStatus status = SetupAudioUnit(context-&gt;spectrumUnit,</span>
<span class="line-removed">292                                              processingFormat,</span>
<span class="line-removed">293                                              (UInt32)maxFrames);</span>
<span class="line-removed">294             if (noErr != status) {</span>
<span class="line-removed">295                 NSLog(@&quot;Error creating audio spectrum unit: %d&quot;, status);</span>
<span class="line-removed">296                 AudioComponentInstanceDispose(context-&gt;spectrumUnit);</span>
<span class="line-removed">297                 context-&gt;spectrumUnit = NULL;</span>
<span class="line-removed">298             }</span>
<span class="line-removed">299         }</span>
300     }
301 
<span class="line-removed">302     context-&gt;volumeUnit = NULL;</span>
303     if (context-&gt;audioSLU != nullptr) {
<span class="line-modified">304         context-&gt;volumeUnit = NewKernelProcessorUnit(static_pointer_cast&lt;AVFKernelProcessor&gt;(context-&gt;audioSLU));</span>
<span class="line-removed">305         if (context-&gt;volumeUnit) {</span>
<span class="line-removed">306             OSStatus status = SetupAudioUnit(context-&gt;volumeUnit,</span>
<span class="line-removed">307                                              processingFormat,</span>
<span class="line-removed">308                                              (UInt32)maxFrames);</span>
<span class="line-removed">309             if (noErr != status) {</span>
<span class="line-removed">310                 NSLog(@&quot;Error setting up Sound Level Unit: %d&quot;, status);</span>
<span class="line-removed">311                 AudioComponentInstanceDispose(context-&gt;volumeUnit);</span>
<span class="line-removed">312                 context-&gt;volumeUnit = NULL;</span>
<span class="line-removed">313             }</span>
<span class="line-removed">314         }</span>
<span class="line-removed">315     }</span>
<span class="line-removed">316 </span>
<span class="line-removed">317     /*</span>
<span class="line-removed">318      * Use AudioUnitConnections to build a processing graph</span>
<span class="line-removed">319      * The last unit in the chain will be the unit we call to render, it will</span>
<span class="line-removed">320      * pull through the graph until we get to the first, which will fetch samples</span>
<span class="line-removed">321      * via the render proc we install.</span>
<span class="line-removed">322      *</span>
<span class="line-removed">323      * The graph will look like this:</span>
<span class="line-removed">324      *    (render proc) -&gt; eqUnit -&gt; spectrumUnit -&gt; volUnit</span>
<span class="line-removed">325      *</span>
<span class="line-removed">326      * This will allow the EQ settings to affect the spectrum output, but not</span>
<span class="line-removed">327      * the volume or balance.</span>
<span class="line-removed">328      */</span>
<span class="line-removed">329     AudioUnit firstUnit = NULL;</span>
<span class="line-removed">330     context-&gt;renderUnit = NULL;</span>
<span class="line-removed">331 </span>
<span class="line-removed">332     // Set initial settings</span>
<span class="line-removed">333     if (context-&gt;eqUnit) {</span>
<span class="line-removed">334         if (context-&gt;renderUnit) {</span>
<span class="line-removed">335             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;eqUnit);</span>
<span class="line-removed">336         }</span>
<span class="line-removed">337         context-&gt;renderUnit = context-&gt;eqUnit;</span>
<span class="line-removed">338         if (!firstUnit) {</span>
<span class="line-removed">339             firstUnit = context-&gt;eqUnit;</span>
<span class="line-removed">340         }</span>
341     }
<span class="line-removed">342     if (context-&gt;spectrumUnit) {</span>
<span class="line-removed">343         if (context-&gt;renderUnit) {</span>
<span class="line-removed">344             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;spectrumUnit);</span>
<span class="line-removed">345         }</span>
<span class="line-removed">346         context-&gt;renderUnit = context-&gt;spectrumUnit;</span>
<span class="line-removed">347         if (!firstUnit) {</span>
<span class="line-removed">348             firstUnit = context-&gt;spectrumUnit;</span>
<span class="line-removed">349         }</span>
<span class="line-removed">350     }</span>
<span class="line-removed">351     if (context-&gt;volumeUnit) {</span>
<span class="line-removed">352         if (context-&gt;renderUnit) {</span>
<span class="line-removed">353             ConnectAudioUnits(context-&gt;renderUnit, context-&gt;volumeUnit);</span>
<span class="line-removed">354         }</span>
<span class="line-removed">355         context-&gt;renderUnit = context-&gt;volumeUnit;</span>
<span class="line-removed">356         if (!firstUnit) {</span>
<span class="line-removed">357             firstUnit = context-&gt;volumeUnit;</span>
<span class="line-removed">358         }</span>
<span class="line-removed">359     }</span>
<span class="line-removed">360 </span>
<span class="line-removed">361     // Set up a render callback on our first unit</span>
<span class="line-removed">362     if (firstUnit) {</span>
<span class="line-removed">363         AURenderCallbackStruct renderCB;</span>
<span class="line-removed">364         renderCB.inputProc = (AURenderCallback)AVFTapRenderCallback;</span>
<span class="line-removed">365         renderCB.inputProcRefCon = (void*)tapRef;</span>
<span class="line-removed">366         AudioUnitSetProperty(firstUnit,</span>
<span class="line-removed">367                              kAudioUnitProperty_SetRenderCallback,</span>
<span class="line-removed">368                              kAudioUnitScope_Input, 0,</span>
<span class="line-removed">369                              &amp;renderCB, sizeof(renderCB));</span>
<span class="line-removed">370     }</span>
<span class="line-removed">371     context-&gt;totalFrames = 0;</span>
372 }
373 
<span class="line-modified">374 void UnprepareAudioTap(MTAudioProcessingTapRef tapRef)</span>
<span class="line-modified">375 {</span>
<span class="line-removed">376     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-removed">377     context-&gt;renderUnit = NULL;</span>
<span class="line-removed">378 </span>
<span class="line-removed">379     if (context-&gt;spectrumUnit) {</span>
<span class="line-removed">380         AudioUnitUninitialize(context-&gt;spectrumUnit);</span>
<span class="line-removed">381         AudioComponentInstanceDispose(context-&gt;spectrumUnit);</span>
<span class="line-removed">382         context-&gt;spectrumUnit = NULL;</span>
<span class="line-removed">383     }</span>
<span class="line-removed">384     if (context-&gt;volumeUnit) {</span>
<span class="line-removed">385         AudioUnitUninitialize(context-&gt;volumeUnit);</span>
<span class="line-removed">386         AudioComponentInstanceDispose(context-&gt;volumeUnit);</span>
<span class="line-removed">387         context-&gt;volumeUnit = NULL;</span>
<span class="line-removed">388     }</span>
<span class="line-removed">389     if (context-&gt;eqUnit) {</span>
<span class="line-removed">390         AudioUnitUninitialize(context-&gt;eqUnit);</span>
<span class="line-removed">391         AudioComponentInstanceDispose(context-&gt;eqUnit);</span>
<span class="line-removed">392         context-&gt;eqUnit = NULL;</span>
<span class="line-removed">393     }</span>
394 }
395 
396 void ProcessAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">397                      CMItemCount numberFrames,</span>
<span class="line-modified">398                      uint32_t flags,</span>
<span class="line-modified">399                      AudioBufferList *bufferListInOut,</span>
<span class="line-modified">400                      CMItemCount *numberFramesOut,</span>
<span class="line-modified">401                      uint32_t *flagsOut)</span>
<span class="line-modified">402 {</span>
<span class="line-modified">403     AVFTapContext *context = (AVFTapContext*)MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-modified">404     OSStatus status = noErr;</span>




405 
<span class="line-modified">406     if (context-&gt;renderUnit) {</span>
<span class="line-modified">407         AudioTimeStamp audioTimeStamp;</span>
<span class="line-modified">408         audioTimeStamp.mSampleTime = context-&gt;totalFrames;</span>
<span class="line-removed">409         audioTimeStamp.mFlags = kAudioTimeStampSampleTimeValid;</span>
<span class="line-removed">410 </span>
<span class="line-removed">411         status = AudioUnitRender(context-&gt;renderUnit,</span>
<span class="line-removed">412                                  0,</span>
<span class="line-removed">413                                  &amp;audioTimeStamp,</span>
<span class="line-removed">414                                  0,</span>
<span class="line-removed">415                                  (UInt32)numberFrames,</span>
<span class="line-removed">416                                  bufferListInOut);</span>
<span class="line-removed">417         if (noErr != status) {</span>
418             return;
419         }
<span class="line-removed">420         context-&gt;totalFrames += numberFrames;</span>
<span class="line-removed">421         *numberFramesOut = numberFrames;</span>
<span class="line-removed">422     } else {</span>
<span class="line-removed">423         MTAudioProcessingTapGetSourceAudio(tapRef, numberFrames, bufferListInOut,</span>
<span class="line-removed">424                                 flagsOut, NULL, numberFramesOut);</span>
425     }
<span class="line-removed">426 }</span>
427 
<span class="line-modified">428 static OSStatus AVFTapRenderCallback(void *inRefCon,</span>
<span class="line-modified">429                                      AudioUnitRenderActionFlags *ioActionFlags,</span>
<span class="line-modified">430                                      const AudioTimeStamp *inTimeStamp,</span>
<span class="line-modified">431                                      UInt32 inBusNumber,</span>
<span class="line-modified">432                                      UInt32 inNumberFrames,</span>
<span class="line-modified">433                                      AudioBufferList *ioData)</span>
<span class="line-modified">434 {</span>
<span class="line-modified">435     MTAudioProcessingTapRef tapRef = static_cast&lt;MTAudioProcessingTapRef&gt;(inRefCon);</span>
<span class="line-modified">436     return MTAudioProcessingTapGetSourceAudio(tapRef, inNumberFrames, ioData, NULL, NULL, NULL);</span>




437 }
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2014, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.  Oracle designates this
  8  * particular file as subject to the &quot;Classpath&quot; exception as provided
  9  * by Oracle in the LICENSE file that accompanied this code.
 10  *
 11  * This code is distributed in the hope that it will be useful, but WITHOUT
 12  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 13  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 14  * version 2 for more details (a copy is included in the LICENSE file that
 15  * accompanied this code).
 16  *
 17  * You should have received a copy of the GNU General Public License version
 18  * 2 along with this work; if not, write to the Free Software Foundation,
 19  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 20  *
 21  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 22  * or visit www.oracle.com if you need additional information or have any
 23  * questions.
 24  */
 25 
 26 #import &quot;AVFAudioProcessor.h&quot;
 27 #import &quot;AVFMediaPlayer.h&quot;
 28 
 29 #import &lt;AVFoundation/AVFoundation.h&gt;
 30 #import &lt;MediaToolbox/MediaToolbox.h&gt;
 31 

 32 #import &lt;CoreFoundation/CoreFoundation.h&gt;
 33 
 34 #import &lt;pthread.h&gt;
 35 #import &lt;objc/message.h&gt;
 36 
 37 static void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut);
 38 static void FinalizeAudioTap(MTAudioProcessingTapRef tapRef);
 39 static void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified"> 40         CMItemCount maxFrames,</span>
<span class="line-modified"> 41         const AudioStreamBasicDescription *processingFormat);</span>
 42 static void UnprepareAudioTap(MTAudioProcessingTapRef tapRef);
 43 static void ProcessAudioTap(MTAudioProcessingTapRef tapRef, CMItemCount numberFrames,
<span class="line-modified"> 44         MTAudioProcessingTapFlags flags,</span>
<span class="line-modified"> 45         AudioBufferList *bufferListInOut,</span>
<span class="line-modified"> 46         CMItemCount *numberFramesOut,</span>
<span class="line-modified"> 47         MTAudioProcessingTapFlags *flagsOut);</span>

 48 static OSStatus AVFTapRenderCallback(void *inRefCon,
 49                                      AudioUnitRenderActionFlags *ioActionFlags,
 50                                      const AudioTimeStamp *inTimeStamp,
 51                                      UInt32 inBusNumber,
 52                                      UInt32 inNumberFrames,
 53                                      AudioBufferList *ioData);
 54 



























 55 @implementation AVFAudioProcessor
 56 
 57 - (id) init {
 58     if ((self = [super init]) != nil) {
 59         _soundLevelUnit = AVFSoundLevelUnitPtr(new AVFSoundLevelUnit());
 60         _audioSpectrum = AVFAudioSpectrumUnitPtr(new AVFAudioSpectrumUnit());
 61         _audioEqualizer = AVFAudioEqualizerPtr(new AVFAudioEqualizer());
 62 
 63         _volume = 1.0f;
 64         _balance = 0.0f;
 65         _audioDelay = 0LL;
 66     }
 67     return self;
 68 }
 69 
<span class="line-modified"> 70 -(void) dealloc {</span>
 71     _soundLevelUnit = nullptr;
 72     _audioSpectrum = nullptr;
 73     _audioEqualizer = nullptr;
 74 }
 75 
<span class="line-modified"> 76 -(void) setAudioTrack : (AVAssetTrack *) track {</span>
 77     if (track != _audioTrack) {
 78         // reset the audio mixer if it&#39;s already been created
 79         // this theoretically should never happen...
 80         _mixer = nil;
 81     }
 82     _audioTrack = track;
 83 }
 84 
<span class="line-modified"> 85 -(AVAudioMix*) mixer {</span>
 86     if (!self.audioTrack) {
 87         return nil;
 88     }
 89 
 90     if (!_mixer) {
 91         AVMutableAudioMix *mixer = [AVMutableAudioMix audioMix];
 92         if (mixer) {
 93             AVMutableAudioMixInputParameters *audioMixInputParameters =
<span class="line-modified"> 94                     [AVMutableAudioMixInputParameters audioMixInputParametersWithTrack : self.audioTrack];</span>
 95             if (audioMixInputParameters &amp;&amp;
<span class="line-modified"> 96                     [audioMixInputParameters respondsToSelector : @selector(setAudioTapProcessor :)]) {</span>
 97                 MTAudioProcessingTapCallbacks callbacks;
 98 
 99                 callbacks.version = kMTAudioProcessingTapCallbacksVersion_0;
<span class="line-modified">100                 callbacks.clientInfo = (__bridge void *) self;</span>
101                 callbacks.init = InitAudioTap;
102                 callbacks.finalize = FinalizeAudioTap;
103                 callbacks.prepare = PrepareAudioTap;
104                 callbacks.unprepare = UnprepareAudioTap;
105                 callbacks.process = ProcessAudioTap;
106 
107                 MTAudioProcessingTapRef audioProcessingTap;
108                 if (noErr == MTAudioProcessingTapCreate(kCFAllocatorDefault, &amp;callbacks,
<span class="line-modified">109                         kMTAudioProcessingTapCreationFlag_PreEffects,</span>
<span class="line-modified">110                         &amp;audioProcessingTap)) {</span>
<span class="line-modified">111                     [audioMixInputParameters setAudioTapProcessor:audioProcessingTap];</span>



112 
113                     CFRelease(audioProcessingTap); // owned by the mixer now
114                     mixer.inputParameters = @[audioMixInputParameters];
115 
116                     _mixer = mixer;
117                 }
118             }
119         }
120     }
121     return _mixer;
122 }
123 
<span class="line-modified">124 -(void) setVolume : (float) volume {</span>
125     _volume = volume;
126     if (_soundLevelUnit != nullptr) {
127         _soundLevelUnit-&gt;setVolume(volume);
128     }
129 }
130 
<span class="line-modified">131 -(void) setBalance : (float) balance {</span>
132     _balance = balance;
133     if (_soundLevelUnit != nullptr) {
134         _soundLevelUnit-&gt;setBalance(balance);
135     }
136 }
137 
138 @end
139 
<span class="line-modified">140 AVFTapContext::AVFTapContext(AVFSoundLevelUnitPtr slu, AVFAudioSpectrumUnitPtr spectrum,</span>
<span class="line-modified">141                              AVFAudioEqualizerPtr eq) : audioSLU(slu),</span>
<span class="line-added">142                                                         audioSpectrum(spectrum),</span>
<span class="line-added">143                                                         audioEQ(eq),</span>
<span class="line-added">144                                                         // Some reasonable defaults</span>
<span class="line-added">145                                                         mSampleRate(48000),</span>
<span class="line-added">146                                                         mChannels(2) {</span>
<span class="line-added">147 }</span>
<span class="line-added">148 </span>
<span class="line-added">149 AVFTapContext::~AVFTapContext() {</span>
<span class="line-added">150     // AudioUnits have already been deallocated by now</span>
<span class="line-added">151     // shared_ptrs get freed automatically</span>
<span class="line-added">152 }</span>
<span class="line-added">153 </span>
<span class="line-added">154 void InitAudioTap(MTAudioProcessingTapRef tapRef, void *clientInfo, void **tapStorageOut) {</span>
155     // retain the AU kernels so they don&#39;t get freed while we&#39;re running
<span class="line-modified">156     AVFAudioProcessor *processor = (__bridge AVFAudioProcessor *) clientInfo;</span>
157     if (processor) {
158         AVFTapContext *context = new AVFTapContext(processor.soundLevelUnit,
<span class="line-modified">159                 processor.audioSpectrum,</span>
<span class="line-modified">160                 processor.audioEqualizer);</span>
161         *tapStorageOut = context;
162     }
163 }
164 
<span class="line-modified">165 void FinalizeAudioTap(MTAudioProcessingTapRef tapRef) {</span>
<span class="line-modified">166     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);</span>


167     if (context) {
168         delete context;
169     }
170 }
171 
172 static OSStatus SetupAudioUnit(AudioUnit unit,
173                                const AudioStreamBasicDescription *processingFormat,
174                                UInt32 maxFrames) {
175     OSStatus status = noErr;
176     if (noErr == status) {
177         status = AudioUnitSetProperty(unit,
178                                       kAudioUnitProperty_StreamFormat,
179                                       kAudioUnitScope_Input, 0,
180                                       processingFormat, sizeof(AudioStreamBasicDescription));
181     }
182     if (noErr == status) {
183         status = AudioUnitSetProperty(unit,
184                                       kAudioUnitProperty_StreamFormat,
185                                       kAudioUnitScope_Output, 0,
186                                       processingFormat, sizeof(AudioStreamBasicDescription));
187     }
188     if (noErr == status) {
189         status = AudioUnitSetProperty(unit,
190                                       kAudioUnitProperty_MaximumFramesPerSlice,
191                                       kAudioUnitScope_Global, 0,
192                                       &amp;maxFrames, sizeof(UInt32));
193     }
194     if (noErr == status) {
195         status = AudioUnitInitialize(unit);
196     }
197     return status;
198 }
199 



























200 void PrepareAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">201         CMItemCount maxFrames,</span>
<span class="line-modified">202         const AudioStreamBasicDescription *processingFormat) {</span>
<span class="line-modified">203     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);</span>

204 
205     // Validate the audio format before we enable the processor

206     // Failures here should rarely, if ever, happen so leave the NSLogs in for
207     // easier diagnosis in the field
208     if (processingFormat-&gt;mFormatID != kAudioFormatLinearPCM) {
209         NSLog(@&quot;AVFAudioProcessor needs linear PCM&quot;);
210         return;
211     }
212 
213     // Use the convenient kAudioFormatFlagsNativeFloatPacked to check if we can
214     // process the incoming audio
215     if ((processingFormat-&gt;mFormatFlags &amp; kAudioFormatFlagsNativeFloatPacked)
<span class="line-modified">216             != kAudioFormatFlagsNativeFloatPacked) {</span>
217         NSLog(@&quot;AVFAudioProcessor needs native endian packed float samples!!&quot;);
218         return;
219     }
220 
<span class="line-modified">221     context-&gt;mSampleRate = processingFormat-&gt;mSampleRate;</span>
<span class="line-modified">222     context-&gt;mChannels = processingFormat-&gt;mChannelsPerFrame;</span>
<span class="line-added">223     context-&gt;mMaxFrames = maxFrames;</span>
<span class="line-added">224 </span>
<span class="line-added">225     // Configure audio equalizer</span>
226     if (context-&gt;audioEQ != nullptr) {
<span class="line-modified">227         context-&gt;audioEQ.get()-&gt;SetSampleRate(context-&gt;mSampleRate);</span>
<span class="line-modified">228         context-&gt;audioEQ.get()-&gt;SetChannels(context-&gt;mChannels);</span>
<span class="line-modified">229         context-&gt;audioEQ.get()-&gt;ResetBandParameters();</span>








230     }
231 
<span class="line-modified">232     // Configure spectrum</span>
233     if (context-&gt;audioSpectrum != nullptr) {
<span class="line-modified">234         context-&gt;audioSpectrum.get()-&gt;SetSampleRate(context-&gt;mSampleRate);</span>
<span class="line-modified">235         context-&gt;audioSpectrum.get()-&gt;SetChannels(context-&gt;mChannels);</span>
<span class="line-modified">236         context-&gt;audioSpectrum.get()-&gt;SetMaxFrames(context-&gt;mMaxFrames);</span>








237     }
238 

239     if (context-&gt;audioSLU != nullptr) {
<span class="line-modified">240         context-&gt;audioSLU.get()-&gt;SetChannels(context-&gt;mChannels);</span>




































241     }






























242 }
243 
<span class="line-modified">244 void UnprepareAudioTap(MTAudioProcessingTapRef tapRef) {</span>
<span class="line-modified">245     // We do not need it anymore</span>


















246 }
247 
248 void ProcessAudioTap(MTAudioProcessingTapRef tapRef,
<span class="line-modified">249         CMItemCount numberFrames,</span>
<span class="line-modified">250         uint32_t flags,</span>
<span class="line-modified">251         AudioBufferList *bufferListInOut,</span>
<span class="line-modified">252         CMItemCount *numberFramesOut,</span>
<span class="line-modified">253         uint32_t *flagsOut) {</span>
<span class="line-modified">254     AVFTapContext *context = (AVFTapContext*) MTAudioProcessingTapGetStorage(tapRef);</span>
<span class="line-modified">255     OSStatus status = MTAudioProcessingTapGetSourceAudio(tapRef, numberFrames, bufferListInOut,</span>
<span class="line-modified">256             flagsOut, NULL, numberFramesOut);</span>
<span class="line-added">257     if (status != noErr) {</span>
<span class="line-added">258         NSLog(@&quot;MTAudioProcessingTapGetSourceAudio failed: %d&quot;, status);</span>
<span class="line-added">259         return;</span>
<span class="line-added">260     }</span>
261 
<span class="line-modified">262     if (context-&gt;audioEQ != nullptr) {</span>
<span class="line-modified">263         if (!context-&gt;audioEQ.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {</span>
<span class="line-modified">264             NSLog(@&quot;audioEQ ProcessBufferLists() failed&quot;);</span>









265             return;
266         }





267     }

268 
<span class="line-modified">269     if (context-&gt;audioSpectrum != nullptr) {</span>
<span class="line-modified">270         if (!context-&gt;audioSpectrum.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {</span>
<span class="line-modified">271             NSLog(@&quot;audioSpectrum ProcessBufferLists() failed&quot;);</span>
<span class="line-modified">272             return;</span>
<span class="line-modified">273         }</span>
<span class="line-modified">274     }</span>
<span class="line-modified">275 </span>
<span class="line-modified">276     if (context-&gt;audioSLU != nullptr) {</span>
<span class="line-modified">277         if (!context-&gt;audioSLU.get()-&gt;ProcessBufferLists(*bufferListInOut, numberFrames)) {</span>
<span class="line-added">278             NSLog(@&quot;audioSLU ProcessBufferLists() failed&quot;);</span>
<span class="line-added">279             return;</span>
<span class="line-added">280         }</span>
<span class="line-added">281     }</span>
282 }
</pre>
</td>
</tr>
</table>
<center><a href="AVFAudioProcessor.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AVFAudioSpectrumUnit.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>