<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2010 Google Inc. All rights reserved.
<a name="1" id="anc1"></a><span class="line-modified">  3  * Copyright (C) 2016 Apple Inc. All rights reserved.</span>
  4  *
  5  * Redistribution and use in source and binary forms, with or without
  6  * modification, are permitted provided that the following conditions
  7  * are met:
  8  * 1.  Redistributions of source code must retain the above copyright
  9  *    notice, this list of conditions and the following disclaimer.
 10  * 2.  Redistributions in binary form must reproduce the above copyright
 11  *    notice, this list of conditions and the following disclaimer in the
 12  *    documentation and/or other materials provided with the distribution.
 13  *
 14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 16  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 17  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 18  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 19  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 20  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 21  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 23  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;ActiveDOMObject.h&quot;
 29 #include &quot;AsyncAudioDecoder.h&quot;
 30 #include &quot;AudioBus.h&quot;
 31 #include &quot;AudioDestinationNode.h&quot;
 32 #include &quot;EventTarget.h&quot;
 33 #include &quot;JSDOMPromiseDeferred.h&quot;
 34 #include &quot;MediaCanStartListener.h&quot;
 35 #include &quot;MediaProducer.h&quot;
 36 #include &quot;PlatformMediaSession.h&quot;
<a name="2" id="anc2"></a>
 37 #include &quot;VisibilityChangeClient.h&quot;
<a name="3" id="anc3"></a>
 38 #include &lt;JavaScriptCore/Float32Array.h&gt;
 39 #include &lt;atomic&gt;
 40 #include &lt;wtf/HashSet.h&gt;
<a name="4" id="anc4"></a>
 41 #include &lt;wtf/MainThread.h&gt;
 42 #include &lt;wtf/RefPtr.h&gt;
 43 #include &lt;wtf/ThreadSafeRefCounted.h&gt;
 44 #include &lt;wtf/Threading.h&gt;
 45 #include &lt;wtf/Vector.h&gt;
<a name="5" id="anc5"></a><span class="line-modified"> 46 #include &lt;wtf/text/AtomicStringHash.h&gt;</span>
 47 
 48 namespace WebCore {
 49 
 50 class AnalyserNode;
 51 class AudioBuffer;
 52 class AudioBufferCallback;
 53 class AudioBufferSourceNode;
 54 class AudioListener;
 55 class AudioSummingJunction;
 56 class BiquadFilterNode;
 57 class ChannelMergerNode;
 58 class ChannelSplitterNode;
 59 class ConvolverNode;
 60 class DelayNode;
 61 class Document;
 62 class DynamicsCompressorNode;
 63 class GainNode;
 64 class GenericEventQueue;
 65 class HTMLMediaElement;
 66 class MediaElementAudioSourceNode;
 67 class MediaStream;
 68 class MediaStreamAudioDestinationNode;
 69 class MediaStreamAudioSourceNode;
 70 class OscillatorNode;
 71 class PannerNode;
 72 class PeriodicWave;
 73 class ScriptProcessorNode;
<a name="6" id="anc6"></a>
 74 class WaveShaperNode;
 75 
 76 // AudioContext is the cornerstone of the web audio API and all AudioNodes are created from it.
 77 // For thread safety between the audio thread and the main thread, it has a rendering graph locking mechanism.
 78 
<a name="7" id="anc7"></a><span class="line-modified"> 79 class AudioContext : public ActiveDOMObject, public ThreadSafeRefCounted&lt;AudioContext&gt;, public EventTargetWithInlineData, public MediaCanStartListener, public MediaProducer, private PlatformMediaSessionClient, private VisibilityChangeClient {</span>












 80 public:
 81     // Create an AudioContext for rendering to the audio hardware.
 82     static RefPtr&lt;AudioContext&gt; create(Document&amp;);
 83 
 84     virtual ~AudioContext();
 85 
 86     bool isInitialized() const;
 87 
 88     bool isOfflineContext() const { return m_isOfflineContext; }
 89 
 90     Document* document() const; // ASSERTs if document no longer exists.
 91 
 92     Document* hostingDocument() const final;
 93 
 94     AudioDestinationNode* destination() { return m_destinationNode.get(); }
<a name="8" id="anc8"></a><span class="line-modified"> 95     size_t currentSampleFrame() const { return m_destinationNode-&gt;currentSampleFrame(); }</span>
<span class="line-modified"> 96     double currentTime() const { return m_destinationNode-&gt;currentTime(); }</span>
<span class="line-modified"> 97     float sampleRate() const { return m_destinationNode-&gt;sampleRate(); }</span>
 98     unsigned long activeSourceCount() const { return static_cast&lt;unsigned long&gt;(m_activeSourceCount); }
 99 
100     void incrementActiveSourceCount();
101     void decrementActiveSourceCount();
102 
103     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
104     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(ArrayBuffer&amp;, bool mixToMono);
105 
106     // Asynchronous audio file data decoding.
107     void decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;);
108 
109     AudioListener* listener() { return m_listener.get(); }
110 
111     using ActiveDOMObject::suspend;
112     using ActiveDOMObject::resume;
113 
114     void suspend(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
115     void resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
116     void close(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
117 
118     enum class State { Suspended, Running, Interrupted, Closed };
119     State state() const;
<a name="9" id="anc9"></a>
120 
121     bool wouldTaintOrigin(const URL&amp;) const;
122 
123     // The AudioNode create methods are called on the main thread (from JavaScript).
<a name="10" id="anc10"></a><span class="line-modified">124     Ref&lt;AudioBufferSourceNode&gt; createBufferSource();</span>
125 #if ENABLE(VIDEO)
126     ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; createMediaElementSource(HTMLMediaElement&amp;);
127 #endif
128 #if ENABLE(MEDIA_STREAM)
129     ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; createMediaStreamSource(MediaStream&amp;);
<a name="11" id="anc11"></a><span class="line-modified">130     Ref&lt;MediaStreamAudioDestinationNode&gt; createMediaStreamDestination();</span>
131 #endif
<a name="12" id="anc12"></a><span class="line-modified">132     Ref&lt;GainNode&gt; createGain();</span>
<span class="line-modified">133     Ref&lt;BiquadFilterNode&gt; createBiquadFilter();</span>
<span class="line-modified">134     Ref&lt;WaveShaperNode&gt; createWaveShaper();</span>
135     ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; createDelay(double maxDelayTime);
<a name="13" id="anc13"></a><span class="line-modified">136     Ref&lt;PannerNode&gt; createPanner();</span>
<span class="line-modified">137     Ref&lt;ConvolverNode&gt; createConvolver();</span>
<span class="line-modified">138     Ref&lt;DynamicsCompressorNode&gt; createDynamicsCompressor();</span>
<span class="line-modified">139     Ref&lt;AnalyserNode&gt; createAnalyser();</span>
140     ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels);
141     ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; createChannelSplitter(size_t numberOfOutputs);
142     ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; createChannelMerger(size_t numberOfInputs);
<a name="14" id="anc14"></a><span class="line-modified">143     Ref&lt;OscillatorNode&gt; createOscillator();</span>
144     ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary);
145 
146     // When a source node has no more processing to do (has finished playing), then it tells the context to dereference it.
147     void notifyNodeFinishedProcessing(AudioNode*);
148 
149     // Called at the start of each render quantum.
150     void handlePreRenderTasks();
151 
152     // Called at the end of each render quantum.
153     void handlePostRenderTasks();
154 
155     // Called periodically at the end of each render quantum to dereference finished source nodes.
156     void derefFinishedSourceNodes();
157 
158     // We schedule deletion of all marked nodes at the end of each realtime render quantum.
159     void markForDeletion(AudioNode&amp;);
160     void deleteMarkedNodes();
161 
162     // AudioContext can pull node(s) at the end of each render quantum even when they are not connected to any downstream nodes.
163     // These two methods are called by the nodes who want to add/remove themselves into/from the automatic pull lists.
164     void addAutomaticPullNode(AudioNode&amp;);
165     void removeAutomaticPullNode(AudioNode&amp;);
166 
167     // Called right before handlePostRenderTasks() to handle nodes which need to be pulled even when they are not connected to anything.
168     void processAutomaticPullNodes(size_t framesToProcess);
169 
170     // Keeps track of the number of connections made.
171     void incrementConnectionCount()
172     {
173         ASSERT(isMainThread());
174         m_connectionCount++;
175     }
176 
177     unsigned connectionCount() const { return m_connectionCount; }
178 
179     //
180     // Thread Safety and Graph Locking:
181     //
182 
183     void setAudioThread(Thread&amp; thread) { m_audioThread = &amp;thread; } // FIXME: check either not initialized or the same
184     Thread* audioThread() const { return m_audioThread; }
185     bool isAudioThread() const;
186 
187     // Returns true only after the audio thread has been started and then shutdown.
188     bool isAudioThreadFinished() { return m_isAudioThreadFinished; }
189 
190     // mustReleaseLock is set to true if we acquired the lock in this method call and caller must unlock(), false if it was previously acquired.
191     void lock(bool&amp; mustReleaseLock);
192 
193     // Returns true if we own the lock.
194     // mustReleaseLock is set to true if we acquired the lock in this method call and caller must unlock(), false if it was previously acquired.
195     bool tryLock(bool&amp; mustReleaseLock);
196 
197     void unlock();
198 
199     // Returns true if this thread owns the context&#39;s lock.
200     bool isGraphOwner() const;
201 
202     // Returns the maximum number of channels we can support.
203     static unsigned maxNumberOfChannels() { return MaxNumberOfChannels; }
204 
205     class AutoLocker {
206     public:
207         explicit AutoLocker(AudioContext&amp; context)
208             : m_context(context)
209         {
210             m_context.lock(m_mustReleaseLock);
211         }
212 
213         ~AutoLocker()
214         {
215             if (m_mustReleaseLock)
216                 m_context.unlock();
217         }
218 
219     private:
220         AudioContext&amp; m_context;
221         bool m_mustReleaseLock;
222     };
223 
224     // In AudioNode::deref() a tryLock() is used for calling finishDeref(), but if it fails keep track here.
225     void addDeferredFinishDeref(AudioNode*);
226 
227     // In the audio thread at the start of each render cycle, we&#39;ll call handleDeferredFinishDerefs().
228     void handleDeferredFinishDerefs();
229 
230     // Only accessed when the graph lock is held.
231     void markSummingJunctionDirty(AudioSummingJunction*);
232     void markAudioNodeOutputDirty(AudioNodeOutput*);
233 
234     // Must be called on main thread.
235     void removeMarkedSummingJunction(AudioSummingJunction*);
236 
237     // EventTarget
238     EventTargetInterface eventTargetInterface() const final { return AudioContextEventTargetInterfaceType; }
<a name="15" id="anc15"></a><span class="line-removed">239     ScriptExecutionContext* scriptExecutionContext() const final;</span>
240 
241     // Reconcile ref/deref which are defined both in ThreadSafeRefCounted and EventTarget.
242     using ThreadSafeRefCounted::ref;
243     using ThreadSafeRefCounted::deref;
244 
245     void startRendering();
<a name="16" id="anc16"></a><span class="line-modified">246     void fireCompletionEvent();</span>
247 
248     static unsigned s_hardwareContextCount;
249 
250     // Restrictions to change default behaviors.
251     enum BehaviorRestrictionFlags {
252         NoRestrictions = 0,
253         RequireUserGestureForAudioStartRestriction = 1 &lt;&lt; 0,
254         RequirePageConsentForAudioStartRestriction = 1 &lt;&lt; 1,
255     };
256     typedef unsigned BehaviorRestrictions;
257 
258     BehaviorRestrictions behaviorRestrictions() const { return m_restrictions; }
259     void addBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions |= restriction; }
260     void removeBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions &amp;= ~restriction; }
261 
262     void isPlayingAudioDidChange();
263 
264     void nodeWillBeginPlayback();
265 
<a name="17" id="anc17"></a>












266 protected:
267     explicit AudioContext(Document&amp;);
268     AudioContext(Document&amp;, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
269 
270     static bool isSampleRateRangeGood(float sampleRate);
<a name="18" id="anc18"></a>

271 
272 private:
273     void constructCommon();
274 
275     void lazyInitialize();
276     void uninitialize();
277 
278     bool willBeginPlayback();
279     bool willPausePlayback();
280 
281     bool userGestureRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequireUserGestureForAudioStartRestriction; }
282     bool pageConsentRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequirePageConsentForAudioStartRestriction; }
283 
284     void setState(State);
285 
286     void clear();
287 
288     void scheduleNodeDeletion();
289 
290     void mediaCanStart(Document&amp;) override;
291 
<a name="19" id="anc19"></a>



292     // MediaProducer
293     MediaProducer::MediaStateFlags mediaState() const override;
294     void pageMutedStateDidChange() override;
295 
296     // The context itself keeps a reference to all source nodes.  The source nodes, then reference all nodes they&#39;re connected to.
297     // In turn, these nodes reference all nodes they&#39;re connected to.  All nodes are ultimately connected to the AudioDestinationNode.
298     // When the context dereferences a source node, it will be deactivated from the rendering graph along with all other nodes it is
299     // uniquely connected to.  See the AudioNode::ref() and AudioNode::deref() methods for more details.
300     void refNode(AudioNode&amp;);
301     void derefNode(AudioNode&amp;);
302 
303     // ActiveDOMObject API.
304     void stop() override;
305     bool canSuspendForDocumentSuspension() const override;
306     const char* activeDOMObjectName() const override;
307 
308     // When the context goes away, there might still be some sources which haven&#39;t finished playing.
309     // Make sure to dereference them here.
310     void derefUnfinishedSourceNodes();
311 
312     // PlatformMediaSessionClient
313     PlatformMediaSession::MediaType mediaType() const override { return PlatformMediaSession::WebAudio; }
314     PlatformMediaSession::MediaType presentationType() const override { return PlatformMediaSession::WebAudio; }
315     PlatformMediaSession::CharacteristicsFlags characteristics() const override { return m_state == State::Running ? PlatformMediaSession::HasAudio : PlatformMediaSession::HasNothing; }
316     void mayResumePlayback(bool shouldResume) override;
317     void suspendPlayback() override;
318     bool canReceiveRemoteControlCommands() const override { return false; }
319     void didReceiveRemoteControlCommand(PlatformMediaSession::RemoteControlCommandType, const PlatformMediaSession::RemoteCommandArgument*) override { }
320     bool supportsSeeking() const override { return false; }
321     bool shouldOverrideBackgroundPlaybackRestriction(PlatformMediaSession::InterruptionType) const override { return false; }
322     String sourceApplicationIdentifier() const override;
323     bool canProduceAudio() const final { return true; }
324     bool isSuspended() const final;
325     bool processingUserGestureForMedia() const final;
326 
327     void visibilityStateChanged() final;
328 
329     // EventTarget
330     void refEventTarget() override { ref(); }
331     void derefEventTarget() override { deref(); }
332 
333     void handleDirtyAudioSummingJunctions();
334     void handleDirtyAudioNodeOutputs();
335 
336     void addReaction(State, DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
337     void updateAutomaticPullNodes();
338 
<a name="20" id="anc20"></a>








339     // Only accessed in the audio thread.
340     Vector&lt;AudioNode*&gt; m_finishedNodes;
341 
342     // We don&#39;t use RefPtr&lt;AudioNode&gt; here because AudioNode has a more complex ref() / deref() implementation
343     // with an optional argument for refType.  We need to use the special refType: RefTypeConnection
344     // Either accessed when the graph lock is held, or on the main thread when the audio thread has finished.
345     Vector&lt;AudioNode*&gt; m_referencedNodes;
346 
347     // Accumulate nodes which need to be deleted here.
348     // This is copied to m_nodesToDelete at the end of a render cycle in handlePostRenderTasks(), where we&#39;re assured of a stable graph
349     // state which will have no references to any of the nodes in m_nodesToDelete once the context lock is released
350     // (when handlePostRenderTasks() has completed).
351     Vector&lt;AudioNode*&gt; m_nodesMarkedForDeletion;
352 
353     // They will be scheduled for deletion (on the main thread) at the end of a render cycle (in realtime thread).
354     Vector&lt;AudioNode*&gt; m_nodesToDelete;
355 
356     bool m_isDeletionScheduled { false };
357     bool m_isStopScheduled { false };
358     bool m_isInitialized { false };
359     bool m_isAudioThreadFinished { false };
360     bool m_automaticPullNodesNeedUpdating { false };
361     bool m_isOfflineContext { false };
362 
363     // Only accessed when the graph lock is held.
364     HashSet&lt;AudioSummingJunction*&gt; m_dirtySummingJunctions;
365     HashSet&lt;AudioNodeOutput*&gt; m_dirtyAudioNodeOutputs;
366 
367     // For the sake of thread safety, we maintain a seperate Vector of automatic pull nodes for rendering in m_renderingAutomaticPullNodes.
368     // It will be copied from m_automaticPullNodes by updateAutomaticPullNodes() at the very start or end of the rendering quantum.
369     HashSet&lt;AudioNode*&gt; m_automaticPullNodes;
370     Vector&lt;AudioNode*&gt; m_renderingAutomaticPullNodes;
371     // Only accessed in the audio thread.
372     Vector&lt;AudioNode*&gt; m_deferredFinishDerefList;
373     Vector&lt;Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt;&gt; m_stateReactions;
374 
375     std::unique_ptr&lt;PlatformMediaSession&gt; m_mediaSession;
376     std::unique_ptr&lt;GenericEventQueue&gt; m_eventQueue;
377 
378     RefPtr&lt;AudioBuffer&gt; m_renderTarget;
379     RefPtr&lt;AudioDestinationNode&gt; m_destinationNode;
380     RefPtr&lt;AudioListener&gt; m_listener;
381 
382     unsigned m_connectionCount { 0 };
383 
384     // Graph locking.
385     Lock m_contextGraphMutex;
386     // FIXME: Using volatile seems incorrect.
387     // https://bugs.webkit.org/show_bug.cgi?id=180332
388     Thread* volatile m_audioThread { nullptr };
389     Thread* volatile m_graphOwnerThread { nullptr }; // if the lock is held then this is the thread which owns it, otherwise == nullptr.
390 
<a name="21" id="anc21"></a><span class="line-modified">391     AsyncAudioDecoder m_audioDecoder;</span>
392 
393     // This is considering 32 is large enough for multiple channels audio.
394     // It is somewhat arbitrary and could be increased if necessary.
395     enum { MaxNumberOfChannels = 32 };
396 
397     // Number of AudioBufferSourceNodes that are active (playing).
398     std::atomic&lt;int&gt; m_activeSourceCount { 0 };
399 
400     BehaviorRestrictions m_restrictions { NoRestrictions };
401 
402     State m_state { State::Suspended };
<a name="22" id="anc22"></a>
403 };
404 
405 // FIXME: Find out why these ==/!= functions are needed and remove them if possible.
406 
407 inline bool operator==(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
408 {
409     return &amp;lhs == &amp;rhs;
410 }
411 
412 inline bool operator!=(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
413 {
414     return &amp;lhs != &amp;rhs;
415 }
416 
417 inline AudioContext::State AudioContext::state() const
418 {
419     return m_state;
420 }
421 
422 } // WebCore
<a name="23" id="anc23"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="23" type="hidden" />
</body>
</html>