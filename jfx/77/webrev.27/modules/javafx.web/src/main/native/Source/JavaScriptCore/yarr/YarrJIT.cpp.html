<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/yarr/YarrJIT.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2009-2018 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;YarrJIT.h&quot;
  28 
  29 #include &lt;wtf/ASCIICType.h&gt;
  30 #include &quot;LinkBuffer.h&quot;
  31 #include &quot;Options.h&quot;
  32 #include &quot;VM.h&quot;
  33 #include &quot;Yarr.h&quot;
  34 #include &quot;YarrCanonicalize.h&quot;
  35 #include &quot;YarrDisassembler.h&quot;
  36 
  37 #if ENABLE(YARR_JIT)
  38 
  39 namespace JSC { namespace Yarr {
  40 
  41 template&lt;YarrJITCompileMode compileMode&gt;
  42 class YarrGenerator : public YarrJITInfo, private MacroAssembler {
  43 
  44 #if CPU(ARM_THUMB2)
  45     static const RegisterID input = ARMRegisters::r0;
  46     static const RegisterID index = ARMRegisters::r1;
  47     static const RegisterID length = ARMRegisters::r2;
  48     static const RegisterID output = ARMRegisters::r3;
  49 
  50     static const RegisterID regT0 = ARMRegisters::r4;
  51     static const RegisterID regT1 = ARMRegisters::r5;
  52     static const RegisterID initialStart = ARMRegisters::r8;
  53 
  54     static const RegisterID returnRegister = ARMRegisters::r0;
  55     static const RegisterID returnRegister2 = ARMRegisters::r1;
  56 
  57 #define HAVE_INITIAL_START_REG
  58 #elif CPU(ARM64)
  59     // Argument registers
  60     static const RegisterID input = ARM64Registers::x0;
  61     static const RegisterID index = ARM64Registers::x1;
  62     static const RegisterID length = ARM64Registers::x2;
  63     static const RegisterID output = ARM64Registers::x3;
  64     static const RegisterID freelistRegister = ARM64Registers::x4;
  65     static const RegisterID freelistSizeRegister = ARM64Registers::x5;
  66 
  67     // Scratch registers
  68     static const RegisterID regT0 = ARM64Registers::x6;
  69     static const RegisterID regT1 = ARM64Registers::x7;
  70     static const RegisterID regT2 = ARM64Registers::x8;
  71     static const RegisterID remainingMatchCount = ARM64Registers::x9;
  72     static const RegisterID regUnicodeInputAndTrail = ARM64Registers::x10;
  73     static const RegisterID initialStart = ARM64Registers::x11;
  74     static const RegisterID supplementaryPlanesBase = ARM64Registers::x12;
  75     static const RegisterID leadingSurrogateTag = ARM64Registers::x13;
  76     static const RegisterID trailingSurrogateTag = ARM64Registers::x14;
  77     static const RegisterID endOfStringAddress = ARM64Registers::x15;
  78 
  79     static const RegisterID returnRegister = ARM64Registers::x0;
  80     static const RegisterID returnRegister2 = ARM64Registers::x1;
  81 
  82     const TrustedImm32 surrogateTagMask = TrustedImm32(0xfffffc00);
  83 #define HAVE_INITIAL_START_REG
  84 #define JIT_UNICODE_EXPRESSIONS
  85 #elif CPU(MIPS)
  86     static const RegisterID input = MIPSRegisters::a0;
  87     static const RegisterID index = MIPSRegisters::a1;
  88     static const RegisterID length = MIPSRegisters::a2;
  89     static const RegisterID output = MIPSRegisters::a3;
  90 
  91     static const RegisterID regT0 = MIPSRegisters::t4;
  92     static const RegisterID regT1 = MIPSRegisters::t5;
  93     static const RegisterID initialStart = MIPSRegisters::t6;
  94 
  95     static const RegisterID returnRegister = MIPSRegisters::v0;
  96     static const RegisterID returnRegister2 = MIPSRegisters::v1;
  97 
  98 #define HAVE_INITIAL_START_REG
  99 #elif CPU(X86)
 100     static const RegisterID input = X86Registers::eax;
 101     static const RegisterID index = X86Registers::edx;
 102     static const RegisterID length = X86Registers::ecx;
 103     static const RegisterID output = X86Registers::edi;
 104 
 105     static const RegisterID regT0 = X86Registers::ebx;
 106     static const RegisterID regT1 = X86Registers::esi;
 107 
 108     static const RegisterID returnRegister = X86Registers::eax;
 109     static const RegisterID returnRegister2 = X86Registers::edx;
 110 #elif CPU(X86_64)
 111 #if !OS(WINDOWS)
 112     // Argument registers
 113     static const RegisterID input = X86Registers::edi;
 114     static const RegisterID index = X86Registers::esi;
 115     static const RegisterID length = X86Registers::edx;
 116     static const RegisterID output = X86Registers::ecx;
 117     static const RegisterID freelistRegister = X86Registers::r8;
 118     static const RegisterID freelistSizeRegister = X86Registers::r9; // Only used during initialization.
 119 #else
 120     // If the return value doesn&#39;t fit in 64bits, its destination is pointed by rcx and the parameters are shifted.
 121     // http://msdn.microsoft.com/en-us/library/7572ztz4.aspx
 122     COMPILE_ASSERT(sizeof(MatchResult) &gt; sizeof(void*), MatchResult_does_not_fit_in_64bits);
 123     static const RegisterID input = X86Registers::edx;
 124     static const RegisterID index = X86Registers::r8;
 125     static const RegisterID length = X86Registers::r9;
 126     static const RegisterID output = X86Registers::r10;
 127 #endif
 128 
 129     // Scratch registers
 130     static const RegisterID regT0 = X86Registers::eax;
 131 #if !OS(WINDOWS)
 132     static const RegisterID regT1 = X86Registers::r9;
 133     static const RegisterID regT2 = X86Registers::r10;
 134 #else
 135     static const RegisterID regT1 = X86Registers::ecx;
 136     static const RegisterID regT2 = X86Registers::edi;
 137 #endif
 138 
 139     static const RegisterID initialStart = X86Registers::ebx;
 140 #if !OS(WINDOWS)
 141     static const RegisterID remainingMatchCount = X86Registers::r12;
 142 #else
 143     static const RegisterID remainingMatchCount = X86Registers::esi;
 144 #endif
 145     static const RegisterID regUnicodeInputAndTrail = X86Registers::r13;
 146     static const RegisterID leadingSurrogateTag = X86Registers::r14;
 147     static const RegisterID endOfStringAddress = X86Registers::r15;
 148 
 149     static const RegisterID returnRegister = X86Registers::eax;
 150     static const RegisterID returnRegister2 = X86Registers::edx;
 151 
 152     const TrustedImm32 supplementaryPlanesBase = TrustedImm32(0x10000);
 153     const TrustedImm32 trailingSurrogateTag = TrustedImm32(0xdc00);
 154     const TrustedImm32 surrogateTagMask = TrustedImm32(0xfffffc00);
 155 #define HAVE_INITIAL_START_REG
 156 #define JIT_UNICODE_EXPRESSIONS
 157 #endif
 158 
 159 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
 160     struct ParenContextSizes {
 161         size_t m_numSubpatterns;
 162         size_t m_frameSlots;
 163 
 164         ParenContextSizes(size_t numSubpatterns, size_t frameSlots)
 165             : m_numSubpatterns(numSubpatterns)
 166             , m_frameSlots(frameSlots)
 167         {
 168         }
 169 
 170         size_t numSubpatterns() { return m_numSubpatterns; }
 171 
 172         size_t frameSlots() { return m_frameSlots; }
 173     };
 174 
 175     struct ParenContext {
 176         struct ParenContext* next;
 177         uint32_t begin;
 178         uint32_t matchAmount;
 179         uintptr_t returnAddress;
 180         struct Subpatterns {
 181             unsigned start;
 182             unsigned end;
 183         } subpatterns[0];
 184         uintptr_t frameSlots[0];
 185 
 186         static size_t sizeFor(ParenContextSizes&amp; parenContextSizes)
 187         {
 188             return sizeof(ParenContext) + sizeof(Subpatterns) * parenContextSizes.numSubpatterns() + sizeof(uintptr_t) * parenContextSizes.frameSlots();
 189         }
 190 
 191         static ptrdiff_t nextOffset()
 192         {
 193             return offsetof(ParenContext, next);
 194         }
 195 
 196         static ptrdiff_t beginOffset()
 197         {
 198             return offsetof(ParenContext, begin);
 199         }
 200 
 201         static ptrdiff_t matchAmountOffset()
 202         {
 203             return offsetof(ParenContext, matchAmount);
 204         }
 205 
 206         static ptrdiff_t returnAddressOffset()
 207         {
 208             return offsetof(ParenContext, returnAddress);
 209         }
 210 
 211         static ptrdiff_t subpatternOffset(size_t subpattern)
 212         {
 213             return offsetof(ParenContext, subpatterns) + (subpattern - 1) * sizeof(Subpatterns);
 214         }
 215 
 216         static ptrdiff_t savedFrameOffset(ParenContextSizes&amp; parenContextSizes)
 217         {
 218             return offsetof(ParenContext, subpatterns) + (parenContextSizes.numSubpatterns()) * sizeof(Subpatterns);
 219         }
 220     };
 221 
 222     void initParenContextFreeList()
 223     {
 224         RegisterID parenContextPointer = regT0;
 225         RegisterID nextParenContextPointer = regT2;
 226 
 227         size_t parenContextSize = ParenContext::sizeFor(m_parenContextSizes);
 228 
 229         parenContextSize = WTF::roundUpToMultipleOf&lt;sizeof(uintptr_t)&gt;(parenContextSize);
 230 
 231         if (parenContextSize &gt; VM::patternContextBufferSize) {
 232             m_failureReason = JITFailureReason::ParenthesisNestedTooDeep;
 233             return;
 234         }
 235 
 236         Jump emptyFreeList = branchTestPtr(Zero, freelistRegister);
 237         move(freelistRegister, parenContextPointer);
 238         addPtr(TrustedImm32(parenContextSize), freelistRegister, nextParenContextPointer);
 239         addPtr(freelistRegister, freelistSizeRegister);
 240         subPtr(TrustedImm32(parenContextSize), freelistSizeRegister);
 241 
 242         Label loopTop(this);
 243         Jump initDone = branchPtr(Above, nextParenContextPointer, freelistSizeRegister);
 244         storePtr(nextParenContextPointer, Address(parenContextPointer, ParenContext::nextOffset()));
 245         move(nextParenContextPointer, parenContextPointer);
 246         addPtr(TrustedImm32(parenContextSize), parenContextPointer, nextParenContextPointer);
 247         jump(loopTop);
 248 
 249         initDone.link(this);
 250         storePtr(TrustedImmPtr(nullptr), Address(parenContextPointer, ParenContext::nextOffset()));
 251         emptyFreeList.link(this);
 252     }
 253 
 254     void allocateParenContext(RegisterID result)
 255     {
 256         m_abortExecution.append(branchTestPtr(Zero, freelistRegister));
 257         sub32(TrustedImm32(1), remainingMatchCount);
 258         m_hitMatchLimit.append(branchTestPtr(Zero, remainingMatchCount));
 259         move(freelistRegister, result);
 260         loadPtr(Address(freelistRegister, ParenContext::nextOffset()), freelistRegister);
 261     }
 262 
 263     void freeParenContext(RegisterID headPtrRegister, RegisterID newHeadPtrRegister)
 264     {
 265         loadPtr(Address(headPtrRegister, ParenContext::nextOffset()), newHeadPtrRegister);
 266         storePtr(freelistRegister, Address(headPtrRegister, ParenContext::nextOffset()));
 267         move(headPtrRegister, freelistRegister);
 268     }
 269 
 270     void saveParenContext(RegisterID parenContextReg, RegisterID tempReg, unsigned firstSubpattern, unsigned lastSubpattern, unsigned subpatternBaseFrameLocation)
 271     {
 272         store32(index, Address(parenContextReg, ParenContext::beginOffset()));
 273         loadFromFrame(subpatternBaseFrameLocation + BackTrackInfoParentheses::matchAmountIndex(), tempReg);
 274         store32(tempReg, Address(parenContextReg, ParenContext::matchAmountOffset()));
 275         loadFromFrame(subpatternBaseFrameLocation + BackTrackInfoParentheses::returnAddressIndex(), tempReg);
 276         storePtr(tempReg, Address(parenContextReg, ParenContext::returnAddressOffset()));
 277         if (compileMode == IncludeSubpatterns) {
 278             for (unsigned subpattern = firstSubpattern; subpattern &lt;= lastSubpattern; subpattern++) {
 279                 loadPtr(Address(output, (subpattern &lt;&lt; 1) * sizeof(unsigned)), tempReg);
 280                 storePtr(tempReg, Address(parenContextReg, ParenContext::subpatternOffset(subpattern)));
 281                 clearSubpatternStart(subpattern);
 282             }
 283         }
 284         subpatternBaseFrameLocation += YarrStackSpaceForBackTrackInfoParentheses;
 285         for (unsigned frameLocation = subpatternBaseFrameLocation; frameLocation &lt; m_parenContextSizes.frameSlots(); frameLocation++) {
 286             loadFromFrame(frameLocation, tempReg);
 287             storePtr(tempReg, Address(parenContextReg, ParenContext::savedFrameOffset(m_parenContextSizes) + frameLocation * sizeof(uintptr_t)));
 288         }
 289     }
 290 
 291     void restoreParenContext(RegisterID parenContextReg, RegisterID tempReg, unsigned firstSubpattern, unsigned lastSubpattern, unsigned subpatternBaseFrameLocation)
 292     {
 293         load32(Address(parenContextReg, ParenContext::beginOffset()), index);
 294         storeToFrame(index, subpatternBaseFrameLocation + BackTrackInfoParentheses::beginIndex());
 295         load32(Address(parenContextReg, ParenContext::matchAmountOffset()), tempReg);
 296         storeToFrame(tempReg, subpatternBaseFrameLocation + BackTrackInfoParentheses::matchAmountIndex());
 297         loadPtr(Address(parenContextReg, ParenContext::returnAddressOffset()), tempReg);
 298         storeToFrame(tempReg, subpatternBaseFrameLocation + BackTrackInfoParentheses::returnAddressIndex());
 299         if (compileMode == IncludeSubpatterns) {
 300             for (unsigned subpattern = firstSubpattern; subpattern &lt;= lastSubpattern; subpattern++) {
 301                 loadPtr(Address(parenContextReg, ParenContext::subpatternOffset(subpattern)), tempReg);
 302                 storePtr(tempReg, Address(output, (subpattern &lt;&lt; 1) * sizeof(unsigned)));
 303             }
 304         }
 305         subpatternBaseFrameLocation += YarrStackSpaceForBackTrackInfoParentheses;
 306         for (unsigned frameLocation = subpatternBaseFrameLocation; frameLocation &lt; m_parenContextSizes.frameSlots(); frameLocation++) {
 307             loadPtr(Address(parenContextReg, ParenContext::savedFrameOffset(m_parenContextSizes) + frameLocation * sizeof(uintptr_t)), tempReg);
 308             storeToFrame(tempReg, frameLocation);
 309         }
 310     }
 311 #endif
 312 
 313     void optimizeAlternative(PatternAlternative* alternative)
 314     {
 315         if (!alternative-&gt;m_terms.size())
 316             return;
 317 
 318         for (unsigned i = 0; i &lt; alternative-&gt;m_terms.size() - 1; ++i) {
 319             PatternTerm&amp; term = alternative-&gt;m_terms[i];
 320             PatternTerm&amp; nextTerm = alternative-&gt;m_terms[i + 1];
 321 
 322             // We can move BMP only character classes after fixed character terms.
 323             if ((term.type == PatternTerm::TypeCharacterClass)
 324                 &amp;&amp; (term.quantityType == QuantifierFixedCount)
 325                 &amp;&amp; (!m_decodeSurrogatePairs || (term.characterClass-&gt;hasOneCharacterSize() &amp;&amp; !term.m_invert))
 326                 &amp;&amp; (nextTerm.type == PatternTerm::TypePatternCharacter)
 327                 &amp;&amp; (nextTerm.quantityType == QuantifierFixedCount)) {
 328                 PatternTerm termCopy = term;
 329                 alternative-&gt;m_terms[i] = nextTerm;
 330                 alternative-&gt;m_terms[i + 1] = termCopy;
 331             }
 332         }
 333     }
 334 
 335     void matchCharacterClassRange(RegisterID character, JumpList&amp; failures, JumpList&amp; matchDest, const CharacterRange* ranges, unsigned count, unsigned* matchIndex, const UChar32* matches, unsigned matchCount)
 336     {
 337         do {
 338             // pick which range we&#39;re going to generate
 339             int which = count &gt;&gt; 1;
 340             char lo = ranges[which].begin;
 341             char hi = ranges[which].end;
 342 
 343             // check if there are any ranges or matches below lo.  If not, just jl to failure -
 344             // if there is anything else to check, check that first, if it falls through jmp to failure.
 345             if ((*matchIndex &lt; matchCount) &amp;&amp; (matches[*matchIndex] &lt; lo)) {
 346                 Jump loOrAbove = branch32(GreaterThanOrEqual, character, Imm32((unsigned short)lo));
 347 
 348                 // generate code for all ranges before this one
 349                 if (which)
 350                     matchCharacterClassRange(character, failures, matchDest, ranges, which, matchIndex, matches, matchCount);
 351 
 352                 while ((*matchIndex &lt; matchCount) &amp;&amp; (matches[*matchIndex] &lt; lo)) {
 353                     matchDest.append(branch32(Equal, character, Imm32((unsigned short)matches[*matchIndex])));
 354                     ++*matchIndex;
 355                 }
 356                 failures.append(jump());
 357 
 358                 loOrAbove.link(this);
 359             } else if (which) {
 360                 Jump loOrAbove = branch32(GreaterThanOrEqual, character, Imm32((unsigned short)lo));
 361 
 362                 matchCharacterClassRange(character, failures, matchDest, ranges, which, matchIndex, matches, matchCount);
 363                 failures.append(jump());
 364 
 365                 loOrAbove.link(this);
 366             } else
 367                 failures.append(branch32(LessThan, character, Imm32((unsigned short)lo)));
 368 
 369             while ((*matchIndex &lt; matchCount) &amp;&amp; (matches[*matchIndex] &lt;= hi))
 370                 ++*matchIndex;
 371 
 372             matchDest.append(branch32(LessThanOrEqual, character, Imm32((unsigned short)hi)));
 373             // fall through to here, the value is above hi.
 374 
 375             // shuffle along &amp; loop around if there are any more matches to handle.
 376             unsigned next = which + 1;
 377             ranges += next;
 378             count -= next;
 379         } while (count);
 380     }
 381 
 382     void matchCharacterClass(RegisterID character, JumpList&amp; matchDest, const CharacterClass* charClass)
 383     {
 384         if (charClass-&gt;m_table &amp;&amp; !m_decodeSurrogatePairs) {
 385             ExtendedAddress tableEntry(character, reinterpret_cast&lt;intptr_t&gt;(charClass-&gt;m_table));
 386             matchDest.append(branchTest8(charClass-&gt;m_tableInverted ? Zero : NonZero, tableEntry));
 387             return;
 388         }
 389 
 390         JumpList unicodeFail;
 391         if (charClass-&gt;m_matchesUnicode.size() || charClass-&gt;m_rangesUnicode.size()) {
 392             JumpList isAscii;
 393             if (charClass-&gt;m_matches.size() || charClass-&gt;m_ranges.size())
 394                 isAscii.append(branch32(LessThanOrEqual, character, TrustedImm32(0x7f)));
 395 
 396             if (charClass-&gt;m_matchesUnicode.size()) {
 397                 for (unsigned i = 0; i &lt; charClass-&gt;m_matchesUnicode.size(); ++i) {
 398                     UChar32 ch = charClass-&gt;m_matchesUnicode[i];
 399                     matchDest.append(branch32(Equal, character, Imm32(ch)));
 400                 }
 401             }
 402 
 403             if (charClass-&gt;m_rangesUnicode.size()) {
 404                 for (unsigned i = 0; i &lt; charClass-&gt;m_rangesUnicode.size(); ++i) {
 405                     UChar32 lo = charClass-&gt;m_rangesUnicode[i].begin;
 406                     UChar32 hi = charClass-&gt;m_rangesUnicode[i].end;
 407 
 408                     Jump below = branch32(LessThan, character, Imm32(lo));
 409                     matchDest.append(branch32(LessThanOrEqual, character, Imm32(hi)));
 410                     below.link(this);
 411                 }
 412             }
 413 
 414             if (charClass-&gt;m_matches.size() || charClass-&gt;m_ranges.size())
 415                 unicodeFail = jump();
 416             isAscii.link(this);
 417         }
 418 
 419         if (charClass-&gt;m_ranges.size()) {
 420             unsigned matchIndex = 0;
 421             JumpList failures;
 422             matchCharacterClassRange(character, failures, matchDest, charClass-&gt;m_ranges.begin(), charClass-&gt;m_ranges.size(), &amp;matchIndex, charClass-&gt;m_matches.begin(), charClass-&gt;m_matches.size());
 423             while (matchIndex &lt; charClass-&gt;m_matches.size())
 424                 matchDest.append(branch32(Equal, character, Imm32((unsigned short)charClass-&gt;m_matches[matchIndex++])));
 425 
 426             failures.link(this);
 427         } else if (charClass-&gt;m_matches.size()) {
 428             // optimization: gather &#39;a&#39;,&#39;A&#39; etc back together, can mask &amp; test once.
 429             Vector&lt;char&gt; matchesAZaz;
 430 
 431             for (unsigned i = 0; i &lt; charClass-&gt;m_matches.size(); ++i) {
 432                 char ch = charClass-&gt;m_matches[i];
 433                 if (m_pattern.ignoreCase()) {
 434                     if (isASCIILower(ch)) {
 435                         matchesAZaz.append(ch);
 436                         continue;
 437                     }
 438                     if (isASCIIUpper(ch))
 439                         continue;
 440                 }
 441                 matchDest.append(branch32(Equal, character, Imm32((unsigned short)ch)));
 442             }
 443 
 444             if (unsigned countAZaz = matchesAZaz.size()) {
 445                 or32(TrustedImm32(32), character);
 446                 for (unsigned i = 0; i &lt; countAZaz; ++i)
 447                     matchDest.append(branch32(Equal, character, TrustedImm32(matchesAZaz[i])));
 448             }
 449         }
 450 
 451         if (charClass-&gt;m_matchesUnicode.size() || charClass-&gt;m_rangesUnicode.size())
 452             unicodeFail.link(this);
 453     }
 454 
 455 #ifdef JIT_UNICODE_EXPRESSIONS
 456     void advanceIndexAfterCharacterClassTermMatch(const PatternTerm* term, JumpList&amp; failuresAfterIncrementingIndex, const RegisterID character)
 457     {
 458         ASSERT(term-&gt;type == PatternTerm::TypeCharacterClass);
 459 
 460         if (term-&gt;isFixedWidthCharacterClass())
 461             add32(TrustedImm32(term-&gt;characterClass-&gt;hasNonBMPCharacters() ? 2 : 1), index);
 462         else {
 463             add32(TrustedImm32(1), index);
 464             Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);
 465             failuresAfterIncrementingIndex.append(atEndOfInput());
 466             add32(TrustedImm32(1), index);
 467             isBMPChar.link(this);
 468         }
 469     }
 470 #endif
 471 
 472     // Jumps if input not available; will have (incorrectly) incremented already!
 473     Jump jumpIfNoAvailableInput(unsigned countToCheck = 0)
 474     {
 475         if (countToCheck)
 476             add32(Imm32(countToCheck), index);
 477         return branch32(Above, index, length);
 478     }
 479 
 480     Jump jumpIfAvailableInput(unsigned countToCheck)
 481     {
 482         add32(Imm32(countToCheck), index);
 483         return branch32(BelowOrEqual, index, length);
 484     }
 485 
 486     Jump checkNotEnoughInput(RegisterID additionalAmount)
 487     {
 488         add32(index, additionalAmount);
 489         return branch32(Above, additionalAmount, length);
 490     }
 491 
 492     Jump checkInput()
 493     {
 494         return branch32(BelowOrEqual, index, length);
 495     }
 496 
 497     Jump atEndOfInput()
 498     {
 499         return branch32(Equal, index, length);
 500     }
 501 
 502     Jump notAtEndOfInput()
 503     {
 504         return branch32(NotEqual, index, length);
 505     }
 506 
 507     BaseIndex negativeOffsetIndexedAddress(Checked&lt;unsigned&gt; negativeCharacterOffset, RegisterID tempReg, RegisterID indexReg = index)
 508     {
 509         RegisterID base = input;
 510 
 511         // BaseIndex() addressing can take a int32_t offset. Given that we can have a regular
 512         // expression that has unsigned character offsets, BaseIndex&#39;s signed offset is insufficient
 513         // for addressing in extreme cases where we might underflow. Therefore we check to see if
 514         // negativeCharacterOffset will underflow directly or after converting for 16 bit characters.
 515         // If so, we do our own address calculating by adjusting the base, using the result register
 516         // as a temp address register.
 517         unsigned maximumNegativeOffsetForCharacterSize = m_charSize == Char8 ? 0x7fffffff : 0x3fffffff;
 518         unsigned offsetAdjustAmount = 0x40000000;
 519         if (negativeCharacterOffset.unsafeGet() &gt; maximumNegativeOffsetForCharacterSize) {
 520             base = tempReg;
 521             move(input, base);
 522             while (negativeCharacterOffset.unsafeGet() &gt; maximumNegativeOffsetForCharacterSize) {
 523                 subPtr(TrustedImm32(offsetAdjustAmount), base);
 524                 if (m_charSize != Char8)
 525                     subPtr(TrustedImm32(offsetAdjustAmount), base);
 526                 negativeCharacterOffset -= offsetAdjustAmount;
 527             }
 528         }
 529 
 530         Checked&lt;int32_t&gt; characterOffset(-static_cast&lt;int32_t&gt;(negativeCharacterOffset.unsafeGet()));
 531 
 532         if (m_charSize == Char8)
 533             return BaseIndex(input, indexReg, TimesOne, (characterOffset * static_cast&lt;int32_t&gt;(sizeof(char))).unsafeGet());
 534 
 535         return BaseIndex(input, indexReg, TimesTwo, (characterOffset * static_cast&lt;int32_t&gt;(sizeof(UChar))).unsafeGet());
 536     }
 537 
 538 #ifdef JIT_UNICODE_EXPRESSIONS
 539     void tryReadUnicodeCharImpl(RegisterID resultReg)
 540     {
 541         ASSERT(m_charSize == Char16);
 542 
 543         JumpList notUnicode;
 544 
 545         load16Unaligned(regUnicodeInputAndTrail, resultReg);
 546         and32(surrogateTagMask, resultReg, regT2);
 547         notUnicode.append(branch32(NotEqual, regT2, leadingSurrogateTag));
 548         addPtr(TrustedImm32(2), regUnicodeInputAndTrail);
 549         notUnicode.append(branchPtr(AboveOrEqual, regUnicodeInputAndTrail, endOfStringAddress));
 550         load16Unaligned(Address(regUnicodeInputAndTrail), regUnicodeInputAndTrail);
 551         and32(surrogateTagMask, regUnicodeInputAndTrail, regT2);
 552         notUnicode.append(branch32(NotEqual, regT2, trailingSurrogateTag));
 553         sub32(leadingSurrogateTag, resultReg);
 554         sub32(trailingSurrogateTag, regUnicodeInputAndTrail);
 555         lshift32(TrustedImm32(10), resultReg);
 556         or32(regUnicodeInputAndTrail, resultReg);
 557         add32(supplementaryPlanesBase, resultReg);
 558         notUnicode.link(this);
 559     }
 560 
 561     void tryReadUnicodeChar(BaseIndex address, RegisterID resultReg)
 562     {
 563         ASSERT(m_charSize == Char16);
 564 
 565         getEffectiveAddress(address, regUnicodeInputAndTrail);
 566 
 567         if (resultReg == regT0)
 568             m_tryReadUnicodeCharacterCalls.append(nearCall());
 569         else
 570             tryReadUnicodeCharImpl(resultReg);
 571     }
 572 #endif
 573 
 574     void readCharacterDontDecodeSurrogates(Checked&lt;unsigned&gt; negativeCharacterOffset, RegisterID resultReg, RegisterID indexReg = index)
 575     {
 576         BaseIndex address = negativeOffsetIndexedAddress(negativeCharacterOffset, resultReg, indexReg);
 577 
 578         if (m_charSize == Char8)
 579             load8(address, resultReg);
 580         else
 581             load16Unaligned(address, resultReg);
 582     }
 583 
 584     void readCharacter(Checked&lt;unsigned&gt; negativeCharacterOffset, RegisterID resultReg, RegisterID indexReg = index)
 585     {
 586         BaseIndex address = negativeOffsetIndexedAddress(negativeCharacterOffset, resultReg, indexReg);
 587 
 588         if (m_charSize == Char8)
 589             load8(address, resultReg);
 590 #ifdef JIT_UNICODE_EXPRESSIONS
 591         else if (m_decodeSurrogatePairs)
 592             tryReadUnicodeChar(address, resultReg);
 593 #endif
 594         else
 595             load16Unaligned(address, resultReg);
 596     }
 597 
 598     Jump jumpIfCharNotEquals(UChar32 ch, Checked&lt;unsigned&gt; negativeCharacterOffset, RegisterID character)
 599     {
 600         readCharacter(negativeCharacterOffset, character);
 601 
 602         // For case-insesitive compares, non-ascii characters that have different
 603         // upper &amp; lower case representations are converted to a character class.
 604         ASSERT(!m_pattern.ignoreCase() || isASCIIAlpha(ch) || isCanonicallyUnique(ch, m_canonicalMode));
 605         if (m_pattern.ignoreCase() &amp;&amp; isASCIIAlpha(ch)) {
 606             or32(TrustedImm32(0x20), character);
 607             ch |= 0x20;
 608         }
 609 
 610         return branch32(NotEqual, character, Imm32(ch));
 611     }
 612 
 613     void storeToFrame(RegisterID reg, unsigned frameLocation)
 614     {
 615         poke(reg, frameLocation);
 616     }
 617 
 618     void storeToFrame(TrustedImm32 imm, unsigned frameLocation)
 619     {
 620         poke(imm, frameLocation);
 621     }
 622 
 623 #if CPU(ARM64) || CPU(X86_64)
 624     void storeToFrame(TrustedImmPtr imm, unsigned frameLocation)
 625     {
 626         poke(imm, frameLocation);
 627     }
 628 #endif
 629 
 630     DataLabelPtr storeToFrameWithPatch(unsigned frameLocation)
 631     {
 632         return storePtrWithPatch(TrustedImmPtr(nullptr), Address(stackPointerRegister, frameLocation * sizeof(void*)));
 633     }
 634 
 635     void loadFromFrame(unsigned frameLocation, RegisterID reg)
 636     {
 637         peek(reg, frameLocation);
 638     }
 639 
 640     void loadFromFrameAndJump(unsigned frameLocation)
 641     {
 642         farJump(Address(stackPointerRegister, frameLocation * sizeof(void*)), YarrBacktrackPtrTag);
 643     }
 644 
 645     unsigned alignCallFrameSizeInBytes(unsigned callFrameSize)
 646     {
 647         if (!callFrameSize)
 648             return 0;
 649 
 650         callFrameSize *= sizeof(void*);
 651         if (callFrameSize / sizeof(void*) != m_pattern.m_body-&gt;m_callFrameSize)
 652             CRASH();
 653         callFrameSize = (callFrameSize + 0x3f) &amp; ~0x3f;
 654         return callFrameSize;
 655     }
 656     void initCallFrame()
 657     {
 658         unsigned callFrameSizeInBytes = alignCallFrameSizeInBytes(m_pattern.m_body-&gt;m_callFrameSize);
 659         if (callFrameSizeInBytes) {
 660 #if CPU(X86_64) || CPU(ARM64)
 661             if (Options::zeroStackFrame()) {
 662                 // We need to start from the stack pointer, because we could have spilled callee saves
 663                 move(stackPointerRegister, regT0);
 664                 subPtr(Imm32(callFrameSizeInBytes), stackPointerRegister);
 665                 if (callFrameSizeInBytes &lt;= 128) {
 666                     for (unsigned offset = 0; offset &lt; callFrameSizeInBytes; offset += sizeof(intptr_t))
 667                         storePtr(TrustedImm32(0), Address(regT0, -8 - offset));
 668                 } else {
 669                     Label zeroLoop = label();
 670                     subPtr(TrustedImm32(sizeof(intptr_t) * 2), regT0);
 671 #if CPU(ARM64)
 672                     storePair64(ARM64Registers::zr, ARM64Registers::zr, regT0);
 673 #else
 674                     storePtr(TrustedImm32(0), Address(regT0));
 675                     storePtr(TrustedImm32(0), Address(regT0, sizeof(intptr_t)));
 676 #endif
 677                     branchPtr(NotEqual, regT0, stackPointerRegister).linkTo(zeroLoop, this);
 678                 }
 679             } else
 680 #endif
 681                 subPtr(Imm32(callFrameSizeInBytes), stackPointerRegister);
 682 
 683         }
 684     }
 685     void removeCallFrame()
 686     {
 687         unsigned callFrameSizeInBytes = alignCallFrameSizeInBytes(m_pattern.m_body-&gt;m_callFrameSize);
 688         if (callFrameSizeInBytes)
 689             addPtr(Imm32(callFrameSizeInBytes), stackPointerRegister);
 690     }
 691 
 692     void generateFailReturn()
 693     {
 694         move(TrustedImmPtr((void*)WTF::notFound), returnRegister);
 695         move(TrustedImm32(0), returnRegister2);
 696         generateReturn();
 697     }
 698 
 699     void generateJITFailReturn()
 700     {
 701         if (m_abortExecution.empty() &amp;&amp; m_hitMatchLimit.empty())
 702             return;
 703 
 704         JumpList finishExiting;
 705         if (!m_abortExecution.empty()) {
 706             m_abortExecution.link(this);
 707             move(TrustedImmPtr((void*)static_cast&lt;size_t&gt;(-2)), returnRegister);
 708             finishExiting.append(jump());
 709         }
 710 
 711         if (!m_hitMatchLimit.empty()) {
 712             m_hitMatchLimit.link(this);
 713             move(TrustedImmPtr((void*)static_cast&lt;size_t&gt;(-1)), returnRegister);
 714         }
 715 
 716         finishExiting.link(this);
 717         removeCallFrame();
 718         move(TrustedImm32(0), returnRegister2);
 719         generateReturn();
 720     }
 721 
 722     // Used to record subpatterns, should only be called if compileMode is IncludeSubpatterns.
 723     void setSubpatternStart(RegisterID reg, unsigned subpattern)
 724     {
 725         ASSERT(subpattern);
 726         // FIXME: should be able to ASSERT(compileMode == IncludeSubpatterns), but then this function is conditionally NORETURN. :-(
 727         store32(reg, Address(output, (subpattern &lt;&lt; 1) * sizeof(int)));
 728     }
 729     void setSubpatternEnd(RegisterID reg, unsigned subpattern)
 730     {
 731         ASSERT(subpattern);
 732         // FIXME: should be able to ASSERT(compileMode == IncludeSubpatterns), but then this function is conditionally NORETURN. :-(
 733         store32(reg, Address(output, ((subpattern &lt;&lt; 1) + 1) * sizeof(int)));
 734     }
 735     void clearSubpatternStart(unsigned subpattern)
 736     {
 737         ASSERT(subpattern);
 738         // FIXME: should be able to ASSERT(compileMode == IncludeSubpatterns), but then this function is conditionally NORETURN. :-(
 739         store32(TrustedImm32(-1), Address(output, (subpattern &lt;&lt; 1) * sizeof(int)));
 740     }
 741 
 742     void clearMatches(unsigned subpattern, unsigned lastSubpattern)
 743     {
 744         for (; subpattern &lt;= lastSubpattern; subpattern++)
 745             clearSubpatternStart(subpattern);
 746     }
 747 
 748     // We use one of three different strategies to track the start of the current match,
 749     // while matching.
 750     // 1) If the pattern has a fixed size, do nothing! - we calculate the value lazily
 751     //    at the end of matching. This is irrespective of compileMode, and in this case
 752     //    these methods should never be called.
 753     // 2) If we&#39;re compiling IncludeSubpatterns, &#39;output&#39; contains a pointer to an output
 754     //    vector, store the match start in the output vector.
 755     // 3) If we&#39;re compiling MatchOnly, &#39;output&#39; is unused, store the match start directly
 756     //    in this register.
 757     void setMatchStart(RegisterID reg)
 758     {
 759         ASSERT(!m_pattern.m_body-&gt;m_hasFixedSize);
 760         if (compileMode == IncludeSubpatterns)
 761             store32(reg, output);
 762         else
 763             move(reg, output);
 764     }
 765     void getMatchStart(RegisterID reg)
 766     {
 767         ASSERT(!m_pattern.m_body-&gt;m_hasFixedSize);
 768         if (compileMode == IncludeSubpatterns)
 769             load32(output, reg);
 770         else
 771             move(output, reg);
 772     }
 773 
 774     enum YarrOpCode : uint8_t {
 775         // These nodes wrap body alternatives - those in the main disjunction,
 776         // rather than subpatterns or assertions. These are chained together in
 777         // a doubly linked list, with a &#39;begin&#39; node for the first alternative,
 778         // a &#39;next&#39; node for each subsequent alternative, and an &#39;end&#39; node at
 779         // the end. In the case of repeating alternatives, the &#39;end&#39; node also
 780         // has a reference back to &#39;begin&#39;.
 781         OpBodyAlternativeBegin,
 782         OpBodyAlternativeNext,
 783         OpBodyAlternativeEnd,
 784         // Similar to the body alternatives, but used for subpatterns with two
 785         // or more alternatives.
 786         OpNestedAlternativeBegin,
 787         OpNestedAlternativeNext,
 788         OpNestedAlternativeEnd,
 789         // Used for alternatives in subpatterns where there is only a single
 790         // alternative (backtracking is easier in these cases), or for alternatives
 791         // which never need to be backtracked (those in parenthetical assertions,
 792         // terminal subpatterns).
 793         OpSimpleNestedAlternativeBegin,
 794         OpSimpleNestedAlternativeNext,
 795         OpSimpleNestedAlternativeEnd,
 796         // Used to wrap &#39;Once&#39; subpattern matches (quantityMaxCount == 1).
 797         OpParenthesesSubpatternOnceBegin,
 798         OpParenthesesSubpatternOnceEnd,
 799         // Used to wrap &#39;Terminal&#39; subpattern matches (at the end of the regexp).
 800         OpParenthesesSubpatternTerminalBegin,
 801         OpParenthesesSubpatternTerminalEnd,
 802         // Used to wrap generic captured matches
 803         OpParenthesesSubpatternBegin,
 804         OpParenthesesSubpatternEnd,
 805         // Used to wrap parenthetical assertions.
 806         OpParentheticalAssertionBegin,
 807         OpParentheticalAssertionEnd,
 808         // Wraps all simple terms (pattern characters, character classes).
 809         OpTerm,
 810         // Where an expression contains only &#39;once through&#39; body alternatives
 811         // and no repeating ones, this op is used to return match failure.
 812         OpMatchFailed
 813     };
 814 
 815     // This structure is used to hold the compiled opcode information,
 816     // including reference back to the original PatternTerm/PatternAlternatives,
 817     // and JIT compilation data structures.
 818     struct YarrOp {
 819         explicit YarrOp(PatternTerm* term)
 820             : m_term(term)
 821             , m_op(OpTerm)
 822             , m_isDeadCode(false)
 823         {
 824         }
 825 
 826         explicit YarrOp(YarrOpCode op)
 827             : m_op(op)
 828             , m_isDeadCode(false)
 829         {
 830         }
 831 
 832         // For alternatives, this holds the PatternAlternative and doubly linked
 833         // references to this alternative&#39;s siblings. In the case of the
 834         // OpBodyAlternativeEnd node at the end of a section of repeating nodes,
 835         // m_nextOp will reference the OpBodyAlternativeBegin node of the first
 836         // repeating alternative.
 837         PatternAlternative* m_alternative;
 838         size_t m_previousOp;
 839         size_t m_nextOp;
 840 
 841         // The operation, as a YarrOpCode, and also a reference to the PatternTerm.
 842         PatternTerm* m_term;
 843         YarrOpCode m_op;
 844 
 845         // Used to record a set of Jumps out of the generated code, typically
 846         // used for jumps out to backtracking code, and a single reentry back
 847         // into the code for a node (likely where a backtrack will trigger
 848         // rematching).
 849         Label m_reentry;
 850         JumpList m_jumps;
 851 
 852         // Used for backtracking when the prior alternative did not consume any
 853         // characters but matched.
 854         Jump m_zeroLengthMatch;
 855 
 856         // This flag is used to null out the second pattern character, when
 857         // two are fused to match a pair together.
 858         bool m_isDeadCode;
 859 
 860         // Currently used in the case of some of the more complex management of
 861         // &#39;m_checkedOffset&#39;, to cache the offset used in this alternative, to avoid
 862         // recalculating it.
 863         Checked&lt;unsigned&gt; m_checkAdjust;
 864 
 865         // Used by OpNestedAlternativeNext/End to hold the pointer to the
 866         // value that will be pushed into the pattern&#39;s frame to return to,
 867         // upon backtracking back into the disjunction.
 868         DataLabelPtr m_returnAddress;
 869     };
 870 
 871     // BacktrackingState
 872     // This class encapsulates information about the state of code generation
 873     // whilst generating the code for backtracking, when a term fails to match.
 874     // Upon entry to code generation of the backtracking code for a given node,
 875     // the Backtracking state will hold references to all control flow sources
 876     // that are outputs in need of further backtracking from the prior node
 877     // generated (which is the subsequent operation in the regular expression,
 878     // and in the m_ops Vector, since we generated backtracking backwards).
 879     // These references to control flow take the form of:
 880     //  - A jump list of jumps, to be linked to code that will backtrack them
 881     //    further.
 882     //  - A set of DataLabelPtr values, to be populated with values to be
 883     //    treated effectively as return addresses backtracking into complex
 884     //    subpatterns.
 885     //  - A flag indicating that the current sequence of generated code up to
 886     //    this point requires backtracking.
 887     class BacktrackingState {
 888     public:
 889         BacktrackingState()
 890             : m_pendingFallthrough(false)
 891         {
 892         }
 893 
 894         // Add a jump or jumps, a return address, or set the flag indicating
 895         // that the current &#39;fallthrough&#39; control flow requires backtracking.
 896         void append(const Jump&amp; jump)
 897         {
 898             m_laterFailures.append(jump);
 899         }
 900         void append(JumpList&amp; jumpList)
 901         {
 902             m_laterFailures.append(jumpList);
 903         }
 904         void append(const DataLabelPtr&amp; returnAddress)
 905         {
 906             m_pendingReturns.append(returnAddress);
 907         }
 908         void fallthrough()
 909         {
 910             ASSERT(!m_pendingFallthrough);
 911             m_pendingFallthrough = true;
 912         }
 913 
 914         // These methods clear the backtracking state, either linking to the
 915         // current location, a provided label, or copying the backtracking out
 916         // to a JumpList. All actions may require code generation to take place,
 917         // and as such are passed a pointer to the assembler.
 918         void link(MacroAssembler* assembler)
 919         {
 920             if (m_pendingReturns.size()) {
 921                 Label here(assembler);
 922                 for (unsigned i = 0; i &lt; m_pendingReturns.size(); ++i)
 923                     m_backtrackRecords.append(ReturnAddressRecord(m_pendingReturns[i], here));
 924                 m_pendingReturns.clear();
 925             }
 926             m_laterFailures.link(assembler);
 927             m_laterFailures.clear();
 928             m_pendingFallthrough = false;
 929         }
 930         void linkTo(Label label, MacroAssembler* assembler)
 931         {
 932             if (m_pendingReturns.size()) {
 933                 for (unsigned i = 0; i &lt; m_pendingReturns.size(); ++i)
 934                     m_backtrackRecords.append(ReturnAddressRecord(m_pendingReturns[i], label));
 935                 m_pendingReturns.clear();
 936             }
 937             if (m_pendingFallthrough)
 938                 assembler-&gt;jump(label);
 939             m_laterFailures.linkTo(label, assembler);
 940             m_laterFailures.clear();
 941             m_pendingFallthrough = false;
 942         }
 943         void takeBacktracksToJumpList(JumpList&amp; jumpList, MacroAssembler* assembler)
 944         {
 945             if (m_pendingReturns.size()) {
 946                 Label here(assembler);
 947                 for (unsigned i = 0; i &lt; m_pendingReturns.size(); ++i)
 948                     m_backtrackRecords.append(ReturnAddressRecord(m_pendingReturns[i], here));
 949                 m_pendingReturns.clear();
 950                 m_pendingFallthrough = true;
 951             }
 952             if (m_pendingFallthrough)
 953                 jumpList.append(assembler-&gt;jump());
 954             jumpList.append(m_laterFailures);
 955             m_laterFailures.clear();
 956             m_pendingFallthrough = false;
 957         }
 958 
 959         bool isEmpty()
 960         {
 961             return m_laterFailures.empty() &amp;&amp; m_pendingReturns.isEmpty() &amp;&amp; !m_pendingFallthrough;
 962         }
 963 
 964         // Called at the end of code generation to link all return addresses.
 965         void linkDataLabels(LinkBuffer&amp; linkBuffer)
 966         {
 967             ASSERT(isEmpty());
 968             for (unsigned i = 0; i &lt; m_backtrackRecords.size(); ++i)
 969                 linkBuffer.patch(m_backtrackRecords[i].m_dataLabel, linkBuffer.locationOf&lt;YarrBacktrackPtrTag&gt;(m_backtrackRecords[i].m_backtrackLocation));
 970         }
 971 
 972     private:
 973         struct ReturnAddressRecord {
 974             ReturnAddressRecord(DataLabelPtr dataLabel, Label backtrackLocation)
 975                 : m_dataLabel(dataLabel)
 976                 , m_backtrackLocation(backtrackLocation)
 977             {
 978             }
 979 
 980             DataLabelPtr m_dataLabel;
 981             Label m_backtrackLocation;
 982         };
 983 
 984         JumpList m_laterFailures;
 985         bool m_pendingFallthrough;
 986         Vector&lt;DataLabelPtr, 4&gt; m_pendingReturns;
 987         Vector&lt;ReturnAddressRecord, 4&gt; m_backtrackRecords;
 988     };
 989 
 990     // Generation methods:
 991     // ===================
 992 
 993     // This method provides a default implementation of backtracking common
 994     // to many terms; terms commonly jump out of the forwards  matching path
 995     // on any failed conditions, and add these jumps to the m_jumps list. If
 996     // no special handling is required we can often just backtrack to m_jumps.
 997     void backtrackTermDefault(size_t opIndex)
 998     {
 999         YarrOp&amp; op = m_ops[opIndex];
1000         m_backtrackingState.append(op.m_jumps);
1001     }
1002 
1003     void generateAssertionBOL(size_t opIndex)
1004     {
1005         YarrOp&amp; op = m_ops[opIndex];
1006         PatternTerm* term = op.m_term;
1007 
1008         if (m_pattern.multiline()) {
1009             const RegisterID character = regT0;
1010 
1011             JumpList matchDest;
1012             if (!term-&gt;inputPosition)
1013                 matchDest.append(branch32(Equal, index, Imm32(m_checkedOffset.unsafeGet())));
1014 
1015             readCharacter(m_checkedOffset - term-&gt;inputPosition + 1, character);
1016             matchCharacterClass(character, matchDest, m_pattern.newlineCharacterClass());
1017             op.m_jumps.append(jump());
1018 
1019             matchDest.link(this);
1020         } else {
1021             // Erk, really should poison out these alternatives early. :-/
1022             if (term-&gt;inputPosition)
1023                 op.m_jumps.append(jump());
1024             else
1025                 op.m_jumps.append(branch32(NotEqual, index, Imm32(m_checkedOffset.unsafeGet())));
1026         }
1027     }
1028     void backtrackAssertionBOL(size_t opIndex)
1029     {
1030         backtrackTermDefault(opIndex);
1031     }
1032 
1033     void generateAssertionEOL(size_t opIndex)
1034     {
1035         YarrOp&amp; op = m_ops[opIndex];
1036         PatternTerm* term = op.m_term;
1037 
1038         if (m_pattern.multiline()) {
1039             const RegisterID character = regT0;
1040 
1041             JumpList matchDest;
1042             if (term-&gt;inputPosition == m_checkedOffset.unsafeGet())
1043                 matchDest.append(atEndOfInput());
1044 
1045             readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1046             matchCharacterClass(character, matchDest, m_pattern.newlineCharacterClass());
1047             op.m_jumps.append(jump());
1048 
1049             matchDest.link(this);
1050         } else {
1051             if (term-&gt;inputPosition == m_checkedOffset.unsafeGet())
1052                 op.m_jumps.append(notAtEndOfInput());
1053             // Erk, really should poison out these alternatives early. :-/
1054             else
1055                 op.m_jumps.append(jump());
1056         }
1057     }
1058     void backtrackAssertionEOL(size_t opIndex)
1059     {
1060         backtrackTermDefault(opIndex);
1061     }
1062 
1063     // Also falls though on nextIsNotWordChar.
1064     void matchAssertionWordchar(size_t opIndex, JumpList&amp; nextIsWordChar, JumpList&amp; nextIsNotWordChar)
1065     {
1066         YarrOp&amp; op = m_ops[opIndex];
1067         PatternTerm* term = op.m_term;
1068 
1069         const RegisterID character = regT0;
1070 
1071         if (term-&gt;inputPosition == m_checkedOffset.unsafeGet())
1072             nextIsNotWordChar.append(atEndOfInput());
1073 
1074         readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1075 
1076         CharacterClass* wordcharCharacterClass;
1077 
1078         if (m_unicodeIgnoreCase)
1079             wordcharCharacterClass = m_pattern.wordUnicodeIgnoreCaseCharCharacterClass();
1080         else
1081             wordcharCharacterClass = m_pattern.wordcharCharacterClass();
1082 
1083         matchCharacterClass(character, nextIsWordChar, wordcharCharacterClass);
1084     }
1085 
1086     void generateAssertionWordBoundary(size_t opIndex)
1087     {
1088         YarrOp&amp; op = m_ops[opIndex];
1089         PatternTerm* term = op.m_term;
1090 
1091         const RegisterID character = regT0;
1092 
1093         Jump atBegin;
1094         JumpList matchDest;
1095         if (!term-&gt;inputPosition)
1096             atBegin = branch32(Equal, index, Imm32(m_checkedOffset.unsafeGet()));
1097         readCharacter(m_checkedOffset - term-&gt;inputPosition + 1, character);
1098 
1099         CharacterClass* wordcharCharacterClass;
1100 
1101         if (m_unicodeIgnoreCase)
1102             wordcharCharacterClass = m_pattern.wordUnicodeIgnoreCaseCharCharacterClass();
1103         else
1104             wordcharCharacterClass = m_pattern.wordcharCharacterClass();
1105 
1106         matchCharacterClass(character, matchDest, wordcharCharacterClass);
1107         if (!term-&gt;inputPosition)
1108             atBegin.link(this);
1109 
1110         // We fall through to here if the last character was not a wordchar.
1111         JumpList nonWordCharThenWordChar;
1112         JumpList nonWordCharThenNonWordChar;
1113         if (term-&gt;invert()) {
1114             matchAssertionWordchar(opIndex, nonWordCharThenNonWordChar, nonWordCharThenWordChar);
1115             nonWordCharThenWordChar.append(jump());
1116         } else {
1117             matchAssertionWordchar(opIndex, nonWordCharThenWordChar, nonWordCharThenNonWordChar);
1118             nonWordCharThenNonWordChar.append(jump());
1119         }
1120         op.m_jumps.append(nonWordCharThenNonWordChar);
1121 
1122         // We jump here if the last character was a wordchar.
1123         matchDest.link(this);
1124         JumpList wordCharThenWordChar;
1125         JumpList wordCharThenNonWordChar;
1126         if (term-&gt;invert()) {
1127             matchAssertionWordchar(opIndex, wordCharThenNonWordChar, wordCharThenWordChar);
1128             wordCharThenWordChar.append(jump());
1129         } else {
1130             matchAssertionWordchar(opIndex, wordCharThenWordChar, wordCharThenNonWordChar);
1131             // This can fall-though!
1132         }
1133 
1134         op.m_jumps.append(wordCharThenWordChar);
1135 
1136         nonWordCharThenWordChar.link(this);
1137         wordCharThenNonWordChar.link(this);
1138     }
1139     void backtrackAssertionWordBoundary(size_t opIndex)
1140     {
1141         backtrackTermDefault(opIndex);
1142     }
1143 
1144 #if ENABLE(YARR_JIT_BACKREFERENCES)
1145     void matchBackreference(size_t opIndex, JumpList&amp; characterMatchFails, RegisterID character, RegisterID patternIndex, RegisterID patternCharacter)
1146     {
1147         YarrOp&amp; op = m_ops[opIndex];
1148         PatternTerm* term = op.m_term;
1149         unsigned subpatternId = term-&gt;backReferenceSubpatternId;
1150 
1151         Label loop(this);
1152 
1153         readCharacterDontDecodeSurrogates(0, patternCharacter, patternIndex);
1154         readCharacterDontDecodeSurrogates(m_checkedOffset - term-&gt;inputPosition, character);
1155 
1156         if (!m_pattern.ignoreCase())
1157             characterMatchFails.append(branch32(NotEqual, character, patternCharacter));
1158         else {
1159             Jump charactersMatch = branch32(Equal, character, patternCharacter);
1160             ExtendedAddress characterTableEntry(character, reinterpret_cast&lt;intptr_t&gt;(&amp;canonicalTableLChar));
1161             load16(characterTableEntry, character);
1162             ExtendedAddress patternTableEntry(patternCharacter, reinterpret_cast&lt;intptr_t&gt;(&amp;canonicalTableLChar));
1163             load16(patternTableEntry, patternCharacter);
1164             characterMatchFails.append(branch32(NotEqual, character, patternCharacter));
1165             charactersMatch.link(this);
1166         }
1167 
1168 
1169         add32(TrustedImm32(1), index);
1170         add32(TrustedImm32(1), patternIndex);
1171 
1172         branch32(NotEqual, patternIndex, Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int))).linkTo(loop, this);
1173     }
1174 
1175     void generateBackReference(size_t opIndex)
1176     {
1177         YarrOp&amp; op = m_ops[opIndex];
1178         PatternTerm* term = op.m_term;
1179 
1180         if (m_pattern.ignoreCase() &amp;&amp; m_charSize != Char8) {
1181             m_failureReason = JITFailureReason::BackReference;
1182             return;
1183         }
1184 
1185         unsigned subpatternId = term-&gt;backReferenceSubpatternId;
1186         unsigned parenthesesFrameLocation = term-&gt;frameLocation;
1187 
1188         const RegisterID characterOrTemp = regT0;
1189         const RegisterID patternIndex = regT1;
1190         const RegisterID patternTemp = regT2;
1191 
1192         storeToFrame(index, parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex());
1193         if (term-&gt;quantityType != QuantifierFixedCount || term-&gt;quantityMaxCount != 1)
1194             storeToFrame(TrustedImm32(0), parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1195 
1196         JumpList matches;
1197 
1198         if (term-&gt;quantityType != QuantifierNonGreedy) {
1199             load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternIndex);
1200             load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternTemp);
1201 
1202             // An empty match is successful without consuming characters
1203             if (term-&gt;quantityType != QuantifierFixedCount || term-&gt;quantityMaxCount != 1) {
1204                 matches.append(branch32(Equal, TrustedImm32(-1), patternIndex));
1205                 matches.append(branch32(Equal, patternIndex, patternTemp));
1206             } else {
1207                 Jump zeroLengthMatch = branch32(Equal, TrustedImm32(-1), patternIndex);
1208                 Jump tryNonZeroMatch = branch32(NotEqual, patternIndex, patternTemp);
1209                 zeroLengthMatch.link(this);
1210                 storeToFrame(TrustedImm32(1), parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1211                 matches.append(jump());
1212                 tryNonZeroMatch.link(this);
1213             }
1214         }
1215 
1216         switch (term-&gt;quantityType) {
1217         case QuantifierFixedCount: {
1218             Label outerLoop(this);
1219 
1220             // PatternTemp should contain pattern end index at this point
1221             sub32(patternIndex, patternTemp);
1222             op.m_jumps.append(checkNotEnoughInput(patternTemp));
1223 
1224             matchBackreference(opIndex, op.m_jumps, characterOrTemp, patternIndex, patternTemp);
1225 
1226             if (term-&gt;quantityMaxCount != 1) {
1227                 loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex(), characterOrTemp);
1228                 add32(TrustedImm32(1), characterOrTemp);
1229                 storeToFrame(characterOrTemp, parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1230                 matches.append(branch32(Equal, Imm32(term-&gt;quantityMaxCount.unsafeGet()), characterOrTemp));
1231                 load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternIndex);
1232                 load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternTemp);
1233                 jump(outerLoop);
1234             }
1235             matches.link(this);
1236             break;
1237         }
1238 
1239         case QuantifierGreedy: {
1240             JumpList incompleteMatches;
1241 
1242             Label outerLoop(this);
1243 
1244             // PatternTemp should contain pattern end index at this point
1245             sub32(patternIndex, patternTemp);
1246             matches.append(checkNotEnoughInput(patternTemp));
1247 
1248             matchBackreference(opIndex, incompleteMatches, characterOrTemp, patternIndex, patternTemp);
1249 
1250             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex(), characterOrTemp);
1251             add32(TrustedImm32(1), characterOrTemp);
1252             storeToFrame(characterOrTemp, parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1253             if (term-&gt;quantityMaxCount != quantifyInfinite)
1254                 matches.append(branch32(Equal, Imm32(term-&gt;quantityMaxCount.unsafeGet()), characterOrTemp));
1255             load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternIndex);
1256             load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternTemp);
1257 
1258             // Store current index in frame for restoring after a partial match
1259             storeToFrame(index, parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex());
1260             jump(outerLoop);
1261 
1262             incompleteMatches.link(this);
1263             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex(), index);
1264 
1265             matches.link(this);
1266             op.m_reentry = label();
1267             break;
1268         }
1269 
1270         case QuantifierNonGreedy: {
1271             JumpList incompleteMatches;
1272 
1273             matches.append(jump());
1274 
1275             op.m_reentry = label();
1276 
1277             load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternIndex);
1278             load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternTemp);
1279 
1280             // An empty match is successful without consuming characters
1281             Jump zeroLengthMatch = branch32(Equal, TrustedImm32(-1), patternIndex);
1282             Jump tryNonZeroMatch = branch32(NotEqual, patternIndex, patternTemp);
1283             zeroLengthMatch.link(this);
1284             storeToFrame(TrustedImm32(1), parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1285             matches.append(jump());
1286             tryNonZeroMatch.link(this);
1287 
1288             // Check if we have input remaining to match
1289             sub32(patternIndex, patternTemp);
1290             matches.append(checkNotEnoughInput(patternTemp));
1291 
1292             storeToFrame(index, parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex());
1293 
1294             matchBackreference(opIndex, incompleteMatches, characterOrTemp, patternIndex, patternTemp);
1295 
1296             matches.append(jump());
1297 
1298             incompleteMatches.link(this);
1299             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex(), index);
1300 
1301             matches.link(this);
1302             break;
1303         }
1304         }
1305     }
1306     void backtrackBackReference(size_t opIndex)
1307     {
1308         YarrOp&amp; op = m_ops[opIndex];
1309         PatternTerm* term = op.m_term;
1310 
1311         unsigned subpatternId = term-&gt;backReferenceSubpatternId;
1312 
1313         m_backtrackingState.link(this);
1314         op.m_jumps.link(this);
1315 
1316         JumpList failures;
1317 
1318         unsigned parenthesesFrameLocation = term-&gt;frameLocation;
1319         switch (term-&gt;quantityType) {
1320         case QuantifierFixedCount:
1321             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::beginIndex(), index);
1322             break;
1323 
1324         case QuantifierGreedy: {
1325             const RegisterID matchAmount = regT0;
1326             const RegisterID patternStartIndex = regT1;
1327             const RegisterID patternEndIndexOrLen = regT2;
1328 
1329             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex(), matchAmount);
1330             failures.append(branchTest32(Zero, matchAmount));
1331 
1332             load32(Address(output, (subpatternId &lt;&lt; 1) * sizeof(int)), patternStartIndex);
1333             load32(Address(output, ((subpatternId &lt;&lt; 1) + 1) * sizeof(int)), patternEndIndexOrLen);
1334             sub32(patternStartIndex, patternEndIndexOrLen);
1335             sub32(patternEndIndexOrLen, index);
1336 
1337             sub32(TrustedImm32(1), matchAmount);
1338             storeToFrame(matchAmount, parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1339             jump(op.m_reentry);
1340             break;
1341         }
1342 
1343         case QuantifierNonGreedy: {
1344             const RegisterID matchAmount = regT0;
1345 
1346             failures.append(atEndOfInput());
1347             loadFromFrame(parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex(), matchAmount);
1348             if (term-&gt;quantityMaxCount != quantifyInfinite)
1349                 failures.append(branch32(AboveOrEqual, Imm32(term-&gt;quantityMaxCount.unsafeGet()), matchAmount));
1350             add32(TrustedImm32(1), matchAmount);
1351             storeToFrame(matchAmount, parenthesesFrameLocation + BackTrackInfoBackReference::matchAmountIndex());
1352             jump(op.m_reentry);
1353             break;
1354         }
1355         }
1356         failures.link(this);
1357         m_backtrackingState.fallthrough();
1358     }
1359 #endif
1360 
1361     void generatePatternCharacterOnce(size_t opIndex)
1362     {
1363         YarrOp&amp; op = m_ops[opIndex];
1364 
1365         if (op.m_isDeadCode)
1366             return;
1367 
1368         // m_ops always ends with a OpBodyAlternativeEnd or OpMatchFailed
1369         // node, so there must always be at least one more node.
1370         ASSERT(opIndex + 1 &lt; m_ops.size());
1371         YarrOp* nextOp = &amp;m_ops[opIndex + 1];
1372 
1373         PatternTerm* term = op.m_term;
1374         UChar32 ch = term-&gt;patternCharacter;
1375 
1376         if (!isLatin1(ch) &amp;&amp; (m_charSize == Char8)) {
1377             // Have a 16 bit pattern character and an 8 bit string - short circuit
1378             op.m_jumps.append(jump());
1379             return;
1380         }
1381 
1382         const RegisterID character = regT0;
1383 #if CPU(X86_64) || CPU(ARM64)
1384         unsigned maxCharactersAtOnce = m_charSize == Char8 ? 8 : 4;
1385 #else
1386         unsigned maxCharactersAtOnce = m_charSize == Char8 ? 4 : 2;
1387 #endif
1388         uint64_t ignoreCaseMask = 0;
1389 #if CPU(BIG_ENDIAN)
1390         uint64_t allCharacters = ch &lt;&lt; (m_charSize == Char8 ? 24 : 16);
1391 #else
1392         uint64_t allCharacters = ch;
1393 #endif
1394         unsigned numberCharacters;
1395         unsigned startTermPosition = term-&gt;inputPosition;
1396 
1397         // For case-insesitive compares, non-ascii characters that have different
1398         // upper &amp; lower case representations are converted to a character class.
1399         ASSERT(!m_pattern.ignoreCase() || isASCIIAlpha(ch) || isCanonicallyUnique(ch, m_canonicalMode));
1400 
1401         if (m_pattern.ignoreCase() &amp;&amp; isASCIIAlpha(ch)) {
1402 #if CPU(BIG_ENDIAN)
1403             ignoreCaseMask |= 32 &lt;&lt; (m_charSize == Char8 ? 24 : 16);
1404 #else
1405             ignoreCaseMask |= 32;
1406 #endif
1407         }
1408 
1409         for (numberCharacters = 1; numberCharacters &lt; maxCharactersAtOnce &amp;&amp; nextOp-&gt;m_op == OpTerm; ++numberCharacters, nextOp = &amp;m_ops[opIndex + numberCharacters]) {
1410             PatternTerm* nextTerm = nextOp-&gt;m_term;
1411 
1412             // YarrJIT handles decoded surrogate pair as one character if unicode flag is enabled.
1413             // Note that the numberCharacters become 1 while the width of the pattern character becomes 32bit in this case.
1414             if (nextTerm-&gt;type != PatternTerm::TypePatternCharacter
1415                 || nextTerm-&gt;quantityType != QuantifierFixedCount
1416                 || nextTerm-&gt;quantityMaxCount != 1
1417                 || nextTerm-&gt;inputPosition != (startTermPosition + numberCharacters)
1418                 || (U16_LENGTH(nextTerm-&gt;patternCharacter) != 1 &amp;&amp; m_decodeSurrogatePairs))
1419                 break;
1420 
1421             nextOp-&gt;m_isDeadCode = true;
1422 
1423 #if CPU(BIG_ENDIAN)
1424             int shiftAmount = (m_charSize == Char8 ? 24 : 16) - ((m_charSize == Char8 ? 8 : 16) * numberCharacters);
1425 #else
1426             int shiftAmount = (m_charSize == Char8 ? 8 : 16) * numberCharacters;
1427 #endif
1428 
1429             UChar32 currentCharacter = nextTerm-&gt;patternCharacter;
1430 
1431             if (!isLatin1(currentCharacter) &amp;&amp; (m_charSize == Char8)) {
1432                 // Have a 16 bit pattern character and an 8 bit string - short circuit
1433                 op.m_jumps.append(jump());
1434                 return;
1435             }
1436 
1437             // For case-insesitive compares, non-ascii characters that have different
1438             // upper &amp; lower case representations are converted to a character class.
1439             ASSERT(!m_pattern.ignoreCase() || isASCIIAlpha(currentCharacter) || isCanonicallyUnique(currentCharacter, m_canonicalMode));
1440 
1441             allCharacters |= (static_cast&lt;uint64_t&gt;(currentCharacter) &lt;&lt; shiftAmount);
1442 
1443             if ((m_pattern.ignoreCase()) &amp;&amp; (isASCIIAlpha(currentCharacter)))
1444                 ignoreCaseMask |= 32ULL &lt;&lt; shiftAmount;
1445         }
1446 
1447         if (m_decodeSurrogatePairs)
1448             op.m_jumps.append(jumpIfNoAvailableInput());
1449 
1450         if (m_charSize == Char8) {
1451             auto check1 = [&amp;] (Checked&lt;unsigned&gt; offset, UChar32 characters) {
1452                 op.m_jumps.append(jumpIfCharNotEquals(characters, offset, character));
1453             };
1454 
1455             auto check2 = [&amp;] (Checked&lt;unsigned&gt; offset, uint16_t characters, uint16_t mask) {
1456                 load16Unaligned(negativeOffsetIndexedAddress(offset, character), character);
1457                 if (mask)
1458                     or32(Imm32(mask), character);
1459                 op.m_jumps.append(branch32(NotEqual, character, Imm32(characters | mask)));
1460             };
1461 
1462             auto check4 = [&amp;] (Checked&lt;unsigned&gt; offset, unsigned characters, unsigned mask) {
1463                 if (mask) {
1464                     load32WithUnalignedHalfWords(negativeOffsetIndexedAddress(offset, character), character);
1465                     if (mask)
1466                         or32(Imm32(mask), character);
1467                     op.m_jumps.append(branch32(NotEqual, character, Imm32(characters | mask)));
1468                     return;
1469                 }
1470                 op.m_jumps.append(branch32WithUnalignedHalfWords(NotEqual, negativeOffsetIndexedAddress(offset, character), TrustedImm32(characters)));
1471             };
1472 
1473 #if CPU(X86_64) || CPU(ARM64)
1474             auto check8 = [&amp;] (Checked&lt;unsigned&gt; offset, uint64_t characters, uint64_t mask) {
1475                 load64(negativeOffsetIndexedAddress(offset, character), character);
1476                 if (mask)
1477                     or64(TrustedImm64(mask), character);
1478                 op.m_jumps.append(branch64(NotEqual, character, TrustedImm64(characters | mask)));
1479             };
1480 #endif
1481 
1482             switch (numberCharacters) {
1483             case 1:
1484                 // Use 32bit width of allCharacters since Yarr counts surrogate pairs as one character with unicode flag.
1485                 check1(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff);
1486                 return;
1487             case 2: {
1488                 check2(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffff, ignoreCaseMask &amp; 0xffff);
1489                 return;
1490             }
1491             case 3: {
1492                 check2(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffff, ignoreCaseMask &amp; 0xffff);
1493                 check1(m_checkedOffset - startTermPosition - 2, (allCharacters &gt;&gt; 16) &amp; 0xff);
1494                 return;
1495             }
1496             case 4: {
1497                 check4(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1498                 return;
1499             }
1500 #if CPU(X86_64) || CPU(ARM64)
1501             case 5: {
1502                 check4(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1503                 check1(m_checkedOffset - startTermPosition - 4, (allCharacters &gt;&gt; 32) &amp; 0xff);
1504                 return;
1505             }
1506             case 6: {
1507                 check4(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1508                 check2(m_checkedOffset - startTermPosition - 4, (allCharacters &gt;&gt; 32) &amp; 0xffff, (ignoreCaseMask &gt;&gt; 32) &amp; 0xffff);
1509                 return;
1510             }
1511             case 7: {
1512                 check4(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1513                 check2(m_checkedOffset - startTermPosition - 4, (allCharacters &gt;&gt; 32) &amp; 0xffff, (ignoreCaseMask &gt;&gt; 32) &amp; 0xffff);
1514                 check1(m_checkedOffset - startTermPosition - 6, (allCharacters &gt;&gt; 48) &amp; 0xff);
1515                 return;
1516             }
1517             case 8: {
1518                 check8(m_checkedOffset - startTermPosition, allCharacters, ignoreCaseMask);
1519                 return;
1520             }
1521 #endif
1522             }
1523         } else {
1524             auto check1 = [&amp;] (Checked&lt;unsigned&gt; offset, UChar32 characters) {
1525                 op.m_jumps.append(jumpIfCharNotEquals(characters, offset, character));
1526             };
1527 
1528             auto check2 = [&amp;] (Checked&lt;unsigned&gt; offset, unsigned characters, unsigned mask) {
1529                 if (mask) {
1530                     load32WithUnalignedHalfWords(negativeOffsetIndexedAddress(offset, character), character);
1531                     if (mask)
1532                         or32(Imm32(mask), character);
1533                     op.m_jumps.append(branch32(NotEqual, character, Imm32(characters | mask)));
1534                     return;
1535                 }
1536                 op.m_jumps.append(branch32WithUnalignedHalfWords(NotEqual, negativeOffsetIndexedAddress(offset, character), TrustedImm32(characters)));
1537             };
1538 
1539 #if CPU(X86_64) || CPU(ARM64)
1540             auto check4 = [&amp;] (Checked&lt;unsigned&gt; offset, uint64_t characters, uint64_t mask) {
1541                 load64(negativeOffsetIndexedAddress(offset, character), character);
1542                 if (mask)
1543                     or64(TrustedImm64(mask), character);
1544                 op.m_jumps.append(branch64(NotEqual, character, TrustedImm64(characters | mask)));
1545             };
1546 #endif
1547 
1548             switch (numberCharacters) {
1549             case 1:
1550                 // Use 32bit width of allCharacters since Yarr counts surrogate pairs as one character with unicode flag.
1551                 check1(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff);
1552                 return;
1553             case 2:
1554                 check2(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1555                 return;
1556 #if CPU(X86_64) || CPU(ARM64)
1557             case 3:
1558                 check2(m_checkedOffset - startTermPosition, allCharacters &amp; 0xffffffff, ignoreCaseMask &amp; 0xffffffff);
1559                 check1(m_checkedOffset - startTermPosition - 2, (allCharacters &gt;&gt; 32) &amp; 0xffff);
1560                 return;
1561             case 4:
1562                 check4(m_checkedOffset - startTermPosition, allCharacters, ignoreCaseMask);
1563                 return;
1564 #endif
1565             }
1566         }
1567     }
1568     void backtrackPatternCharacterOnce(size_t opIndex)
1569     {
1570         backtrackTermDefault(opIndex);
1571     }
1572 
1573     void generatePatternCharacterFixed(size_t opIndex)
1574     {
1575         YarrOp&amp; op = m_ops[opIndex];
1576         PatternTerm* term = op.m_term;
1577         UChar32 ch = term-&gt;patternCharacter;
1578 
1579         const RegisterID character = regT0;
1580         const RegisterID countRegister = regT1;
1581 
1582         if (m_decodeSurrogatePairs)
1583             op.m_jumps.append(jumpIfNoAvailableInput());
1584 
1585         move(index, countRegister);
1586         Checked&lt;unsigned&gt; scaledMaxCount = term-&gt;quantityMaxCount;
1587         scaledMaxCount *= U_IS_BMP(ch) ? 1 : 2;
1588         sub32(Imm32(scaledMaxCount.unsafeGet()), countRegister);
1589 
1590         Label loop(this);
1591         readCharacter(m_checkedOffset - term-&gt;inputPosition - scaledMaxCount, character, countRegister);
1592         // For case-insesitive compares, non-ascii characters that have different
1593         // upper &amp; lower case representations are converted to a character class.
1594         ASSERT(!m_pattern.ignoreCase() || isASCIIAlpha(ch) || isCanonicallyUnique(ch, m_canonicalMode));
1595         if (m_pattern.ignoreCase() &amp;&amp; isASCIIAlpha(ch)) {
1596             or32(TrustedImm32(0x20), character);
1597             ch |= 0x20;
1598         }
1599 
1600         op.m_jumps.append(branch32(NotEqual, character, Imm32(ch)));
1601 #ifdef JIT_UNICODE_EXPRESSIONS
1602         if (m_decodeSurrogatePairs &amp;&amp; !U_IS_BMP(ch))
1603             add32(TrustedImm32(2), countRegister);
1604         else
1605 #endif
1606             add32(TrustedImm32(1), countRegister);
1607         branch32(NotEqual, countRegister, index).linkTo(loop, this);
1608     }
1609     void backtrackPatternCharacterFixed(size_t opIndex)
1610     {
1611         backtrackTermDefault(opIndex);
1612     }
1613 
1614     void generatePatternCharacterGreedy(size_t opIndex)
1615     {
1616         YarrOp&amp; op = m_ops[opIndex];
1617         PatternTerm* term = op.m_term;
1618         UChar32 ch = term-&gt;patternCharacter;
1619 
1620         const RegisterID character = regT0;
1621         const RegisterID countRegister = regT1;
1622 
1623         move(TrustedImm32(0), countRegister);
1624 
1625         // Unless have a 16 bit pattern character and an 8 bit string - short circuit
1626         if (!(!isLatin1(ch) &amp;&amp; (m_charSize == Char8))) {
1627             JumpList failures;
1628             Label loop(this);
1629             failures.append(atEndOfInput());
1630             failures.append(jumpIfCharNotEquals(ch, m_checkedOffset - term-&gt;inputPosition, character));
1631 
1632             add32(TrustedImm32(1), index);
1633 #ifdef JIT_UNICODE_EXPRESSIONS
1634             if (m_decodeSurrogatePairs &amp;&amp; !U_IS_BMP(ch)) {
1635                 Jump surrogatePairOk = notAtEndOfInput();
1636                 sub32(TrustedImm32(1), index);
1637                 failures.append(jump());
1638                 surrogatePairOk.link(this);
1639                 add32(TrustedImm32(1), index);
1640             }
1641 #endif
1642             add32(TrustedImm32(1), countRegister);
1643 
1644             if (term-&gt;quantityMaxCount == quantifyInfinite)
1645                 jump(loop);
1646             else
1647                 branch32(NotEqual, countRegister, Imm32(term-&gt;quantityMaxCount.unsafeGet())).linkTo(loop, this);
1648 
1649             failures.link(this);
1650         }
1651         op.m_reentry = label();
1652 
1653         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoPatternCharacter::matchAmountIndex());
1654     }
1655     void backtrackPatternCharacterGreedy(size_t opIndex)
1656     {
1657         YarrOp&amp; op = m_ops[opIndex];
1658         PatternTerm* term = op.m_term;
1659 
1660         const RegisterID countRegister = regT1;
1661 
1662         m_backtrackingState.link(this);
1663 
1664         loadFromFrame(term-&gt;frameLocation + BackTrackInfoPatternCharacter::matchAmountIndex(), countRegister);
1665         m_backtrackingState.append(branchTest32(Zero, countRegister));
1666         sub32(TrustedImm32(1), countRegister);
1667         if (!m_decodeSurrogatePairs || U_IS_BMP(term-&gt;patternCharacter))
1668             sub32(TrustedImm32(1), index);
1669         else
1670             sub32(TrustedImm32(2), index);
1671         jump(op.m_reentry);
1672     }
1673 
1674     void generatePatternCharacterNonGreedy(size_t opIndex)
1675     {
1676         YarrOp&amp; op = m_ops[opIndex];
1677         PatternTerm* term = op.m_term;
1678 
1679         const RegisterID countRegister = regT1;
1680 
1681         move(TrustedImm32(0), countRegister);
1682         op.m_reentry = label();
1683         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoPatternCharacter::matchAmountIndex());
1684     }
1685     void backtrackPatternCharacterNonGreedy(size_t opIndex)
1686     {
1687         YarrOp&amp; op = m_ops[opIndex];
1688         PatternTerm* term = op.m_term;
1689         UChar32 ch = term-&gt;patternCharacter;
1690 
1691         const RegisterID character = regT0;
1692         const RegisterID countRegister = regT1;
1693 
1694         m_backtrackingState.link(this);
1695 
1696         loadFromFrame(term-&gt;frameLocation + BackTrackInfoPatternCharacter::matchAmountIndex(), countRegister);
1697 
1698         // Unless have a 16 bit pattern character and an 8 bit string - short circuit
1699         if (!(!isLatin1(ch) &amp;&amp; (m_charSize == Char8))) {
1700             JumpList nonGreedyFailures;
1701             nonGreedyFailures.append(atEndOfInput());
1702             if (term-&gt;quantityMaxCount != quantifyInfinite)
1703                 nonGreedyFailures.append(branch32(Equal, countRegister, Imm32(term-&gt;quantityMaxCount.unsafeGet())));
1704             nonGreedyFailures.append(jumpIfCharNotEquals(ch, m_checkedOffset - term-&gt;inputPosition, character));
1705 
1706             add32(TrustedImm32(1), index);
1707 #ifdef JIT_UNICODE_EXPRESSIONS
1708             if (m_decodeSurrogatePairs &amp;&amp; !U_IS_BMP(ch)) {
1709                 Jump surrogatePairOk = notAtEndOfInput();
1710                 sub32(TrustedImm32(1), index);
1711                 nonGreedyFailures.append(jump());
1712                 surrogatePairOk.link(this);
1713                 add32(TrustedImm32(1), index);
1714             }
1715 #endif
1716             add32(TrustedImm32(1), countRegister);
1717 
1718             jump(op.m_reentry);
1719             nonGreedyFailures.link(this);
1720         }
1721 
1722         if (m_decodeSurrogatePairs &amp;&amp; !U_IS_BMP(ch)) {
1723             // subtract countRegister*2 for non-BMP characters
1724             lshift32(TrustedImm32(1), countRegister);
1725         }
1726 
1727         sub32(countRegister, index);
1728         m_backtrackingState.fallthrough();
1729     }
1730 
1731     void generateCharacterClassOnce(size_t opIndex)
1732     {
1733         YarrOp&amp; op = m_ops[opIndex];
1734         PatternTerm* term = op.m_term;
1735 
1736         const RegisterID character = regT0;
1737 
1738         if (m_decodeSurrogatePairs) {
1739             op.m_jumps.append(jumpIfNoAvailableInput());
1740             storeToFrame(index, term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex());
1741         }
1742 
1743         JumpList matchDest;
1744         readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1745         // If we are matching the &quot;any character&quot; builtin class we only need to read the
1746         // character and don&#39;t need to match as it will always succeed.
1747         if (term-&gt;invert() || !term-&gt;characterClass-&gt;m_anyCharacter) {
1748             matchCharacterClass(character, matchDest, term-&gt;characterClass);
1749 
1750             if (term-&gt;invert())
1751                 op.m_jumps.append(matchDest);
1752             else {
1753                 op.m_jumps.append(jump());
1754                 matchDest.link(this);
1755             }
1756         }
1757 #ifdef JIT_UNICODE_EXPRESSIONS
1758         if (m_decodeSurrogatePairs &amp;&amp; (!term-&gt;characterClass-&gt;hasOneCharacterSize() || term-&gt;invert())) {
1759             Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);
1760             op.m_jumps.append(atEndOfInput());
1761             add32(TrustedImm32(1), index);
1762             isBMPChar.link(this);
1763         }
1764 #endif
1765     }
1766     void backtrackCharacterClassOnce(size_t opIndex)
1767     {
1768 #ifdef JIT_UNICODE_EXPRESSIONS
1769         if (m_decodeSurrogatePairs) {
1770             YarrOp&amp; op = m_ops[opIndex];
1771             PatternTerm* term = op.m_term;
1772 
1773             m_backtrackingState.link(this);
1774             loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex(), index);
1775             m_backtrackingState.fallthrough();
1776         }
1777 #endif
1778         backtrackTermDefault(opIndex);
1779     }
1780 
1781     void generateCharacterClassFixed(size_t opIndex)
1782     {
1783         YarrOp&amp; op = m_ops[opIndex];
1784         PatternTerm* term = op.m_term;
1785 
1786         const RegisterID character = regT0;
1787         const RegisterID countRegister = regT1;
1788 
1789         if (m_decodeSurrogatePairs)
1790             op.m_jumps.append(jumpIfNoAvailableInput());
1791 
1792         move(index, countRegister);
1793 
1794         Checked&lt;unsigned&gt; scaledMaxCount = term-&gt;quantityMaxCount;
1795 
1796 #ifdef JIT_UNICODE_EXPRESSIONS
1797         if (m_decodeSurrogatePairs &amp;&amp; term-&gt;characterClass-&gt;hasOnlyNonBMPCharacters() &amp;&amp; !term-&gt;invert())
1798             scaledMaxCount *= 2;
1799 #endif
1800         sub32(Imm32(scaledMaxCount.unsafeGet()), countRegister);
1801 
1802         Label loop(this);
1803         JumpList matchDest;
1804         readCharacter(m_checkedOffset - term-&gt;inputPosition - scaledMaxCount, character, countRegister);
1805         // If we are matching the &quot;any character&quot; builtin class we only need to read the
1806         // character and don&#39;t need to match as it will always succeed.
1807         if (term-&gt;invert() || !term-&gt;characterClass-&gt;m_anyCharacter) {
1808             matchCharacterClass(character, matchDest, term-&gt;characterClass);
1809 
1810             if (term-&gt;invert())
1811                 op.m_jumps.append(matchDest);
1812             else {
1813                 op.m_jumps.append(jump());
1814                 matchDest.link(this);
1815             }
1816         }
1817 
1818 #ifdef JIT_UNICODE_EXPRESSIONS
1819         if (m_decodeSurrogatePairs) {
1820             if (term-&gt;isFixedWidthCharacterClass())
1821                 add32(TrustedImm32(term-&gt;characterClass-&gt;hasNonBMPCharacters() ? 2 : 1), countRegister);
1822             else {
1823                 add32(TrustedImm32(1), countRegister);
1824                 Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);
1825                 op.m_jumps.append(atEndOfInput());
1826                 add32(TrustedImm32(1), countRegister);
1827                 add32(TrustedImm32(1), index);
1828                 isBMPChar.link(this);
1829             }
1830         } else
1831 #endif
1832             add32(TrustedImm32(1), countRegister);
1833         branch32(NotEqual, countRegister, index).linkTo(loop, this);
1834     }
1835     void backtrackCharacterClassFixed(size_t opIndex)
1836     {
1837         backtrackTermDefault(opIndex);
1838     }
1839 
1840     void generateCharacterClassGreedy(size_t opIndex)
1841     {
1842         YarrOp&amp; op = m_ops[opIndex];
1843         PatternTerm* term = op.m_term;
1844 
1845         const RegisterID character = regT0;
1846         const RegisterID countRegister = regT1;
1847 
1848         if (m_decodeSurrogatePairs &amp;&amp; (!term-&gt;characterClass-&gt;hasOneCharacterSize() || term-&gt;invert()))
1849             storeToFrame(index, term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex());
1850         move(TrustedImm32(0), countRegister);
1851 
1852         JumpList failures;
1853         JumpList failuresDecrementIndex;
1854         Label loop(this);
1855 #ifdef JIT_UNICODE_EXPRESSIONS
1856         if (term-&gt;isFixedWidthCharacterClass() &amp;&amp; term-&gt;characterClass-&gt;hasNonBMPCharacters()) {
1857             move(TrustedImm32(1), character);
1858             failures.append(checkNotEnoughInput(character));
1859         } else
1860 #endif
1861             failures.append(atEndOfInput());
1862 
1863         if (term-&gt;invert()) {
1864             readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1865             matchCharacterClass(character, failures, term-&gt;characterClass);
1866         } else {
1867             JumpList matchDest;
1868             readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1869             // If we are matching the &quot;any character&quot; builtin class for non-unicode patterns,
1870             // we only need to read the character and don&#39;t need to match as it will always succeed.
1871             if (!term-&gt;characterClass-&gt;m_anyCharacter) {
1872                 matchCharacterClass(character, matchDest, term-&gt;characterClass);
1873                 failures.append(jump());
1874             }
1875             matchDest.link(this);
1876         }
1877 
1878 #ifdef JIT_UNICODE_EXPRESSIONS
1879         if (m_decodeSurrogatePairs)
1880             advanceIndexAfterCharacterClassTermMatch(term, failuresDecrementIndex, character);
1881         else
1882 #endif
1883             add32(TrustedImm32(1), index);
1884         add32(TrustedImm32(1), countRegister);
1885 
1886         if (term-&gt;quantityMaxCount != quantifyInfinite) {
1887             branch32(NotEqual, countRegister, Imm32(term-&gt;quantityMaxCount.unsafeGet())).linkTo(loop, this);
1888             failures.append(jump());
1889         } else
1890             jump(loop);
1891 
1892         if (!failuresDecrementIndex.empty()) {
1893             failuresDecrementIndex.link(this);
1894             sub32(TrustedImm32(1), index);
1895         }
1896 
1897         failures.link(this);
1898         op.m_reentry = label();
1899 
1900         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex());
1901     }
1902     void backtrackCharacterClassGreedy(size_t opIndex)
1903     {
1904         YarrOp&amp; op = m_ops[opIndex];
1905         PatternTerm* term = op.m_term;
1906 
1907         const RegisterID countRegister = regT1;
1908 
1909         m_backtrackingState.link(this);
1910 
1911         loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex(), countRegister);
1912         m_backtrackingState.append(branchTest32(Zero, countRegister));
1913         sub32(TrustedImm32(1), countRegister);
1914         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex());
1915 
1916         if (!m_decodeSurrogatePairs)
1917             sub32(TrustedImm32(1), index);
1918         else if (term-&gt;isFixedWidthCharacterClass())
1919             sub32(TrustedImm32(term-&gt;characterClass-&gt;hasNonBMPCharacters() ? 2 : 1), index);
1920         else {
1921             // Rematch one less
1922             const RegisterID character = regT0;
1923 
1924             loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex(), index);
1925 
1926             Label rematchLoop(this);
1927             Jump doneRematching = branchTest32(Zero, countRegister);
1928 
1929             readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1930 
1931             sub32(TrustedImm32(1), countRegister);
1932             add32(TrustedImm32(1), index);
1933 
1934 #ifdef JIT_UNICODE_EXPRESSIONS
1935             Jump isBMPChar = branch32(LessThan, character, supplementaryPlanesBase);
1936             add32(TrustedImm32(1), index);
1937             isBMPChar.link(this);
1938 #endif
1939 
1940             jump(rematchLoop);
1941             doneRematching.link(this);
1942 
1943             loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex(), countRegister);
1944         }
1945         jump(op.m_reentry);
1946     }
1947 
1948     void generateCharacterClassNonGreedy(size_t opIndex)
1949     {
1950         YarrOp&amp; op = m_ops[opIndex];
1951         PatternTerm* term = op.m_term;
1952 
1953         const RegisterID countRegister = regT1;
1954 
1955         move(TrustedImm32(0), countRegister);
1956         op.m_reentry = label();
1957 
1958 #ifdef JIT_UNICODE_EXPRESSIONS
1959         if (m_decodeSurrogatePairs) {
1960             if (!term-&gt;characterClass-&gt;hasOneCharacterSize() || term-&gt;invert())
1961                 storeToFrame(index, term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex());
1962         }
1963 #endif
1964 
1965         storeToFrame(countRegister, term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex());
1966     }
1967 
1968     void backtrackCharacterClassNonGreedy(size_t opIndex)
1969     {
1970         YarrOp&amp; op = m_ops[opIndex];
1971         PatternTerm* term = op.m_term;
1972 
1973         const RegisterID character = regT0;
1974         const RegisterID countRegister = regT1;
1975 
1976         JumpList nonGreedyFailures;
1977         JumpList nonGreedyFailuresDecrementIndex;
1978 
1979         m_backtrackingState.link(this);
1980 
1981 #ifdef JIT_UNICODE_EXPRESSIONS
1982         if (m_decodeSurrogatePairs) {
1983             if (!term-&gt;characterClass-&gt;hasOneCharacterSize() || term-&gt;invert())
1984                 loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::beginIndex(), index);
1985         }
1986 #endif
1987 
1988         loadFromFrame(term-&gt;frameLocation + BackTrackInfoCharacterClass::matchAmountIndex(), countRegister);
1989 
1990         nonGreedyFailures.append(atEndOfInput());
1991         nonGreedyFailures.append(branch32(Equal, countRegister, Imm32(term-&gt;quantityMaxCount.unsafeGet())));
1992 
1993         JumpList matchDest;
1994         readCharacter(m_checkedOffset - term-&gt;inputPosition, character);
1995         // If we are matching the &quot;any character&quot; builtin class for non-unicode patterns,
1996         // we only need to read the character and don&#39;t need to match as it will always succeed.
1997         if (term-&gt;invert() || !term-&gt;characterClass-&gt;m_anyCharacter) {
1998             matchCharacterClass(character, matchDest, term-&gt;characterClass);
1999 
2000             if (term-&gt;invert())
2001                 nonGreedyFailures.append(matchDest);
2002             else {
2003                 nonGreedyFailures.append(jump());
2004                 matchDest.link(this);
2005             }
2006         }
2007 
2008 #ifdef JIT_UNICODE_EXPRESSIONS
2009         if (m_decodeSurrogatePairs)
2010             advanceIndexAfterCharacterClassTermMatch(term, nonGreedyFailuresDecrementIndex, character);
2011         else
2012 #endif
2013             add32(TrustedImm32(1), index);
2014         add32(TrustedImm32(1), countRegister);
2015 
2016         jump(op.m_reentry);
2017 
2018         if (!nonGreedyFailuresDecrementIndex.empty()) {
2019             nonGreedyFailuresDecrementIndex.link(this);
2020             breakpoint();
2021         }
2022         nonGreedyFailures.link(this);
2023         sub32(countRegister, index);
2024         m_backtrackingState.fallthrough();
2025     }
2026 
2027     void generateDotStarEnclosure(size_t opIndex)
2028     {
2029         YarrOp&amp; op = m_ops[opIndex];
2030         PatternTerm* term = op.m_term;
2031 
2032         const RegisterID character = regT0;
2033         const RegisterID matchPos = regT1;
2034 #ifndef HAVE_INITIAL_START_REG
2035         const RegisterID initialStart = character;
2036 #endif
2037 
2038         JumpList foundBeginningNewLine;
2039         JumpList saveStartIndex;
2040         JumpList foundEndingNewLine;
2041 
2042         if (m_pattern.dotAll()) {
2043             move(TrustedImm32(0), matchPos);
2044             setMatchStart(matchPos);
2045             move(length, index);
2046             return;
2047         }
2048 
2049         ASSERT(!m_pattern.m_body-&gt;m_hasFixedSize);
2050         getMatchStart(matchPos);
2051 
2052 #ifndef HAVE_INITIAL_START_REG
2053         loadFromFrame(m_pattern.m_initialStartValueFrameLocation, initialStart);
2054 #endif
2055         saveStartIndex.append(branch32(BelowOrEqual, matchPos, initialStart));
2056         Label findBOLLoop(this);
2057         sub32(TrustedImm32(1), matchPos);
2058         if (m_charSize == Char8)
2059             load8(BaseIndex(input, matchPos, TimesOne, 0), character);
2060         else
2061             load16(BaseIndex(input, matchPos, TimesTwo, 0), character);
2062         matchCharacterClass(character, foundBeginningNewLine, m_pattern.newlineCharacterClass());
2063 
2064 #ifndef HAVE_INITIAL_START_REG
2065         loadFromFrame(m_pattern.m_initialStartValueFrameLocation, initialStart);
2066 #endif
2067         branch32(Above, matchPos, initialStart).linkTo(findBOLLoop, this);
2068         saveStartIndex.append(jump());
2069 
2070         foundBeginningNewLine.link(this);
2071         add32(TrustedImm32(1), matchPos); // Advance past newline
2072         saveStartIndex.link(this);
2073 
2074         if (!m_pattern.multiline() &amp;&amp; term-&gt;anchors.bolAnchor)
2075             op.m_jumps.append(branchTest32(NonZero, matchPos));
2076 
2077         ASSERT(!m_pattern.m_body-&gt;m_hasFixedSize);
2078         setMatchStart(matchPos);
2079 
2080         move(index, matchPos);
2081 
2082         Label findEOLLoop(this);
2083         foundEndingNewLine.append(branch32(Equal, matchPos, length));
2084         if (m_charSize == Char8)
2085             load8(BaseIndex(input, matchPos, TimesOne, 0), character);
2086         else
2087             load16(BaseIndex(input, matchPos, TimesTwo, 0), character);
2088         matchCharacterClass(character, foundEndingNewLine, m_pattern.newlineCharacterClass());
2089         add32(TrustedImm32(1), matchPos);
2090         jump(findEOLLoop);
2091 
2092         foundEndingNewLine.link(this);
2093 
2094         if (!m_pattern.multiline() &amp;&amp; term-&gt;anchors.eolAnchor)
2095             op.m_jumps.append(branch32(NotEqual, matchPos, length));
2096 
2097         move(matchPos, index);
2098     }
2099 
2100     void backtrackDotStarEnclosure(size_t opIndex)
2101     {
2102         backtrackTermDefault(opIndex);
2103     }
2104 
2105     // Code generation/backtracking for simple terms
2106     // (pattern characters, character classes, and assertions).
2107     // These methods farm out work to the set of functions above.
2108     void generateTerm(size_t opIndex)
2109     {
2110         YarrOp&amp; op = m_ops[opIndex];
2111         PatternTerm* term = op.m_term;
2112 
2113         switch (term-&gt;type) {
2114         case PatternTerm::TypePatternCharacter:
2115             switch (term-&gt;quantityType) {
2116             case QuantifierFixedCount:
2117                 if (term-&gt;quantityMaxCount == 1)
2118                     generatePatternCharacterOnce(opIndex);
2119                 else
2120                     generatePatternCharacterFixed(opIndex);
2121                 break;
2122             case QuantifierGreedy:
2123                 generatePatternCharacterGreedy(opIndex);
2124                 break;
2125             case QuantifierNonGreedy:
2126                 generatePatternCharacterNonGreedy(opIndex);
2127                 break;
2128             }
2129             break;
2130 
2131         case PatternTerm::TypeCharacterClass:
2132             switch (term-&gt;quantityType) {
2133             case QuantifierFixedCount:
2134                 if (term-&gt;quantityMaxCount == 1)
2135                     generateCharacterClassOnce(opIndex);
2136                 else
2137                     generateCharacterClassFixed(opIndex);
2138                 break;
2139             case QuantifierGreedy:
2140                 generateCharacterClassGreedy(opIndex);
2141                 break;
2142             case QuantifierNonGreedy:
2143                 generateCharacterClassNonGreedy(opIndex);
2144                 break;
2145             }
2146             break;
2147 
2148         case PatternTerm::TypeAssertionBOL:
2149             generateAssertionBOL(opIndex);
2150             break;
2151 
2152         case PatternTerm::TypeAssertionEOL:
2153             generateAssertionEOL(opIndex);
2154             break;
2155 
2156         case PatternTerm::TypeAssertionWordBoundary:
2157             generateAssertionWordBoundary(opIndex);
2158             break;
2159 
2160         case PatternTerm::TypeForwardReference:
2161             m_failureReason = JITFailureReason::ForwardReference;
2162             break;
2163 
2164         case PatternTerm::TypeParenthesesSubpattern:
2165         case PatternTerm::TypeParentheticalAssertion:
2166             RELEASE_ASSERT_NOT_REACHED();
2167 
2168         case PatternTerm::TypeBackReference:
2169 #if ENABLE(YARR_JIT_BACKREFERENCES)
2170             generateBackReference(opIndex);
2171 #else
2172             m_failureReason = JITFailureReason::BackReference;
2173 #endif
2174             break;
2175         case PatternTerm::TypeDotStarEnclosure:
2176             generateDotStarEnclosure(opIndex);
2177             break;
2178         }
2179     }
2180     void backtrackTerm(size_t opIndex)
2181     {
2182         YarrOp&amp; op = m_ops[opIndex];
2183         PatternTerm* term = op.m_term;
2184 
2185         switch (term-&gt;type) {
2186         case PatternTerm::TypePatternCharacter:
2187             switch (term-&gt;quantityType) {
2188             case QuantifierFixedCount:
2189                 if (term-&gt;quantityMaxCount == 1)
2190                     backtrackPatternCharacterOnce(opIndex);
2191                 else
2192                     backtrackPatternCharacterFixed(opIndex);
2193                 break;
2194             case QuantifierGreedy:
2195                 backtrackPatternCharacterGreedy(opIndex);
2196                 break;
2197             case QuantifierNonGreedy:
2198                 backtrackPatternCharacterNonGreedy(opIndex);
2199                 break;
2200             }
2201             break;
2202 
2203         case PatternTerm::TypeCharacterClass:
2204             switch (term-&gt;quantityType) {
2205             case QuantifierFixedCount:
2206                 if (term-&gt;quantityMaxCount == 1)
2207                     backtrackCharacterClassOnce(opIndex);
2208                 else
2209                     backtrackCharacterClassFixed(opIndex);
2210                 break;
2211             case QuantifierGreedy:
2212                 backtrackCharacterClassGreedy(opIndex);
2213                 break;
2214             case QuantifierNonGreedy:
2215                 backtrackCharacterClassNonGreedy(opIndex);
2216                 break;
2217             }
2218             break;
2219 
2220         case PatternTerm::TypeAssertionBOL:
2221             backtrackAssertionBOL(opIndex);
2222             break;
2223 
2224         case PatternTerm::TypeAssertionEOL:
2225             backtrackAssertionEOL(opIndex);
2226             break;
2227 
2228         case PatternTerm::TypeAssertionWordBoundary:
2229             backtrackAssertionWordBoundary(opIndex);
2230             break;
2231 
2232         case PatternTerm::TypeForwardReference:
2233             m_failureReason = JITFailureReason::ForwardReference;
2234             break;
2235 
2236         case PatternTerm::TypeParenthesesSubpattern:
2237         case PatternTerm::TypeParentheticalAssertion:
2238             RELEASE_ASSERT_NOT_REACHED();
2239 
2240         case PatternTerm::TypeBackReference:
2241 #if ENABLE(YARR_JIT_BACKREFERENCES)
2242             backtrackBackReference(opIndex);
2243 #else
2244             m_failureReason = JITFailureReason::BackReference;
2245 #endif
2246             break;
2247 
2248         case PatternTerm::TypeDotStarEnclosure:
2249             backtrackDotStarEnclosure(opIndex);
2250             break;
2251         }
2252     }
2253 
2254     void generate()
2255     {
2256         // Forwards generate the matching code.
2257         ASSERT(m_ops.size());
2258         size_t opIndex = 0;
2259 
2260         do {
2261             if (m_disassembler)
2262                 m_disassembler-&gt;setForGenerate(opIndex, label());
2263 
2264             YarrOp&amp; op = m_ops[opIndex];
2265             switch (op.m_op) {
2266 
2267             case OpTerm:
2268                 generateTerm(opIndex);
2269                 break;
2270 
2271             // OpBodyAlternativeBegin/Next/End
2272             //
2273             // These nodes wrap the set of alternatives in the body of the regular expression.
2274             // There may be either one or two chains of OpBodyAlternative nodes, one representing
2275             // the &#39;once through&#39; sequence of alternatives (if any exist), and one representing
2276             // the repeating alternatives (again, if any exist).
2277             //
2278             // Upon normal entry to the Begin alternative, we will check that input is available.
2279             // Reentry to the Begin alternative will take place after the check has taken place,
2280             // and will assume that the input position has already been progressed as appropriate.
2281             //
2282             // Entry to subsequent Next/End alternatives occurs when the prior alternative has
2283             // successfully completed a match - return a success state from JIT code.
2284             //
2285             // Next alternatives allow for reentry optimized to suit backtracking from its
2286             // preceding alternative. It expects the input position to still be set to a position
2287             // appropriate to its predecessor, and it will only perform an input check if the
2288             // predecessor had a minimum size less than its own.
2289             //
2290             // In the case &#39;once through&#39; expressions, the End node will also have a reentry
2291             // point to jump to when the last alternative fails. Again, this expects the input
2292             // position to still reflect that expected by the prior alternative.
2293             case OpBodyAlternativeBegin: {
2294                 PatternAlternative* alternative = op.m_alternative;
2295 
2296                 // Upon entry at the head of the set of alternatives, check if input is available
2297                 // to run the first alternative. (This progresses the input position).
2298                 op.m_jumps.append(jumpIfNoAvailableInput(alternative-&gt;m_minimumSize));
2299                 // We will reenter after the check, and assume the input position to have been
2300                 // set as appropriate to this alternative.
2301                 op.m_reentry = label();
2302 
2303                 m_checkedOffset += alternative-&gt;m_minimumSize;
2304                 break;
2305             }
2306             case OpBodyAlternativeNext:
2307             case OpBodyAlternativeEnd: {
2308                 PatternAlternative* priorAlternative = m_ops[op.m_previousOp].m_alternative;
2309                 PatternAlternative* alternative = op.m_alternative;
2310 
2311                 // If we get here, the prior alternative matched - return success.
2312 
2313                 // Adjust the stack pointer to remove the pattern&#39;s frame.
2314                 removeCallFrame();
2315 
2316                 // Load appropriate values into the return register and the first output
2317                 // slot, and return. In the case of pattern with a fixed size, we will
2318                 // not have yet set the value in the first
2319                 ASSERT(index != returnRegister);
2320                 if (m_pattern.m_body-&gt;m_hasFixedSize) {
2321                     move(index, returnRegister);
2322                     if (priorAlternative-&gt;m_minimumSize)
2323                         sub32(Imm32(priorAlternative-&gt;m_minimumSize), returnRegister);
2324                     if (compileMode == IncludeSubpatterns)
2325                         store32(returnRegister, output);
2326                 } else
2327                     getMatchStart(returnRegister);
2328                 if (compileMode == IncludeSubpatterns)
2329                     store32(index, Address(output, 4));
2330                 move(index, returnRegister2);
2331 
2332                 generateReturn();
2333 
2334                 // This is the divide between the tail of the prior alternative, above, and
2335                 // the head of the subsequent alternative, below.
2336 
2337                 if (op.m_op == OpBodyAlternativeNext) {
2338                     // This is the reentry point for the Next alternative. We expect any code
2339                     // that jumps here to do so with the input position matching that of the
2340                     // PRIOR alteranative, and we will only check input availability if we
2341                     // need to progress it forwards.
2342                     op.m_reentry = label();
2343                     if (alternative-&gt;m_minimumSize &gt; priorAlternative-&gt;m_minimumSize) {
2344                         add32(Imm32(alternative-&gt;m_minimumSize - priorAlternative-&gt;m_minimumSize), index);
2345                         op.m_jumps.append(jumpIfNoAvailableInput());
2346                     } else if (priorAlternative-&gt;m_minimumSize &gt; alternative-&gt;m_minimumSize)
2347                         sub32(Imm32(priorAlternative-&gt;m_minimumSize - alternative-&gt;m_minimumSize), index);
2348                 } else if (op.m_nextOp == notFound) {
2349                     // This is the reentry point for the End of &#39;once through&#39; alternatives,
2350                     // jumped to when the last alternative fails to match.
2351                     op.m_reentry = label();
2352                     sub32(Imm32(priorAlternative-&gt;m_minimumSize), index);
2353                 }
2354 
2355                 if (op.m_op == OpBodyAlternativeNext)
2356                     m_checkedOffset += alternative-&gt;m_minimumSize;
2357                 m_checkedOffset -= priorAlternative-&gt;m_minimumSize;
2358                 break;
2359             }
2360 
2361             // OpSimpleNestedAlternativeBegin/Next/End
2362             // OpNestedAlternativeBegin/Next/End
2363             //
2364             // These nodes are used to handle sets of alternatives that are nested within
2365             // subpatterns and parenthetical assertions. The &#39;simple&#39; forms are used where
2366             // we do not need to be able to backtrack back into any alternative other than
2367             // the last, the normal forms allow backtracking into any alternative.
2368             //
2369             // Each Begin/Next node is responsible for planting an input check to ensure
2370             // sufficient input is available on entry. Next nodes additionally need to
2371             // jump to the end - Next nodes use the End node&#39;s m_jumps list to hold this
2372             // set of jumps.
2373             //
2374             // In the non-simple forms, successful alternative matches must store a
2375             // &#39;return address&#39; using a DataLabelPtr, used to store the address to jump
2376             // to when backtracking, to get to the code for the appropriate alternative.
2377             case OpSimpleNestedAlternativeBegin:
2378             case OpNestedAlternativeBegin: {
2379                 PatternTerm* term = op.m_term;
2380                 PatternAlternative* alternative = op.m_alternative;
2381                 PatternDisjunction* disjunction = term-&gt;parentheses.disjunction;
2382 
2383                 // Calculate how much input we need to check for, and if non-zero check.
2384                 op.m_checkAdjust = Checked&lt;unsigned&gt;(alternative-&gt;m_minimumSize);
2385                 if ((term-&gt;quantityType == QuantifierFixedCount) &amp;&amp; (term-&gt;type != PatternTerm::TypeParentheticalAssertion))
2386                     op.m_checkAdjust -= disjunction-&gt;m_minimumSize;
2387                 if (op.m_checkAdjust)
2388                     op.m_jumps.append(jumpIfNoAvailableInput(op.m_checkAdjust.unsafeGet()));
2389 
2390                 m_checkedOffset += op.m_checkAdjust;
2391                 break;
2392             }
2393             case OpSimpleNestedAlternativeNext:
2394             case OpNestedAlternativeNext: {
2395                 PatternTerm* term = op.m_term;
2396                 PatternAlternative* alternative = op.m_alternative;
2397                 PatternDisjunction* disjunction = term-&gt;parentheses.disjunction;
2398 
2399                 // In the non-simple case, store a &#39;return address&#39; so we can backtrack correctly.
2400                 if (op.m_op == OpNestedAlternativeNext) {
2401                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2402                     op.m_returnAddress = storeToFrameWithPatch(parenthesesFrameLocation + BackTrackInfoParentheses::returnAddressIndex());
2403                 }
2404 
2405                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !m_ops[op.m_previousOp].m_alternative-&gt;m_minimumSize) {
2406                     // If the previous alternative matched without consuming characters then
2407                     // backtrack to try to match while consumming some input.
2408                     op.m_zeroLengthMatch = branch32(Equal, index, Address(stackPointerRegister, term-&gt;frameLocation * sizeof(void*)));
2409                 }
2410 
2411                 // If we reach here then the last alternative has matched - jump to the
2412                 // End node, to skip over any further alternatives.
2413                 //
2414                 // FIXME: this is logically O(N^2) (though N can be expected to be very
2415                 // small). We could avoid this either by adding an extra jump to the JIT
2416                 // data structures, or by making backtracking code that jumps to Next
2417                 // alternatives are responsible for checking that input is available (if
2418                 // we didn&#39;t need to plant the input checks, then m_jumps would be free).
2419                 YarrOp* endOp = &amp;m_ops[op.m_nextOp];
2420                 while (endOp-&gt;m_nextOp != notFound) {
2421                     ASSERT(endOp-&gt;m_op == OpSimpleNestedAlternativeNext || endOp-&gt;m_op == OpNestedAlternativeNext);
2422                     endOp = &amp;m_ops[endOp-&gt;m_nextOp];
2423                 }
2424                 ASSERT(endOp-&gt;m_op == OpSimpleNestedAlternativeEnd || endOp-&gt;m_op == OpNestedAlternativeEnd);
2425                 endOp-&gt;m_jumps.append(jump());
2426 
2427                 // This is the entry point for the next alternative.
2428                 op.m_reentry = label();
2429 
2430                 // Calculate how much input we need to check for, and if non-zero check.
2431                 op.m_checkAdjust = alternative-&gt;m_minimumSize;
2432                 if ((term-&gt;quantityType == QuantifierFixedCount) &amp;&amp; (term-&gt;type != PatternTerm::TypeParentheticalAssertion))
2433                     op.m_checkAdjust -= disjunction-&gt;m_minimumSize;
2434                 if (op.m_checkAdjust)
2435                     op.m_jumps.append(jumpIfNoAvailableInput(op.m_checkAdjust.unsafeGet()));
2436 
2437                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
2438                 m_checkedOffset -= lastOp.m_checkAdjust;
2439                 m_checkedOffset += op.m_checkAdjust;
2440                 break;
2441             }
2442             case OpSimpleNestedAlternativeEnd:
2443             case OpNestedAlternativeEnd: {
2444                 PatternTerm* term = op.m_term;
2445 
2446                 // In the non-simple case, store a &#39;return address&#39; so we can backtrack correctly.
2447                 if (op.m_op == OpNestedAlternativeEnd) {
2448                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2449                     op.m_returnAddress = storeToFrameWithPatch(parenthesesFrameLocation + BackTrackInfoParentheses::returnAddressIndex());
2450                 }
2451 
2452                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !m_ops[op.m_previousOp].m_alternative-&gt;m_minimumSize) {
2453                     // If the previous alternative matched without consuming characters then
2454                     // backtrack to try to match while consumming some input.
2455                     op.m_zeroLengthMatch = branch32(Equal, index, Address(stackPointerRegister, term-&gt;frameLocation * sizeof(void*)));
2456                 }
2457 
2458                 // If this set of alternatives contains more than one alternative,
2459                 // then the Next nodes will have planted jumps to the End, and added
2460                 // them to this node&#39;s m_jumps list.
2461                 op.m_jumps.link(this);
2462                 op.m_jumps.clear();
2463 
2464                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
2465                 m_checkedOffset -= lastOp.m_checkAdjust;
2466                 break;
2467             }
2468 
2469             // OpParenthesesSubpatternOnceBegin/End
2470             //
2471             // These nodes support (optionally) capturing subpatterns, that have a
2472             // quantity count of 1 (this covers fixed once, and ?/?? quantifiers).
2473             case OpParenthesesSubpatternOnceBegin: {
2474                 PatternTerm* term = op.m_term;
2475                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2476                 const RegisterID indexTemporary = regT0;
2477                 ASSERT(term-&gt;quantityMaxCount == 1);
2478 
2479                 // Upon entry to a Greedy quantified set of parenthese store the index.
2480                 // We&#39;ll use this for two purposes:
2481                 //  - To indicate which iteration we are on of mathing the remainder of
2482                 //    the expression after the parentheses - the first, including the
2483                 //    match within the parentheses, or the second having skipped over them.
2484                 //  - To check for empty matches, which must be rejected.
2485                 //
2486                 // At the head of a NonGreedy set of parentheses we&#39;ll immediately set the
2487                 // value on the stack to -1 (indicating a match skipping the subpattern),
2488                 // and plant a jump to the end. We&#39;ll also plant a label to backtrack to
2489                 // to reenter the subpattern later, with a store to set up index on the
2490                 // second iteration.
2491                 //
2492                 // FIXME: for capturing parens, could use the index in the capture array?
2493                 if (term-&gt;quantityType == QuantifierGreedy)
2494                     storeToFrame(index, parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex());
2495                 else if (term-&gt;quantityType == QuantifierNonGreedy) {
2496                     storeToFrame(TrustedImm32(-1), parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex());
2497                     op.m_jumps.append(jump());
2498                     op.m_reentry = label();
2499                     storeToFrame(index, parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex());
2500                 }
2501 
2502                 // If the parenthese are capturing, store the starting index value to the
2503                 // captures array, offsetting as necessary.
2504                 //
2505                 // FIXME: could avoid offsetting this value in JIT code, apply
2506                 // offsets only afterwards, at the point the results array is
2507                 // being accessed.
2508                 if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) {
2509                     unsigned inputOffset = (m_checkedOffset - term-&gt;inputPosition).unsafeGet();
2510                     if (term-&gt;quantityType == QuantifierFixedCount)
2511                         inputOffset += term-&gt;parentheses.disjunction-&gt;m_minimumSize;
2512                     if (inputOffset) {
2513                         move(index, indexTemporary);
2514                         sub32(Imm32(inputOffset), indexTemporary);
2515                         setSubpatternStart(indexTemporary, term-&gt;parentheses.subpatternId);
2516                     } else
2517                         setSubpatternStart(index, term-&gt;parentheses.subpatternId);
2518                 }
2519                 break;
2520             }
2521             case OpParenthesesSubpatternOnceEnd: {
2522                 PatternTerm* term = op.m_term;
2523                 const RegisterID indexTemporary = regT0;
2524                 ASSERT(term-&gt;quantityMaxCount == 1);
2525 
2526                 // If the nested alternative matched without consuming any characters, punt this back to the interpreter.
2527                 // FIXME: &lt;https://bugs.webkit.org/show_bug.cgi?id=200786&gt; Add ability for the YARR JIT to properly
2528                 // handle nested expressions that can match without consuming characters
2529                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !term-&gt;parentheses.disjunction-&gt;m_minimumSize)
2530                     m_abortExecution.append(branch32(Equal, index, Address(stackPointerRegister, term-&gt;frameLocation * sizeof(void*))));
2531 
2532                 // If the parenthese are capturing, store the ending index value to the
2533                 // captures array, offsetting as necessary.
2534                 //
2535                 // FIXME: could avoid offsetting this value in JIT code, apply
2536                 // offsets only afterwards, at the point the results array is
2537                 // being accessed.
2538                 if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) {
2539                     unsigned inputOffset = (m_checkedOffset - term-&gt;inputPosition).unsafeGet();
2540                     if (inputOffset) {
2541                         move(index, indexTemporary);
2542                         sub32(Imm32(inputOffset), indexTemporary);
2543                         setSubpatternEnd(indexTemporary, term-&gt;parentheses.subpatternId);
2544                     } else
2545                         setSubpatternEnd(index, term-&gt;parentheses.subpatternId);
2546                 }
2547 
2548                 // If the parentheses are quantified Greedy then add a label to jump back
2549                 // to if we get a failed match from after the parentheses. For NonGreedy
2550                 // parentheses, link the jump from before the subpattern to here.
2551                 if (term-&gt;quantityType == QuantifierGreedy)
2552                     op.m_reentry = label();
2553                 else if (term-&gt;quantityType == QuantifierNonGreedy) {
2554                     YarrOp&amp; beginOp = m_ops[op.m_previousOp];
2555                     beginOp.m_jumps.link(this);
2556                 }
2557                 break;
2558             }
2559 
2560             // OpParenthesesSubpatternTerminalBegin/End
2561             case OpParenthesesSubpatternTerminalBegin: {
2562                 PatternTerm* term = op.m_term;
2563                 ASSERT(term-&gt;quantityType == QuantifierGreedy);
2564                 ASSERT(term-&gt;quantityMaxCount == quantifyInfinite);
2565                 ASSERT(!term-&gt;capture());
2566 
2567                 // Upon entry set a label to loop back to.
2568                 op.m_reentry = label();
2569 
2570                 // Store the start index of the current match; we need to reject zero
2571                 // length matches.
2572                 storeToFrame(index, term-&gt;frameLocation + BackTrackInfoParenthesesTerminal::beginIndex());
2573                 break;
2574             }
2575             case OpParenthesesSubpatternTerminalEnd: {
2576                 YarrOp&amp; beginOp = m_ops[op.m_previousOp];
2577                 PatternTerm* term = op.m_term;
2578 
2579                 // If the nested alternative matched without consuming any characters, punt this back to the interpreter.
2580                 // FIXME: &lt;https://bugs.webkit.org/show_bug.cgi?id=200786&gt; Add ability for the YARR JIT to properly
2581                 // handle nested expressions that can match without consuming characters
2582                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !term-&gt;parentheses.disjunction-&gt;m_minimumSize)
2583                     m_abortExecution.append(branch32(Equal, index, Address(stackPointerRegister, term-&gt;frameLocation * sizeof(void*))));
2584 
2585                 // We know that the match is non-zero, we can accept it and
2586                 // loop back up to the head of the subpattern.
2587                 jump(beginOp.m_reentry);
2588 
2589                 // This is the entry point to jump to when we stop matching - we will
2590                 // do so once the subpattern cannot match any more.
2591                 op.m_reentry = label();
2592                 break;
2593             }
2594 
2595             // OpParenthesesSubpatternBegin/End
2596             //
2597             // These nodes support generic subpatterns.
2598             case OpParenthesesSubpatternBegin: {
2599 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
2600                 PatternTerm* term = op.m_term;
2601                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2602 
2603                 // Upon entry to a Greedy quantified set of parenthese store the index.
2604                 // We&#39;ll use this for two purposes:
2605                 //  - To indicate which iteration we are on of mathing the remainder of
2606                 //    the expression after the parentheses - the first, including the
2607                 //    match within the parentheses, or the second having skipped over them.
2608                 //  - To check for empty matches, which must be rejected.
2609                 //
2610                 // At the head of a NonGreedy set of parentheses we&#39;ll immediately set &#39;begin&#39;
2611                 // in the backtrack info to -1 (indicating a match skipping the subpattern),
2612                 // and plant a jump to the end. We&#39;ll also plant a label to backtrack to
2613                 // to reenter the subpattern later, with a store to set &#39;begin&#39; to current index
2614                 // on the second iteration.
2615                 //
2616                 // FIXME: for capturing parens, could use the index in the capture array?
2617                 if (term-&gt;quantityType == QuantifierGreedy || term-&gt;quantityType == QuantifierNonGreedy) {
2618                     storeToFrame(TrustedImm32(0), parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex());
2619                     storeToFrame(TrustedImmPtr(nullptr), parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex());
2620 
2621                     if (term-&gt;quantityType == QuantifierNonGreedy) {
2622                         storeToFrame(TrustedImm32(-1), parenthesesFrameLocation + BackTrackInfoParentheses::beginIndex());
2623                         op.m_jumps.append(jump());
2624                     }
2625 
2626                     op.m_reentry = label();
2627                     RegisterID currParenContextReg = regT0;
2628                     RegisterID newParenContextReg = regT1;
2629 
2630                     loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex(), currParenContextReg);
2631                     allocateParenContext(newParenContextReg);
2632                     storePtr(currParenContextReg, newParenContextReg);
2633                     storeToFrame(newParenContextReg, parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex());
2634                     saveParenContext(newParenContextReg, regT2, term-&gt;parentheses.subpatternId, term-&gt;parentheses.lastSubpatternId, parenthesesFrameLocation);
2635                     storeToFrame(index, parenthesesFrameLocation + BackTrackInfoParentheses::beginIndex());
2636                 }
2637 
2638                 // If the parenthese are capturing, store the starting index value to the
2639                 // captures array, offsetting as necessary.
2640                 //
2641                 // FIXME: could avoid offsetting this value in JIT code, apply
2642                 // offsets only afterwards, at the point the results array is
2643                 // being accessed.
2644                 if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) {
2645                     const RegisterID indexTemporary = regT0;
2646                     unsigned inputOffset = (m_checkedOffset - term-&gt;inputPosition).unsafeGet();
2647                     if (term-&gt;quantityType == QuantifierFixedCount)
2648                         inputOffset += term-&gt;parentheses.disjunction-&gt;m_minimumSize;
2649                     if (inputOffset) {
2650                         move(index, indexTemporary);
2651                         sub32(Imm32(inputOffset), indexTemporary);
2652                         setSubpatternStart(indexTemporary, term-&gt;parentheses.subpatternId);
2653                     } else
2654                         setSubpatternStart(index, term-&gt;parentheses.subpatternId);
2655                 }
2656 #else // !YARR_JIT_ALL_PARENS_EXPRESSIONS
2657                 RELEASE_ASSERT_NOT_REACHED();
2658 #endif
2659                 break;
2660             }
2661             case OpParenthesesSubpatternEnd: {
2662 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
2663                 PatternTerm* term = op.m_term;
2664                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2665 
2666                 // If the nested alternative matched without consuming any characters, punt this back to the interpreter.
2667                 // FIXME: &lt;https://bugs.webkit.org/show_bug.cgi?id=200786&gt; Add ability for the YARR JIT to properly
2668                 // handle nested expressions that can match without consuming characters
2669                 if (term-&gt;quantityType != QuantifierFixedCount &amp;&amp; !term-&gt;parentheses.disjunction-&gt;m_minimumSize)
2670                     m_abortExecution.append(branch32(Equal, index, Address(stackPointerRegister, parenthesesFrameLocation * sizeof(void*))));
2671 
2672                 const RegisterID countTemporary = regT1;
2673 
2674                 YarrOp&amp; beginOp = m_ops[op.m_previousOp];
2675                 loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex(), countTemporary);
2676                 add32(TrustedImm32(1), countTemporary);
2677                 storeToFrame(countTemporary, parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex());
2678 
2679                 // If the parenthese are capturing, store the ending index value to the
2680                 // captures array, offsetting as necessary.
2681                 //
2682                 // FIXME: could avoid offsetting this value in JIT code, apply
2683                 // offsets only afterwards, at the point the results array is
2684                 // being accessed.
2685                 if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) {
2686                     const RegisterID indexTemporary = regT0;
2687 
2688                     unsigned inputOffset = (m_checkedOffset - term-&gt;inputPosition).unsafeGet();
2689                     if (inputOffset) {
2690                         move(index, indexTemporary);
2691                         sub32(Imm32(inputOffset), indexTemporary);
2692                         setSubpatternEnd(indexTemporary, term-&gt;parentheses.subpatternId);
2693                     } else
2694                         setSubpatternEnd(index, term-&gt;parentheses.subpatternId);
2695                 }
2696 
2697                 // If the parentheses are quantified Greedy then add a label to jump back
2698                 // to if we get a failed match from after the parentheses. For NonGreedy
2699                 // parentheses, link the jump from before the subpattern to here.
2700                 if (term-&gt;quantityType == QuantifierGreedy) {
2701                     if (term-&gt;quantityMaxCount != quantifyInfinite)
2702                         branch32(Below, countTemporary, Imm32(term-&gt;quantityMaxCount.unsafeGet())).linkTo(beginOp.m_reentry, this);
2703                     else
2704                         jump(beginOp.m_reentry);
2705 
2706                     op.m_reentry = label();
2707                 } else if (term-&gt;quantityType == QuantifierNonGreedy) {
2708                     YarrOp&amp; beginOp = m_ops[op.m_previousOp];
2709                     beginOp.m_jumps.link(this);
2710                     op.m_reentry = label();
2711                 }
2712 #else // !YARR_JIT_ALL_PARENS_EXPRESSIONS
2713                 RELEASE_ASSERT_NOT_REACHED();
2714 #endif
2715                 break;
2716             }
2717 
2718             // OpParentheticalAssertionBegin/End
2719             case OpParentheticalAssertionBegin: {
2720                 PatternTerm* term = op.m_term;
2721 
2722                 // Store the current index - assertions should not update index, so
2723                 // we will need to restore it upon a successful match.
2724                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2725                 storeToFrame(index, parenthesesFrameLocation + BackTrackInfoParentheticalAssertion::beginIndex());
2726 
2727                 // Check
2728                 op.m_checkAdjust = m_checkedOffset - term-&gt;inputPosition;
2729                 if (op.m_checkAdjust)
2730                     sub32(Imm32(op.m_checkAdjust.unsafeGet()), index);
2731 
2732                 m_checkedOffset -= op.m_checkAdjust;
2733                 break;
2734             }
2735             case OpParentheticalAssertionEnd: {
2736                 PatternTerm* term = op.m_term;
2737 
2738                 // Restore the input index value.
2739                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
2740                 loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheticalAssertion::beginIndex(), index);
2741 
2742                 // If inverted, a successful match of the assertion must be treated
2743                 // as a failure, so jump to backtracking.
2744                 if (term-&gt;invert()) {
2745                     op.m_jumps.append(jump());
2746                     op.m_reentry = label();
2747                 }
2748 
2749                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
2750                 m_checkedOffset += lastOp.m_checkAdjust;
2751                 break;
2752             }
2753 
2754             case OpMatchFailed:
2755                 removeCallFrame();
2756                 generateFailReturn();
2757                 break;
2758             }
2759 
2760             ++opIndex;
2761         } while (opIndex &lt; m_ops.size());
2762     }
2763 
2764     void backtrack()
2765     {
2766         // Backwards generate the backtracking code.
2767         size_t opIndex = m_ops.size();
2768         ASSERT(opIndex);
2769 
2770         do {
2771             --opIndex;
2772 
2773             if (m_disassembler)
2774                 m_disassembler-&gt;setForBacktrack(opIndex, label());
2775 
2776             YarrOp&amp; op = m_ops[opIndex];
2777             switch (op.m_op) {
2778 
2779             case OpTerm:
2780                 backtrackTerm(opIndex);
2781                 break;
2782 
2783             // OpBodyAlternativeBegin/Next/End
2784             //
2785             // For each Begin/Next node representing an alternative, we need to decide what to do
2786             // in two circumstances:
2787             //  - If we backtrack back into this node, from within the alternative.
2788             //  - If the input check at the head of the alternative fails (if this exists).
2789             //
2790             // We treat these two cases differently since in the former case we have slightly
2791             // more information - since we are backtracking out of a prior alternative we know
2792             // that at least enough input was available to run it. For example, given the regular
2793             // expression /a|b/, if we backtrack out of the first alternative (a failed pattern
2794             // character match of &#39;a&#39;), then we need not perform an additional input availability
2795             // check before running the second alternative.
2796             //
2797             // Backtracking required differs for the last alternative, which in the case of the
2798             // repeating set of alternatives must loop. The code generated for the last alternative
2799             // will also be used to handle all input check failures from any prior alternatives -
2800             // these require similar functionality, in seeking the next available alternative for
2801             // which there is sufficient input.
2802             //
2803             // Since backtracking of all other alternatives simply requires us to link backtracks
2804             // to the reentry point for the subsequent alternative, we will only be generating any
2805             // code when backtracking the last alternative.
2806             case OpBodyAlternativeBegin:
2807             case OpBodyAlternativeNext: {
2808                 PatternAlternative* alternative = op.m_alternative;
2809 
2810                 if (op.m_op == OpBodyAlternativeNext) {
2811                     PatternAlternative* priorAlternative = m_ops[op.m_previousOp].m_alternative;
2812                     m_checkedOffset += priorAlternative-&gt;m_minimumSize;
2813                 }
2814                 m_checkedOffset -= alternative-&gt;m_minimumSize;
2815 
2816                 // Is this the last alternative? If not, then if we backtrack to this point we just
2817                 // need to jump to try to match the next alternative.
2818                 if (m_ops[op.m_nextOp].m_op != OpBodyAlternativeEnd) {
2819                     m_backtrackingState.linkTo(m_ops[op.m_nextOp].m_reentry, this);
2820                     break;
2821                 }
2822                 YarrOp&amp; endOp = m_ops[op.m_nextOp];
2823 
2824                 YarrOp* beginOp = &amp;op;
2825                 while (beginOp-&gt;m_op != OpBodyAlternativeBegin) {
2826                     ASSERT(beginOp-&gt;m_op == OpBodyAlternativeNext);
2827                     beginOp = &amp;m_ops[beginOp-&gt;m_previousOp];
2828                 }
2829 
2830                 bool onceThrough = endOp.m_nextOp == notFound;
2831 
2832                 JumpList lastStickyAlternativeFailures;
2833 
2834                 // First, generate code to handle cases where we backtrack out of an attempted match
2835                 // of the last alternative. If this is a &#39;once through&#39; set of alternatives then we
2836                 // have nothing to do - link this straight through to the End.
2837                 if (onceThrough)
2838                     m_backtrackingState.linkTo(endOp.m_reentry, this);
2839                 else {
2840                     // If we don&#39;t need to move the input poistion, and the pattern has a fixed size
2841                     // (in which case we omit the store of the start index until the pattern has matched)
2842                     // then we can just link the backtrack out of the last alternative straight to the
2843                     // head of the first alternative.
2844                     if (m_pattern.m_body-&gt;m_hasFixedSize
2845                         &amp;&amp; (alternative-&gt;m_minimumSize &gt; beginOp-&gt;m_alternative-&gt;m_minimumSize)
2846                         &amp;&amp; (alternative-&gt;m_minimumSize - beginOp-&gt;m_alternative-&gt;m_minimumSize == 1))
2847                         m_backtrackingState.linkTo(beginOp-&gt;m_reentry, this);
2848                     else if (m_pattern.sticky() &amp;&amp; m_ops[op.m_nextOp].m_op == OpBodyAlternativeEnd) {
2849                         // It is a sticky pattern and the last alternative failed, jump to the end.
2850                         m_backtrackingState.takeBacktracksToJumpList(lastStickyAlternativeFailures, this);
2851                     } else {
2852                         // We need to generate a trampoline of code to execute before looping back
2853                         // around to the first alternative.
2854                         m_backtrackingState.link(this);
2855 
2856                         // No need to advance and retry for a sticky pattern.
2857                         if (!m_pattern.sticky()) {
2858                             // If the pattern size is not fixed, then store the start index for use if we match.
2859                             if (!m_pattern.m_body-&gt;m_hasFixedSize) {
2860                                 if (alternative-&gt;m_minimumSize == 1)
2861                                     setMatchStart(index);
2862                                 else {
2863                                     move(index, regT0);
2864                                     if (alternative-&gt;m_minimumSize)
2865                                         sub32(Imm32(alternative-&gt;m_minimumSize - 1), regT0);
2866                                     else
2867                                         add32(TrustedImm32(1), regT0);
2868                                     setMatchStart(regT0);
2869                                 }
2870                             }
2871 
2872                             // Generate code to loop. Check whether the last alternative is longer than the
2873                             // first (e.g. /a|xy/ or /a|xyz/).
2874                             if (alternative-&gt;m_minimumSize &gt; beginOp-&gt;m_alternative-&gt;m_minimumSize) {
2875                                 // We want to loop, and increment input position. If the delta is 1, it is
2876                                 // already correctly incremented, if more than one then decrement as appropriate.
2877                                 unsigned delta = alternative-&gt;m_minimumSize - beginOp-&gt;m_alternative-&gt;m_minimumSize;
2878                                 ASSERT(delta);
2879                                 if (delta != 1)
2880                                     sub32(Imm32(delta - 1), index);
2881                                 jump(beginOp-&gt;m_reentry);
2882                             } else {
2883                                 // If the first alternative has minimum size 0xFFFFFFFFu, then there cannot
2884                                 // be sufficent input available to handle this, so just fall through.
2885                                 unsigned delta = beginOp-&gt;m_alternative-&gt;m_minimumSize - alternative-&gt;m_minimumSize;
2886                                 if (delta != 0xFFFFFFFFu) {
2887                                     // We need to check input because we are incrementing the input.
2888                                     add32(Imm32(delta + 1), index);
2889                                     checkInput().linkTo(beginOp-&gt;m_reentry, this);
2890                                 }
2891                             }
2892                         }
2893                     }
2894                 }
2895 
2896                 // We can reach this point in the code in two ways:
2897                 //  - Fallthrough from the code above (a repeating alternative backtracked out of its
2898                 //    last alternative, and did not have sufficent input to run the first).
2899                 //  - We will loop back up to the following label when a repeating alternative loops,
2900                 //    following a failed input check.
2901                 //
2902                 // Either way, we have just failed the input check for the first alternative.
2903                 Label firstInputCheckFailed(this);
2904 
2905                 // Generate code to handle input check failures from alternatives except the last.
2906                 // prevOp is the alternative we&#39;re handling a bail out from (initially Begin), and
2907                 // nextOp is the alternative we will be attempting to reenter into.
2908                 //
2909                 // We will link input check failures from the forwards matching path back to the code
2910                 // that can handle them.
2911                 YarrOp* prevOp = beginOp;
2912                 YarrOp* nextOp = &amp;m_ops[beginOp-&gt;m_nextOp];
2913                 while (nextOp-&gt;m_op != OpBodyAlternativeEnd) {
2914                     prevOp-&gt;m_jumps.link(this);
2915 
2916                     // We only get here if an input check fails, it is only worth checking again
2917                     // if the next alternative has a minimum size less than the last.
2918                     if (prevOp-&gt;m_alternative-&gt;m_minimumSize &gt; nextOp-&gt;m_alternative-&gt;m_minimumSize) {
2919                         // FIXME: if we added an extra label to YarrOp, we could avoid needing to
2920                         // subtract delta back out, and reduce this code. Should performance test
2921                         // the benefit of this.
2922                         unsigned delta = prevOp-&gt;m_alternative-&gt;m_minimumSize - nextOp-&gt;m_alternative-&gt;m_minimumSize;
2923                         sub32(Imm32(delta), index);
2924                         Jump fail = jumpIfNoAvailableInput();
2925                         add32(Imm32(delta), index);
2926                         jump(nextOp-&gt;m_reentry);
2927                         fail.link(this);
2928                     } else if (prevOp-&gt;m_alternative-&gt;m_minimumSize &lt; nextOp-&gt;m_alternative-&gt;m_minimumSize)
2929                         add32(Imm32(nextOp-&gt;m_alternative-&gt;m_minimumSize - prevOp-&gt;m_alternative-&gt;m_minimumSize), index);
2930                     prevOp = nextOp;
2931                     nextOp = &amp;m_ops[nextOp-&gt;m_nextOp];
2932                 }
2933 
2934                 // We fall through to here if there is insufficient input to run the last alternative.
2935 
2936                 // If there is insufficient input to run the last alternative, then for &#39;once through&#39;
2937                 // alternatives we are done - just jump back up into the forwards matching path at the End.
2938                 if (onceThrough) {
2939                     op.m_jumps.linkTo(endOp.m_reentry, this);
2940                     jump(endOp.m_reentry);
2941                     break;
2942                 }
2943 
2944                 // For repeating alternatives, link any input check failure from the last alternative to
2945                 // this point.
2946                 op.m_jumps.link(this);
2947 
2948                 bool needsToUpdateMatchStart = !m_pattern.m_body-&gt;m_hasFixedSize;
2949 
2950                 // Check for cases where input position is already incremented by 1 for the last
2951                 // alternative (this is particularly useful where the minimum size of the body
2952                 // disjunction is 0, e.g. /a*|b/).
2953                 if (needsToUpdateMatchStart &amp;&amp; alternative-&gt;m_minimumSize == 1) {
2954                     // index is already incremented by 1, so just store it now!
2955                     setMatchStart(index);
2956                     needsToUpdateMatchStart = false;
2957                 }
2958 
2959                 if (!m_pattern.sticky()) {
2960                     // Check whether there is sufficient input to loop. Increment the input position by
2961                     // one, and check. Also add in the minimum disjunction size before checking - there
2962                     // is no point in looping if we&#39;re just going to fail all the input checks around
2963                     // the next iteration.
2964                     ASSERT(alternative-&gt;m_minimumSize &gt;= m_pattern.m_body-&gt;m_minimumSize);
2965                     if (alternative-&gt;m_minimumSize == m_pattern.m_body-&gt;m_minimumSize) {
2966                         // If the last alternative had the same minimum size as the disjunction,
2967                         // just simply increment input pos by 1, no adjustment based on minimum size.
2968                         add32(TrustedImm32(1), index);
2969                     } else {
2970                         // If the minumum for the last alternative was one greater than than that
2971                         // for the disjunction, we&#39;re already progressed by 1, nothing to do!
2972                         unsigned delta = (alternative-&gt;m_minimumSize - m_pattern.m_body-&gt;m_minimumSize) - 1;
2973                         if (delta)
2974                             sub32(Imm32(delta), index);
2975                     }
2976                     Jump matchFailed = jumpIfNoAvailableInput();
2977 
2978                     if (needsToUpdateMatchStart) {
2979                         if (!m_pattern.m_body-&gt;m_minimumSize)
2980                             setMatchStart(index);
2981                         else {
2982                             move(index, regT0);
2983                             sub32(Imm32(m_pattern.m_body-&gt;m_minimumSize), regT0);
2984                             setMatchStart(regT0);
2985                         }
2986                     }
2987 
2988                     // Calculate how much more input the first alternative requires than the minimum
2989                     // for the body as a whole. If no more is needed then we dont need an additional
2990                     // input check here - jump straight back up to the start of the first alternative.
2991                     if (beginOp-&gt;m_alternative-&gt;m_minimumSize == m_pattern.m_body-&gt;m_minimumSize)
2992                         jump(beginOp-&gt;m_reentry);
2993                     else {
2994                         if (beginOp-&gt;m_alternative-&gt;m_minimumSize &gt; m_pattern.m_body-&gt;m_minimumSize)
2995                             add32(Imm32(beginOp-&gt;m_alternative-&gt;m_minimumSize - m_pattern.m_body-&gt;m_minimumSize), index);
2996                         else
2997                             sub32(Imm32(m_pattern.m_body-&gt;m_minimumSize - beginOp-&gt;m_alternative-&gt;m_minimumSize), index);
2998                         checkInput().linkTo(beginOp-&gt;m_reentry, this);
2999                         jump(firstInputCheckFailed);
3000                     }
3001 
3002                     // We jump to here if we iterate to the point that there is insufficient input to
3003                     // run any matches, and need to return a failure state from JIT code.
3004                     matchFailed.link(this);
3005                 }
3006 
3007                 lastStickyAlternativeFailures.link(this);
3008                 removeCallFrame();
3009                 generateFailReturn();
3010                 break;
3011             }
3012             case OpBodyAlternativeEnd: {
3013                 // We should never backtrack back into a body disjunction.
3014                 ASSERT(m_backtrackingState.isEmpty());
3015 
3016                 PatternAlternative* priorAlternative = m_ops[op.m_previousOp].m_alternative;
3017                 m_checkedOffset += priorAlternative-&gt;m_minimumSize;
3018                 break;
3019             }
3020 
3021             // OpSimpleNestedAlternativeBegin/Next/End
3022             // OpNestedAlternativeBegin/Next/End
3023             //
3024             // Generate code for when we backtrack back out of an alternative into
3025             // a Begin or Next node, or when the entry input count check fails. If
3026             // there are more alternatives we need to jump to the next alternative,
3027             // if not we backtrack back out of the current set of parentheses.
3028             //
3029             // In the case of non-simple nested assertions we need to also link the
3030             // &#39;return address&#39; appropriately to backtrack back out into the correct
3031             // alternative.
3032             case OpSimpleNestedAlternativeBegin:
3033             case OpSimpleNestedAlternativeNext:
3034             case OpNestedAlternativeBegin:
3035             case OpNestedAlternativeNext: {
3036                 YarrOp&amp; nextOp = m_ops[op.m_nextOp];
3037                 bool isBegin = op.m_previousOp == notFound;
3038                 bool isLastAlternative = nextOp.m_nextOp == notFound;
3039                 ASSERT(isBegin == (op.m_op == OpSimpleNestedAlternativeBegin || op.m_op == OpNestedAlternativeBegin));
3040                 ASSERT(isLastAlternative == (nextOp.m_op == OpSimpleNestedAlternativeEnd || nextOp.m_op == OpNestedAlternativeEnd));
3041 
3042                 // Treat an input check failure the same as a failed match.
3043                 m_backtrackingState.append(op.m_jumps);
3044 
3045                 // Set the backtracks to jump to the appropriate place. We may need
3046                 // to link the backtracks in one of three different way depending on
3047                 // the type of alternative we are dealing with:
3048                 //  - A single alternative, with no simplings.
3049                 //  - The last alternative of a set of two or more.
3050                 //  - An alternative other than the last of a set of two or more.
3051                 //
3052                 // In the case of a single alternative on its own, we don&#39;t need to
3053                 // jump anywhere - if the alternative fails to match we can just
3054                 // continue to backtrack out of the parentheses without jumping.
3055                 //
3056                 // In the case of the last alternative in a set of more than one, we
3057                 // need to jump to return back out to the beginning. We&#39;ll do so by
3058                 // adding a jump to the End node&#39;s m_jumps list, and linking this
3059                 // when we come to generate the Begin node. For alternatives other
3060                 // than the last, we need to jump to the next alternative.
3061                 //
3062                 // If the alternative had adjusted the input position we must link
3063                 // backtracking to here, correct, and then jump on. If not we can
3064                 // link the backtracks directly to their destination.
3065                 if (op.m_checkAdjust) {
3066                     // Handle the cases where we need to link the backtracks here.
3067                     m_backtrackingState.link(this);
3068                     sub32(Imm32(op.m_checkAdjust.unsafeGet()), index);
3069                     if (!isLastAlternative) {
3070                         // An alternative that is not the last should jump to its successor.
3071                         jump(nextOp.m_reentry);
3072                     } else if (!isBegin) {
3073                         // The last of more than one alternatives must jump back to the beginning.
3074                         nextOp.m_jumps.append(jump());
3075                     } else {
3076                         // A single alternative on its own can fall through.
3077                         m_backtrackingState.fallthrough();
3078                     }
3079                 } else {
3080                     // Handle the cases where we can link the backtracks directly to their destinations.
3081                     if (!isLastAlternative) {
3082                         // An alternative that is not the last should jump to its successor.
3083                         m_backtrackingState.linkTo(nextOp.m_reentry, this);
3084                     } else if (!isBegin) {
3085                         // The last of more than one alternatives must jump back to the beginning.
3086                         m_backtrackingState.takeBacktracksToJumpList(nextOp.m_jumps, this);
3087                     }
3088                     // In the case of a single alternative on its own do nothing - it can fall through.
3089                 }
3090 
3091                 // If there is a backtrack jump from a zero length match link it here.
3092                 if (op.m_zeroLengthMatch.isSet())
3093                     m_backtrackingState.append(op.m_zeroLengthMatch);
3094 
3095                 // At this point we&#39;ve handled the backtracking back into this node.
3096                 // Now link any backtracks that need to jump to here.
3097 
3098                 // For non-simple alternatives, link the alternative&#39;s &#39;return address&#39;
3099                 // so that we backtrack back out into the previous alternative.
3100                 if (op.m_op == OpNestedAlternativeNext)
3101                     m_backtrackingState.append(op.m_returnAddress);
3102 
3103                 // If there is more than one alternative, then the last alternative will
3104                 // have planted a jump to be linked to the end. This jump was added to the
3105                 // End node&#39;s m_jumps list. If we are back at the beginning, link it here.
3106                 if (isBegin) {
3107                     YarrOp* endOp = &amp;m_ops[op.m_nextOp];
3108                     while (endOp-&gt;m_nextOp != notFound) {
3109                         ASSERT(endOp-&gt;m_op == OpSimpleNestedAlternativeNext || endOp-&gt;m_op == OpNestedAlternativeNext);
3110                         endOp = &amp;m_ops[endOp-&gt;m_nextOp];
3111                     }
3112                     ASSERT(endOp-&gt;m_op == OpSimpleNestedAlternativeEnd || endOp-&gt;m_op == OpNestedAlternativeEnd);
3113                     m_backtrackingState.append(endOp-&gt;m_jumps);
3114                 }
3115 
3116                 if (!isBegin) {
3117                     YarrOp&amp; lastOp = m_ops[op.m_previousOp];
3118                     m_checkedOffset += lastOp.m_checkAdjust;
3119                 }
3120                 m_checkedOffset -= op.m_checkAdjust;
3121                 break;
3122             }
3123             case OpSimpleNestedAlternativeEnd:
3124             case OpNestedAlternativeEnd: {
3125                 PatternTerm* term = op.m_term;
3126 
3127                 // If there is a backtrack jump from a zero length match link it here.
3128                 if (op.m_zeroLengthMatch.isSet())
3129                     m_backtrackingState.append(op.m_zeroLengthMatch);
3130 
3131                 // If we backtrack into the end of a simple subpattern do nothing;
3132                 // just continue through into the last alternative. If we backtrack
3133                 // into the end of a non-simple set of alterntives we need to jump
3134                 // to the backtracking return address set up during generation.
3135                 if (op.m_op == OpNestedAlternativeEnd) {
3136                     m_backtrackingState.link(this);
3137 
3138                     // Plant a jump to the return address.
3139                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3140                     loadFromFrameAndJump(parenthesesFrameLocation + BackTrackInfoParentheses::returnAddressIndex());
3141 
3142                     // Link the DataLabelPtr associated with the end of the last
3143                     // alternative to this point.
3144                     m_backtrackingState.append(op.m_returnAddress);
3145                 }
3146 
3147                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
3148                 m_checkedOffset += lastOp.m_checkAdjust;
3149                 break;
3150             }
3151 
3152             // OpParenthesesSubpatternOnceBegin/End
3153             //
3154             // When we are backtracking back out of a capturing subpattern we need
3155             // to clear the start index in the matches output array, to record that
3156             // this subpattern has not been captured.
3157             //
3158             // When backtracking back out of a Greedy quantified subpattern we need
3159             // to catch this, and try running the remainder of the alternative after
3160             // the subpattern again, skipping the parentheses.
3161             //
3162             // Upon backtracking back into a quantified set of parentheses we need to
3163             // check whether we were currently skipping the subpattern. If not, we
3164             // can backtrack into them, if we were we need to either backtrack back
3165             // out of the start of the parentheses, or jump back to the forwards
3166             // matching start, depending of whether the match is Greedy or NonGreedy.
3167             case OpParenthesesSubpatternOnceBegin: {
3168                 PatternTerm* term = op.m_term;
3169                 ASSERT(term-&gt;quantityMaxCount == 1);
3170 
3171                 // We only need to backtrack to this point if capturing or greedy.
3172                 if ((term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns) || term-&gt;quantityType == QuantifierGreedy) {
3173                     m_backtrackingState.link(this);
3174 
3175                     // If capturing, clear the capture (we only need to reset start).
3176                     if (term-&gt;capture() &amp;&amp; compileMode == IncludeSubpatterns)
3177                         clearSubpatternStart(term-&gt;parentheses.subpatternId);
3178 
3179                     // If Greedy, jump to the end.
3180                     if (term-&gt;quantityType == QuantifierGreedy) {
3181                         // Clear the flag in the stackframe indicating we ran through the subpattern.
3182                         unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3183                         storeToFrame(TrustedImm32(-1), parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex());
3184                         // Jump to after the parentheses, skipping the subpattern.
3185                         jump(m_ops[op.m_nextOp].m_reentry);
3186                         // A backtrack from after the parentheses, when skipping the subpattern,
3187                         // will jump back to here.
3188                         op.m_jumps.link(this);
3189                     }
3190 
3191                     m_backtrackingState.fallthrough();
3192                 }
3193                 break;
3194             }
3195             case OpParenthesesSubpatternOnceEnd: {
3196                 PatternTerm* term = op.m_term;
3197 
3198                 if (term-&gt;quantityType != QuantifierFixedCount) {
3199                     m_backtrackingState.link(this);
3200 
3201                     // Check whether we should backtrack back into the parentheses, or if we
3202                     // are currently in a state where we had skipped over the subpattern
3203                     // (in which case the flag value on the stack will be -1).
3204                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3205                     Jump hadSkipped = branch32(Equal, Address(stackPointerRegister, (parenthesesFrameLocation + BackTrackInfoParenthesesOnce::beginIndex()) * sizeof(void*)), TrustedImm32(-1));
3206 
3207                     if (term-&gt;quantityType == QuantifierGreedy) {
3208                         // For Greedy parentheses, we skip after having already tried going
3209                         // through the subpattern, so if we get here we&#39;re done.
3210                         YarrOp&amp; beginOp = m_ops[op.m_previousOp];
3211                         beginOp.m_jumps.append(hadSkipped);
3212                     } else {
3213                         // For NonGreedy parentheses, we try skipping the subpattern first,
3214                         // so if we get here we need to try running through the subpattern
3215                         // next. Jump back to the start of the parentheses in the forwards
3216                         // matching path.
3217                         ASSERT(term-&gt;quantityType == QuantifierNonGreedy);
3218                         YarrOp&amp; beginOp = m_ops[op.m_previousOp];
3219                         hadSkipped.linkTo(beginOp.m_reentry, this);
3220                     }
3221 
3222                     m_backtrackingState.fallthrough();
3223                 }
3224 
3225                 m_backtrackingState.append(op.m_jumps);
3226                 break;
3227             }
3228 
3229             // OpParenthesesSubpatternTerminalBegin/End
3230             //
3231             // Terminal subpatterns will always match - there is nothing after them to
3232             // force a backtrack, and they have a minimum count of 0, and as such will
3233             // always produce an acceptable result.
3234             case OpParenthesesSubpatternTerminalBegin: {
3235                 // We will backtrack to this point once the subpattern cannot match any
3236                 // more. Since no match is accepted as a successful match (we are Greedy
3237                 // quantified with a minimum of zero) jump back to the forwards matching
3238                 // path at the end.
3239                 YarrOp&amp; endOp = m_ops[op.m_nextOp];
3240                 m_backtrackingState.linkTo(endOp.m_reentry, this);
3241                 break;
3242             }
3243             case OpParenthesesSubpatternTerminalEnd:
3244                 // We should never be backtracking to here (hence the &#39;terminal&#39; in the name).
3245                 ASSERT(m_backtrackingState.isEmpty());
3246                 m_backtrackingState.append(op.m_jumps);
3247                 break;
3248 
3249             // OpParenthesesSubpatternBegin/End
3250             //
3251             // When we are backtracking back out of a capturing subpattern we need
3252             // to clear the start index in the matches output array, to record that
3253             // this subpattern has not been captured.
3254             //
3255             // When backtracking back out of a Greedy quantified subpattern we need
3256             // to catch this, and try running the remainder of the alternative after
3257             // the subpattern again, skipping the parentheses.
3258             //
3259             // Upon backtracking back into a quantified set of parentheses we need to
3260             // check whether we were currently skipping the subpattern. If not, we
3261             // can backtrack into them, if we were we need to either backtrack back
3262             // out of the start of the parentheses, or jump back to the forwards
3263             // matching start, depending of whether the match is Greedy or NonGreedy.
3264             case OpParenthesesSubpatternBegin: {
3265 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3266                 PatternTerm* term = op.m_term;
3267                 unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3268 
3269                 if (term-&gt;quantityType != QuantifierFixedCount) {
3270                     m_backtrackingState.link(this);
3271 
3272                     RegisterID currParenContextReg = regT0;
3273                     RegisterID newParenContextReg = regT1;
3274 
3275                     loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex(), currParenContextReg);
3276 
3277                     restoreParenContext(currParenContextReg, regT2, term-&gt;parentheses.subpatternId, term-&gt;parentheses.lastSubpatternId, parenthesesFrameLocation);
3278 
3279                     freeParenContext(currParenContextReg, newParenContextReg);
3280                     storeToFrame(newParenContextReg, parenthesesFrameLocation + BackTrackInfoParentheses::parenContextHeadIndex());
3281 
3282                     const RegisterID countTemporary = regT0;
3283                     loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex(), countTemporary);
3284                     Jump zeroLengthMatch = branchTest32(Zero, countTemporary);
3285 
3286                     sub32(TrustedImm32(1), countTemporary);
3287                     storeToFrame(countTemporary, parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex());
3288 
3289                     jump(m_ops[op.m_nextOp].m_reentry);
3290 
3291                     zeroLengthMatch.link(this);
3292 
3293                     // Clear the flag in the stackframe indicating we didn&#39;t run through the subpattern.
3294                     storeToFrame(TrustedImm32(-1), parenthesesFrameLocation + BackTrackInfoParentheses::beginIndex());
3295 
3296                     if (term-&gt;quantityType == QuantifierGreedy)
3297                         jump(m_ops[op.m_nextOp].m_reentry);
3298 
3299                     // If Greedy, jump to the end.
3300                     if (term-&gt;quantityType == QuantifierGreedy) {
3301                         // A backtrack from after the parentheses, when skipping the subpattern,
3302                         // will jump back to here.
3303                         op.m_jumps.link(this);
3304                     }
3305 
3306                     m_backtrackingState.fallthrough();
3307                 }
3308 #else // !YARR_JIT_ALL_PARENS_EXPRESSIONS
3309                 RELEASE_ASSERT_NOT_REACHED();
3310 #endif
3311                 break;
3312             }
3313             case OpParenthesesSubpatternEnd: {
3314 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3315                 PatternTerm* term = op.m_term;
3316 
3317                 if (term-&gt;quantityType != QuantifierFixedCount) {
3318                     m_backtrackingState.link(this);
3319 
3320                     unsigned parenthesesFrameLocation = term-&gt;frameLocation;
3321 
3322                     if (term-&gt;quantityType == QuantifierGreedy) {
3323                         // Check whether we should backtrack back into the parentheses, or if we
3324                         // are currently in a state where we had skipped over the subpattern
3325                         // (in which case the flag value on the stack will be -1).
3326                         Jump hadSkipped = branch32(Equal, Address(stackPointerRegister, (parenthesesFrameLocation  + BackTrackInfoParentheses::beginIndex()) * sizeof(void*)), TrustedImm32(-1));
3327 
3328                         // For Greedy parentheses, we skip after having already tried going
3329                         // through the subpattern, so if we get here we&#39;re done.
3330                         YarrOp&amp; beginOp = m_ops[op.m_previousOp];
3331                         beginOp.m_jumps.append(hadSkipped);
3332                     } else {
3333                         // For NonGreedy parentheses, we try skipping the subpattern first,
3334                         // so if we get here we need to try running through the subpattern
3335                         // next. Jump back to the start of the parentheses in the forwards
3336                         // matching path.
3337                         ASSERT(term-&gt;quantityType == QuantifierNonGreedy);
3338 
3339                         const RegisterID beginTemporary = regT0;
3340                         const RegisterID countTemporary = regT1;
3341 
3342                         YarrOp&amp; beginOp = m_ops[op.m_previousOp];
3343 
3344                         loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::beginIndex(), beginTemporary);
3345                         branch32(Equal, beginTemporary, TrustedImm32(-1)).linkTo(beginOp.m_reentry, this);
3346 
3347                         JumpList exceededMatchLimit;
3348 
3349                         if (term-&gt;quantityMaxCount != quantifyInfinite) {
3350                             loadFromFrame(parenthesesFrameLocation + BackTrackInfoParentheses::matchAmountIndex(), countTemporary);
3351                             exceededMatchLimit.append(branch32(AboveOrEqual, countTemporary, Imm32(term-&gt;quantityMaxCount.unsafeGet())));
3352                         }
3353 
3354                         branch32(Above, index, beginTemporary).linkTo(beginOp.m_reentry, this);
3355 
3356                         exceededMatchLimit.link(this);
3357                     }
3358 
3359                     m_backtrackingState.fallthrough();
3360                 }
3361 
3362                 m_backtrackingState.append(op.m_jumps);
3363 #else // !YARR_JIT_ALL_PARENS_EXPRESSIONS
3364                 RELEASE_ASSERT_NOT_REACHED();
3365 #endif
3366                 break;
3367             }
3368 
3369             // OpParentheticalAssertionBegin/End
3370             case OpParentheticalAssertionBegin: {
3371                 PatternTerm* term = op.m_term;
3372                 YarrOp&amp; endOp = m_ops[op.m_nextOp];
3373 
3374                 // We need to handle the backtracks upon backtracking back out
3375                 // of a parenthetical assertion if either we need to correct
3376                 // the input index, or the assertion was inverted.
3377                 if (op.m_checkAdjust || term-&gt;invert()) {
3378                      m_backtrackingState.link(this);
3379 
3380                     if (op.m_checkAdjust)
3381                         add32(Imm32(op.m_checkAdjust.unsafeGet()), index);
3382 
3383                     // In an inverted assertion failure to match the subpattern
3384                     // is treated as a successful match - jump to the end of the
3385                     // subpattern. We already have adjusted the input position
3386                     // back to that before the assertion, which is correct.
3387                     if (term-&gt;invert())
3388                         jump(endOp.m_reentry);
3389 
3390                     m_backtrackingState.fallthrough();
3391                 }
3392 
3393                 // The End node&#39;s jump list will contain any backtracks into
3394                 // the end of the assertion. Also, if inverted, we will have
3395                 // added the failure caused by a successful match to this.
3396                 m_backtrackingState.append(endOp.m_jumps);
3397 
3398                 m_checkedOffset += op.m_checkAdjust;
3399                 break;
3400             }
3401             case OpParentheticalAssertionEnd: {
3402                 // FIXME: We should really be clearing any nested subpattern
3403                 // matches on bailing out from after the pattern. Firefox has
3404                 // this bug too (presumably because they use YARR!)
3405 
3406                 // Never backtrack into an assertion; later failures bail to before the begin.
3407                 m_backtrackingState.takeBacktracksToJumpList(op.m_jumps, this);
3408 
3409                 YarrOp&amp; lastOp = m_ops[op.m_previousOp];
3410                 m_checkedOffset -= lastOp.m_checkAdjust;
3411                 break;
3412             }
3413 
3414             case OpMatchFailed:
3415                 break;
3416             }
3417 
3418         } while (opIndex);
3419     }
3420 
3421     // Compilation methods:
3422     // ====================
3423 
3424     // opCompileParenthesesSubpattern
3425     // Emits ops for a subpattern (set of parentheses). These consist
3426     // of a set of alternatives wrapped in an outer set of nodes for
3427     // the parentheses.
3428     // Supported types of parentheses are &#39;Once&#39; (quantityMaxCount == 1),
3429     // &#39;Terminal&#39; (non-capturing parentheses quantified as greedy
3430     // and infinite), and 0 based greedy / non-greedy quantified parentheses.
3431     // Alternatives will use the &#39;Simple&#39; set of ops if either the
3432     // subpattern is terminal (in which case we will never need to
3433     // backtrack), or if the subpattern only contains one alternative.
3434     void opCompileParenthesesSubpattern(PatternTerm* term)
3435     {
3436         YarrOpCode parenthesesBeginOpCode;
3437         YarrOpCode parenthesesEndOpCode;
3438         YarrOpCode alternativeBeginOpCode = OpSimpleNestedAlternativeBegin;
3439         YarrOpCode alternativeNextOpCode = OpSimpleNestedAlternativeNext;
3440         YarrOpCode alternativeEndOpCode = OpSimpleNestedAlternativeEnd;
3441 
3442         if (UNLIKELY(!m_vm-&gt;isSafeToRecurse())) {
3443             m_failureReason = JITFailureReason::ParenthesisNestedTooDeep;
3444             return;
3445         }
3446 
3447         // We can currently only compile quantity 1 subpatterns that are
3448         // not copies. We generate a copy in the case of a range quantifier,
3449         // e.g. /(?:x){3,9}/, or /(?:x)+/ (These are effectively expanded to
3450         // /(?:x){3,3}(?:x){0,6}/ and /(?:x)(?:x)*/ repectively). The problem
3451         // comes where the subpattern is capturing, in which case we would
3452         // need to restore the capture from the first subpattern upon a
3453         // failure in the second.
3454         if (term-&gt;quantityMinCount &amp;&amp; term-&gt;quantityMinCount != term-&gt;quantityMaxCount) {
3455             m_failureReason = JITFailureReason::VariableCountedParenthesisWithNonZeroMinimum;
3456             return;
3457         }
3458 
3459         if (term-&gt;quantityMaxCount == 1 &amp;&amp; !term-&gt;parentheses.isCopy) {
3460             // Select the &#39;Once&#39; nodes.
3461             parenthesesBeginOpCode = OpParenthesesSubpatternOnceBegin;
3462             parenthesesEndOpCode = OpParenthesesSubpatternOnceEnd;
3463 
3464             // If there is more than one alternative we cannot use the &#39;simple&#39; nodes.
3465             if (term-&gt;parentheses.disjunction-&gt;m_alternatives.size() != 1) {
3466                 alternativeBeginOpCode = OpNestedAlternativeBegin;
3467                 alternativeNextOpCode = OpNestedAlternativeNext;
3468                 alternativeEndOpCode = OpNestedAlternativeEnd;
3469             }
3470         } else if (term-&gt;parentheses.isTerminal) {
3471             // Select the &#39;Terminal&#39; nodes.
3472             parenthesesBeginOpCode = OpParenthesesSubpatternTerminalBegin;
3473             parenthesesEndOpCode = OpParenthesesSubpatternTerminalEnd;
3474         } else {
3475 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3476             // We only handle generic parenthesis with non-fixed counts.
3477             if (term-&gt;quantityType == QuantifierFixedCount) {
3478                 // This subpattern is not supported by the JIT.
3479                 m_failureReason = JITFailureReason::FixedCountParenthesizedSubpattern;
3480                 return;
3481             }
3482 
3483             m_containsNestedSubpatterns = true;
3484 
3485             // Select the &#39;Generic&#39; nodes.
3486             parenthesesBeginOpCode = OpParenthesesSubpatternBegin;
3487             parenthesesEndOpCode = OpParenthesesSubpatternEnd;
3488 
3489             // If there is more than one alternative we cannot use the &#39;simple&#39; nodes.
3490             if (term-&gt;parentheses.disjunction-&gt;m_alternatives.size() != 1) {
3491                 alternativeBeginOpCode = OpNestedAlternativeBegin;
3492                 alternativeNextOpCode = OpNestedAlternativeNext;
3493                 alternativeEndOpCode = OpNestedAlternativeEnd;
3494             }
3495 #else
3496             // This subpattern is not supported by the JIT.
3497             m_failureReason = JITFailureReason::ParenthesizedSubpattern;
3498             return;
3499 #endif
3500         }
3501 
3502         size_t parenBegin = m_ops.size();
3503         m_ops.append(parenthesesBeginOpCode);
3504 
3505         m_ops.append(alternativeBeginOpCode);
3506         m_ops.last().m_previousOp = notFound;
3507         m_ops.last().m_term = term;
3508         Vector&lt;std::unique_ptr&lt;PatternAlternative&gt;&gt;&amp; alternatives = term-&gt;parentheses.disjunction-&gt;m_alternatives;
3509         for (unsigned i = 0; i &lt; alternatives.size(); ++i) {
3510             size_t lastOpIndex = m_ops.size() - 1;
3511 
3512             PatternAlternative* nestedAlternative = alternatives[i].get();
3513             opCompileAlternative(nestedAlternative);
3514 
3515             size_t thisOpIndex = m_ops.size();
3516             m_ops.append(YarrOp(alternativeNextOpCode));
3517 
3518             YarrOp&amp; lastOp = m_ops[lastOpIndex];
3519             YarrOp&amp; thisOp = m_ops[thisOpIndex];
3520 
3521             lastOp.m_alternative = nestedAlternative;
3522             lastOp.m_nextOp = thisOpIndex;
3523             thisOp.m_previousOp = lastOpIndex;
3524             thisOp.m_term = term;
3525         }
3526         YarrOp&amp; lastOp = m_ops.last();
3527         ASSERT(lastOp.m_op == alternativeNextOpCode);
3528         lastOp.m_op = alternativeEndOpCode;
3529         lastOp.m_alternative = 0;
3530         lastOp.m_nextOp = notFound;
3531 
3532         size_t parenEnd = m_ops.size();
3533         m_ops.append(parenthesesEndOpCode);
3534 
3535         m_ops[parenBegin].m_term = term;
3536         m_ops[parenBegin].m_previousOp = notFound;
3537         m_ops[parenBegin].m_nextOp = parenEnd;
3538         m_ops[parenEnd].m_term = term;
3539         m_ops[parenEnd].m_previousOp = parenBegin;
3540         m_ops[parenEnd].m_nextOp = notFound;
3541     }
3542 
3543     // opCompileParentheticalAssertion
3544     // Emits ops for a parenthetical assertion. These consist of an
3545     // OpSimpleNestedAlternativeBegin/Next/End set of nodes wrapping
3546     // the alternatives, with these wrapped by an outer pair of
3547     // OpParentheticalAssertionBegin/End nodes.
3548     // We can always use the OpSimpleNestedAlternative nodes in the
3549     // case of parenthetical assertions since these only ever match
3550     // once, and will never backtrack back into the assertion.
3551     void opCompileParentheticalAssertion(PatternTerm* term)
3552     {
3553         if (UNLIKELY(!m_vm-&gt;isSafeToRecurse())) {
3554             m_failureReason = JITFailureReason::ParenthesisNestedTooDeep;
3555             return;
3556         }
3557 
3558         size_t parenBegin = m_ops.size();
3559         m_ops.append(OpParentheticalAssertionBegin);
3560 
3561         m_ops.append(OpSimpleNestedAlternativeBegin);
3562         m_ops.last().m_previousOp = notFound;
3563         m_ops.last().m_term = term;
3564         Vector&lt;std::unique_ptr&lt;PatternAlternative&gt;&gt;&amp; alternatives =  term-&gt;parentheses.disjunction-&gt;m_alternatives;
3565         for (unsigned i = 0; i &lt; alternatives.size(); ++i) {
3566             size_t lastOpIndex = m_ops.size() - 1;
3567 
3568             PatternAlternative* nestedAlternative = alternatives[i].get();
3569             opCompileAlternative(nestedAlternative);
3570 
3571             size_t thisOpIndex = m_ops.size();
3572             m_ops.append(YarrOp(OpSimpleNestedAlternativeNext));
3573 
3574             YarrOp&amp; lastOp = m_ops[lastOpIndex];
3575             YarrOp&amp; thisOp = m_ops[thisOpIndex];
3576 
3577             lastOp.m_alternative = nestedAlternative;
3578             lastOp.m_nextOp = thisOpIndex;
3579             thisOp.m_previousOp = lastOpIndex;
3580             thisOp.m_term = term;
3581         }
3582         YarrOp&amp; lastOp = m_ops.last();
3583         ASSERT(lastOp.m_op == OpSimpleNestedAlternativeNext);
3584         lastOp.m_op = OpSimpleNestedAlternativeEnd;
3585         lastOp.m_alternative = 0;
3586         lastOp.m_nextOp = notFound;
3587 
3588         size_t parenEnd = m_ops.size();
3589         m_ops.append(OpParentheticalAssertionEnd);
3590 
3591         m_ops[parenBegin].m_term = term;
3592         m_ops[parenBegin].m_previousOp = notFound;
3593         m_ops[parenBegin].m_nextOp = parenEnd;
3594         m_ops[parenEnd].m_term = term;
3595         m_ops[parenEnd].m_previousOp = parenBegin;
3596         m_ops[parenEnd].m_nextOp = notFound;
3597     }
3598 
3599     // opCompileAlternative
3600     // Called to emit nodes for all terms in an alternative.
3601     void opCompileAlternative(PatternAlternative* alternative)
3602     {
3603         optimizeAlternative(alternative);
3604 
3605         for (unsigned i = 0; i &lt; alternative-&gt;m_terms.size(); ++i) {
3606             PatternTerm* term = &amp;alternative-&gt;m_terms[i];
3607 
3608             switch (term-&gt;type) {
3609             case PatternTerm::TypeParenthesesSubpattern:
3610                 opCompileParenthesesSubpattern(term);
3611                 break;
3612 
3613             case PatternTerm::TypeParentheticalAssertion:
3614                 opCompileParentheticalAssertion(term);
3615                 break;
3616 
3617             default:
3618                 m_ops.append(term);
3619             }
3620         }
3621     }
3622 
3623     // opCompileBody
3624     // This method compiles the body disjunction of the regular expression.
3625     // The body consists of two sets of alternatives - zero or more &#39;once
3626     // through&#39; (BOL anchored) alternatives, followed by zero or more
3627     // repeated alternatives.
3628     // For each of these two sets of alteratives, if not empty they will be
3629     // wrapped in a set of OpBodyAlternativeBegin/Next/End nodes (with the
3630     // &#39;begin&#39; node referencing the first alternative, and &#39;next&#39; nodes
3631     // referencing any further alternatives. The begin/next/end nodes are
3632     // linked together in a doubly linked list. In the case of repeating
3633     // alternatives, the end node is also linked back to the beginning.
3634     // If no repeating alternatives exist, then a OpMatchFailed node exists
3635     // to return the failing result.
3636     void opCompileBody(PatternDisjunction* disjunction)
3637     {
3638         if (UNLIKELY(!m_vm-&gt;isSafeToRecurse())) {
3639             m_failureReason = JITFailureReason::ParenthesisNestedTooDeep;
3640             return;
3641         }
3642 
3643         Vector&lt;std::unique_ptr&lt;PatternAlternative&gt;&gt;&amp; alternatives = disjunction-&gt;m_alternatives;
3644         size_t currentAlternativeIndex = 0;
3645 
3646         // Emit the &#39;once through&#39; alternatives.
3647         if (alternatives.size() &amp;&amp; alternatives[0]-&gt;onceThrough()) {
3648             m_ops.append(YarrOp(OpBodyAlternativeBegin));
3649             m_ops.last().m_previousOp = notFound;
3650 
3651             do {
3652                 size_t lastOpIndex = m_ops.size() - 1;
3653                 PatternAlternative* alternative = alternatives[currentAlternativeIndex].get();
3654                 opCompileAlternative(alternative);
3655 
3656                 size_t thisOpIndex = m_ops.size();
3657                 m_ops.append(YarrOp(OpBodyAlternativeNext));
3658 
3659                 YarrOp&amp; lastOp = m_ops[lastOpIndex];
3660                 YarrOp&amp; thisOp = m_ops[thisOpIndex];
3661 
3662                 lastOp.m_alternative = alternative;
3663                 lastOp.m_nextOp = thisOpIndex;
3664                 thisOp.m_previousOp = lastOpIndex;
3665 
3666                 ++currentAlternativeIndex;
3667             } while (currentAlternativeIndex &lt; alternatives.size() &amp;&amp; alternatives[currentAlternativeIndex]-&gt;onceThrough());
3668 
3669             YarrOp&amp; lastOp = m_ops.last();
3670 
3671             ASSERT(lastOp.m_op == OpBodyAlternativeNext);
3672             lastOp.m_op = OpBodyAlternativeEnd;
3673             lastOp.m_alternative = 0;
3674             lastOp.m_nextOp = notFound;
3675         }
3676 
3677         if (currentAlternativeIndex == alternatives.size()) {
3678             m_ops.append(YarrOp(OpMatchFailed));
3679             return;
3680         }
3681 
3682         // Emit the repeated alternatives.
3683         size_t repeatLoop = m_ops.size();
3684         m_ops.append(YarrOp(OpBodyAlternativeBegin));
3685         m_ops.last().m_previousOp = notFound;
3686         do {
3687             size_t lastOpIndex = m_ops.size() - 1;
3688             PatternAlternative* alternative = alternatives[currentAlternativeIndex].get();
3689             ASSERT(!alternative-&gt;onceThrough());
3690             opCompileAlternative(alternative);
3691 
3692             size_t thisOpIndex = m_ops.size();
3693             m_ops.append(YarrOp(OpBodyAlternativeNext));
3694 
3695             YarrOp&amp; lastOp = m_ops[lastOpIndex];
3696             YarrOp&amp; thisOp = m_ops[thisOpIndex];
3697 
3698             lastOp.m_alternative = alternative;
3699             lastOp.m_nextOp = thisOpIndex;
3700             thisOp.m_previousOp = lastOpIndex;
3701 
3702             ++currentAlternativeIndex;
3703         } while (currentAlternativeIndex &lt; alternatives.size());
3704         YarrOp&amp; lastOp = m_ops.last();
3705         ASSERT(lastOp.m_op == OpBodyAlternativeNext);
3706         lastOp.m_op = OpBodyAlternativeEnd;
3707         lastOp.m_alternative = 0;
3708         lastOp.m_nextOp = repeatLoop;
3709     }
3710 
3711     void generateTryReadUnicodeCharacterHelper()
3712     {
3713 #ifdef JIT_UNICODE_EXPRESSIONS
3714         if (m_tryReadUnicodeCharacterCalls.isEmpty())
3715             return;
3716 
3717         ASSERT(m_decodeSurrogatePairs);
3718 
3719         m_tryReadUnicodeCharacterEntry = label();
3720 
3721         tagReturnAddress();
3722 
3723         tryReadUnicodeCharImpl(regT0);
3724 
3725         ret();
3726 #endif
3727     }
3728 
3729     void generateEnter()
3730     {
3731 #if CPU(X86_64)
3732         push(X86Registers::ebp);
3733         move(stackPointerRegister, X86Registers::ebp);
3734 
3735         if (m_pattern.m_saveInitialStartValue)
3736             push(X86Registers::ebx);
3737 
3738 #if OS(WINDOWS)
3739         push(X86Registers::edi);
3740 #endif
3741 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3742         if (m_containsNestedSubpatterns) {
3743 #if OS(WINDOWS)
3744             push(X86Registers::esi);
3745 #endif
3746             push(X86Registers::r12);
3747         }
3748 #endif
3749 
3750         if (m_decodeSurrogatePairs) {
3751             push(X86Registers::r13);
3752             push(X86Registers::r14);
3753             push(X86Registers::r15);
3754 
3755             move(TrustedImm32(0xd800), leadingSurrogateTag);
3756         }
3757         // The ABI doesn&#39;t guarantee the upper bits are zero on unsigned arguments, so clear them ourselves.
3758         zeroExtend32ToPtr(index, index);
3759         zeroExtend32ToPtr(length, length);
3760 #if OS(WINDOWS)
3761         if (compileMode == IncludeSubpatterns)
3762             loadPtr(Address(X86Registers::ebp, 6 * sizeof(void*)), output);
3763         // rcx is the pointer to the allocated space for result in x64 Windows.
3764         push(X86Registers::ecx);
3765 #endif
3766 #elif CPU(X86)
3767         push(X86Registers::ebp);
3768         move(stackPointerRegister, X86Registers::ebp);
3769         // TODO: do we need spill registers to fill the output pointer if there are no sub captures?
3770         push(X86Registers::ebx);
3771         push(X86Registers::edi);
3772         push(X86Registers::esi);
3773         // load output into edi (2 = saved ebp + return address).
3774     #if COMPILER(MSVC)
3775         loadPtr(Address(X86Registers::ebp, 2 * sizeof(void*)), input);
3776         loadPtr(Address(X86Registers::ebp, 3 * sizeof(void*)), index);
3777         loadPtr(Address(X86Registers::ebp, 4 * sizeof(void*)), length);
3778         if (compileMode == IncludeSubpatterns)
3779             loadPtr(Address(X86Registers::ebp, 5 * sizeof(void*)), output);
3780     #else
3781         if (compileMode == IncludeSubpatterns)
3782             loadPtr(Address(X86Registers::ebp, 2 * sizeof(void*)), output);
3783     #endif
3784 #elif CPU(ARM64)
3785         tagReturnAddress();
3786         if (m_decodeSurrogatePairs) {
3787             pushPair(framePointerRegister, linkRegister);
3788             move(TrustedImm32(0x10000), supplementaryPlanesBase);
3789             move(TrustedImm32(0xd800), leadingSurrogateTag);
3790             move(TrustedImm32(0xdc00), trailingSurrogateTag);
3791         }
3792 
3793         // The ABI doesn&#39;t guarantee the upper bits are zero on unsigned arguments, so clear them ourselves.
3794         zeroExtend32ToPtr(index, index);
3795         zeroExtend32ToPtr(length, length);
3796 #elif CPU(ARM_THUMB2)
3797         push(ARMRegisters::r4);
3798         push(ARMRegisters::r5);
3799         push(ARMRegisters::r6);
3800         push(ARMRegisters::r8);
3801 #elif CPU(MIPS)
3802         // Do nothing.
3803 #endif
3804 
3805         store8(TrustedImm32(1), &amp;m_vm-&gt;isExecutingInRegExpJIT);
3806     }
3807 
3808     void generateReturn()
3809     {
3810         store8(TrustedImm32(0), &amp;m_vm-&gt;isExecutingInRegExpJIT);
3811 
3812 #if CPU(X86_64)
3813 #if OS(WINDOWS)
3814         // Store the return value in the allocated space pointed by rcx.
3815         pop(X86Registers::ecx);
3816         store64(returnRegister, Address(X86Registers::ecx));
3817         store64(returnRegister2, Address(X86Registers::ecx, sizeof(void*)));
3818         move(X86Registers::ecx, returnRegister);
3819 #endif
3820         if (m_decodeSurrogatePairs) {
3821             pop(X86Registers::r15);
3822             pop(X86Registers::r14);
3823             pop(X86Registers::r13);
3824         }
3825 
3826 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3827         if (m_containsNestedSubpatterns) {
3828             pop(X86Registers::r12);
3829 #if OS(WINDOWS)
3830             pop(X86Registers::esi);
3831 #endif
3832         }
3833 #endif
3834 #if OS(WINDOWS)
3835         pop(X86Registers::edi);
3836 #endif
3837 
3838         if (m_pattern.m_saveInitialStartValue)
3839             pop(X86Registers::ebx);
3840         pop(X86Registers::ebp);
3841 #elif CPU(X86)
3842         pop(X86Registers::esi);
3843         pop(X86Registers::edi);
3844         pop(X86Registers::ebx);
3845         pop(X86Registers::ebp);
3846 #elif CPU(ARM64)
3847         if (m_decodeSurrogatePairs)
3848             popPair(framePointerRegister, linkRegister);
3849 #elif CPU(ARM_THUMB2)
3850         pop(ARMRegisters::r8);
3851         pop(ARMRegisters::r6);
3852         pop(ARMRegisters::r5);
3853         pop(ARMRegisters::r4);
3854 #elif CPU(MIPS)
3855         // Do nothing
3856 #endif
3857         ret();
3858     }
3859 
3860 public:
3861     YarrGenerator(VM* vm, YarrPattern&amp; pattern, String&amp; patternString, YarrCodeBlock&amp; codeBlock, YarrCharSize charSize)
3862         : m_vm(vm)
3863         , m_pattern(pattern)
3864         , m_patternString(patternString)
3865         , m_codeBlock(codeBlock)
3866         , m_charSize(charSize)
3867         , m_decodeSurrogatePairs(m_charSize == Char16 &amp;&amp; m_pattern.unicode())
3868         , m_unicodeIgnoreCase(m_pattern.unicode() &amp;&amp; m_pattern.ignoreCase())
3869         , m_fixedSizedAlternative(false)
3870         , m_canonicalMode(m_pattern.unicode() ? CanonicalMode::Unicode : CanonicalMode::UCS2)
3871 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3872         , m_containsNestedSubpatterns(false)
3873         , m_parenContextSizes(compileMode == IncludeSubpatterns ? m_pattern.m_numSubpatterns : 0, m_pattern.m_body-&gt;m_callFrameSize)
3874 #endif
3875     {
3876     }
3877 
3878     void compile()
3879     {
3880         YarrCodeBlock&amp; codeBlock = m_codeBlock;
3881 
3882 #ifndef JIT_UNICODE_EXPRESSIONS
3883         if (m_decodeSurrogatePairs) {
3884             codeBlock.setFallBackWithFailureReason(JITFailureReason::DecodeSurrogatePair);
3885             return;
3886         }
3887 #endif
3888 
3889         if (m_pattern.m_containsBackreferences
3890 #if ENABLE(YARR_JIT_BACKREFERENCES)
3891             &amp;&amp; (compileMode == MatchOnly || (m_pattern.ignoreCase() &amp;&amp; m_charSize != Char8))
3892 #endif
3893             ) {
3894                 codeBlock.setFallBackWithFailureReason(JITFailureReason::BackReference);
3895                 return;
3896         }
3897 
3898         // We need to compile before generating code since we set flags based on compilation that
3899         // are used during generation.
3900         opCompileBody(m_pattern.m_body);
3901 
3902         if (m_failureReason) {
3903             codeBlock.setFallBackWithFailureReason(*m_failureReason);
3904             return;
3905         }
3906 
3907         if (UNLIKELY(Options::dumpDisassembly() || Options::dumpRegExpDisassembly()))
3908             m_disassembler = makeUnique&lt;YarrDisassembler&gt;(this);
3909 
3910         if (m_disassembler)
3911             m_disassembler-&gt;setStartOfCode(label());
3912 
3913 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3914         if (m_containsNestedSubpatterns)
3915             codeBlock.setUsesPatternContextBuffer();
3916 #endif
3917 
3918         generateEnter();
3919 
3920         Jump hasInput = checkInput();
3921         generateFailReturn();
3922         hasInput.link(this);
3923 
3924 #ifdef JIT_UNICODE_EXPRESSIONS
3925         if (m_decodeSurrogatePairs)
3926             getEffectiveAddress(BaseIndex(input, length, TimesTwo), endOfStringAddress);
3927 #endif
3928 
3929 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3930         if (m_containsNestedSubpatterns)
3931             move(TrustedImm32(matchLimit), remainingMatchCount);
3932 #endif
3933 
3934         if (compileMode == IncludeSubpatterns) {
3935             for (unsigned i = 0; i &lt; m_pattern.m_numSubpatterns + 1; ++i)
3936                 store32(TrustedImm32(-1), Address(output, (i &lt;&lt; 1) * sizeof(int)));
3937         }
3938 
3939         if (!m_pattern.m_body-&gt;m_hasFixedSize)
3940             setMatchStart(index);
3941 
3942         initCallFrame();
3943 
3944 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
3945         if (m_containsNestedSubpatterns) {
3946             initParenContextFreeList();
3947             if (m_failureReason) {
3948                 codeBlock.setFallBackWithFailureReason(*m_failureReason);
3949                 return;
3950             }
3951         }
3952 #endif
3953 
3954         if (m_pattern.m_saveInitialStartValue) {
3955 #ifdef HAVE_INITIAL_START_REG
3956             move(index, initialStart);
3957 #else
3958             storeToFrame(index, m_pattern.m_initialStartValueFrameLocation);
3959 #endif
3960         }
3961 
3962         generate();
3963         if (m_disassembler)
3964             m_disassembler-&gt;setEndOfGenerate(label());
3965         backtrack();
3966         if (m_disassembler)
3967             m_disassembler-&gt;setEndOfBacktrack(label());
3968 
3969         generateTryReadUnicodeCharacterHelper();
3970 
3971         generateJITFailReturn();
3972 
3973         if (m_disassembler)
3974             m_disassembler-&gt;setEndOfCode(label());
3975 
3976         LinkBuffer linkBuffer(*this, REGEXP_CODE_ID, JITCompilationCanFail);
3977         if (linkBuffer.didFailToAllocate()) {
3978             codeBlock.setFallBackWithFailureReason(JITFailureReason::ExecutableMemoryAllocationFailure);
3979             return;
3980         }
3981 
3982         if (!m_tryReadUnicodeCharacterCalls.isEmpty()) {
3983             CodeLocationLabel&lt;NoPtrTag&gt; tryReadUnicodeCharacterHelper = linkBuffer.locationOf&lt;NoPtrTag&gt;(m_tryReadUnicodeCharacterEntry);
3984 
3985             for (auto call : m_tryReadUnicodeCharacterCalls)
3986                 linkBuffer.link(call, tryReadUnicodeCharacterHelper);
3987         }
3988 
3989         m_backtrackingState.linkDataLabels(linkBuffer);
3990 
3991         if (m_disassembler)
3992             m_disassembler-&gt;dump(linkBuffer);
3993 
3994         if (compileMode == MatchOnly) {
3995             if (m_charSize == Char8)
3996                 codeBlock.set8BitCodeMatchOnly(FINALIZE_REGEXP_CODE(linkBuffer, YarrMatchOnly8BitPtrTag, &quot;Match-only 8-bit regular expression&quot;));
3997             else
3998                 codeBlock.set16BitCodeMatchOnly(FINALIZE_REGEXP_CODE(linkBuffer, YarrMatchOnly16BitPtrTag, &quot;Match-only 16-bit regular expression&quot;));
3999         } else {
4000             if (m_charSize == Char8)
4001                 codeBlock.set8BitCode(FINALIZE_REGEXP_CODE(linkBuffer, Yarr8BitPtrTag, &quot;8-bit regular expression&quot;));
4002             else
4003                 codeBlock.set16BitCode(FINALIZE_REGEXP_CODE(linkBuffer, Yarr16BitPtrTag, &quot;16-bit regular expression&quot;));
4004         }
4005         if (m_failureReason)
4006             codeBlock.setFallBackWithFailureReason(*m_failureReason);
4007     }
4008 
4009     const char* variant() override
4010     {
4011         if (compileMode == MatchOnly) {
4012             if (m_charSize == Char8)
4013                 return &quot;Match-only 8-bit regular expression&quot;;
4014 
4015             return &quot;Match-only 16-bit regular expression&quot;;
4016         }
4017 
4018         if (m_charSize == Char8)
4019             return &quot;8-bit regular expression&quot;;
4020 
4021         return &quot;16-bit regular expression&quot;;
4022     }
4023 
4024     unsigned opCount() override
4025     {
4026         return m_ops.size();
4027     }
4028 
4029     void dumpPatternString(PrintStream&amp; out) override
4030     {
4031         m_pattern.dumpPatternString(out, m_patternString);
4032     }
4033 
4034     int dumpFor(PrintStream&amp; out, unsigned opIndex) override
4035     {
4036         if (opIndex &gt;= opCount())
4037             return 0;
4038 
4039         out.printf(&quot;%4d:&quot;, opIndex);
4040 
4041         YarrOp&amp; op = m_ops[opIndex];
4042         PatternTerm* term = op.m_term;
4043         switch (op.m_op) {
4044         case OpTerm: {
4045             out.print(&quot;OpTerm &quot;);
4046             switch (term-&gt;type) {
4047             case PatternTerm::TypeAssertionBOL:
4048                 out.print(&quot;Assert BOL&quot;);
4049                 break;
4050 
4051             case PatternTerm::TypeAssertionEOL:
4052                 out.print(&quot;Assert EOL&quot;);
4053                 break;
4054 
4055             case PatternTerm::TypeBackReference:
4056                 out.printf(&quot;BackReference pattern #%u&quot;, term-&gt;backReferenceSubpatternId);
4057                 term-&gt;dumpQuantifier(out);
4058                 break;
4059 
4060             case PatternTerm::TypePatternCharacter:
4061                 out.print(&quot;TypePatternCharacter &quot;);
4062                 dumpUChar32(out, term-&gt;patternCharacter);
4063                 if (m_pattern.ignoreCase())
4064                     out.print(&quot; ignore case&quot;);
4065 
4066                 term-&gt;dumpQuantifier(out);
4067                 break;
4068 
4069             case PatternTerm::TypeCharacterClass:
4070                 out.print(&quot;TypePatternCharacterClass &quot;);
4071                 if (term-&gt;invert())
4072                     out.print(&quot;not &quot;);
4073                 dumpCharacterClass(out, &amp;m_pattern, term-&gt;characterClass);
4074                 term-&gt;dumpQuantifier(out);
4075                 break;
4076 
4077             case PatternTerm::TypeAssertionWordBoundary:
4078                 out.printf(&quot;%sword boundary&quot;, term-&gt;invert() ? &quot;non-&quot; : &quot;&quot;);
4079                 break;
4080 
4081             case PatternTerm::TypeDotStarEnclosure:
4082                 out.print(&quot;.* enclosure&quot;);
4083                 break;
4084 
4085             case PatternTerm::TypeForwardReference:
4086                 out.print(&quot;TypeForwardReference &lt;not handled&gt;&quot;);
4087                 break;
4088 
4089             case PatternTerm::TypeParenthesesSubpattern:
4090             case PatternTerm::TypeParentheticalAssertion:
4091                 RELEASE_ASSERT_NOT_REACHED();
4092                 break;
4093             }
4094 
4095             if (op.m_isDeadCode)
4096                 out.print(&quot; already handled&quot;);
4097             out.print(&quot;\n&quot;);
4098             return(0);
4099         }
4100 
4101         case OpBodyAlternativeBegin:
4102             out.printf(&quot;OpBodyAlternativeBegin minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4103             return(0);
4104 
4105         case OpBodyAlternativeNext:
4106             out.printf(&quot;OpBodyAlternativeNext minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4107             return(0);
4108 
4109         case OpBodyAlternativeEnd:
4110             out.print(&quot;OpBodyAlternativeEnd\n&quot;);
4111             return(0);
4112 
4113         case OpSimpleNestedAlternativeBegin:
4114             out.printf(&quot;OpSimpleNestedAlternativeBegin minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4115             return(1);
4116 
4117         case OpNestedAlternativeBegin:
4118             out.printf(&quot;OpNestedAlternativeBegin minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4119             return(1);
4120 
4121         case OpSimpleNestedAlternativeNext:
4122             out.printf(&quot;OpSimpleNestedAlternativeNext minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4123             return(0);
4124 
4125         case OpNestedAlternativeNext:
4126             out.printf(&quot;OpNestedAlternativeNext minimum size %u\n&quot;, op.m_alternative-&gt;m_minimumSize);
4127             return(0);
4128 
4129         case OpSimpleNestedAlternativeEnd:
4130             out.print(&quot;OpSimpleNestedAlternativeEnd&quot;);
4131             term-&gt;dumpQuantifier(out);
4132             out.print(&quot;\n&quot;);
4133             return(-1);
4134 
4135         case OpNestedAlternativeEnd:
4136             out.print(&quot;OpNestedAlternativeEnd&quot;);
4137             term-&gt;dumpQuantifier(out);
4138             out.print(&quot;\n&quot;);
4139             return(-1);
4140 
4141         case OpParenthesesSubpatternOnceBegin:
4142             out.print(&quot;OpParenthesesSubpatternOnceBegin &quot;);
4143             if (term-&gt;capture())
4144                 out.printf(&quot;capturing pattern #%u&quot;, term-&gt;parentheses.subpatternId);
4145             else
4146                 out.print(&quot;non-capturing&quot;);
4147             term-&gt;dumpQuantifier(out);
4148             out.print(&quot;\n&quot;);
4149             return(0);
4150 
4151         case OpParenthesesSubpatternOnceEnd:
4152             out.print(&quot;OpParenthesesSubpatternOnceEnd &quot;);
4153             if (term-&gt;capture())
4154                 out.printf(&quot;capturing pattern #%u&quot;, term-&gt;parentheses.subpatternId);
4155             else
4156                 out.print(&quot;non-capturing&quot;);
4157             term-&gt;dumpQuantifier(out);
4158             out.print(&quot;\n&quot;);
4159             return(0);
4160 
4161         case OpParenthesesSubpatternTerminalBegin:
4162             out.print(&quot;OpParenthesesSubpatternTerminalBegin &quot;);
4163             if (term-&gt;capture())
4164                 out.printf(&quot;capturing pattern #%u\n&quot;, term-&gt;parentheses.subpatternId);
4165             else
4166                 out.print(&quot;non-capturing\n&quot;);
4167             return(0);
4168 
4169         case OpParenthesesSubpatternTerminalEnd:
4170             out.print(&quot;OpParenthesesSubpatternTerminalEnd &quot;);
4171             if (term-&gt;capture())
4172                 out.printf(&quot;capturing pattern #%u\n&quot;, term-&gt;parentheses.subpatternId);
4173             else
4174                 out.print(&quot;non-capturing\n&quot;);
4175             return(0);
4176 
4177         case OpParenthesesSubpatternBegin:
4178             out.print(&quot;OpParenthesesSubpatternBegin &quot;);
4179             if (term-&gt;capture())
4180                 out.printf(&quot;capturing pattern #%u&quot;, term-&gt;parentheses.subpatternId);
4181             else
4182                 out.print(&quot;non-capturing&quot;);
4183             term-&gt;dumpQuantifier(out);
4184             out.print(&quot;\n&quot;);
4185             return(0);
4186 
4187         case OpParenthesesSubpatternEnd:
4188             out.print(&quot;OpParenthesesSubpatternEnd &quot;);
4189             if (term-&gt;capture())
4190                 out.printf(&quot;capturing pattern #%u&quot;, term-&gt;parentheses.subpatternId);
4191             else
4192                 out.print(&quot;non-capturing&quot;);
4193             term-&gt;dumpQuantifier(out);
4194             out.print(&quot;\n&quot;);
4195             return(0);
4196 
4197         case OpParentheticalAssertionBegin:
4198             out.printf(&quot;OpParentheticalAssertionBegin%s\n&quot;, term-&gt;invert() ? &quot; inverted&quot; : &quot;&quot;);
4199             return(0);
4200 
4201         case OpParentheticalAssertionEnd:
4202             out.printf(&quot;OpParentheticalAssertionEnd%s\n&quot;, term-&gt;invert() ? &quot; inverted&quot; : &quot;&quot;);
4203             return(0);
4204 
4205         case OpMatchFailed:
4206             out.print(&quot;OpMatchFailed\n&quot;);
4207             return(0);
4208         }
4209 
4210         return(0);
4211     }
4212 
4213 private:
4214     VM* m_vm;
4215 
4216     YarrPattern&amp; m_pattern;
4217     String&amp; m_patternString;
4218 
4219     YarrCodeBlock&amp; m_codeBlock;
4220     YarrCharSize m_charSize;
4221 
4222     // Used to detect regular expression constructs that are not currently
4223     // supported in the JIT; fall back to the interpreter when this is detected.
4224     Optional&lt;JITFailureReason&gt; m_failureReason;
4225 
4226     bool m_decodeSurrogatePairs;
4227     bool m_unicodeIgnoreCase;
4228     bool m_fixedSizedAlternative;
4229     CanonicalMode m_canonicalMode;
4230 #if ENABLE(YARR_JIT_ALL_PARENS_EXPRESSIONS)
4231     bool m_containsNestedSubpatterns;
4232     ParenContextSizes m_parenContextSizes;
4233 #endif
4234     JumpList m_abortExecution;
4235     JumpList m_hitMatchLimit;
4236     Vector&lt;Call&gt; m_tryReadUnicodeCharacterCalls;
4237     Label m_tryReadUnicodeCharacterEntry;
4238 
4239     // The regular expression expressed as a linear sequence of operations.
4240     Vector&lt;YarrOp, 128&gt; m_ops;
4241 
4242     // This records the current input offset being applied due to the current
4243     // set of alternatives we are nested within. E.g. when matching the
4244     // character &#39;b&#39; within the regular expression /abc/, we will know that
4245     // the minimum size for the alternative is 3, checked upon entry to the
4246     // alternative, and that &#39;b&#39; is at offset 1 from the start, and as such
4247     // when matching &#39;b&#39; we need to apply an offset of -2 to the load.
4248     //
4249     // FIXME: This should go away. Rather than tracking this value throughout
4250     // code generation, we should gather this information up front &amp; store it
4251     // on the YarrOp structure.
4252     Checked&lt;unsigned&gt; m_checkedOffset;
4253 
4254     // This class records state whilst generating the backtracking path of code.
4255     BacktrackingState m_backtrackingState;
4256 
4257     std::unique_ptr&lt;YarrDisassembler&gt; m_disassembler;
4258 };
4259 
4260 static void dumpCompileFailure(JITFailureReason failure)
4261 {
4262     switch (failure) {
4263     case JITFailureReason::DecodeSurrogatePair:
4264         dataLog(&quot;Can&#39;t JIT a pattern decoding surrogate pairs\n&quot;);
4265         break;
4266     case JITFailureReason::BackReference:
4267         dataLog(&quot;Can&#39;t JIT some patterns containing back references\n&quot;);
4268         break;
4269     case JITFailureReason::ForwardReference:
4270         dataLog(&quot;Can&#39;t JIT a pattern containing forward references\n&quot;);
4271         break;
4272     case JITFailureReason::VariableCountedParenthesisWithNonZeroMinimum:
4273         dataLog(&quot;Can&#39;t JIT a pattern containing a variable counted parenthesis with a non-zero minimum\n&quot;);
4274         break;
4275     case JITFailureReason::ParenthesizedSubpattern:
4276         dataLog(&quot;Can&#39;t JIT a pattern containing parenthesized subpatterns\n&quot;);
4277         break;
4278     case JITFailureReason::FixedCountParenthesizedSubpattern:
4279         dataLog(&quot;Can&#39;t JIT a pattern containing fixed count parenthesized subpatterns\n&quot;);
4280         break;
4281     case JITFailureReason::ParenthesisNestedTooDeep:
4282         dataLog(&quot;Can&#39;t JIT pattern due to parentheses nested too deeply\n&quot;);
4283         break;
4284     case JITFailureReason::ExecutableMemoryAllocationFailure:
4285         dataLog(&quot;Can&#39;t JIT because of failure of allocation of executable memory\n&quot;);
4286         break;
4287     }
4288 }
4289 
4290 void jitCompile(YarrPattern&amp; pattern, String&amp; patternString, YarrCharSize charSize, VM* vm, YarrCodeBlock&amp; codeBlock, YarrJITCompileMode mode)
4291 {
4292     if (mode == MatchOnly)
4293         YarrGenerator&lt;MatchOnly&gt;(vm, pattern, patternString, codeBlock, charSize).compile();
4294     else
4295         YarrGenerator&lt;IncludeSubpatterns&gt;(vm, pattern, patternString, codeBlock, charSize).compile();
4296 
4297     if (auto failureReason = codeBlock.failureReason()) {
4298         if (Options::dumpCompiledRegExpPatterns()) {
4299             pattern.dumpPatternString(WTF::dataFile(), patternString);
4300             dataLog(&quot; : &quot;);
4301             dumpCompileFailure(*failureReason);
4302         }
4303     }
4304 }
4305 
4306 }}
4307 
4308 #endif
    </pre>
  </body>
</html>