diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/Heap.h b/modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/Heap.h
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/Heap.h
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/Heap.h
@@ -84,11 +84,11 @@
 class SweepingScope;
 class VM;
 class WeakGCMapBase;
 struct CurrentThreadState;
 
-#if USE(GLIB)
+#ifdef JSC_GLIB_API_ENABLED
 class JSCGLibWrapperObject;
 #endif
 
 namespace DFG {
 class SpeculativeJIT;
@@ -121,11 +121,11 @@
     // deadline when calling Heap::isPagedOut. Decreasing it will cause us to detect
     // overstepping our deadline more quickly, while increasing it will cause
     // our scan to run faster.
     static const unsigned s_timeCheckResolution = 16;
 
-    static bool isMarked(const void*);
+    bool isMarked(const void*);
     static bool testAndSetMarked(HeapVersion, const void*);
 
     static size_t cellSize(const void*);
 
     void writeBarrier(const JSCell* from);
@@ -137,16 +137,16 @@
     void mutatorFence();
 
     // Take this if you know that from->cellState() < barrierThreshold.
     JS_EXPORT_PRIVATE void writeBarrierSlowPath(const JSCell* from);
 
-    Heap(VM*, HeapType);
+    Heap(VM&, HeapType);
     ~Heap();
     void lastChanceToFinalize();
     void releaseDelayedReleasedObjects();
 
-    VM* vm() const;
+    VM& vm() const;
 
     MarkedSpace& objectSpace() { return m_objectSpace; }
     MachineThreads& machineThreads() { return *m_machineThreads; }
 
     SlotVisitor& collectorSlotVisitor() { return *m_collectorSlotVisitor; }
@@ -176,11 +176,11 @@
     void notifyIsSafeToCollect();
     bool isSafeToCollect() const { return m_isSafeToCollect; }
 
     bool isShuttingDown() const { return m_isShuttingDown; }
 
-    JS_EXPORT_PRIVATE bool isHeapSnapshotting() const;
+    JS_EXPORT_PRIVATE bool isAnalyzingHeap() const;
 
     JS_EXPORT_PRIVATE void sweepSynchronously();
 
     bool shouldCollectHeuristic();
 
@@ -277,11 +277,11 @@
     CodeBlockSet& codeBlockSet() { return *m_codeBlocks; }
 
 #if USE(FOUNDATION)
     template<typename T> void releaseSoon(RetainPtr<T>&&);
 #endif
-#if USE(GLIB)
+#ifdef JSC_GLIB_API_ENABLED
     void releaseSoon(std::unique_ptr<JSCGLibWrapperObject>&&);
 #endif
 
     JS_EXPORT_PRIVATE void registerWeakGCMap(WeakGCMapBase* weakGCMap);
     JS_EXPORT_PRIVATE void unregisterWeakGCMap(WeakGCMapBase* weakGCMap);
@@ -391,11 +391,10 @@
         runTaskInParallel(createSharedTask<void(SlotVisitor&)>(func));
     }
 
     template<typename Func>
     void forEachSlotVisitor(const Func&);
-    unsigned numberOfSlotVisitors();
 
     Seconds totalGCTime() const { return m_totalGCTime; }
 
     HashMap<JSImmutableButterfly*, JSString*> immutableButterflyToStringCache;
 
@@ -424,12 +423,12 @@
     friend class SweepingScope;
     friend class IncrementalSweeper;
     friend class VM;
     friend class WeakSet;
 
-    class Thread;
-    friend class Thread;
+    class HeapThread;
+    friend class HeapThread;
 
     static const size_t minExtraMemory = 256;
 
     class FinalizerOwner : public WeakHandleOwner {
         void finalize(Handle<Unknown>, void* context) override;
@@ -529,11 +528,11 @@
     void deleteUnmarkedCompiledCode();
     JS_EXPORT_PRIVATE void addToRememberedSet(const JSCell*);
     void updateAllocationLimits();
     void didFinishCollection();
     void resumeCompilerThreads();
-    void gatherExtraHeapSnapshotData(HeapProfiler&);
+    void gatherExtraHeapData(HeapProfiler&);
     void removeDeadHeapSnapshotNodes(HeapProfiler&);
     void finalize();
     void sweepInFinalize();
 
     void sweepAllLogicallyEmptyWeakBlocks();
@@ -571,10 +570,12 @@
 
     void assertMarkStacksEmpty();
 
     void setBonusVisitorTask(RefPtr<SharedTask<void(SlotVisitor&)>>);
 
+    void dumpHeapStatisticsAtVMDestruction();
+
     static bool useGenerationalGC();
     static bool shouldSweepSynchronously();
 
     const HeapType m_heapType;
     MutatorState m_mutatorState { MutatorState::Running };
@@ -639,11 +640,11 @@
     bool m_isShuttingDown { false };
     bool m_mutatorShouldBeFenced { Options::forceFencedBarrier() };
 
     unsigned m_barrierThreshold { Options::forceFencedBarrier() ? tautologicalThreshold : blackThreshold };
 
-    VM* m_vm;
+    VM& m_vm;
     Seconds m_lastFullGCLength { 10_ms };
     Seconds m_lastEdenGCLength { 10_ms };
 
     Vector<WeakBlock*> m_logicallyEmptyWeakBlocks;
     size_t m_indexOfNextLogicallyEmptyWeakBlockToSweep { WTF::notFound };
@@ -661,11 +662,11 @@
 
 #if USE(FOUNDATION)
     Vector<RetainPtr<CFTypeRef>> m_delayedReleaseObjects;
     unsigned m_delayedReleaseRecursionCount { 0 };
 #endif
-#if USE(GLIB)
+#ifdef JSC_GLIB_API_ENABLED
     Vector<std::unique_ptr<JSCGLibWrapperObject>> m_delayedReleaseObjects;
     unsigned m_delayedReleaseRecursionCount { 0 };
 #endif
     unsigned m_deferralDepth { 0 };
 
@@ -711,10 +712,11 @@
     Ticket m_lastGrantedTicket { 0 };
 
     CollectorPhase m_lastPhase { CollectorPhase::NotRunning };
     CollectorPhase m_currentPhase { CollectorPhase::NotRunning };
     CollectorPhase m_nextPhase { CollectorPhase::NotRunning };
+    bool m_collectorThreadIsRunning { false };
     bool m_threadShouldStop { false };
     bool m_threadIsStopping { false };
     bool m_mutatorDidRun { true };
     bool m_didDeferGCWork { false };
     bool m_shouldStopCollectingContinuously { false };
@@ -723,21 +725,21 @@
     uint64_t m_phaseVersion { 0 };
     Box<Lock> m_threadLock;
     Ref<AutomaticThreadCondition> m_threadCondition; // The mutator must not wait on this. It would cause a deadlock.
     RefPtr<AutomaticThread> m_thread;
 
-    RefPtr<WTF::Thread> m_collectContinuouslyThread { nullptr };
+    RefPtr<Thread> m_collectContinuouslyThread { nullptr };
 
     MonotonicTime m_lastGCStartTime;
     MonotonicTime m_lastGCEndTime;
     MonotonicTime m_currentGCStartTime;
     Seconds m_totalGCTime;
 
     uintptr_t m_barriersExecuted { 0 };
 
     CurrentThreadState* m_currentThreadState { nullptr };
-    WTF::Thread* m_currentThread { nullptr }; // It's OK if this becomes a dangling pointer.
+    Thread* m_currentThread { nullptr }; // It's OK if this becomes a dangling pointer.
 
 #if PLATFORM(IOS_FAMILY)
     unsigned m_precentAvailableMemoryCachedCallCount;
     bool m_overCriticalMemoryThreshold;
 #endif
