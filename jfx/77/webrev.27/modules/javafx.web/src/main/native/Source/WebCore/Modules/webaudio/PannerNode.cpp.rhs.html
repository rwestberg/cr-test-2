<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/PannerNode.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2010, Google Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1.  Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2.  Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 15  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 16  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 17  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 18  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 19  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 20  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 21  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 22  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 23  */
 24 
 25 #include &quot;config.h&quot;
 26 #include &quot;PannerNode.h&quot;
 27 
 28 #if ENABLE(WEB_AUDIO)
 29 
 30 #include &quot;AudioBufferSourceNode.h&quot;
 31 #include &quot;AudioBus.h&quot;
 32 #include &quot;AudioContext.h&quot;
 33 #include &quot;AudioNodeInput.h&quot;
 34 #include &quot;AudioNodeOutput.h&quot;
 35 #include &quot;HRTFPanner.h&quot;
 36 #include &quot;ScriptExecutionContext.h&quot;
<a name="1" id="anc1"></a><span class="line-added"> 37 #include &lt;wtf/IsoMallocInlines.h&gt;</span>
 38 #include &lt;wtf/MathExtras.h&gt;
 39 
 40 namespace WebCore {
 41 
<a name="2" id="anc2"></a><span class="line-added"> 42 WTF_MAKE_ISO_ALLOCATED_IMPL(PannerNode);</span>
<span class="line-added"> 43 </span>
 44 static void fixNANs(double &amp;x)
 45 {
 46     if (std::isnan(x) || std::isinf(x))
 47         x = 0.0;
 48 }
 49 
 50 PannerNode::PannerNode(AudioContext&amp; context, float sampleRate)
 51     : AudioNode(context, sampleRate)
 52     , m_panningModel(PanningModelType::HRTF)
 53     , m_lastGain(-1.0)
 54     , m_connectionCount(0)
 55 {
<a name="3" id="anc3"></a><span class="line-added"> 56     setNodeType(NodeTypePanner);</span>
<span class="line-added"> 57 </span>
 58     // Load the HRTF database asynchronously so we don&#39;t block the Javascript thread while creating the HRTF database.
 59     m_hrtfDatabaseLoader = HRTFDatabaseLoader::createAndLoadAsynchronouslyIfNecessary(context.sampleRate());
 60 
<a name="4" id="anc4"></a><span class="line-modified"> 61     addInput(makeUnique&lt;AudioNodeInput&gt;(this));</span>
<span class="line-modified"> 62     addOutput(makeUnique&lt;AudioNodeOutput&gt;(this, 2));</span>
 63 
 64     // Node-specific default mixing rules.
 65     m_channelCount = 2;
 66     m_channelCountMode = ClampedMax;
 67     m_channelInterpretation = AudioBus::Speakers;
 68 
 69     m_distanceGain = AudioParam::create(context, &quot;distanceGain&quot;, 1.0, 0.0, 1.0);
 70     m_coneGain = AudioParam::create(context, &quot;coneGain&quot;, 1.0, 0.0, 1.0);
 71 
 72     m_position = FloatPoint3D(0, 0, 0);
 73     m_orientation = FloatPoint3D(1, 0, 0);
 74     m_velocity = FloatPoint3D(0, 0, 0);
 75 
<a name="5" id="anc5"></a>

 76     initialize();
 77 }
 78 
 79 PannerNode::~PannerNode()
 80 {
 81     uninitialize();
 82 }
 83 
 84 void PannerNode::pullInputs(size_t framesToProcess)
 85 {
 86     // We override pullInputs(), so we can detect new AudioSourceNodes which have connected to us when new connections are made.
 87     // These AudioSourceNodes need to be made aware of our existence in order to handle doppler shift pitch changes.
 88     if (m_connectionCount != context().connectionCount()) {
 89         m_connectionCount = context().connectionCount();
 90 
 91         // Recursively go through all nodes connected to us.
 92         HashSet&lt;AudioNode*&gt; visitedNodes;
 93         notifyAudioSourcesConnectedToNode(this, visitedNodes);
 94     }
 95 
 96     AudioNode::pullInputs(framesToProcess);
 97 }
 98 
 99 void PannerNode::process(size_t framesToProcess)
100 {
101     AudioBus* destination = output(0)-&gt;bus();
102 
103     if (!isInitialized() || !input(0)-&gt;isConnected() || !m_panner.get()) {
104         destination-&gt;zero();
105         return;
106     }
107 
108     AudioBus* source = input(0)-&gt;bus();
109     if (!source) {
110         destination-&gt;zero();
111         return;
112     }
113 
114     // HRTFDatabase should be loaded before proceeding for offline audio context when panningModel() is &quot;HRTF&quot;.
115     if (panningModel() == PanningModelType::HRTF &amp;&amp; !m_hrtfDatabaseLoader-&gt;isLoaded()) {
116         if (context().isOfflineContext())
117             m_hrtfDatabaseLoader-&gt;waitForLoaderThreadCompletion();
118         else {
119             destination-&gt;zero();
120             return;
121         }
122     }
123 
124     // The audio thread can&#39;t block on this lock, so we use std::try_to_lock instead.
125     std::unique_lock&lt;Lock&gt; lock(m_pannerMutex, std::try_to_lock);
126     if (!lock.owns_lock()) {
127         // Too bad - The try_lock() failed. We must be in the middle of changing the panner.
128         destination-&gt;zero();
129         return;
130     }
131 
132     // Apply the panning effect.
133     double azimuth;
134     double elevation;
135     getAzimuthElevation(&amp;azimuth, &amp;elevation);
136     m_panner-&gt;pan(azimuth, elevation, source, destination, framesToProcess);
137 
138     // Get the distance and cone gain.
139     double totalGain = distanceConeGain();
140 
141     // Snap to desired gain at the beginning.
142     if (m_lastGain == -1.0)
143         m_lastGain = totalGain;
144 
145     // Apply gain in-place with de-zippering.
146     destination-&gt;copyWithGainFrom(*destination, &amp;m_lastGain, totalGain);
147 }
148 
149 void PannerNode::reset()
150 {
151     m_lastGain = -1.0; // force to snap to initial gain
152     if (m_panner.get())
153         m_panner-&gt;reset();
154 }
155 
156 void PannerNode::initialize()
157 {
158     if (isInitialized())
159         return;
160 
161     m_panner = Panner::create(m_panningModel, sampleRate(), m_hrtfDatabaseLoader.get());
162 
163     AudioNode::initialize();
164 }
165 
166 void PannerNode::uninitialize()
167 {
168     if (!isInitialized())
169         return;
170 
171     m_panner = nullptr;
172     AudioNode::uninitialize();
173 }
174 
175 AudioListener* PannerNode::listener()
176 {
177     return context().listener();
178 }
179 
180 void PannerNode::setPanningModel(PanningModelType model)
181 {
182     if (!m_panner.get() || model != m_panningModel) {
183         // This synchronizes with process().
184         std::lock_guard&lt;Lock&gt; lock(m_pannerMutex);
185 
186         m_panner = Panner::create(model, sampleRate(), m_hrtfDatabaseLoader.get());
187         m_panningModel = model;
188     }
189 }
190 
191 DistanceModelType PannerNode::distanceModel() const
192 {
193     return const_cast&lt;PannerNode*&gt;(this)-&gt;m_distanceEffect.model();
194 }
195 
196 void PannerNode::setDistanceModel(DistanceModelType model)
197 {
198     m_distanceEffect.setModel(model, true);
199 }
200 
201 void PannerNode::getAzimuthElevation(double* outAzimuth, double* outElevation)
202 {
203     // FIXME: we should cache azimuth and elevation (if possible), so we only re-calculate if a change has been made.
204 
205     double azimuth = 0.0;
206 
207     // Calculate the source-listener vector
208     FloatPoint3D listenerPosition = listener()-&gt;position();
209     FloatPoint3D sourceListener = m_position - listenerPosition;
210 
211     if (sourceListener.isZero()) {
212         // degenerate case if source and listener are at the same point
213         *outAzimuth = 0.0;
214         *outElevation = 0.0;
215         return;
216     }
217 
218     sourceListener.normalize();
219 
220     // Align axes
221     FloatPoint3D listenerFront = listener()-&gt;orientation();
222     FloatPoint3D listenerUp = listener()-&gt;upVector();
223     FloatPoint3D listenerRight = listenerFront.cross(listenerUp);
224     listenerRight.normalize();
225 
226     FloatPoint3D listenerFrontNorm = listenerFront;
227     listenerFrontNorm.normalize();
228 
229     FloatPoint3D up = listenerRight.cross(listenerFrontNorm);
230 
231     float upProjection = sourceListener.dot(up);
232 
233     FloatPoint3D projectedSource = sourceListener - upProjection * up;
234     projectedSource.normalize();
235 
236     azimuth = 180.0 * acos(projectedSource.dot(listenerRight)) / piDouble;
237     fixNANs(azimuth); // avoid illegal values
238 
239     // Source  in front or behind the listener
240     double frontBack = projectedSource.dot(listenerFrontNorm);
241     if (frontBack &lt; 0.0)
242         azimuth = 360.0 - azimuth;
243 
244     // Make azimuth relative to &quot;front&quot; and not &quot;right&quot; listener vector
245     if ((azimuth &gt;= 0.0) &amp;&amp; (azimuth &lt;= 270.0))
246         azimuth = 90.0 - azimuth;
247     else
248         azimuth = 450.0 - azimuth;
249 
250     // Elevation
251     double elevation = 90.0 - 180.0 * acos(sourceListener.dot(up)) / piDouble;
252     fixNANs(elevation); // avoid illegal values
253 
254     if (elevation &gt; 90.0)
255         elevation = 180.0 - elevation;
256     else if (elevation &lt; -90.0)
257         elevation = -180.0 - elevation;
258 
259     if (outAzimuth)
260         *outAzimuth = azimuth;
261     if (outElevation)
262         *outElevation = elevation;
263 }
264 
265 float PannerNode::dopplerRate()
266 {
267     double dopplerShift = 1.0;
268 
269     // FIXME: optimize for case when neither source nor listener has changed...
270     double dopplerFactor = listener()-&gt;dopplerFactor();
271 
272     if (dopplerFactor &gt; 0.0) {
273         double speedOfSound = listener()-&gt;speedOfSound();
274 
275         const FloatPoint3D &amp;sourceVelocity = m_velocity;
276         const FloatPoint3D &amp;listenerVelocity = listener()-&gt;velocity();
277 
278         // Don&#39;t bother if both source and listener have no velocity
279         bool sourceHasVelocity = !sourceVelocity.isZero();
280         bool listenerHasVelocity = !listenerVelocity.isZero();
281 
282         if (sourceHasVelocity || listenerHasVelocity) {
283             // Calculate the source to listener vector
284             FloatPoint3D listenerPosition = listener()-&gt;position();
285             FloatPoint3D sourceToListener = m_position - listenerPosition;
286 
287             double sourceListenerMagnitude = sourceToListener.length();
288 
289             double listenerProjection = sourceToListener.dot(listenerVelocity) / sourceListenerMagnitude;
290             double sourceProjection = sourceToListener.dot(sourceVelocity) / sourceListenerMagnitude;
291 
292             listenerProjection = -listenerProjection;
293             sourceProjection = -sourceProjection;
294 
295             double scaledSpeedOfSound = speedOfSound / dopplerFactor;
296             listenerProjection = std::min(listenerProjection, scaledSpeedOfSound);
297             sourceProjection = std::min(sourceProjection, scaledSpeedOfSound);
298 
299             dopplerShift = ((speedOfSound - dopplerFactor * listenerProjection) / (speedOfSound - dopplerFactor * sourceProjection));
300             fixNANs(dopplerShift); // avoid illegal values
301 
302             // Limit the pitch shifting to 4 octaves up and 3 octaves down.
303             if (dopplerShift &gt; 16.0)
304                 dopplerShift = 16.0;
305             else if (dopplerShift &lt; 0.125)
306                 dopplerShift = 0.125;
307         }
308     }
309 
310     return static_cast&lt;float&gt;(dopplerShift);
311 }
312 
313 float PannerNode::distanceConeGain()
314 {
315     FloatPoint3D listenerPosition = listener()-&gt;position();
316 
317     double listenerDistance = m_position.distanceTo(listenerPosition);
318     double distanceGain = m_distanceEffect.gain(listenerDistance);
319 
320     m_distanceGain-&gt;setValue(static_cast&lt;float&gt;(distanceGain));
321 
322     // FIXME: could optimize by caching coneGain
323     double coneGain = m_coneEffect.gain(m_position, m_orientation, listenerPosition);
324 
325     m_coneGain-&gt;setValue(static_cast&lt;float&gt;(coneGain));
326 
327     return float(distanceGain * coneGain);
328 }
329 
330 void PannerNode::notifyAudioSourcesConnectedToNode(AudioNode* node, HashSet&lt;AudioNode*&gt;&amp; visitedNodes)
331 {
332     ASSERT(node);
333     if (!node)
334         return;
335 
336     // First check if this node is an AudioBufferSourceNode. If so, let it know about us so that doppler shift pitch can be taken into account.
337     if (node-&gt;nodeType() == NodeTypeAudioBufferSource) {
338         AudioBufferSourceNode* bufferSourceNode = reinterpret_cast&lt;AudioBufferSourceNode*&gt;(node);
339         bufferSourceNode-&gt;setPannerNode(this);
340     } else {
341         // Go through all inputs to this node.
342         for (unsigned i = 0; i &lt; node-&gt;numberOfInputs(); ++i) {
343             AudioNodeInput* input = node-&gt;input(i);
344 
345             // For each input, go through all of its connections, looking for AudioBufferSourceNodes.
346             for (unsigned j = 0; j &lt; input-&gt;numberOfRenderingConnections(); ++j) {
347                 AudioNodeOutput* connectedOutput = input-&gt;renderingOutput(j);
348                 AudioNode* connectedNode = connectedOutput-&gt;node();
349                 if (visitedNodes.contains(connectedNode))
350                     continue;
351 
352                 visitedNodes.add(connectedNode);
353                 notifyAudioSourcesConnectedToNode(connectedNode, visitedNodes);
354             }
355         }
356     }
357 }
358 
359 } // namespace WebCore
360 
361 #endif // ENABLE(WEB_AUDIO)
<a name="6" id="anc6"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="6" type="hidden" />
</body>
</html>