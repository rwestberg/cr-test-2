<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoEncoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2018 Metrological Group B.V.
  3  * Copyright (C) 2018 Igalia S.L. All rights reserved.
  4  *
  5  * This library is free software; you can redistribute it and/or
  6  * modify it under the terms of the GNU Library General Public
  7  * License as published by the Free Software Foundation; either
  8  * version 2 of the License, or (at your option) any later version.
  9  *
 10  * This library is distributed in the hope that it will be useful,
 11  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 12  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 13  * Library General Public License for more details.
 14  *
 15  * You should have received a copy of the GNU Library General Public License
 16  * aint with this library; see the file COPYING.LIB.  If not, write to
 17  * the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
 18  * Boston, MA 02110-1301, USA.
 19  */
 20 
 21 #include &quot;config.h&quot;
 22 
 23 #if ENABLE(VIDEO) &amp;&amp; ENABLE(MEDIA_STREAM) &amp;&amp; USE(LIBWEBRTC) &amp;&amp; USE(GSTREAMER)
 24 #include &quot;GStreamerVideoEncoderFactory.h&quot;
 25 
 26 #include &quot;GStreamerVideoEncoder.h&quot;
 27 #include &quot;GStreamerVideoFrameLibWebRTC.h&quot;
 28 #include &quot;webrtc/common_video/h264/h264_common.h&quot;
 29 #include &quot;webrtc/common_video/h264/profile_level_id.h&quot;
 30 #include &quot;webrtc/media/base/codec.h&quot;
 31 #include &quot;webrtc/modules/video_coding/codecs/h264/include/h264.h&quot;
 32 #include &quot;webrtc/modules/video_coding/codecs/vp8/include/vp8.h&quot;
 33 #include &quot;webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_encoder.h&quot;
 34 #include &quot;webrtc/modules/video_coding/include/video_codec_interface.h&quot;
 35 #include &quot;webrtc/modules/video_coding/utility/simulcast_utility.h&quot;
 36 
 37 #include &lt;gst/app/gstappsink.h&gt;
 38 #include &lt;gst/app/gstappsrc.h&gt;
 39 #define GST_USE_UNSTABLE_API 1
 40 #include &lt;gst/codecparsers/gsth264parser.h&gt;
 41 #undef GST_USE_UNSTABLE_API
 42 #include &lt;gst/pbutils/encoding-profile.h&gt;
 43 #include &lt;gst/video/video.h&gt;
 44 #include &lt;wtf/Atomics.h&gt;
 45 #include &lt;wtf/HashMap.h&gt;
 46 #include &lt;wtf/Lock.h&gt;
 47 #include &lt;wtf/StdMap.h&gt;
 48 #include &lt;wtf/text/StringConcatenateNumbers.h&gt;
 49 
 50 // Required for unified builds
 51 #ifdef GST_CAT_DEFAULT
 52 #undef GST_CAT_DEFAULT
 53 #endif
 54 
 55 GST_DEBUG_CATEGORY(webkit_webrtcenc_debug);
 56 #define GST_CAT_DEFAULT webkit_webrtcenc_debug
 57 
 58 #define KBIT_TO_BIT 1024
 59 
 60 namespace WebCore {
 61 
 62 class GStreamerVideoEncoder : public webrtc::VideoEncoder {
 63     WTF_MAKE_FAST_ALLOCATED;
 64 public:
 65     GStreamerVideoEncoder(const webrtc::SdpVideoFormat&amp;)
 66         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 67         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
 68     {
 69     }
 70     GStreamerVideoEncoder()
 71         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 72         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
 73     {
 74     }
 75 
 76     int SetRates(uint32_t newBitrate, uint32_t frameRate) override
 77     {
 78         GST_INFO_OBJECT(m_pipeline.get(), &quot;New bitrate: %d - framerate is %d&quot;,
 79             newBitrate, frameRate);
 80 
 81         auto caps = adoptGRef(gst_caps_copy(m_restrictionCaps.get()));
 82 
 83         SetRestrictionCaps(WTFMove(caps));
 84 
 85         if (m_encoder)
 86             g_object_set(m_encoder, &quot;bitrate&quot;, newBitrate, nullptr);
 87 
 88         return WEBRTC_VIDEO_CODEC_OK;
 89     }
 90 
 91     GstElement* pipeline()
 92     {
 93         return m_pipeline.get();
 94     }
 95 
 96     GstElement* makeElement(const gchar* factoryName)
 97     {
 98         static Atomic&lt;uint32_t&gt; elementId;
 99         auto name = makeString(Name(), &quot;-enc-&quot;, factoryName, &quot;-&quot;, elementId.exchangeAdd(1));
100         auto elem = gst_element_factory_make(factoryName, name.utf8().data());
101 
102         return elem;
103     }
104 
105     int32_t InitEncode(const webrtc::VideoCodec* codecSettings, int32_t, size_t)
106     {
107         g_return_val_if_fail(codecSettings, WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
108         g_return_val_if_fail(codecSettings-&gt;codecType == CodecType(), WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
109 
110         if (webrtc::SimulcastUtility::NumberOfSimulcastStreams(*codecSettings) &gt; 1) {
111             GST_ERROR(&quot;Simulcast not supported.&quot;);
112 
113             return WEBRTC_VIDEO_CODEC_ERR_SIMULCAST_PARAMETERS_NOT_SUPPORTED;
114         }
115 
116         m_encodedFrame._size = codecSettings-&gt;width * codecSettings-&gt;height * 3;
117         m_encodedFrame._buffer = new uint8_t[m_encodedFrame._size];
118         m_encodedImageBuffer.reset(m_encodedFrame._buffer);
119         m_encodedFrame._completeFrame = true;
120         m_encodedFrame._encodedWidth = 0;
121         m_encodedFrame._encodedHeight = 0;
122         m_encodedFrame._length = 0;
123 
124         m_pipeline = makeElement(&quot;pipeline&quot;);
125 
126         connectSimpleBusMessageCallback(m_pipeline.get());
127         auto encoder = createEncoder();
128         ASSERT(encoder);
129         m_encoder = encoder.get();
130 
131         g_object_set(m_encoder, &quot;keyframe-interval&quot;, KeyframeInterval(codecSettings), nullptr);
132 
133         m_src = makeElement(&quot;appsrc&quot;);
134         g_object_set(m_src, &quot;is-live&quot;, true, &quot;format&quot;, GST_FORMAT_TIME, nullptr);
135 
136         auto videoconvert = makeElement(&quot;videoconvert&quot;);
137         m_sink = makeElement(&quot;appsink&quot;);
138         g_object_set(m_sink, &quot;sync&quot;, FALSE, nullptr);
139 
140         m_capsFilter = makeElement(&quot;capsfilter&quot;);
141         if (m_restrictionCaps)
142             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
143 
144         gst_bin_add_many(GST_BIN(m_pipeline.get()), m_src, videoconvert, m_capsFilter, encoder.leakRef(), m_sink, nullptr);
145         if (!gst_element_link_many(m_src, videoconvert, m_capsFilter, m_encoder, m_sink, nullptr)) {
146             GST_DEBUG_BIN_TO_DOT_FILE_WITH_TS(GST_BIN(m_pipeline.get()), GST_DEBUG_GRAPH_SHOW_VERBOSE, &quot;webkit-webrtc-encoder.error&quot;);
147 
148             ASSERT_NOT_REACHED();
149         }
150 
151         gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
152 
153         return WEBRTC_VIDEO_CODEC_OK;
154     }
155 
156     bool SupportsNativeHandle() const final
157     {
158         return true;
159     }
160 
161     int32_t RegisterEncodeCompleteCallback(webrtc::EncodedImageCallback* callback) final
162     {
163         m_imageReadyCb = callback;
164 
165         return WEBRTC_VIDEO_CODEC_OK;
166     }
167 
168     int32_t Release() final
169     {
170         m_encodedFrame._buffer = nullptr;
171         m_encodedImageBuffer.reset();
172         if (m_pipeline) {
173             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
174             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
175 
176             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
177             m_src = nullptr;
178             m_encoder = nullptr;
179             m_capsFilter = nullptr;
180             m_sink = nullptr;
181             m_pipeline = nullptr;
182         }
183 
184         return WEBRTC_VIDEO_CODEC_OK;
185     }
186 
187     int32_t returnFromFlowReturn(GstFlowReturn flow)
188     {
189         switch (flow) {
190         case GST_FLOW_OK:
191             return WEBRTC_VIDEO_CODEC_OK;
192         case GST_FLOW_FLUSHING:
193             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
194         default:
195             return WEBRTC_VIDEO_CODEC_ERROR;
196         }
197     }
198 
199     int32_t Encode(const webrtc::VideoFrame&amp; frame,
200         const webrtc::CodecSpecificInfo*,
201         const std::vector&lt;webrtc::FrameType&gt;* frameTypes) final
202     {
203         int32_t res;
204 
205         if (!m_imageReadyCb) {
206             GST_INFO_OBJECT(m_pipeline.get(), &quot;No encoded callback set yet!&quot;);
207 
208             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
209         }
210 
211         if (!m_src) {
212             GST_INFO_OBJECT(m_pipeline.get(), &quot;No source set yet!&quot;);
213 
214             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
215         }
216 
217         auto sample = GStreamerSampleFromLibWebRTCVideoFrame(frame);
218         auto buffer = gst_sample_get_buffer(sample.get());
219 
220         if (!GST_CLOCK_TIME_IS_VALID(m_firstFramePts)) {
221             m_firstFramePts = GST_BUFFER_PTS(buffer);
222             auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
223             gst_pad_set_offset(pad.get(), -m_firstFramePts);
224         }
225 
226         for (auto frame_type : *frameTypes) {
227             if (frame_type == webrtc::kVideoFrameKey) {
228                 auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
229                 auto forceKeyUnit = gst_video_event_new_downstream_force_key_unit(GST_CLOCK_TIME_NONE,
230                     GST_CLOCK_TIME_NONE, GST_CLOCK_TIME_NONE, FALSE, 1);
231                 GST_INFO_OBJECT(m_pipeline.get(), &quot;Requesting KEYFRAME!&quot;);
232 
233                 if (!gst_pad_push_event(pad.get(), forceKeyUnit))
234                     GST_WARNING_OBJECT(pipeline(), &quot;Could not send ForceKeyUnit event&quot;);
235 
236                 break;
237             }
238         }
239 
240         res = returnFromFlowReturn(gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get()));
241         if (res != WEBRTC_VIDEO_CODEC_OK)
242             return res;
243 
244         auto encodedSample = adoptGRef(gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), 5 * GST_SECOND));
245         if (!encodedSample) {
246             GST_ERROR(&quot;Didn&#39;t get any encodedSample&quot;);
247             return WEBRTC_VIDEO_CODEC_ERROR;
248         }
249 
250         auto encodedBuffer = gst_sample_get_buffer(encodedSample.get());
251         auto encodedCaps = gst_sample_get_caps(encodedSample.get());
252 
253         webrtc::RTPFragmentationHeader fragmentationInfo;
254 
255         Fragmentize(&amp;m_encodedFrame, &amp;m_encodedImageBuffer, &amp;m_encodedImageBufferSize, encodedBuffer, &amp;fragmentationInfo);
256         if (!m_encodedFrame._size)
257             return WEBRTC_VIDEO_CODEC_OK;
258 
259         gst_structure_get(gst_caps_get_structure(encodedCaps, 0),
260             &quot;width&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedWidth,
261             &quot;height&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedHeight,
262             nullptr);
263 
264         m_encodedFrame._frameType = GST_BUFFER_FLAG_IS_SET(encodedBuffer, GST_BUFFER_FLAG_DELTA_UNIT) ? webrtc::kVideoFrameDelta : webrtc::kVideoFrameKey;
265         m_encodedFrame._completeFrame = true;
266         m_encodedFrame.capture_time_ms_ = frame.render_time_ms();
267         m_encodedFrame.SetTimestamp(frame.timestamp());
268 
269         GST_LOG_OBJECT(m_pipeline.get(), &quot;Got buffer capture_time_ms: %&quot; G_GINT64_FORMAT  &quot; _timestamp: %u&quot;,
270             m_encodedFrame.capture_time_ms_, m_encodedFrame.Timestamp());
271 
272         webrtc::CodecSpecificInfo codecInfo;
273         PopulateCodecSpecific(&amp;codecInfo, encodedBuffer);
274         webrtc::EncodedImageCallback::Result result = m_imageReadyCb-&gt;OnEncodedImage(m_encodedFrame, &amp;codecInfo, &amp;fragmentationInfo);
275         if (result.error != webrtc::EncodedImageCallback::Result::OK)
276             GST_ERROR_OBJECT(m_pipeline.get(), &quot;Encode callback failed: %d&quot;, result.error);
277 
278         return WEBRTC_VIDEO_CODEC_OK;
279     }
280 
281     GRefPtr&lt;GstElement&gt; createEncoder(void)
282     {
283         GRefPtr&lt;GstElement&gt; encoder = nullptr;
284         GstElement* webrtcencoder = GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL)));
285 
286         g_object_set(webrtcencoder, &quot;format&quot;, adoptGRef(gst_caps_from_string(Caps())).get(), NULL);
287         g_object_get(webrtcencoder, &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
288 
289         if (!encoder) {
290             GST_INFO(&quot;No encoder found for %s&quot;, Caps());
291 
292             return nullptr;
293         }
294 
295         return webrtcencoder;
296     }
297 
298     void AddCodecIfSupported(std::vector&lt;webrtc::SdpVideoFormat&gt;* supportedFormats)
299     {
300         GstElement* encoder;
301 
302         if (createEncoder().get() != nullptr) {
303             webrtc::SdpVideoFormat format = ConfigureSupportedCodec(encoder);
304 
305             supportedFormats-&gt;push_back(format);
306         }
307     }
308 
309     virtual const gchar* Caps()
310     {
311         return nullptr;
312     }
313 
314     virtual webrtc::VideoCodecType CodecType() = 0;
315     virtual webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*)
316     {
317         return webrtc::SdpVideoFormat(Name());
318     }
319 
320     virtual void PopulateCodecSpecific(webrtc::CodecSpecificInfo*, GstBuffer*) = 0;
321 
322     virtual void Fragmentize(webrtc::EncodedImage* encodedImage, std::unique_ptr&lt;uint8_t[]&gt;* encodedImageBuffer,
323         size_t* bufferSize, GstBuffer* buffer, webrtc::RTPFragmentationHeader* fragmentationInfo)
324     {
325         auto map = GstMappedBuffer::create(buffer, GST_MAP_READ);
326 
327         if (*bufferSize &lt; map-&gt;size()) {
328             encodedImage-&gt;_size = map-&gt;size();
329             encodedImage-&gt;_buffer = new uint8_t[encodedImage-&gt;_size];
330             encodedImageBuffer-&gt;reset(encodedImage-&gt;_buffer);
331             *bufferSize = map-&gt;size();
332         }
333 
334         memcpy(encodedImage-&gt;_buffer, map-&gt;data(), map-&gt;size());
335         encodedImage-&gt;_length = map-&gt;size();
336         encodedImage-&gt;_size = map-&gt;size();
337 
338         fragmentationInfo-&gt;VerifyAndAllocateFragmentationHeader(1);
339         fragmentationInfo-&gt;fragmentationOffset[0] = 0;
340         fragmentationInfo-&gt;fragmentationLength[0] = map-&gt;size();
341         fragmentationInfo-&gt;fragmentationPlType[0] = 0;
342         fragmentationInfo-&gt;fragmentationTimeDiff[0] = 0;
343     }
344 
345     const char* ImplementationName() const
346     {
347         GRefPtr&lt;GstElement&gt; encoderImplementation;
348         g_return_val_if_fail(m_encoder, nullptr);
349 
350         g_object_get(m_encoder, &quot;encoder&quot;, &amp;encoderImplementation.outPtr(), nullptr);
351 
352         return GST_OBJECT_NAME(gst_element_get_factory(encoderImplementation.get()));
353     }
354 
355     virtual const gchar* Name() = 0;
356     virtual int KeyframeInterval(const webrtc::VideoCodec* codecSettings) = 0;
357 
358     void SetRestrictionCaps(GRefPtr&lt;GstCaps&gt; caps)
359     {
360         if (m_restrictionCaps)
361             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
362 
363         m_restrictionCaps = caps;
364     }
365 
366 private:
367     GRefPtr&lt;GstElement&gt; m_pipeline;
368     GstElement* m_src;
369     GstElement* m_encoder;
370     GstElement* m_capsFilter;
371 
372     webrtc::EncodedImageCallback* m_imageReadyCb;
373     GstClockTime m_firstFramePts;
374     GRefPtr&lt;GstCaps&gt; m_restrictionCaps;
375     webrtc::EncodedImage m_encodedFrame;
376     std::unique_ptr&lt;uint8_t[]&gt; m_encodedImageBuffer;
377     size_t m_encodedImageBufferSize;
378 
379     Lock m_bufferMapLock;
380     GstElement* m_sink;
381 };
382 
383 class GStreamerH264Encoder : public GStreamerVideoEncoder {
384 public:
385     GStreamerH264Encoder() { }
386 
387     GStreamerH264Encoder(const webrtc::SdpVideoFormat&amp; format)
388         : m_parser(gst_h264_nal_parser_new())
389         , packetizationMode(webrtc::H264PacketizationMode::NonInterleaved)
390     {
391         auto it = format.parameters.find(cricket::kH264FmtpPacketizationMode);
392 
393         if (it != format.parameters.end() &amp;&amp; it-&gt;second == &quot;1&quot;)
394             packetizationMode = webrtc::H264PacketizationMode::NonInterleaved;
395     }
396 
397     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
398     {
399         return codecSettings-&gt;H264().keyFrameInterval;
400     }
401 
402     // FIXME - MT. safety!
403     void Fragmentize(webrtc::EncodedImage* encodedImage, std::unique_ptr&lt;uint8_t[]&gt;* encodedImageBuffer, size_t *bufferSize,
404         GstBuffer* gstbuffer, webrtc::RTPFragmentationHeader* fragmentationHeader) final
405     {
406         GstH264NalUnit nalu;
407         auto parserResult = GST_H264_PARSER_OK;
408 
409         gsize offset = 0;
410         size_t requiredSize = 0;
411 
412         std::vector&lt;GstH264NalUnit&gt; nals;
413 
414         const uint8_t startCode[4] = { 0, 0, 0, 1 };
415         auto map = GstMappedBuffer::create(gstbuffer, GST_MAP_READ);
416         while (parserResult == GST_H264_PARSER_OK) {
417             parserResult = gst_h264_parser_identify_nalu(m_parser, map-&gt;data(), offset, map-&gt;size(), &amp;nalu);
418 
419             nalu.sc_offset = offset;
420             nalu.offset = offset + sizeof(startCode);
421             if (parserResult != GST_H264_PARSER_OK &amp;&amp; parserResult != GST_H264_PARSER_NO_NAL_END)
422                 break;
423 
424             requiredSize += nalu.size + sizeof(startCode);
425             nals.push_back(nalu);
426             offset = nalu.offset + nalu.size;
427         }
428 
429         if (encodedImage-&gt;_size &lt; requiredSize) {
430             encodedImage-&gt;_size = requiredSize;
431             encodedImage-&gt;_buffer = new uint8_t[encodedImage-&gt;_size];
432             encodedImageBuffer-&gt;reset(encodedImage-&gt;_buffer);
433             *bufferSize = map-&gt;size();
434         }
435 
436         // Iterate nal units and fill the Fragmentation info.
437         fragmentationHeader-&gt;VerifyAndAllocateFragmentationHeader(nals.size());
438         size_t fragmentIndex = 0;
439         encodedImage-&gt;_length = 0;
440         for (std::vector&lt;GstH264NalUnit&gt;::iterator nal = nals.begin(); nal != nals.end(); ++nal, fragmentIndex++) {
441 
442             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 0] == startCode[0]);
443             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 1] == startCode[1]);
444             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 2] == startCode[2]);
445             ASSERT(map-&gt;data()[nal-&gt;sc_offset + 3] == startCode[3]);
446 
447             fragmentationHeader-&gt;fragmentationOffset[fragmentIndex] = nal-&gt;offset;
448             fragmentationHeader-&gt;fragmentationLength[fragmentIndex] = nal-&gt;size;
449 
450             memcpy(encodedImage-&gt;_buffer + encodedImage-&gt;_length, &amp;map-&gt;data()[nal-&gt;sc_offset],
451                 sizeof(startCode) + nal-&gt;size);
452             encodedImage-&gt;_length += nal-&gt;size + sizeof(startCode);
453         }
454     }
455 
456     webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*) final
457     {
458         // TODO- Create from encoder src pad caps template
459         return webrtc::SdpVideoFormat(cricket::kH264CodecName,
460             { { cricket::kH264FmtpProfileLevelId, cricket::kH264ProfileLevelConstrainedBaseline },
461                 { cricket::kH264FmtpLevelAsymmetryAllowed, &quot;1&quot; },
462                 { cricket::kH264FmtpPacketizationMode, &quot;1&quot; } });
463     }
464 
465     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
466     const gchar* Name() final { return cricket::kH264CodecName; }
467     GstH264NalParser* m_parser;
468     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
469 
470     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer*) final
471     {
472         codecSpecificInfos-&gt;codecType = CodecType();
473         codecSpecificInfos-&gt;codec_name = ImplementationName();
474         webrtc::CodecSpecificInfoH264* h264Info = &amp;(codecSpecificInfos-&gt;codecSpecific.H264);
475         h264Info-&gt;packetization_mode = packetizationMode;
476     }
477 
478     webrtc::H264PacketizationMode packetizationMode;
479 };
480 
481 class GStreamerVP8Encoder : public GStreamerVideoEncoder {
482 public:
483     GStreamerVP8Encoder() { }
484     GStreamerVP8Encoder(const webrtc::SdpVideoFormat&amp;) { }
485     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
486     const gchar* Name() final { return cricket::kVp8CodecName; }
487     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
488 
489     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
490     {
491         return codecSettings-&gt;VP8().keyFrameInterval;
492     }
493 
494     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer* buffer) final
495     {
496         codecSpecificInfos-&gt;codecType = webrtc::kVideoCodecVP8;
497         codecSpecificInfos-&gt;codec_name = ImplementationName();
498         webrtc::CodecSpecificInfoVP8* vp8Info = &amp;(codecSpecificInfos-&gt;codecSpecific.VP8);
499         vp8Info-&gt;temporalIdx = 0;
500 
501         vp8Info-&gt;keyIdx = webrtc::kNoKeyIdx;
502         vp8Info-&gt;nonReference = GST_BUFFER_FLAG_IS_SET(buffer, GST_BUFFER_FLAG_DELTA_UNIT);
503     }
504 };
505 
506 std::unique_ptr&lt;webrtc::VideoEncoder&gt; GStreamerVideoEncoderFactory::CreateVideoEncoder(const webrtc::SdpVideoFormat&amp; format)
507 {
508     if (format.name == cricket::kVp8CodecName) {
509         GRefPtr&lt;GstElement&gt; webrtcencoder = adoptGRef(GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL))));
510         GRefPtr&lt;GstElement&gt; encoder = nullptr;
511 
512         g_object_set(webrtcencoder.get(), &quot;format&quot;, adoptGRef(gst_caps_from_string(&quot;video/x-vp8&quot;)).get(), NULL);
513         g_object_get(webrtcencoder.get(), &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
514 
515         if (encoder)
516             return makeUnique&lt;GStreamerVP8Encoder&gt;(format);
517 
518         GST_INFO(&quot;Using VP8 Encoder from LibWebRTC.&quot;);
519         return makeUniqueWithoutFastMallocCheck&lt;webrtc::LibvpxVp8Encoder&gt;();
520     }
521 
522     if (format.name == cricket::kH264CodecName)
523         return makeUnique&lt;GStreamerH264Encoder&gt;(format);
524 
525     return nullptr;
526 }
527 
528 GStreamerVideoEncoderFactory::GStreamerVideoEncoderFactory()
529 {
530     static std::once_flag debugRegisteredFlag;
531 
532     std::call_once(debugRegisteredFlag, [] {
533         GST_DEBUG_CATEGORY_INIT(webkit_webrtcenc_debug, &quot;webkitlibwebrtcvideoencoder&quot;, 0, &quot;WebKit WebRTC video encoder&quot;);
534         gst_element_register(nullptr, &quot;webrtcvideoencoder&quot;, GST_RANK_PRIMARY, GST_TYPE_WEBRTC_VIDEO_ENCODER);
535     });
536 }
537 
538 std::vector&lt;webrtc::SdpVideoFormat&gt; GStreamerVideoEncoderFactory::GetSupportedFormats() const
539 {
540     std::vector&lt;webrtc::SdpVideoFormat&gt; supportedCodecs;
541 
542     supportedCodecs.push_back(webrtc::SdpVideoFormat(cricket::kVp8CodecName));
543     GStreamerH264Encoder().AddCodecIfSupported(&amp;supportedCodecs);
544 
545     return supportedCodecs;
546 }
547 
548 } // namespace WebCore
549 #endif
    </pre>
  </body>
</html>