<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AudioBufferSourceNode.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioContext.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  78 #if ENABLE(VIDEO)
  79 #include &quot;HTMLMediaElement.h&quot;
  80 #include &quot;MediaElementAudioSourceNode.h&quot;
  81 #endif
  82 
  83 #if DEBUG_AUDIONODE_REFERENCES
  84 #include &lt;stdio.h&gt;
  85 #endif
  86 
  87 #if USE(GSTREAMER)
  88 #include &quot;GStreamerCommon.h&quot;
  89 #endif
  90 
  91 #if PLATFORM(IOS_FAMILY)
  92 #include &quot;ScriptController.h&quot;
  93 #include &quot;Settings.h&quot;
  94 #endif
  95 
  96 #include &lt;JavaScriptCore/ArrayBuffer.h&gt;
  97 #include &lt;wtf/Atomics.h&gt;

  98 #include &lt;wtf/MainThread.h&gt;
  99 #include &lt;wtf/Ref.h&gt;
 100 #include &lt;wtf/RefCounted.h&gt;

 101 #include &lt;wtf/text/WTFString.h&gt;
 102 
 103 const unsigned MaxPeriodicWaveLength = 4096;
 104 
 105 namespace WebCore {
 106 
<span class="line-modified"> 107 #define RELEASE_LOG_IF_ALLOWED(fmt, ...) RELEASE_LOG_IF(document()-&gt;page() &amp;&amp; document()-&gt;page()-&gt;isAlwaysOnLoggingAllowed(), Media, &quot;%p - AudioContext::&quot; fmt, this, ##__VA_ARGS__)</span>


 108 
 109 bool AudioContext::isSampleRateRangeGood(float sampleRate)
 110 {
 111     // FIXME: It would be nice if the minimum sample-rate could be less than 44.1KHz,
 112     // but that will require some fixes in HRTFPanner::fftSizeForSampleRate(), and some testing there.
 113     return sampleRate &gt;= 44100 &amp;&amp; sampleRate &lt;= 96000;
 114 }
 115 
 116 // Don&#39;t allow more than this number of simultaneous AudioContexts talking to hardware.
 117 const unsigned MaxHardwareContexts = 4;
 118 unsigned AudioContext::s_hardwareContextCount = 0;
 119 
 120 RefPtr&lt;AudioContext&gt; AudioContext::create(Document&amp; document)
 121 {
 122     ASSERT(isMainThread());
 123     if (s_hardwareContextCount &gt;= MaxHardwareContexts)
 124         return nullptr;
 125 
 126     RefPtr&lt;AudioContext&gt; audioContext(adoptRef(new AudioContext(document)));
 127     audioContext-&gt;suspendIfNeeded();
 128     return audioContext;
 129 }
 130 
 131 // Constructor for rendering to the audio hardware.
 132 AudioContext::AudioContext(Document&amp; document)
 133     : ActiveDOMObject(document)




 134     , m_mediaSession(PlatformMediaSession::create(*this))
<span class="line-modified"> 135     , m_eventQueue(std::make_unique&lt;GenericEventQueue&gt;(*this))</span>
 136 {




 137     constructCommon();
 138 
 139     m_destinationNode = DefaultAudioDestinationNode::create(*this);
 140 
 141     // Initialize the destination node&#39;s muted state to match the page&#39;s current muted state.
 142     pageMutedStateDidChange();



 143 }
 144 
 145 // Constructor for offline (non-realtime) rendering.
 146 AudioContext::AudioContext(Document&amp; document, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)
 147     : ActiveDOMObject(document)




 148     , m_isOfflineContext(true)
 149     , m_mediaSession(PlatformMediaSession::create(*this))
<span class="line-modified"> 150     , m_eventQueue(std::make_unique&lt;GenericEventQueue&gt;(*this))</span>
 151 {
 152     constructCommon();
 153 
 154     // Create a new destination for offline rendering.
 155     m_renderTarget = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);
 156     m_destinationNode = OfflineAudioDestinationNode::create(*this, m_renderTarget.get());
 157 }
 158 
 159 void AudioContext::constructCommon()
 160 {
<span class="line-removed"> 161     // According to spec AudioContext must die only after page navigate.</span>
<span class="line-removed"> 162     // Lets mark it as ActiveDOMObject with pending activity and unmark it in clear method.</span>
<span class="line-removed"> 163     setPendingActivity(*this);</span>
<span class="line-removed"> 164 </span>
 165     FFTFrame::initialize();
 166 
 167     m_listener = AudioListener::create();
 168 

 169     if (document()-&gt;audioPlaybackRequiresUserGesture())
 170         addBehaviorRestriction(RequireUserGestureForAudioStartRestriction);
 171     else
 172         m_restrictions = NoRestrictions;
 173 
 174 #if PLATFORM(COCOA)
 175     addBehaviorRestriction(RequirePageConsentForAudioStartRestriction);
 176 #endif
 177 }
 178 
 179 AudioContext::~AudioContext()
 180 {
 181 #if DEBUG_AUDIONODE_REFERENCES
 182     fprintf(stderr, &quot;%p: AudioContext::~AudioContext()\n&quot;, this);
 183 #endif
 184     ASSERT(!m_isInitialized);
 185     ASSERT(m_isStopScheduled);
 186     ASSERT(m_nodesToDelete.isEmpty());
 187     ASSERT(m_referencedNodes.isEmpty());
 188     ASSERT(m_finishedNodes.isEmpty()); // FIXME (bug 105870): This assertion fails on tests sometimes.
 189     ASSERT(m_automaticPullNodes.isEmpty());
 190     if (m_automaticPullNodesNeedUpdating)
 191         m_renderingAutomaticPullNodes.resize(m_automaticPullNodes.size());
 192     ASSERT(m_renderingAutomaticPullNodes.isEmpty());
 193     // FIXME: Can we assert that m_deferredFinishDerefList is empty?





 194 }
 195 
 196 void AudioContext::lazyInitialize()
 197 {


 198     if (m_isInitialized)
 199         return;
 200 
 201     // Don&#39;t allow the context to initialize a second time after it&#39;s already been explicitly uninitialized.
 202     ASSERT(!m_isAudioThreadFinished);
 203     if (m_isAudioThreadFinished)
 204         return;
 205 
 206     if (m_destinationNode) {
 207         m_destinationNode-&gt;initialize();
 208 
 209         if (!isOfflineContext()) {
<span class="line-removed"> 210             document()-&gt;addAudioProducer(*this);</span>
<span class="line-removed"> 211             document()-&gt;registerForVisibilityStateChangedCallbacks(*this);</span>
<span class="line-removed"> 212 </span>
 213             // This starts the audio thread. The destination node&#39;s provideInput() method will now be called repeatedly to render audio.
 214             // Each time provideInput() is called, a portion of the audio stream is rendered. Let&#39;s call this time period a &quot;render quantum&quot;.
 215             // NOTE: for now default AudioContext does not need an explicit startRendering() call from JavaScript.
 216             // We may want to consider requiring it for symmetry with OfflineAudioContext.
 217             startRendering();
 218             ++s_hardwareContextCount;
 219         }
 220     }
 221     m_isInitialized = true;
 222 }
 223 
 224 void AudioContext::clear()
 225 {


 226     // We have to release our reference to the destination node before the context will ever be deleted since the destination node holds a reference to the context.
 227     if (m_destinationNode)
 228         m_destinationNode = nullptr;
 229 
 230     // Audio thread is dead. Nobody will schedule node deletion action. Let&#39;s do it ourselves.
 231     do {
 232         deleteMarkedNodes();
 233         m_nodesToDelete.appendVector(m_nodesMarkedForDeletion);
 234         m_nodesMarkedForDeletion.clear();
 235     } while (m_nodesToDelete.size());
 236 
<span class="line-modified"> 237     // It was set in constructCommon.</span>
<span class="line-removed"> 238     unsetPendingActivity(*this);</span>
 239 }
 240 
 241 void AudioContext::uninitialize()
 242 {


 243     ASSERT(isMainThread());
 244 
 245     if (!m_isInitialized)
 246         return;
 247 
 248     // This stops the audio thread and all audio rendering.
<span class="line-modified"> 249     m_destinationNode-&gt;uninitialize();</span>

 250 
 251     // Don&#39;t allow the context to initialize a second time after it&#39;s already been explicitly uninitialized.
 252     m_isAudioThreadFinished = true;
 253 
 254     if (!isOfflineContext()) {
<span class="line-removed"> 255         document()-&gt;removeAudioProducer(*this);</span>
<span class="line-removed"> 256         document()-&gt;unregisterForVisibilityStateChangedCallbacks(*this);</span>
<span class="line-removed"> 257 </span>
 258         ASSERT(s_hardwareContextCount);
 259         --s_hardwareContextCount;
 260 
 261         // Offline contexts move to &#39;Closed&#39; state when dispatching the completion event.
 262         setState(State::Closed);
 263     }
 264 
 265     // Get rid of the sources which may still be playing.
 266     derefUnfinishedSourceNodes();
 267 
 268     m_isInitialized = false;
 269 }
 270 
 271 bool AudioContext::isInitialized() const
 272 {
 273     return m_isInitialized;
 274 }
 275 
 276 void AudioContext::addReaction(State state, DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
 277 {
</pre>
<hr />
<pre>
 286 {
 287     if (m_state == state)
 288         return;
 289 
 290     m_state = state;
 291     m_eventQueue-&gt;enqueueEvent(Event::create(eventNames().statechangeEvent, Event::CanBubble::Yes, Event::IsCancelable::No));
 292 
 293     size_t stateIndex = static_cast&lt;size_t&gt;(state);
 294     if (stateIndex &gt;= m_stateReactions.size())
 295         return;
 296 
 297     Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt; reactions;
 298     m_stateReactions[stateIndex].swap(reactions);
 299 
 300     for (auto&amp; promise : reactions)
 301         promise.resolve();
 302 }
 303 
 304 void AudioContext::stop()
 305 {


 306     ASSERT(isMainThread());
 307 
 308     // Usually ScriptExecutionContext calls stop twice.
 309     if (m_isStopScheduled)
 310         return;
 311     m_isStopScheduled = true;
 312 

 313     document()-&gt;updateIsPlayingMedia();
 314 
 315     m_eventQueue-&gt;close();
 316 
 317     uninitialize();
 318     clear();
 319 }
 320 
 321 bool AudioContext::canSuspendForDocumentSuspension() const
 322 {
 323     // FIXME: We should be able to suspend while rendering as well with some more code.
 324     return m_state == State::Suspended || m_state == State::Closed;
 325 }
 326 
 327 const char* AudioContext::activeDOMObjectName() const
 328 {
 329     return &quot;AudioContext&quot;;
 330 }
 331 
 332 Document* AudioContext::document() const
 333 {
<span class="line-removed"> 334     ASSERT(m_scriptExecutionContext);</span>
 335     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 336 }
 337 
 338 Document* AudioContext::hostingDocument() const
 339 {
 340     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 341 }
 342 
 343 String AudioContext::sourceApplicationIdentifier() const
 344 {
 345     Document* document = this-&gt;document();
 346     if (Frame* frame = document ? document-&gt;frame() : nullptr) {
 347         if (NetworkingContext* networkingContext = frame-&gt;loader().networkingContext())
 348             return networkingContext-&gt;sourceApplicationIdentifier();
 349     }
 350     return emptyString();
 351 }
 352 
 353 bool AudioContext::processingUserGestureForMedia() const
 354 {
 355     return document() ? document()-&gt;processingUserGestureForMedia() : false;
 356 }
 357 
 358 bool AudioContext::isSuspended() const
 359 {
 360     return !document() || document()-&gt;activeDOMObjectsAreSuspended() || document()-&gt;activeDOMObjectsAreStopped();
 361 }
 362 
 363 void AudioContext::visibilityStateChanged()
 364 {
 365     // Do not suspend if audio is audible.
<span class="line-modified"> 366     if (mediaState() == MediaProducer::IsPlayingAudio)</span>
 367         return;
 368 
 369     if (document()-&gt;hidden()) {
 370         if (state() == State::Running) {
 371             RELEASE_LOG_IF_ALLOWED(&quot;visibilityStateChanged() Suspending playback after going to the background&quot;);
 372             m_mediaSession-&gt;beginInterruption(PlatformMediaSession::EnteringBackground);
 373         }
 374     } else {
 375         if (state() == State::Interrupted) {
 376             RELEASE_LOG_IF_ALLOWED(&quot;visibilityStateChanged() Resuming playback after entering foreground&quot;);
 377             m_mediaSession-&gt;endInterruption(PlatformMediaSession::MayResumePlaying);
 378         }
 379     }
 380 }
 381 
 382 bool AudioContext::wouldTaintOrigin(const URL&amp; url) const
 383 {
 384     if (url.protocolIsData())
 385         return false;
 386 
</pre>
<hr />
<pre>
 391 }
 392 
 393 ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; AudioContext::createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)
 394 {
 395     auto audioBuffer = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);
 396     if (!audioBuffer)
 397         return Exception { NotSupportedError };
 398     return audioBuffer.releaseNonNull();
 399 }
 400 
 401 ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; AudioContext::createBuffer(ArrayBuffer&amp; arrayBuffer, bool mixToMono)
 402 {
 403     auto audioBuffer = AudioBuffer::createFromAudioFileData(arrayBuffer.data(), arrayBuffer.byteLength(), mixToMono, sampleRate());
 404     if (!audioBuffer)
 405         return Exception { SyntaxError };
 406     return audioBuffer.releaseNonNull();
 407 }
 408 
 409 void AudioContext::decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp; audioData, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp; successCallback, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp; errorCallback)
 410 {
<span class="line-modified"> 411     m_audioDecoder.decodeAsync(WTFMove(audioData), sampleRate(), WTFMove(successCallback), WTFMove(errorCallback));</span>


 412 }
 413 
<span class="line-modified"> 414 Ref&lt;AudioBufferSourceNode&gt; AudioContext::createBufferSource()</span>
 415 {


 416     ASSERT(isMainThread());




 417     lazyInitialize();
<span class="line-modified"> 418     Ref&lt;AudioBufferSourceNode&gt; node = AudioBufferSourceNode::create(*this, m_destinationNode-&gt;sampleRate());</span>
 419 
 420     // Because this is an AudioScheduledSourceNode, the context keeps a reference until it has finished playing.
 421     // When this happens, AudioScheduledSourceNode::finish() calls AudioContext::notifyNodeFinishedProcessing().
 422     refNode(node);
 423 
 424     return node;
 425 }
 426 
 427 #if ENABLE(VIDEO)
 428 
 429 ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; AudioContext::createMediaElementSource(HTMLMediaElement&amp; mediaElement)
 430 {


 431     ASSERT(isMainThread());
<span class="line-removed"> 432     lazyInitialize();</span>
 433 
<span class="line-modified"> 434     if (mediaElement.audioSourceNode())</span>
 435         return Exception { InvalidStateError };
 436 


 437     auto node = MediaElementAudioSourceNode::create(*this, mediaElement);
 438 
 439     mediaElement.setAudioSourceNode(node.ptr());
 440 
 441     refNode(node.get()); // context keeps reference until node is disconnected
<span class="line-modified"> 442     return WTFMove(node);</span>
 443 }
 444 
 445 #endif
 446 
 447 #if ENABLE(MEDIA_STREAM)
 448 
 449 ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; AudioContext::createMediaStreamSource(MediaStream&amp; mediaStream)
 450 {


 451     ASSERT(isMainThread());
 452 



 453     auto audioTracks = mediaStream.getAudioTracks();
 454     if (audioTracks.isEmpty())
 455         return Exception { InvalidStateError };
 456 
 457     MediaStreamTrack* providerTrack = nullptr;
 458     for (auto&amp; track : audioTracks) {
 459         if (track-&gt;audioSourceProvider()) {
 460             providerTrack = track.get();
 461             break;
 462         }
 463     }
 464     if (!providerTrack)
 465         return Exception { InvalidStateError };
 466 
 467     lazyInitialize();
 468 
 469     auto node = MediaStreamAudioSourceNode::create(*this, mediaStream, *providerTrack);
 470     node-&gt;setFormat(2, sampleRate());
 471 
 472     refNode(node); // context keeps reference until node is disconnected
<span class="line-modified"> 473     return WTFMove(node);</span>
 474 }
 475 
<span class="line-modified"> 476 Ref&lt;MediaStreamAudioDestinationNode&gt; AudioContext::createMediaStreamDestination()</span>
 477 {



 478     // FIXME: Add support for an optional argument which specifies the number of channels.
 479     // FIXME: The default should probably be stereo instead of mono.
 480     return MediaStreamAudioDestinationNode::create(*this, 1);
 481 }
 482 
 483 #endif
 484 
 485 ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; AudioContext::createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels)
 486 {


 487     ASSERT(isMainThread());




 488     lazyInitialize();
 489 
 490     // W3C Editor&#39;s Draft 06 June 2017
 491     //  https://webaudio.github.io/web-audio-api/#widl-BaseAudioContext-createScriptProcessor-ScriptProcessorNode-unsigned-long-bufferSize-unsigned-long-numberOfInputChannels-unsigned-long-numberOfOutputChannels
 492 
 493     // The bufferSize parameter determines the buffer size in units of sample-frames. If it&#39;s not passed in,
 494     // or if the value is 0, then the implementation will choose the best buffer size for the given environment,
 495     // which will be constant power of 2 throughout the lifetime of the node. ... If the value of this parameter
 496     // is not one of the allowed power-of-2 values listed above, an IndexSizeError must be thrown.
 497     switch (bufferSize) {
 498     case 0:
 499 #if USE(AUDIO_SESSION)
 500         // Pick a value between 256 (2^8) and 16384 (2^14), based on the buffer size of the current AudioSession:
 501         bufferSize = 1 &lt;&lt; std::max&lt;size_t&gt;(8, std::min&lt;size_t&gt;(14, std::log2(AudioSession::sharedSession().bufferSize())));
 502 #else
 503         bufferSize = 2048;
 504 #endif
 505         break;
 506     case 256:
 507     case 512:
</pre>
<hr />
<pre>
 517 
 518     // An IndexSizeError exception must be thrown if bufferSize or numberOfInputChannels or numberOfOutputChannels
 519     // are outside the valid range. It is invalid for both numberOfInputChannels and numberOfOutputChannels to be zero.
 520     // In this case an IndexSizeError must be thrown.
 521 
 522     if (!numberOfInputChannels &amp;&amp; !numberOfOutputChannels)
 523         return Exception { NotSupportedError };
 524 
 525     // This parameter [numberOfInputChannels] determines the number of channels for this node&#39;s input. Values of
 526     // up to 32 must be supported. A NotSupportedError must be thrown if the number of channels is not supported.
 527 
 528     if (numberOfInputChannels &gt; maxNumberOfChannels())
 529         return Exception { NotSupportedError };
 530 
 531     // This parameter [numberOfOutputChannels] determines the number of channels for this node&#39;s output. Values of
 532     // up to 32 must be supported. A NotSupportedError must be thrown if the number of channels is not supported.
 533 
 534     if (numberOfOutputChannels &gt; maxNumberOfChannels())
 535         return Exception { NotSupportedError };
 536 
<span class="line-modified"> 537     auto node = ScriptProcessorNode::create(*this, m_destinationNode-&gt;sampleRate(), bufferSize, numberOfInputChannels, numberOfOutputChannels);</span>
 538 
 539     refNode(node); // context keeps reference until we stop making javascript rendering callbacks
<span class="line-modified"> 540     return WTFMove(node);</span>
 541 }
 542 
<span class="line-modified"> 543 Ref&lt;BiquadFilterNode&gt; AudioContext::createBiquadFilter()</span>
 544 {


 545     ASSERT(isMainThread());



 546     lazyInitialize();
<span class="line-modified"> 547     return BiquadFilterNode::create(*this, m_destinationNode-&gt;sampleRate());</span>

 548 }
 549 
<span class="line-modified"> 550 Ref&lt;WaveShaperNode&gt; AudioContext::createWaveShaper()</span>
 551 {


 552     ASSERT(isMainThread());



 553     lazyInitialize();
 554     return WaveShaperNode::create(*this);
 555 }
 556 
<span class="line-modified"> 557 Ref&lt;PannerNode&gt; AudioContext::createPanner()</span>
 558 {


 559     ASSERT(isMainThread());



 560     lazyInitialize();
<span class="line-modified"> 561     return PannerNode::create(*this, m_destinationNode-&gt;sampleRate());</span>
 562 }
 563 
<span class="line-modified"> 564 Ref&lt;ConvolverNode&gt; AudioContext::createConvolver()</span>
 565 {


 566     ASSERT(isMainThread());



 567     lazyInitialize();
<span class="line-modified"> 568     return ConvolverNode::create(*this, m_destinationNode-&gt;sampleRate());</span>
 569 }
 570 
<span class="line-modified"> 571 Ref&lt;DynamicsCompressorNode&gt; AudioContext::createDynamicsCompressor()</span>
 572 {


 573     ASSERT(isMainThread());



 574     lazyInitialize();
<span class="line-modified"> 575     return DynamicsCompressorNode::create(*this, m_destinationNode-&gt;sampleRate());</span>
 576 }
 577 
<span class="line-modified"> 578 Ref&lt;AnalyserNode&gt; AudioContext::createAnalyser()</span>
 579 {


 580     ASSERT(isMainThread());



 581     lazyInitialize();
<span class="line-modified"> 582     return AnalyserNode::create(*this, m_destinationNode-&gt;sampleRate());</span>
 583 }
 584 
<span class="line-modified"> 585 Ref&lt;GainNode&gt; AudioContext::createGain()</span>
 586 {


 587     ASSERT(isMainThread());



 588     lazyInitialize();
<span class="line-modified"> 589     return GainNode::create(*this, m_destinationNode-&gt;sampleRate());</span>
 590 }
 591 
 592 ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; AudioContext::createDelay(double maxDelayTime)
 593 {


 594     ASSERT(isMainThread());



 595     lazyInitialize();
<span class="line-modified"> 596     return DelayNode::create(*this, m_destinationNode-&gt;sampleRate(), maxDelayTime);</span>
 597 }
 598 
 599 ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; AudioContext::createChannelSplitter(size_t numberOfOutputs)
 600 {


 601     ASSERT(isMainThread());



 602     lazyInitialize();
<span class="line-modified"> 603     auto node = ChannelSplitterNode::create(*this, m_destinationNode-&gt;sampleRate(), numberOfOutputs);</span>
 604     if (!node)
 605         return Exception { IndexSizeError };
 606     return node.releaseNonNull();
 607 }
 608 
 609 ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; AudioContext::createChannelMerger(size_t numberOfInputs)
 610 {


 611     ASSERT(isMainThread());



 612     lazyInitialize();
<span class="line-modified"> 613     auto node = ChannelMergerNode::create(*this, m_destinationNode-&gt;sampleRate(), numberOfInputs);</span>
 614     if (!node)
 615         return Exception { IndexSizeError };
 616     return node.releaseNonNull();
 617 }
 618 
<span class="line-modified"> 619 Ref&lt;OscillatorNode&gt; AudioContext::createOscillator()</span>
 620 {


 621     ASSERT(isMainThread());



 622     lazyInitialize();
 623 
<span class="line-modified"> 624     Ref&lt;OscillatorNode&gt; node = OscillatorNode::create(*this, m_destinationNode-&gt;sampleRate());</span>
 625 
 626     // Because this is an AudioScheduledSourceNode, the context keeps a reference until it has finished playing.
 627     // When this happens, AudioScheduledSourceNode::finish() calls AudioContext::notifyNodeFinishedProcessing().
 628     refNode(node);
 629 
 630     return node;
 631 }
 632 
 633 ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; AudioContext::createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary)
 634 {


 635     ASSERT(isMainThread());



 636     if (real.length() != imaginary.length() || (real.length() &gt; MaxPeriodicWaveLength) || !real.length())
 637         return Exception { IndexSizeError };
 638     lazyInitialize();
 639     return PeriodicWave::create(sampleRate(), real, imaginary);
 640 }
 641 
 642 void AudioContext::notifyNodeFinishedProcessing(AudioNode* node)
 643 {
 644     ASSERT(isAudioThread());
 645     m_finishedNodes.append(node);
 646 }
 647 
 648 void AudioContext::derefFinishedSourceNodes()
 649 {
 650     ASSERT(isGraphOwner());
 651     ASSERT(isAudioThread() || isAudioThreadFinished());
 652     for (auto&amp; node : m_finishedNodes)
 653         derefNode(*node);
 654 
 655     m_finishedNodes.clear();
</pre>
<hr />
<pre>
 945         m_renderingAutomaticPullNodes.resize(m_automaticPullNodes.size());
 946 
 947         unsigned i = 0;
 948         for (auto&amp; output : m_automaticPullNodes)
 949             m_renderingAutomaticPullNodes[i++] = output;
 950 
 951         m_automaticPullNodesNeedUpdating = false;
 952     }
 953 }
 954 
 955 void AudioContext::processAutomaticPullNodes(size_t framesToProcess)
 956 {
 957     ASSERT(isAudioThread());
 958 
 959     for (auto&amp; node : m_renderingAutomaticPullNodes)
 960         node-&gt;processIfNecessary(framesToProcess);
 961 }
 962 
 963 ScriptExecutionContext* AudioContext::scriptExecutionContext() const
 964 {
<span class="line-modified"> 965     return m_isStopScheduled ? 0 : ActiveDOMObject::scriptExecutionContext();</span>
 966 }
 967 
 968 void AudioContext::nodeWillBeginPlayback()
 969 {
 970     // Called by scheduled AudioNodes when clients schedule their start times.
 971     // Prior to the introduction of suspend(), resume(), and stop(), starting
 972     // a scheduled AudioNode would remove the user-gesture restriction, if present,
 973     // and would thus unmute the context. Now that AudioContext stays in the
 974     // &quot;suspended&quot; state if a user-gesture restriction is present, starting a
 975     // schedule AudioNode should set the state to &quot;running&quot;, but only if the
 976     // user-gesture restriction is set.
 977     if (userGestureRequiredForAudioStart())
 978         startRendering();
 979 }
 980 
 981 bool AudioContext::willBeginPlayback()
 982 {



 983     if (userGestureRequiredForAudioStart()) {
<span class="line-modified"> 984         if (!processingUserGestureForMedia() &amp;&amp; !document()-&gt;isCapturing())</span>

 985             return false;

 986         removeBehaviorRestriction(AudioContext::RequireUserGestureForAudioStartRestriction);
 987     }
 988 
 989     if (pageConsentRequiredForAudioStart()) {
 990         Page* page = document()-&gt;page();
 991         if (page &amp;&amp; !page-&gt;canStartMedia()) {
 992             document()-&gt;addMediaCanStartListener(*this);

 993             return false;
 994         }
 995         removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
 996     }
 997 
<span class="line-modified"> 998     return m_mediaSession-&gt;clientWillBeginPlayback();</span>



 999 }
1000 
1001 bool AudioContext::willPausePlayback()
1002 {



1003     if (userGestureRequiredForAudioStart()) {
1004         if (!processingUserGestureForMedia())
1005             return false;
1006         removeBehaviorRestriction(AudioContext::RequireUserGestureForAudioStartRestriction);
1007     }
1008 
1009     if (pageConsentRequiredForAudioStart()) {
1010         Page* page = document()-&gt;page();
1011         if (page &amp;&amp; !page-&gt;canStartMedia()) {
1012             document()-&gt;addMediaCanStartListener(*this);
1013             return false;
1014         }
1015         removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1016     }
1017 
1018     return m_mediaSession-&gt;clientWillPausePlayback();
1019 }
1020 
1021 void AudioContext::startRendering()
1022 {
<span class="line-modified">1023     if (!willBeginPlayback())</span>

1024         return;
1025 


1026     destination()-&gt;startRendering();
1027     setState(State::Running);
1028 }
1029 
1030 void AudioContext::mediaCanStart(Document&amp; document)
1031 {
1032     ASSERT_UNUSED(document, &amp;document == this-&gt;document());
1033     removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1034     mayResumePlayback(true);
1035 }
1036 
1037 MediaProducer::MediaStateFlags AudioContext::mediaState() const
1038 {
1039     if (!m_isStopScheduled &amp;&amp; m_destinationNode &amp;&amp; m_destinationNode-&gt;isPlayingAudio())
1040         return MediaProducer::IsPlayingAudio;
1041 
1042     return MediaProducer::IsNotPlaying;
1043 }
1044 
1045 void AudioContext::pageMutedStateDidChange()
1046 {
<span class="line-modified">1047     if (m_destinationNode &amp;&amp; document()-&gt;page())</span>
1048         m_destinationNode-&gt;setMuted(document()-&gt;page()-&gt;isAudioMuted());
1049 }
1050 
1051 void AudioContext::isPlayingAudioDidChange()
1052 {
1053     // Make sure to call Document::updateIsPlayingMedia() on the main thread, since
1054     // we could be on the audio I/O thread here and the call into WebCore could block.
1055     callOnMainThread([protectedThis = makeRef(*this)] {
1056         if (protectedThis-&gt;document())
1057             protectedThis-&gt;document()-&gt;updateIsPlayingMedia();
1058     });
1059 }
1060 
<span class="line-modified">1061 void AudioContext::fireCompletionEvent()</span>
1062 {

1063     ASSERT(isMainThread());
1064     if (!isMainThread())
1065         return;
1066 










1067     AudioBuffer* renderedBuffer = m_renderTarget.get();
1068     setState(State::Closed);
1069 
1070     ASSERT(renderedBuffer);
1071     if (!renderedBuffer)
1072         return;
1073 
1074     // Avoid firing the event if the document has already gone away.
<span class="line-modified">1075     if (scriptExecutionContext()) {</span>
<span class="line-modified">1076         // Call the offline rendering completion event listener.</span>
<span class="line-modified">1077         m_eventQueue-&gt;enqueueEvent(OfflineAudioCompletionEvent::create(renderedBuffer));</span>
<span class="line-modified">1078     }</span>








1079 }
1080 
1081 void AudioContext::incrementActiveSourceCount()
1082 {
1083     ++m_activeSourceCount;
1084 }
1085 
1086 void AudioContext::decrementActiveSourceCount()
1087 {
1088     --m_activeSourceCount;
1089 }
1090 
1091 void AudioContext::suspend(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1092 {
<span class="line-modified">1093     if (isOfflineContext()) {</span>
1094         promise.reject(InvalidStateError);
1095         return;
1096     }
1097 
1098     if (m_state == State::Suspended) {
1099         promise.resolve();
1100         return;
1101     }
1102 
1103     if (m_state == State::Closed || m_state == State::Interrupted || !m_destinationNode) {
1104         promise.reject();
1105         return;
1106     }
1107 
1108     addReaction(State::Suspended, WTFMove(promise));
1109 
1110     if (!willPausePlayback())
1111         return;
1112 
1113     lazyInitialize();
1114 
1115     m_destinationNode-&gt;suspend([this, protectedThis = makeRef(*this)] {
1116         setState(State::Suspended);
1117     });
1118 }
1119 
1120 void AudioContext::resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1121 {
<span class="line-modified">1122     if (isOfflineContext()) {</span>
1123         promise.reject(InvalidStateError);
1124         return;
1125     }
1126 
1127     if (m_state == State::Running) {
1128         promise.resolve();
1129         return;
1130     }
1131 
1132     if (m_state == State::Closed || !m_destinationNode) {
1133         promise.reject();
1134         return;
1135     }
1136 
1137     addReaction(State::Running, WTFMove(promise));
1138 
1139     if (!willBeginPlayback())
1140         return;
1141 
1142     lazyInitialize();
1143 
1144     m_destinationNode-&gt;resume([this, protectedThis = makeRef(*this)] {
1145         setState(State::Running);
1146     });
1147 }
1148 
1149 void AudioContext::close(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1150 {
<span class="line-modified">1151     if (isOfflineContext()) {</span>
1152         promise.reject(InvalidStateError);
1153         return;
1154     }
1155 
1156     if (m_state == State::Closed || !m_destinationNode) {
1157         promise.resolve();
1158         return;
1159     }
1160 
1161     addReaction(State::Closed, WTFMove(promise));
1162 
1163     lazyInitialize();
1164 
1165     m_destinationNode-&gt;close([this, protectedThis = makeRef(*this)] {
1166         setState(State::Closed);
1167         uninitialize();
1168     });
1169 }
1170 
1171 
</pre>
<hr />
<pre>
1191 void AudioContext::mayResumePlayback(bool shouldResume)
1192 {
1193     if (!m_destinationNode || m_state == State::Closed || m_state == State::Running)
1194         return;
1195 
1196     if (!shouldResume) {
1197         setState(State::Suspended);
1198         return;
1199     }
1200 
1201     if (!willBeginPlayback())
1202         return;
1203 
1204     lazyInitialize();
1205 
1206     m_destinationNode-&gt;resume([this, protectedThis = makeRef(*this)] {
1207         setState(State::Running);
1208     });
1209 }
1210 










































1211 
1212 } // namespace WebCore
1213 
1214 #endif // ENABLE(WEB_AUDIO)
</pre>
</td>
<td>
<hr />
<pre>
  78 #if ENABLE(VIDEO)
  79 #include &quot;HTMLMediaElement.h&quot;
  80 #include &quot;MediaElementAudioSourceNode.h&quot;
  81 #endif
  82 
  83 #if DEBUG_AUDIONODE_REFERENCES
  84 #include &lt;stdio.h&gt;
  85 #endif
  86 
  87 #if USE(GSTREAMER)
  88 #include &quot;GStreamerCommon.h&quot;
  89 #endif
  90 
  91 #if PLATFORM(IOS_FAMILY)
  92 #include &quot;ScriptController.h&quot;
  93 #include &quot;Settings.h&quot;
  94 #endif
  95 
  96 #include &lt;JavaScriptCore/ArrayBuffer.h&gt;
  97 #include &lt;wtf/Atomics.h&gt;
<span class="line-added">  98 #include &lt;wtf/IsoMallocInlines.h&gt;</span>
  99 #include &lt;wtf/MainThread.h&gt;
 100 #include &lt;wtf/Ref.h&gt;
 101 #include &lt;wtf/RefCounted.h&gt;
<span class="line-added"> 102 #include &lt;wtf/Scope.h&gt;</span>
 103 #include &lt;wtf/text/WTFString.h&gt;
 104 
 105 const unsigned MaxPeriodicWaveLength = 4096;
 106 
 107 namespace WebCore {
 108 
<span class="line-modified"> 109 WTF_MAKE_ISO_ALLOCATED_IMPL(AudioContext);</span>
<span class="line-added"> 110 </span>
<span class="line-added"> 111 #define RELEASE_LOG_IF_ALLOWED(fmt, ...) RELEASE_LOG_IF(document() &amp;&amp; document()-&gt;page() &amp;&amp; document()-&gt;page()-&gt;isAlwaysOnLoggingAllowed(), Media, &quot;%p - AudioContext::&quot; fmt, this, ##__VA_ARGS__)</span>
 112 
 113 bool AudioContext::isSampleRateRangeGood(float sampleRate)
 114 {
 115     // FIXME: It would be nice if the minimum sample-rate could be less than 44.1KHz,
 116     // but that will require some fixes in HRTFPanner::fftSizeForSampleRate(), and some testing there.
 117     return sampleRate &gt;= 44100 &amp;&amp; sampleRate &lt;= 96000;
 118 }
 119 
 120 // Don&#39;t allow more than this number of simultaneous AudioContexts talking to hardware.
 121 const unsigned MaxHardwareContexts = 4;
 122 unsigned AudioContext::s_hardwareContextCount = 0;
 123 
 124 RefPtr&lt;AudioContext&gt; AudioContext::create(Document&amp; document)
 125 {
 126     ASSERT(isMainThread());
 127     if (s_hardwareContextCount &gt;= MaxHardwareContexts)
 128         return nullptr;
 129 
 130     RefPtr&lt;AudioContext&gt; audioContext(adoptRef(new AudioContext(document)));
 131     audioContext-&gt;suspendIfNeeded();
 132     return audioContext;
 133 }
 134 
 135 // Constructor for rendering to the audio hardware.
 136 AudioContext::AudioContext(Document&amp; document)
 137     : ActiveDOMObject(document)
<span class="line-added"> 138 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added"> 139     , m_logger(document.logger())</span>
<span class="line-added"> 140     , m_logIdentifier(uniqueLogIdentifier())</span>
<span class="line-added"> 141 #endif</span>
 142     , m_mediaSession(PlatformMediaSession::create(*this))
<span class="line-modified"> 143     , m_eventQueue(makeUnique&lt;GenericEventQueue&gt;(*this))</span>
 144 {
<span class="line-added"> 145     // According to spec AudioContext must die only after page navigate.</span>
<span class="line-added"> 146     // Lets mark it as ActiveDOMObject with pending activity and unmark it in clear method.</span>
<span class="line-added"> 147     makePendingActivity();</span>
<span class="line-added"> 148 </span>
 149     constructCommon();
 150 
 151     m_destinationNode = DefaultAudioDestinationNode::create(*this);
 152 
 153     // Initialize the destination node&#39;s muted state to match the page&#39;s current muted state.
 154     pageMutedStateDidChange();
<span class="line-added"> 155 </span>
<span class="line-added"> 156     document.addAudioProducer(*this);</span>
<span class="line-added"> 157     document.registerForVisibilityStateChangedCallbacks(*this);</span>
 158 }
 159 
 160 // Constructor for offline (non-realtime) rendering.
 161 AudioContext::AudioContext(Document&amp; document, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)
 162     : ActiveDOMObject(document)
<span class="line-added"> 163 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added"> 164     , m_logger(document.logger())</span>
<span class="line-added"> 165     , m_logIdentifier(uniqueLogIdentifier())</span>
<span class="line-added"> 166 #endif</span>
 167     , m_isOfflineContext(true)
 168     , m_mediaSession(PlatformMediaSession::create(*this))
<span class="line-modified"> 169     , m_eventQueue(makeUnique&lt;GenericEventQueue&gt;(*this))</span>
 170 {
 171     constructCommon();
 172 
 173     // Create a new destination for offline rendering.
 174     m_renderTarget = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);
 175     m_destinationNode = OfflineAudioDestinationNode::create(*this, m_renderTarget.get());
 176 }
 177 
 178 void AudioContext::constructCommon()
 179 {




 180     FFTFrame::initialize();
 181 
 182     m_listener = AudioListener::create();
 183 
<span class="line-added"> 184     ASSERT(document());</span>
 185     if (document()-&gt;audioPlaybackRequiresUserGesture())
 186         addBehaviorRestriction(RequireUserGestureForAudioStartRestriction);
 187     else
 188         m_restrictions = NoRestrictions;
 189 
 190 #if PLATFORM(COCOA)
 191     addBehaviorRestriction(RequirePageConsentForAudioStartRestriction);
 192 #endif
 193 }
 194 
 195 AudioContext::~AudioContext()
 196 {
 197 #if DEBUG_AUDIONODE_REFERENCES
 198     fprintf(stderr, &quot;%p: AudioContext::~AudioContext()\n&quot;, this);
 199 #endif
 200     ASSERT(!m_isInitialized);
 201     ASSERT(m_isStopScheduled);
 202     ASSERT(m_nodesToDelete.isEmpty());
 203     ASSERT(m_referencedNodes.isEmpty());
 204     ASSERT(m_finishedNodes.isEmpty()); // FIXME (bug 105870): This assertion fails on tests sometimes.
 205     ASSERT(m_automaticPullNodes.isEmpty());
 206     if (m_automaticPullNodesNeedUpdating)
 207         m_renderingAutomaticPullNodes.resize(m_automaticPullNodes.size());
 208     ASSERT(m_renderingAutomaticPullNodes.isEmpty());
 209     // FIXME: Can we assert that m_deferredFinishDerefList is empty?
<span class="line-added"> 210 </span>
<span class="line-added"> 211     if (!isOfflineContext() &amp;&amp; scriptExecutionContext()) {</span>
<span class="line-added"> 212         document()-&gt;removeAudioProducer(*this);</span>
<span class="line-added"> 213         document()-&gt;unregisterForVisibilityStateChangedCallbacks(*this);</span>
<span class="line-added"> 214     }</span>
 215 }
 216 
 217 void AudioContext::lazyInitialize()
 218 {
<span class="line-added"> 219     ASSERT(!m_isStopScheduled);</span>
<span class="line-added"> 220 </span>
 221     if (m_isInitialized)
 222         return;
 223 
 224     // Don&#39;t allow the context to initialize a second time after it&#39;s already been explicitly uninitialized.
 225     ASSERT(!m_isAudioThreadFinished);
 226     if (m_isAudioThreadFinished)
 227         return;
 228 
 229     if (m_destinationNode) {
 230         m_destinationNode-&gt;initialize();
 231 
 232         if (!isOfflineContext()) {



 233             // This starts the audio thread. The destination node&#39;s provideInput() method will now be called repeatedly to render audio.
 234             // Each time provideInput() is called, a portion of the audio stream is rendered. Let&#39;s call this time period a &quot;render quantum&quot;.
 235             // NOTE: for now default AudioContext does not need an explicit startRendering() call from JavaScript.
 236             // We may want to consider requiring it for symmetry with OfflineAudioContext.
 237             startRendering();
 238             ++s_hardwareContextCount;
 239         }
 240     }
 241     m_isInitialized = true;
 242 }
 243 
 244 void AudioContext::clear()
 245 {
<span class="line-added"> 246     Ref&lt;AudioContext&gt; protectedThis(*this);</span>
<span class="line-added"> 247 </span>
 248     // We have to release our reference to the destination node before the context will ever be deleted since the destination node holds a reference to the context.
 249     if (m_destinationNode)
 250         m_destinationNode = nullptr;
 251 
 252     // Audio thread is dead. Nobody will schedule node deletion action. Let&#39;s do it ourselves.
 253     do {
 254         deleteMarkedNodes();
 255         m_nodesToDelete.appendVector(m_nodesMarkedForDeletion);
 256         m_nodesMarkedForDeletion.clear();
 257     } while (m_nodesToDelete.size());
 258 
<span class="line-modified"> 259     clearPendingActivity();</span>

 260 }
 261 
 262 void AudioContext::uninitialize()
 263 {
<span class="line-added"> 264     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 265 </span>
 266     ASSERT(isMainThread());
 267 
 268     if (!m_isInitialized)
 269         return;
 270 
 271     // This stops the audio thread and all audio rendering.
<span class="line-modified"> 272     if (m_destinationNode)</span>
<span class="line-added"> 273         m_destinationNode-&gt;uninitialize();</span>
 274 
 275     // Don&#39;t allow the context to initialize a second time after it&#39;s already been explicitly uninitialized.
 276     m_isAudioThreadFinished = true;
 277 
 278     if (!isOfflineContext()) {



 279         ASSERT(s_hardwareContextCount);
 280         --s_hardwareContextCount;
 281 
 282         // Offline contexts move to &#39;Closed&#39; state when dispatching the completion event.
 283         setState(State::Closed);
 284     }
 285 
 286     // Get rid of the sources which may still be playing.
 287     derefUnfinishedSourceNodes();
 288 
 289     m_isInitialized = false;
 290 }
 291 
 292 bool AudioContext::isInitialized() const
 293 {
 294     return m_isInitialized;
 295 }
 296 
 297 void AudioContext::addReaction(State state, DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
 298 {
</pre>
<hr />
<pre>
 307 {
 308     if (m_state == state)
 309         return;
 310 
 311     m_state = state;
 312     m_eventQueue-&gt;enqueueEvent(Event::create(eventNames().statechangeEvent, Event::CanBubble::Yes, Event::IsCancelable::No));
 313 
 314     size_t stateIndex = static_cast&lt;size_t&gt;(state);
 315     if (stateIndex &gt;= m_stateReactions.size())
 316         return;
 317 
 318     Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt; reactions;
 319     m_stateReactions[stateIndex].swap(reactions);
 320 
 321     for (auto&amp; promise : reactions)
 322         promise.resolve();
 323 }
 324 
 325 void AudioContext::stop()
 326 {
<span class="line-added"> 327     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 328 </span>
 329     ASSERT(isMainThread());
 330 
 331     // Usually ScriptExecutionContext calls stop twice.
 332     if (m_isStopScheduled)
 333         return;
 334     m_isStopScheduled = true;
 335 
<span class="line-added"> 336     ASSERT(document());</span>
 337     document()-&gt;updateIsPlayingMedia();
 338 
 339     m_eventQueue-&gt;close();
 340 
 341     uninitialize();
 342     clear();
 343 }
 344 
 345 bool AudioContext::canSuspendForDocumentSuspension() const
 346 {
 347     // FIXME: We should be able to suspend while rendering as well with some more code.
 348     return m_state == State::Suspended || m_state == State::Closed;
 349 }
 350 
 351 const char* AudioContext::activeDOMObjectName() const
 352 {
 353     return &quot;AudioContext&quot;;
 354 }
 355 
 356 Document* AudioContext::document() const
 357 {

 358     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 359 }
 360 
 361 Document* AudioContext::hostingDocument() const
 362 {
 363     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 364 }
 365 
 366 String AudioContext::sourceApplicationIdentifier() const
 367 {
 368     Document* document = this-&gt;document();
 369     if (Frame* frame = document ? document-&gt;frame() : nullptr) {
 370         if (NetworkingContext* networkingContext = frame-&gt;loader().networkingContext())
 371             return networkingContext-&gt;sourceApplicationIdentifier();
 372     }
 373     return emptyString();
 374 }
 375 
 376 bool AudioContext::processingUserGestureForMedia() const
 377 {
 378     return document() ? document()-&gt;processingUserGestureForMedia() : false;
 379 }
 380 
 381 bool AudioContext::isSuspended() const
 382 {
 383     return !document() || document()-&gt;activeDOMObjectsAreSuspended() || document()-&gt;activeDOMObjectsAreStopped();
 384 }
 385 
 386 void AudioContext::visibilityStateChanged()
 387 {
 388     // Do not suspend if audio is audible.
<span class="line-modified"> 389     if (!document() || mediaState() == MediaProducer::IsPlayingAudio || m_isStopScheduled)</span>
 390         return;
 391 
 392     if (document()-&gt;hidden()) {
 393         if (state() == State::Running) {
 394             RELEASE_LOG_IF_ALLOWED(&quot;visibilityStateChanged() Suspending playback after going to the background&quot;);
 395             m_mediaSession-&gt;beginInterruption(PlatformMediaSession::EnteringBackground);
 396         }
 397     } else {
 398         if (state() == State::Interrupted) {
 399             RELEASE_LOG_IF_ALLOWED(&quot;visibilityStateChanged() Resuming playback after entering foreground&quot;);
 400             m_mediaSession-&gt;endInterruption(PlatformMediaSession::MayResumePlaying);
 401         }
 402     }
 403 }
 404 
 405 bool AudioContext::wouldTaintOrigin(const URL&amp; url) const
 406 {
 407     if (url.protocolIsData())
 408         return false;
 409 
</pre>
<hr />
<pre>
 414 }
 415 
 416 ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; AudioContext::createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)
 417 {
 418     auto audioBuffer = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);
 419     if (!audioBuffer)
 420         return Exception { NotSupportedError };
 421     return audioBuffer.releaseNonNull();
 422 }
 423 
 424 ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; AudioContext::createBuffer(ArrayBuffer&amp; arrayBuffer, bool mixToMono)
 425 {
 426     auto audioBuffer = AudioBuffer::createFromAudioFileData(arrayBuffer.data(), arrayBuffer.byteLength(), mixToMono, sampleRate());
 427     if (!audioBuffer)
 428         return Exception { SyntaxError };
 429     return audioBuffer.releaseNonNull();
 430 }
 431 
 432 void AudioContext::decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp; audioData, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp; successCallback, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp; errorCallback)
 433 {
<span class="line-modified"> 434     if (!m_audioDecoder)</span>
<span class="line-added"> 435         m_audioDecoder = makeUnique&lt;AsyncAudioDecoder&gt;();</span>
<span class="line-added"> 436     m_audioDecoder-&gt;decodeAsync(WTFMove(audioData), sampleRate(), WTFMove(successCallback), WTFMove(errorCallback));</span>
 437 }
 438 
<span class="line-modified"> 439 ExceptionOr&lt;Ref&lt;AudioBufferSourceNode&gt;&gt; AudioContext::createBufferSource()</span>
 440 {
<span class="line-added"> 441     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 442 </span>
 443     ASSERT(isMainThread());
<span class="line-added"> 444 </span>
<span class="line-added"> 445     if (m_isStopScheduled)</span>
<span class="line-added"> 446         return Exception { InvalidStateError };</span>
<span class="line-added"> 447 </span>
 448     lazyInitialize();
<span class="line-modified"> 449     Ref&lt;AudioBufferSourceNode&gt; node = AudioBufferSourceNode::create(*this, sampleRate());</span>
 450 
 451     // Because this is an AudioScheduledSourceNode, the context keeps a reference until it has finished playing.
 452     // When this happens, AudioScheduledSourceNode::finish() calls AudioContext::notifyNodeFinishedProcessing().
 453     refNode(node);
 454 
 455     return node;
 456 }
 457 
 458 #if ENABLE(VIDEO)
 459 
 460 ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; AudioContext::createMediaElementSource(HTMLMediaElement&amp; mediaElement)
 461 {
<span class="line-added"> 462     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 463 </span>
 464     ASSERT(isMainThread());

 465 
<span class="line-modified"> 466     if (m_isStopScheduled || mediaElement.audioSourceNode())</span>
 467         return Exception { InvalidStateError };
 468 
<span class="line-added"> 469     lazyInitialize();</span>
<span class="line-added"> 470 </span>
 471     auto node = MediaElementAudioSourceNode::create(*this, mediaElement);
 472 
 473     mediaElement.setAudioSourceNode(node.ptr());
 474 
 475     refNode(node.get()); // context keeps reference until node is disconnected
<span class="line-modified"> 476     return node;</span>
 477 }
 478 
 479 #endif
 480 
 481 #if ENABLE(MEDIA_STREAM)
 482 
 483 ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; AudioContext::createMediaStreamSource(MediaStream&amp; mediaStream)
 484 {
<span class="line-added"> 485     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 486 </span>
 487     ASSERT(isMainThread());
 488 
<span class="line-added"> 489     if (m_isStopScheduled)</span>
<span class="line-added"> 490         return Exception { InvalidStateError };</span>
<span class="line-added"> 491 </span>
 492     auto audioTracks = mediaStream.getAudioTracks();
 493     if (audioTracks.isEmpty())
 494         return Exception { InvalidStateError };
 495 
 496     MediaStreamTrack* providerTrack = nullptr;
 497     for (auto&amp; track : audioTracks) {
 498         if (track-&gt;audioSourceProvider()) {
 499             providerTrack = track.get();
 500             break;
 501         }
 502     }
 503     if (!providerTrack)
 504         return Exception { InvalidStateError };
 505 
 506     lazyInitialize();
 507 
 508     auto node = MediaStreamAudioSourceNode::create(*this, mediaStream, *providerTrack);
 509     node-&gt;setFormat(2, sampleRate());
 510 
 511     refNode(node); // context keeps reference until node is disconnected
<span class="line-modified"> 512     return node;</span>
 513 }
 514 
<span class="line-modified"> 515 ExceptionOr&lt;Ref&lt;MediaStreamAudioDestinationNode&gt;&gt; AudioContext::createMediaStreamDestination()</span>
 516 {
<span class="line-added"> 517     if (m_isStopScheduled)</span>
<span class="line-added"> 518         return Exception { InvalidStateError };</span>
<span class="line-added"> 519 </span>
 520     // FIXME: Add support for an optional argument which specifies the number of channels.
 521     // FIXME: The default should probably be stereo instead of mono.
 522     return MediaStreamAudioDestinationNode::create(*this, 1);
 523 }
 524 
 525 #endif
 526 
 527 ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; AudioContext::createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels)
 528 {
<span class="line-added"> 529     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 530 </span>
 531     ASSERT(isMainThread());
<span class="line-added"> 532 </span>
<span class="line-added"> 533     if (m_isStopScheduled)</span>
<span class="line-added"> 534         return Exception { InvalidStateError };</span>
<span class="line-added"> 535 </span>
 536     lazyInitialize();
 537 
 538     // W3C Editor&#39;s Draft 06 June 2017
 539     //  https://webaudio.github.io/web-audio-api/#widl-BaseAudioContext-createScriptProcessor-ScriptProcessorNode-unsigned-long-bufferSize-unsigned-long-numberOfInputChannels-unsigned-long-numberOfOutputChannels
 540 
 541     // The bufferSize parameter determines the buffer size in units of sample-frames. If it&#39;s not passed in,
 542     // or if the value is 0, then the implementation will choose the best buffer size for the given environment,
 543     // which will be constant power of 2 throughout the lifetime of the node. ... If the value of this parameter
 544     // is not one of the allowed power-of-2 values listed above, an IndexSizeError must be thrown.
 545     switch (bufferSize) {
 546     case 0:
 547 #if USE(AUDIO_SESSION)
 548         // Pick a value between 256 (2^8) and 16384 (2^14), based on the buffer size of the current AudioSession:
 549         bufferSize = 1 &lt;&lt; std::max&lt;size_t&gt;(8, std::min&lt;size_t&gt;(14, std::log2(AudioSession::sharedSession().bufferSize())));
 550 #else
 551         bufferSize = 2048;
 552 #endif
 553         break;
 554     case 256:
 555     case 512:
</pre>
<hr />
<pre>
 565 
 566     // An IndexSizeError exception must be thrown if bufferSize or numberOfInputChannels or numberOfOutputChannels
 567     // are outside the valid range. It is invalid for both numberOfInputChannels and numberOfOutputChannels to be zero.
 568     // In this case an IndexSizeError must be thrown.
 569 
 570     if (!numberOfInputChannels &amp;&amp; !numberOfOutputChannels)
 571         return Exception { NotSupportedError };
 572 
 573     // This parameter [numberOfInputChannels] determines the number of channels for this node&#39;s input. Values of
 574     // up to 32 must be supported. A NotSupportedError must be thrown if the number of channels is not supported.
 575 
 576     if (numberOfInputChannels &gt; maxNumberOfChannels())
 577         return Exception { NotSupportedError };
 578 
 579     // This parameter [numberOfOutputChannels] determines the number of channels for this node&#39;s output. Values of
 580     // up to 32 must be supported. A NotSupportedError must be thrown if the number of channels is not supported.
 581 
 582     if (numberOfOutputChannels &gt; maxNumberOfChannels())
 583         return Exception { NotSupportedError };
 584 
<span class="line-modified"> 585     auto node = ScriptProcessorNode::create(*this, sampleRate(), bufferSize, numberOfInputChannels, numberOfOutputChannels);</span>
 586 
 587     refNode(node); // context keeps reference until we stop making javascript rendering callbacks
<span class="line-modified"> 588     return node;</span>
 589 }
 590 
<span class="line-modified"> 591 ExceptionOr&lt;Ref&lt;BiquadFilterNode&gt;&gt; AudioContext::createBiquadFilter()</span>
 592 {
<span class="line-added"> 593     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 594 </span>
 595     ASSERT(isMainThread());
<span class="line-added"> 596     if (m_isStopScheduled)</span>
<span class="line-added"> 597         return Exception { InvalidStateError };</span>
<span class="line-added"> 598 </span>
 599     lazyInitialize();
<span class="line-modified"> 600 </span>
<span class="line-added"> 601     return BiquadFilterNode::create(*this, sampleRate());</span>
 602 }
 603 
<span class="line-modified"> 604 ExceptionOr&lt;Ref&lt;WaveShaperNode&gt;&gt; AudioContext::createWaveShaper()</span>
 605 {
<span class="line-added"> 606     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 607 </span>
 608     ASSERT(isMainThread());
<span class="line-added"> 609     if (m_isStopScheduled)</span>
<span class="line-added"> 610         return Exception { InvalidStateError };</span>
<span class="line-added"> 611 </span>
 612     lazyInitialize();
 613     return WaveShaperNode::create(*this);
 614 }
 615 
<span class="line-modified"> 616 ExceptionOr&lt;Ref&lt;PannerNode&gt;&gt; AudioContext::createPanner()</span>
 617 {
<span class="line-added"> 618     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 619 </span>
 620     ASSERT(isMainThread());
<span class="line-added"> 621     if (m_isStopScheduled)</span>
<span class="line-added"> 622         return Exception { InvalidStateError };</span>
<span class="line-added"> 623 </span>
 624     lazyInitialize();
<span class="line-modified"> 625     return PannerNode::create(*this, sampleRate());</span>
 626 }
 627 
<span class="line-modified"> 628 ExceptionOr&lt;Ref&lt;ConvolverNode&gt;&gt; AudioContext::createConvolver()</span>
 629 {
<span class="line-added"> 630     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 631 </span>
 632     ASSERT(isMainThread());
<span class="line-added"> 633     if (m_isStopScheduled)</span>
<span class="line-added"> 634         return Exception { InvalidStateError };</span>
<span class="line-added"> 635 </span>
 636     lazyInitialize();
<span class="line-modified"> 637     return ConvolverNode::create(*this, sampleRate());</span>
 638 }
 639 
<span class="line-modified"> 640 ExceptionOr&lt;Ref&lt;DynamicsCompressorNode&gt;&gt; AudioContext::createDynamicsCompressor()</span>
 641 {
<span class="line-added"> 642     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 643 </span>
 644     ASSERT(isMainThread());
<span class="line-added"> 645     if (m_isStopScheduled)</span>
<span class="line-added"> 646         return Exception { InvalidStateError };</span>
<span class="line-added"> 647 </span>
 648     lazyInitialize();
<span class="line-modified"> 649     return DynamicsCompressorNode::create(*this, sampleRate());</span>
 650 }
 651 
<span class="line-modified"> 652 ExceptionOr&lt;Ref&lt;AnalyserNode&gt;&gt; AudioContext::createAnalyser()</span>
 653 {
<span class="line-added"> 654     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 655 </span>
 656     ASSERT(isMainThread());
<span class="line-added"> 657     if (m_isStopScheduled)</span>
<span class="line-added"> 658         return Exception { InvalidStateError };</span>
<span class="line-added"> 659 </span>
 660     lazyInitialize();
<span class="line-modified"> 661     return AnalyserNode::create(*this, sampleRate());</span>
 662 }
 663 
<span class="line-modified"> 664 ExceptionOr&lt;Ref&lt;GainNode&gt;&gt; AudioContext::createGain()</span>
 665 {
<span class="line-added"> 666     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 667 </span>
 668     ASSERT(isMainThread());
<span class="line-added"> 669     if (m_isStopScheduled)</span>
<span class="line-added"> 670         return Exception { InvalidStateError };</span>
<span class="line-added"> 671 </span>
 672     lazyInitialize();
<span class="line-modified"> 673     return GainNode::create(*this, sampleRate());</span>
 674 }
 675 
 676 ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; AudioContext::createDelay(double maxDelayTime)
 677 {
<span class="line-added"> 678     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 679 </span>
 680     ASSERT(isMainThread());
<span class="line-added"> 681     if (m_isStopScheduled)</span>
<span class="line-added"> 682         return Exception { InvalidStateError };</span>
<span class="line-added"> 683 </span>
 684     lazyInitialize();
<span class="line-modified"> 685     return DelayNode::create(*this, sampleRate(), maxDelayTime);</span>
 686 }
 687 
 688 ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; AudioContext::createChannelSplitter(size_t numberOfOutputs)
 689 {
<span class="line-added"> 690     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 691 </span>
 692     ASSERT(isMainThread());
<span class="line-added"> 693     if (m_isStopScheduled)</span>
<span class="line-added"> 694         return Exception { InvalidStateError };</span>
<span class="line-added"> 695 </span>
 696     lazyInitialize();
<span class="line-modified"> 697     auto node = ChannelSplitterNode::create(*this, sampleRate(), numberOfOutputs);</span>
 698     if (!node)
 699         return Exception { IndexSizeError };
 700     return node.releaseNonNull();
 701 }
 702 
 703 ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; AudioContext::createChannelMerger(size_t numberOfInputs)
 704 {
<span class="line-added"> 705     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 706 </span>
 707     ASSERT(isMainThread());
<span class="line-added"> 708     if (m_isStopScheduled)</span>
<span class="line-added"> 709         return Exception { InvalidStateError };</span>
<span class="line-added"> 710 </span>
 711     lazyInitialize();
<span class="line-modified"> 712     auto node = ChannelMergerNode::create(*this, sampleRate(), numberOfInputs);</span>
 713     if (!node)
 714         return Exception { IndexSizeError };
 715     return node.releaseNonNull();
 716 }
 717 
<span class="line-modified"> 718 ExceptionOr&lt;Ref&lt;OscillatorNode&gt;&gt; AudioContext::createOscillator()</span>
 719 {
<span class="line-added"> 720     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 721 </span>
 722     ASSERT(isMainThread());
<span class="line-added"> 723     if (m_isStopScheduled)</span>
<span class="line-added"> 724         return Exception { InvalidStateError };</span>
<span class="line-added"> 725 </span>
 726     lazyInitialize();
 727 
<span class="line-modified"> 728     Ref&lt;OscillatorNode&gt; node = OscillatorNode::create(*this, sampleRate());</span>
 729 
 730     // Because this is an AudioScheduledSourceNode, the context keeps a reference until it has finished playing.
 731     // When this happens, AudioScheduledSourceNode::finish() calls AudioContext::notifyNodeFinishedProcessing().
 732     refNode(node);
 733 
 734     return node;
 735 }
 736 
 737 ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; AudioContext::createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary)
 738 {
<span class="line-added"> 739     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added"> 740 </span>
 741     ASSERT(isMainThread());
<span class="line-added"> 742     if (m_isStopScheduled)</span>
<span class="line-added"> 743         return Exception { InvalidStateError };</span>
<span class="line-added"> 744 </span>
 745     if (real.length() != imaginary.length() || (real.length() &gt; MaxPeriodicWaveLength) || !real.length())
 746         return Exception { IndexSizeError };
 747     lazyInitialize();
 748     return PeriodicWave::create(sampleRate(), real, imaginary);
 749 }
 750 
 751 void AudioContext::notifyNodeFinishedProcessing(AudioNode* node)
 752 {
 753     ASSERT(isAudioThread());
 754     m_finishedNodes.append(node);
 755 }
 756 
 757 void AudioContext::derefFinishedSourceNodes()
 758 {
 759     ASSERT(isGraphOwner());
 760     ASSERT(isAudioThread() || isAudioThreadFinished());
 761     for (auto&amp; node : m_finishedNodes)
 762         derefNode(*node);
 763 
 764     m_finishedNodes.clear();
</pre>
<hr />
<pre>
1054         m_renderingAutomaticPullNodes.resize(m_automaticPullNodes.size());
1055 
1056         unsigned i = 0;
1057         for (auto&amp; output : m_automaticPullNodes)
1058             m_renderingAutomaticPullNodes[i++] = output;
1059 
1060         m_automaticPullNodesNeedUpdating = false;
1061     }
1062 }
1063 
1064 void AudioContext::processAutomaticPullNodes(size_t framesToProcess)
1065 {
1066     ASSERT(isAudioThread());
1067 
1068     for (auto&amp; node : m_renderingAutomaticPullNodes)
1069         node-&gt;processIfNecessary(framesToProcess);
1070 }
1071 
1072 ScriptExecutionContext* AudioContext::scriptExecutionContext() const
1073 {
<span class="line-modified">1074     return ActiveDOMObject::scriptExecutionContext();</span>
1075 }
1076 
1077 void AudioContext::nodeWillBeginPlayback()
1078 {
1079     // Called by scheduled AudioNodes when clients schedule their start times.
1080     // Prior to the introduction of suspend(), resume(), and stop(), starting
1081     // a scheduled AudioNode would remove the user-gesture restriction, if present,
1082     // and would thus unmute the context. Now that AudioContext stays in the
1083     // &quot;suspended&quot; state if a user-gesture restriction is present, starting a
1084     // schedule AudioNode should set the state to &quot;running&quot;, but only if the
1085     // user-gesture restriction is set.
1086     if (userGestureRequiredForAudioStart())
1087         startRendering();
1088 }
1089 
1090 bool AudioContext::willBeginPlayback()
1091 {
<span class="line-added">1092     if (!document())</span>
<span class="line-added">1093         return false;</span>
<span class="line-added">1094 </span>
1095     if (userGestureRequiredForAudioStart()) {
<span class="line-modified">1096         if (!processingUserGestureForMedia() &amp;&amp; !document()-&gt;isCapturing()) {</span>
<span class="line-added">1097             ALWAYS_LOG(LOGIDENTIFIER, &quot;returning false, not processing user gesture or capturing&quot;);</span>
1098             return false;
<span class="line-added">1099         }</span>
1100         removeBehaviorRestriction(AudioContext::RequireUserGestureForAudioStartRestriction);
1101     }
1102 
1103     if (pageConsentRequiredForAudioStart()) {
1104         Page* page = document()-&gt;page();
1105         if (page &amp;&amp; !page-&gt;canStartMedia()) {
1106             document()-&gt;addMediaCanStartListener(*this);
<span class="line-added">1107             ALWAYS_LOG(LOGIDENTIFIER, &quot;returning false, page doesn&#39;t allow media to start&quot;);</span>
1108             return false;
1109         }
1110         removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1111     }
1112 
<span class="line-modified">1113     auto willBegin = m_mediaSession-&gt;clientWillBeginPlayback();</span>
<span class="line-added">1114     ALWAYS_LOG(LOGIDENTIFIER, &quot;returning &quot;, willBegin);</span>
<span class="line-added">1115 </span>
<span class="line-added">1116     return willBegin;</span>
1117 }
1118 
1119 bool AudioContext::willPausePlayback()
1120 {
<span class="line-added">1121     if (!document())</span>
<span class="line-added">1122         return false;</span>
<span class="line-added">1123 </span>
1124     if (userGestureRequiredForAudioStart()) {
1125         if (!processingUserGestureForMedia())
1126             return false;
1127         removeBehaviorRestriction(AudioContext::RequireUserGestureForAudioStartRestriction);
1128     }
1129 
1130     if (pageConsentRequiredForAudioStart()) {
1131         Page* page = document()-&gt;page();
1132         if (page &amp;&amp; !page-&gt;canStartMedia()) {
1133             document()-&gt;addMediaCanStartListener(*this);
1134             return false;
1135         }
1136         removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1137     }
1138 
1139     return m_mediaSession-&gt;clientWillPausePlayback();
1140 }
1141 
1142 void AudioContext::startRendering()
1143 {
<span class="line-modified">1144     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added">1145     if (m_isStopScheduled || !willBeginPlayback())</span>
1146         return;
1147 
<span class="line-added">1148     makePendingActivity();</span>
<span class="line-added">1149 </span>
1150     destination()-&gt;startRendering();
1151     setState(State::Running);
1152 }
1153 
1154 void AudioContext::mediaCanStart(Document&amp; document)
1155 {
1156     ASSERT_UNUSED(document, &amp;document == this-&gt;document());
1157     removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1158     mayResumePlayback(true);
1159 }
1160 
1161 MediaProducer::MediaStateFlags AudioContext::mediaState() const
1162 {
1163     if (!m_isStopScheduled &amp;&amp; m_destinationNode &amp;&amp; m_destinationNode-&gt;isPlayingAudio())
1164         return MediaProducer::IsPlayingAudio;
1165 
1166     return MediaProducer::IsNotPlaying;
1167 }
1168 
1169 void AudioContext::pageMutedStateDidChange()
1170 {
<span class="line-modified">1171     if (m_destinationNode &amp;&amp; document() &amp;&amp; document()-&gt;page())</span>
1172         m_destinationNode-&gt;setMuted(document()-&gt;page()-&gt;isAudioMuted());
1173 }
1174 
1175 void AudioContext::isPlayingAudioDidChange()
1176 {
1177     // Make sure to call Document::updateIsPlayingMedia() on the main thread, since
1178     // we could be on the audio I/O thread here and the call into WebCore could block.
1179     callOnMainThread([protectedThis = makeRef(*this)] {
1180         if (protectedThis-&gt;document())
1181             protectedThis-&gt;document()-&gt;updateIsPlayingMedia();
1182     });
1183 }
1184 
<span class="line-modified">1185 void AudioContext::finishedRendering(bool didRendering)</span>
1186 {
<span class="line-added">1187     ASSERT(isOfflineContext());</span>
1188     ASSERT(isMainThread());
1189     if (!isMainThread())
1190         return;
1191 
<span class="line-added">1192     auto clearPendingActivityIfExitEarly = WTF::makeScopeExit([this] {</span>
<span class="line-added">1193         clearPendingActivity();</span>
<span class="line-added">1194     });</span>
<span class="line-added">1195 </span>
<span class="line-added">1196 </span>
<span class="line-added">1197     ALWAYS_LOG(LOGIDENTIFIER);</span>
<span class="line-added">1198 </span>
<span class="line-added">1199     if (!didRendering)</span>
<span class="line-added">1200         return;</span>
<span class="line-added">1201 </span>
1202     AudioBuffer* renderedBuffer = m_renderTarget.get();
1203     setState(State::Closed);
1204 
1205     ASSERT(renderedBuffer);
1206     if (!renderedBuffer)
1207         return;
1208 
1209     // Avoid firing the event if the document has already gone away.
<span class="line-modified">1210     if (m_isStopScheduled)</span>
<span class="line-modified">1211         return;</span>
<span class="line-modified">1212 </span>
<span class="line-modified">1213     clearPendingActivityIfExitEarly.release();</span>
<span class="line-added">1214     m_eventQueue-&gt;enqueueEvent(OfflineAudioCompletionEvent::create(renderedBuffer));</span>
<span class="line-added">1215 }</span>
<span class="line-added">1216 </span>
<span class="line-added">1217 void AudioContext::dispatchEvent(Event&amp; event)</span>
<span class="line-added">1218 {</span>
<span class="line-added">1219     EventTarget::dispatchEvent(event);</span>
<span class="line-added">1220     if (event.eventInterface() == OfflineAudioCompletionEventInterfaceType)</span>
<span class="line-added">1221         clearPendingActivity();</span>
1222 }
1223 
1224 void AudioContext::incrementActiveSourceCount()
1225 {
1226     ++m_activeSourceCount;
1227 }
1228 
1229 void AudioContext::decrementActiveSourceCount()
1230 {
1231     --m_activeSourceCount;
1232 }
1233 
1234 void AudioContext::suspend(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1235 {
<span class="line-modified">1236     if (isOfflineContext() || m_isStopScheduled) {</span>
1237         promise.reject(InvalidStateError);
1238         return;
1239     }
1240 
1241     if (m_state == State::Suspended) {
1242         promise.resolve();
1243         return;
1244     }
1245 
1246     if (m_state == State::Closed || m_state == State::Interrupted || !m_destinationNode) {
1247         promise.reject();
1248         return;
1249     }
1250 
1251     addReaction(State::Suspended, WTFMove(promise));
1252 
1253     if (!willPausePlayback())
1254         return;
1255 
1256     lazyInitialize();
1257 
1258     m_destinationNode-&gt;suspend([this, protectedThis = makeRef(*this)] {
1259         setState(State::Suspended);
1260     });
1261 }
1262 
1263 void AudioContext::resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1264 {
<span class="line-modified">1265     if (isOfflineContext() || m_isStopScheduled) {</span>
1266         promise.reject(InvalidStateError);
1267         return;
1268     }
1269 
1270     if (m_state == State::Running) {
1271         promise.resolve();
1272         return;
1273     }
1274 
1275     if (m_state == State::Closed || !m_destinationNode) {
1276         promise.reject();
1277         return;
1278     }
1279 
1280     addReaction(State::Running, WTFMove(promise));
1281 
1282     if (!willBeginPlayback())
1283         return;
1284 
1285     lazyInitialize();
1286 
1287     m_destinationNode-&gt;resume([this, protectedThis = makeRef(*this)] {
1288         setState(State::Running);
1289     });
1290 }
1291 
1292 void AudioContext::close(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1293 {
<span class="line-modified">1294     if (isOfflineContext() || m_isStopScheduled) {</span>
1295         promise.reject(InvalidStateError);
1296         return;
1297     }
1298 
1299     if (m_state == State::Closed || !m_destinationNode) {
1300         promise.resolve();
1301         return;
1302     }
1303 
1304     addReaction(State::Closed, WTFMove(promise));
1305 
1306     lazyInitialize();
1307 
1308     m_destinationNode-&gt;close([this, protectedThis = makeRef(*this)] {
1309         setState(State::Closed);
1310         uninitialize();
1311     });
1312 }
1313 
1314 
</pre>
<hr />
<pre>
1334 void AudioContext::mayResumePlayback(bool shouldResume)
1335 {
1336     if (!m_destinationNode || m_state == State::Closed || m_state == State::Running)
1337         return;
1338 
1339     if (!shouldResume) {
1340         setState(State::Suspended);
1341         return;
1342     }
1343 
1344     if (!willBeginPlayback())
1345         return;
1346 
1347     lazyInitialize();
1348 
1349     m_destinationNode-&gt;resume([this, protectedThis = makeRef(*this)] {
1350         setState(State::Running);
1351     });
1352 }
1353 
<span class="line-added">1354 void AudioContext::postTask(WTF::Function&lt;void()&gt;&amp;&amp; task)</span>
<span class="line-added">1355 {</span>
<span class="line-added">1356     if (m_isStopScheduled)</span>
<span class="line-added">1357         return;</span>
<span class="line-added">1358 </span>
<span class="line-added">1359     m_scriptExecutionContext-&gt;postTask(WTFMove(task));</span>
<span class="line-added">1360 }</span>
<span class="line-added">1361 </span>
<span class="line-added">1362 const SecurityOrigin* AudioContext::origin() const</span>
<span class="line-added">1363 {</span>
<span class="line-added">1364     return m_scriptExecutionContext ? m_scriptExecutionContext-&gt;securityOrigin() : nullptr;</span>
<span class="line-added">1365 }</span>
<span class="line-added">1366 </span>
<span class="line-added">1367 void AudioContext::addConsoleMessage(MessageSource source, MessageLevel level, const String&amp; message)</span>
<span class="line-added">1368 {</span>
<span class="line-added">1369     if (m_scriptExecutionContext)</span>
<span class="line-added">1370         m_scriptExecutionContext-&gt;addConsoleMessage(source, level, message);</span>
<span class="line-added">1371 }</span>
<span class="line-added">1372 </span>
<span class="line-added">1373 void AudioContext::clearPendingActivity()</span>
<span class="line-added">1374 {</span>
<span class="line-added">1375     if (!m_pendingActivity)</span>
<span class="line-added">1376         return;</span>
<span class="line-added">1377     m_pendingActivity = nullptr;</span>
<span class="line-added">1378     // FIXME: Remove this specific deref() and ref() call in makePendingActivity().</span>
<span class="line-added">1379     deref();</span>
<span class="line-added">1380 }</span>
<span class="line-added">1381 </span>
<span class="line-added">1382 void AudioContext::makePendingActivity()</span>
<span class="line-added">1383 {</span>
<span class="line-added">1384     if (m_pendingActivity)</span>
<span class="line-added">1385         return;</span>
<span class="line-added">1386     m_pendingActivity = ActiveDOMObject::makePendingActivity(*this);</span>
<span class="line-added">1387     ref();</span>
<span class="line-added">1388 }</span>
<span class="line-added">1389 </span>
<span class="line-added">1390 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">1391 WTFLogChannel&amp; AudioContext::logChannel() const</span>
<span class="line-added">1392 {</span>
<span class="line-added">1393     return LogMedia;</span>
<span class="line-added">1394 }</span>
<span class="line-added">1395 #endif</span>
1396 
1397 } // namespace WebCore
1398 
1399 #endif // ENABLE(WEB_AUDIO)
</pre>
</td>
</tr>
</table>
<center><a href="AudioBufferSourceNode.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioContext.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>