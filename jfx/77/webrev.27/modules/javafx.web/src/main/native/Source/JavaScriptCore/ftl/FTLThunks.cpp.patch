diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/ftl/FTLThunks.cpp b/modules/javafx.web/src/main/native/Source/JavaScriptCore/ftl/FTLThunks.cpp
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/ftl/FTLThunks.cpp
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/ftl/FTLThunks.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (C) 2013-2018 Apple Inc. All rights reserved.
+ * Copyright (C) 2013-2019 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
  * are met:
  * 1. Redistributions of source code must retain the above copyright
@@ -45,17 +45,17 @@
     Needed,
     NotNeeded
 };
 
 static MacroAssemblerCodeRef<JITThunkPtrTag> genericGenerationThunkGenerator(
-    VM* vm, FunctionPtr<CFunctionPtrTag> generationFunction, PtrTag resultTag, const char* name, unsigned extraPopsToRestore, FrameAndStackAdjustmentRequirement frameAndStackAdjustmentRequirement)
+    VM& vm, FunctionPtr<CFunctionPtrTag> generationFunction, PtrTag resultTag, const char* name, unsigned extraPopsToRestore, FrameAndStackAdjustmentRequirement frameAndStackAdjustmentRequirement)
 {
     AssemblyHelpers jit(nullptr);
 
     if (frameAndStackAdjustmentRequirement == FrameAndStackAdjustmentRequirement::Needed) {
         // This needs to happen before we use the scratch buffer because this function also uses the scratch buffer.
-        adjustFrameAndStackInOSRExitCompilerThunk<FTL::JITCode>(jit, vm, JITCode::FTLJIT);
+        adjustFrameAndStackInOSRExitCompilerThunk<FTL::JITCode>(jit, vm, JITType::FTLJIT);
     }
 
     // Note that the "return address" will be the ID that we pass to the generation function.
 
     ptrdiff_t stackMisalignment = MacroAssembler::pushToSaveByteOffset();
@@ -71,11 +71,11 @@
         jit.pushToSave(GPRInfo::regT0);
         stackMisalignment += MacroAssembler::pushToSaveByteOffset();
         numberOfRequiredPops++;
     } while (stackMisalignment % stackAlignmentBytes());
 
-    ScratchBuffer* scratchBuffer = vm->scratchBufferForSize(requiredScratchMemorySizeInBytes());
+    ScratchBuffer* scratchBuffer = vm.scratchBufferForSize(requiredScratchMemorySizeInBytes());
     char* buffer = static_cast<char*>(scratchBuffer->dataBuffer());
 
     saveAllRegisters(jit, buffer);
 
     // Tell GC mark phase how much of the scratch buffer is active during call.
@@ -113,12 +113,12 @@
     // ensures that the return address is out of the way of register restoration.
     jit.restoreReturnAddressBeforeReturn(GPRInfo::regT0);
 
     restoreAllRegisters(jit, buffer);
 
-#if CPU(ARM64) && USE(POINTER_PROFILING)
-    jit.untagPtr(AssemblyHelpers::linkRegister, resultTag);
+#if CPU(ARM64E)
+    jit.untagPtr(resultTag, AssemblyHelpers::linkRegister);
     jit.tagReturnAddress();
 #else
     UNUSED_PARAM(resultTag);
 #endif
     jit.ret();
@@ -126,18 +126,18 @@
     LinkBuffer patchBuffer(jit, GLOBAL_THUNK_ID);
     patchBuffer.link(functionCall, generationFunction.retagged<OperationPtrTag>());
     return FINALIZE_CODE(patchBuffer, JITThunkPtrTag, "%s", name);
 }
 
-MacroAssemblerCodeRef<JITThunkPtrTag> osrExitGenerationThunkGenerator(VM* vm)
+MacroAssemblerCodeRef<JITThunkPtrTag> osrExitGenerationThunkGenerator(VM& vm)
 {
     unsigned extraPopsToRestore = 0;
     return genericGenerationThunkGenerator(
         vm, compileFTLOSRExit, OSRExitPtrTag, "FTL OSR exit generation thunk", extraPopsToRestore, FrameAndStackAdjustmentRequirement::Needed);
 }
 
-MacroAssemblerCodeRef<JITThunkPtrTag> lazySlowPathGenerationThunkGenerator(VM* vm)
+MacroAssemblerCodeRef<JITThunkPtrTag> lazySlowPathGenerationThunkGenerator(VM& vm)
 {
     unsigned extraPopsToRestore = 1;
     return genericGenerationThunkGenerator(
         vm, compileFTLLazySlowPath, JITStubRoutinePtrTag, "FTL lazy slow path generation thunk", extraPopsToRestore, FrameAndStackAdjustmentRequirement::NotNeeded);
 }
