<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2018 Metrological Group B.V.
  3  * Copyright (C) 2018 Igalia S.L. All rights reserved.
  4  *
  5  * This library is free software; you can redistribute it and/or
  6  * modify it under the terms of the GNU Library General Public
  7  * License as published by the Free Software Foundation; either
  8  * version 2 of the License, or (at your option) any later version.
  9  *
 10  * This library is distributed in the hope that it will be useful,
 11  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 12  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 13  * Library General Public License for more details.
 14  *
 15  * You should have received a copy of the GNU Library General Public License
 16  * aint with this library; see the file COPYING.LIB.  If not, write to
 17  * the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
 18  * Boston, MA 02110-1301, USA.
 19  */
 20 
 21 #include &quot;config.h&quot;
 22 
 23 #if ENABLE(VIDEO) &amp;&amp; ENABLE(MEDIA_STREAM) &amp;&amp; USE(LIBWEBRTC) &amp;&amp; USE(GSTREAMER)
 24 #include &quot;GStreamerVideoDecoderFactory.h&quot;
 25 
 26 #include &quot;GStreamerVideoFrameLibWebRTC.h&quot;
 27 #include &quot;webrtc/common_video/h264/h264_common.h&quot;
 28 #include &quot;webrtc/common_video/h264/profile_level_id.h&quot;
 29 #include &quot;webrtc/media/base/codec.h&quot;
 30 #include &quot;webrtc/modules/video_coding/codecs/h264/include/h264.h&quot;
 31 #include &quot;webrtc/modules/video_coding/codecs/vp8/include/vp8.h&quot;
 32 #include &quot;webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_decoder.h&quot;
 33 #include &quot;webrtc/modules/video_coding/include/video_codec_interface.h&quot;
 34 #include &lt;gst/app/gstappsink.h&gt;
 35 #include &lt;gst/app/gstappsrc.h&gt;
 36 #include &lt;gst/video/video.h&gt;
 37 #include &lt;mutex&gt;
 38 #include &lt;wtf/Lock.h&gt;
 39 #include &lt;wtf/StdMap.h&gt;
 40 #include &lt;wtf/glib/RunLoopSourcePriority.h&gt;
 41 #include &lt;wtf/text/WTFString.h&gt;
 42 
 43 GST_DEBUG_CATEGORY(webkit_webrtcdec_debug);
 44 #define GST_CAT_DEFAULT webkit_webrtcdec_debug
 45 
 46 namespace WebCore {
 47 
 48 typedef struct {
 49     uint64_t timestamp;
 50     int64_t renderTimeMs;
 51 } InputTimestamps;
 52 
 53 class GStreamerVideoDecoder : public webrtc::VideoDecoder {
 54 public:
 55     GStreamerVideoDecoder()
 56         : m_pictureId(0)
 57         , m_width(0)
 58         , m_height(0)
 59         , m_requireParse(false)
 60         , m_needsKeyframe(true)
 61         , m_firstBufferPts(GST_CLOCK_TIME_NONE)
 62         , m_firstBufferDts(GST_CLOCK_TIME_NONE)
 63     {
 64     }
 65 
 66     static void decodebinPadAddedCb(GstElement*,
 67         GstPad* srcpad,
 68         GstPad* sinkpad)
 69     {
 70         GST_INFO_OBJECT(srcpad, &quot;connecting pad with %&quot; GST_PTR_FORMAT, sinkpad);
 71         if (gst_pad_link(srcpad, sinkpad) != GST_PAD_LINK_OK)
 72             ASSERT_NOT_REACHED();
 73     }
 74 
 75     GstElement* pipeline()
 76     {
 77         return m_pipeline.get();
 78     }
 79 
 80     GstElement* makeElement(const gchar* factoryName)
 81     {
 82         GUniquePtr&lt;char&gt; name(g_strdup_printf(&quot;%s_dec_%s_%p&quot;, Name(), factoryName, this));
 83 
 84         return gst_element_factory_make(factoryName, name.get());
 85     }
 86 
 87     int32_t InitDecode(const webrtc::VideoCodec* codecSettings, int32_t) override
 88     {
 89         m_src = makeElement(&quot;appsrc&quot;);
 90 
 91         GRefPtr&lt;GstCaps&gt; caps = nullptr;
 92         auto capsfilter = CreateFilter();
 93         auto decoder = makeElement(&quot;decodebin&quot;);
 94 
 95         if (codecSettings) {
 96             m_width = codecSettings-&gt;width;
 97             m_height = codecSettings-&gt;height;
 98         }
 99 
100         m_pipeline = makeElement(&quot;pipeline&quot;);
101         connectSimpleBusMessageCallback(m_pipeline.get());
102 
103         auto sinkpad = adoptGRef(gst_element_get_static_pad(capsfilter, &quot;sink&quot;));
104         g_signal_connect(decoder, &quot;pad-added&quot;, G_CALLBACK(decodebinPadAddedCb), sinkpad.get());
105         // Make the decoder output &quot;parsed&quot; frames only and let the main decodebin
106         // do the real decoding. This allows us to have optimized decoding/rendering
107         // happening in the main pipeline.
108         if (m_requireParse) {
109             caps = gst_caps_new_simple(Caps(), &quot;parsed&quot;, G_TYPE_BOOLEAN, TRUE, nullptr);
110             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
111 
112             gst_bus_enable_sync_message_emission(bus.get());
113             g_signal_connect(bus.get(), &quot;sync-message::warning&quot;,
114                 G_CALLBACK(+[](GstBus*, GstMessage* message, GStreamerVideoDecoder* justThis) {
115                 GUniqueOutPtr&lt;GError&gt; err;
116 
117                 switch (GST_MESSAGE_TYPE(message)) {
118                 case GST_MESSAGE_WARNING: {
119                     gst_message_parse_warning(message, &amp;err.outPtr(), nullptr);
120                     FALLTHROUGH;
121                 }
122                 case GST_MESSAGE_ERROR: {
123                     if (!err)
124                         gst_message_parse_error(message, &amp;err.outPtr(), nullptr);
125 
126                     if (g_error_matches(err.get(), GST_STREAM_ERROR, GST_STREAM_ERROR_DECODE)) {
127                         GST_INFO_OBJECT(justThis-&gt;pipeline(), &quot;--&gt; needs keyframe (%s)&quot;,
128                             err-&gt;message);
129                         justThis-&gt;m_needsKeyframe = true;
130                     }
131                     break;
132                 }
133                 default:
134                     break;
135                 }
136                 }), this);
137         } else {
138             /* FIXME - How could we handle missing keyframes case we do not plug parsers ? */
139             caps = gst_caps_new_empty_simple(Caps());
140         }
141         g_object_set(decoder, &quot;caps&quot;, caps.get(), nullptr);
142 
143         m_sink = makeElement(&quot;appsink&quot;);
144         gst_app_sink_set_emit_signals(GST_APP_SINK(m_sink), true);
145         // This is an decoder, everything should happen as fast as possible and not
146         // be synced on the clock.
147         g_object_set(m_sink, &quot;sync&quot;, false, nullptr);
148 
149         gst_bin_add_many(GST_BIN(pipeline()), m_src, decoder, capsfilter, m_sink, nullptr);
150         if (!gst_element_link(m_src, decoder)) {
151             GST_ERROR_OBJECT(pipeline(), &quot;Could not link src to decoder.&quot;);
152             return WEBRTC_VIDEO_CODEC_ERROR;
153         }
154 
155         if (!gst_element_link(capsfilter, m_sink)) {
156             GST_ERROR_OBJECT(pipeline(), &quot;Could not link capsfilter to sink.&quot;);
157             return WEBRTC_VIDEO_CODEC_ERROR;
158         }
159 
160         if (gst_element_set_state(pipeline(), GST_STATE_PLAYING) == GST_STATE_CHANGE_FAILURE) {
161             GST_ERROR_OBJECT(pipeline(), &quot;Could not set state to PLAYING.&quot;);
162             return WEBRTC_VIDEO_CODEC_ERROR;
163         }
164 
165         return WEBRTC_VIDEO_CODEC_OK;
166     }
167 
168     int32_t RegisterDecodeCompleteCallback(webrtc::DecodedImageCallback* callback)
169     {
170         m_imageReadyCb = callback;
171 
172         return WEBRTC_VIDEO_CODEC_OK;
173     }
174 
175     virtual GstElement* CreateFilter()
176     {
177         return makeElement(&quot;identity&quot;);
178     }
179 
180     int32_t Release() final
181     {
182         if (m_pipeline.get()) {
183             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
184             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
185 
186             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
187             m_src = nullptr;
188             m_sink = nullptr;
189             m_pipeline = nullptr;
190         }
191 
192         return WEBRTC_VIDEO_CODEC_OK;
193     }
194 
195     int32_t Decode(const webrtc::EncodedImage&amp; inputImage,
196         bool,
197         const webrtc::CodecSpecificInfo*,
198         int64_t renderTimeMs) override
199     {
200         if (m_needsKeyframe) {
201             if (inputImage._frameType != webrtc::kVideoFrameKey) {
202                 GST_ERROR(&quot;Waiting for keyframe but got a delta unit... asking for keyframe&quot;);
203                 return WEBRTC_VIDEO_CODEC_ERROR;
204             }
205             if (inputImage._completeFrame)
206                 m_needsKeyframe = false;
207             else {
208                 GST_ERROR(&quot;Waiting for keyframe but didn&#39;t get full frame, getting out&quot;);
209                 return WEBRTC_VIDEO_CODEC_ERROR;
210             }
211         }
212 
213 
214         if (!m_src) {
215             GST_ERROR(&quot;No source set, can&#39;t decode.&quot;);
216 
217             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
218         }
219 
220         if (!GST_CLOCK_TIME_IS_VALID(m_firstBufferPts)) {
221             GRefPtr&lt;GstPad&gt; srcpad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
222             m_firstBufferPts = (static_cast&lt;guint64&gt;(renderTimeMs)) * GST_MSECOND;
223             m_firstBufferDts = (static_cast&lt;guint64&gt;(inputImage.Timestamp())) * GST_MSECOND;
224         }
225 
226         // FIXME- Use a GstBufferPool.
227         auto buffer = adoptGRef(gst_buffer_new_wrapped(g_memdup(inputImage._buffer, inputImage._size),
228             inputImage._size));
229         GST_BUFFER_DTS(buffer.get()) = (static_cast&lt;guint64&gt;(inputImage.Timestamp()) * GST_MSECOND) - m_firstBufferDts;
230         GST_BUFFER_PTS(buffer.get()) = (static_cast&lt;guint64&gt;(renderTimeMs) * GST_MSECOND) - m_firstBufferPts;
231         InputTimestamps timestamps = {inputImage.Timestamp(), renderTimeMs};
232         m_dtsPtsMap[GST_BUFFER_PTS(buffer.get())] = timestamps;
233 
234         GST_LOG_OBJECT(pipeline(), &quot;%&quot; G_GINT64_FORMAT &quot; Decoding: %&quot; GST_PTR_FORMAT, renderTimeMs, buffer.get());
235         auto sample = adoptGRef(gst_sample_new(buffer.get(), GetCapsForFrame(inputImage), nullptr, nullptr));
236         switch (gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get())) {
237         case GST_FLOW_OK:
238             break;
239         case GST_FLOW_FLUSHING:
240             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
241         default:
242             return WEBRTC_VIDEO_CODEC_ERROR;
243         }
244 
245         return pullSample();
246     }
247 
248     int32_t pullSample()
249     {
250         auto sample = gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), GST_SECOND / 30);
251         if (!sample) {
252             GST_ERROR(&quot;Needs more data&quot;);
253             return WEBRTC_VIDEO_CODEC_OK;
254         }
255         auto buffer = gst_sample_get_buffer(sample);
256 
257         // Make sure that the frame.timestamp == previsouly input_frame._timeStamp
258         // as it is required by the VideoDecoder baseclass.
259         auto timestamps = m_dtsPtsMap[GST_BUFFER_PTS(buffer)];
260         m_dtsPtsMap.erase(GST_BUFFER_PTS(buffer));
261 
262         auto frame(LibWebRTCVideoFrameFromGStreamerSample(sample, webrtc::kVideoRotation_0,
263             timestamps.timestamp, timestamps.renderTimeMs));
264 
265         GST_BUFFER_DTS(buffer) = GST_CLOCK_TIME_NONE;
266         GST_LOG_OBJECT(pipeline(), &quot;Output decoded frame! %d -&gt; %&quot; GST_PTR_FORMAT,
267             frame-&gt;timestamp(), buffer);
268 
269         m_imageReadyCb-&gt;Decoded(*frame.get(), absl::optional&lt;int32_t&gt;(), absl::optional&lt;uint8_t&gt;());
270 
271         return WEBRTC_VIDEO_CODEC_OK;
272     }
273 
274     virtual GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image)
275     {
276         if (!m_caps) {
277             m_caps = adoptGRef(gst_caps_new_simple(Caps(),
278                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth ? image._encodedWidth : m_width,
279                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight ? image._encodedHeight : m_height,
280                 nullptr));
281         }
282 
283         return m_caps.get();
284     }
285 
286     void AddDecoderIfSupported(std::vector&lt;webrtc::SdpVideoFormat&gt; codecList)
287     {
288         if (HasGstDecoder()) {
289             webrtc::SdpVideoFormat format = ConfigureSupportedDecoder();
290 
291             codecList.push_back(format);
292         }
293     }
294 
295     virtual webrtc::SdpVideoFormat ConfigureSupportedDecoder()
296     {
297         return webrtc::SdpVideoFormat(Name());
298     }
299 
300     static GRefPtr&lt;GstElementFactory&gt; GstDecoderFactory(const char *capsStr)
301     {
302         auto all_decoders = gst_element_factory_list_get_elements(GST_ELEMENT_FACTORY_TYPE_DECODER,
303             GST_RANK_MARGINAL);
304         auto caps = adoptGRef(gst_caps_from_string(capsStr));
305         auto decoders = gst_element_factory_list_filter(all_decoders,
306             caps.get(), GST_PAD_SINK, FALSE);
307 
308         gst_plugin_feature_list_free(all_decoders);
309         GRefPtr&lt;GstElementFactory&gt; res;
310         if (decoders)
311             res = GST_ELEMENT_FACTORY(decoders-&gt;data);
312         gst_plugin_feature_list_free(decoders);
313 
314         return res;
315     }
316 
317     bool HasGstDecoder()
318     {
319         return GstDecoderFactory(Caps());
320     }
321 
322     virtual const gchar* Caps() = 0;
323     virtual webrtc::VideoCodecType CodecType() = 0;
324     const char* ImplementationName() const { return &quot;GStreamer&quot;; }
325     virtual const gchar* Name() = 0;
326 
327 protected:
328     GRefPtr&lt;GstCaps&gt; m_caps;
329     gint m_pictureId;
330     gint m_width;
331     gint m_height;
332     bool m_requireParse = false;
333     bool m_needsKeyframe;
334 
335 private:
336     GRefPtr&lt;GstElement&gt; m_pipeline;
337     GstElement* m_sink;
338     GstElement* m_src;
339 
340     GstVideoInfo m_info;
341     webrtc::DecodedImageCallback* m_imageReadyCb;
342 
343     StdMap&lt;GstClockTime, InputTimestamps&gt; m_dtsPtsMap;
344     GstClockTime m_firstBufferPts;
345     GstClockTime m_firstBufferDts;
346 };
347 
348 class H264Decoder : public GStreamerVideoDecoder {
349 public:
350     H264Decoder() { m_requireParse = true; }
351 
352     int32_t InitDecode(const webrtc::VideoCodec* codecInfo, int32_t nCores) final
353     {
354         if (codecInfo &amp;&amp; codecInfo-&gt;codecType != webrtc::kVideoCodecH264)
355             return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
356 
357         m_profile = nullptr;
358         if (codecInfo) {
359             auto h264Info = codecInfo-&gt;H264();
360 
361             switch (h264Info.profile) {
362             case webrtc::H264::kProfileConstrainedBaseline:
363                 m_profile = &quot;constrained-baseline&quot;;
364                 break;
365             case webrtc::H264::kProfileBaseline:
366                 m_profile = &quot;baseline&quot;;
367                 break;
368             case webrtc::H264::kProfileMain:
369                 m_profile = &quot;main&quot;;
370                 break;
371             case webrtc::H264::kProfileConstrainedHigh:
372                 m_profile = &quot;constrained-high&quot;;
373                 break;
374             case webrtc::H264::kProfileHigh:
375                 m_profile = &quot;high&quot;;
376                 break;
377             }
378         }
379 
380         return GStreamerVideoDecoder::InitDecode(codecInfo, nCores);
381     }
382 
383     GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image) final
384     {
385         if (!m_caps) {
386             m_caps = adoptGRef(gst_caps_new_simple(Caps(),
387                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth ? image._encodedWidth : m_width,
388                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight ? image._encodedHeight : m_height,
389                 &quot;alignment&quot;, G_TYPE_STRING, &quot;au&quot;,
390                 nullptr));
391         }
392 
393         return m_caps.get();
394     }
395     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
396     const gchar* Name() final { return cricket::kH264CodecName; }
397     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
398 
399 private:
400     const gchar* m_profile;
401 };
402 
403 class VP8Decoder : public GStreamerVideoDecoder {
404 public:
405     VP8Decoder() { }
406     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
407     const gchar* Name() final { return cricket::kVp8CodecName; }
408     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
409     static std::unique_ptr&lt;webrtc::VideoDecoder&gt; Create()
410     {
411         auto factory = GstDecoderFactory(&quot;video/x-vp8&quot;);
412 
413         if (factory &amp;&amp; !g_strcmp0(GST_OBJECT_NAME(GST_OBJECT(factory.get())), &quot;vp8dec&quot;)) {
414             GST_INFO(&quot;Our best GStreamer VP8 decoder is vp8dec, better use the one from LibWebRTC&quot;);
415 
416             return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(new webrtc::LibvpxVp8Decoder());
417         }
418 
419         return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(new VP8Decoder());
420     }
421 };
422 
423 std::unique_ptr&lt;webrtc::VideoDecoder&gt; GStreamerVideoDecoderFactory::CreateVideoDecoder(const webrtc::SdpVideoFormat&amp; format)
424 {
425     webrtc::VideoDecoder* dec;
426 
427     if (format.name == cricket::kH264CodecName)
428         dec = new H264Decoder();
429     else if (format.name == cricket::kVp8CodecName)
430         return VP8Decoder::Create();
431     else {
432         GST_ERROR(&quot;Could not create decoder for %s&quot;, format.name.c_str());
433 
434         return nullptr;
435     }
436 
437     return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(dec);
438 }
439 
440 GStreamerVideoDecoderFactory::GStreamerVideoDecoderFactory()
441 {
442     static std::once_flag debugRegisteredFlag;
443 
444     std::call_once(debugRegisteredFlag, [] {
445         GST_DEBUG_CATEGORY_INIT(webkit_webrtcdec_debug, &quot;webkitlibwebrtcvideodecoder&quot;, 0, &quot;WebKit WebRTC video decoder&quot;);
446     });
447 }
448 std::vector&lt;webrtc::SdpVideoFormat&gt; GStreamerVideoDecoderFactory::GetSupportedFormats() const
449 {
450     std::vector&lt;webrtc::SdpVideoFormat&gt; formats;
451 
452     VP8Decoder().AddDecoderIfSupported(formats);
453     H264Decoder().AddDecoderIfSupported(formats);
454 
455     return formats;
456 }
457 }
458 #endif
    </pre>
  </body>
</html>