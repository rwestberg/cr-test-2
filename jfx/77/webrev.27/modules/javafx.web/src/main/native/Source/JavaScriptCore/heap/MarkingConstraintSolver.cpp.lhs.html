<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/MarkingConstraintSolver.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2017 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
 14  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 15  * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
 17  * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 18  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 19  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 20  * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 21  * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 22  * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 23  * THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;MarkingConstraintSolver.h&quot;
 28 
 29 #include &quot;JSCInlines.h&quot;
<a name="1" id="anc1"></a>
 30 
 31 namespace JSC {
 32 
 33 MarkingConstraintSolver::MarkingConstraintSolver(MarkingConstraintSet&amp; set)
 34     : m_heap(set.m_heap)
 35     , m_mainVisitor(m_heap.collectorSlotVisitor())
 36     , m_set(set)
 37 {
 38     m_heap.forEachSlotVisitor(
 39         [&amp;] (SlotVisitor&amp; visitor) {
 40             m_visitCounters.append(VisitCounter(visitor));
 41         });
 42 }
 43 
 44 MarkingConstraintSolver::~MarkingConstraintSolver()
 45 {
 46 }
 47 
 48 bool MarkingConstraintSolver::didVisitSomething() const
 49 {
 50     for (const VisitCounter&amp; visitCounter : m_visitCounters) {
 51         if (visitCounter.visitCount())
 52             return true;
 53     }
<a name="2" id="anc2"></a><span class="line-removed"> 54     // If the number of SlotVisitors increases after creating m_visitCounters,</span>
<span class="line-removed"> 55     // we conservatively say there could be something visited by added SlotVisitors.</span>
<span class="line-removed"> 56     if (m_heap.numberOfSlotVisitors() &gt; m_visitCounters.size())</span>
<span class="line-removed"> 57         return true;</span>
 58     return false;
 59 }
 60 
 61 void MarkingConstraintSolver::execute(SchedulerPreference preference, ScopedLambda&lt;Optional&lt;unsigned&gt;()&gt; pickNext)
 62 {
 63     m_pickNextIsStillActive = true;
 64     RELEASE_ASSERT(!m_numThreadsThatMayProduceWork);
 65 
 66     if (Options::useParallelMarkingConstraintSolver()) {
 67         if (Options::logGC())
 68             dataLog(preference == ParallelWorkFirst ? &quot;P&quot; : &quot;N&quot;, &quot;&lt;&quot;);
 69 
 70         m_heap.runFunctionInParallel(
 71             [&amp;] (SlotVisitor&amp; visitor) { runExecutionThread(visitor, preference, pickNext); });
 72 
 73         if (Options::logGC())
 74             dataLog(&quot;&gt;&quot;);
 75     } else
 76         runExecutionThread(m_mainVisitor, preference, pickNext);
 77 
 78     RELEASE_ASSERT(!m_pickNextIsStillActive);
 79     RELEASE_ASSERT(!m_numThreadsThatMayProduceWork);
 80 
 81     if (!m_toExecuteSequentially.isEmpty()) {
 82         for (unsigned indexToRun : m_toExecuteSequentially)
 83             execute(*m_set.m_set[indexToRun]);
 84         m_toExecuteSequentially.clear();
 85     }
 86 
 87     RELEASE_ASSERT(m_toExecuteInParallel.isEmpty());
 88 }
 89 
 90 void MarkingConstraintSolver::drain(BitVector&amp; unexecuted)
 91 {
 92     auto iter = unexecuted.begin();
 93     auto end = unexecuted.end();
 94     if (iter == end)
 95         return;
 96     auto pickNext = scopedLambda&lt;Optional&lt;unsigned&gt;()&gt;(
 97         [&amp;] () -&gt; Optional&lt;unsigned&gt; {
 98             if (iter == end)
 99                 return WTF::nullopt;
100             return *iter++;
101         });
102     execute(NextConstraintFirst, pickNext);
103     unexecuted.clearAll();
104 }
105 
106 void MarkingConstraintSolver::converge(const Vector&lt;MarkingConstraint*&gt;&amp; order)
107 {
108     if (didVisitSomething())
109         return;
110 
111     if (order.isEmpty())
112         return;
113 
114     size_t index = 0;
115 
116     // We want to execute the first constraint sequentially if we think it will quickly give us a
117     // result. If we ran it in parallel to other constraints, then we might end up having to wait for
118     // those other constraints to finish, which would be a waste of time since during convergence it&#39;s
119     // empirically most optimal to return to draining as soon as a constraint generates work. Most
120     // constraints don&#39;t generate any work most of the time, and when they do generate work, they tend
121     // to generate enough of it to feed a decent draining cycle. Therefore, pause times are lowest if
122     // we get the heck out of here as soon as a constraint generates work. I think that part of what
123     // makes this optimal is that we also never abort running a constraint early, so when we do run
124     // one, it has an opportunity to generate as much work as it possibly can.
125     if (order[index]-&gt;quickWorkEstimate(m_mainVisitor) &gt; 0.) {
126         execute(*order[index++]);
127 
128         if (m_toExecuteInParallel.isEmpty()
129             &amp;&amp; (order.isEmpty() || didVisitSomething()))
130             return;
131     }
132 
133     auto pickNext = scopedLambda&lt;Optional&lt;unsigned&gt;()&gt;(
134         [&amp;] () -&gt; Optional&lt;unsigned&gt; {
135             if (didVisitSomething())
136                 return WTF::nullopt;
137 
138             if (index &gt;= order.size())
139                 return WTF::nullopt;
140 
141             MarkingConstraint&amp; constraint = *order[index++];
142             return constraint.index();
143         });
144 
145     execute(ParallelWorkFirst, pickNext);
146 }
147 
148 void MarkingConstraintSolver::execute(MarkingConstraint&amp; constraint)
149 {
150     if (m_executed.get(constraint.index()))
151         return;
152 
153     constraint.prepareToExecute(NoLockingNecessary, m_mainVisitor);
154     constraint.execute(m_mainVisitor);
155     m_executed.set(constraint.index());
156 }
157 
158 void MarkingConstraintSolver::addParallelTask(RefPtr&lt;SharedTask&lt;void(SlotVisitor&amp;)&gt;&gt; task, MarkingConstraint&amp; constraint)
159 {
160     auto locker = holdLock(m_lock);
161     m_toExecuteInParallel.append(TaskWithConstraint(WTFMove(task), &amp;constraint));
162 }
163 
164 void MarkingConstraintSolver::runExecutionThread(SlotVisitor&amp; visitor, SchedulerPreference preference, ScopedLambda&lt;Optional&lt;unsigned&gt;()&gt; pickNext)
165 {
166     for (;;) {
167         bool doParallelWorkMode;
168         MarkingConstraint* constraint = nullptr;
169         unsigned indexToRun = UINT_MAX;
170         TaskWithConstraint task;
171         {
172             auto locker = holdLock(m_lock);
173 
174             for (;;) {
175                 auto tryParallelWork = [&amp;] () -&gt; bool {
176                     if (m_toExecuteInParallel.isEmpty())
177                         return false;
178 
179                     task = m_toExecuteInParallel.first();
180                     constraint = task.constraint;
181                     doParallelWorkMode = true;
182                     return true;
183                 };
184 
185                 auto tryNextConstraint = [&amp;] () -&gt; bool {
186                     if (!m_pickNextIsStillActive)
187                         return false;
188 
189                     for (;;) {
190                         Optional&lt;unsigned&gt; pickResult = pickNext();
191                         if (!pickResult) {
192                             m_pickNextIsStillActive = false;
193                             return false;
194                         }
195 
196                         if (m_executed.get(*pickResult))
197                             continue;
198 
199                         MarkingConstraint&amp; candidateConstraint = *m_set.m_set[*pickResult];
200                         if (candidateConstraint.concurrency() == ConstraintConcurrency::Sequential) {
201                             m_toExecuteSequentially.append(*pickResult);
202                             continue;
203                         }
204                         if (candidateConstraint.parallelism() == ConstraintParallelism::Parallel)
205                             m_numThreadsThatMayProduceWork++;
206                         indexToRun = *pickResult;
207                         constraint = &amp;candidateConstraint;
208                         doParallelWorkMode = false;
209                         constraint-&gt;prepareToExecute(locker, visitor);
210                         return true;
211                     }
212                 };
213 
214                 if (preference == ParallelWorkFirst) {
215                     if (tryParallelWork() || tryNextConstraint())
216                         break;
217                 } else {
218                     if (tryNextConstraint() || tryParallelWork())
219                         break;
220                 }
221 
222                 // This means that we have nothing left to run. The only way for us to have more work is
223                 // if someone is running a constraint that may produce parallel work.
224 
225                 if (!m_numThreadsThatMayProduceWork)
226                     return;
227 
228                 // FIXME: Any waiting could be replaced with just running the SlotVisitor.
229                 // I wonder if that would be profitable.
230                 m_condition.wait(m_lock);
231             }
232         }
233 
234         if (doParallelWorkMode)
235             constraint-&gt;doParallelWork(visitor, *task.task);
236         else {
237             if (constraint-&gt;parallelism() == ConstraintParallelism::Parallel) {
238                 visitor.m_currentConstraint = constraint;
239                 visitor.m_currentSolver = this;
240             }
241 
242             constraint-&gt;execute(visitor);
243 
244             visitor.m_currentConstraint = nullptr;
245             visitor.m_currentSolver = nullptr;
246         }
247 
248         {
249             auto locker = holdLock(m_lock);
250 
251             if (doParallelWorkMode) {
252                 if (!m_toExecuteInParallel.isEmpty()
253                     &amp;&amp; task == m_toExecuteInParallel.first())
254                     m_toExecuteInParallel.takeFirst();
255                 else
256                     ASSERT(!m_toExecuteInParallel.contains(task));
257             } else {
258                 if (constraint-&gt;parallelism() == ConstraintParallelism::Parallel)
259                     m_numThreadsThatMayProduceWork--;
260                 m_executed.set(indexToRun);
261             }
262 
263             m_condition.notifyAll();
264         }
265     }
266 }
267 
268 } // namespace JSC
269 
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>