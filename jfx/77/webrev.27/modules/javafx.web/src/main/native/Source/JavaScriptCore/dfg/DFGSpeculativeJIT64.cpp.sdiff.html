<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGSpeculativeJIT64.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGSpeculativeJIT32_64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGStoreBarrierClusteringPhase.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGSpeculativeJIT64.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 200     JITGetByIdWithThisGenerator gen(
 201         m_jit.codeBlock(), codeOrigin, callSite, usedRegisters, identifierUID(identifierNumber),
 202         JSValueRegs(resultGPR), JSValueRegs(baseGPR), JSValueRegs(thisGPR), AccessType::GetWithThis);
 203     gen.generateFastPath(m_jit);
 204 
 205     JITCompiler::JumpList slowCases;
 206     slowCases.append(slowPathTarget);
 207     slowCases.append(gen.slowPathJump());
 208 
 209     std::unique_ptr&lt;SlowPathGenerator&gt; slowPath = slowPathCall(
 210         slowCases, this, operationGetByIdWithThisOptimize,
 211         DontSpill, ExceptionCheckRequirement::CheckNeeded,
 212         resultGPR, gen.stubInfo(), baseGPR, thisGPR, identifierUID(identifierNumber));
 213 
 214     m_jit.addGetByIdWithThis(gen, slowPath.get());
 215     addSlowPathGenerator(WTFMove(slowPath));
 216 }
 217 
 218 void SpeculativeJIT::nonSpeculativeNonPeepholeCompareNullOrUndefined(Edge operand)
 219 {
<span class="line-removed"> 220     ASSERT_WITH_MESSAGE(!masqueradesAsUndefinedWatchpointIsStillValid() || !isKnownCell(operand.node()), &quot;The Compare should have been eliminated, it is known to be always false.&quot;);</span>
<span class="line-removed"> 221 </span>
 222     JSValueOperand arg(this, operand, ManualOperandSpeculation);
 223     GPRReg argGPR = arg.gpr();
 224 
 225     GPRTemporary result(this);
 226     GPRReg resultGPR = result.gpr();
 227 
 228     m_jit.move(TrustedImm32(0), resultGPR);
 229 
 230     JITCompiler::JumpList done;
 231     if (masqueradesAsUndefinedWatchpointIsStillValid()) {
 232         if (!isKnownNotCell(operand.node()))
 233             done.append(m_jit.branchIfCell(JSValueRegs(argGPR)));
 234     } else {
 235         GPRTemporary localGlobalObject(this);
 236         GPRTemporary remoteGlobalObject(this);
 237         GPRTemporary scratch(this);
 238 
 239         JITCompiler::Jump notCell;
 240         if (!isKnownCell(operand.node()))
 241             notCell = m_jit.branchIfNotCell(JSValueRegs(argGPR));
 242 
 243         JITCompiler::Jump isNotMasqueradesAsUndefined = m_jit.branchTest8(
 244             JITCompiler::Zero,
 245             JITCompiler::Address(argGPR, JSCell::typeInfoFlagsOffset()),
 246             JITCompiler::TrustedImm32(MasqueradesAsUndefined));
 247         done.append(isNotMasqueradesAsUndefined);
 248 
 249         GPRReg localGlobalObjectGPR = localGlobalObject.gpr();
 250         GPRReg remoteGlobalObjectGPR = remoteGlobalObject.gpr();
 251         m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.graph().globalObjectFor(m_currentNode-&gt;origin.semantic)), localGlobalObjectGPR);
<span class="line-modified"> 252         m_jit.emitLoadStructure(*m_jit.vm(), argGPR, resultGPR, scratch.gpr());</span>
 253         m_jit.loadPtr(JITCompiler::Address(resultGPR, Structure::globalObjectOffset()), remoteGlobalObjectGPR);
 254         m_jit.comparePtr(JITCompiler::Equal, localGlobalObjectGPR, remoteGlobalObjectGPR, resultGPR);
 255         done.append(m_jit.jump());
 256         if (!isKnownCell(operand.node()))
 257             notCell.link(&amp;m_jit);
 258     }
 259 
 260     if (!isKnownNotOther(operand.node())) {
 261         m_jit.move(argGPR, resultGPR);
 262         m_jit.and64(JITCompiler::TrustedImm32(~TagBitUndefined), resultGPR);
 263         m_jit.compare64(JITCompiler::Equal, resultGPR, JITCompiler::TrustedImm32(ValueNull), resultGPR);
 264     }
 265 
 266     done.link(&amp;m_jit);
 267 
 268     m_jit.or32(TrustedImm32(ValueFalse), resultGPR);
 269     jsValueResult(resultGPR, m_currentNode, DataFormatJSBoolean);
 270 }
 271 
 272 void SpeculativeJIT::nonSpeculativePeepholeBranchNullOrUndefined(Edge operand, Node* branchNode)
</pre>
<hr />
<pre>
 285         if (!isKnownNotCell(operand.node())) {
 286             JITCompiler::Jump isCell = m_jit.branchIfCell(JSValueRegs(argGPR));
 287             addBranch(isCell, notTaken);
 288         }
 289     } else {
 290         GPRTemporary localGlobalObject(this);
 291         GPRTemporary remoteGlobalObject(this);
 292         GPRTemporary scratch(this);
 293 
 294         JITCompiler::Jump notCell;
 295         if (!isKnownCell(operand.node()))
 296             notCell = m_jit.branchIfNotCell(JSValueRegs(argGPR));
 297 
 298         branchTest8(JITCompiler::Zero,
 299             JITCompiler::Address(argGPR, JSCell::typeInfoFlagsOffset()),
 300             JITCompiler::TrustedImm32(MasqueradesAsUndefined), notTaken);
 301 
 302         GPRReg localGlobalObjectGPR = localGlobalObject.gpr();
 303         GPRReg remoteGlobalObjectGPR = remoteGlobalObject.gpr();
 304         m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.graph().globalObjectFor(m_currentNode-&gt;origin.semantic)), localGlobalObjectGPR);
<span class="line-modified"> 305         m_jit.emitLoadStructure(*m_jit.vm(), argGPR, resultGPR, scratch.gpr());</span>
 306         m_jit.loadPtr(JITCompiler::Address(resultGPR, Structure::globalObjectOffset()), remoteGlobalObjectGPR);
 307         branchPtr(JITCompiler::Equal, localGlobalObjectGPR, remoteGlobalObjectGPR, taken);
 308 
 309         if (!isKnownCell(operand.node())) {
 310             jump(notTaken, ForceJump);
 311             notCell.link(&amp;m_jit);
 312         }
 313     }
 314 
 315     if (isKnownNotOther(operand.node()))
 316         jump(notTaken);
 317     else {
 318         JITCompiler::RelationalCondition condition = JITCompiler::Equal;
 319         if (taken == nextBlock()) {
 320             condition = JITCompiler::NotEqual;
 321             std::swap(taken, notTaken);
 322         }
 323         m_jit.move(argGPR, resultGPR);
 324         m_jit.and64(JITCompiler::TrustedImm32(~TagBitUndefined), resultGPR);
 325         branch64(condition, resultGPR, JITCompiler::TrustedImm64(ValueNull), taken);
</pre>
<hr />
<pre>
 532         isTail = true;
 533         isDirect = true;
 534         break;
 535     case DirectTailCallInlinedCaller:
 536         callType = CallLinkInfo::DirectCall;
 537         isEmulatedTail = true;
 538         isDirect = true;
 539         break;
 540     default:
 541         DFG_CRASH(m_jit.graph(), node, &quot;bad node type&quot;);
 542         break;
 543     }
 544 
 545     GPRReg calleeGPR = InvalidGPRReg;
 546     CallFrameShuffleData shuffleData;
 547 
 548     ExecutableBase* executable = nullptr;
 549     FunctionExecutable* functionExecutable = nullptr;
 550     if (isDirect) {
 551         executable = node-&gt;castOperand&lt;ExecutableBase*&gt;();
<span class="line-modified"> 552         functionExecutable = jsDynamicCast&lt;FunctionExecutable*&gt;(*m_jit.vm(), executable);</span>
 553     }
 554 
 555     unsigned numPassedArgs = 0;
 556     unsigned numAllocatedArgs = 0;
 557 
 558     // Gotta load the arguments somehow. Varargs is trickier.
 559     if (isVarargs || isForwardVarargs) {
 560         RELEASE_ASSERT(!isDirect);
 561         CallVarargsData* data = node-&gt;callVarargsData();
 562 
 563         int numUsedStackSlots = m_jit.graph().m_nextMachineLocal;
 564 
 565         if (isForwardVarargs) {
 566             flushRegisters();
 567             if (node-&gt;child3())
 568                 use(node-&gt;child3());
 569 
 570             GPRReg scratchGPR1;
 571             GPRReg scratchGPR2;
 572             GPRReg scratchGPR3;
 573 
 574             scratchGPR1 = JITCompiler::selectScratchGPR();
 575             scratchGPR2 = JITCompiler::selectScratchGPR(scratchGPR1);
 576             scratchGPR3 = JITCompiler::selectScratchGPR(scratchGPR1, scratchGPR2);
 577 
 578             m_jit.move(TrustedImm32(numUsedStackSlots), scratchGPR2);
 579             JITCompiler::JumpList slowCase;
 580             InlineCallFrame* inlineCallFrame;
 581             if (node-&gt;child3())
<span class="line-modified"> 582                 inlineCallFrame = node-&gt;child3()-&gt;origin.semantic.inlineCallFrame;</span>
 583             else
<span class="line-modified"> 584                 inlineCallFrame = node-&gt;origin.semantic.inlineCallFrame;</span>
 585             // emitSetupVarargsFrameFastCase modifies the stack pointer if it succeeds.
<span class="line-modified"> 586             emitSetupVarargsFrameFastCase(*m_jit.vm(), m_jit, scratchGPR2, scratchGPR1, scratchGPR2, scratchGPR3, inlineCallFrame, data-&gt;firstVarArgOffset, slowCase);</span>
 587             JITCompiler::Jump done = m_jit.jump();
 588             slowCase.link(&amp;m_jit);
 589             callOperation(operationThrowStackOverflowForVarargs);
 590             m_jit.exceptionCheck();
 591             m_jit.abortWithReason(DFGVarargsThrowingPathDidNotThrow);
 592             done.link(&amp;m_jit);
 593         } else {
 594             GPRReg argumentsGPR;
 595             GPRReg scratchGPR1;
 596             GPRReg scratchGPR2;
 597             GPRReg scratchGPR3;
 598 
 599             auto loadArgumentsGPR = [&amp;] (GPRReg reservedGPR) {
 600                 if (reservedGPR != InvalidGPRReg)
 601                     lock(reservedGPR);
 602                 JSValueOperand arguments(this, node-&gt;child3());
 603                 argumentsGPR = arguments.gpr();
 604                 if (reservedGPR != InvalidGPRReg)
 605                     unlock(reservedGPR);
 606                 flushRegisters();
</pre>
<hr />
<pre>
 703 
 704                 m_jit.store64(argGPR, JITCompiler::calleeArgumentSlot(i));
 705             }
 706 
 707             for (unsigned i = numPassedArgs; i &lt; numAllocatedArgs; ++i)
 708                 m_jit.storeTrustedValue(jsUndefined(), JITCompiler::calleeArgumentSlot(i));
 709         }
 710     }
 711 
 712     if (!isTail || isVarargs || isForwardVarargs) {
 713         Edge calleeEdge = m_jit.graph().child(node, 0);
 714         JSValueOperand callee(this, calleeEdge);
 715         calleeGPR = callee.gpr();
 716         callee.use();
 717         m_jit.store64(calleeGPR, JITCompiler::calleeFrameSlot(CallFrameSlot::callee));
 718 
 719         flushRegisters();
 720     }
 721 
 722     CodeOrigin staticOrigin = node-&gt;origin.semantic;
<span class="line-modified"> 723     ASSERT(!isTail || !staticOrigin.inlineCallFrame || !staticOrigin.inlineCallFrame-&gt;getCallerSkippingTailCalls());</span>
<span class="line-modified"> 724     ASSERT(!isEmulatedTail || (staticOrigin.inlineCallFrame &amp;&amp; staticOrigin.inlineCallFrame-&gt;getCallerSkippingTailCalls()));</span>

 725     CodeOrigin dynamicOrigin =
<span class="line-modified"> 726         isEmulatedTail ? *staticOrigin.inlineCallFrame-&gt;getCallerSkippingTailCalls() : staticOrigin;</span>
 727 
 728     CallSiteIndex callSite = m_jit.recordCallSiteAndGenerateExceptionHandlingOSRExitIfNeeded(dynamicOrigin, m_stream-&gt;size());
 729 
 730     auto setResultAndResetStack = [&amp;] () {
 731         GPRFlushedCallResult result(this);
 732         GPRReg resultGPR = result.gpr();
 733         m_jit.move(GPRInfo::returnValueGPR, resultGPR);
 734 
 735         jsValueResult(resultGPR, m_currentNode, DataFormatJS, UseChildrenCalledExplicitly);
 736 
 737         // After the calls are done, we need to reestablish our stack
 738         // pointer. We rely on this for varargs calls, calls with arity
 739         // mismatch (the callframe is slided) and tail calls.
 740         m_jit.addPtr(TrustedImm32(m_jit.graph().stackPointerOffset() * sizeof(Register)), GPRInfo::callFrameRegister, JITCompiler::stackPointerRegister);
 741     };
 742 
 743     CallLinkInfo* callLinkInfo = m_jit.codeBlock()-&gt;addCallLinkInfo();
 744     callLinkInfo-&gt;setUpCall(callType, m_currentNode-&gt;origin.semantic, calleeGPR);
 745 
 746     if (node-&gt;op() == CallEval) {
</pre>
<hr />
<pre>
 751 
 752         m_jit.emitStoreCallSiteIndex(callSite);
 753         m_jit.addPtr(TrustedImm32(-static_cast&lt;ptrdiff_t&gt;(sizeof(CallerFrameAndPC))), JITCompiler::stackPointerRegister, GPRInfo::regT0);
 754         m_jit.storePtr(GPRInfo::callFrameRegister, JITCompiler::Address(GPRInfo::regT0, CallFrame::callerFrameOffset()));
 755 
 756         // Now we need to make room for:
 757         // - The caller frame and PC of a call to operationCallEval.
 758         // - Potentially two arguments on the stack.
 759         unsigned requiredBytes = sizeof(CallerFrameAndPC) + sizeof(ExecState*) * 2;
 760         requiredBytes = WTF::roundUpToMultipleOf(stackAlignmentBytes(), requiredBytes);
 761         m_jit.subPtr(TrustedImm32(requiredBytes), JITCompiler::stackPointerRegister);
 762         m_jit.setupArguments&lt;decltype(operationCallEval)&gt;(GPRInfo::regT0);
 763         prepareForExternalCall();
 764         m_jit.appendCall(operationCallEval);
 765         m_jit.exceptionCheck();
 766         JITCompiler::Jump done = m_jit.branchIfNotEmpty(GPRInfo::returnValueGPR);
 767 
 768         // This is the part where we meant to make a normal call. Oops.
 769         m_jit.addPtr(TrustedImm32(requiredBytes), JITCompiler::stackPointerRegister);
 770         m_jit.load64(JITCompiler::calleeFrameSlot(CallFrameSlot::callee), GPRInfo::regT0);
<span class="line-modified"> 771         m_jit.emitDumbVirtualCall(*m_jit.vm(), callLinkInfo);</span>
 772 
 773         done.link(&amp;m_jit);
 774         setResultAndResetStack();
 775         return;
 776     }
 777 
 778     if (isDirect) {
 779         callLinkInfo-&gt;setExecutableDuringCompilation(executable);
 780         callLinkInfo-&gt;setMaxNumArguments(numAllocatedArgs);
 781 
 782         if (isTail) {
 783             RELEASE_ASSERT(node-&gt;op() == DirectTailCall);
 784 
 785             JITCompiler::PatchableJump patchableJump = m_jit.patchableJump();
 786             JITCompiler::Label mainPath = m_jit.label();
 787 
 788             m_jit.emitStoreCallSiteIndex(callSite);
 789 
 790             callLinkInfo-&gt;setFrameShuffleData(shuffleData);
 791             CallFrameShuffler(m_jit, shuffleData).prepareForTailCall();
</pre>
<hr />
<pre>
 926             if (spillFormat == DataFormatInt32) {
 927                 m_jit.load32(JITCompiler::addressFor(virtualRegister), gpr);
 928                 info.fillInt32(*m_stream, gpr);
 929                 returnFormat = DataFormatInt32;
 930             } else {
 931                 m_jit.load64(JITCompiler::addressFor(virtualRegister), gpr);
 932                 info.fillJSValue(*m_stream, gpr, DataFormatJSInt32);
 933                 returnFormat = DataFormatJSInt32;
 934             }
 935             return gpr;
 936         }
 937         m_jit.load64(JITCompiler::addressFor(virtualRegister), gpr);
 938 
 939         // Fill as JSValue, and fall through.
 940         info.fillJSValue(*m_stream, gpr, DataFormatJSInt32);
 941         m_gprs.unlock(gpr);
 942         FALLTHROUGH;
 943     }
 944 
 945     case DataFormatJS: {
<span class="line-modified"> 946         DFG_ASSERT(m_jit.graph(), m_currentNode, !(type &amp; SpecInt52Only));</span>
 947         // Check the value is an integer.
 948         GPRReg gpr = info.gpr();
 949         m_gprs.lock(gpr);
 950         if (type &amp; ~SpecInt32Only)
 951             speculationCheck(BadType, JSValueRegs(gpr), edge, m_jit.branchIfNotInt32(gpr));
 952         info.fillJSValue(*m_stream, gpr, DataFormatJSInt32);
 953         // If !strict we&#39;re done, return.
 954         if (!strict) {
 955             returnFormat = DataFormatJSInt32;
 956             return gpr;
 957         }
 958         // else fall through &amp; handle as DataFormatJSInt32.
 959         m_gprs.unlock(gpr);
 960         FALLTHROUGH;
 961     }
 962 
 963     case DataFormatJSInt32: {
 964         // In a strict fill we need to strip off the value tag.
 965         if (strict) {
 966             GPRReg gpr = info.gpr();
</pre>
<hr />
<pre>
1011 IGNORE_WARNINGS_END
1012 
1013 GPRReg SpeculativeJIT::fillSpeculateInt32(Edge edge, DataFormat&amp; returnFormat)
1014 {
1015     return fillSpeculateInt32Internal&lt;false&gt;(edge, returnFormat);
1016 }
1017 
1018 GPRReg SpeculativeJIT::fillSpeculateInt32Strict(Edge edge)
1019 {
1020     DataFormat mustBeDataFormatInt32;
1021     GPRReg result = fillSpeculateInt32Internal&lt;true&gt;(edge, mustBeDataFormatInt32);
1022     DFG_ASSERT(m_jit.graph(), m_currentNode, mustBeDataFormatInt32 == DataFormatInt32, mustBeDataFormatInt32);
1023     return result;
1024 }
1025 
1026 GPRReg SpeculativeJIT::fillSpeculateInt52(Edge edge, DataFormat desiredFormat)
1027 {
1028     ASSERT(desiredFormat == DataFormatInt52 || desiredFormat == DataFormatStrictInt52);
1029     AbstractValue&amp; value = m_state.forNode(edge);
1030 
<span class="line-modified">1031     m_interpreter.filter(value, SpecAnyInt);</span>
1032     if (value.isClear()) {
1033         if (mayHaveTypeCheck(edge.useKind()))
1034             terminateSpeculativeExecution(Uncountable, JSValueRegs(), 0);
1035         return allocate();
1036     }
1037 
1038     VirtualRegister virtualRegister = edge-&gt;virtualRegister();
1039     GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
1040 
1041     switch (info.registerFormat()) {
1042     case DataFormatNone: {
1043         GPRReg gpr = allocate();
1044 
1045         if (edge-&gt;hasConstant()) {
1046             JSValue jsValue = edge-&gt;asJSValue();
1047             ASSERT(jsValue.isAnyInt());
1048             m_gprs.retain(gpr, virtualRegister, SpillOrderConstant);
1049             int64_t value = jsValue.asAnyInt();
1050             if (desiredFormat == DataFormatInt52)
1051                 value = value &lt;&lt; JSValue::int52ShiftAmount;
</pre>
<hr />
<pre>
1587         structure.adopt(realStructure);
1588         scratch.adopt(realScratch);
1589         structureGPR = structure.gpr();
1590         scratchGPR = scratch.gpr();
1591     }
1592 
1593     MacroAssembler::Jump notCell = m_jit.branchIfNotCell(JSValueRegs(valueGPR));
1594     if (masqueradesAsUndefinedWatchpointValid) {
1595         DFG_TYPE_CHECK(
1596             JSValueRegs(valueGPR), nodeUse, (~SpecCellCheck) | SpecObject, m_jit.branchIfNotObject(valueGPR));
1597     } else {
1598         DFG_TYPE_CHECK(
1599             JSValueRegs(valueGPR), nodeUse, (~SpecCellCheck) | SpecObject, m_jit.branchIfNotObject(valueGPR));
1600 
1601         MacroAssembler::Jump isNotMasqueradesAsUndefined =
1602             m_jit.branchTest8(
1603                 MacroAssembler::Zero,
1604                 MacroAssembler::Address(valueGPR, JSCell::typeInfoFlagsOffset()),
1605                 MacroAssembler::TrustedImm32(MasqueradesAsUndefined));
1606 
<span class="line-modified">1607         m_jit.emitLoadStructure(*m_jit.vm(), valueGPR, structureGPR, scratchGPR);</span>
1608         speculationCheck(BadType, JSValueRegs(valueGPR), nodeUse,
1609             m_jit.branchPtr(
1610                 MacroAssembler::Equal,
1611                 MacroAssembler::Address(structureGPR, Structure::globalObjectOffset()),
1612                 TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.graph().globalObjectFor(m_currentNode-&gt;origin.semantic))));
1613 
1614         isNotMasqueradesAsUndefined.link(&amp;m_jit);
1615     }
1616     m_jit.move(TrustedImm32(ValueFalse), resultGPR);
1617     MacroAssembler::Jump done = m_jit.jump();
1618 
1619     notCell.link(&amp;m_jit);
1620 
1621     if (needsTypeCheck(nodeUse, SpecCellCheck | SpecOther)) {
1622         m_jit.move(valueGPR, resultGPR);
1623         m_jit.and64(MacroAssembler::TrustedImm32(~TagBitUndefined), resultGPR);
1624         typeCheck(
1625             JSValueRegs(valueGPR), nodeUse, SpecCellCheck | SpecOther, m_jit.branch64(
1626                 MacroAssembler::NotEqual,
1627                 resultGPR,
</pre>
<hr />
<pre>
1693 
1694     case UntypedUse: {
1695         JSValueOperand arg1(this, node-&gt;child1());
1696         GPRTemporary result(this);
1697 
1698         GPRReg arg1GPR = arg1.gpr();
1699         GPRReg resultGPR = result.gpr();
1700 
1701         FPRTemporary valueFPR(this);
1702         FPRTemporary tempFPR(this);
1703 
1704         bool shouldCheckMasqueradesAsUndefined = !masqueradesAsUndefinedWatchpointIsStillValid();
1705         JSGlobalObject* globalObject = m_jit.graph().globalObjectFor(node-&gt;origin.semantic);
1706         Optional&lt;GPRTemporary&gt; scratch;
1707         GPRReg scratchGPR = InvalidGPRReg;
1708         if (shouldCheckMasqueradesAsUndefined) {
1709             scratch.emplace(this);
1710             scratchGPR = scratch-&gt;gpr();
1711         }
1712         bool negateResult = true;
<span class="line-modified">1713         m_jit.emitConvertValueToBoolean(*m_jit.vm(), JSValueRegs(arg1GPR), resultGPR, scratchGPR, valueFPR.fpr(), tempFPR.fpr(), shouldCheckMasqueradesAsUndefined, globalObject, negateResult);</span>
1714         m_jit.or32(TrustedImm32(ValueFalse), resultGPR);
1715         jsValueResult(resultGPR, node, DataFormatJSBoolean);
1716         return;
1717     }
1718     case StringUse:
1719         return compileStringZeroLength(node);
1720 
1721     case StringOrOtherUse:
1722         return compileLogicalNotStringOrOther(node);
1723 
1724     default:
1725         DFG_CRASH(m_jit.graph(), node, &quot;Bad use kind&quot;);
1726         break;
1727     }
1728 }
1729 
1730 void SpeculativeJIT::emitObjectOrOtherBranch(Edge nodeUse, BasicBlock* taken, BasicBlock* notTaken)
1731 {
1732     JSValueOperand value(this, nodeUse, ManualOperandSpeculation);
1733     GPRTemporary scratch(this);
</pre>
<hr />
<pre>
1738 
1739     if (!masqueradesAsUndefinedWatchpointIsStillValid()) {
1740         GPRTemporary realStructure(this);
1741         structure.adopt(realStructure);
1742         structureGPR = structure.gpr();
1743     }
1744 
1745     MacroAssembler::Jump notCell = m_jit.branchIfNotCell(JSValueRegs(valueGPR));
1746     if (masqueradesAsUndefinedWatchpointIsStillValid()) {
1747         DFG_TYPE_CHECK(
1748             JSValueRegs(valueGPR), nodeUse, (~SpecCellCheck) | SpecObject, m_jit.branchIfNotObject(valueGPR));
1749     } else {
1750         DFG_TYPE_CHECK(
1751             JSValueRegs(valueGPR), nodeUse, (~SpecCellCheck) | SpecObject, m_jit.branchIfNotObject(valueGPR));
1752 
1753         JITCompiler::Jump isNotMasqueradesAsUndefined = m_jit.branchTest8(
1754             JITCompiler::Zero,
1755             MacroAssembler::Address(valueGPR, JSCell::typeInfoFlagsOffset()),
1756             TrustedImm32(MasqueradesAsUndefined));
1757 
<span class="line-modified">1758         m_jit.emitLoadStructure(*m_jit.vm(), valueGPR, structureGPR, scratchGPR);</span>
1759         speculationCheck(BadType, JSValueRegs(valueGPR), nodeUse,
1760             m_jit.branchPtr(
1761                 MacroAssembler::Equal,
1762                 MacroAssembler::Address(structureGPR, Structure::globalObjectOffset()),
1763                 TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.graph().globalObjectFor(m_currentNode-&gt;origin.semantic))));
1764 
1765         isNotMasqueradesAsUndefined.link(&amp;m_jit);
1766     }
1767     jump(taken, ForceJump);
1768 
1769     notCell.link(&amp;m_jit);
1770 
1771     if (needsTypeCheck(nodeUse, SpecCellCheck | SpecOther)) {
1772         m_jit.move(valueGPR, scratchGPR);
1773         m_jit.and64(MacroAssembler::TrustedImm32(~TagBitUndefined), scratchGPR);
1774         typeCheck(
1775             JSValueRegs(valueGPR), nodeUse, SpecCellCheck | SpecOther, m_jit.branch64(
1776                 MacroAssembler::NotEqual, scratchGPR, MacroAssembler::TrustedImm64(ValueNull)));
1777     }
1778     jump(notTaken);
</pre>
<hr />
<pre>
1866                 scratchGPR = scratch-&gt;gpr();
1867             }
1868 
1869             GPRReg resultGPR = result.gpr();
1870             FPRReg valueFPR = fprValue.fpr();
1871             FPRReg tempFPR = fprTemp.fpr();
1872 
1873             if (node-&gt;child1()-&gt;prediction() &amp; SpecInt32Only) {
1874                 branch64(MacroAssembler::Equal, valueGPR, MacroAssembler::TrustedImm64(JSValue::encode(jsNumber(0))), notTaken);
1875                 branch64(MacroAssembler::AboveOrEqual, valueGPR, GPRInfo::tagTypeNumberRegister, taken);
1876             }
1877 
1878             if (node-&gt;child1()-&gt;prediction() &amp; SpecBoolean) {
1879                 branch64(MacroAssembler::Equal, valueGPR, MacroAssembler::TrustedImm64(JSValue::encode(jsBoolean(false))), notTaken);
1880                 branch64(MacroAssembler::Equal, valueGPR, MacroAssembler::TrustedImm64(JSValue::encode(jsBoolean(true))), taken);
1881             }
1882 
1883             value.use();
1884 
1885             JSGlobalObject* globalObject = m_jit.graph().globalObjectFor(node-&gt;origin.semantic);
<span class="line-modified">1886             auto truthy = m_jit.branchIfTruthy(*m_jit.vm(), JSValueRegs(valueGPR), resultGPR, scratchGPR, valueFPR, tempFPR, shouldCheckMasqueradesAsUndefined, globalObject);</span>
1887             addBranch(truthy, taken);
1888             jump(notTaken);
1889         }
1890 
1891         noResult(node, UseChildrenCalledExplicitly);
1892         return;
1893     }
1894 
1895     default:
1896         DFG_CRASH(m_jit.graph(), m_currentNode, &quot;Bad use kind&quot;);
1897     }
1898 }
1899 
1900 void SpeculativeJIT::compile(Node* node)
1901 {
1902     NodeType op = node-&gt;op();
1903 
1904     if (validateDFGDoesGC) {
1905         bool expectDoesGC = doesGC(m_jit.graph(), node);
<span class="line-modified">1906         m_jit.store8(TrustedImm32(expectDoesGC), m_jit.vm()-&gt;heap.addressOfExpectDoesGC());</span>
1907     }
1908 
1909 #if ENABLE(DFG_REGISTER_ALLOCATION_VALIDATION)
1910     m_jit.clearRegisterAllocationOffsets();
1911 #endif
1912 
1913     switch (op) {
1914     case JSConstant:
1915     case DoubleConstant:
1916     case Int52Constant:
1917     case PhantomDirectArguments:
1918     case PhantomClonedArguments:
1919         initConstantInfo(node);
1920         break;
1921 
1922     case LazyJSConstant:
1923         compileLazyJSConstant(node);
1924         break;
1925 
1926     case Identity: {
</pre>
<hr />
<pre>
2055             recordSetLocal(DataFormatBoolean);
2056             break;
2057         }
2058 
2059         case FlushedJSValue: {
2060             JSValueOperand value(this, node-&gt;child1());
2061             m_jit.store64(value.gpr(), JITCompiler::addressFor(node-&gt;machineLocal()));
2062             noResult(node);
2063             recordSetLocal(dataFormatFor(node-&gt;variableAccessData()-&gt;flushFormat()));
2064             break;
2065         }
2066 
2067         default:
2068             DFG_CRASH(m_jit.graph(), node, &quot;Bad flush format&quot;);
2069             break;
2070         }
2071 
2072         break;
2073     }
2074 
<span class="line-modified">2075     case SetArgument:</span>

2076         // This is a no-op; it just marks the fact that the argument is being used.
2077         // But it may be profitable to use this as a hook to run speculation checks
2078         // on arguments, thereby allowing us to trivially eliminate such checks if
2079         // the argument is not used.
2080         recordSetLocal(dataFormatFor(node-&gt;variableAccessData()-&gt;flushFormat()));
2081         break;
2082 




2083     case ArithBitNot:
2084         compileBitwiseNot(node);
2085         break;
2086 
2087     case ValueBitAnd:
2088     case ValueBitXor:
2089     case ValueBitOr:
2090         compileValueBitwiseOp(node);
2091         break;
2092 
2093     case ArithBitAnd:
2094     case ArithBitOr:
2095     case ArithBitXor:
2096         compileBitwiseOp(node);
2097         break;
2098 




2099     case BitRShift:
<span class="line-modified">2100     case BitLShift:</span>
2101     case BitURShift:
2102         compileShiftOp(node);
2103         break;
2104 
2105     case UInt32ToNumber: {
2106         compileUInt32ToNumber(node);
2107         break;
2108     }
2109 
2110     case DoubleAsInt32: {
2111         compileDoubleAsInt32(node);
2112         break;
2113     }
2114 
2115     case ValueToInt32: {
2116         compileValueToInt32(node);
2117         break;
2118     }
2119 
2120     case DoubleRep: {
</pre>
<hr />
<pre>
2212         break;
2213 
2214     case ArithMul:
2215         compileArithMul(node);
2216         break;
2217 
2218     case ValueMul:
2219         compileValueMul(node);
2220         break;
2221 
2222     case ValueDiv: {
2223         compileValueDiv(node);
2224         break;
2225     }
2226 
2227     case ArithDiv: {
2228         compileArithDiv(node);
2229         break;
2230     }
2231 





2232     case ArithMod: {
2233         compileArithMod(node);
2234         break;
2235     }
2236 
2237     case ArithAbs:
2238         compileArithAbs(node);
2239         break;
2240 
2241     case ArithMin:
2242     case ArithMax: {
2243         compileArithMinMax(node);
2244         break;
2245     }
2246 




2247     case ArithPow:
2248         compileArithPow(node);
2249         break;
2250 
2251     case ArithSqrt:
2252         compileArithSqrt(node);
2253         break;
2254 
2255     case ArithFRound:
2256         compileArithFRound(node);
2257         break;
2258 
2259     case ArithRandom:
2260         compileArithRandom(node);
2261         break;
2262 
2263     case ArithRound:
2264     case ArithFloor:
2265     case ArithCeil:
2266     case ArithTrunc:
</pre>
<hr />
<pre>
2706 
2707                 if (!arrayMode.isOutOfBounds())
2708                     speculationCheck(OutOfBounds, JSValueRegs(), 0, slowCase);
2709 
2710                 m_jit.add32(TrustedImm32(1), propertyReg, temporaryReg);
2711                 m_jit.store32(temporaryReg, MacroAssembler::Address(storageReg, Butterfly::offsetOfPublicLength()));
2712 
2713                 inBounds.link(&amp;m_jit);
2714             }
2715 
2716             m_jit.store64(valueReg, MacroAssembler::BaseIndex(storageReg, propertyReg, MacroAssembler::TimesEight));
2717 
2718             base.use();
2719             property.use();
2720             value.use();
2721             storage.use();
2722 
2723             if (arrayMode.isOutOfBounds()) {
2724                 addSlowPathGenerator(slowPathCall(
2725                     slowCase, this,
<span class="line-modified">2726                     m_jit.codeBlock()-&gt;isStrictMode()</span>
2727                         ? (node-&gt;op() == PutByValDirect ? operationPutByValDirectBeyondArrayBoundsStrict : operationPutByValBeyondArrayBoundsStrict)
2728                         : (node-&gt;op() == PutByValDirect ? operationPutByValDirectBeyondArrayBoundsNonStrict : operationPutByValBeyondArrayBoundsNonStrict),
2729                     NoResult, baseReg, propertyReg, valueReg));
2730             }
2731 
2732             noResult(node, UseChildrenCalledExplicitly);
2733             break;
2734         }
2735 
2736         case Array::Double: {
2737             compileDoublePutByVal(node, base, property);
2738             break;
2739         }
2740 
2741         case Array::ArrayStorage:
2742         case Array::SlowPutArrayStorage: {
2743             JSValueOperand value(this, child3);
2744 
2745             GPRReg valueReg = value.gpr();
2746 
</pre>
<hr />
<pre>
2790                     MacroAssembler::Jump lengthDoesNotNeedUpdate = m_jit.branch32(MacroAssembler::Below, propertyReg, MacroAssembler::Address(storageReg, ArrayStorage::lengthOffset()));
2791                     m_jit.add32(TrustedImm32(1), propertyReg, temporaryReg);
2792                     m_jit.store32(temporaryReg, MacroAssembler::Address(storageReg, ArrayStorage::lengthOffset()));
2793 
2794                     lengthDoesNotNeedUpdate.link(&amp;m_jit);
2795                 }
2796                 notHoleValue.link(&amp;m_jit);
2797             }
2798 
2799             // Store the value to the array.
2800             m_jit.store64(valueReg, MacroAssembler::BaseIndex(storageReg, propertyReg, MacroAssembler::TimesEight, ArrayStorage::vectorOffset()));
2801 
2802             base.use();
2803             property.use();
2804             value.use();
2805             storage.use();
2806 
2807             if (!slowCases.empty()) {
2808                 addSlowPathGenerator(slowPathCall(
2809                     slowCases, this,
<span class="line-modified">2810                     m_jit.codeBlock()-&gt;isStrictMode()</span>
2811                         ? (node-&gt;op() == PutByValDirect ? operationPutByValDirectBeyondArrayBoundsStrict : operationPutByValBeyondArrayBoundsStrict)
2812                         : (node-&gt;op() == PutByValDirect ? operationPutByValDirectBeyondArrayBoundsNonStrict : operationPutByValBeyondArrayBoundsNonStrict),
2813                     NoResult, baseReg, propertyReg, valueReg));
2814             }
2815 
2816             noResult(node, UseChildrenCalledExplicitly);
2817             break;
2818         }
2819 
2820         case Array::Int8Array:
2821         case Array::Int16Array:
2822         case Array::Int32Array:
2823         case Array::Uint8Array:
2824         case Array::Uint8ClampedArray:
2825         case Array::Uint16Array:
2826         case Array::Uint32Array:
2827         case Array::Float32Array:
2828         case Array::Float64Array: {
2829             TypedArrayType type = arrayMode.typedArrayType();
2830             if (isInt(type))
</pre>
<hr />
<pre>
3878         m_jit.compare64(JITCompiler::Equal, value.gpr(), TrustedImm32(ValueUndefined), result.gpr());
3879         JITCompiler::Jump done = m_jit.jump();
3880 
3881         isCell.link(&amp;m_jit);
3882         JITCompiler::Jump notMasqueradesAsUndefined;
3883         if (masqueradesAsUndefinedWatchpointIsStillValid()) {
3884             m_jit.move(TrustedImm32(0), result.gpr());
3885             notMasqueradesAsUndefined = m_jit.jump();
3886         } else {
3887             JITCompiler::Jump isMasqueradesAsUndefined = m_jit.branchTest8(
3888                 JITCompiler::NonZero,
3889                 JITCompiler::Address(value.gpr(), JSCell::typeInfoFlagsOffset()),
3890                 TrustedImm32(MasqueradesAsUndefined));
3891             m_jit.move(TrustedImm32(0), result.gpr());
3892             notMasqueradesAsUndefined = m_jit.jump();
3893 
3894             isMasqueradesAsUndefined.link(&amp;m_jit);
3895             GPRReg localGlobalObjectGPR = localGlobalObject.gpr();
3896             GPRReg remoteGlobalObjectGPR = remoteGlobalObject.gpr();
3897             m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.globalObjectFor(node-&gt;origin.semantic)), localGlobalObjectGPR);
<span class="line-modified">3898             m_jit.emitLoadStructure(*m_jit.vm(), value.gpr(), result.gpr(), scratch.gpr());</span>
3899             m_jit.loadPtr(JITCompiler::Address(result.gpr(), Structure::globalObjectOffset()), remoteGlobalObjectGPR);
3900             m_jit.comparePtr(JITCompiler::Equal, localGlobalObjectGPR, remoteGlobalObjectGPR, result.gpr());
3901         }
3902 
3903         notMasqueradesAsUndefined.link(&amp;m_jit);
3904         done.link(&amp;m_jit);
3905         m_jit.or32(TrustedImm32(ValueFalse), result.gpr());
3906         jsValueResult(result.gpr(), node, DataFormatJSBoolean);
3907         break;
3908     }
3909 
3910     case IsUndefinedOrNull: {
3911         JSValueOperand value(this, node-&gt;child1());
3912         GPRTemporary result(this, Reuse, value);
3913 
3914         GPRReg valueGPR = value.gpr();
3915         GPRReg resultGPR = result.gpr();
3916 
3917         m_jit.move(valueGPR, resultGPR);
3918         m_jit.and64(CCallHelpers::TrustedImm32(~TagBitUndefined), resultGPR);
</pre>
<hr />
<pre>
4200         if (!loopAround.empty())
4201             loopAround.link(&amp;m_jit);
4202 
4203         m_jit.add32(TrustedImm32(1), indexGPR);
4204         m_jit.jump().linkTo(loop, &amp;m_jit);
4205 
4206         if (!slowPathCases.empty()) {
4207             slowPathCases.link(&amp;m_jit);
4208             silentSpillAllRegisters(indexGPR);
4209             if (node-&gt;child1().useKind() == MapObjectUse)
4210                 callOperation(operationJSMapFindBucket, resultGPR, mapGPR, keyGPR, hashGPR);
4211             else
4212                 callOperation(operationJSSetFindBucket, resultGPR, mapGPR, keyGPR, hashGPR);
4213             silentFillAllRegisters();
4214             m_jit.exceptionCheck();
4215             done.append(m_jit.jump());
4216         }
4217 
4218         notPresentInTable.link(&amp;m_jit);
4219         if (node-&gt;child1().useKind() == MapObjectUse)
<span class="line-modified">4220             m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.vm()-&gt;sentinelMapBucket()), resultGPR);</span>
4221         else
<span class="line-modified">4222             m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.vm()-&gt;sentinelSetBucket()), resultGPR);</span>
4223         done.link(&amp;m_jit);
4224         cellResult(resultGPR, node);
4225         break;
4226     }
4227 
4228     case GetMapBucketHead:
4229         compileGetMapBucketHead(node);
4230         break;
4231 
4232     case GetMapBucketNext:
4233         compileGetMapBucketNext(node);
4234         break;
4235 
4236     case LoadKeyFromMapBucket:
4237         compileLoadKeyFromMapBucket(node);
4238         break;
4239 
4240     case LoadValueFromMapBucket:
4241         compileLoadValueFromMapBucket(node);
4242         break;
</pre>
<hr />
<pre>
4436         GPRReg tempGPR = temp.gpr();
4437         GPRReg hashGPR = hash.gpr();
4438         GPRReg structureIDGPR = structureID.gpr();
4439         GPRReg resultGPR = result.gpr();
4440 
4441         speculateObject(node-&gt;child1());
4442 
4443         MacroAssembler::JumpList slowPath;
4444         switch (node-&gt;child2().useKind()) {
4445         case SymbolUse: {
4446             speculateSymbol(node-&gt;child2(), keyGPR);
4447             m_jit.loadPtr(MacroAssembler::Address(keyGPR, Symbol::offsetOfSymbolImpl()), implGPR);
4448             break;
4449         }
4450         case StringUse: {
4451             speculateString(node-&gt;child2(), keyGPR);
4452             m_jit.loadPtr(MacroAssembler::Address(keyGPR, JSString::offsetOfValue()), implGPR);
4453             slowPath.append(m_jit.branchIfRopeStringImpl(implGPR));
4454             slowPath.append(m_jit.branchTest32(
4455                 MacroAssembler::Zero, MacroAssembler::Address(implGPR, StringImpl::flagsOffset()),
<span class="line-modified">4456                 MacroAssembler::TrustedImm32(StringImpl::flagIsAtomic())));</span>
4457             break;
4458         }
4459         case UntypedUse: {
4460             slowPath.append(m_jit.branchIfNotCell(JSValueRegs(keyGPR)));
4461             auto isNotString = m_jit.branchIfNotString(keyGPR);
4462             m_jit.loadPtr(MacroAssembler::Address(keyGPR, JSString::offsetOfValue()), implGPR);
4463             slowPath.append(m_jit.branchIfRopeStringImpl(implGPR));
4464             slowPath.append(m_jit.branchTest32(
4465                 MacroAssembler::Zero, MacroAssembler::Address(implGPR, StringImpl::flagsOffset()),
<span class="line-modified">4466                 MacroAssembler::TrustedImm32(StringImpl::flagIsAtomic())));</span>
4467             auto hasUniquedImpl = m_jit.jump();
4468 
4469             isNotString.link(&amp;m_jit);
4470             slowPath.append(m_jit.branchIfNotSymbol(keyGPR));
4471             m_jit.loadPtr(MacroAssembler::Address(keyGPR, Symbol::offsetOfSymbolImpl()), implGPR);
4472 
4473             hasUniquedImpl.link(&amp;m_jit);
4474             break;
4475         }
4476         default:
4477             RELEASE_ASSERT_NOT_REACHED();
4478         }
4479 
<span class="line-modified">4480         // Note that we don&#39;t test if the hash is zero here. AtomicStringImpl&#39;s can&#39;t have a zero</span>
4481         // hash, however, a SymbolImpl may. But, because this is a cache, we don&#39;t care. We only
4482         // ever load the result from the cache if the cache entry matches what we are querying for.
4483         // So we either get super lucky and use zero for the hash and somehow collide with the entity
4484         // we&#39;re looking for, or we realize we&#39;re comparing against another entity, and go to the
4485         // slow path anyways.
4486         m_jit.load32(MacroAssembler::Address(implGPR, UniquedStringImpl::flagsOffset()), hashGPR);
4487         m_jit.urshift32(MacroAssembler::TrustedImm32(StringImpl::s_flagCount), hashGPR);
4488         m_jit.load32(MacroAssembler::Address(objectGPR, JSCell::structureIDOffset()), structureIDGPR);
4489         m_jit.add32(structureIDGPR, hashGPR);
4490         m_jit.and32(TrustedImm32(HasOwnPropertyCache::mask), hashGPR);
4491         if (hasOneBitSet(sizeof(HasOwnPropertyCache::Entry))) // is a power of 2
4492             m_jit.lshift32(TrustedImm32(getLSBSet(sizeof(HasOwnPropertyCache::Entry))), hashGPR);
4493         else
4494             m_jit.mul32(TrustedImm32(sizeof(HasOwnPropertyCache::Entry)), hashGPR, hashGPR);
<span class="line-modified">4495         ASSERT(m_jit.vm()-&gt;hasOwnPropertyCache());</span>
<span class="line-modified">4496         m_jit.move(TrustedImmPtr(m_jit.vm()-&gt;hasOwnPropertyCache()), tempGPR);</span>
4497         slowPath.append(m_jit.branchPtr(MacroAssembler::NotEqual,
4498             MacroAssembler::BaseIndex(tempGPR, hashGPR, MacroAssembler::TimesOne, HasOwnPropertyCache::Entry::offsetOfImpl()), implGPR));
4499         m_jit.load8(MacroAssembler::BaseIndex(tempGPR, hashGPR, MacroAssembler::TimesOne, HasOwnPropertyCache::Entry::offsetOfResult()), resultGPR);
4500         m_jit.load32(MacroAssembler::BaseIndex(tempGPR, hashGPR, MacroAssembler::TimesOne, HasOwnPropertyCache::Entry::offsetOfStructureID()), tempGPR);
4501         slowPath.append(m_jit.branch32(MacroAssembler::NotEqual, tempGPR, structureIDGPR));
4502         auto done = m_jit.jump();
4503 
4504         slowPath.link(&amp;m_jit);
4505         silentSpillAllRegisters(resultGPR);
4506         callOperation(operationHasOwnProperty, resultGPR, objectGPR, keyGPR);
4507         silentFillAllRegisters();
4508         m_jit.exceptionCheck();
4509 
4510         done.link(&amp;m_jit);
4511         m_jit.or32(TrustedImm32(ValueFalse), resultGPR);
4512         jsValueResult(resultGPR, node, DataFormatJSBoolean);
4513         break;
4514     }
4515 
4516     case CountExecution:
</pre>
<hr />
<pre>
4652         GPRTemporary temp1(this);
4653         GPRReg t1 = temp1.gpr();
4654         GPRTemporary temp2(this);
4655         GPRReg t2 = temp2.gpr();
4656 
4657         Optional&lt;SpeculateBooleanOperand&gt; isLittleEndianOperand;
4658         if (node-&gt;child3())
4659             isLittleEndianOperand.emplace(this, node-&gt;child3());
4660         GPRReg isLittleEndianGPR = isLittleEndianOperand ? isLittleEndianOperand-&gt;gpr() : InvalidGPRReg;
4661 
4662         DataViewData data = node-&gt;dataViewData();
4663 
4664         m_jit.zeroExtend32ToPtr(indexGPR, t2);
4665         if (data.byteSize &gt; 1)
4666             m_jit.add64(TrustedImm32(data.byteSize - 1), t2);
4667         m_jit.load32(MacroAssembler::Address(dataViewGPR, JSArrayBufferView::offsetOfLength()), t1);
4668         speculationCheck(OutOfBounds, JSValueRegs(), node,
4669             m_jit.branch64(MacroAssembler::AboveOrEqual, t2, t1));
4670 
4671         m_jit.loadPtr(JITCompiler::Address(dataViewGPR, JSArrayBufferView::offsetOfVector()), t2);
<span class="line-modified">4672         cageTypedArrayStorage(t2);</span>
4673 
4674         m_jit.zeroExtend32ToPtr(indexGPR, t1);
4675         auto baseIndex = JITCompiler::BaseIndex(t2, t1, MacroAssembler::TimesOne);
4676 
4677         if (node-&gt;op() == DataViewGetInt) {
4678             switch (data.byteSize) {
4679             case 1:
4680                 if (data.isSigned)
4681                     m_jit.load8SignedExtendTo32(baseIndex, t2);
4682                 else
4683                     m_jit.load8(baseIndex, t2);
4684                 int32Result(t2, node);
4685                 break;
4686             case 2: {
4687                 auto emitLittleEndianLoad = [&amp;] {
4688                     if (data.isSigned)
4689                         m_jit.load16SignedExtendTo32(baseIndex, t2);
4690                     else
4691                         m_jit.load16(baseIndex, t2);
4692                 };
</pre>
<hr />
<pre>
4848         GPRTemporary temp1(this);
4849         GPRReg t1 = temp1.gpr();
4850         GPRTemporary temp2(this);
4851         GPRReg t2 = temp2.gpr();
4852         GPRTemporary temp3(this);
4853         GPRReg t3 = temp3.gpr();
4854 
4855         Optional&lt;SpeculateBooleanOperand&gt; isLittleEndianOperand;
4856         if (m_graph.varArgChild(node, 3))
4857             isLittleEndianOperand.emplace(this, m_graph.varArgChild(node, 3));
4858         GPRReg isLittleEndianGPR = isLittleEndianOperand ? isLittleEndianOperand-&gt;gpr() : InvalidGPRReg;
4859 
4860         m_jit.zeroExtend32ToPtr(indexGPR, t2);
4861         if (data.byteSize &gt; 1)
4862             m_jit.add64(TrustedImm32(data.byteSize - 1), t2);
4863         m_jit.load32(MacroAssembler::Address(dataViewGPR, JSArrayBufferView::offsetOfLength()), t1);
4864         speculationCheck(OutOfBounds, JSValueRegs(), node,
4865             m_jit.branch64(MacroAssembler::AboveOrEqual, t2, t1));
4866 
4867         m_jit.loadPtr(JITCompiler::Address(dataViewGPR, JSArrayBufferView::offsetOfVector()), t2);
<span class="line-modified">4868         cageTypedArrayStorage(t2);</span>
4869 
4870         m_jit.zeroExtend32ToPtr(indexGPR, t1);
4871         auto baseIndex = JITCompiler::BaseIndex(t2, t1, MacroAssembler::TimesOne);
4872 
4873         if (data.isFloatingPoint) {
4874             RELEASE_ASSERT(valueFPR != InvalidFPRReg);
4875             if (data.byteSize == 4) {
4876                 RELEASE_ASSERT(tempFPR != InvalidFPRReg);
4877                 m_jit.convertDoubleToFloat(valueFPR, tempFPR);
4878 
4879                 auto emitLittleEndianCode = [&amp;] {
4880                     m_jit.storeFloat(tempFPR, baseIndex);
4881                 };
4882 
4883                 auto emitBigEndianCode = [&amp;] {
4884                     m_jit.moveFloatTo32(tempFPR, t3);
4885                     m_jit.byteSwap32(t3);
4886                     m_jit.store32(t3, baseIndex);
4887                 };
4888 
</pre>
<hr />
<pre>
4993             default:
4994                 RELEASE_ASSERT_NOT_REACHED();
4995             }
4996         }
4997 
4998         noResult(node);
4999         break;
5000     }
5001 
5002 #if ENABLE(FTL_JIT)
5003     case CheckTierUpInLoop: {
5004         MacroAssembler::Jump callTierUp = m_jit.branchAdd32(
5005             MacroAssembler::PositiveOrZero,
5006             TrustedImm32(Options::ftlTierUpCounterIncrementForLoop()),
5007             MacroAssembler::AbsoluteAddress(&amp;m_jit.jitCode()-&gt;tierUpCounter.m_counter));
5008 
5009         MacroAssembler::Label toNextOperation = m_jit.label();
5010 
5011         Vector&lt;SilentRegisterSavePlan&gt; savePlans;
5012         silentSpillAllRegistersImpl(false, savePlans, InvalidGPRReg);
<span class="line-modified">5013         unsigned bytecodeIndex = node-&gt;origin.semantic.bytecodeIndex;</span>
5014 
5015         addSlowPathGeneratorLambda([=]() {
5016             callTierUp.link(&amp;m_jit);
5017 
5018             silentSpill(savePlans);
5019             callOperation(triggerTierUpNowInLoop, TrustedImm32(bytecodeIndex));
5020             silentFill(savePlans);
5021 
5022             m_jit.jump().linkTo(toNextOperation, &amp;m_jit);
5023         });
5024         break;
5025     }
5026 
5027     case CheckTierUpAtReturn: {
5028         MacroAssembler::Jump done = m_jit.branchAdd32(
5029             MacroAssembler::Signed,
5030             TrustedImm32(Options::ftlTierUpCounterIncrementForReturn()),
5031             MacroAssembler::AbsoluteAddress(&amp;m_jit.jitCode()-&gt;tierUpCounter.m_counter));
5032 
5033         silentSpillAllRegisters(InvalidGPRReg);
5034         callOperation(triggerTierUpNow);
5035         silentFillAllRegisters();
5036 
5037         done.link(&amp;m_jit);
5038         break;
5039     }
5040 
5041     case CheckTierUpAndOSREnter: {
<span class="line-modified">5042         ASSERT(!node-&gt;origin.semantic.inlineCallFrame);</span>
5043 
5044         GPRTemporary temp(this);
5045         GPRReg tempGPR = temp.gpr();
5046 
<span class="line-modified">5047         unsigned bytecodeIndex = node-&gt;origin.semantic.bytecodeIndex;</span>
5048         auto triggerIterator = m_jit.jitCode()-&gt;tierUpEntryTriggers.find(bytecodeIndex);
5049         DFG_ASSERT(m_jit.graph(), node, triggerIterator != m_jit.jitCode()-&gt;tierUpEntryTriggers.end());
5050         JITCode::TriggerReason* forceEntryTrigger = &amp;(m_jit.jitCode()-&gt;tierUpEntryTriggers.find(bytecodeIndex)-&gt;value);
5051         static_assert(!static_cast&lt;uint8_t&gt;(JITCode::TriggerReason::DontTrigger), &quot;the JIT code assumes non-zero means &#39;enter&#39;&quot;);
5052         static_assert(sizeof(JITCode::TriggerReason) == 1, &quot;branchTest8 assumes this size&quot;);
5053 
5054         MacroAssembler::Jump forceOSREntry = m_jit.branchTest8(MacroAssembler::NonZero, MacroAssembler::AbsoluteAddress(forceEntryTrigger));
5055         MacroAssembler::Jump overflowedCounter = m_jit.branchAdd32(
5056             MacroAssembler::PositiveOrZero,
5057             TrustedImm32(Options::ftlTierUpCounterIncrementForLoop()),
5058             MacroAssembler::AbsoluteAddress(&amp;m_jit.jitCode()-&gt;tierUpCounter.m_counter));
5059         MacroAssembler::Label toNextOperation = m_jit.label();
5060 
5061         Vector&lt;SilentRegisterSavePlan&gt; savePlans;
5062         silentSpillAllRegistersImpl(false, savePlans, tempGPR);
5063 
5064         unsigned streamIndex = m_stream-&gt;size();
5065         m_jit.jitCode()-&gt;bytecodeIndexToStreamIndex.add(bytecodeIndex, streamIndex);
5066 
5067         addSlowPathGeneratorLambda([=]() {
5068             forceOSREntry.link(&amp;m_jit);
5069             overflowedCounter.link(&amp;m_jit);
5070 
5071             silentSpill(savePlans);
5072             callOperation(triggerOSREntryNow, tempGPR, TrustedImm32(bytecodeIndex));
5073 
5074             if (savePlans.isEmpty())
5075                 m_jit.branchTestPtr(MacroAssembler::Zero, tempGPR).linkTo(toNextOperation, &amp;m_jit);
5076             else {
5077                 MacroAssembler::Jump osrEnter = m_jit.branchTestPtr(MacroAssembler::NonZero, tempGPR);
5078                 silentFill(savePlans);
5079                 m_jit.jump().linkTo(toNextOperation, &amp;m_jit);
5080                 osrEnter.link(&amp;m_jit);
5081             }
5082             m_jit.emitRestoreCalleeSaves();
<span class="line-modified">5083             m_jit.jump(tempGPR, GPRInfo::callFrameRegister);</span>
5084         });
5085         break;
5086     }
5087 
5088 #else // ENABLE(FTL_JIT)
5089     case CheckTierUpInLoop:
5090     case CheckTierUpAtReturn:
5091     case CheckTierUpAndOSREnter:
5092         DFG_CRASH(m_jit.graph(), node, &quot;Unexpected tier-up node&quot;);
5093         break;
5094 #endif // ENABLE(FTL_JIT)
5095 
5096     case FilterCallLinkStatus:
5097     case FilterGetByIdStatus:
5098     case FilterPutByIdStatus:
5099     case FilterInByIdStatus:
5100         m_interpreter.filterICStatus(node);
5101         noResult(node);
5102         break;
5103 
</pre>
</td>
<td>
<hr />
<pre>
 200     JITGetByIdWithThisGenerator gen(
 201         m_jit.codeBlock(), codeOrigin, callSite, usedRegisters, identifierUID(identifierNumber),
 202         JSValueRegs(resultGPR), JSValueRegs(baseGPR), JSValueRegs(thisGPR), AccessType::GetWithThis);
 203     gen.generateFastPath(m_jit);
 204 
 205     JITCompiler::JumpList slowCases;
 206     slowCases.append(slowPathTarget);
 207     slowCases.append(gen.slowPathJump());
 208 
 209     std::unique_ptr&lt;SlowPathGenerator&gt; slowPath = slowPathCall(
 210         slowCases, this, operationGetByIdWithThisOptimize,
 211         DontSpill, ExceptionCheckRequirement::CheckNeeded,
 212         resultGPR, gen.stubInfo(), baseGPR, thisGPR, identifierUID(identifierNumber));
 213 
 214     m_jit.addGetByIdWithThis(gen, slowPath.get());
 215     addSlowPathGenerator(WTFMove(slowPath));
 216 }
 217 
 218 void SpeculativeJIT::nonSpeculativeNonPeepholeCompareNullOrUndefined(Edge operand)
 219 {


 220     JSValueOperand arg(this, operand, ManualOperandSpeculation);
 221     GPRReg argGPR = arg.gpr();
 222 
 223     GPRTemporary result(this);
 224     GPRReg resultGPR = result.gpr();
 225 
 226     m_jit.move(TrustedImm32(0), resultGPR);
 227 
 228     JITCompiler::JumpList done;
 229     if (masqueradesAsUndefinedWatchpointIsStillValid()) {
 230         if (!isKnownNotCell(operand.node()))
 231             done.append(m_jit.branchIfCell(JSValueRegs(argGPR)));
 232     } else {
 233         GPRTemporary localGlobalObject(this);
 234         GPRTemporary remoteGlobalObject(this);
 235         GPRTemporary scratch(this);
 236 
 237         JITCompiler::Jump notCell;
 238         if (!isKnownCell(operand.node()))
 239             notCell = m_jit.branchIfNotCell(JSValueRegs(argGPR));
 240 
 241         JITCompiler::Jump isNotMasqueradesAsUndefined = m_jit.branchTest8(
 242             JITCompiler::Zero,
 243             JITCompiler::Address(argGPR, JSCell::typeInfoFlagsOffset()),
 244             JITCompiler::TrustedImm32(MasqueradesAsUndefined));
 245         done.append(isNotMasqueradesAsUndefined);
 246 
 247         GPRReg localGlobalObjectGPR = localGlobalObject.gpr();
 248         GPRReg remoteGlobalObjectGPR = remoteGlobalObject.gpr();
 249         m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.graph().globalObjectFor(m_currentNode-&gt;origin.semantic)), localGlobalObjectGPR);
<span class="line-modified"> 250         m_jit.emitLoadStructure(vm(), argGPR, resultGPR, scratch.gpr());</span>
 251         m_jit.loadPtr(JITCompiler::Address(resultGPR, Structure::globalObjectOffset()), remoteGlobalObjectGPR);
 252         m_jit.comparePtr(JITCompiler::Equal, localGlobalObjectGPR, remoteGlobalObjectGPR, resultGPR);
 253         done.append(m_jit.jump());
 254         if (!isKnownCell(operand.node()))
 255             notCell.link(&amp;m_jit);
 256     }
 257 
 258     if (!isKnownNotOther(operand.node())) {
 259         m_jit.move(argGPR, resultGPR);
 260         m_jit.and64(JITCompiler::TrustedImm32(~TagBitUndefined), resultGPR);
 261         m_jit.compare64(JITCompiler::Equal, resultGPR, JITCompiler::TrustedImm32(ValueNull), resultGPR);
 262     }
 263 
 264     done.link(&amp;m_jit);
 265 
 266     m_jit.or32(TrustedImm32(ValueFalse), resultGPR);
 267     jsValueResult(resultGPR, m_currentNode, DataFormatJSBoolean);
 268 }
 269 
 270 void SpeculativeJIT::nonSpeculativePeepholeBranchNullOrUndefined(Edge operand, Node* branchNode)
</pre>
<hr />
<pre>
 283         if (!isKnownNotCell(operand.node())) {
 284             JITCompiler::Jump isCell = m_jit.branchIfCell(JSValueRegs(argGPR));
 285             addBranch(isCell, notTaken);
 286         }
 287     } else {
 288         GPRTemporary localGlobalObject(this);
 289         GPRTemporary remoteGlobalObject(this);
 290         GPRTemporary scratch(this);
 291 
 292         JITCompiler::Jump notCell;
 293         if (!isKnownCell(operand.node()))
 294             notCell = m_jit.branchIfNotCell(JSValueRegs(argGPR));
 295 
 296         branchTest8(JITCompiler::Zero,
 297             JITCompiler::Address(argGPR, JSCell::typeInfoFlagsOffset()),
 298             JITCompiler::TrustedImm32(MasqueradesAsUndefined), notTaken);
 299 
 300         GPRReg localGlobalObjectGPR = localGlobalObject.gpr();
 301         GPRReg remoteGlobalObjectGPR = remoteGlobalObject.gpr();
 302         m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.graph().globalObjectFor(m_currentNode-&gt;origin.semantic)), localGlobalObjectGPR);
<span class="line-modified"> 303         m_jit.emitLoadStructure(vm(), argGPR, resultGPR, scratch.gpr());</span>
 304         m_jit.loadPtr(JITCompiler::Address(resultGPR, Structure::globalObjectOffset()), remoteGlobalObjectGPR);
 305         branchPtr(JITCompiler::Equal, localGlobalObjectGPR, remoteGlobalObjectGPR, taken);
 306 
 307         if (!isKnownCell(operand.node())) {
 308             jump(notTaken, ForceJump);
 309             notCell.link(&amp;m_jit);
 310         }
 311     }
 312 
 313     if (isKnownNotOther(operand.node()))
 314         jump(notTaken);
 315     else {
 316         JITCompiler::RelationalCondition condition = JITCompiler::Equal;
 317         if (taken == nextBlock()) {
 318             condition = JITCompiler::NotEqual;
 319             std::swap(taken, notTaken);
 320         }
 321         m_jit.move(argGPR, resultGPR);
 322         m_jit.and64(JITCompiler::TrustedImm32(~TagBitUndefined), resultGPR);
 323         branch64(condition, resultGPR, JITCompiler::TrustedImm64(ValueNull), taken);
</pre>
<hr />
<pre>
 530         isTail = true;
 531         isDirect = true;
 532         break;
 533     case DirectTailCallInlinedCaller:
 534         callType = CallLinkInfo::DirectCall;
 535         isEmulatedTail = true;
 536         isDirect = true;
 537         break;
 538     default:
 539         DFG_CRASH(m_jit.graph(), node, &quot;bad node type&quot;);
 540         break;
 541     }
 542 
 543     GPRReg calleeGPR = InvalidGPRReg;
 544     CallFrameShuffleData shuffleData;
 545 
 546     ExecutableBase* executable = nullptr;
 547     FunctionExecutable* functionExecutable = nullptr;
 548     if (isDirect) {
 549         executable = node-&gt;castOperand&lt;ExecutableBase*&gt;();
<span class="line-modified"> 550         functionExecutable = jsDynamicCast&lt;FunctionExecutable*&gt;(vm(), executable);</span>
 551     }
 552 
 553     unsigned numPassedArgs = 0;
 554     unsigned numAllocatedArgs = 0;
 555 
 556     // Gotta load the arguments somehow. Varargs is trickier.
 557     if (isVarargs || isForwardVarargs) {
 558         RELEASE_ASSERT(!isDirect);
 559         CallVarargsData* data = node-&gt;callVarargsData();
 560 
 561         int numUsedStackSlots = m_jit.graph().m_nextMachineLocal;
 562 
 563         if (isForwardVarargs) {
 564             flushRegisters();
 565             if (node-&gt;child3())
 566                 use(node-&gt;child3());
 567 
 568             GPRReg scratchGPR1;
 569             GPRReg scratchGPR2;
 570             GPRReg scratchGPR3;
 571 
 572             scratchGPR1 = JITCompiler::selectScratchGPR();
 573             scratchGPR2 = JITCompiler::selectScratchGPR(scratchGPR1);
 574             scratchGPR3 = JITCompiler::selectScratchGPR(scratchGPR1, scratchGPR2);
 575 
 576             m_jit.move(TrustedImm32(numUsedStackSlots), scratchGPR2);
 577             JITCompiler::JumpList slowCase;
 578             InlineCallFrame* inlineCallFrame;
 579             if (node-&gt;child3())
<span class="line-modified"> 580                 inlineCallFrame = node-&gt;child3()-&gt;origin.semantic.inlineCallFrame();</span>
 581             else
<span class="line-modified"> 582                 inlineCallFrame = node-&gt;origin.semantic.inlineCallFrame();</span>
 583             // emitSetupVarargsFrameFastCase modifies the stack pointer if it succeeds.
<span class="line-modified"> 584             emitSetupVarargsFrameFastCase(vm(), m_jit, scratchGPR2, scratchGPR1, scratchGPR2, scratchGPR3, inlineCallFrame, data-&gt;firstVarArgOffset, slowCase);</span>
 585             JITCompiler::Jump done = m_jit.jump();
 586             slowCase.link(&amp;m_jit);
 587             callOperation(operationThrowStackOverflowForVarargs);
 588             m_jit.exceptionCheck();
 589             m_jit.abortWithReason(DFGVarargsThrowingPathDidNotThrow);
 590             done.link(&amp;m_jit);
 591         } else {
 592             GPRReg argumentsGPR;
 593             GPRReg scratchGPR1;
 594             GPRReg scratchGPR2;
 595             GPRReg scratchGPR3;
 596 
 597             auto loadArgumentsGPR = [&amp;] (GPRReg reservedGPR) {
 598                 if (reservedGPR != InvalidGPRReg)
 599                     lock(reservedGPR);
 600                 JSValueOperand arguments(this, node-&gt;child3());
 601                 argumentsGPR = arguments.gpr();
 602                 if (reservedGPR != InvalidGPRReg)
 603                     unlock(reservedGPR);
 604                 flushRegisters();
</pre>
<hr />
<pre>
 701 
 702                 m_jit.store64(argGPR, JITCompiler::calleeArgumentSlot(i));
 703             }
 704 
 705             for (unsigned i = numPassedArgs; i &lt; numAllocatedArgs; ++i)
 706                 m_jit.storeTrustedValue(jsUndefined(), JITCompiler::calleeArgumentSlot(i));
 707         }
 708     }
 709 
 710     if (!isTail || isVarargs || isForwardVarargs) {
 711         Edge calleeEdge = m_jit.graph().child(node, 0);
 712         JSValueOperand callee(this, calleeEdge);
 713         calleeGPR = callee.gpr();
 714         callee.use();
 715         m_jit.store64(calleeGPR, JITCompiler::calleeFrameSlot(CallFrameSlot::callee));
 716 
 717         flushRegisters();
 718     }
 719 
 720     CodeOrigin staticOrigin = node-&gt;origin.semantic;
<span class="line-modified"> 721     InlineCallFrame* staticInlineCallFrame = staticOrigin.inlineCallFrame();</span>
<span class="line-modified"> 722     ASSERT(!isTail || !staticInlineCallFrame || !staticInlineCallFrame-&gt;getCallerSkippingTailCalls());</span>
<span class="line-added"> 723     ASSERT(!isEmulatedTail || (staticInlineCallFrame &amp;&amp; staticInlineCallFrame-&gt;getCallerSkippingTailCalls()));</span>
 724     CodeOrigin dynamicOrigin =
<span class="line-modified"> 725         isEmulatedTail ? *staticInlineCallFrame-&gt;getCallerSkippingTailCalls() : staticOrigin;</span>
 726 
 727     CallSiteIndex callSite = m_jit.recordCallSiteAndGenerateExceptionHandlingOSRExitIfNeeded(dynamicOrigin, m_stream-&gt;size());
 728 
 729     auto setResultAndResetStack = [&amp;] () {
 730         GPRFlushedCallResult result(this);
 731         GPRReg resultGPR = result.gpr();
 732         m_jit.move(GPRInfo::returnValueGPR, resultGPR);
 733 
 734         jsValueResult(resultGPR, m_currentNode, DataFormatJS, UseChildrenCalledExplicitly);
 735 
 736         // After the calls are done, we need to reestablish our stack
 737         // pointer. We rely on this for varargs calls, calls with arity
 738         // mismatch (the callframe is slided) and tail calls.
 739         m_jit.addPtr(TrustedImm32(m_jit.graph().stackPointerOffset() * sizeof(Register)), GPRInfo::callFrameRegister, JITCompiler::stackPointerRegister);
 740     };
 741 
 742     CallLinkInfo* callLinkInfo = m_jit.codeBlock()-&gt;addCallLinkInfo();
 743     callLinkInfo-&gt;setUpCall(callType, m_currentNode-&gt;origin.semantic, calleeGPR);
 744 
 745     if (node-&gt;op() == CallEval) {
</pre>
<hr />
<pre>
 750 
 751         m_jit.emitStoreCallSiteIndex(callSite);
 752         m_jit.addPtr(TrustedImm32(-static_cast&lt;ptrdiff_t&gt;(sizeof(CallerFrameAndPC))), JITCompiler::stackPointerRegister, GPRInfo::regT0);
 753         m_jit.storePtr(GPRInfo::callFrameRegister, JITCompiler::Address(GPRInfo::regT0, CallFrame::callerFrameOffset()));
 754 
 755         // Now we need to make room for:
 756         // - The caller frame and PC of a call to operationCallEval.
 757         // - Potentially two arguments on the stack.
 758         unsigned requiredBytes = sizeof(CallerFrameAndPC) + sizeof(ExecState*) * 2;
 759         requiredBytes = WTF::roundUpToMultipleOf(stackAlignmentBytes(), requiredBytes);
 760         m_jit.subPtr(TrustedImm32(requiredBytes), JITCompiler::stackPointerRegister);
 761         m_jit.setupArguments&lt;decltype(operationCallEval)&gt;(GPRInfo::regT0);
 762         prepareForExternalCall();
 763         m_jit.appendCall(operationCallEval);
 764         m_jit.exceptionCheck();
 765         JITCompiler::Jump done = m_jit.branchIfNotEmpty(GPRInfo::returnValueGPR);
 766 
 767         // This is the part where we meant to make a normal call. Oops.
 768         m_jit.addPtr(TrustedImm32(requiredBytes), JITCompiler::stackPointerRegister);
 769         m_jit.load64(JITCompiler::calleeFrameSlot(CallFrameSlot::callee), GPRInfo::regT0);
<span class="line-modified"> 770         m_jit.emitDumbVirtualCall(vm(), callLinkInfo);</span>
 771 
 772         done.link(&amp;m_jit);
 773         setResultAndResetStack();
 774         return;
 775     }
 776 
 777     if (isDirect) {
 778         callLinkInfo-&gt;setExecutableDuringCompilation(executable);
 779         callLinkInfo-&gt;setMaxNumArguments(numAllocatedArgs);
 780 
 781         if (isTail) {
 782             RELEASE_ASSERT(node-&gt;op() == DirectTailCall);
 783 
 784             JITCompiler::PatchableJump patchableJump = m_jit.patchableJump();
 785             JITCompiler::Label mainPath = m_jit.label();
 786 
 787             m_jit.emitStoreCallSiteIndex(callSite);
 788 
 789             callLinkInfo-&gt;setFrameShuffleData(shuffleData);
 790             CallFrameShuffler(m_jit, shuffleData).prepareForTailCall();
</pre>
<hr />
<pre>
 925             if (spillFormat == DataFormatInt32) {
 926                 m_jit.load32(JITCompiler::addressFor(virtualRegister), gpr);
 927                 info.fillInt32(*m_stream, gpr);
 928                 returnFormat = DataFormatInt32;
 929             } else {
 930                 m_jit.load64(JITCompiler::addressFor(virtualRegister), gpr);
 931                 info.fillJSValue(*m_stream, gpr, DataFormatJSInt32);
 932                 returnFormat = DataFormatJSInt32;
 933             }
 934             return gpr;
 935         }
 936         m_jit.load64(JITCompiler::addressFor(virtualRegister), gpr);
 937 
 938         // Fill as JSValue, and fall through.
 939         info.fillJSValue(*m_stream, gpr, DataFormatJSInt32);
 940         m_gprs.unlock(gpr);
 941         FALLTHROUGH;
 942     }
 943 
 944     case DataFormatJS: {
<span class="line-modified"> 945         DFG_ASSERT(m_jit.graph(), m_currentNode, !(type &amp; SpecInt52Any));</span>
 946         // Check the value is an integer.
 947         GPRReg gpr = info.gpr();
 948         m_gprs.lock(gpr);
 949         if (type &amp; ~SpecInt32Only)
 950             speculationCheck(BadType, JSValueRegs(gpr), edge, m_jit.branchIfNotInt32(gpr));
 951         info.fillJSValue(*m_stream, gpr, DataFormatJSInt32);
 952         // If !strict we&#39;re done, return.
 953         if (!strict) {
 954             returnFormat = DataFormatJSInt32;
 955             return gpr;
 956         }
 957         // else fall through &amp; handle as DataFormatJSInt32.
 958         m_gprs.unlock(gpr);
 959         FALLTHROUGH;
 960     }
 961 
 962     case DataFormatJSInt32: {
 963         // In a strict fill we need to strip off the value tag.
 964         if (strict) {
 965             GPRReg gpr = info.gpr();
</pre>
<hr />
<pre>
1010 IGNORE_WARNINGS_END
1011 
1012 GPRReg SpeculativeJIT::fillSpeculateInt32(Edge edge, DataFormat&amp; returnFormat)
1013 {
1014     return fillSpeculateInt32Internal&lt;false&gt;(edge, returnFormat);
1015 }
1016 
1017 GPRReg SpeculativeJIT::fillSpeculateInt32Strict(Edge edge)
1018 {
1019     DataFormat mustBeDataFormatInt32;
1020     GPRReg result = fillSpeculateInt32Internal&lt;true&gt;(edge, mustBeDataFormatInt32);
1021     DFG_ASSERT(m_jit.graph(), m_currentNode, mustBeDataFormatInt32 == DataFormatInt32, mustBeDataFormatInt32);
1022     return result;
1023 }
1024 
1025 GPRReg SpeculativeJIT::fillSpeculateInt52(Edge edge, DataFormat desiredFormat)
1026 {
1027     ASSERT(desiredFormat == DataFormatInt52 || desiredFormat == DataFormatStrictInt52);
1028     AbstractValue&amp; value = m_state.forNode(edge);
1029 
<span class="line-modified">1030     m_interpreter.filter(value, SpecInt52Any);</span>
1031     if (value.isClear()) {
1032         if (mayHaveTypeCheck(edge.useKind()))
1033             terminateSpeculativeExecution(Uncountable, JSValueRegs(), 0);
1034         return allocate();
1035     }
1036 
1037     VirtualRegister virtualRegister = edge-&gt;virtualRegister();
1038     GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
1039 
1040     switch (info.registerFormat()) {
1041     case DataFormatNone: {
1042         GPRReg gpr = allocate();
1043 
1044         if (edge-&gt;hasConstant()) {
1045             JSValue jsValue = edge-&gt;asJSValue();
1046             ASSERT(jsValue.isAnyInt());
1047             m_gprs.retain(gpr, virtualRegister, SpillOrderConstant);
1048             int64_t value = jsValue.asAnyInt();
1049             if (desiredFormat == DataFormatInt52)
1050                 value = value &lt;&lt; JSValue::int52ShiftAmount;
</pre>
<hr />
<pre>
1586         structure.adopt(realStructure);
1587         scratch.adopt(realScratch);
1588         structureGPR = structure.gpr();
1589         scratchGPR = scratch.gpr();
1590     }
1591 
1592     MacroAssembler::Jump notCell = m_jit.branchIfNotCell(JSValueRegs(valueGPR));
1593     if (masqueradesAsUndefinedWatchpointValid) {
1594         DFG_TYPE_CHECK(
1595             JSValueRegs(valueGPR), nodeUse, (~SpecCellCheck) | SpecObject, m_jit.branchIfNotObject(valueGPR));
1596     } else {
1597         DFG_TYPE_CHECK(
1598             JSValueRegs(valueGPR), nodeUse, (~SpecCellCheck) | SpecObject, m_jit.branchIfNotObject(valueGPR));
1599 
1600         MacroAssembler::Jump isNotMasqueradesAsUndefined =
1601             m_jit.branchTest8(
1602                 MacroAssembler::Zero,
1603                 MacroAssembler::Address(valueGPR, JSCell::typeInfoFlagsOffset()),
1604                 MacroAssembler::TrustedImm32(MasqueradesAsUndefined));
1605 
<span class="line-modified">1606         m_jit.emitLoadStructure(vm(), valueGPR, structureGPR, scratchGPR);</span>
1607         speculationCheck(BadType, JSValueRegs(valueGPR), nodeUse,
1608             m_jit.branchPtr(
1609                 MacroAssembler::Equal,
1610                 MacroAssembler::Address(structureGPR, Structure::globalObjectOffset()),
1611                 TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.graph().globalObjectFor(m_currentNode-&gt;origin.semantic))));
1612 
1613         isNotMasqueradesAsUndefined.link(&amp;m_jit);
1614     }
1615     m_jit.move(TrustedImm32(ValueFalse), resultGPR);
1616     MacroAssembler::Jump done = m_jit.jump();
1617 
1618     notCell.link(&amp;m_jit);
1619 
1620     if (needsTypeCheck(nodeUse, SpecCellCheck | SpecOther)) {
1621         m_jit.move(valueGPR, resultGPR);
1622         m_jit.and64(MacroAssembler::TrustedImm32(~TagBitUndefined), resultGPR);
1623         typeCheck(
1624             JSValueRegs(valueGPR), nodeUse, SpecCellCheck | SpecOther, m_jit.branch64(
1625                 MacroAssembler::NotEqual,
1626                 resultGPR,
</pre>
<hr />
<pre>
1692 
1693     case UntypedUse: {
1694         JSValueOperand arg1(this, node-&gt;child1());
1695         GPRTemporary result(this);
1696 
1697         GPRReg arg1GPR = arg1.gpr();
1698         GPRReg resultGPR = result.gpr();
1699 
1700         FPRTemporary valueFPR(this);
1701         FPRTemporary tempFPR(this);
1702 
1703         bool shouldCheckMasqueradesAsUndefined = !masqueradesAsUndefinedWatchpointIsStillValid();
1704         JSGlobalObject* globalObject = m_jit.graph().globalObjectFor(node-&gt;origin.semantic);
1705         Optional&lt;GPRTemporary&gt; scratch;
1706         GPRReg scratchGPR = InvalidGPRReg;
1707         if (shouldCheckMasqueradesAsUndefined) {
1708             scratch.emplace(this);
1709             scratchGPR = scratch-&gt;gpr();
1710         }
1711         bool negateResult = true;
<span class="line-modified">1712         m_jit.emitConvertValueToBoolean(vm(), JSValueRegs(arg1GPR), resultGPR, scratchGPR, valueFPR.fpr(), tempFPR.fpr(), shouldCheckMasqueradesAsUndefined, globalObject, negateResult);</span>
1713         m_jit.or32(TrustedImm32(ValueFalse), resultGPR);
1714         jsValueResult(resultGPR, node, DataFormatJSBoolean);
1715         return;
1716     }
1717     case StringUse:
1718         return compileStringZeroLength(node);
1719 
1720     case StringOrOtherUse:
1721         return compileLogicalNotStringOrOther(node);
1722 
1723     default:
1724         DFG_CRASH(m_jit.graph(), node, &quot;Bad use kind&quot;);
1725         break;
1726     }
1727 }
1728 
1729 void SpeculativeJIT::emitObjectOrOtherBranch(Edge nodeUse, BasicBlock* taken, BasicBlock* notTaken)
1730 {
1731     JSValueOperand value(this, nodeUse, ManualOperandSpeculation);
1732     GPRTemporary scratch(this);
</pre>
<hr />
<pre>
1737 
1738     if (!masqueradesAsUndefinedWatchpointIsStillValid()) {
1739         GPRTemporary realStructure(this);
1740         structure.adopt(realStructure);
1741         structureGPR = structure.gpr();
1742     }
1743 
1744     MacroAssembler::Jump notCell = m_jit.branchIfNotCell(JSValueRegs(valueGPR));
1745     if (masqueradesAsUndefinedWatchpointIsStillValid()) {
1746         DFG_TYPE_CHECK(
1747             JSValueRegs(valueGPR), nodeUse, (~SpecCellCheck) | SpecObject, m_jit.branchIfNotObject(valueGPR));
1748     } else {
1749         DFG_TYPE_CHECK(
1750             JSValueRegs(valueGPR), nodeUse, (~SpecCellCheck) | SpecObject, m_jit.branchIfNotObject(valueGPR));
1751 
1752         JITCompiler::Jump isNotMasqueradesAsUndefined = m_jit.branchTest8(
1753             JITCompiler::Zero,
1754             MacroAssembler::Address(valueGPR, JSCell::typeInfoFlagsOffset()),
1755             TrustedImm32(MasqueradesAsUndefined));
1756 
<span class="line-modified">1757         m_jit.emitLoadStructure(vm(), valueGPR, structureGPR, scratchGPR);</span>
1758         speculationCheck(BadType, JSValueRegs(valueGPR), nodeUse,
1759             m_jit.branchPtr(
1760                 MacroAssembler::Equal,
1761                 MacroAssembler::Address(structureGPR, Structure::globalObjectOffset()),
1762                 TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.graph().globalObjectFor(m_currentNode-&gt;origin.semantic))));
1763 
1764         isNotMasqueradesAsUndefined.link(&amp;m_jit);
1765     }
1766     jump(taken, ForceJump);
1767 
1768     notCell.link(&amp;m_jit);
1769 
1770     if (needsTypeCheck(nodeUse, SpecCellCheck | SpecOther)) {
1771         m_jit.move(valueGPR, scratchGPR);
1772         m_jit.and64(MacroAssembler::TrustedImm32(~TagBitUndefined), scratchGPR);
1773         typeCheck(
1774             JSValueRegs(valueGPR), nodeUse, SpecCellCheck | SpecOther, m_jit.branch64(
1775                 MacroAssembler::NotEqual, scratchGPR, MacroAssembler::TrustedImm64(ValueNull)));
1776     }
1777     jump(notTaken);
</pre>
<hr />
<pre>
1865                 scratchGPR = scratch-&gt;gpr();
1866             }
1867 
1868             GPRReg resultGPR = result.gpr();
1869             FPRReg valueFPR = fprValue.fpr();
1870             FPRReg tempFPR = fprTemp.fpr();
1871 
1872             if (node-&gt;child1()-&gt;prediction() &amp; SpecInt32Only) {
1873                 branch64(MacroAssembler::Equal, valueGPR, MacroAssembler::TrustedImm64(JSValue::encode(jsNumber(0))), notTaken);
1874                 branch64(MacroAssembler::AboveOrEqual, valueGPR, GPRInfo::tagTypeNumberRegister, taken);
1875             }
1876 
1877             if (node-&gt;child1()-&gt;prediction() &amp; SpecBoolean) {
1878                 branch64(MacroAssembler::Equal, valueGPR, MacroAssembler::TrustedImm64(JSValue::encode(jsBoolean(false))), notTaken);
1879                 branch64(MacroAssembler::Equal, valueGPR, MacroAssembler::TrustedImm64(JSValue::encode(jsBoolean(true))), taken);
1880             }
1881 
1882             value.use();
1883 
1884             JSGlobalObject* globalObject = m_jit.graph().globalObjectFor(node-&gt;origin.semantic);
<span class="line-modified">1885             auto truthy = m_jit.branchIfTruthy(vm(), JSValueRegs(valueGPR), resultGPR, scratchGPR, valueFPR, tempFPR, shouldCheckMasqueradesAsUndefined, globalObject);</span>
1886             addBranch(truthy, taken);
1887             jump(notTaken);
1888         }
1889 
1890         noResult(node, UseChildrenCalledExplicitly);
1891         return;
1892     }
1893 
1894     default:
1895         DFG_CRASH(m_jit.graph(), m_currentNode, &quot;Bad use kind&quot;);
1896     }
1897 }
1898 
1899 void SpeculativeJIT::compile(Node* node)
1900 {
1901     NodeType op = node-&gt;op();
1902 
1903     if (validateDFGDoesGC) {
1904         bool expectDoesGC = doesGC(m_jit.graph(), node);
<span class="line-modified">1905         m_jit.store8(TrustedImm32(expectDoesGC), vm().heap.addressOfExpectDoesGC());</span>
1906     }
1907 
1908 #if ENABLE(DFG_REGISTER_ALLOCATION_VALIDATION)
1909     m_jit.clearRegisterAllocationOffsets();
1910 #endif
1911 
1912     switch (op) {
1913     case JSConstant:
1914     case DoubleConstant:
1915     case Int52Constant:
1916     case PhantomDirectArguments:
1917     case PhantomClonedArguments:
1918         initConstantInfo(node);
1919         break;
1920 
1921     case LazyJSConstant:
1922         compileLazyJSConstant(node);
1923         break;
1924 
1925     case Identity: {
</pre>
<hr />
<pre>
2054             recordSetLocal(DataFormatBoolean);
2055             break;
2056         }
2057 
2058         case FlushedJSValue: {
2059             JSValueOperand value(this, node-&gt;child1());
2060             m_jit.store64(value.gpr(), JITCompiler::addressFor(node-&gt;machineLocal()));
2061             noResult(node);
2062             recordSetLocal(dataFormatFor(node-&gt;variableAccessData()-&gt;flushFormat()));
2063             break;
2064         }
2065 
2066         default:
2067             DFG_CRASH(m_jit.graph(), node, &quot;Bad flush format&quot;);
2068             break;
2069         }
2070 
2071         break;
2072     }
2073 
<span class="line-modified">2074     case SetArgumentDefinitely:</span>
<span class="line-added">2075     case SetArgumentMaybe:</span>
2076         // This is a no-op; it just marks the fact that the argument is being used.
2077         // But it may be profitable to use this as a hook to run speculation checks
2078         // on arguments, thereby allowing us to trivially eliminate such checks if
2079         // the argument is not used.
2080         recordSetLocal(dataFormatFor(node-&gt;variableAccessData()-&gt;flushFormat()));
2081         break;
2082 
<span class="line-added">2083     case ValueBitNot:</span>
<span class="line-added">2084         compileValueBitNot(node);</span>
<span class="line-added">2085         break;</span>
<span class="line-added">2086 </span>
2087     case ArithBitNot:
2088         compileBitwiseNot(node);
2089         break;
2090 
2091     case ValueBitAnd:
2092     case ValueBitXor:
2093     case ValueBitOr:
2094         compileValueBitwiseOp(node);
2095         break;
2096 
2097     case ArithBitAnd:
2098     case ArithBitOr:
2099     case ArithBitXor:
2100         compileBitwiseOp(node);
2101         break;
2102 
<span class="line-added">2103     case ValueBitLShift:</span>
<span class="line-added">2104         compileValueLShiftOp(node);</span>
<span class="line-added">2105         break;</span>
<span class="line-added">2106 </span>
2107     case BitRShift:
<span class="line-modified">2108     case ArithBitLShift:</span>
2109     case BitURShift:
2110         compileShiftOp(node);
2111         break;
2112 
2113     case UInt32ToNumber: {
2114         compileUInt32ToNumber(node);
2115         break;
2116     }
2117 
2118     case DoubleAsInt32: {
2119         compileDoubleAsInt32(node);
2120         break;
2121     }
2122 
2123     case ValueToInt32: {
2124         compileValueToInt32(node);
2125         break;
2126     }
2127 
2128     case DoubleRep: {
</pre>
<hr />
<pre>
2220         break;
2221 
2222     case ArithMul:
2223         compileArithMul(node);
2224         break;
2225 
2226     case ValueMul:
2227         compileValueMul(node);
2228         break;
2229 
2230     case ValueDiv: {
2231         compileValueDiv(node);
2232         break;
2233     }
2234 
2235     case ArithDiv: {
2236         compileArithDiv(node);
2237         break;
2238     }
2239 
<span class="line-added">2240     case ValueMod: {</span>
<span class="line-added">2241         compileValueMod(node);</span>
<span class="line-added">2242         break;</span>
<span class="line-added">2243     }</span>
<span class="line-added">2244 </span>
2245     case ArithMod: {
2246         compileArithMod(node);
2247         break;
2248     }
2249 
2250     case ArithAbs:
2251         compileArithAbs(node);
2252         break;
2253 
2254     case ArithMin:
2255     case ArithMax: {
2256         compileArithMinMax(node);
2257         break;
2258     }
2259 
<span class="line-added">2260     case ValuePow:</span>
<span class="line-added">2261         compileValuePow(node);</span>
<span class="line-added">2262         break;</span>
<span class="line-added">2263 </span>
2264     case ArithPow:
2265         compileArithPow(node);
2266         break;
2267 
2268     case ArithSqrt:
2269         compileArithSqrt(node);
2270         break;
2271 
2272     case ArithFRound:
2273         compileArithFRound(node);
2274         break;
2275 
2276     case ArithRandom:
2277         compileArithRandom(node);
2278         break;
2279 
2280     case ArithRound:
2281     case ArithFloor:
2282     case ArithCeil:
2283     case ArithTrunc:
</pre>
<hr />
<pre>
2723 
2724                 if (!arrayMode.isOutOfBounds())
2725                     speculationCheck(OutOfBounds, JSValueRegs(), 0, slowCase);
2726 
2727                 m_jit.add32(TrustedImm32(1), propertyReg, temporaryReg);
2728                 m_jit.store32(temporaryReg, MacroAssembler::Address(storageReg, Butterfly::offsetOfPublicLength()));
2729 
2730                 inBounds.link(&amp;m_jit);
2731             }
2732 
2733             m_jit.store64(valueReg, MacroAssembler::BaseIndex(storageReg, propertyReg, MacroAssembler::TimesEight));
2734 
2735             base.use();
2736             property.use();
2737             value.use();
2738             storage.use();
2739 
2740             if (arrayMode.isOutOfBounds()) {
2741                 addSlowPathGenerator(slowPathCall(
2742                     slowCase, this,
<span class="line-modified">2743                     m_jit.isStrictModeFor(node-&gt;origin.semantic)</span>
2744                         ? (node-&gt;op() == PutByValDirect ? operationPutByValDirectBeyondArrayBoundsStrict : operationPutByValBeyondArrayBoundsStrict)
2745                         : (node-&gt;op() == PutByValDirect ? operationPutByValDirectBeyondArrayBoundsNonStrict : operationPutByValBeyondArrayBoundsNonStrict),
2746                     NoResult, baseReg, propertyReg, valueReg));
2747             }
2748 
2749             noResult(node, UseChildrenCalledExplicitly);
2750             break;
2751         }
2752 
2753         case Array::Double: {
2754             compileDoublePutByVal(node, base, property);
2755             break;
2756         }
2757 
2758         case Array::ArrayStorage:
2759         case Array::SlowPutArrayStorage: {
2760             JSValueOperand value(this, child3);
2761 
2762             GPRReg valueReg = value.gpr();
2763 
</pre>
<hr />
<pre>
2807                     MacroAssembler::Jump lengthDoesNotNeedUpdate = m_jit.branch32(MacroAssembler::Below, propertyReg, MacroAssembler::Address(storageReg, ArrayStorage::lengthOffset()));
2808                     m_jit.add32(TrustedImm32(1), propertyReg, temporaryReg);
2809                     m_jit.store32(temporaryReg, MacroAssembler::Address(storageReg, ArrayStorage::lengthOffset()));
2810 
2811                     lengthDoesNotNeedUpdate.link(&amp;m_jit);
2812                 }
2813                 notHoleValue.link(&amp;m_jit);
2814             }
2815 
2816             // Store the value to the array.
2817             m_jit.store64(valueReg, MacroAssembler::BaseIndex(storageReg, propertyReg, MacroAssembler::TimesEight, ArrayStorage::vectorOffset()));
2818 
2819             base.use();
2820             property.use();
2821             value.use();
2822             storage.use();
2823 
2824             if (!slowCases.empty()) {
2825                 addSlowPathGenerator(slowPathCall(
2826                     slowCases, this,
<span class="line-modified">2827                     m_jit.isStrictModeFor(node-&gt;origin.semantic)</span>
2828                         ? (node-&gt;op() == PutByValDirect ? operationPutByValDirectBeyondArrayBoundsStrict : operationPutByValBeyondArrayBoundsStrict)
2829                         : (node-&gt;op() == PutByValDirect ? operationPutByValDirectBeyondArrayBoundsNonStrict : operationPutByValBeyondArrayBoundsNonStrict),
2830                     NoResult, baseReg, propertyReg, valueReg));
2831             }
2832 
2833             noResult(node, UseChildrenCalledExplicitly);
2834             break;
2835         }
2836 
2837         case Array::Int8Array:
2838         case Array::Int16Array:
2839         case Array::Int32Array:
2840         case Array::Uint8Array:
2841         case Array::Uint8ClampedArray:
2842         case Array::Uint16Array:
2843         case Array::Uint32Array:
2844         case Array::Float32Array:
2845         case Array::Float64Array: {
2846             TypedArrayType type = arrayMode.typedArrayType();
2847             if (isInt(type))
</pre>
<hr />
<pre>
3895         m_jit.compare64(JITCompiler::Equal, value.gpr(), TrustedImm32(ValueUndefined), result.gpr());
3896         JITCompiler::Jump done = m_jit.jump();
3897 
3898         isCell.link(&amp;m_jit);
3899         JITCompiler::Jump notMasqueradesAsUndefined;
3900         if (masqueradesAsUndefinedWatchpointIsStillValid()) {
3901             m_jit.move(TrustedImm32(0), result.gpr());
3902             notMasqueradesAsUndefined = m_jit.jump();
3903         } else {
3904             JITCompiler::Jump isMasqueradesAsUndefined = m_jit.branchTest8(
3905                 JITCompiler::NonZero,
3906                 JITCompiler::Address(value.gpr(), JSCell::typeInfoFlagsOffset()),
3907                 TrustedImm32(MasqueradesAsUndefined));
3908             m_jit.move(TrustedImm32(0), result.gpr());
3909             notMasqueradesAsUndefined = m_jit.jump();
3910 
3911             isMasqueradesAsUndefined.link(&amp;m_jit);
3912             GPRReg localGlobalObjectGPR = localGlobalObject.gpr();
3913             GPRReg remoteGlobalObjectGPR = remoteGlobalObject.gpr();
3914             m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), m_jit.globalObjectFor(node-&gt;origin.semantic)), localGlobalObjectGPR);
<span class="line-modified">3915             m_jit.emitLoadStructure(vm(), value.gpr(), result.gpr(), scratch.gpr());</span>
3916             m_jit.loadPtr(JITCompiler::Address(result.gpr(), Structure::globalObjectOffset()), remoteGlobalObjectGPR);
3917             m_jit.comparePtr(JITCompiler::Equal, localGlobalObjectGPR, remoteGlobalObjectGPR, result.gpr());
3918         }
3919 
3920         notMasqueradesAsUndefined.link(&amp;m_jit);
3921         done.link(&amp;m_jit);
3922         m_jit.or32(TrustedImm32(ValueFalse), result.gpr());
3923         jsValueResult(result.gpr(), node, DataFormatJSBoolean);
3924         break;
3925     }
3926 
3927     case IsUndefinedOrNull: {
3928         JSValueOperand value(this, node-&gt;child1());
3929         GPRTemporary result(this, Reuse, value);
3930 
3931         GPRReg valueGPR = value.gpr();
3932         GPRReg resultGPR = result.gpr();
3933 
3934         m_jit.move(valueGPR, resultGPR);
3935         m_jit.and64(CCallHelpers::TrustedImm32(~TagBitUndefined), resultGPR);
</pre>
<hr />
<pre>
4217         if (!loopAround.empty())
4218             loopAround.link(&amp;m_jit);
4219 
4220         m_jit.add32(TrustedImm32(1), indexGPR);
4221         m_jit.jump().linkTo(loop, &amp;m_jit);
4222 
4223         if (!slowPathCases.empty()) {
4224             slowPathCases.link(&amp;m_jit);
4225             silentSpillAllRegisters(indexGPR);
4226             if (node-&gt;child1().useKind() == MapObjectUse)
4227                 callOperation(operationJSMapFindBucket, resultGPR, mapGPR, keyGPR, hashGPR);
4228             else
4229                 callOperation(operationJSSetFindBucket, resultGPR, mapGPR, keyGPR, hashGPR);
4230             silentFillAllRegisters();
4231             m_jit.exceptionCheck();
4232             done.append(m_jit.jump());
4233         }
4234 
4235         notPresentInTable.link(&amp;m_jit);
4236         if (node-&gt;child1().useKind() == MapObjectUse)
<span class="line-modified">4237             m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), vm().sentinelMapBucket()), resultGPR);</span>
4238         else
<span class="line-modified">4239             m_jit.move(TrustedImmPtr::weakPointer(m_jit.graph(), vm().sentinelSetBucket()), resultGPR);</span>
4240         done.link(&amp;m_jit);
4241         cellResult(resultGPR, node);
4242         break;
4243     }
4244 
4245     case GetMapBucketHead:
4246         compileGetMapBucketHead(node);
4247         break;
4248 
4249     case GetMapBucketNext:
4250         compileGetMapBucketNext(node);
4251         break;
4252 
4253     case LoadKeyFromMapBucket:
4254         compileLoadKeyFromMapBucket(node);
4255         break;
4256 
4257     case LoadValueFromMapBucket:
4258         compileLoadValueFromMapBucket(node);
4259         break;
</pre>
<hr />
<pre>
4453         GPRReg tempGPR = temp.gpr();
4454         GPRReg hashGPR = hash.gpr();
4455         GPRReg structureIDGPR = structureID.gpr();
4456         GPRReg resultGPR = result.gpr();
4457 
4458         speculateObject(node-&gt;child1());
4459 
4460         MacroAssembler::JumpList slowPath;
4461         switch (node-&gt;child2().useKind()) {
4462         case SymbolUse: {
4463             speculateSymbol(node-&gt;child2(), keyGPR);
4464             m_jit.loadPtr(MacroAssembler::Address(keyGPR, Symbol::offsetOfSymbolImpl()), implGPR);
4465             break;
4466         }
4467         case StringUse: {
4468             speculateString(node-&gt;child2(), keyGPR);
4469             m_jit.loadPtr(MacroAssembler::Address(keyGPR, JSString::offsetOfValue()), implGPR);
4470             slowPath.append(m_jit.branchIfRopeStringImpl(implGPR));
4471             slowPath.append(m_jit.branchTest32(
4472                 MacroAssembler::Zero, MacroAssembler::Address(implGPR, StringImpl::flagsOffset()),
<span class="line-modified">4473                 MacroAssembler::TrustedImm32(StringImpl::flagIsAtom())));</span>
4474             break;
4475         }
4476         case UntypedUse: {
4477             slowPath.append(m_jit.branchIfNotCell(JSValueRegs(keyGPR)));
4478             auto isNotString = m_jit.branchIfNotString(keyGPR);
4479             m_jit.loadPtr(MacroAssembler::Address(keyGPR, JSString::offsetOfValue()), implGPR);
4480             slowPath.append(m_jit.branchIfRopeStringImpl(implGPR));
4481             slowPath.append(m_jit.branchTest32(
4482                 MacroAssembler::Zero, MacroAssembler::Address(implGPR, StringImpl::flagsOffset()),
<span class="line-modified">4483                 MacroAssembler::TrustedImm32(StringImpl::flagIsAtom())));</span>
4484             auto hasUniquedImpl = m_jit.jump();
4485 
4486             isNotString.link(&amp;m_jit);
4487             slowPath.append(m_jit.branchIfNotSymbol(keyGPR));
4488             m_jit.loadPtr(MacroAssembler::Address(keyGPR, Symbol::offsetOfSymbolImpl()), implGPR);
4489 
4490             hasUniquedImpl.link(&amp;m_jit);
4491             break;
4492         }
4493         default:
4494             RELEASE_ASSERT_NOT_REACHED();
4495         }
4496 
<span class="line-modified">4497         // Note that we don&#39;t test if the hash is zero here. AtomStringImpl&#39;s can&#39;t have a zero</span>
4498         // hash, however, a SymbolImpl may. But, because this is a cache, we don&#39;t care. We only
4499         // ever load the result from the cache if the cache entry matches what we are querying for.
4500         // So we either get super lucky and use zero for the hash and somehow collide with the entity
4501         // we&#39;re looking for, or we realize we&#39;re comparing against another entity, and go to the
4502         // slow path anyways.
4503         m_jit.load32(MacroAssembler::Address(implGPR, UniquedStringImpl::flagsOffset()), hashGPR);
4504         m_jit.urshift32(MacroAssembler::TrustedImm32(StringImpl::s_flagCount), hashGPR);
4505         m_jit.load32(MacroAssembler::Address(objectGPR, JSCell::structureIDOffset()), structureIDGPR);
4506         m_jit.add32(structureIDGPR, hashGPR);
4507         m_jit.and32(TrustedImm32(HasOwnPropertyCache::mask), hashGPR);
4508         if (hasOneBitSet(sizeof(HasOwnPropertyCache::Entry))) // is a power of 2
4509             m_jit.lshift32(TrustedImm32(getLSBSet(sizeof(HasOwnPropertyCache::Entry))), hashGPR);
4510         else
4511             m_jit.mul32(TrustedImm32(sizeof(HasOwnPropertyCache::Entry)), hashGPR, hashGPR);
<span class="line-modified">4512         ASSERT(vm().hasOwnPropertyCache());</span>
<span class="line-modified">4513         m_jit.move(TrustedImmPtr(vm().hasOwnPropertyCache()), tempGPR);</span>
4514         slowPath.append(m_jit.branchPtr(MacroAssembler::NotEqual,
4515             MacroAssembler::BaseIndex(tempGPR, hashGPR, MacroAssembler::TimesOne, HasOwnPropertyCache::Entry::offsetOfImpl()), implGPR));
4516         m_jit.load8(MacroAssembler::BaseIndex(tempGPR, hashGPR, MacroAssembler::TimesOne, HasOwnPropertyCache::Entry::offsetOfResult()), resultGPR);
4517         m_jit.load32(MacroAssembler::BaseIndex(tempGPR, hashGPR, MacroAssembler::TimesOne, HasOwnPropertyCache::Entry::offsetOfStructureID()), tempGPR);
4518         slowPath.append(m_jit.branch32(MacroAssembler::NotEqual, tempGPR, structureIDGPR));
4519         auto done = m_jit.jump();
4520 
4521         slowPath.link(&amp;m_jit);
4522         silentSpillAllRegisters(resultGPR);
4523         callOperation(operationHasOwnProperty, resultGPR, objectGPR, keyGPR);
4524         silentFillAllRegisters();
4525         m_jit.exceptionCheck();
4526 
4527         done.link(&amp;m_jit);
4528         m_jit.or32(TrustedImm32(ValueFalse), resultGPR);
4529         jsValueResult(resultGPR, node, DataFormatJSBoolean);
4530         break;
4531     }
4532 
4533     case CountExecution:
</pre>
<hr />
<pre>
4669         GPRTemporary temp1(this);
4670         GPRReg t1 = temp1.gpr();
4671         GPRTemporary temp2(this);
4672         GPRReg t2 = temp2.gpr();
4673 
4674         Optional&lt;SpeculateBooleanOperand&gt; isLittleEndianOperand;
4675         if (node-&gt;child3())
4676             isLittleEndianOperand.emplace(this, node-&gt;child3());
4677         GPRReg isLittleEndianGPR = isLittleEndianOperand ? isLittleEndianOperand-&gt;gpr() : InvalidGPRReg;
4678 
4679         DataViewData data = node-&gt;dataViewData();
4680 
4681         m_jit.zeroExtend32ToPtr(indexGPR, t2);
4682         if (data.byteSize &gt; 1)
4683             m_jit.add64(TrustedImm32(data.byteSize - 1), t2);
4684         m_jit.load32(MacroAssembler::Address(dataViewGPR, JSArrayBufferView::offsetOfLength()), t1);
4685         speculationCheck(OutOfBounds, JSValueRegs(), node,
4686             m_jit.branch64(MacroAssembler::AboveOrEqual, t2, t1));
4687 
4688         m_jit.loadPtr(JITCompiler::Address(dataViewGPR, JSArrayBufferView::offsetOfVector()), t2);
<span class="line-modified">4689         cageTypedArrayStorage(dataViewGPR, t2);</span>
4690 
4691         m_jit.zeroExtend32ToPtr(indexGPR, t1);
4692         auto baseIndex = JITCompiler::BaseIndex(t2, t1, MacroAssembler::TimesOne);
4693 
4694         if (node-&gt;op() == DataViewGetInt) {
4695             switch (data.byteSize) {
4696             case 1:
4697                 if (data.isSigned)
4698                     m_jit.load8SignedExtendTo32(baseIndex, t2);
4699                 else
4700                     m_jit.load8(baseIndex, t2);
4701                 int32Result(t2, node);
4702                 break;
4703             case 2: {
4704                 auto emitLittleEndianLoad = [&amp;] {
4705                     if (data.isSigned)
4706                         m_jit.load16SignedExtendTo32(baseIndex, t2);
4707                     else
4708                         m_jit.load16(baseIndex, t2);
4709                 };
</pre>
<hr />
<pre>
4865         GPRTemporary temp1(this);
4866         GPRReg t1 = temp1.gpr();
4867         GPRTemporary temp2(this);
4868         GPRReg t2 = temp2.gpr();
4869         GPRTemporary temp3(this);
4870         GPRReg t3 = temp3.gpr();
4871 
4872         Optional&lt;SpeculateBooleanOperand&gt; isLittleEndianOperand;
4873         if (m_graph.varArgChild(node, 3))
4874             isLittleEndianOperand.emplace(this, m_graph.varArgChild(node, 3));
4875         GPRReg isLittleEndianGPR = isLittleEndianOperand ? isLittleEndianOperand-&gt;gpr() : InvalidGPRReg;
4876 
4877         m_jit.zeroExtend32ToPtr(indexGPR, t2);
4878         if (data.byteSize &gt; 1)
4879             m_jit.add64(TrustedImm32(data.byteSize - 1), t2);
4880         m_jit.load32(MacroAssembler::Address(dataViewGPR, JSArrayBufferView::offsetOfLength()), t1);
4881         speculationCheck(OutOfBounds, JSValueRegs(), node,
4882             m_jit.branch64(MacroAssembler::AboveOrEqual, t2, t1));
4883 
4884         m_jit.loadPtr(JITCompiler::Address(dataViewGPR, JSArrayBufferView::offsetOfVector()), t2);
<span class="line-modified">4885         cageTypedArrayStorage(dataViewGPR, t2);</span>
4886 
4887         m_jit.zeroExtend32ToPtr(indexGPR, t1);
4888         auto baseIndex = JITCompiler::BaseIndex(t2, t1, MacroAssembler::TimesOne);
4889 
4890         if (data.isFloatingPoint) {
4891             RELEASE_ASSERT(valueFPR != InvalidFPRReg);
4892             if (data.byteSize == 4) {
4893                 RELEASE_ASSERT(tempFPR != InvalidFPRReg);
4894                 m_jit.convertDoubleToFloat(valueFPR, tempFPR);
4895 
4896                 auto emitLittleEndianCode = [&amp;] {
4897                     m_jit.storeFloat(tempFPR, baseIndex);
4898                 };
4899 
4900                 auto emitBigEndianCode = [&amp;] {
4901                     m_jit.moveFloatTo32(tempFPR, t3);
4902                     m_jit.byteSwap32(t3);
4903                     m_jit.store32(t3, baseIndex);
4904                 };
4905 
</pre>
<hr />
<pre>
5010             default:
5011                 RELEASE_ASSERT_NOT_REACHED();
5012             }
5013         }
5014 
5015         noResult(node);
5016         break;
5017     }
5018 
5019 #if ENABLE(FTL_JIT)
5020     case CheckTierUpInLoop: {
5021         MacroAssembler::Jump callTierUp = m_jit.branchAdd32(
5022             MacroAssembler::PositiveOrZero,
5023             TrustedImm32(Options::ftlTierUpCounterIncrementForLoop()),
5024             MacroAssembler::AbsoluteAddress(&amp;m_jit.jitCode()-&gt;tierUpCounter.m_counter));
5025 
5026         MacroAssembler::Label toNextOperation = m_jit.label();
5027 
5028         Vector&lt;SilentRegisterSavePlan&gt; savePlans;
5029         silentSpillAllRegistersImpl(false, savePlans, InvalidGPRReg);
<span class="line-modified">5030         unsigned bytecodeIndex = node-&gt;origin.semantic.bytecodeIndex();</span>
5031 
5032         addSlowPathGeneratorLambda([=]() {
5033             callTierUp.link(&amp;m_jit);
5034 
5035             silentSpill(savePlans);
5036             callOperation(triggerTierUpNowInLoop, TrustedImm32(bytecodeIndex));
5037             silentFill(savePlans);
5038 
5039             m_jit.jump().linkTo(toNextOperation, &amp;m_jit);
5040         });
5041         break;
5042     }
5043 
5044     case CheckTierUpAtReturn: {
5045         MacroAssembler::Jump done = m_jit.branchAdd32(
5046             MacroAssembler::Signed,
5047             TrustedImm32(Options::ftlTierUpCounterIncrementForReturn()),
5048             MacroAssembler::AbsoluteAddress(&amp;m_jit.jitCode()-&gt;tierUpCounter.m_counter));
5049 
5050         silentSpillAllRegisters(InvalidGPRReg);
5051         callOperation(triggerTierUpNow);
5052         silentFillAllRegisters();
5053 
5054         done.link(&amp;m_jit);
5055         break;
5056     }
5057 
5058     case CheckTierUpAndOSREnter: {
<span class="line-modified">5059         ASSERT(!node-&gt;origin.semantic.inlineCallFrame());</span>
5060 
5061         GPRTemporary temp(this);
5062         GPRReg tempGPR = temp.gpr();
5063 
<span class="line-modified">5064         unsigned bytecodeIndex = node-&gt;origin.semantic.bytecodeIndex();</span>
5065         auto triggerIterator = m_jit.jitCode()-&gt;tierUpEntryTriggers.find(bytecodeIndex);
5066         DFG_ASSERT(m_jit.graph(), node, triggerIterator != m_jit.jitCode()-&gt;tierUpEntryTriggers.end());
5067         JITCode::TriggerReason* forceEntryTrigger = &amp;(m_jit.jitCode()-&gt;tierUpEntryTriggers.find(bytecodeIndex)-&gt;value);
5068         static_assert(!static_cast&lt;uint8_t&gt;(JITCode::TriggerReason::DontTrigger), &quot;the JIT code assumes non-zero means &#39;enter&#39;&quot;);
5069         static_assert(sizeof(JITCode::TriggerReason) == 1, &quot;branchTest8 assumes this size&quot;);
5070 
5071         MacroAssembler::Jump forceOSREntry = m_jit.branchTest8(MacroAssembler::NonZero, MacroAssembler::AbsoluteAddress(forceEntryTrigger));
5072         MacroAssembler::Jump overflowedCounter = m_jit.branchAdd32(
5073             MacroAssembler::PositiveOrZero,
5074             TrustedImm32(Options::ftlTierUpCounterIncrementForLoop()),
5075             MacroAssembler::AbsoluteAddress(&amp;m_jit.jitCode()-&gt;tierUpCounter.m_counter));
5076         MacroAssembler::Label toNextOperation = m_jit.label();
5077 
5078         Vector&lt;SilentRegisterSavePlan&gt; savePlans;
5079         silentSpillAllRegistersImpl(false, savePlans, tempGPR);
5080 
5081         unsigned streamIndex = m_stream-&gt;size();
5082         m_jit.jitCode()-&gt;bytecodeIndexToStreamIndex.add(bytecodeIndex, streamIndex);
5083 
5084         addSlowPathGeneratorLambda([=]() {
5085             forceOSREntry.link(&amp;m_jit);
5086             overflowedCounter.link(&amp;m_jit);
5087 
5088             silentSpill(savePlans);
5089             callOperation(triggerOSREntryNow, tempGPR, TrustedImm32(bytecodeIndex));
5090 
5091             if (savePlans.isEmpty())
5092                 m_jit.branchTestPtr(MacroAssembler::Zero, tempGPR).linkTo(toNextOperation, &amp;m_jit);
5093             else {
5094                 MacroAssembler::Jump osrEnter = m_jit.branchTestPtr(MacroAssembler::NonZero, tempGPR);
5095                 silentFill(savePlans);
5096                 m_jit.jump().linkTo(toNextOperation, &amp;m_jit);
5097                 osrEnter.link(&amp;m_jit);
5098             }
5099             m_jit.emitRestoreCalleeSaves();
<span class="line-modified">5100             m_jit.farJump(tempGPR, GPRInfo::callFrameRegister);</span>
5101         });
5102         break;
5103     }
5104 
5105 #else // ENABLE(FTL_JIT)
5106     case CheckTierUpInLoop:
5107     case CheckTierUpAtReturn:
5108     case CheckTierUpAndOSREnter:
5109         DFG_CRASH(m_jit.graph(), node, &quot;Unexpected tier-up node&quot;);
5110         break;
5111 #endif // ENABLE(FTL_JIT)
5112 
5113     case FilterCallLinkStatus:
5114     case FilterGetByIdStatus:
5115     case FilterPutByIdStatus:
5116     case FilterInByIdStatus:
5117         m_interpreter.filterICStatus(node);
5118         noResult(node);
5119         break;
5120 
</pre>
</td>
</tr>
</table>
<center><a href="DFGSpeculativeJIT32_64.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGStoreBarrierClusteringPhase.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>