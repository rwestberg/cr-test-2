<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2010 Google Inc. All rights reserved.
   3  * Copyright (C) 2016 Apple Inc. All rights reserved.
   4  *
   5  * Redistribution and use in source and binary forms, with or without
   6  * modification, are permitted provided that the following conditions
   7  * are met:
   8  * 1.  Redistributions of source code must retain the above copyright
   9  *    notice, this list of conditions and the following disclaimer.
  10  * 2.  Redistributions in binary form must reproduce the above copyright
  11  *    notice, this list of conditions and the following disclaimer in the
  12  *    documentation and/or other materials provided with the distribution.
  13  *
  14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
  15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
  16  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  17  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
  18  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
  19  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
  20  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
  21  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
  23  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 
  28 #if ENABLE(WEB_AUDIO)
  29 
  30 #include &quot;AudioContext.h&quot;
  31 
  32 #include &quot;AnalyserNode.h&quot;
  33 #include &quot;AsyncAudioDecoder.h&quot;
  34 #include &quot;AudioBuffer.h&quot;
  35 #include &quot;AudioBufferCallback.h&quot;
  36 #include &quot;AudioBufferSourceNode.h&quot;
  37 #include &quot;AudioListener.h&quot;
  38 #include &quot;AudioNodeInput.h&quot;
  39 #include &quot;AudioNodeOutput.h&quot;
  40 #include &quot;AudioSession.h&quot;
  41 #include &quot;BiquadFilterNode.h&quot;
  42 #include &quot;ChannelMergerNode.h&quot;
  43 #include &quot;ChannelSplitterNode.h&quot;
  44 #include &quot;ConvolverNode.h&quot;
  45 #include &quot;DefaultAudioDestinationNode.h&quot;
  46 #include &quot;DelayNode.h&quot;
  47 #include &quot;Document.h&quot;
  48 #include &quot;DynamicsCompressorNode.h&quot;
  49 #include &quot;EventNames.h&quot;
  50 #include &quot;FFTFrame.h&quot;
  51 #include &quot;Frame.h&quot;
  52 #include &quot;FrameLoader.h&quot;
  53 #include &quot;GainNode.h&quot;
  54 #include &quot;GenericEventQueue.h&quot;
  55 #include &quot;HRTFDatabaseLoader.h&quot;
  56 #include &quot;HRTFPanner.h&quot;
  57 #include &quot;JSDOMPromiseDeferred.h&quot;
  58 #include &quot;Logging.h&quot;
  59 #include &quot;NetworkingContext.h&quot;
  60 #include &quot;OfflineAudioCompletionEvent.h&quot;
  61 #include &quot;OfflineAudioDestinationNode.h&quot;
  62 #include &quot;OscillatorNode.h&quot;
  63 #include &quot;Page.h&quot;
  64 #include &quot;PannerNode.h&quot;
  65 #include &quot;PeriodicWave.h&quot;
  66 #include &quot;ScriptController.h&quot;
  67 #include &quot;ScriptProcessorNode.h&quot;
  68 #include &quot;WaveShaperNode.h&quot;
  69 #include &lt;JavaScriptCore/ScriptCallStack.h&gt;
  70 
  71 #if ENABLE(MEDIA_STREAM)
  72 #include &quot;MediaStream.h&quot;
  73 #include &quot;MediaStreamAudioDestinationNode.h&quot;
  74 #include &quot;MediaStreamAudioSource.h&quot;
  75 #include &quot;MediaStreamAudioSourceNode.h&quot;
  76 #endif
  77 
  78 #if ENABLE(VIDEO)
  79 #include &quot;HTMLMediaElement.h&quot;
  80 #include &quot;MediaElementAudioSourceNode.h&quot;
  81 #endif
  82 
  83 #if DEBUG_AUDIONODE_REFERENCES
  84 #include &lt;stdio.h&gt;
  85 #endif
  86 
  87 #if USE(GSTREAMER)
  88 #include &quot;GStreamerCommon.h&quot;
  89 #endif
  90 
  91 #if PLATFORM(IOS_FAMILY)
  92 #include &quot;ScriptController.h&quot;
  93 #include &quot;Settings.h&quot;
  94 #endif
  95 
  96 #include &lt;JavaScriptCore/ArrayBuffer.h&gt;
  97 #include &lt;wtf/Atomics.h&gt;
  98 #include &lt;wtf/MainThread.h&gt;
  99 #include &lt;wtf/Ref.h&gt;
 100 #include &lt;wtf/RefCounted.h&gt;
 101 #include &lt;wtf/text/WTFString.h&gt;
 102 
 103 const unsigned MaxPeriodicWaveLength = 4096;
 104 
 105 namespace WebCore {
 106 
 107 #define RELEASE_LOG_IF_ALLOWED(fmt, ...) RELEASE_LOG_IF(document()-&gt;page() &amp;&amp; document()-&gt;page()-&gt;isAlwaysOnLoggingAllowed(), Media, &quot;%p - AudioContext::&quot; fmt, this, ##__VA_ARGS__)
 108 
 109 bool AudioContext::isSampleRateRangeGood(float sampleRate)
 110 {
 111     // FIXME: It would be nice if the minimum sample-rate could be less than 44.1KHz,
 112     // but that will require some fixes in HRTFPanner::fftSizeForSampleRate(), and some testing there.
 113     return sampleRate &gt;= 44100 &amp;&amp; sampleRate &lt;= 96000;
 114 }
 115 
 116 // Don&#39;t allow more than this number of simultaneous AudioContexts talking to hardware.
 117 const unsigned MaxHardwareContexts = 4;
 118 unsigned AudioContext::s_hardwareContextCount = 0;
 119 
 120 RefPtr&lt;AudioContext&gt; AudioContext::create(Document&amp; document)
 121 {
 122     ASSERT(isMainThread());
 123     if (s_hardwareContextCount &gt;= MaxHardwareContexts)
 124         return nullptr;
 125 
 126     RefPtr&lt;AudioContext&gt; audioContext(adoptRef(new AudioContext(document)));
 127     audioContext-&gt;suspendIfNeeded();
 128     return audioContext;
 129 }
 130 
 131 // Constructor for rendering to the audio hardware.
 132 AudioContext::AudioContext(Document&amp; document)
 133     : ActiveDOMObject(document)
 134     , m_mediaSession(PlatformMediaSession::create(*this))
 135     , m_eventQueue(std::make_unique&lt;GenericEventQueue&gt;(*this))
 136 {
 137     constructCommon();
 138 
 139     m_destinationNode = DefaultAudioDestinationNode::create(*this);
 140 
 141     // Initialize the destination node&#39;s muted state to match the page&#39;s current muted state.
 142     pageMutedStateDidChange();
 143 }
 144 
 145 // Constructor for offline (non-realtime) rendering.
 146 AudioContext::AudioContext(Document&amp; document, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)
 147     : ActiveDOMObject(document)
 148     , m_isOfflineContext(true)
 149     , m_mediaSession(PlatformMediaSession::create(*this))
 150     , m_eventQueue(std::make_unique&lt;GenericEventQueue&gt;(*this))
 151 {
 152     constructCommon();
 153 
 154     // Create a new destination for offline rendering.
 155     m_renderTarget = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);
 156     m_destinationNode = OfflineAudioDestinationNode::create(*this, m_renderTarget.get());
 157 }
 158 
 159 void AudioContext::constructCommon()
 160 {
 161     // According to spec AudioContext must die only after page navigate.
 162     // Lets mark it as ActiveDOMObject with pending activity and unmark it in clear method.
 163     setPendingActivity(*this);
 164 
 165     FFTFrame::initialize();
 166 
 167     m_listener = AudioListener::create();
 168 
 169     if (document()-&gt;audioPlaybackRequiresUserGesture())
 170         addBehaviorRestriction(RequireUserGestureForAudioStartRestriction);
 171     else
 172         m_restrictions = NoRestrictions;
 173 
 174 #if PLATFORM(COCOA)
 175     addBehaviorRestriction(RequirePageConsentForAudioStartRestriction);
 176 #endif
 177 }
 178 
 179 AudioContext::~AudioContext()
 180 {
 181 #if DEBUG_AUDIONODE_REFERENCES
 182     fprintf(stderr, &quot;%p: AudioContext::~AudioContext()\n&quot;, this);
 183 #endif
 184     ASSERT(!m_isInitialized);
 185     ASSERT(m_isStopScheduled);
 186     ASSERT(m_nodesToDelete.isEmpty());
 187     ASSERT(m_referencedNodes.isEmpty());
 188     ASSERT(m_finishedNodes.isEmpty()); // FIXME (bug 105870): This assertion fails on tests sometimes.
 189     ASSERT(m_automaticPullNodes.isEmpty());
 190     if (m_automaticPullNodesNeedUpdating)
 191         m_renderingAutomaticPullNodes.resize(m_automaticPullNodes.size());
 192     ASSERT(m_renderingAutomaticPullNodes.isEmpty());
 193     // FIXME: Can we assert that m_deferredFinishDerefList is empty?
 194 }
 195 
 196 void AudioContext::lazyInitialize()
 197 {
 198     if (m_isInitialized)
 199         return;
 200 
 201     // Don&#39;t allow the context to initialize a second time after it&#39;s already been explicitly uninitialized.
 202     ASSERT(!m_isAudioThreadFinished);
 203     if (m_isAudioThreadFinished)
 204         return;
 205 
 206     if (m_destinationNode) {
 207         m_destinationNode-&gt;initialize();
 208 
 209         if (!isOfflineContext()) {
 210             document()-&gt;addAudioProducer(*this);
 211             document()-&gt;registerForVisibilityStateChangedCallbacks(*this);
 212 
 213             // This starts the audio thread. The destination node&#39;s provideInput() method will now be called repeatedly to render audio.
 214             // Each time provideInput() is called, a portion of the audio stream is rendered. Let&#39;s call this time period a &quot;render quantum&quot;.
 215             // NOTE: for now default AudioContext does not need an explicit startRendering() call from JavaScript.
 216             // We may want to consider requiring it for symmetry with OfflineAudioContext.
 217             startRendering();
 218             ++s_hardwareContextCount;
 219         }
 220     }
 221     m_isInitialized = true;
 222 }
 223 
 224 void AudioContext::clear()
 225 {
 226     // We have to release our reference to the destination node before the context will ever be deleted since the destination node holds a reference to the context.
 227     if (m_destinationNode)
 228         m_destinationNode = nullptr;
 229 
 230     // Audio thread is dead. Nobody will schedule node deletion action. Let&#39;s do it ourselves.
 231     do {
 232         deleteMarkedNodes();
 233         m_nodesToDelete.appendVector(m_nodesMarkedForDeletion);
 234         m_nodesMarkedForDeletion.clear();
 235     } while (m_nodesToDelete.size());
 236 
 237     // It was set in constructCommon.
 238     unsetPendingActivity(*this);
 239 }
 240 
 241 void AudioContext::uninitialize()
 242 {
 243     ASSERT(isMainThread());
 244 
 245     if (!m_isInitialized)
 246         return;
 247 
 248     // This stops the audio thread and all audio rendering.
 249     m_destinationNode-&gt;uninitialize();
 250 
 251     // Don&#39;t allow the context to initialize a second time after it&#39;s already been explicitly uninitialized.
 252     m_isAudioThreadFinished = true;
 253 
 254     if (!isOfflineContext()) {
 255         document()-&gt;removeAudioProducer(*this);
 256         document()-&gt;unregisterForVisibilityStateChangedCallbacks(*this);
 257 
 258         ASSERT(s_hardwareContextCount);
 259         --s_hardwareContextCount;
 260 
 261         // Offline contexts move to &#39;Closed&#39; state when dispatching the completion event.
 262         setState(State::Closed);
 263     }
 264 
 265     // Get rid of the sources which may still be playing.
 266     derefUnfinishedSourceNodes();
 267 
 268     m_isInitialized = false;
 269 }
 270 
 271 bool AudioContext::isInitialized() const
 272 {
 273     return m_isInitialized;
 274 }
 275 
 276 void AudioContext::addReaction(State state, DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
 277 {
 278     size_t stateIndex = static_cast&lt;size_t&gt;(state);
 279     if (stateIndex &gt;= m_stateReactions.size())
 280         m_stateReactions.grow(stateIndex + 1);
 281 
 282     m_stateReactions[stateIndex].append(WTFMove(promise));
 283 }
 284 
 285 void AudioContext::setState(State state)
 286 {
 287     if (m_state == state)
 288         return;
 289 
 290     m_state = state;
 291     m_eventQueue-&gt;enqueueEvent(Event::create(eventNames().statechangeEvent, Event::CanBubble::Yes, Event::IsCancelable::No));
 292 
 293     size_t stateIndex = static_cast&lt;size_t&gt;(state);
 294     if (stateIndex &gt;= m_stateReactions.size())
 295         return;
 296 
 297     Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt; reactions;
 298     m_stateReactions[stateIndex].swap(reactions);
 299 
 300     for (auto&amp; promise : reactions)
 301         promise.resolve();
 302 }
 303 
 304 void AudioContext::stop()
 305 {
 306     ASSERT(isMainThread());
 307 
 308     // Usually ScriptExecutionContext calls stop twice.
 309     if (m_isStopScheduled)
 310         return;
 311     m_isStopScheduled = true;
 312 
 313     document()-&gt;updateIsPlayingMedia();
 314 
 315     m_eventQueue-&gt;close();
 316 
 317     uninitialize();
 318     clear();
 319 }
 320 
 321 bool AudioContext::canSuspendForDocumentSuspension() const
 322 {
 323     // FIXME: We should be able to suspend while rendering as well with some more code.
 324     return m_state == State::Suspended || m_state == State::Closed;
 325 }
 326 
 327 const char* AudioContext::activeDOMObjectName() const
 328 {
 329     return &quot;AudioContext&quot;;
 330 }
 331 
 332 Document* AudioContext::document() const
 333 {
 334     ASSERT(m_scriptExecutionContext);
 335     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 336 }
 337 
 338 Document* AudioContext::hostingDocument() const
 339 {
 340     return downcast&lt;Document&gt;(m_scriptExecutionContext);
 341 }
 342 
 343 String AudioContext::sourceApplicationIdentifier() const
 344 {
 345     Document* document = this-&gt;document();
 346     if (Frame* frame = document ? document-&gt;frame() : nullptr) {
 347         if (NetworkingContext* networkingContext = frame-&gt;loader().networkingContext())
 348             return networkingContext-&gt;sourceApplicationIdentifier();
 349     }
 350     return emptyString();
 351 }
 352 
 353 bool AudioContext::processingUserGestureForMedia() const
 354 {
 355     return document() ? document()-&gt;processingUserGestureForMedia() : false;
 356 }
 357 
 358 bool AudioContext::isSuspended() const
 359 {
 360     return !document() || document()-&gt;activeDOMObjectsAreSuspended() || document()-&gt;activeDOMObjectsAreStopped();
 361 }
 362 
 363 void AudioContext::visibilityStateChanged()
 364 {
 365     // Do not suspend if audio is audible.
 366     if (mediaState() == MediaProducer::IsPlayingAudio)
 367         return;
 368 
 369     if (document()-&gt;hidden()) {
 370         if (state() == State::Running) {
 371             RELEASE_LOG_IF_ALLOWED(&quot;visibilityStateChanged() Suspending playback after going to the background&quot;);
 372             m_mediaSession-&gt;beginInterruption(PlatformMediaSession::EnteringBackground);
 373         }
 374     } else {
 375         if (state() == State::Interrupted) {
 376             RELEASE_LOG_IF_ALLOWED(&quot;visibilityStateChanged() Resuming playback after entering foreground&quot;);
 377             m_mediaSession-&gt;endInterruption(PlatformMediaSession::MayResumePlaying);
 378         }
 379     }
 380 }
 381 
 382 bool AudioContext::wouldTaintOrigin(const URL&amp; url) const
 383 {
 384     if (url.protocolIsData())
 385         return false;
 386 
 387     if (auto* document = this-&gt;document())
 388         return !document-&gt;securityOrigin().canRequest(url);
 389 
 390     return false;
 391 }
 392 
 393 ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; AudioContext::createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate)
 394 {
 395     auto audioBuffer = AudioBuffer::create(numberOfChannels, numberOfFrames, sampleRate);
 396     if (!audioBuffer)
 397         return Exception { NotSupportedError };
 398     return audioBuffer.releaseNonNull();
 399 }
 400 
 401 ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; AudioContext::createBuffer(ArrayBuffer&amp; arrayBuffer, bool mixToMono)
 402 {
 403     auto audioBuffer = AudioBuffer::createFromAudioFileData(arrayBuffer.data(), arrayBuffer.byteLength(), mixToMono, sampleRate());
 404     if (!audioBuffer)
 405         return Exception { SyntaxError };
 406     return audioBuffer.releaseNonNull();
 407 }
 408 
 409 void AudioContext::decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp; audioData, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp; successCallback, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp; errorCallback)
 410 {
 411     m_audioDecoder.decodeAsync(WTFMove(audioData), sampleRate(), WTFMove(successCallback), WTFMove(errorCallback));
 412 }
 413 
 414 Ref&lt;AudioBufferSourceNode&gt; AudioContext::createBufferSource()
 415 {
 416     ASSERT(isMainThread());
 417     lazyInitialize();
 418     Ref&lt;AudioBufferSourceNode&gt; node = AudioBufferSourceNode::create(*this, m_destinationNode-&gt;sampleRate());
 419 
 420     // Because this is an AudioScheduledSourceNode, the context keeps a reference until it has finished playing.
 421     // When this happens, AudioScheduledSourceNode::finish() calls AudioContext::notifyNodeFinishedProcessing().
 422     refNode(node);
 423 
 424     return node;
 425 }
 426 
 427 #if ENABLE(VIDEO)
 428 
 429 ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; AudioContext::createMediaElementSource(HTMLMediaElement&amp; mediaElement)
 430 {
 431     ASSERT(isMainThread());
 432     lazyInitialize();
 433 
 434     if (mediaElement.audioSourceNode())
 435         return Exception { InvalidStateError };
 436 
 437     auto node = MediaElementAudioSourceNode::create(*this, mediaElement);
 438 
 439     mediaElement.setAudioSourceNode(node.ptr());
 440 
 441     refNode(node.get()); // context keeps reference until node is disconnected
 442     return WTFMove(node);
 443 }
 444 
 445 #endif
 446 
 447 #if ENABLE(MEDIA_STREAM)
 448 
 449 ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; AudioContext::createMediaStreamSource(MediaStream&amp; mediaStream)
 450 {
 451     ASSERT(isMainThread());
 452 
 453     auto audioTracks = mediaStream.getAudioTracks();
 454     if (audioTracks.isEmpty())
 455         return Exception { InvalidStateError };
 456 
 457     MediaStreamTrack* providerTrack = nullptr;
 458     for (auto&amp; track : audioTracks) {
 459         if (track-&gt;audioSourceProvider()) {
 460             providerTrack = track.get();
 461             break;
 462         }
 463     }
 464     if (!providerTrack)
 465         return Exception { InvalidStateError };
 466 
 467     lazyInitialize();
 468 
 469     auto node = MediaStreamAudioSourceNode::create(*this, mediaStream, *providerTrack);
 470     node-&gt;setFormat(2, sampleRate());
 471 
 472     refNode(node); // context keeps reference until node is disconnected
 473     return WTFMove(node);
 474 }
 475 
 476 Ref&lt;MediaStreamAudioDestinationNode&gt; AudioContext::createMediaStreamDestination()
 477 {
 478     // FIXME: Add support for an optional argument which specifies the number of channels.
 479     // FIXME: The default should probably be stereo instead of mono.
 480     return MediaStreamAudioDestinationNode::create(*this, 1);
 481 }
 482 
 483 #endif
 484 
 485 ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; AudioContext::createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels)
 486 {
 487     ASSERT(isMainThread());
 488     lazyInitialize();
 489 
 490     // W3C Editor&#39;s Draft 06 June 2017
 491     //  https://webaudio.github.io/web-audio-api/#widl-BaseAudioContext-createScriptProcessor-ScriptProcessorNode-unsigned-long-bufferSize-unsigned-long-numberOfInputChannels-unsigned-long-numberOfOutputChannels
 492 
 493     // The bufferSize parameter determines the buffer size in units of sample-frames. If it&#39;s not passed in,
 494     // or if the value is 0, then the implementation will choose the best buffer size for the given environment,
 495     // which will be constant power of 2 throughout the lifetime of the node. ... If the value of this parameter
 496     // is not one of the allowed power-of-2 values listed above, an IndexSizeError must be thrown.
 497     switch (bufferSize) {
 498     case 0:
 499 #if USE(AUDIO_SESSION)
 500         // Pick a value between 256 (2^8) and 16384 (2^14), based on the buffer size of the current AudioSession:
 501         bufferSize = 1 &lt;&lt; std::max&lt;size_t&gt;(8, std::min&lt;size_t&gt;(14, std::log2(AudioSession::sharedSession().bufferSize())));
 502 #else
 503         bufferSize = 2048;
 504 #endif
 505         break;
 506     case 256:
 507     case 512:
 508     case 1024:
 509     case 2048:
 510     case 4096:
 511     case 8192:
 512     case 16384:
 513         break;
 514     default:
 515         return Exception { IndexSizeError };
 516     }
 517 
 518     // An IndexSizeError exception must be thrown if bufferSize or numberOfInputChannels or numberOfOutputChannels
 519     // are outside the valid range. It is invalid for both numberOfInputChannels and numberOfOutputChannels to be zero.
 520     // In this case an IndexSizeError must be thrown.
 521 
 522     if (!numberOfInputChannels &amp;&amp; !numberOfOutputChannels)
 523         return Exception { NotSupportedError };
 524 
 525     // This parameter [numberOfInputChannels] determines the number of channels for this node&#39;s input. Values of
 526     // up to 32 must be supported. A NotSupportedError must be thrown if the number of channels is not supported.
 527 
 528     if (numberOfInputChannels &gt; maxNumberOfChannels())
 529         return Exception { NotSupportedError };
 530 
 531     // This parameter [numberOfOutputChannels] determines the number of channels for this node&#39;s output. Values of
 532     // up to 32 must be supported. A NotSupportedError must be thrown if the number of channels is not supported.
 533 
 534     if (numberOfOutputChannels &gt; maxNumberOfChannels())
 535         return Exception { NotSupportedError };
 536 
 537     auto node = ScriptProcessorNode::create(*this, m_destinationNode-&gt;sampleRate(), bufferSize, numberOfInputChannels, numberOfOutputChannels);
 538 
 539     refNode(node); // context keeps reference until we stop making javascript rendering callbacks
 540     return WTFMove(node);
 541 }
 542 
 543 Ref&lt;BiquadFilterNode&gt; AudioContext::createBiquadFilter()
 544 {
 545     ASSERT(isMainThread());
 546     lazyInitialize();
 547     return BiquadFilterNode::create(*this, m_destinationNode-&gt;sampleRate());
 548 }
 549 
 550 Ref&lt;WaveShaperNode&gt; AudioContext::createWaveShaper()
 551 {
 552     ASSERT(isMainThread());
 553     lazyInitialize();
 554     return WaveShaperNode::create(*this);
 555 }
 556 
 557 Ref&lt;PannerNode&gt; AudioContext::createPanner()
 558 {
 559     ASSERT(isMainThread());
 560     lazyInitialize();
 561     return PannerNode::create(*this, m_destinationNode-&gt;sampleRate());
 562 }
 563 
 564 Ref&lt;ConvolverNode&gt; AudioContext::createConvolver()
 565 {
 566     ASSERT(isMainThread());
 567     lazyInitialize();
 568     return ConvolverNode::create(*this, m_destinationNode-&gt;sampleRate());
 569 }
 570 
 571 Ref&lt;DynamicsCompressorNode&gt; AudioContext::createDynamicsCompressor()
 572 {
 573     ASSERT(isMainThread());
 574     lazyInitialize();
 575     return DynamicsCompressorNode::create(*this, m_destinationNode-&gt;sampleRate());
 576 }
 577 
 578 Ref&lt;AnalyserNode&gt; AudioContext::createAnalyser()
 579 {
 580     ASSERT(isMainThread());
 581     lazyInitialize();
 582     return AnalyserNode::create(*this, m_destinationNode-&gt;sampleRate());
 583 }
 584 
 585 Ref&lt;GainNode&gt; AudioContext::createGain()
 586 {
 587     ASSERT(isMainThread());
 588     lazyInitialize();
 589     return GainNode::create(*this, m_destinationNode-&gt;sampleRate());
 590 }
 591 
 592 ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; AudioContext::createDelay(double maxDelayTime)
 593 {
 594     ASSERT(isMainThread());
 595     lazyInitialize();
 596     return DelayNode::create(*this, m_destinationNode-&gt;sampleRate(), maxDelayTime);
 597 }
 598 
 599 ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; AudioContext::createChannelSplitter(size_t numberOfOutputs)
 600 {
 601     ASSERT(isMainThread());
 602     lazyInitialize();
 603     auto node = ChannelSplitterNode::create(*this, m_destinationNode-&gt;sampleRate(), numberOfOutputs);
 604     if (!node)
 605         return Exception { IndexSizeError };
 606     return node.releaseNonNull();
 607 }
 608 
 609 ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; AudioContext::createChannelMerger(size_t numberOfInputs)
 610 {
 611     ASSERT(isMainThread());
 612     lazyInitialize();
 613     auto node = ChannelMergerNode::create(*this, m_destinationNode-&gt;sampleRate(), numberOfInputs);
 614     if (!node)
 615         return Exception { IndexSizeError };
 616     return node.releaseNonNull();
 617 }
 618 
 619 Ref&lt;OscillatorNode&gt; AudioContext::createOscillator()
 620 {
 621     ASSERT(isMainThread());
 622     lazyInitialize();
 623 
 624     Ref&lt;OscillatorNode&gt; node = OscillatorNode::create(*this, m_destinationNode-&gt;sampleRate());
 625 
 626     // Because this is an AudioScheduledSourceNode, the context keeps a reference until it has finished playing.
 627     // When this happens, AudioScheduledSourceNode::finish() calls AudioContext::notifyNodeFinishedProcessing().
 628     refNode(node);
 629 
 630     return node;
 631 }
 632 
 633 ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; AudioContext::createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary)
 634 {
 635     ASSERT(isMainThread());
 636     if (real.length() != imaginary.length() || (real.length() &gt; MaxPeriodicWaveLength) || !real.length())
 637         return Exception { IndexSizeError };
 638     lazyInitialize();
 639     return PeriodicWave::create(sampleRate(), real, imaginary);
 640 }
 641 
 642 void AudioContext::notifyNodeFinishedProcessing(AudioNode* node)
 643 {
 644     ASSERT(isAudioThread());
 645     m_finishedNodes.append(node);
 646 }
 647 
 648 void AudioContext::derefFinishedSourceNodes()
 649 {
 650     ASSERT(isGraphOwner());
 651     ASSERT(isAudioThread() || isAudioThreadFinished());
 652     for (auto&amp; node : m_finishedNodes)
 653         derefNode(*node);
 654 
 655     m_finishedNodes.clear();
 656 }
 657 
 658 void AudioContext::refNode(AudioNode&amp; node)
 659 {
 660     ASSERT(isMainThread());
 661     AutoLocker locker(*this);
 662 
 663     node.ref(AudioNode::RefTypeConnection);
 664     m_referencedNodes.append(&amp;node);
 665 }
 666 
 667 void AudioContext::derefNode(AudioNode&amp; node)
 668 {
 669     ASSERT(isGraphOwner());
 670 
 671     node.deref(AudioNode::RefTypeConnection);
 672 
 673     ASSERT(m_referencedNodes.contains(&amp;node));
 674     m_referencedNodes.removeFirst(&amp;node);
 675 }
 676 
 677 void AudioContext::derefUnfinishedSourceNodes()
 678 {
 679     ASSERT(isMainThread() &amp;&amp; isAudioThreadFinished());
 680     for (auto&amp; node : m_referencedNodes)
 681         node-&gt;deref(AudioNode::RefTypeConnection);
 682 
 683     m_referencedNodes.clear();
 684 }
 685 
 686 void AudioContext::lock(bool&amp; mustReleaseLock)
 687 {
 688     // Don&#39;t allow regular lock in real-time audio thread.
 689     ASSERT(isMainThread());
 690 
 691     Thread&amp; thisThread = Thread::current();
 692 
 693     if (&amp;thisThread == m_graphOwnerThread) {
 694         // We already have the lock.
 695         mustReleaseLock = false;
 696     } else {
 697         // Acquire the lock.
 698         m_contextGraphMutex.lock();
 699         m_graphOwnerThread = &amp;thisThread;
 700         mustReleaseLock = true;
 701     }
 702 }
 703 
 704 bool AudioContext::tryLock(bool&amp; mustReleaseLock)
 705 {
 706     Thread&amp; thisThread = Thread::current();
 707     bool isAudioThread = &amp;thisThread == audioThread();
 708 
 709     // Try to catch cases of using try lock on main thread - it should use regular lock.
 710     ASSERT(isAudioThread || isAudioThreadFinished());
 711 
 712     if (!isAudioThread) {
 713         // In release build treat tryLock() as lock() (since above ASSERT(isAudioThread) never fires) - this is the best we can do.
 714         lock(mustReleaseLock);
 715         return true;
 716     }
 717 
 718     bool hasLock;
 719 
 720     if (&amp;thisThread == m_graphOwnerThread) {
 721         // Thread already has the lock.
 722         hasLock = true;
 723         mustReleaseLock = false;
 724     } else {
 725         // Don&#39;t already have the lock - try to acquire it.
 726         hasLock = m_contextGraphMutex.tryLock();
 727 
 728         if (hasLock)
 729             m_graphOwnerThread = &amp;thisThread;
 730 
 731         mustReleaseLock = hasLock;
 732     }
 733 
 734     return hasLock;
 735 }
 736 
 737 void AudioContext::unlock()
 738 {
 739     ASSERT(m_graphOwnerThread == &amp;Thread::current());
 740 
 741     m_graphOwnerThread = nullptr;
 742     m_contextGraphMutex.unlock();
 743 }
 744 
 745 bool AudioContext::isAudioThread() const
 746 {
 747     return m_audioThread == &amp;Thread::current();
 748 }
 749 
 750 bool AudioContext::isGraphOwner() const
 751 {
 752     return m_graphOwnerThread == &amp;Thread::current();
 753 }
 754 
 755 void AudioContext::addDeferredFinishDeref(AudioNode* node)
 756 {
 757     ASSERT(isAudioThread());
 758     m_deferredFinishDerefList.append(node);
 759 }
 760 
 761 void AudioContext::handlePreRenderTasks()
 762 {
 763     ASSERT(isAudioThread());
 764 
 765     // At the beginning of every render quantum, try to update the internal rendering graph state (from main thread changes).
 766     // It&#39;s OK if the tryLock() fails, we&#39;ll just take slightly longer to pick up the changes.
 767     bool mustReleaseLock;
 768     if (tryLock(mustReleaseLock)) {
 769         // Fixup the state of any dirty AudioSummingJunctions and AudioNodeOutputs.
 770         handleDirtyAudioSummingJunctions();
 771         handleDirtyAudioNodeOutputs();
 772 
 773         updateAutomaticPullNodes();
 774 
 775         if (mustReleaseLock)
 776             unlock();
 777     }
 778 }
 779 
 780 void AudioContext::handlePostRenderTasks()
 781 {
 782     ASSERT(isAudioThread());
 783 
 784     // Must use a tryLock() here too. Don&#39;t worry, the lock will very rarely be contended and this method is called frequently.
 785     // The worst that can happen is that there will be some nodes which will take slightly longer than usual to be deleted or removed
 786     // from the render graph (in which case they&#39;ll render silence).
 787     bool mustReleaseLock;
 788     if (tryLock(mustReleaseLock)) {
 789         // Take care of finishing any derefs where the tryLock() failed previously.
 790         handleDeferredFinishDerefs();
 791 
 792         // Dynamically clean up nodes which are no longer needed.
 793         derefFinishedSourceNodes();
 794 
 795         // Don&#39;t delete in the real-time thread. Let the main thread do it.
 796         // Ref-counted objects held by certain AudioNodes may not be thread-safe.
 797         scheduleNodeDeletion();
 798 
 799         // Fixup the state of any dirty AudioSummingJunctions and AudioNodeOutputs.
 800         handleDirtyAudioSummingJunctions();
 801         handleDirtyAudioNodeOutputs();
 802 
 803         updateAutomaticPullNodes();
 804 
 805         if (mustReleaseLock)
 806             unlock();
 807     }
 808 }
 809 
 810 void AudioContext::handleDeferredFinishDerefs()
 811 {
 812     ASSERT(isAudioThread() &amp;&amp; isGraphOwner());
 813     for (auto&amp; node : m_deferredFinishDerefList)
 814         node-&gt;finishDeref(AudioNode::RefTypeConnection);
 815 
 816     m_deferredFinishDerefList.clear();
 817 }
 818 
 819 void AudioContext::markForDeletion(AudioNode&amp; node)
 820 {
 821     ASSERT(isGraphOwner());
 822 
 823     if (isAudioThreadFinished())
 824         m_nodesToDelete.append(&amp;node);
 825     else
 826         m_nodesMarkedForDeletion.append(&amp;node);
 827 
 828     // This is probably the best time for us to remove the node from automatic pull list,
 829     // since all connections are gone and we hold the graph lock. Then when handlePostRenderTasks()
 830     // gets a chance to schedule the deletion work, updateAutomaticPullNodes() also gets a chance to
 831     // modify m_renderingAutomaticPullNodes.
 832     removeAutomaticPullNode(node);
 833 }
 834 
 835 void AudioContext::scheduleNodeDeletion()
 836 {
 837     bool isGood = m_isInitialized &amp;&amp; isGraphOwner();
 838     ASSERT(isGood);
 839     if (!isGood)
 840         return;
 841 
 842     // Make sure to call deleteMarkedNodes() on main thread.
 843     if (m_nodesMarkedForDeletion.size() &amp;&amp; !m_isDeletionScheduled) {
 844         m_nodesToDelete.appendVector(m_nodesMarkedForDeletion);
 845         m_nodesMarkedForDeletion.clear();
 846 
 847         m_isDeletionScheduled = true;
 848 
 849         callOnMainThread([protectedThis = makeRef(*this)]() mutable {
 850             protectedThis-&gt;deleteMarkedNodes();
 851         });
 852     }
 853 }
 854 
 855 void AudioContext::deleteMarkedNodes()
 856 {
 857     ASSERT(isMainThread());
 858 
 859     // Protect this object from being deleted before we release the mutex locked by AutoLocker.
 860     Ref&lt;AudioContext&gt; protectedThis(*this);
 861     {
 862         AutoLocker locker(*this);
 863 
 864         while (m_nodesToDelete.size()) {
 865             AudioNode* node = m_nodesToDelete.takeLast();
 866 
 867             // Before deleting the node, clear out any AudioNodeInputs from m_dirtySummingJunctions.
 868             unsigned numberOfInputs = node-&gt;numberOfInputs();
 869             for (unsigned i = 0; i &lt; numberOfInputs; ++i)
 870                 m_dirtySummingJunctions.remove(node-&gt;input(i));
 871 
 872             // Before deleting the node, clear out any AudioNodeOutputs from m_dirtyAudioNodeOutputs.
 873             unsigned numberOfOutputs = node-&gt;numberOfOutputs();
 874             for (unsigned i = 0; i &lt; numberOfOutputs; ++i)
 875                 m_dirtyAudioNodeOutputs.remove(node-&gt;output(i));
 876 
 877             // Finally, delete it.
 878             delete node;
 879         }
 880         m_isDeletionScheduled = false;
 881     }
 882 }
 883 
 884 void AudioContext::markSummingJunctionDirty(AudioSummingJunction* summingJunction)
 885 {
 886     ASSERT(isGraphOwner());
 887     m_dirtySummingJunctions.add(summingJunction);
 888 }
 889 
 890 void AudioContext::removeMarkedSummingJunction(AudioSummingJunction* summingJunction)
 891 {
 892     ASSERT(isMainThread());
 893     AutoLocker locker(*this);
 894     m_dirtySummingJunctions.remove(summingJunction);
 895 }
 896 
 897 void AudioContext::markAudioNodeOutputDirty(AudioNodeOutput* output)
 898 {
 899     ASSERT(isGraphOwner());
 900     m_dirtyAudioNodeOutputs.add(output);
 901 }
 902 
 903 void AudioContext::handleDirtyAudioSummingJunctions()
 904 {
 905     ASSERT(isGraphOwner());
 906 
 907     for (auto&amp; junction : m_dirtySummingJunctions)
 908         junction-&gt;updateRenderingState();
 909 
 910     m_dirtySummingJunctions.clear();
 911 }
 912 
 913 void AudioContext::handleDirtyAudioNodeOutputs()
 914 {
 915     ASSERT(isGraphOwner());
 916 
 917     for (auto&amp; output : m_dirtyAudioNodeOutputs)
 918         output-&gt;updateRenderingState();
 919 
 920     m_dirtyAudioNodeOutputs.clear();
 921 }
 922 
 923 void AudioContext::addAutomaticPullNode(AudioNode&amp; node)
 924 {
 925     ASSERT(isGraphOwner());
 926 
 927     if (m_automaticPullNodes.add(&amp;node).isNewEntry)
 928         m_automaticPullNodesNeedUpdating = true;
 929 }
 930 
 931 void AudioContext::removeAutomaticPullNode(AudioNode&amp; node)
 932 {
 933     ASSERT(isGraphOwner());
 934 
 935     if (m_automaticPullNodes.remove(&amp;node))
 936         m_automaticPullNodesNeedUpdating = true;
 937 }
 938 
 939 void AudioContext::updateAutomaticPullNodes()
 940 {
 941     ASSERT(isGraphOwner());
 942 
 943     if (m_automaticPullNodesNeedUpdating) {
 944         // Copy from m_automaticPullNodes to m_renderingAutomaticPullNodes.
 945         m_renderingAutomaticPullNodes.resize(m_automaticPullNodes.size());
 946 
 947         unsigned i = 0;
 948         for (auto&amp; output : m_automaticPullNodes)
 949             m_renderingAutomaticPullNodes[i++] = output;
 950 
 951         m_automaticPullNodesNeedUpdating = false;
 952     }
 953 }
 954 
 955 void AudioContext::processAutomaticPullNodes(size_t framesToProcess)
 956 {
 957     ASSERT(isAudioThread());
 958 
 959     for (auto&amp; node : m_renderingAutomaticPullNodes)
 960         node-&gt;processIfNecessary(framesToProcess);
 961 }
 962 
 963 ScriptExecutionContext* AudioContext::scriptExecutionContext() const
 964 {
 965     return m_isStopScheduled ? 0 : ActiveDOMObject::scriptExecutionContext();
 966 }
 967 
 968 void AudioContext::nodeWillBeginPlayback()
 969 {
 970     // Called by scheduled AudioNodes when clients schedule their start times.
 971     // Prior to the introduction of suspend(), resume(), and stop(), starting
 972     // a scheduled AudioNode would remove the user-gesture restriction, if present,
 973     // and would thus unmute the context. Now that AudioContext stays in the
 974     // &quot;suspended&quot; state if a user-gesture restriction is present, starting a
 975     // schedule AudioNode should set the state to &quot;running&quot;, but only if the
 976     // user-gesture restriction is set.
 977     if (userGestureRequiredForAudioStart())
 978         startRendering();
 979 }
 980 
 981 bool AudioContext::willBeginPlayback()
 982 {
 983     if (userGestureRequiredForAudioStart()) {
 984         if (!processingUserGestureForMedia() &amp;&amp; !document()-&gt;isCapturing())
 985             return false;
 986         removeBehaviorRestriction(AudioContext::RequireUserGestureForAudioStartRestriction);
 987     }
 988 
 989     if (pageConsentRequiredForAudioStart()) {
 990         Page* page = document()-&gt;page();
 991         if (page &amp;&amp; !page-&gt;canStartMedia()) {
 992             document()-&gt;addMediaCanStartListener(*this);
 993             return false;
 994         }
 995         removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
 996     }
 997 
 998     return m_mediaSession-&gt;clientWillBeginPlayback();
 999 }
1000 
1001 bool AudioContext::willPausePlayback()
1002 {
1003     if (userGestureRequiredForAudioStart()) {
1004         if (!processingUserGestureForMedia())
1005             return false;
1006         removeBehaviorRestriction(AudioContext::RequireUserGestureForAudioStartRestriction);
1007     }
1008 
1009     if (pageConsentRequiredForAudioStart()) {
1010         Page* page = document()-&gt;page();
1011         if (page &amp;&amp; !page-&gt;canStartMedia()) {
1012             document()-&gt;addMediaCanStartListener(*this);
1013             return false;
1014         }
1015         removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1016     }
1017 
1018     return m_mediaSession-&gt;clientWillPausePlayback();
1019 }
1020 
1021 void AudioContext::startRendering()
1022 {
1023     if (!willBeginPlayback())
1024         return;
1025 
1026     destination()-&gt;startRendering();
1027     setState(State::Running);
1028 }
1029 
1030 void AudioContext::mediaCanStart(Document&amp; document)
1031 {
1032     ASSERT_UNUSED(document, &amp;document == this-&gt;document());
1033     removeBehaviorRestriction(AudioContext::RequirePageConsentForAudioStartRestriction);
1034     mayResumePlayback(true);
1035 }
1036 
1037 MediaProducer::MediaStateFlags AudioContext::mediaState() const
1038 {
1039     if (!m_isStopScheduled &amp;&amp; m_destinationNode &amp;&amp; m_destinationNode-&gt;isPlayingAudio())
1040         return MediaProducer::IsPlayingAudio;
1041 
1042     return MediaProducer::IsNotPlaying;
1043 }
1044 
1045 void AudioContext::pageMutedStateDidChange()
1046 {
1047     if (m_destinationNode &amp;&amp; document()-&gt;page())
1048         m_destinationNode-&gt;setMuted(document()-&gt;page()-&gt;isAudioMuted());
1049 }
1050 
1051 void AudioContext::isPlayingAudioDidChange()
1052 {
1053     // Make sure to call Document::updateIsPlayingMedia() on the main thread, since
1054     // we could be on the audio I/O thread here and the call into WebCore could block.
1055     callOnMainThread([protectedThis = makeRef(*this)] {
1056         if (protectedThis-&gt;document())
1057             protectedThis-&gt;document()-&gt;updateIsPlayingMedia();
1058     });
1059 }
1060 
1061 void AudioContext::fireCompletionEvent()
1062 {
1063     ASSERT(isMainThread());
1064     if (!isMainThread())
1065         return;
1066 
1067     AudioBuffer* renderedBuffer = m_renderTarget.get();
1068     setState(State::Closed);
1069 
1070     ASSERT(renderedBuffer);
1071     if (!renderedBuffer)
1072         return;
1073 
1074     // Avoid firing the event if the document has already gone away.
1075     if (scriptExecutionContext()) {
1076         // Call the offline rendering completion event listener.
1077         m_eventQueue-&gt;enqueueEvent(OfflineAudioCompletionEvent::create(renderedBuffer));
1078     }
1079 }
1080 
1081 void AudioContext::incrementActiveSourceCount()
1082 {
1083     ++m_activeSourceCount;
1084 }
1085 
1086 void AudioContext::decrementActiveSourceCount()
1087 {
1088     --m_activeSourceCount;
1089 }
1090 
1091 void AudioContext::suspend(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1092 {
1093     if (isOfflineContext()) {
1094         promise.reject(InvalidStateError);
1095         return;
1096     }
1097 
1098     if (m_state == State::Suspended) {
1099         promise.resolve();
1100         return;
1101     }
1102 
1103     if (m_state == State::Closed || m_state == State::Interrupted || !m_destinationNode) {
1104         promise.reject();
1105         return;
1106     }
1107 
1108     addReaction(State::Suspended, WTFMove(promise));
1109 
1110     if (!willPausePlayback())
1111         return;
1112 
1113     lazyInitialize();
1114 
1115     m_destinationNode-&gt;suspend([this, protectedThis = makeRef(*this)] {
1116         setState(State::Suspended);
1117     });
1118 }
1119 
1120 void AudioContext::resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1121 {
1122     if (isOfflineContext()) {
1123         promise.reject(InvalidStateError);
1124         return;
1125     }
1126 
1127     if (m_state == State::Running) {
1128         promise.resolve();
1129         return;
1130     }
1131 
1132     if (m_state == State::Closed || !m_destinationNode) {
1133         promise.reject();
1134         return;
1135     }
1136 
1137     addReaction(State::Running, WTFMove(promise));
1138 
1139     if (!willBeginPlayback())
1140         return;
1141 
1142     lazyInitialize();
1143 
1144     m_destinationNode-&gt;resume([this, protectedThis = makeRef(*this)] {
1145         setState(State::Running);
1146     });
1147 }
1148 
1149 void AudioContext::close(DOMPromiseDeferred&lt;void&gt;&amp;&amp; promise)
1150 {
1151     if (isOfflineContext()) {
1152         promise.reject(InvalidStateError);
1153         return;
1154     }
1155 
1156     if (m_state == State::Closed || !m_destinationNode) {
1157         promise.resolve();
1158         return;
1159     }
1160 
1161     addReaction(State::Closed, WTFMove(promise));
1162 
1163     lazyInitialize();
1164 
1165     m_destinationNode-&gt;close([this, protectedThis = makeRef(*this)] {
1166         setState(State::Closed);
1167         uninitialize();
1168     });
1169 }
1170 
1171 
1172 void AudioContext::suspendPlayback()
1173 {
1174     if (!m_destinationNode || m_state == State::Closed)
1175         return;
1176 
1177     if (m_state == State::Suspended) {
1178         if (m_mediaSession-&gt;state() == PlatformMediaSession::Interrupted)
1179             setState(State::Interrupted);
1180         return;
1181     }
1182 
1183     lazyInitialize();
1184 
1185     m_destinationNode-&gt;suspend([this, protectedThis = makeRef(*this)] {
1186         bool interrupted = m_mediaSession-&gt;state() == PlatformMediaSession::Interrupted;
1187         setState(interrupted ? State::Interrupted : State::Suspended);
1188     });
1189 }
1190 
1191 void AudioContext::mayResumePlayback(bool shouldResume)
1192 {
1193     if (!m_destinationNode || m_state == State::Closed || m_state == State::Running)
1194         return;
1195 
1196     if (!shouldResume) {
1197         setState(State::Suspended);
1198         return;
1199     }
1200 
1201     if (!willBeginPlayback())
1202         return;
1203 
1204     lazyInitialize();
1205 
1206     m_destinationNode-&gt;resume([this, protectedThis = makeRef(*this)] {
1207         setState(State::Running);
1208     });
1209 }
1210 
1211 
1212 } // namespace WebCore
1213 
1214 #endif // ENABLE(WEB_AUDIO)
    </pre>
  </body>
</html>