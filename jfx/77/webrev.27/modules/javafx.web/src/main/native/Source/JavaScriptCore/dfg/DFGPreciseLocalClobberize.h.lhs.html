<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGPreciseLocalClobberize.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2014-2018 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #if ENABLE(DFG_JIT)
 29 
 30 #include &quot;DFGClobberize.h&quot;
 31 
 32 namespace JSC { namespace DFG {
 33 
 34 template&lt;typename ReadFunctor, typename WriteFunctor, typename DefFunctor&gt;
 35 class PreciseLocalClobberizeAdaptor {
 36 public:
 37     PreciseLocalClobberizeAdaptor(
 38         Graph&amp; graph, Node* node,
 39         const ReadFunctor&amp; read, const WriteFunctor&amp; write, const DefFunctor&amp; def)
 40         : m_graph(graph)
 41         , m_node(node)
 42         , m_read(read)
 43         , m_unconditionalWrite(write)
 44         , m_def(def)
 45     {
 46     }
 47 
 48     void read(AbstractHeap heap)
 49     {
 50         if (heap.kind() == Stack) {
 51             if (heap.payload().isTop()) {
 52                 readTop();
 53                 return;
 54             }
 55 
 56             callIfAppropriate(m_read, VirtualRegister(heap.payload().value32()));
 57             return;
 58         }
 59 
 60         if (heap.overlaps(Stack)) {
 61             readTop();
 62             return;
 63         }
 64     }
 65 
 66     void write(AbstractHeap heap)
 67     {
 68         // We expect stack writes to already be precisely characterized by DFG::clobberize().
 69         if (heap.kind() == Stack) {
 70             RELEASE_ASSERT(!heap.payload().isTop());
 71             callIfAppropriate(m_unconditionalWrite, VirtualRegister(heap.payload().value32()));
 72             return;
 73         }
 74 
 75         RELEASE_ASSERT(!heap.overlaps(Stack));
 76     }
 77 
 78     void def(PureValue)
 79     {
 80         // PureValue defs never have anything to do with locals, so ignore this.
 81     }
 82 
 83     void def(HeapLocation location, LazyNode node)
 84     {
 85         if (location.kind() != StackLoc)
 86             return;
 87 
 88         RELEASE_ASSERT(location.heap().kind() == Stack);
 89 
 90         m_def(VirtualRegister(location.heap().payload().value32()), node);
 91     }
 92 
 93 private:
 94     template&lt;typename Functor&gt;
 95     void callIfAppropriate(const Functor&amp; functor, VirtualRegister operand)
 96     {
 97         if (operand.isLocal() &amp;&amp; static_cast&lt;unsigned&gt;(operand.toLocal()) &gt;= m_graph.block(0)-&gt;variablesAtHead.numberOfLocals())
 98             return;
 99 
100         if (operand.isArgument() &amp;&amp; !operand.isHeader() &amp;&amp; static_cast&lt;unsigned&gt;(operand.toArgument()) &gt;= m_graph.block(0)-&gt;variablesAtHead.numberOfArguments())
101             return;
102 
103         functor(operand);
104     }
105 
106     void readTop()
107     {
108         auto readFrame = [&amp;] (InlineCallFrame* inlineCallFrame, unsigned numberOfArgumentsToSkip) {
109             if (!inlineCallFrame) {
110                 // Read the outermost arguments and argument count.
111                 for (unsigned i = numberOfArgumentsToSkip; i &lt; static_cast&lt;unsigned&gt;(m_graph.m_codeBlock-&gt;numParameters()); i++)
112                     m_read(virtualRegisterForArgument(i));
113                 m_read(VirtualRegister(CallFrameSlot::argumentCount));
114                 return;
115             }
116 
117             for (unsigned i = numberOfArgumentsToSkip; i &lt; inlineCallFrame-&gt;argumentsWithFixup.size(); i++)
118                 m_read(VirtualRegister(inlineCallFrame-&gt;stackOffset + virtualRegisterForArgument(i).offset()));
119             if (inlineCallFrame-&gt;isVarargs())
120                 m_read(VirtualRegister(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount));
121         };
122 
123         auto readSpread = [&amp;] (Node* spread) {
124             ASSERT(spread-&gt;op() == Spread || spread-&gt;op() == PhantomSpread);
125             if (!spread-&gt;child1()-&gt;isPhantomAllocation())
126                 return;
127 
128             ASSERT(spread-&gt;child1()-&gt;op() == PhantomCreateRest || spread-&gt;child1()-&gt;op() == PhantomNewArrayBuffer);
129             if (spread-&gt;child1()-&gt;op() == PhantomNewArrayBuffer) {
130                 // This reads from a constant buffer.
131                 return;
132             }
<a name="1" id="anc1"></a><span class="line-modified">133             InlineCallFrame* inlineCallFrame = spread-&gt;child1()-&gt;origin.semantic.inlineCallFrame;</span>
134             unsigned numberOfArgumentsToSkip = spread-&gt;child1()-&gt;numberOfArgumentsToSkip();
135             readFrame(inlineCallFrame, numberOfArgumentsToSkip);
136         };
137 
138         auto readNewArrayWithSpreadNode = [&amp;] (Node* arrayWithSpread) {
139             ASSERT(arrayWithSpread-&gt;op() == NewArrayWithSpread || arrayWithSpread-&gt;op() == PhantomNewArrayWithSpread);
140             BitVector* bitVector = arrayWithSpread-&gt;bitVector();
141             for (unsigned i = 0; i &lt; arrayWithSpread-&gt;numChildren(); i++) {
142                 if (bitVector-&gt;get(i)) {
143                     Node* child = m_graph.varArgChild(arrayWithSpread, i).node();
144                     if (child-&gt;op() == PhantomSpread)
145                         readSpread(child);
146                 }
147             }
148         };
149 
150         switch (m_node-&gt;op()) {
151         case ForwardVarargs:
152         case CallForwardVarargs:
153         case ConstructForwardVarargs:
154         case TailCallForwardVarargs:
155         case TailCallForwardVarargsInlinedCaller:
156         case GetMyArgumentByVal:
157         case GetMyArgumentByValOutOfBounds:
158         case CreateDirectArguments:
159         case CreateScopedArguments:
160         case CreateClonedArguments:
161         case PhantomDirectArguments:
162         case PhantomClonedArguments:
163         case GetRestLength:
164         case CreateRest: {
165             bool isForwardingNode = false;
166             bool isPhantomNode = false;
167             switch (m_node-&gt;op()) {
168             case ForwardVarargs:
169             case CallForwardVarargs:
170             case ConstructForwardVarargs:
171             case TailCallForwardVarargs:
172             case TailCallForwardVarargsInlinedCaller:
173                 isForwardingNode = true;
174                 break;
175             case PhantomDirectArguments:
176             case PhantomClonedArguments:
177                 isPhantomNode = true;
178                 break;
179             default:
180                 break;
181             }
182 
183             if (isPhantomNode &amp;&amp; m_graph.m_plan.isFTL())
184                 break;
185 
186             if (isForwardingNode &amp;&amp; m_node-&gt;hasArgumentsChild() &amp;&amp; m_node-&gt;argumentsChild()
187                 &amp;&amp; (m_node-&gt;argumentsChild()-&gt;op() == PhantomNewArrayWithSpread || m_node-&gt;argumentsChild()-&gt;op() == PhantomSpread)) {
188                 if (m_node-&gt;argumentsChild()-&gt;op() == PhantomNewArrayWithSpread)
189                     readNewArrayWithSpreadNode(m_node-&gt;argumentsChild().node());
190                 else
191                     readSpread(m_node-&gt;argumentsChild().node());
192             } else {
193                 InlineCallFrame* inlineCallFrame;
194                 if (m_node-&gt;hasArgumentsChild() &amp;&amp; m_node-&gt;argumentsChild())
<a name="2" id="anc2"></a><span class="line-modified">195                     inlineCallFrame = m_node-&gt;argumentsChild()-&gt;origin.semantic.inlineCallFrame;</span>
196                 else
<a name="3" id="anc3"></a><span class="line-modified">197                     inlineCallFrame = m_node-&gt;origin.semantic.inlineCallFrame;</span>
198 
199                 unsigned numberOfArgumentsToSkip = 0;
200                 if (m_node-&gt;op() == GetMyArgumentByVal || m_node-&gt;op() == GetMyArgumentByValOutOfBounds) {
201                     // The value of numberOfArgumentsToSkip guarantees that GetMyArgumentByVal* will never
202                     // read any arguments below the number of arguments to skip. For example, if numberOfArgumentsToSkip is 2,
203                     // we will never read argument 0 or argument 1.
204                     numberOfArgumentsToSkip = m_node-&gt;numberOfArgumentsToSkip();
205                 }
206 
207                 readFrame(inlineCallFrame, numberOfArgumentsToSkip);
208             }
209 
210             break;
211         }
212 
213         case Spread:
214             readSpread(m_node);
215             break;
216 
217         case NewArrayWithSpread: {
218             readNewArrayWithSpreadNode(m_node);
219             break;
220         }
221 
222         case GetArgument: {
<a name="4" id="anc4"></a><span class="line-modified">223             InlineCallFrame* inlineCallFrame = m_node-&gt;origin.semantic.inlineCallFrame;</span>
224             unsigned indexIncludingThis = m_node-&gt;argumentIndex();
225             if (!inlineCallFrame) {
226                 if (indexIncludingThis &lt; static_cast&lt;unsigned&gt;(m_graph.m_codeBlock-&gt;numParameters()))
227                     m_read(virtualRegisterForArgument(indexIncludingThis));
228                 m_read(VirtualRegister(CallFrameSlot::argumentCount));
229                 break;
230             }
231 
232             ASSERT_WITH_MESSAGE(inlineCallFrame-&gt;isVarargs(), &quot;GetArgument is only used for InlineCallFrame if the call frame is varargs.&quot;);
233             if (indexIncludingThis &lt; inlineCallFrame-&gt;argumentsWithFixup.size())
234                 m_read(VirtualRegister(inlineCallFrame-&gt;stackOffset + virtualRegisterForArgument(indexIncludingThis).offset()));
235             m_read(VirtualRegister(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount));
236             break;
237         }
238 
239         default: {
240             // All of the outermost arguments, except this, are read in sloppy mode.
241             if (!m_graph.m_codeBlock-&gt;isStrictMode()) {
242                 for (unsigned i = m_graph.m_codeBlock-&gt;numParameters(); i--;)
243                     m_read(virtualRegisterForArgument(i));
244             }
245 
246             // The stack header is read.
247             for (unsigned i = 0; i &lt; CallFrameSlot::thisArgument; ++i)
248                 m_read(VirtualRegister(i));
249 
250             // Read all of the inline arguments and call frame headers that we didn&#39;t already capture.
<a name="5" id="anc5"></a><span class="line-modified">251             for (InlineCallFrame* inlineCallFrame = m_node-&gt;origin.semantic.inlineCallFrame; inlineCallFrame; inlineCallFrame = inlineCallFrame-&gt;getCallerInlineFrameSkippingTailCalls()) {</span>
252                 if (!inlineCallFrame-&gt;isStrictMode()) {
253                     for (unsigned i = inlineCallFrame-&gt;argumentsWithFixup.size(); i--;)
254                         m_read(VirtualRegister(inlineCallFrame-&gt;stackOffset + virtualRegisterForArgument(i).offset()));
255                 }
256                 if (inlineCallFrame-&gt;isClosureCall)
257                     m_read(VirtualRegister(inlineCallFrame-&gt;stackOffset + CallFrameSlot::callee));
258                 if (inlineCallFrame-&gt;isVarargs())
259                     m_read(VirtualRegister(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount));
260             }
261             break;
262         } }
263     }
264 
265     Graph&amp; m_graph;
266     Node* m_node;
267     const ReadFunctor&amp; m_read;
268     const WriteFunctor&amp; m_unconditionalWrite;
269     const DefFunctor&amp; m_def;
270 };
271 
272 template&lt;typename ReadFunctor, typename WriteFunctor, typename DefFunctor&gt;
273 void preciseLocalClobberize(
274     Graph&amp; graph, Node* node,
275     const ReadFunctor&amp; read, const WriteFunctor&amp; write, const DefFunctor&amp; def)
276 {
277     PreciseLocalClobberizeAdaptor&lt;ReadFunctor, WriteFunctor, DefFunctor&gt;
278         adaptor(graph, node, read, write, def);
279     clobberize(graph, node, adaptor);
280 }
281 
282 } } // namespace JSC::DFG
283 
284 #endif // ENABLE(DFG_JIT)
<a name="6" id="anc6"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="6" type="hidden" />
</body>
</html>