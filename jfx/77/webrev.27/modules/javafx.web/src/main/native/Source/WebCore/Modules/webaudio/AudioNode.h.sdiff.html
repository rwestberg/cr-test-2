<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioNode.h</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AudioNode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioNode.idl.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioNode.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 15  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 16  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 17  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 18  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 19  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 20  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 21  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 22  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 23  */
 24 
 25 #pragma once
 26 
 27 #include &quot;AudioBus.h&quot;
 28 #include &quot;EventTarget.h&quot;
 29 #include &quot;ExceptionOr.h&quot;
 30 #include &lt;wtf/Forward.h&gt;

 31 
 32 #define DEBUG_AUDIONODE_REFERENCES 0
 33 
 34 namespace WebCore {
 35 
 36 class AudioContext;
 37 class AudioNodeInput;
 38 class AudioNodeOutput;
 39 class AudioParam;
 40 
 41 // An AudioNode is the basic building block for handling audio within an AudioContext.
 42 // It may be an audio source, an intermediate processing module, or an audio destination.
 43 // Each AudioNode can have inputs and/or outputs. An AudioSourceNode has no inputs and a single output.
 44 // An AudioDestinationNode has one input and no outputs and represents the final destination to the audio hardware.
 45 // Most processing nodes such as filters will have one input and one output, although multiple inputs and outputs are possible.
 46 
<span class="line-modified"> 47 class AudioNode : public EventTargetWithInlineData {</span>





 48     WTF_MAKE_NONCOPYABLE(AudioNode);
<span class="line-modified"> 49     WTF_MAKE_FAST_ALLOCATED;</span>
 50 public:
 51     enum { ProcessingSizeInFrames = 128 };
 52 
 53     AudioNode(AudioContext&amp;, float sampleRate);
 54     virtual ~AudioNode();
 55 
 56     AudioContext&amp; context() { return m_context.get(); }
 57     const AudioContext&amp; context() const { return m_context.get(); }
 58 
 59     enum NodeType {
 60         NodeTypeUnknown,
 61         NodeTypeDestination,
 62         NodeTypeOscillator,
 63         NodeTypeAudioBufferSource,
 64         NodeTypeMediaElementAudioSource,
 65         NodeTypeMediaStreamAudioDestination,
 66         NodeTypeMediaStreamAudioSource,
 67         NodeTypeJavaScript,
 68         NodeTypeBiquadFilter,
 69         NodeTypePanner,
 70         NodeTypeConvolver,
 71         NodeTypeDelay,
 72         NodeTypeGain,
 73         NodeTypeChannelSplitter,
 74         NodeTypeChannelMerger,
 75         NodeTypeAnalyser,
 76         NodeTypeDynamicsCompressor,
 77         NodeTypeWaveShaper,

 78         NodeTypeEnd
 79     };
 80 
 81     enum ChannelCountMode {
 82         Max,
 83         ClampedMax,
 84         Explicit
 85     };
 86 
 87     NodeType nodeType() const { return m_nodeType; }
 88     void setNodeType(NodeType);
 89 
 90     // We handle our own ref-counting because of the threading issues and subtle nature of
 91     // how AudioNodes can continue processing (playing one-shot sound) after there are no more
 92     // JavaScript references to the object.
 93     enum RefType { RefTypeNormal, RefTypeConnection };
 94 
 95     // Can be called from main thread or context&#39;s audio thread.
 96     void ref(RefType refType = RefTypeNormal);
 97     void deref(RefType refType = RefTypeNormal);
</pre>
<hr />
<pre>
157     // will take tailTime() and latencyTime() into account when determining whether the node will propagate silence.
158     virtual bool propagatesSilence() const;
159     bool inputsAreSilent();
160     void silenceOutputs();
161 
162     void enableOutputsIfNecessary();
163     void disableOutputsIfNecessary();
164 
165     unsigned channelCount();
166     virtual ExceptionOr&lt;void&gt; setChannelCount(unsigned);
167 
168     String channelCountMode();
169     ExceptionOr&lt;void&gt; setChannelCountMode(const String&amp;);
170 
171     String channelInterpretation();
172     ExceptionOr&lt;void&gt; setChannelInterpretation(const String&amp;);
173 
174     ChannelCountMode internalChannelCountMode() const { return m_channelCountMode; }
175     AudioBus::ChannelInterpretation internalChannelInterpretation() const { return m_channelInterpretation; }
176 
<span class="line-removed">177     // EventTarget</span>
<span class="line-removed">178     EventTargetInterface eventTargetInterface() const override;</span>
<span class="line-removed">179     ScriptExecutionContext* scriptExecutionContext() const final;</span>
<span class="line-removed">180 </span>
181 protected:
182     // Inputs and outputs must be created before the AudioNode is initialized.
183     void addInput(std::unique_ptr&lt;AudioNodeInput&gt;);
184     void addOutput(std::unique_ptr&lt;AudioNodeOutput&gt;);
185 
186     // Called by processIfNecessary() to cause all parts of the rendering graph connected to us to process.
187     // Each rendering quantum, the audio data for each of the AudioNode&#39;s inputs will be available after this method is called.
188     // Called from context&#39;s audio thread.
189     virtual void pullInputs(size_t framesToProcess);
190 
191     // Force all inputs to take any channel interpretation changes into account.
192     void updateChannelsForInputs();
193 







194 private:




195     volatile bool m_isInitialized;
196     NodeType m_nodeType;
197     Ref&lt;AudioContext&gt; m_context;
198     float m_sampleRate;
199     Vector&lt;std::unique_ptr&lt;AudioNodeInput&gt;&gt; m_inputs;
200     Vector&lt;std::unique_ptr&lt;AudioNodeOutput&gt;&gt; m_outputs;
201 
202     double m_lastProcessingTime;
203     double m_lastNonSilentTime;
204 
205     // Ref-counting
206     std::atomic&lt;int&gt; m_normalRefCount;
207     std::atomic&lt;int&gt; m_connectionRefCount;
208 
209     bool m_isMarkedForDeletion;
210     bool m_isDisabled;
211 
212 #if DEBUG_AUDIONODE_REFERENCES
213     static bool s_isNodeCountInitialized;
214     static int s_nodeCount[NodeTypeEnd];
215 #endif
216 
217     void refEventTarget() override { ref(); }
218     void derefEventTarget() override { deref(); }
219 





220 protected:
221     unsigned m_channelCount;
222     ChannelCountMode m_channelCountMode;
223     AudioBus::ChannelInterpretation m_channelInterpretation;
224 };
225 


226 } // namespace WebCore








</pre>
</td>
<td>
<hr />
<pre>
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 15  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 16  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 17  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 18  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 19  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 20  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 21  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 22  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 23  */
 24 
 25 #pragma once
 26 
 27 #include &quot;AudioBus.h&quot;
 28 #include &quot;EventTarget.h&quot;
 29 #include &quot;ExceptionOr.h&quot;
 30 #include &lt;wtf/Forward.h&gt;
<span class="line-added"> 31 #include &lt;wtf/LoggerHelper.h&gt;</span>
 32 
 33 #define DEBUG_AUDIONODE_REFERENCES 0
 34 
 35 namespace WebCore {
 36 
 37 class AudioContext;
 38 class AudioNodeInput;
 39 class AudioNodeOutput;
 40 class AudioParam;
 41 
 42 // An AudioNode is the basic building block for handling audio within an AudioContext.
 43 // It may be an audio source, an intermediate processing module, or an audio destination.
 44 // Each AudioNode can have inputs and/or outputs. An AudioSourceNode has no inputs and a single output.
 45 // An AudioDestinationNode has one input and no outputs and represents the final destination to the audio hardware.
 46 // Most processing nodes such as filters will have one input and one output, although multiple inputs and outputs are possible.
 47 
<span class="line-modified"> 48 class AudioNode</span>
<span class="line-added"> 49     : public EventTargetWithInlineData</span>
<span class="line-added"> 50 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added"> 51     , private LoggerHelper</span>
<span class="line-added"> 52 #endif</span>
<span class="line-added"> 53 {</span>
 54     WTF_MAKE_NONCOPYABLE(AudioNode);
<span class="line-modified"> 55     WTF_MAKE_ISO_ALLOCATED(AudioNode);</span>
 56 public:
 57     enum { ProcessingSizeInFrames = 128 };
 58 
 59     AudioNode(AudioContext&amp;, float sampleRate);
 60     virtual ~AudioNode();
 61 
 62     AudioContext&amp; context() { return m_context.get(); }
 63     const AudioContext&amp; context() const { return m_context.get(); }
 64 
 65     enum NodeType {
 66         NodeTypeUnknown,
 67         NodeTypeDestination,
 68         NodeTypeOscillator,
 69         NodeTypeAudioBufferSource,
 70         NodeTypeMediaElementAudioSource,
 71         NodeTypeMediaStreamAudioDestination,
 72         NodeTypeMediaStreamAudioSource,
 73         NodeTypeJavaScript,
 74         NodeTypeBiquadFilter,
 75         NodeTypePanner,
 76         NodeTypeConvolver,
 77         NodeTypeDelay,
 78         NodeTypeGain,
 79         NodeTypeChannelSplitter,
 80         NodeTypeChannelMerger,
 81         NodeTypeAnalyser,
 82         NodeTypeDynamicsCompressor,
 83         NodeTypeWaveShaper,
<span class="line-added"> 84         NodeTypeBasicInspector,</span>
 85         NodeTypeEnd
 86     };
 87 
 88     enum ChannelCountMode {
 89         Max,
 90         ClampedMax,
 91         Explicit
 92     };
 93 
 94     NodeType nodeType() const { return m_nodeType; }
 95     void setNodeType(NodeType);
 96 
 97     // We handle our own ref-counting because of the threading issues and subtle nature of
 98     // how AudioNodes can continue processing (playing one-shot sound) after there are no more
 99     // JavaScript references to the object.
100     enum RefType { RefTypeNormal, RefTypeConnection };
101 
102     // Can be called from main thread or context&#39;s audio thread.
103     void ref(RefType refType = RefTypeNormal);
104     void deref(RefType refType = RefTypeNormal);
</pre>
<hr />
<pre>
164     // will take tailTime() and latencyTime() into account when determining whether the node will propagate silence.
165     virtual bool propagatesSilence() const;
166     bool inputsAreSilent();
167     void silenceOutputs();
168 
169     void enableOutputsIfNecessary();
170     void disableOutputsIfNecessary();
171 
172     unsigned channelCount();
173     virtual ExceptionOr&lt;void&gt; setChannelCount(unsigned);
174 
175     String channelCountMode();
176     ExceptionOr&lt;void&gt; setChannelCountMode(const String&amp;);
177 
178     String channelInterpretation();
179     ExceptionOr&lt;void&gt; setChannelInterpretation(const String&amp;);
180 
181     ChannelCountMode internalChannelCountMode() const { return m_channelCountMode; }
182     AudioBus::ChannelInterpretation internalChannelInterpretation() const { return m_channelInterpretation; }
183 




184 protected:
185     // Inputs and outputs must be created before the AudioNode is initialized.
186     void addInput(std::unique_ptr&lt;AudioNodeInput&gt;);
187     void addOutput(std::unique_ptr&lt;AudioNodeOutput&gt;);
188 
189     // Called by processIfNecessary() to cause all parts of the rendering graph connected to us to process.
190     // Each rendering quantum, the audio data for each of the AudioNode&#39;s inputs will be available after this method is called.
191     // Called from context&#39;s audio thread.
192     virtual void pullInputs(size_t framesToProcess);
193 
194     // Force all inputs to take any channel interpretation changes into account.
195     void updateChannelsForInputs();
196 
<span class="line-added">197 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">198     const Logger&amp; logger() const final { return m_logger.get(); }</span>
<span class="line-added">199     const void* logIdentifier() const final { return m_logIdentifier; }</span>
<span class="line-added">200     const char* logClassName() const final { return &quot;AudioNode&quot;; }</span>
<span class="line-added">201     WTFLogChannel&amp; logChannel() const final;</span>
<span class="line-added">202 #endif</span>
<span class="line-added">203 </span>
204 private:
<span class="line-added">205     // EventTarget</span>
<span class="line-added">206     EventTargetInterface eventTargetInterface() const override;</span>
<span class="line-added">207     ScriptExecutionContext* scriptExecutionContext() const final;</span>
<span class="line-added">208 </span>
209     volatile bool m_isInitialized;
210     NodeType m_nodeType;
211     Ref&lt;AudioContext&gt; m_context;
212     float m_sampleRate;
213     Vector&lt;std::unique_ptr&lt;AudioNodeInput&gt;&gt; m_inputs;
214     Vector&lt;std::unique_ptr&lt;AudioNodeOutput&gt;&gt; m_outputs;
215 
216     double m_lastProcessingTime;
217     double m_lastNonSilentTime;
218 
219     // Ref-counting
220     std::atomic&lt;int&gt; m_normalRefCount;
221     std::atomic&lt;int&gt; m_connectionRefCount;
222 
223     bool m_isMarkedForDeletion;
224     bool m_isDisabled;
225 
226 #if DEBUG_AUDIONODE_REFERENCES
227     static bool s_isNodeCountInitialized;
228     static int s_nodeCount[NodeTypeEnd];
229 #endif
230 
231     void refEventTarget() override { ref(); }
232     void derefEventTarget() override { deref(); }
233 
<span class="line-added">234 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">235     mutable Ref&lt;const Logger&gt; m_logger;</span>
<span class="line-added">236     const void* m_logIdentifier;</span>
<span class="line-added">237 #endif</span>
<span class="line-added">238 </span>
239 protected:
240     unsigned m_channelCount;
241     ChannelCountMode m_channelCountMode;
242     AudioBus::ChannelInterpretation m_channelInterpretation;
243 };
244 
<span class="line-added">245 String convertEnumerationToString(AudioNode::NodeType);</span>
<span class="line-added">246 </span>
247 } // namespace WebCore
<span class="line-added">248 </span>
<span class="line-added">249 namespace WTF {</span>
<span class="line-added">250 </span>
<span class="line-added">251 template&lt;&gt; struct LogArgument&lt;WebCore::AudioNode::NodeType&gt; {</span>
<span class="line-added">252     static String toString(WebCore::AudioNode::NodeType type) { return convertEnumerationToString(type); }</span>
<span class="line-added">253 };</span>
<span class="line-added">254 </span>
<span class="line-added">255 } // namespace WTF</span>
</pre>
</td>
</tr>
</table>
<center><a href="AudioNode.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioNode.idl.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>