<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LLIntSlowPaths.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;LLIntSlowPaths.h&quot;
  28 
  29 #include &quot;ArrayConstructor.h&quot;
  30 #include &quot;CallFrame.h&quot;
  31 #include &quot;CommonSlowPaths.h&quot;
  32 #include &quot;Error.h&quot;
  33 #include &quot;ErrorHandlingScope.h&quot;
  34 #include &quot;EvalCodeBlock.h&quot;
  35 #include &quot;Exception.h&quot;
  36 #include &quot;ExceptionFuzz.h&quot;
  37 #include &quot;ExecutableBaseInlines.h&quot;
  38 #include &quot;FrameTracers.h&quot;
  39 #include &quot;FunctionCodeBlock.h&quot;
  40 #include &quot;FunctionWhitelist.h&quot;
  41 #include &quot;GetterSetter.h&quot;
  42 #include &quot;HostCallReturnValue.h&quot;
  43 #include &quot;InterpreterInlines.h&quot;
  44 #include &quot;IteratorOperations.h&quot;
  45 #include &quot;JIT.h&quot;
  46 #include &quot;JITExceptions.h&quot;
  47 #include &quot;JITWorklist.h&quot;
  48 #include &quot;JSAsyncFunction.h&quot;
  49 #include &quot;JSAsyncGeneratorFunction.h&quot;
  50 #include &quot;JSCInlines.h&quot;
  51 #include &quot;JSCJSValue.h&quot;
  52 #include &quot;JSGeneratorFunction.h&quot;
  53 #include &quot;JSGlobalObjectFunctions.h&quot;
  54 #include &quot;JSLexicalEnvironment.h&quot;
  55 #include &quot;JSString.h&quot;
  56 #include &quot;JSWithScope.h&quot;
  57 #include &quot;LLIntCommon.h&quot;
  58 #include &quot;LLIntData.h&quot;
  59 #include &quot;LLIntExceptions.h&quot;
  60 #include &quot;LLIntPrototypeLoadAdaptiveStructureWatchpoint.h&quot;
  61 #include &quot;LowLevelInterpreter.h&quot;
  62 #include &quot;ModuleProgramCodeBlock.h&quot;
  63 #include &quot;ObjectConstructor.h&quot;
  64 #include &quot;ObjectPropertyConditionSet.h&quot;
  65 #include &quot;OpcodeInlines.h&quot;
  66 #include &quot;ProgramCodeBlock.h&quot;
  67 #include &quot;ProtoCallFrame.h&quot;
  68 #include &quot;RegExpObject.h&quot;
  69 #include &quot;ShadowChicken.h&quot;
  70 #include &quot;StructureRareDataInlines.h&quot;
  71 #include &quot;SuperSampler.h&quot;
  72 #include &quot;VMInlines.h&quot;
  73 #include &lt;wtf/NeverDestroyed.h&gt;
  74 #include &lt;wtf/StringPrintStream.h&gt;
  75 
  76 namespace JSC { namespace LLInt {
  77 
  78 #define LLINT_BEGIN_NO_SET_PC() \
  79     VM&amp; vm = exec-&gt;vm();      \
  80     NativeCallFrameTracer tracer(vm, exec); \
  81     auto throwScope = DECLARE_THROW_SCOPE(vm)
  82 
  83 #ifndef NDEBUG
  84 #define LLINT_SET_PC_FOR_STUBS() do { \
  85         exec-&gt;codeBlock()-&gt;bytecodeOffset(pc); \
  86         exec-&gt;setCurrentVPC(pc); \
  87     } while (false)
  88 #else
  89 #define LLINT_SET_PC_FOR_STUBS() do { \
  90         exec-&gt;setCurrentVPC(pc); \
  91     } while (false)
  92 #endif
  93 
  94 #define LLINT_BEGIN()                           \
  95     LLINT_BEGIN_NO_SET_PC();                    \
  96     LLINT_SET_PC_FOR_STUBS()
  97 
  98 inline JSValue getNonConstantOperand(ExecState* exec, const VirtualRegister&amp; operand) { return exec-&gt;uncheckedR(operand.offset()).jsValue(); }
  99 inline JSValue getOperand(ExecState* exec, const VirtualRegister&amp; operand) { return exec-&gt;r(operand.offset()).jsValue(); }
 100 
 101 #define LLINT_RETURN_TWO(first, second) do {       \
 102         return encodeResult(first, second);        \
 103     } while (false)
 104 
 105 #define LLINT_END_IMPL() LLINT_RETURN_TWO(pc, 0)
 106 
 107 #define LLINT_THROW(exceptionToThrow) do {                        \
 108         throwException(exec, throwScope, exceptionToThrow);       \
 109         pc = returnToThrow(exec);                                 \
 110         LLINT_END_IMPL();                                         \
 111     } while (false)
 112 
 113 #define LLINT_CHECK_EXCEPTION() do {                    \
 114         doExceptionFuzzingIfEnabled(exec, throwScope, &quot;LLIntSlowPaths&quot;, pc);    \
 115         if (UNLIKELY(throwScope.exception())) {         \
 116             pc = returnToThrow(exec);                   \
 117             LLINT_END_IMPL();                           \
 118         }                                               \
 119     } while (false)
 120 
 121 #define LLINT_END() do {                        \
 122         LLINT_CHECK_EXCEPTION();                \
 123         LLINT_END_IMPL();                       \
 124     } while (false)
 125 
 126 #define JUMP_OFFSET(targetOffset) \
 127     ((targetOffset) ? (targetOffset) : exec-&gt;codeBlock()-&gt;outOfLineJumpOffset(pc))
 128 
 129 #define JUMP_TO(target) do { \
 130         pc = reinterpret_cast&lt;const Instruction*&gt;(reinterpret_cast&lt;const uint8_t*&gt;(pc) + (target)); \
 131     } while (false)
 132 
 133 #define LLINT_BRANCH(condition) do {                  \
 134         bool __b_condition = (condition);                         \
 135         LLINT_CHECK_EXCEPTION();                                  \
 136         if (__b_condition)                                        \
 137             JUMP_TO(JUMP_OFFSET(bytecode.m_targetLabel));         \
 138         else                                                      \
 139             JUMP_TO(pc-&gt;size()); \
 140         LLINT_END_IMPL();                                         \
 141     } while (false)
 142 
 143 #define LLINT_RETURN(value) do {                \
 144         JSValue __r_returnValue = (value);      \
 145         LLINT_CHECK_EXCEPTION();                \
 146         exec-&gt;uncheckedR(bytecode.m_dst) = __r_returnValue;          \
 147         LLINT_END_IMPL();                       \
 148     } while (false)
 149 
 150 #define LLINT_RETURN_PROFILED(value) do {               \
 151         JSValue __rp_returnValue = (value);                     \
 152         LLINT_CHECK_EXCEPTION();                                \
 153         exec-&gt;uncheckedR(bytecode.m_dst) = __rp_returnValue;                         \
 154         LLINT_PROFILE_VALUE(__rp_returnValue);          \
 155         LLINT_END_IMPL();                                       \
 156     } while (false)
 157 
 158 #define LLINT_PROFILE_VALUE(value) do { \
 159         bytecode.metadata(exec).m_profile.m_buckets[0] = JSValue::encode(value); \
 160     } while (false)
 161 
 162 #define LLINT_CALL_END_IMPL(exec, callTarget, callTargetTag) \
 163     LLINT_RETURN_TWO(retagCodePtr((callTarget), callTargetTag, SlowPathPtrTag), (exec))
 164 
 165 #define LLINT_CALL_THROW(exec, exceptionToThrow) do {                   \
 166         ExecState* __ct_exec = (exec);                                  \
 167         throwException(__ct_exec, throwScope, exceptionToThrow);        \
 168         LLINT_CALL_END_IMPL(0, callToThrow(__ct_exec), ExceptionHandlerPtrTag);                 \
 169     } while (false)
 170 
 171 #define LLINT_CALL_CHECK_EXCEPTION(exec, execCallee) do {               \
 172         ExecState* __cce_exec = (exec);                                 \
 173         ExecState* __cce_execCallee = (execCallee);                     \
 174         doExceptionFuzzingIfEnabled(__cce_exec, throwScope, &quot;LLIntSlowPaths/call&quot;, nullptr); \
 175         if (UNLIKELY(throwScope.exception()))                           \
 176             LLINT_CALL_END_IMPL(0, callToThrow(__cce_execCallee), ExceptionHandlerPtrTag); \
 177     } while (false)
 178 
 179 #define LLINT_CALL_RETURN(exec, execCallee, callTarget, callTargetTag) do { \
 180         ExecState* __cr_exec = (exec);                                  \
 181         ExecState* __cr_execCallee = (execCallee);                      \
 182         void* __cr_callTarget = (callTarget);                           \
 183         LLINT_CALL_CHECK_EXCEPTION(__cr_exec, __cr_execCallee);         \
 184         LLINT_CALL_END_IMPL(__cr_execCallee, __cr_callTarget, callTargetTag); \
 185     } while (false)
 186 
 187 #define LLINT_RETURN_CALLEE_FRAME(execCallee) do {                      \
 188         ExecState* __rcf_exec = (execCallee);                           \
 189         LLINT_RETURN_TWO(pc, __rcf_exec);                               \
 190     } while (false)
 191 
 192 #if LLINT_TRACING
 193 
 194 template&lt;typename... Types&gt;
 195 void slowPathLog(const Types&amp;... values)
 196 {
 197     dataLogIf(Options::traceLLIntSlowPath(), values...);
 198 }
 199 
 200 template&lt;typename... Types&gt;
 201 void slowPathLn(const Types&amp;... values)
 202 {
 203     dataLogLnIf(Options::traceLLIntSlowPath(), values...);
 204 }
 205 
 206 template&lt;typename... Types&gt;
 207 void slowPathLogF(const char* format, const Types&amp;... values)
 208 {
 209     ALLOW_NONLITERAL_FORMAT_BEGIN
 210     IGNORE_WARNINGS_BEGIN(&quot;format-security&quot;)
 211     if (Options::traceLLIntSlowPath())
 212         dataLogF(format, values...);
 213     IGNORE_WARNINGS_END
 214     ALLOW_NONLITERAL_FORMAT_END
 215 }
 216 
 217 #else // not LLINT_TRACING
 218 
 219 template&lt;typename... Types&gt; void slowPathLog(const Types&amp;...) { }
 220 template&lt;typename... Types&gt; void slowPathLogLn(const Types&amp;...) { }
 221 template&lt;typename... Types&gt; void slowPathLogF(const char*, const Types&amp;...) { }
 222 
 223 #endif // LLINT_TRACING
 224 
 225 extern &quot;C&quot; SlowPathReturnType llint_trace_operand(ExecState* exec, const Instruction* pc, int fromWhere, int operand)
 226 {
 227     if (!Options::traceLLIntExecution())
 228         LLINT_END_IMPL();
 229 
 230     LLINT_BEGIN();
 231     dataLogF(
 232         &quot;&lt;%p&gt; %p / %p: executing bc#%zu, op#%u: Trace(%d): %d\n&quot;,
 233         &amp;Thread::current(),
 234         exec-&gt;codeBlock(),
 235         exec,
 236         static_cast&lt;intptr_t&gt;(exec-&gt;codeBlock()-&gt;bytecodeOffset(pc)),
 237         pc-&gt;opcodeID(),
 238         fromWhere,
 239         operand);
 240     LLINT_END();
 241 }
 242 
 243 extern &quot;C&quot; SlowPathReturnType llint_trace_value(ExecState* exec, const Instruction* pc, int fromWhere, VirtualRegister operand)
 244 {
 245     if (!Options::traceLLIntExecution())
 246         LLINT_END_IMPL();
 247 
 248     JSValue value = getOperand(exec, operand);
 249     union {
 250         struct {
 251             uint32_t tag;
 252             uint32_t payload;
 253         } bits;
 254         EncodedJSValue asValue;
 255     } u;
 256     u.asValue = JSValue::encode(value);
 257     dataLogF(
 258         &quot;&lt;%p&gt; %p / %p: executing bc#%zu, op#%u: Trace(%d): %d: %08x:%08x: %s\n&quot;,
 259         &amp;Thread::current(),
 260         exec-&gt;codeBlock(),
 261         exec,
 262         static_cast&lt;intptr_t&gt;(exec-&gt;codeBlock()-&gt;bytecodeOffset(pc)),
 263         pc-&gt;opcodeID(),
 264         fromWhere,
 265         operand.offset(),
 266         u.bits.tag,
 267         u.bits.payload,
 268         toCString(value).data());
 269     LLINT_END_IMPL();
 270 }
 271 
 272 LLINT_SLOW_PATH_DECL(trace_prologue)
 273 {
 274     if (!Options::traceLLIntExecution())
 275         LLINT_END_IMPL();
 276 
 277     dataLogF(&quot;&lt;%p&gt; %p / %p: in prologue of &quot;, &amp;Thread::current(), exec-&gt;codeBlock(), exec);
 278     dataLog(exec-&gt;codeBlock(), &quot;\n&quot;);
 279     LLINT_END_IMPL();
 280 }
 281 
 282 static void traceFunctionPrologue(ExecState* exec, const char* comment, CodeSpecializationKind kind)
 283 {
 284     if (!Options::traceLLIntExecution())
 285         return;
 286 
 287     JSFunction* callee = jsCast&lt;JSFunction*&gt;(exec-&gt;jsCallee());
 288     FunctionExecutable* executable = callee-&gt;jsExecutable();
 289     CodeBlock* codeBlock = executable-&gt;codeBlockFor(kind);
 290     dataLogF(&quot;&lt;%p&gt; %p / %p: in %s of &quot;, &amp;Thread::current(), codeBlock, exec, comment);
 291     dataLog(codeBlock);
 292     dataLogF(&quot; function %p, executable %p; numVars = %u, numParameters = %u, numCalleeLocals = %u, caller = %p.\n&quot;,
 293         callee, executable, codeBlock-&gt;numVars(), codeBlock-&gt;numParameters(), codeBlock-&gt;numCalleeLocals(), exec-&gt;callerFrame());
 294 }
 295 
 296 LLINT_SLOW_PATH_DECL(trace_prologue_function_for_call)
 297 {
 298     traceFunctionPrologue(exec, &quot;call prologue&quot;, CodeForCall);
 299     LLINT_END_IMPL();
 300 }
 301 
 302 LLINT_SLOW_PATH_DECL(trace_prologue_function_for_construct)
 303 {
 304     traceFunctionPrologue(exec, &quot;construct prologue&quot;, CodeForConstruct);
 305     LLINT_END_IMPL();
 306 }
 307 
 308 LLINT_SLOW_PATH_DECL(trace_arityCheck_for_call)
 309 {
 310     traceFunctionPrologue(exec, &quot;call arity check&quot;, CodeForCall);
 311     LLINT_END_IMPL();
 312 }
 313 
 314 LLINT_SLOW_PATH_DECL(trace_arityCheck_for_construct)
 315 {
 316     traceFunctionPrologue(exec, &quot;construct arity check&quot;, CodeForConstruct);
 317     LLINT_END_IMPL();
 318 }
 319 
 320 LLINT_SLOW_PATH_DECL(trace)
 321 {
 322     if (!Options::traceLLIntExecution())
 323         LLINT_END_IMPL();
 324 
 325     OpcodeID opcodeID = pc-&gt;opcodeID();
 326     dataLogF(&quot;&lt;%p&gt; %p / %p: executing bc#%zu, %s, pc = %p\n&quot;,
 327             &amp;Thread::current(),
 328             exec-&gt;codeBlock(),
 329             exec,
 330             static_cast&lt;intptr_t&gt;(exec-&gt;codeBlock()-&gt;bytecodeOffset(pc)),
 331             pc-&gt;name(),
 332             pc);
 333     if (opcodeID == op_enter) {
 334         dataLogF(&quot;Frame will eventually return to %p\n&quot;, exec-&gt;returnPC().value());
 335         *removeCodePtrTag&lt;volatile char*&gt;(exec-&gt;returnPC().value());
 336     }
 337     if (opcodeID == op_ret) {
 338         dataLogF(&quot;Will be returning to %p\n&quot;, exec-&gt;returnPC().value());
 339         dataLogF(&quot;The new cfr will be %p\n&quot;, exec-&gt;callerFrame());
 340     }
 341     LLINT_END_IMPL();
 342 }
 343 
 344 enum EntryKind { Prologue, ArityCheck };
 345 
 346 #if ENABLE(JIT)
 347 static FunctionWhitelist&amp; ensureGlobalJITWhitelist()
 348 {
 349     static LazyNeverDestroyed&lt;FunctionWhitelist&gt; baselineWhitelist;
 350     static std::once_flag initializeWhitelistFlag;
 351     std::call_once(initializeWhitelistFlag, [] {
 352         const char* functionWhitelistFile = Options::jitWhitelist();
 353         baselineWhitelist.construct(functionWhitelistFile);
 354     });
 355     return baselineWhitelist;
 356 }
 357 
 358 inline bool shouldJIT(CodeBlock* codeBlock)
 359 {
 360     if (!Options::bytecodeRangeToJITCompile().isInRange(codeBlock-&gt;instructionsSize())
 361         || !ensureGlobalJITWhitelist().contains(codeBlock))
 362         return false;
 363 
 364     return VM::canUseJIT() &amp;&amp; Options::useBaselineJIT();
 365 }
 366 
 367 // Returns true if we should try to OSR.
 368 inline bool jitCompileAndSetHeuristics(CodeBlock* codeBlock, ExecState* exec, unsigned loopOSREntryBytecodeOffset = 0)
 369 {
 370     VM&amp; vm = exec-&gt;vm();
 371     DeferGCForAWhile deferGC(vm.heap); // My callers don&#39;t set top callframe, so we don&#39;t want to GC here at all.
 372     ASSERT(VM::canUseJIT());
 373 
 374     codeBlock-&gt;updateAllValueProfilePredictions();
 375 
 376     if (!codeBlock-&gt;checkIfJITThresholdReached()) {
 377         CODEBLOCK_LOG_EVENT(codeBlock, &quot;delayJITCompile&quot;, (&quot;threshold not reached, counter = &quot;, codeBlock-&gt;llintExecuteCounter()));
 378         if (Options::verboseOSR())
 379             dataLogF(&quot;    JIT threshold should be lifted.\n&quot;);
 380         return false;
 381     }
 382 
 383     JITWorklist::ensureGlobalWorklist().poll(vm);
 384 
 385     switch (codeBlock-&gt;jitType()) {
 386     case JITType::BaselineJIT: {
 387         if (Options::verboseOSR())
 388             dataLogF(&quot;    Code was already compiled.\n&quot;);
 389         codeBlock-&gt;jitSoon();
 390         return true;
 391     }
 392     case JITType::InterpreterThunk: {
 393         JITWorklist::ensureGlobalWorklist().compileLater(codeBlock, loopOSREntryBytecodeOffset);
 394         return codeBlock-&gt;jitType() == JITType::BaselineJIT;
 395     }
 396     default:
 397         dataLog(&quot;Unexpected code block in LLInt: &quot;, *codeBlock, &quot;\n&quot;);
 398         RELEASE_ASSERT_NOT_REACHED();
 399         return false;
 400     }
 401 }
 402 
 403 static SlowPathReturnType entryOSR(ExecState* exec, const Instruction*, CodeBlock* codeBlock, const char *name, EntryKind kind)
 404 {
 405     if (Options::verboseOSR()) {
 406         dataLog(
 407             *codeBlock, &quot;: Entered &quot;, name, &quot; with executeCounter = &quot;,
 408             codeBlock-&gt;llintExecuteCounter(), &quot;\n&quot;);
 409     }
 410 
 411     if (!shouldJIT(codeBlock)) {
 412         codeBlock-&gt;dontJITAnytimeSoon();
 413         LLINT_RETURN_TWO(0, 0);
 414     }
 415     if (!jitCompileAndSetHeuristics(codeBlock, exec))
 416         LLINT_RETURN_TWO(0, 0);
 417 
 418     CODEBLOCK_LOG_EVENT(codeBlock, &quot;OSR entry&quot;, (&quot;in prologue&quot;));
 419 
 420     if (kind == Prologue)
 421         LLINT_RETURN_TWO(codeBlock-&gt;jitCode()-&gt;executableAddress(), 0);
 422     ASSERT(kind == ArityCheck);
 423     LLINT_RETURN_TWO(codeBlock-&gt;jitCode()-&gt;addressForCall(MustCheckArity).executableAddress(), 0);
 424 }
 425 #else // ENABLE(JIT)
 426 static SlowPathReturnType entryOSR(ExecState* exec, const Instruction*, CodeBlock* codeBlock, const char*, EntryKind)
 427 {
 428     codeBlock-&gt;dontJITAnytimeSoon();
 429     LLINT_RETURN_TWO(0, exec);
 430 }
 431 #endif // ENABLE(JIT)
 432 
 433 LLINT_SLOW_PATH_DECL(entry_osr)
 434 {
 435     return entryOSR(exec, pc, exec-&gt;codeBlock(), &quot;entry_osr&quot;, Prologue);
 436 }
 437 
 438 LLINT_SLOW_PATH_DECL(entry_osr_function_for_call)
 439 {
 440     return entryOSR(exec, pc, jsCast&lt;JSFunction*&gt;(exec-&gt;jsCallee())-&gt;jsExecutable()-&gt;codeBlockForCall(), &quot;entry_osr_function_for_call&quot;, Prologue);
 441 }
 442 
 443 LLINT_SLOW_PATH_DECL(entry_osr_function_for_construct)
 444 {
 445     return entryOSR(exec, pc, jsCast&lt;JSFunction*&gt;(exec-&gt;jsCallee())-&gt;jsExecutable()-&gt;codeBlockForConstruct(), &quot;entry_osr_function_for_construct&quot;, Prologue);
 446 }
 447 
 448 LLINT_SLOW_PATH_DECL(entry_osr_function_for_call_arityCheck)
 449 {
 450     return entryOSR(exec, pc, jsCast&lt;JSFunction*&gt;(exec-&gt;jsCallee())-&gt;jsExecutable()-&gt;codeBlockForCall(), &quot;entry_osr_function_for_call_arityCheck&quot;, ArityCheck);
 451 }
 452 
 453 LLINT_SLOW_PATH_DECL(entry_osr_function_for_construct_arityCheck)
 454 {
 455     return entryOSR(exec, pc, jsCast&lt;JSFunction*&gt;(exec-&gt;jsCallee())-&gt;jsExecutable()-&gt;codeBlockForConstruct(), &quot;entry_osr_function_for_construct_arityCheck&quot;, ArityCheck);
 456 }
 457 
 458 LLINT_SLOW_PATH_DECL(loop_osr)
 459 {
 460     LLINT_BEGIN_NO_SET_PC();
 461     UNUSED_PARAM(throwScope);
 462     CodeBlock* codeBlock = exec-&gt;codeBlock();
 463 
 464 #if ENABLE(JIT)
 465     if (Options::verboseOSR()) {
 466         dataLog(
 467             *codeBlock, &quot;: Entered loop_osr with executeCounter = &quot;,
 468             codeBlock-&gt;llintExecuteCounter(), &quot;\n&quot;);
 469     }
 470 
 471     unsigned loopOSREntryBytecodeOffset = codeBlock-&gt;bytecodeOffset(pc);
 472 
 473     if (!shouldJIT(codeBlock)) {
 474         codeBlock-&gt;dontJITAnytimeSoon();
 475         LLINT_RETURN_TWO(0, 0);
 476     }
 477 
 478     if (!jitCompileAndSetHeuristics(codeBlock, exec, loopOSREntryBytecodeOffset))
 479         LLINT_RETURN_TWO(0, 0);
 480 
 481     CODEBLOCK_LOG_EVENT(codeBlock, &quot;osrEntry&quot;, (&quot;at bc#&quot;, loopOSREntryBytecodeOffset));
 482 
 483     ASSERT(codeBlock-&gt;jitType() == JITType::BaselineJIT);
 484 
 485     const JITCodeMap&amp; codeMap = codeBlock-&gt;jitCodeMap();
 486     CodeLocationLabel&lt;JSEntryPtrTag&gt; codeLocation = codeMap.find(loopOSREntryBytecodeOffset);
 487     ASSERT(codeLocation);
 488 
 489     void* jumpTarget = codeLocation.executableAddress();
 490     ASSERT(jumpTarget);
 491 
 492     LLINT_RETURN_TWO(jumpTarget, exec-&gt;topOfFrame());
 493 #else // ENABLE(JIT)
 494     UNUSED_PARAM(pc);
 495     codeBlock-&gt;dontJITAnytimeSoon();
 496     LLINT_RETURN_TWO(0, 0);
 497 #endif // ENABLE(JIT)
 498 }
 499 
 500 LLINT_SLOW_PATH_DECL(replace)
 501 {
 502     LLINT_BEGIN_NO_SET_PC();
 503     UNUSED_PARAM(throwScope);
 504     CodeBlock* codeBlock = exec-&gt;codeBlock();
 505 
 506 #if ENABLE(JIT)
 507     if (Options::verboseOSR()) {
 508         dataLog(
 509             *codeBlock, &quot;: Entered replace with executeCounter = &quot;,
 510             codeBlock-&gt;llintExecuteCounter(), &quot;\n&quot;);
 511     }
 512 
 513     if (shouldJIT(codeBlock))
 514         jitCompileAndSetHeuristics(codeBlock, exec);
 515     else
 516         codeBlock-&gt;dontJITAnytimeSoon();
 517     LLINT_END_IMPL();
 518 #else // ENABLE(JIT)
 519     codeBlock-&gt;dontJITAnytimeSoon();
 520     LLINT_END_IMPL();
 521 #endif // ENABLE(JIT)
 522 }
 523 
 524 LLINT_SLOW_PATH_DECL(stack_check)
 525 {
 526     VM&amp; vm = exec-&gt;vm();
 527     auto throwScope = DECLARE_THROW_SCOPE(vm);
 528 
 529     // It&#39;s ok to create the NativeCallFrameTracer here before we
 530     // convertToStackOverflowFrame() because this function is always called
 531     // after the frame has been propulated with a proper CodeBlock and callee.
 532     NativeCallFrameTracer tracer(vm, exec);
 533 
 534     LLINT_SET_PC_FOR_STUBS();
 535 
 536     CodeBlock* codeBlock = exec-&gt;codeBlock();
 537     slowPathLogF(&quot;Checking stack height with exec = %p.\n&quot;, exec);
 538     slowPathLog(&quot;CodeBlock = &quot;, codeBlock, &quot;\n&quot;);
 539     if (codeBlock) {
 540         slowPathLogF(&quot;Num callee registers = %u.\n&quot;, codeBlock-&gt;numCalleeLocals());
 541         slowPathLogF(&quot;Num vars = %u.\n&quot;, codeBlock-&gt;numVars());
 542     }
 543     slowPathLogF(&quot;Current OS stack end is at %p.\n&quot;, vm.softStackLimit());
 544 #if ENABLE(C_LOOP)
 545     slowPathLogF(&quot;Current C Loop stack end is at %p.\n&quot;, vm.cloopStackLimit());
 546 #endif
 547 
 548     // If the stack check succeeds and we don&#39;t need to throw the error, then
 549     // we&#39;ll return 0 instead. The prologue will check for a non-zero value
 550     // when determining whether to set the callFrame or not.
 551 
 552     // For JIT enabled builds which uses the C stack, the stack is not growable.
 553     // Hence, if we get here, then we know a stack overflow is imminent. So, just
 554     // throw the StackOverflowError unconditionally.
 555 #if ENABLE(C_LOOP)
 556     Register* topOfFrame = exec-&gt;topOfFrame();
 557     if (LIKELY(topOfFrame &lt; reinterpret_cast&lt;Register*&gt;(exec))) {
 558         ASSERT(!vm.interpreter-&gt;cloopStack().containsAddress(topOfFrame));
 559         if (LIKELY(vm.ensureStackCapacityFor(topOfFrame)))
 560             LLINT_RETURN_TWO(pc, 0);
 561     }
 562 #endif
 563 
 564     exec-&gt;convertToStackOverflowFrame(vm, codeBlock);
 565     ErrorHandlingScope errorScope(vm);
 566     throwStackOverflowError(exec, throwScope);
 567     pc = returnToThrow(exec);
 568     LLINT_RETURN_TWO(pc, exec);
 569 }
 570 
 571 LLINT_SLOW_PATH_DECL(slow_path_new_object)
 572 {
 573     LLINT_BEGIN();
 574     auto bytecode = pc-&gt;as&lt;OpNewObject&gt;();
 575     auto&amp; metadata = bytecode.metadata(exec);
 576     LLINT_RETURN(constructEmptyObject(exec, metadata.m_objectAllocationProfile.structure()));
 577 }
 578 
 579 LLINT_SLOW_PATH_DECL(slow_path_new_array)
 580 {
 581     LLINT_BEGIN();
 582     auto bytecode = pc-&gt;as&lt;OpNewArray&gt;();
 583     auto&amp; metadata = bytecode.metadata(exec);
 584     LLINT_RETURN(constructArrayNegativeIndexed(exec, &amp;metadata.m_arrayAllocationProfile, bitwise_cast&lt;JSValue*&gt;(&amp;exec-&gt;uncheckedR(bytecode.m_argv)), bytecode.m_argc));
 585 }
 586 
 587 LLINT_SLOW_PATH_DECL(slow_path_new_array_with_size)
 588 {
 589     LLINT_BEGIN();
 590     auto bytecode = pc-&gt;as&lt;OpNewArrayWithSize&gt;();
 591     auto&amp; metadata = bytecode.metadata(exec);
 592     LLINT_RETURN(constructArrayWithSizeQuirk(exec, &amp;metadata.m_arrayAllocationProfile, exec-&gt;lexicalGlobalObject(), getOperand(exec, bytecode.m_length)));
 593 }
 594 
 595 LLINT_SLOW_PATH_DECL(slow_path_new_regexp)
 596 {
 597     LLINT_BEGIN();
 598     auto bytecode = pc-&gt;as&lt;OpNewRegexp&gt;();
 599     RegExp* regExp = jsCast&lt;RegExp*&gt;(getOperand(exec, bytecode.m_regexp));
 600     ASSERT(regExp-&gt;isValid());
 601     LLINT_RETURN(RegExpObject::create(vm, exec-&gt;lexicalGlobalObject()-&gt;regExpStructure(), regExp));
 602 }
 603 
 604 LLINT_SLOW_PATH_DECL(slow_path_instanceof)
 605 {
 606     LLINT_BEGIN();
 607     auto bytecode = pc-&gt;as&lt;OpInstanceof&gt;();
 608     JSValue value = getOperand(exec, bytecode.m_value);
 609     JSValue proto = getOperand(exec, bytecode.m_prototype);
 610     LLINT_RETURN(jsBoolean(JSObject::defaultHasInstance(exec, value, proto)));
 611 }
 612 
 613 LLINT_SLOW_PATH_DECL(slow_path_instanceof_custom)
 614 {
 615     LLINT_BEGIN();
 616 
 617     auto bytecode = pc-&gt;as&lt;OpInstanceofCustom&gt;();
 618     JSValue value = getOperand(exec, bytecode.m_value);
 619     JSValue constructor = getOperand(exec, bytecode.m_constructor);
 620     JSValue hasInstanceValue = getOperand(exec, bytecode.m_hasInstanceValue);
 621 
 622     ASSERT(constructor.isObject());
 623     ASSERT(hasInstanceValue != exec-&gt;lexicalGlobalObject()-&gt;functionProtoHasInstanceSymbolFunction() || !constructor.getObject()-&gt;structure(vm)-&gt;typeInfo().implementsDefaultHasInstance());
 624 
 625     JSValue result = jsBoolean(constructor.getObject()-&gt;hasInstance(exec, value, hasInstanceValue));
 626     LLINT_RETURN(result);
 627 }
 628 
 629 LLINT_SLOW_PATH_DECL(slow_path_try_get_by_id)
 630 {
 631     LLINT_BEGIN();
 632     auto bytecode = pc-&gt;as&lt;OpTryGetById&gt;();
 633     CodeBlock* codeBlock = exec-&gt;codeBlock();
 634     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_property);
 635     JSValue baseValue = getOperand(exec, bytecode.m_base);
 636     PropertySlot slot(baseValue, PropertySlot::PropertySlot::InternalMethodType::VMInquiry);
 637 
 638     baseValue.getPropertySlot(exec, ident, slot);
 639     JSValue result = slot.getPureResult();
 640 
 641     LLINT_RETURN_PROFILED(result);
 642 }
 643 
 644 LLINT_SLOW_PATH_DECL(slow_path_get_by_id_direct)
 645 {
 646     LLINT_BEGIN();
 647     auto bytecode = pc-&gt;as&lt;OpGetByIdDirect&gt;();
 648     CodeBlock* codeBlock = exec-&gt;codeBlock();
 649     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_property);
 650     JSValue baseValue = getOperand(exec, bytecode.m_base);
 651     PropertySlot slot(baseValue, PropertySlot::PropertySlot::InternalMethodType::GetOwnProperty);
 652 
 653     bool found = baseValue.getOwnPropertySlot(exec, ident, slot);
 654     LLINT_CHECK_EXCEPTION();
 655     JSValue result = found ? slot.getValue(exec, ident) : jsUndefined();
 656     LLINT_CHECK_EXCEPTION();
 657 
 658     if (!LLINT_ALWAYS_ACCESS_SLOW &amp;&amp; slot.isCacheable()) {
 659         auto&amp; metadata = bytecode.metadata(exec);
 660         {
 661             StructureID oldStructureID = metadata.m_structureID;
 662             if (oldStructureID) {
 663                 Structure* a = vm.heap.structureIDTable().get(oldStructureID);
 664                 Structure* b = baseValue.asCell()-&gt;structure(vm);
 665 
 666                 if (Structure::shouldConvertToPolyProto(a, b)) {
 667                     ASSERT(a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint().get() == b-&gt;rareData()-&gt;sharedPolyProtoWatchpoint().get());
 668                     a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint()-&gt;invalidate(vm, StringFireDetail(&quot;Detected poly proto opportunity.&quot;));
 669                 }
 670             }
 671         }
 672 
 673         JSCell* baseCell = baseValue.asCell();
 674         Structure* structure = baseCell-&gt;structure(vm);
 675         if (slot.isValue()) {
 676             // Start out by clearing out the old cache.
 677             metadata.m_structureID = 0;
 678             metadata.m_offset = 0;
 679 
 680             if (structure-&gt;propertyAccessesAreCacheable() &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
 681                 {
 682                     ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 683                     metadata.m_structureID = structure-&gt;id();
 684                     metadata.m_offset = slot.cachedOffset();
 685                 }
 686                 vm.heap.writeBarrier(codeBlock);
 687             }
 688         }
 689     }
 690 
 691     LLINT_RETURN_PROFILED(result);
 692 }
 693 
 694 
 695 static void setupGetByIdPrototypeCache(ExecState* exec, VM&amp; vm, const Instruction* pc, OpGetById::Metadata&amp; metadata, JSCell* baseCell, PropertySlot&amp; slot, const Identifier&amp; ident)
 696 {
 697     CodeBlock* codeBlock = exec-&gt;codeBlock();
 698     Structure* structure = baseCell-&gt;structure(vm);
 699 
 700     if (structure-&gt;typeInfo().prohibitsPropertyCaching())
 701         return;
 702 
 703     if (structure-&gt;needImpurePropertyWatchpoint())
 704         return;
 705 
 706     if (structure-&gt;isDictionary()) {
 707         if (structure-&gt;hasBeenFlattenedBefore())
 708             return;
 709         structure-&gt;flattenDictionaryStructure(vm, jsCast&lt;JSObject*&gt;(baseCell));
 710     }
 711 
 712     ObjectPropertyConditionSet conditions;
 713     if (slot.isUnset())
 714         conditions = generateConditionsForPropertyMiss(vm, codeBlock, exec, structure, ident.impl());
 715     else
 716         conditions = generateConditionsForPrototypePropertyHit(vm, codeBlock, exec, structure, slot.slotBase(), ident.impl());
 717 
 718     if (!conditions.isValid())
 719         return;
 720 
 721     unsigned bytecodeOffset = codeBlock-&gt;bytecodeOffset(pc);
 722     PropertyOffset offset = invalidOffset;
 723     CodeBlock::StructureWatchpointMap&amp; watchpointMap = codeBlock-&gt;llintGetByIdWatchpointMap();
 724     Vector&lt;LLIntPrototypeLoadAdaptiveStructureWatchpoint&gt; watchpoints;
 725     watchpoints.reserveInitialCapacity(conditions.size());
 726     for (ObjectPropertyCondition condition : conditions) {
 727         if (!condition.isWatchable())
 728             return;
 729         if (condition.condition().kind() == PropertyCondition::Presence)
 730             offset = condition.condition().offset();
 731         watchpoints.uncheckedConstructAndAppend(codeBlock, condition, bytecodeOffset);
 732         watchpoints.last().install(vm);
 733     }
 734 
 735     ASSERT((offset == invalidOffset) == slot.isUnset());
 736     auto result = watchpointMap.add(std::make_tuple(structure-&gt;id(), bytecodeOffset), WTFMove(watchpoints));
 737     ASSERT_UNUSED(result, result.isNewEntry);
 738 
 739     {
 740         ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 741         if (slot.isUnset())
 742             metadata.m_modeMetadata.setUnsetMode(structure);
 743         else {
 744             ASSERT(slot.isValue());
 745             metadata.m_modeMetadata.setProtoLoadMode(structure, offset, slot.slotBase());
 746         }
 747     }
 748     vm.heap.writeBarrier(codeBlock);
 749 }
 750 
 751 
 752 LLINT_SLOW_PATH_DECL(slow_path_get_by_id)
 753 {
 754     LLINT_BEGIN();
 755     auto bytecode = pc-&gt;as&lt;OpGetById&gt;();
 756     auto&amp; metadata = bytecode.metadata(exec);
 757     CodeBlock* codeBlock = exec-&gt;codeBlock();
 758     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_property);
 759     JSValue baseValue = getOperand(exec, bytecode.m_base);
 760     PropertySlot slot(baseValue, PropertySlot::PropertySlot::InternalMethodType::Get);
 761 
 762     JSValue result = baseValue.get(exec, ident, slot);
 763     LLINT_CHECK_EXCEPTION();
 764     exec-&gt;uncheckedR(bytecode.m_dst) = result;
 765 
 766     if (!LLINT_ALWAYS_ACCESS_SLOW
 767         &amp;&amp; baseValue.isCell()
 768         &amp;&amp; slot.isCacheable()) {
 769         {
 770             StructureID oldStructureID;
 771             switch (metadata.m_modeMetadata.mode) {
 772             case GetByIdMode::Default:
 773                 oldStructureID = metadata.m_modeMetadata.defaultMode.structureID;
 774                 break;
 775             case GetByIdMode::Unset:
 776                 oldStructureID = metadata.m_modeMetadata.unsetMode.structureID;
 777                 break;
 778             case GetByIdMode::ProtoLoad:
 779                 oldStructureID = metadata.m_modeMetadata.protoLoadMode.structureID;
 780                 break;
 781             default:
 782                 oldStructureID = 0;
 783             }
 784             if (oldStructureID) {
 785                 Structure* a = vm.heap.structureIDTable().get(oldStructureID);
 786                 Structure* b = baseValue.asCell()-&gt;structure(vm);
 787 
 788                 if (Structure::shouldConvertToPolyProto(a, b)) {
 789                     ASSERT(a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint().get() == b-&gt;rareData()-&gt;sharedPolyProtoWatchpoint().get());
 790                     a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint()-&gt;invalidate(vm, StringFireDetail(&quot;Detected poly proto opportunity.&quot;));
 791                 }
 792             }
 793         }
 794 
 795         JSCell* baseCell = baseValue.asCell();
 796         Structure* structure = baseCell-&gt;structure(vm);
 797         if (slot.isValue() &amp;&amp; slot.slotBase() == baseValue) {
 798             ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 799             // Start out by clearing out the old cache.
 800             metadata.m_modeMetadata.clearToDefaultModeWithoutCache();
 801 
 802             // Prevent the prototype cache from ever happening.
 803             metadata.m_modeMetadata.hitCountForLLIntCaching = 0;
 804 
 805             if (structure-&gt;propertyAccessesAreCacheable() &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
 806                 metadata.m_modeMetadata.defaultMode.structureID = structure-&gt;id();
 807                 metadata.m_modeMetadata.defaultMode.cachedOffset = slot.cachedOffset();
 808                 vm.heap.writeBarrier(codeBlock);
 809             }
 810         } else if (UNLIKELY(metadata.m_modeMetadata.hitCountForLLIntCaching &amp;&amp; (slot.isValue() || slot.isUnset()))) {
 811             ASSERT(slot.slotBase() != baseValue);
 812 
 813             if (!(--metadata.m_modeMetadata.hitCountForLLIntCaching))
 814                 setupGetByIdPrototypeCache(exec, vm, pc, metadata, baseCell, slot, ident);
 815         }
 816     } else if (!LLINT_ALWAYS_ACCESS_SLOW &amp;&amp; isJSArray(baseValue) &amp;&amp; ident == vm.propertyNames-&gt;length) {
 817         {
 818             ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 819             metadata.m_modeMetadata.setArrayLengthMode();
 820             metadata.m_modeMetadata.arrayLengthMode.arrayProfile.observeStructure(baseValue.asCell()-&gt;structure(vm));
 821         }
 822         vm.heap.writeBarrier(codeBlock);
 823     }
 824 
 825     LLINT_PROFILE_VALUE(result);
 826     LLINT_END();
 827 }
 828 
 829 LLINT_SLOW_PATH_DECL(slow_path_put_by_id)
 830 {
 831     LLINT_BEGIN();
 832     auto bytecode = pc-&gt;as&lt;OpPutById&gt;();
 833     auto&amp; metadata = bytecode.metadata(exec);
 834     CodeBlock* codeBlock = exec-&gt;codeBlock();
 835     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_property);
 836 
 837     JSValue baseValue = getOperand(exec, bytecode.m_base);
 838     PutPropertySlot slot(baseValue, codeBlock-&gt;isStrictMode(), codeBlock-&gt;putByIdContext());
 839     if (bytecode.m_flags &amp; PutByIdIsDirect)
 840         CommonSlowPaths::putDirectWithReify(vm, exec, asObject(baseValue), ident, getOperand(exec, bytecode.m_value), slot);
 841     else
 842         baseValue.putInline(exec, ident, getOperand(exec, bytecode.m_value), slot);
 843     LLINT_CHECK_EXCEPTION();
 844 
 845     if (!LLINT_ALWAYS_ACCESS_SLOW
 846         &amp;&amp; baseValue.isCell()
 847         &amp;&amp; slot.isCacheablePut()) {
 848 
 849         {
 850             StructureID oldStructureID = metadata.m_oldStructureID;
 851             if (oldStructureID) {
 852                 Structure* a = vm.heap.structureIDTable().get(oldStructureID);
 853                 Structure* b = baseValue.asCell()-&gt;structure(vm);
 854                 if (slot.type() == PutPropertySlot::NewProperty)
 855                     b = b-&gt;previousID();
 856 
 857                 if (Structure::shouldConvertToPolyProto(a, b)) {
 858                     a-&gt;rareData()-&gt;sharedPolyProtoWatchpoint()-&gt;invalidate(vm, StringFireDetail(&quot;Detected poly proto opportunity.&quot;));
 859                     b-&gt;rareData()-&gt;sharedPolyProtoWatchpoint()-&gt;invalidate(vm, StringFireDetail(&quot;Detected poly proto opportunity.&quot;));
 860                 }
 861             }
 862         }
 863 
 864         // Start out by clearing out the old cache.
 865         metadata.m_oldStructureID = 0;
 866         metadata.m_offset = 0;
 867         metadata.m_newStructureID = 0;
 868         metadata.m_structureChain.clear();
 869 
 870         JSCell* baseCell = baseValue.asCell();
 871         Structure* structure = baseCell-&gt;structure(vm);
 872 
 873         if (!structure-&gt;isUncacheableDictionary() &amp;&amp; !structure-&gt;typeInfo().prohibitsPropertyCaching() &amp;&amp; baseCell == slot.base()) {
 874             if (slot.type() == PutPropertySlot::NewProperty) {
 875                 GCSafeConcurrentJSLocker locker(codeBlock-&gt;m_lock, vm.heap);
 876                 if (!structure-&gt;isDictionary() &amp;&amp; structure-&gt;previousID()-&gt;outOfLineCapacity() == structure-&gt;outOfLineCapacity()) {
 877                     ASSERT(structure-&gt;previousID()-&gt;transitionWatchpointSetHasBeenInvalidated());
 878 
 879                     bool sawPolyProto = false;
 880                     auto result = normalizePrototypeChain(exec, baseCell, sawPolyProto);
 881                     if (result != InvalidPrototypeChain &amp;&amp; !sawPolyProto) {
 882                         ASSERT(structure-&gt;previousID()-&gt;isObject());
 883                         metadata.m_oldStructureID = structure-&gt;previousID()-&gt;id();
 884                         metadata.m_offset = slot.cachedOffset();
 885                         metadata.m_newStructureID = structure-&gt;id();
 886                         if (!(bytecode.m_flags &amp; PutByIdIsDirect)) {
 887                             StructureChain* chain = structure-&gt;prototypeChain(exec, asObject(baseCell));
 888                             ASSERT(chain);
 889                             metadata.m_structureChain.set(vm, codeBlock, chain);
 890                         }
 891                         vm.heap.writeBarrier(codeBlock);
 892                     }
 893                 }
 894             } else {
 895                 structure-&gt;didCachePropertyReplacement(vm, slot.cachedOffset());
 896                 {
 897                     ConcurrentJSLocker locker(codeBlock-&gt;m_lock);
 898                     metadata.m_oldStructureID = structure-&gt;id();
 899                     metadata.m_offset = slot.cachedOffset();
 900                 }
 901                 vm.heap.writeBarrier(codeBlock);
 902             }
 903         }
 904     }
 905 
 906     LLINT_END();
 907 }
 908 
 909 LLINT_SLOW_PATH_DECL(slow_path_del_by_id)
 910 {
 911     LLINT_BEGIN();
 912     auto bytecode = pc-&gt;as&lt;OpDelById&gt;();
 913     CodeBlock* codeBlock = exec-&gt;codeBlock();
 914     JSObject* baseObject = getOperand(exec, bytecode.m_base).toObject(exec);
 915     LLINT_CHECK_EXCEPTION();
 916     bool couldDelete = baseObject-&gt;methodTable(vm)-&gt;deleteProperty(baseObject, exec, codeBlock-&gt;identifier(bytecode.m_property));
 917     LLINT_CHECK_EXCEPTION();
 918     if (!couldDelete &amp;&amp; codeBlock-&gt;isStrictMode())
 919         LLINT_THROW(createTypeError(exec, UnableToDeletePropertyError));
 920     LLINT_RETURN(jsBoolean(couldDelete));
 921 }
 922 
 923 static ALWAYS_INLINE JSValue getByVal(VM&amp; vm, ExecState* exec, OpGetByVal bytecode)
 924 {
 925     JSValue baseValue = getOperand(exec, bytecode.m_base);
 926     JSValue subscript = getOperand(exec, bytecode.m_property);
 927     auto scope = DECLARE_THROW_SCOPE(vm);
 928 
 929     if (LIKELY(baseValue.isCell() &amp;&amp; subscript.isString())) {
 930         Structure&amp; structure = *baseValue.asCell()-&gt;structure(vm);
 931         if (JSCell::canUseFastGetOwnProperty(structure)) {
 932             RefPtr&lt;AtomStringImpl&gt; existingAtomString = asString(subscript)-&gt;toExistingAtomString(exec);
 933             RETURN_IF_EXCEPTION(scope, JSValue());
 934             if (existingAtomString) {
 935                 if (JSValue result = baseValue.asCell()-&gt;fastGetOwnProperty(vm, structure, existingAtomString.get()))
 936                     return result;
 937             }
 938         }
 939     }
 940 
 941     if (subscript.isUInt32()) {
 942         uint32_t i = subscript.asUInt32();
 943         auto&amp; metadata = bytecode.metadata(exec);
 944         ArrayProfile* arrayProfile = &amp;metadata.m_arrayProfile;
 945 
 946         if (isJSString(baseValue)) {
 947             if (asString(baseValue)-&gt;canGetIndex(i)) {
 948                 scope.release();
 949                 return asString(baseValue)-&gt;getIndex(exec, i);
 950             }
 951             arrayProfile-&gt;setOutOfBounds();
 952         } else if (baseValue.isObject()) {
 953             JSObject* object = asObject(baseValue);
 954             if (object-&gt;canGetIndexQuickly(i))
 955                 return object-&gt;getIndexQuickly(i);
 956 
 957             bool skipMarkingOutOfBounds = false;
 958 
 959             if (object-&gt;indexingType() == ArrayWithContiguous &amp;&amp; i &lt; object-&gt;butterfly()-&gt;publicLength()) {
 960                 // FIXME: expand this to ArrayStorage, Int32, and maybe Double:
 961                 // https://bugs.webkit.org/show_bug.cgi?id=182940
 962                 auto* globalObject = object-&gt;globalObject(vm);
 963                 skipMarkingOutOfBounds = globalObject-&gt;isOriginalArrayStructure(object-&gt;structure(vm)) &amp;&amp; globalObject-&gt;arrayPrototypeChainIsSane();
 964             }
 965 
 966             if (!skipMarkingOutOfBounds &amp;&amp; !CommonSlowPaths::canAccessArgumentIndexQuickly(*object, i))
 967                 arrayProfile-&gt;setOutOfBounds();
 968         }
 969 
 970         scope.release();
 971         return baseValue.get(exec, i);
 972     }
 973 
 974     baseValue.requireObjectCoercible(exec);
 975     RETURN_IF_EXCEPTION(scope, JSValue());
 976     auto property = subscript.toPropertyKey(exec);
 977     RETURN_IF_EXCEPTION(scope, JSValue());
 978     scope.release();
 979     return baseValue.get(exec, property);
 980 }
 981 
 982 LLINT_SLOW_PATH_DECL(slow_path_get_by_val)
 983 {
 984     LLINT_BEGIN();
 985     auto bytecode = pc-&gt;as&lt;OpGetByVal&gt;();
 986     LLINT_RETURN_PROFILED(getByVal(vm, exec, bytecode));
 987 }
 988 
 989 LLINT_SLOW_PATH_DECL(slow_path_put_by_val)
 990 {
 991     LLINT_BEGIN();
 992 
 993     auto bytecode = pc-&gt;as&lt;OpPutByVal&gt;();
 994     JSValue baseValue = getOperand(exec, bytecode.m_base);
 995     JSValue subscript = getOperand(exec, bytecode.m_property);
 996     JSValue value = getOperand(exec, bytecode.m_value);
 997     bool isStrictMode = exec-&gt;codeBlock()-&gt;isStrictMode();
 998 
 999     if (LIKELY(subscript.isUInt32())) {
1000         uint32_t i = subscript.asUInt32();
1001         if (baseValue.isObject()) {
1002             JSObject* object = asObject(baseValue);
1003             if (object-&gt;canSetIndexQuickly(i, value))
1004                 object-&gt;setIndexQuickly(vm, i, value);
1005             else
1006                 object-&gt;methodTable(vm)-&gt;putByIndex(object, exec, i, value, isStrictMode);
1007             LLINT_END();
1008         }
1009         baseValue.putByIndex(exec, i, value, isStrictMode);
1010         LLINT_END();
1011     }
1012 
1013     auto property = subscript.toPropertyKey(exec);
1014     LLINT_CHECK_EXCEPTION();
1015     PutPropertySlot slot(baseValue, isStrictMode);
1016     baseValue.put(exec, property, value, slot);
1017     LLINT_END();
1018 }
1019 
1020 LLINT_SLOW_PATH_DECL(slow_path_put_by_val_direct)
1021 {
1022     LLINT_BEGIN();
1023 
1024     auto bytecode = pc-&gt;as&lt;OpPutByValDirect&gt;();
1025     JSValue baseValue = getOperand(exec, bytecode.m_base);
1026     JSValue subscript = getOperand(exec, bytecode.m_property);
1027     JSValue value = getOperand(exec, bytecode.m_value);
1028     RELEASE_ASSERT(baseValue.isObject());
1029     JSObject* baseObject = asObject(baseValue);
1030     bool isStrictMode = exec-&gt;codeBlock()-&gt;isStrictMode();
1031     if (LIKELY(subscript.isUInt32())) {
1032         // Despite its name, JSValue::isUInt32 will return true only for positive boxed int32_t; all those values are valid array indices.
1033         ASSERT(isIndex(subscript.asUInt32()));
1034         baseObject-&gt;putDirectIndex(exec, subscript.asUInt32(), value, 0, isStrictMode ? PutDirectIndexShouldThrow : PutDirectIndexShouldNotThrow);
1035         LLINT_END();
1036     }
1037 
1038     if (subscript.isDouble()) {
1039         double subscriptAsDouble = subscript.asDouble();
1040         uint32_t subscriptAsUInt32 = static_cast&lt;uint32_t&gt;(subscriptAsDouble);
1041         if (subscriptAsDouble == subscriptAsUInt32 &amp;&amp; isIndex(subscriptAsUInt32)) {
1042             baseObject-&gt;putDirectIndex(exec, subscriptAsUInt32, value, 0, isStrictMode ? PutDirectIndexShouldThrow : PutDirectIndexShouldNotThrow);
1043             LLINT_END();
1044         }
1045     }
1046 
1047     // Don&#39;t put to an object if toString threw an exception.
1048     auto property = subscript.toPropertyKey(exec);
1049     if (UNLIKELY(throwScope.exception()))
1050         LLINT_END();
1051 
1052     if (Optional&lt;uint32_t&gt; index = parseIndex(property))
1053         baseObject-&gt;putDirectIndex(exec, index.value(), value, 0, isStrictMode ? PutDirectIndexShouldThrow : PutDirectIndexShouldNotThrow);
1054     else {
1055         PutPropertySlot slot(baseObject, isStrictMode);
1056         CommonSlowPaths::putDirectWithReify(vm, exec, baseObject, property, value, slot);
1057     }
1058     LLINT_END();
1059 }
1060 
1061 LLINT_SLOW_PATH_DECL(slow_path_del_by_val)
1062 {
1063     LLINT_BEGIN();
1064     auto bytecode = pc-&gt;as&lt;OpDelByVal&gt;();
1065     JSValue baseValue = getOperand(exec, bytecode.m_base);
1066     JSObject* baseObject = baseValue.toObject(exec);
1067     LLINT_CHECK_EXCEPTION();
1068 
1069     JSValue subscript = getOperand(exec, bytecode.m_property);
1070 
1071     bool couldDelete;
1072 
1073     uint32_t i;
1074     if (subscript.getUInt32(i))
1075         couldDelete = baseObject-&gt;methodTable(vm)-&gt;deletePropertyByIndex(baseObject, exec, i);
1076     else {
1077         LLINT_CHECK_EXCEPTION();
1078         auto property = subscript.toPropertyKey(exec);
1079         LLINT_CHECK_EXCEPTION();
1080         couldDelete = baseObject-&gt;methodTable(vm)-&gt;deleteProperty(baseObject, exec, property);
1081     }
1082     LLINT_CHECK_EXCEPTION();
1083 
1084     if (!couldDelete &amp;&amp; exec-&gt;codeBlock()-&gt;isStrictMode())
1085         LLINT_THROW(createTypeError(exec, UnableToDeletePropertyError));
1086 
1087     LLINT_RETURN(jsBoolean(couldDelete));
1088 }
1089 
1090 LLINT_SLOW_PATH_DECL(slow_path_put_getter_by_id)
1091 {
1092     LLINT_BEGIN();
1093     auto bytecode = pc-&gt;as&lt;OpPutGetterById&gt;();
1094     ASSERT(getNonConstantOperand(exec, bytecode.m_base).isObject());
1095     JSObject* baseObj = asObject(getNonConstantOperand(exec, bytecode.m_base));
1096 
1097     unsigned options = bytecode.m_attributes;
1098 
1099     JSValue getter = getNonConstantOperand(exec, bytecode.m_accessor);
1100     ASSERT(getter.isObject());
1101 
1102     baseObj-&gt;putGetter(exec, exec-&gt;codeBlock()-&gt;identifier(bytecode.m_property), asObject(getter), options);
1103     LLINT_END();
1104 }
1105 
1106 LLINT_SLOW_PATH_DECL(slow_path_put_setter_by_id)
1107 {
1108     LLINT_BEGIN();
1109     auto bytecode = pc-&gt;as&lt;OpPutSetterById&gt;();
1110     ASSERT(getNonConstantOperand(exec, bytecode.m_base).isObject());
1111     JSObject* baseObj = asObject(getNonConstantOperand(exec, bytecode.m_base));
1112 
1113     unsigned options = bytecode.m_attributes;
1114 
1115     JSValue setter = getNonConstantOperand(exec, bytecode.m_accessor);
1116     ASSERT(setter.isObject());
1117 
1118     baseObj-&gt;putSetter(exec, exec-&gt;codeBlock()-&gt;identifier(bytecode.m_property), asObject(setter), options);
1119     LLINT_END();
1120 }
1121 
1122 LLINT_SLOW_PATH_DECL(slow_path_put_getter_setter_by_id)
1123 {
1124     LLINT_BEGIN();
1125     auto bytecode = pc-&gt;as&lt;OpPutGetterSetterById&gt;();
1126     ASSERT(getNonConstantOperand(exec, bytecode.m_base).isObject());
1127     JSObject* baseObject = asObject(getNonConstantOperand(exec, bytecode.m_base));
1128 
1129     JSValue getter = getNonConstantOperand(exec, bytecode.m_getter);
1130     JSValue setter = getNonConstantOperand(exec, bytecode.m_setter);
1131     ASSERT(getter.isObject() || setter.isObject());
1132     GetterSetter* accessor = GetterSetter::create(vm, exec-&gt;lexicalGlobalObject(), getter, setter);
1133 
1134     CommonSlowPaths::putDirectAccessorWithReify(vm, exec, baseObject, exec-&gt;codeBlock()-&gt;identifier(bytecode.m_property), accessor, bytecode.m_attributes);
1135     LLINT_END();
1136 }
1137 
1138 LLINT_SLOW_PATH_DECL(slow_path_put_getter_by_val)
1139 {
1140     LLINT_BEGIN();
1141     auto bytecode = pc-&gt;as&lt;OpPutGetterByVal&gt;();
1142     ASSERT(getNonConstantOperand(exec, bytecode.m_base).isObject());
1143     JSObject* baseObj = asObject(getNonConstantOperand(exec, bytecode.m_base));
1144     JSValue subscript = getOperand(exec, bytecode.m_property);
1145 
1146     unsigned options = bytecode.m_attributes;
1147 
1148     JSValue getter = getNonConstantOperand(exec, bytecode.m_accessor);
1149     ASSERT(getter.isObject());
1150 
1151     auto property = subscript.toPropertyKey(exec);
1152     LLINT_CHECK_EXCEPTION();
1153 
1154     baseObj-&gt;putGetter(exec, property, asObject(getter), options);
1155     LLINT_END();
1156 }
1157 
1158 LLINT_SLOW_PATH_DECL(slow_path_put_setter_by_val)
1159 {
1160     LLINT_BEGIN();
1161     auto bytecode = pc-&gt;as&lt;OpPutSetterByVal&gt;();
1162     ASSERT(getNonConstantOperand(exec, bytecode.m_base).isObject());
1163     JSObject* baseObj = asObject(getNonConstantOperand(exec, bytecode.m_base));
1164     JSValue subscript = getOperand(exec, bytecode.m_property);
1165 
1166     unsigned options = bytecode.m_attributes;
1167 
1168     JSValue setter = getNonConstantOperand(exec, bytecode.m_accessor);
1169     ASSERT(setter.isObject());
1170 
1171     auto property = subscript.toPropertyKey(exec);
1172     LLINT_CHECK_EXCEPTION();
1173 
1174     baseObj-&gt;putSetter(exec, property, asObject(setter), options);
1175     LLINT_END();
1176 }
1177 
1178 LLINT_SLOW_PATH_DECL(slow_path_jtrue)
1179 {
1180     LLINT_BEGIN();
1181     auto bytecode = pc-&gt;as&lt;OpJtrue&gt;();
1182     LLINT_BRANCH(getOperand(exec, bytecode.m_condition).toBoolean(exec));
1183 }
1184 
1185 LLINT_SLOW_PATH_DECL(slow_path_jfalse)
1186 {
1187     LLINT_BEGIN();
1188     auto bytecode = pc-&gt;as&lt;OpJfalse&gt;();
1189     LLINT_BRANCH(!getOperand(exec, bytecode.m_condition).toBoolean(exec));
1190 }
1191 
1192 LLINT_SLOW_PATH_DECL(slow_path_jless)
1193 {
1194     LLINT_BEGIN();
1195     auto bytecode = pc-&gt;as&lt;OpJless&gt;();
1196     LLINT_BRANCH(jsLess&lt;true&gt;(exec, getOperand(exec, bytecode.m_lhs), getOperand(exec, bytecode.m_rhs)));
1197 }
1198 
1199 LLINT_SLOW_PATH_DECL(slow_path_jnless)
1200 {
1201     LLINT_BEGIN();
1202     auto bytecode = pc-&gt;as&lt;OpJnless&gt;();
1203     LLINT_BRANCH(!jsLess&lt;true&gt;(exec, getOperand(exec, bytecode.m_lhs), getOperand(exec, bytecode.m_rhs)));
1204 }
1205 
1206 LLINT_SLOW_PATH_DECL(slow_path_jgreater)
1207 {
1208     LLINT_BEGIN();
1209     auto bytecode = pc-&gt;as&lt;OpJgreater&gt;();
1210     LLINT_BRANCH(jsLess&lt;false&gt;(exec, getOperand(exec, bytecode.m_rhs), getOperand(exec, bytecode.m_lhs)));
1211 }
1212 
1213 LLINT_SLOW_PATH_DECL(slow_path_jngreater)
1214 {
1215     LLINT_BEGIN();
1216     auto bytecode = pc-&gt;as&lt;OpJngreater&gt;();
1217     LLINT_BRANCH(!jsLess&lt;false&gt;(exec, getOperand(exec, bytecode.m_rhs), getOperand(exec, bytecode.m_lhs)));
1218 }
1219 
1220 LLINT_SLOW_PATH_DECL(slow_path_jlesseq)
1221 {
1222     LLINT_BEGIN();
1223     auto bytecode = pc-&gt;as&lt;OpJlesseq&gt;();
1224     LLINT_BRANCH(jsLessEq&lt;true&gt;(exec, getOperand(exec, bytecode.m_lhs), getOperand(exec, bytecode.m_rhs)));
1225 }
1226 
1227 LLINT_SLOW_PATH_DECL(slow_path_jnlesseq)
1228 {
1229     LLINT_BEGIN();
1230     auto bytecode = pc-&gt;as&lt;OpJnlesseq&gt;();
1231     LLINT_BRANCH(!jsLessEq&lt;true&gt;(exec, getOperand(exec, bytecode.m_lhs), getOperand(exec, bytecode.m_rhs)));
1232 }
1233 
1234 LLINT_SLOW_PATH_DECL(slow_path_jgreatereq)
1235 {
1236     LLINT_BEGIN();
1237     auto bytecode = pc-&gt;as&lt;OpJgreatereq&gt;();
1238     LLINT_BRANCH(jsLessEq&lt;false&gt;(exec, getOperand(exec, bytecode.m_rhs), getOperand(exec, bytecode.m_lhs)));
1239 }
1240 
1241 LLINT_SLOW_PATH_DECL(slow_path_jngreatereq)
1242 {
1243     LLINT_BEGIN();
1244     auto bytecode = pc-&gt;as&lt;OpJngreatereq&gt;();
1245     LLINT_BRANCH(!jsLessEq&lt;false&gt;(exec, getOperand(exec, bytecode.m_rhs), getOperand(exec, bytecode.m_lhs)));
1246 }
1247 
1248 LLINT_SLOW_PATH_DECL(slow_path_jeq)
1249 {
1250     LLINT_BEGIN();
1251     auto bytecode = pc-&gt;as&lt;OpJeq&gt;();
1252     LLINT_BRANCH(JSValue::equal(exec, getOperand(exec, bytecode.m_lhs), getOperand(exec, bytecode.m_rhs)));
1253 }
1254 
1255 LLINT_SLOW_PATH_DECL(slow_path_jneq)
1256 {
1257     LLINT_BEGIN();
1258     auto bytecode = pc-&gt;as&lt;OpJneq&gt;();
1259     LLINT_BRANCH(!JSValue::equal(exec, getOperand(exec, bytecode.m_lhs), getOperand(exec, bytecode.m_rhs)));
1260 }
1261 
1262 LLINT_SLOW_PATH_DECL(slow_path_jstricteq)
1263 {
1264     LLINT_BEGIN();
1265     auto bytecode = pc-&gt;as&lt;OpJstricteq&gt;();
1266     LLINT_BRANCH(JSValue::strictEqual(exec, getOperand(exec, bytecode.m_lhs), getOperand(exec, bytecode.m_rhs)));
1267 }
1268 
1269 LLINT_SLOW_PATH_DECL(slow_path_jnstricteq)
1270 {
1271     LLINT_BEGIN();
1272     auto bytecode = pc-&gt;as&lt;OpJnstricteq&gt;();
1273     LLINT_BRANCH(!JSValue::strictEqual(exec, getOperand(exec, bytecode.m_lhs), getOperand(exec, bytecode.m_rhs)));
1274 }
1275 
1276 LLINT_SLOW_PATH_DECL(slow_path_switch_imm)
1277 {
1278     LLINT_BEGIN();
1279     auto bytecode = pc-&gt;as&lt;OpSwitchImm&gt;();
1280     JSValue scrutinee = getOperand(exec, bytecode.m_scrutinee);
1281     ASSERT(scrutinee.isDouble());
1282     double value = scrutinee.asDouble();
1283     int32_t intValue = static_cast&lt;int32_t&gt;(value);
1284     int defaultOffset = JUMP_OFFSET(bytecode.m_defaultOffset);
1285     if (value == intValue) {
1286         CodeBlock* codeBlock = exec-&gt;codeBlock();
1287         JUMP_TO(codeBlock-&gt;switchJumpTable(bytecode.m_tableIndex).offsetForValue(intValue, defaultOffset));
1288     } else
1289         JUMP_TO(defaultOffset);
1290     LLINT_END();
1291 }
1292 
1293 LLINT_SLOW_PATH_DECL(slow_path_switch_char)
1294 {
1295     LLINT_BEGIN();
1296     auto bytecode = pc-&gt;as&lt;OpSwitchChar&gt;();
1297     JSValue scrutinee = getOperand(exec, bytecode.m_scrutinee);
1298     ASSERT(scrutinee.isString());
1299     JSString* string = asString(scrutinee);
1300     ASSERT(string-&gt;length() == 1);
1301     int defaultOffset = JUMP_OFFSET(bytecode.m_defaultOffset);
1302     StringImpl* impl = string-&gt;value(exec).impl();
1303     CodeBlock* codeBlock = exec-&gt;codeBlock();
1304     JUMP_TO(codeBlock-&gt;switchJumpTable(bytecode.m_tableIndex).offsetForValue((*impl)[0], defaultOffset));
1305     LLINT_END();
1306 }
1307 
1308 LLINT_SLOW_PATH_DECL(slow_path_switch_string)
1309 {
1310     LLINT_BEGIN();
1311     auto bytecode = pc-&gt;as&lt;OpSwitchString&gt;();
1312     JSValue scrutinee = getOperand(exec, bytecode.m_scrutinee);
1313     int defaultOffset = JUMP_OFFSET(bytecode.m_defaultOffset);
1314     if (!scrutinee.isString())
1315         JUMP_TO(defaultOffset);
1316     else {
1317         StringImpl* scrutineeStringImpl = asString(scrutinee)-&gt;value(exec).impl();
1318 
1319         LLINT_CHECK_EXCEPTION();
1320 
1321         CodeBlock* codeBlock = exec-&gt;codeBlock();
1322 
1323         JUMP_TO(codeBlock-&gt;stringSwitchJumpTable(bytecode.m_tableIndex).offsetForValue(scrutineeStringImpl, defaultOffset));
1324     }
1325     LLINT_END();
1326 }
1327 
1328 LLINT_SLOW_PATH_DECL(slow_path_new_func)
1329 {
1330     LLINT_BEGIN();
1331     auto bytecode = pc-&gt;as&lt;OpNewFunc&gt;();
1332     CodeBlock* codeBlock = exec-&gt;codeBlock();
1333     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1334     slowPathLogF(&quot;Creating function!\n&quot;);
1335     LLINT_RETURN(JSFunction::create(vm, codeBlock-&gt;functionDecl(bytecode.m_functionDecl), scope));
1336 }
1337 
1338 LLINT_SLOW_PATH_DECL(slow_path_new_generator_func)
1339 {
1340     LLINT_BEGIN();
1341     auto bytecode = pc-&gt;as&lt;OpNewGeneratorFunc&gt;();
1342     CodeBlock* codeBlock = exec-&gt;codeBlock();
1343     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1344     slowPathLogF(&quot;Creating function!\n&quot;);
1345     LLINT_RETURN(JSGeneratorFunction::create(vm, codeBlock-&gt;functionDecl(bytecode.m_functionDecl), scope));
1346 }
1347 
1348 LLINT_SLOW_PATH_DECL(slow_path_new_async_func)
1349 {
1350     LLINT_BEGIN();
1351     auto bytecode = pc-&gt;as&lt;OpNewAsyncFunc&gt;();
1352     CodeBlock* codeBlock = exec-&gt;codeBlock();
1353     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1354     slowPathLogF(&quot;Creating async function!\n&quot;);
1355     LLINT_RETURN(JSAsyncFunction::create(vm, codeBlock-&gt;functionDecl(bytecode.m_functionDecl), scope));
1356 }
1357 
1358 LLINT_SLOW_PATH_DECL(slow_path_new_async_generator_func)
1359 {
1360     LLINT_BEGIN();
1361     auto bytecode = pc-&gt;as&lt;OpNewAsyncGeneratorFunc&gt;();
1362     CodeBlock* codeBlock = exec-&gt;codeBlock();
1363     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1364     slowPathLogF(&quot;Creating async generator function!\n&quot;);
1365     LLINT_RETURN(JSAsyncGeneratorFunction::create(vm, codeBlock-&gt;functionDecl(bytecode.m_functionDecl), scope));
1366 }
1367 
1368 LLINT_SLOW_PATH_DECL(slow_path_new_func_exp)
1369 {
1370     LLINT_BEGIN();
1371 
1372     auto bytecode = pc-&gt;as&lt;OpNewFuncExp&gt;();
1373     CodeBlock* codeBlock = exec-&gt;codeBlock();
1374     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1375     FunctionExecutable* executable = codeBlock-&gt;functionExpr(bytecode.m_functionDecl);
1376 
1377     LLINT_RETURN(JSFunction::create(vm, executable, scope));
1378 }
1379 
1380 LLINT_SLOW_PATH_DECL(slow_path_new_generator_func_exp)
1381 {
1382     LLINT_BEGIN();
1383 
1384     auto bytecode = pc-&gt;as&lt;OpNewGeneratorFuncExp&gt;();
1385     CodeBlock* codeBlock = exec-&gt;codeBlock();
1386     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1387     FunctionExecutable* executable = codeBlock-&gt;functionExpr(bytecode.m_functionDecl);
1388 
1389     LLINT_RETURN(JSGeneratorFunction::create(vm, executable, scope));
1390 }
1391 
1392 LLINT_SLOW_PATH_DECL(slow_path_new_async_func_exp)
1393 {
1394     LLINT_BEGIN();
1395 
1396     auto bytecode = pc-&gt;as&lt;OpNewAsyncFuncExp&gt;();
1397     CodeBlock* codeBlock = exec-&gt;codeBlock();
1398     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1399     FunctionExecutable* executable = codeBlock-&gt;functionExpr(bytecode.m_functionDecl);
1400 
1401     LLINT_RETURN(JSAsyncFunction::create(vm, executable, scope));
1402 }
1403 
1404 LLINT_SLOW_PATH_DECL(slow_path_new_async_generator_func_exp)
1405 {
1406     LLINT_BEGIN();
1407 
1408     auto bytecode = pc-&gt;as&lt;OpNewAsyncGeneratorFuncExp&gt;();
1409     CodeBlock* codeBlock = exec-&gt;codeBlock();
1410     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1411     FunctionExecutable* executable = codeBlock-&gt;functionExpr(bytecode.m_functionDecl);
1412 
1413     LLINT_RETURN(JSAsyncGeneratorFunction::create(vm, executable, scope));
1414 }
1415 
1416 LLINT_SLOW_PATH_DECL(slow_path_set_function_name)
1417 {
1418     LLINT_BEGIN();
1419     auto bytecode = pc-&gt;as&lt;OpSetFunctionName&gt;();
1420     JSFunction* func = jsCast&lt;JSFunction*&gt;(getNonConstantOperand(exec, bytecode.m_function));
1421     JSValue name = getOperand(exec, bytecode.m_name);
1422     func-&gt;setFunctionName(exec, name);
1423     LLINT_END();
1424 }
1425 
1426 static SlowPathReturnType handleHostCall(ExecState* execCallee, JSValue callee, CodeSpecializationKind kind)
1427 {
1428     slowPathLog(&quot;Performing host call.\n&quot;);
1429 
1430     ExecState* exec = execCallee-&gt;callerFrame();
1431     VM&amp; vm = exec-&gt;vm();
1432     auto throwScope = DECLARE_THROW_SCOPE(vm);
1433 
1434     execCallee-&gt;setCodeBlock(0);
1435     execCallee-&gt;clearReturnPC();
1436 
1437     if (kind == CodeForCall) {
1438         CallData callData;
1439         CallType callType = getCallData(vm, callee, callData);
1440 
1441         ASSERT(callType != CallType::JS);
1442 
1443         if (callType == CallType::Host) {
1444             NativeCallFrameTracer tracer(vm, execCallee);
1445             execCallee-&gt;setCallee(asObject(callee));
1446             vm.hostCallReturnValue = JSValue::decode(callData.native.function(execCallee));
1447             LLINT_CALL_RETURN(execCallee, execCallee, LLInt::getCodePtr(getHostCallReturnValue), CFunctionPtrTag);
1448         }
1449 
1450         slowPathLog(&quot;Call callee is not a function: &quot;, callee, &quot;\n&quot;);
1451 
1452         ASSERT(callType == CallType::None);
1453         LLINT_CALL_THROW(exec, createNotAFunctionError(exec, callee));
1454     }
1455 
1456     ASSERT(kind == CodeForConstruct);
1457 
1458     ConstructData constructData;
1459     ConstructType constructType = getConstructData(vm, callee, constructData);
1460 
1461     ASSERT(constructType != ConstructType::JS);
1462 
1463     if (constructType == ConstructType::Host) {
1464         NativeCallFrameTracer tracer(vm, execCallee);
1465         execCallee-&gt;setCallee(asObject(callee));
1466         vm.hostCallReturnValue = JSValue::decode(constructData.native.function(execCallee));
1467         LLINT_CALL_RETURN(execCallee, execCallee, LLInt::getCodePtr(getHostCallReturnValue), CFunctionPtrTag);
1468     }
1469 
1470     slowPathLog(&quot;Constructor callee is not a function: &quot;, callee, &quot;\n&quot;);
1471 
1472     ASSERT(constructType == ConstructType::None);
1473     LLINT_CALL_THROW(exec, createNotAConstructorError(exec, callee));
1474 }
1475 
1476 inline SlowPathReturnType setUpCall(ExecState* execCallee, CodeSpecializationKind kind, JSValue calleeAsValue, LLIntCallLinkInfo* callLinkInfo = nullptr)
1477 {
1478     ExecState* exec = execCallee-&gt;callerFrame();
1479     VM&amp; vm = exec-&gt;vm();
1480     auto throwScope = DECLARE_THROW_SCOPE(vm);
1481 
1482     slowPathLogF(&quot;Performing call with recorded PC = %p\n&quot;, exec-&gt;currentVPC());
1483 
1484     JSCell* calleeAsFunctionCell = getJSFunction(calleeAsValue);
1485     if (!calleeAsFunctionCell) {
1486         if (auto* internalFunction = jsDynamicCast&lt;InternalFunction*&gt;(vm, calleeAsValue)) {
1487             MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr = vm.getCTIInternalFunctionTrampolineFor(kind);
1488             ASSERT(!!codePtr);
1489 
1490             if (!LLINT_ALWAYS_ACCESS_SLOW &amp;&amp; callLinkInfo) {
1491                 CodeBlock* callerCodeBlock = exec-&gt;codeBlock();
1492 
1493                 ConcurrentJSLocker locker(callerCodeBlock-&gt;m_lock);
1494                 callLinkInfo-&gt;link(vm, callerCodeBlock, internalFunction, codePtr);
1495             }
1496 
1497             assertIsTaggedWith(codePtr.executableAddress(), JSEntryPtrTag);
1498             LLINT_CALL_RETURN(exec, execCallee, codePtr.executableAddress(), JSEntryPtrTag);
1499         }
1500         RELEASE_AND_RETURN(throwScope, handleHostCall(execCallee, calleeAsValue, kind));
1501     }
1502     JSFunction* callee = jsCast&lt;JSFunction*&gt;(calleeAsFunctionCell);
1503     JSScope* scope = callee-&gt;scopeUnchecked();
1504     ExecutableBase* executable = callee-&gt;executable();
1505 
1506     MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr;
1507     CodeBlock* codeBlock = 0;
1508     if (executable-&gt;isHostFunction())
1509         codePtr = executable-&gt;entrypointFor(kind, MustCheckArity);
1510     else {
1511         FunctionExecutable* functionExecutable = static_cast&lt;FunctionExecutable*&gt;(executable);
1512 
1513         if (!isCall(kind) &amp;&amp; functionExecutable-&gt;constructAbility() == ConstructAbility::CannotConstruct)
1514             LLINT_CALL_THROW(exec, createNotAConstructorError(exec, callee));
1515 
1516         CodeBlock** codeBlockSlot = execCallee-&gt;addressOfCodeBlock();
1517         Exception* error = functionExecutable-&gt;prepareForExecution&lt;FunctionExecutable&gt;(vm, callee, scope, kind, *codeBlockSlot);
1518         EXCEPTION_ASSERT(throwScope.exception() == error);
1519         if (UNLIKELY(error))
1520             LLINT_CALL_THROW(exec, error);
1521         codeBlock = *codeBlockSlot;
1522         ASSERT(codeBlock);
1523         ArityCheckMode arity;
1524         if (execCallee-&gt;argumentCountIncludingThis() &lt; static_cast&lt;size_t&gt;(codeBlock-&gt;numParameters()))
1525             arity = MustCheckArity;
1526         else
1527             arity = ArityCheckNotRequired;
1528         codePtr = functionExecutable-&gt;entrypointFor(kind, arity);
1529     }
1530 
1531     ASSERT(!!codePtr);
1532 
1533     if (!LLINT_ALWAYS_ACCESS_SLOW &amp;&amp; callLinkInfo) {
1534         CodeBlock* callerCodeBlock = exec-&gt;codeBlock();
1535 
1536         ConcurrentJSLocker locker(callerCodeBlock-&gt;m_lock);
1537         callLinkInfo-&gt;link(vm, callerCodeBlock, callee, codePtr);
1538         if (codeBlock)
1539             codeBlock-&gt;linkIncomingCall(exec, callLinkInfo);
1540     }
1541 
1542     assertIsTaggedWith(codePtr.executableAddress(), JSEntryPtrTag);
1543     LLINT_CALL_RETURN(exec, execCallee, codePtr.executableAddress(), JSEntryPtrTag);
1544 }
1545 
1546 template&lt;typename Op&gt;
1547 inline SlowPathReturnType genericCall(ExecState* exec, Op&amp;&amp; bytecode, CodeSpecializationKind kind)
1548 {
1549     // This needs to:
1550     // - Set up a call frame.
1551     // - Figure out what to call and compile it if necessary.
1552     // - If possible, link the call&#39;s inline cache.
1553     // - Return a tuple of machine code address to call and the new call frame.
1554 
1555     JSValue calleeAsValue = getOperand(exec, bytecode.m_callee);
1556 
1557     ExecState* execCallee = exec - bytecode.m_argv;
1558 
1559     execCallee-&gt;setArgumentCountIncludingThis(bytecode.m_argc);
1560     execCallee-&gt;uncheckedR(CallFrameSlot::callee) = calleeAsValue;
1561     execCallee-&gt;setCallerFrame(exec);
1562 
1563     auto&amp; metadata = bytecode.metadata(exec);
1564     return setUpCall(execCallee, kind, calleeAsValue, &amp;metadata.m_callLinkInfo);
1565 }
1566 
1567 LLINT_SLOW_PATH_DECL(slow_path_call)
1568 {
1569     LLINT_BEGIN_NO_SET_PC();
1570     RELEASE_AND_RETURN(throwScope, genericCall(exec, pc-&gt;as&lt;OpCall&gt;(), CodeForCall));
1571 }
1572 
1573 LLINT_SLOW_PATH_DECL(slow_path_tail_call)
1574 {
1575     LLINT_BEGIN_NO_SET_PC();
1576     RELEASE_AND_RETURN(throwScope, genericCall(exec, pc-&gt;as&lt;OpTailCall&gt;(), CodeForCall));
1577 }
1578 
1579 LLINT_SLOW_PATH_DECL(slow_path_construct)
1580 {
1581     LLINT_BEGIN_NO_SET_PC();
1582     RELEASE_AND_RETURN(throwScope, genericCall(exec, pc-&gt;as&lt;OpConstruct&gt;(), CodeForConstruct));
1583 }
1584 
1585 LLINT_SLOW_PATH_DECL(slow_path_size_frame_for_varargs)
1586 {
1587     LLINT_BEGIN();
1588     // This needs to:
1589     // - Set up a call frame while respecting the variable arguments.
1590 
1591     unsigned numUsedStackSlots;
1592     JSValue arguments;
1593     int firstVarArg;
1594     switch (pc-&gt;opcodeID()) {
1595     case op_call_varargs: {
1596         auto bytecode = pc-&gt;as&lt;OpCallVarargs&gt;();
1597         numUsedStackSlots = -bytecode.m_firstFree.offset();
1598         arguments = getOperand(exec, bytecode.m_arguments);
1599         firstVarArg = bytecode.m_firstVarArg;
1600         break;
1601     }
1602     case op_tail_call_varargs: {
1603         auto bytecode = pc-&gt;as&lt;OpTailCallVarargs&gt;();
1604         numUsedStackSlots = -bytecode.m_firstFree.offset();
1605         arguments = getOperand(exec, bytecode.m_arguments);
1606         firstVarArg = bytecode.m_firstVarArg;
1607         break;
1608     }
1609     case op_construct_varargs: {
1610         auto bytecode = pc-&gt;as&lt;OpConstructVarargs&gt;();
1611         numUsedStackSlots = -bytecode.m_firstFree.offset();
1612         arguments = getOperand(exec, bytecode.m_arguments);
1613         firstVarArg = bytecode.m_firstVarArg;
1614         break;
1615     }
1616     default:
1617         RELEASE_ASSERT_NOT_REACHED();
1618     }
1619     unsigned length = sizeFrameForVarargs(exec, vm, arguments, numUsedStackSlots, firstVarArg);
1620     LLINT_CALL_CHECK_EXCEPTION(exec, exec);
1621 
1622     ExecState* execCallee = calleeFrameForVarargs(exec, numUsedStackSlots, length + 1);
1623     vm.varargsLength = length;
1624     vm.newCallFrameReturnValue = execCallee;
1625 
1626     LLINT_RETURN_CALLEE_FRAME(execCallee);
1627 }
1628 
1629 LLINT_SLOW_PATH_DECL(slow_path_size_frame_for_forward_arguments)
1630 {
1631     LLINT_BEGIN();
1632     // This needs to:
1633     // - Set up a call frame with the same arguments as the current frame.
1634 
1635     auto bytecode = pc-&gt;as&lt;OpTailCallForwardArguments&gt;();
1636     unsigned numUsedStackSlots = -bytecode.m_firstFree.offset();
1637 
1638     unsigned arguments = sizeFrameForForwardArguments(exec, vm, numUsedStackSlots);
1639     LLINT_CALL_CHECK_EXCEPTION(exec, exec);
1640 
1641     ExecState* execCallee = calleeFrameForVarargs(exec, numUsedStackSlots, arguments + 1);
1642 
1643     vm.varargsLength = arguments;
1644     vm.newCallFrameReturnValue = execCallee;
1645 
1646     LLINT_RETURN_CALLEE_FRAME(execCallee);
1647 }
1648 
1649 enum class SetArgumentsWith {
1650     Object,
1651     CurrentArguments
1652 };
1653 
1654 template&lt;typename Op&gt;
1655 inline SlowPathReturnType varargsSetup(ExecState* exec, const Instruction* pc, CodeSpecializationKind kind, SetArgumentsWith set)
1656 {
1657     LLINT_BEGIN_NO_SET_PC();
1658     // This needs to:
1659     // - Figure out what to call and compile it if necessary.
1660     // - Return a tuple of machine code address to call and the new call frame.
1661 
1662     auto bytecode = pc-&gt;as&lt;Op&gt;();
1663     JSValue calleeAsValue = getOperand(exec, bytecode.m_callee);
1664 
1665     ExecState* execCallee = vm.newCallFrameReturnValue;
1666 
1667     if (set == SetArgumentsWith::Object) {
1668         setupVarargsFrameAndSetThis(exec, execCallee, getOperand(exec, bytecode.m_thisValue), getOperand(exec, bytecode.m_arguments), bytecode.m_firstVarArg, vm.varargsLength);
1669         LLINT_CALL_CHECK_EXCEPTION(exec, exec);
1670     } else
1671         setupForwardArgumentsFrameAndSetThis(exec, execCallee, getOperand(exec, bytecode.m_thisValue), vm.varargsLength);
1672 
1673     execCallee-&gt;setCallerFrame(exec);
1674     execCallee-&gt;uncheckedR(CallFrameSlot::callee) = calleeAsValue;
1675     exec-&gt;setCurrentVPC(pc);
1676 
1677     RELEASE_AND_RETURN(throwScope, setUpCall(execCallee, kind, calleeAsValue));
1678 }
1679 
1680 LLINT_SLOW_PATH_DECL(slow_path_call_varargs)
1681 {
1682     return varargsSetup&lt;OpCallVarargs&gt;(exec, pc, CodeForCall, SetArgumentsWith::Object);
1683 }
1684 
1685 LLINT_SLOW_PATH_DECL(slow_path_tail_call_varargs)
1686 {
1687     return varargsSetup&lt;OpTailCallVarargs&gt;(exec, pc, CodeForCall, SetArgumentsWith::Object);
1688 }
1689 
1690 LLINT_SLOW_PATH_DECL(slow_path_tail_call_forward_arguments)
1691 {
1692     return varargsSetup&lt;OpTailCallForwardArguments&gt;(exec, pc, CodeForCall, SetArgumentsWith::CurrentArguments);
1693 }
1694 
1695 LLINT_SLOW_PATH_DECL(slow_path_construct_varargs)
1696 {
1697     return varargsSetup&lt;OpConstructVarargs&gt;(exec, pc, CodeForConstruct, SetArgumentsWith::Object);
1698 }
1699 
1700 inline SlowPathReturnType commonCallEval(ExecState* exec, const Instruction* pc, MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; returnPoint)
1701 {
1702     LLINT_BEGIN_NO_SET_PC();
1703     auto bytecode = pc-&gt;as&lt;OpCallEval&gt;();
1704     JSValue calleeAsValue = getNonConstantOperand(exec, bytecode.m_callee);
1705 
1706     ExecState* execCallee = exec - bytecode.m_argv;
1707 
1708     execCallee-&gt;setArgumentCountIncludingThis(bytecode.m_argc);
1709     execCallee-&gt;setCallerFrame(exec);
1710     execCallee-&gt;uncheckedR(CallFrameSlot::callee) = calleeAsValue;
1711     execCallee-&gt;setReturnPC(returnPoint.executableAddress());
1712     execCallee-&gt;setCodeBlock(0);
1713     exec-&gt;setCurrentVPC(pc);
1714 
1715     if (!isHostFunction(calleeAsValue, globalFuncEval))
1716         RELEASE_AND_RETURN(throwScope, setUpCall(execCallee, CodeForCall, calleeAsValue));
1717 
1718     vm.hostCallReturnValue = eval(execCallee);
1719     LLINT_CALL_RETURN(exec, execCallee, LLInt::getCodePtr(getHostCallReturnValue), CFunctionPtrTag);
1720 }
1721 
1722 LLINT_SLOW_PATH_DECL(slow_path_call_eval)
1723 {
1724     return commonCallEval(exec, pc, LLInt::getCodePtr&lt;JSEntryPtrTag&gt;(llint_generic_return_point));
1725 }
1726 
1727 LLINT_SLOW_PATH_DECL(slow_path_call_eval_wide16)
1728 {
1729     return commonCallEval(exec, pc, LLInt::getWide16CodePtr&lt;JSEntryPtrTag&gt;(llint_generic_return_point));
1730 }
1731 
1732 LLINT_SLOW_PATH_DECL(slow_path_call_eval_wide32)
1733 {
1734     return commonCallEval(exec, pc, LLInt::getWide32CodePtr&lt;JSEntryPtrTag&gt;(llint_generic_return_point));
1735 }
1736 
1737 LLINT_SLOW_PATH_DECL(slow_path_strcat)
1738 {
1739     LLINT_BEGIN();
1740     auto bytecode = pc-&gt;as&lt;OpStrcat&gt;();
1741     LLINT_RETURN(jsStringFromRegisterArray(exec, &amp;exec-&gt;uncheckedR(bytecode.m_src), bytecode.m_count));
1742 }
1743 
1744 LLINT_SLOW_PATH_DECL(slow_path_to_primitive)
1745 {
1746     LLINT_BEGIN();
1747     auto bytecode = pc-&gt;as&lt;OpToPrimitive&gt;();
1748     LLINT_RETURN(getOperand(exec, bytecode.m_src).toPrimitive(exec));
1749 }
1750 
1751 LLINT_SLOW_PATH_DECL(slow_path_throw)
1752 {
1753     LLINT_BEGIN();
1754     auto bytecode = pc-&gt;as&lt;OpThrow&gt;();
1755     LLINT_THROW(getOperand(exec, bytecode.m_value));
1756 }
1757 
1758 LLINT_SLOW_PATH_DECL(slow_path_handle_traps)
1759 {
1760     LLINT_BEGIN_NO_SET_PC();
1761     ASSERT(vm.needTrapHandling());
1762     vm.handleTraps(exec);
1763     UNUSED_PARAM(pc);
1764     LLINT_RETURN_TWO(throwScope.exception(), exec);
1765 }
1766 
1767 LLINT_SLOW_PATH_DECL(slow_path_debug)
1768 {
1769     LLINT_BEGIN();
1770     auto bytecode = pc-&gt;as&lt;OpDebug&gt;();
1771     vm.interpreter-&gt;debug(exec, bytecode.m_debugHookType);
1772 
1773     LLINT_END();
1774 }
1775 
1776 LLINT_SLOW_PATH_DECL(slow_path_handle_exception)
1777 {
1778     LLINT_BEGIN_NO_SET_PC();
1779     UNUSED_PARAM(throwScope);
1780     genericUnwind(vm, exec);
1781     LLINT_END_IMPL();
1782 }
1783 
1784 LLINT_SLOW_PATH_DECL(slow_path_get_from_scope)
1785 {
1786     LLINT_BEGIN();
1787     auto bytecode = pc-&gt;as&lt;OpGetFromScope&gt;();
1788     auto&amp; metadata = bytecode.metadata(exec);
1789     const Identifier&amp; ident = exec-&gt;codeBlock()-&gt;identifier(bytecode.m_var);
1790     JSObject* scope = jsCast&lt;JSObject*&gt;(getNonConstantOperand(exec, bytecode.m_scope));
1791 
1792     // ModuleVar is always converted to ClosureVar for get_from_scope.
1793     ASSERT(metadata.m_getPutInfo.resolveType() != ModuleVar);
1794 
1795     LLINT_RETURN(scope-&gt;getPropertySlot(exec, ident, [&amp;] (bool found, PropertySlot&amp; slot) -&gt; JSValue {
1796         if (!found) {
1797             if (metadata.m_getPutInfo.resolveMode() == ThrowIfNotFound)
1798                 return throwException(exec, throwScope, createUndefinedVariableError(exec, ident));
1799             return jsUndefined();
1800         }
1801 
1802         JSValue result = JSValue();
1803         if (scope-&gt;isGlobalLexicalEnvironment()) {
1804             // When we can&#39;t statically prove we need a TDZ check, we must perform the check on the slow path.
1805             result = slot.getValue(exec, ident);
1806             if (result == jsTDZValue())
1807                 return throwException(exec, throwScope, createTDZError(exec));
1808         }
1809 
1810         CommonSlowPaths::tryCacheGetFromScopeGlobal(exec, vm, bytecode, scope, slot, ident);
1811 
1812         if (!result)
1813             return slot.getValue(exec, ident);
1814         return result;
1815     }));
1816 }
1817 
1818 LLINT_SLOW_PATH_DECL(slow_path_put_to_scope)
1819 {
1820     LLINT_BEGIN();
1821 
1822     auto bytecode = pc-&gt;as&lt;OpPutToScope&gt;();
1823     auto&amp; metadata = bytecode.metadata(exec);
1824     CodeBlock* codeBlock = exec-&gt;codeBlock();
1825     const Identifier&amp; ident = codeBlock-&gt;identifier(bytecode.m_var);
1826     JSObject* scope = jsCast&lt;JSObject*&gt;(getNonConstantOperand(exec, bytecode.m_scope));
1827     JSValue value = getOperand(exec, bytecode.m_value);
1828     if (metadata.m_getPutInfo.resolveType() == LocalClosureVar) {
1829         JSLexicalEnvironment* environment = jsCast&lt;JSLexicalEnvironment*&gt;(scope);
1830         environment-&gt;variableAt(ScopeOffset(metadata.m_operand)).set(vm, environment, value);
1831 
1832         // Have to do this *after* the write, because if this puts the set into IsWatched, then we need
1833         // to have already changed the value of the variable. Otherwise we might watch and constant-fold
1834         // to the Undefined value from before the assignment.
1835         if (metadata.m_watchpointSet)
1836             metadata.m_watchpointSet-&gt;touch(vm, &quot;Executed op_put_scope&lt;LocalClosureVar&gt;&quot;);
1837         LLINT_END();
1838     }
1839 
1840     bool hasProperty = scope-&gt;hasProperty(exec, ident);
1841     LLINT_CHECK_EXCEPTION();
1842     if (hasProperty
1843         &amp;&amp; scope-&gt;isGlobalLexicalEnvironment()
1844         &amp;&amp; !isInitialization(metadata.m_getPutInfo.initializationMode())) {
1845         // When we can&#39;t statically prove we need a TDZ check, we must perform the check on the slow path.
1846         PropertySlot slot(scope, PropertySlot::InternalMethodType::Get);
1847         JSGlobalLexicalEnvironment::getOwnPropertySlot(scope, exec, ident, slot);
1848         if (slot.getValue(exec, ident) == jsTDZValue())
1849             LLINT_THROW(createTDZError(exec));
1850     }
1851 
1852     if (metadata.m_getPutInfo.resolveMode() == ThrowIfNotFound &amp;&amp; !hasProperty)
1853         LLINT_THROW(createUndefinedVariableError(exec, ident));
1854 
1855     PutPropertySlot slot(scope, codeBlock-&gt;isStrictMode(), PutPropertySlot::UnknownContext, isInitialization(metadata.m_getPutInfo.initializationMode()));
1856     scope-&gt;methodTable(vm)-&gt;put(scope, exec, ident, value, slot);
1857 
1858     CommonSlowPaths::tryCachePutToScopeGlobal(exec, codeBlock, bytecode, scope, slot, ident);
1859 
1860     LLINT_END();
1861 }
1862 
1863 LLINT_SLOW_PATH_DECL(slow_path_check_if_exception_is_uncatchable_and_notify_profiler)
1864 {
1865     LLINT_BEGIN();
1866     RELEASE_ASSERT(!!throwScope.exception());
1867 
1868     if (isTerminatedExecutionException(vm, throwScope.exception()))
1869         LLINT_RETURN_TWO(pc, bitwise_cast&lt;void*&gt;(static_cast&lt;uintptr_t&gt;(1)));
1870     LLINT_RETURN_TWO(pc, 0);
1871 }
1872 
1873 LLINT_SLOW_PATH_DECL(slow_path_log_shadow_chicken_prologue)
1874 {
1875     LLINT_BEGIN();
1876 
1877     auto bytecode = pc-&gt;as&lt;OpLogShadowChickenPrologue&gt;();
1878     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1879     ShadowChicken* shadowChicken = vm.shadowChicken();
1880     RELEASE_ASSERT(shadowChicken);
1881     shadowChicken-&gt;log(vm, exec, ShadowChicken::Packet::prologue(exec-&gt;jsCallee(), exec, exec-&gt;callerFrame(), scope));
1882 
1883     LLINT_END();
1884 }
1885 
1886 LLINT_SLOW_PATH_DECL(slow_path_log_shadow_chicken_tail)
1887 {
1888     LLINT_BEGIN();
1889 
1890     auto bytecode = pc-&gt;as&lt;OpLogShadowChickenTail&gt;();
1891     JSValue thisValue = getNonConstantOperand(exec, bytecode.m_thisValue);
1892     JSScope* scope = exec-&gt;uncheckedR(bytecode.m_scope).Register::scope();
1893 
1894 #if USE(JSVALUE64)
1895     CallSiteIndex callSiteIndex(exec-&gt;codeBlock()-&gt;bytecodeOffset(pc));
1896 #else
1897     CallSiteIndex callSiteIndex(pc);
1898 #endif
1899     ShadowChicken* shadowChicken = vm.shadowChicken();
1900     RELEASE_ASSERT(shadowChicken);
1901     shadowChicken-&gt;log(vm, exec, ShadowChicken::Packet::tail(exec, thisValue, scope, exec-&gt;codeBlock(), callSiteIndex));
1902 
1903     LLINT_END();
1904 }
1905 
1906 LLINT_SLOW_PATH_DECL(slow_path_profile_catch)
1907 {
1908     LLINT_BEGIN();
1909 
1910     exec-&gt;codeBlock()-&gt;ensureCatchLivenessIsComputedForBytecodeOffset(exec-&gt;bytecodeOffset());
1911 
1912     auto bytecode = pc-&gt;as&lt;OpCatch&gt;();
1913     auto&amp; metadata = bytecode.metadata(exec);
1914     metadata.m_buffer-&gt;forEach([&amp;] (ValueProfileAndOperand&amp; profile) {
1915         profile.m_buckets[0] = JSValue::encode(exec-&gt;uncheckedR(profile.m_operand).jsValue());
1916     });
1917 
1918     LLINT_END();
1919 }
1920 
1921 LLINT_SLOW_PATH_DECL(slow_path_super_sampler_begin)
1922 {
1923     // FIXME: It seems like we should be able to do this in asm but llint doesn&#39;t seem to like global variables.
1924     // See: https://bugs.webkit.org/show_bug.cgi?id=179438
1925     UNUSED_PARAM(exec);
1926     g_superSamplerCount++;
1927     LLINT_END_IMPL();
1928 }
1929 
1930 LLINT_SLOW_PATH_DECL(slow_path_super_sampler_end)
1931 {
1932     // FIXME: It seems like we should be able to do this in asm but llint doesn&#39;t seem to like global variables.
1933     // See: https://bugs.webkit.org/show_bug.cgi?id=179438
1934     UNUSED_PARAM(exec);
1935     g_superSamplerCount--;
1936     LLINT_END_IMPL();
1937 }
1938 
1939 LLINT_SLOW_PATH_DECL(slow_path_out_of_line_jump_target)
1940 {
1941     CodeBlock* codeBlock = exec-&gt;codeBlock();
1942     pc = codeBlock-&gt;outOfLineJumpTarget(pc);
1943     LLINT_END_IMPL();
1944 }
1945 
1946 extern &quot;C&quot; SlowPathReturnType llint_throw_stack_overflow_error(VM* vm, ProtoCallFrame* protoFrame)
1947 {
1948     ExecState* exec = vm-&gt;topCallFrame;
1949     auto scope = DECLARE_THROW_SCOPE(*vm);
1950 
1951     if (!exec)
1952         exec = protoFrame-&gt;callee()-&gt;globalObject(*vm)-&gt;globalExec();
1953     throwStackOverflowError(exec, scope);
1954     return encodeResult(0, 0);
1955 }
1956 
1957 #if ENABLE(C_LOOP)
1958 extern &quot;C&quot; SlowPathReturnType llint_stack_check_at_vm_entry(VM* vm, Register* newTopOfStack)
1959 {
1960     bool success = vm-&gt;ensureStackCapacityFor(newTopOfStack);
1961     return encodeResult(reinterpret_cast&lt;void*&gt;(success), 0);
1962 }
1963 #endif
1964 
1965 extern &quot;C&quot; void llint_write_barrier_slow(ExecState* exec, JSCell* cell)
1966 {
1967     VM&amp; vm = exec-&gt;vm();
1968     vm.heap.writeBarrier(cell);
1969 }
1970 
1971 extern &quot;C&quot; NO_RETURN_DUE_TO_CRASH void llint_crash()
1972 {
1973     CRASH();
1974 }
1975 
1976 } } // namespace JSC::LLInt
    </pre>
  </body>
</html>