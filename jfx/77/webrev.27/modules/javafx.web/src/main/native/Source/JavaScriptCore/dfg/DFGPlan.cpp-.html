<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGPlan.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2013-2018 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;DFGPlan.h&quot;
 28 
 29 #if ENABLE(DFG_JIT)
 30 
 31 #include &quot;DFGArgumentsEliminationPhase.h&quot;
 32 #include &quot;DFGBackwardsPropagationPhase.h&quot;
 33 #include &quot;DFGByteCodeParser.h&quot;
 34 #include &quot;DFGCFAPhase.h&quot;
 35 #include &quot;DFGCFGSimplificationPhase.h&quot;
 36 #include &quot;DFGCPSRethreadingPhase.h&quot;
 37 #include &quot;DFGCSEPhase.h&quot;
 38 #include &quot;DFGCleanUpPhase.h&quot;
 39 #include &quot;DFGConstantFoldingPhase.h&quot;
 40 #include &quot;DFGConstantHoistingPhase.h&quot;
 41 #include &quot;DFGCriticalEdgeBreakingPhase.h&quot;
 42 #include &quot;DFGDCEPhase.h&quot;
 43 #include &quot;DFGFailedFinalizer.h&quot;
 44 #include &quot;DFGFixupPhase.h&quot;
 45 #include &quot;DFGGraphSafepoint.h&quot;
 46 #include &quot;DFGIntegerCheckCombiningPhase.h&quot;
 47 #include &quot;DFGIntegerRangeOptimizationPhase.h&quot;
 48 #include &quot;DFGInvalidationPointInjectionPhase.h&quot;
 49 #include &quot;DFGJITCompiler.h&quot;
 50 #include &quot;DFGLICMPhase.h&quot;
 51 #include &quot;DFGLiveCatchVariablePreservationPhase.h&quot;
 52 #include &quot;DFGLivenessAnalysisPhase.h&quot;
 53 #include &quot;DFGLoopPreHeaderCreationPhase.h&quot;
 54 #include &quot;DFGMaximalFlushInsertionPhase.h&quot;
 55 #include &quot;DFGMovHintRemovalPhase.h&quot;
 56 #include &quot;DFGOSRAvailabilityAnalysisPhase.h&quot;
 57 #include &quot;DFGOSREntrypointCreationPhase.h&quot;
 58 #include &quot;DFGObjectAllocationSinkingPhase.h&quot;
 59 #include &quot;DFGPhantomInsertionPhase.h&quot;
 60 #include &quot;DFGPredictionInjectionPhase.h&quot;
 61 #include &quot;DFGPredictionPropagationPhase.h&quot;
 62 #include &quot;DFGPutStackSinkingPhase.h&quot;
 63 #include &quot;DFGSSAConversionPhase.h&quot;
 64 #include &quot;DFGSSALoweringPhase.h&quot;
 65 #include &quot;DFGStackLayoutPhase.h&quot;
 66 #include &quot;DFGStaticExecutionCountEstimationPhase.h&quot;
 67 #include &quot;DFGStoreBarrierClusteringPhase.h&quot;
 68 #include &quot;DFGStoreBarrierInsertionPhase.h&quot;
 69 #include &quot;DFGStrengthReductionPhase.h&quot;
 70 #include &quot;DFGTierUpCheckInjectionPhase.h&quot;
 71 #include &quot;DFGTypeCheckHoistingPhase.h&quot;
 72 #include &quot;DFGUnificationPhase.h&quot;
 73 #include &quot;DFGValidate.h&quot;
 74 #include &quot;DFGVarargsForwardingPhase.h&quot;
 75 #include &quot;DFGVirtualRegisterAllocationPhase.h&quot;
 76 #include &quot;DFGWatchpointCollectionPhase.h&quot;
 77 #include &quot;JSCInlines.h&quot;
 78 #include &quot;OperandsInlines.h&quot;
 79 #include &quot;ProfilerDatabase.h&quot;
 80 #include &quot;TrackedReferences.h&quot;
 81 #include &quot;VMInlines.h&quot;
 82 
 83 #if ENABLE(FTL_JIT)
 84 #include &quot;FTLCapabilities.h&quot;
 85 #include &quot;FTLCompile.h&quot;
 86 #include &quot;FTLFail.h&quot;
 87 #include &quot;FTLLink.h&quot;
 88 #include &quot;FTLLowerDFGToB3.h&quot;
 89 #include &quot;FTLState.h&quot;
 90 #endif
 91 
 92 namespace JSC {
 93 
 94 extern Seconds totalDFGCompileTime;
 95 extern Seconds totalFTLCompileTime;
 96 extern Seconds totalFTLDFGCompileTime;
 97 extern Seconds totalFTLB3CompileTime;
 98 
 99 }
100 
101 namespace JSC { namespace DFG {
102 
103 namespace {
104 
105 void dumpAndVerifyGraph(Graph&amp; graph, const char* text, bool forceDump = false)
106 {
107     GraphDumpMode modeForFinalValidate = DumpGraph;
108     if (verboseCompilationEnabled(graph.m_plan.mode()) || forceDump) {
109         dataLog(text, &quot;\n&quot;);
110         graph.dump();
111         modeForFinalValidate = DontDumpGraph;
112     }
113     if (validationEnabled())
114         validate(graph, modeForFinalValidate);
115 }
116 
117 Profiler::CompilationKind profilerCompilationKindForMode(CompilationMode mode)
118 {
119     switch (mode) {
120     case InvalidCompilationMode:
121         RELEASE_ASSERT_NOT_REACHED();
122         return Profiler::DFG;
123     case DFGMode:
124         return Profiler::DFG;
125     case FTLMode:
126         return Profiler::FTL;
127     case FTLForOSREntryMode:
128         return Profiler::FTLForOSREntry;
129     }
130     RELEASE_ASSERT_NOT_REACHED();
131     return Profiler::DFG;
132 }
133 
134 } // anonymous namespace
135 
136 Plan::Plan(CodeBlock* passedCodeBlock, CodeBlock* profiledDFGCodeBlock,
137     CompilationMode mode, unsigned osrEntryBytecodeIndex,
138     const Operands&lt;Optional&lt;JSValue&gt;&gt;&amp; mustHandleValues)
139     : m_vm(passedCodeBlock-&gt;vm())
140     , m_codeBlock(passedCodeBlock)
141     , m_profiledDFGCodeBlock(profiledDFGCodeBlock)
142     , m_mode(mode)
143     , m_osrEntryBytecodeIndex(osrEntryBytecodeIndex)
144     , m_mustHandleValues(mustHandleValues)
145     , m_compilation(UNLIKELY(m_vm-&gt;m_perBytecodeProfiler) ? adoptRef(new Profiler::Compilation(m_vm-&gt;m_perBytecodeProfiler-&gt;ensureBytecodesFor(m_codeBlock), profilerCompilationKindForMode(mode))) : nullptr)
146     , m_inlineCallFrames(adoptRef(new InlineCallFrameSet()))
147     , m_identifiers(m_codeBlock)
148     , m_weakReferences(m_codeBlock)
149     , m_stage(Preparing)
150 {
151     RELEASE_ASSERT(m_codeBlock-&gt;alternative()-&gt;jitCode());
152 }
153 
154 Plan::~Plan()
155 {
156 }
157 
158 bool Plan::computeCompileTimes() const
159 {
160     return reportCompileTimes()
161         || Options::reportTotalCompileTimes()
162         || (m_vm &amp;&amp; m_vm-&gt;m_perBytecodeProfiler);
163 }
164 
165 bool Plan::reportCompileTimes() const
166 {
167     return Options::reportCompileTimes()
168         || Options::reportDFGCompileTimes()
169         || (Options::reportFTLCompileTimes() &amp;&amp; isFTL());
170 }
171 
172 void Plan::compileInThread(ThreadData* threadData)
173 {
174     m_threadData = threadData;
175 
176     MonotonicTime before { };
177     CString codeBlockName;
178     if (UNLIKELY(computeCompileTimes()))
179         before = MonotonicTime::now();
180     if (UNLIKELY(reportCompileTimes()))
181         codeBlockName = toCString(*m_codeBlock);
182 
183     CompilationScope compilationScope;
184 
185     if (logCompilationChanges(m_mode) || Options::logPhaseTimes())
186         dataLog(&quot;DFG(Plan) compiling &quot;, *m_codeBlock, &quot; with &quot;, m_mode, &quot;, number of instructions = &quot;, m_codeBlock-&gt;instructionCount(), &quot;\n&quot;);
187 
188     CompilationPath path = compileInThreadImpl();
189 
190     RELEASE_ASSERT(path == CancelPath || m_finalizer);
191     RELEASE_ASSERT((path == CancelPath) == (m_stage == Cancelled));
192 
193     MonotonicTime after { };
194     if (UNLIKELY(computeCompileTimes())) {
195         after = MonotonicTime::now();
196 
197         if (Options::reportTotalCompileTimes()) {
198             if (isFTL()) {
199                 totalFTLCompileTime += after - before;
200                 totalFTLDFGCompileTime += m_timeBeforeFTL - before;
201                 totalFTLB3CompileTime += after - m_timeBeforeFTL;
202             } else
203                 totalDFGCompileTime += after - before;
204         }
205     }
206     const char* pathName = nullptr;
207     switch (path) {
208     case FailPath:
209         pathName = &quot;N/A (fail)&quot;;
210         break;
211     case DFGPath:
212         pathName = &quot;DFG&quot;;
213         break;
214     case FTLPath:
215         pathName = &quot;FTL&quot;;
216         break;
217     case CancelPath:
218         pathName = &quot;Cancelled&quot;;
219         break;
220     default:
221         RELEASE_ASSERT_NOT_REACHED();
222         break;
223     }
224     if (m_codeBlock) { // m_codeBlock will be null if the compilation was cancelled.
225         if (path == FTLPath)
226             CODEBLOCK_LOG_EVENT(m_codeBlock, &quot;ftlCompile&quot;, (&quot;took &quot;, (after - before).milliseconds(), &quot; ms (DFG: &quot;, (m_timeBeforeFTL - before).milliseconds(), &quot;, B3: &quot;, (after - m_timeBeforeFTL).milliseconds(), &quot;) with &quot;, pathName));
227         else
228             CODEBLOCK_LOG_EVENT(m_codeBlock, &quot;dfgCompile&quot;, (&quot;took &quot;, (after - before).milliseconds(), &quot; ms with &quot;, pathName));
229     }
230     if (UNLIKELY(reportCompileTimes())) {
231         dataLog(&quot;Optimized &quot;, codeBlockName, &quot; using &quot;, m_mode, &quot; with &quot;, pathName, &quot; into &quot;, m_finalizer ? m_finalizer-&gt;codeSize() : 0, &quot; bytes in &quot;, (after - before).milliseconds(), &quot; ms&quot;);
232         if (path == FTLPath)
233             dataLog(&quot; (DFG: &quot;, (m_timeBeforeFTL - before).milliseconds(), &quot;, B3: &quot;, (after - m_timeBeforeFTL).milliseconds(), &quot;)&quot;);
234         dataLog(&quot;.\n&quot;);
235     }
236 }
237 
238 Plan::CompilationPath Plan::compileInThreadImpl()
239 {
240     cleanMustHandleValuesIfNecessary();
241 
242     if (verboseCompilationEnabled(m_mode) &amp;&amp; m_osrEntryBytecodeIndex != UINT_MAX) {
243         dataLog(&quot;\n&quot;);
244         dataLog(&quot;Compiler must handle OSR entry from bc#&quot;, m_osrEntryBytecodeIndex, &quot; with values: &quot;, m_mustHandleValues, &quot;\n&quot;);
245         dataLog(&quot;\n&quot;);
246     }
247 
248     Graph dfg(*m_vm, *this);
249     parse(dfg);
250 
251     m_codeBlock-&gt;setCalleeSaveRegisters(RegisterSet::dfgCalleeSaveRegisters());
252 
253     bool changed = false;
254 
255 #define RUN_PHASE(phase)                                         \
256     do {                                                         \
257         if (Options::safepointBeforeEachPhase()) {               \
258             Safepoint::Result safepointResult;                   \
259             {                                                    \
260                 GraphSafepoint safepoint(dfg, safepointResult);  \
261             }                                                    \
262             if (safepointResult.didGetCancelled())               \
263                 return CancelPath;                               \
264         }                                                        \
265         changed |= phase(dfg);                                   \
266     } while (false);                                             \
267 
268 
269     // By this point the DFG bytecode parser will have potentially mutated various tables
270     // in the CodeBlock. This is a good time to perform an early shrink, which is more
271     // powerful than a late one. It&#39;s safe to do so because we haven&#39;t generated any code
272     // that references any of the tables directly, yet.
273     m_codeBlock-&gt;shrinkToFit(CodeBlock::EarlyShrink);
274 
275     if (validationEnabled())
276         validate(dfg);
277 
278     if (Options::dumpGraphAfterParsing()) {
279         dataLog(&quot;Graph after parsing:\n&quot;);
280         dfg.dump();
281     }
282 
283     RUN_PHASE(performLiveCatchVariablePreservationPhase);
284 
285     if (Options::useMaximalFlushInsertionPhase())
286         RUN_PHASE(performMaximalFlushInsertion);
287 
288     RUN_PHASE(performCPSRethreading);
289     RUN_PHASE(performUnification);
290     RUN_PHASE(performPredictionInjection);
291 
292     RUN_PHASE(performStaticExecutionCountEstimation);
293 
294     if (m_mode == FTLForOSREntryMode) {
295         bool result = performOSREntrypointCreation(dfg);
296         if (!result) {
297             m_finalizer = std::make_unique&lt;FailedFinalizer&gt;(*this);
298             return FailPath;
299         }
300         RUN_PHASE(performCPSRethreading);
301     }
302 
303     if (validationEnabled())
304         validate(dfg);
305 
306     RUN_PHASE(performBackwardsPropagation);
307     RUN_PHASE(performPredictionPropagation);
308     RUN_PHASE(performFixup);
309     RUN_PHASE(performInvalidationPointInjection);
310     RUN_PHASE(performTypeCheckHoisting);
311 
312     dfg.m_fixpointState = FixpointNotConverged;
313 
314     // For now we&#39;re back to avoiding a fixpoint. Note that we&#39;ve ping-ponged on this decision
315     // many times. For maximum throughput, it&#39;s best to fixpoint. But the throughput benefit is
316     // small and not likely to show up in FTL anyway. On the other hand, not fixpointing means
317     // that the compiler compiles more quickly. We want the third tier to compile quickly, which
318     // not fixpointing accomplishes; and the fourth tier shouldn&#39;t need a fixpoint.
319     if (validationEnabled())
320         validate(dfg);
321 
322     RUN_PHASE(performStrengthReduction);
323     RUN_PHASE(performCPSRethreading);
324     RUN_PHASE(performCFA);
325     RUN_PHASE(performConstantFolding);
326     changed = false;
327     RUN_PHASE(performCFGSimplification);
328     RUN_PHASE(performLocalCSE);
329 
330     if (validationEnabled())
331         validate(dfg);
332 
333     RUN_PHASE(performCPSRethreading);
334     if (!isFTL()) {
335         // Only run this if we&#39;re not FTLing, because currently for a LoadVarargs that is forwardable and
336         // in a non-varargs inlined call frame, this will generate ForwardVarargs while the FTL
337         // ArgumentsEliminationPhase will create a sequence of GetStack+PutStacks. The GetStack+PutStack
338         // sequence then gets sunk, eliminating anything that looks like an escape for subsequent phases,
339         // while the ForwardVarargs doesn&#39;t get simplified until later (or not at all) and looks like an
340         // escape for all of the arguments. This then disables object allocation sinking.
341         //
342         // So, for now, we just disable this phase for the FTL.
343         //
344         // If we wanted to enable it, we&#39;d have to do any of the following:
345         // - Enable ForwardVarargs-&gt;GetStack+PutStack strength reduction, and have that run before
346         //   PutStack sinking and object allocation sinking.
347         // - Make VarargsForwarding emit a GetLocal+SetLocal sequence, that we can later turn into
348         //   GetStack+PutStack.
349         //
350         // But, it&#39;s not super valuable to enable those optimizations, since the FTL
351         // ArgumentsEliminationPhase does everything that this phase does, and it doesn&#39;t introduce this
352         // pathology.
353 
354         RUN_PHASE(performVarargsForwarding); // Do this after CFG simplification and CPS rethreading.
355     }
356     if (changed) {
357         RUN_PHASE(performCFA);
358         RUN_PHASE(performConstantFolding);
359     }
360 
361     // If we&#39;re doing validation, then run some analyses, to give them an opportunity
362     // to self-validate. Now is as good a time as any to do this.
363     if (validationEnabled()) {
364         dfg.ensureCPSDominators();
365         dfg.ensureCPSNaturalLoops();
366     }
367 
368     switch (m_mode) {
369     case DFGMode: {
370         dfg.m_fixpointState = FixpointConverged;
371 
372         RUN_PHASE(performTierUpCheckInjection);
373 
374         RUN_PHASE(performFastStoreBarrierInsertion);
375         RUN_PHASE(performStoreBarrierClustering);
376         RUN_PHASE(performCleanUp);
377         RUN_PHASE(performCPSRethreading);
378         RUN_PHASE(performDCE);
379         RUN_PHASE(performPhantomInsertion);
380         RUN_PHASE(performStackLayout);
381         RUN_PHASE(performVirtualRegisterAllocation);
382         RUN_PHASE(performWatchpointCollection);
383         dumpAndVerifyGraph(dfg, &quot;Graph after optimization:&quot;);
384 
385         JITCompiler dataFlowJIT(dfg);
386         if (m_codeBlock-&gt;codeType() == FunctionCode)
387             dataFlowJIT.compileFunction();
388         else
389             dataFlowJIT.compile();
390 
391         return DFGPath;
392     }
393 
394     case FTLMode:
395     case FTLForOSREntryMode: {
396 #if ENABLE(FTL_JIT)
397         if (FTL::canCompile(dfg) == FTL::CannotCompile) {
398             m_finalizer = std::make_unique&lt;FailedFinalizer&gt;(*this);
399             return FailPath;
400         }
401 
402         RUN_PHASE(performCleanUp); // Reduce the graph size a bit.
403         RUN_PHASE(performCriticalEdgeBreaking);
404         if (Options::createPreHeaders())
405             RUN_PHASE(performLoopPreHeaderCreation);
406         RUN_PHASE(performCPSRethreading);
407         RUN_PHASE(performSSAConversion);
408         RUN_PHASE(performSSALowering);
409 
410         // Ideally, these would be run to fixpoint with the object allocation sinking phase.
411         RUN_PHASE(performArgumentsElimination);
412         if (Options::usePutStackSinking())
413             RUN_PHASE(performPutStackSinking);
414 
415         RUN_PHASE(performConstantHoisting);
416         RUN_PHASE(performGlobalCSE);
417         RUN_PHASE(performLivenessAnalysis);
418         RUN_PHASE(performCFA);
419         RUN_PHASE(performConstantFolding);
420         RUN_PHASE(performCleanUp); // Reduce the graph size a lot.
421         changed = false;
422         RUN_PHASE(performStrengthReduction);
423         if (Options::useObjectAllocationSinking()) {
424             RUN_PHASE(performCriticalEdgeBreaking);
425             RUN_PHASE(performObjectAllocationSinking);
426         }
427         if (changed) {
428             // State-at-tail and state-at-head will be invalid if we did strength reduction since
429             // it might increase live ranges.
430             RUN_PHASE(performLivenessAnalysis);
431             RUN_PHASE(performCFA);
432             RUN_PHASE(performConstantFolding);
433         }
434 
435         // Currently, this relies on pre-headers still being valid. That precludes running CFG
436         // simplification before it, unless we re-created the pre-headers. There wouldn&#39;t be anything
437         // wrong with running LICM earlier, if we wanted to put other CFG transforms above this point.
438         // Alternatively, we could run loop pre-header creation after SSA conversion - but if we did that
439         // then we&#39;d need to do some simple SSA fix-up.
440         RUN_PHASE(performLivenessAnalysis);
441         RUN_PHASE(performCFA);
442         RUN_PHASE(performLICM);
443 
444         // FIXME: Currently: IntegerRangeOptimization *must* be run after LICM.
445         //
446         // IntegerRangeOptimization makes changes on nodes based on preceding blocks
447         // and nodes. LICM moves nodes which can invalidates assumptions used
448         // by IntegerRangeOptimization.
449         //
450         // Ideally, the dependencies should be explicit. See https://bugs.webkit.org/show_bug.cgi?id=157534.
451         RUN_PHASE(performLivenessAnalysis);
452         RUN_PHASE(performIntegerRangeOptimization);
453 
454         RUN_PHASE(performCleanUp);
455         RUN_PHASE(performIntegerCheckCombining);
456         RUN_PHASE(performGlobalCSE);
457 
458         // At this point we&#39;re not allowed to do any further code motion because our reasoning
459         // about code motion assumes that it&#39;s OK to insert GC points in random places.
460         dfg.m_fixpointState = FixpointConverged;
461 
462         RUN_PHASE(performLivenessAnalysis);
463         RUN_PHASE(performCFA);
464         RUN_PHASE(performGlobalStoreBarrierInsertion);
465         RUN_PHASE(performStoreBarrierClustering);
466         if (Options::useMovHintRemoval())
467             RUN_PHASE(performMovHintRemoval);
468         RUN_PHASE(performCleanUp);
469         RUN_PHASE(performDCE); // We rely on this to kill dead code that won&#39;t be recognized as dead by B3.
470         RUN_PHASE(performStackLayout);
471         RUN_PHASE(performLivenessAnalysis);
472         RUN_PHASE(performOSRAvailabilityAnalysis);
473         RUN_PHASE(performWatchpointCollection);
474 
475         if (FTL::canCompile(dfg) == FTL::CannotCompile) {
476             m_finalizer = std::make_unique&lt;FailedFinalizer&gt;(*this);
477             return FailPath;
478         }
479 
480         dumpAndVerifyGraph(dfg, &quot;Graph just before FTL lowering:&quot;, shouldDumpDisassembly(m_mode));
481 
482         // Flash a safepoint in case the GC wants some action.
483         Safepoint::Result safepointResult;
484         {
485             GraphSafepoint safepoint(dfg, safepointResult);
486         }
487         if (safepointResult.didGetCancelled())
488             return CancelPath;
489 
490         FTL::State state(dfg);
491         FTL::lowerDFGToB3(state);
492 
493         if (UNLIKELY(computeCompileTimes()))
494             m_timeBeforeFTL = MonotonicTime::now();
495 
496         if (Options::b3AlwaysFailsBeforeCompile()) {
497             FTL::fail(state);
498             return FTLPath;
499         }
500 
501         FTL::compile(state, safepointResult);
502         if (safepointResult.didGetCancelled())
503             return CancelPath;
504 
505         if (Options::b3AlwaysFailsBeforeLink()) {
506             FTL::fail(state);
507             return FTLPath;
508         }
509 
510         if (state.allocationFailed) {
511             FTL::fail(state);
512             return FTLPath;
513         }
514 
515         FTL::link(state);
516 
517         if (state.allocationFailed) {
518             FTL::fail(state);
519             return FTLPath;
520         }
521 
522         return FTLPath;
523 #else
524         RELEASE_ASSERT_NOT_REACHED();
525         return FailPath;
526 #endif // ENABLE(FTL_JIT)
527     }
528 
529     default:
530         RELEASE_ASSERT_NOT_REACHED();
531         return FailPath;
532     }
533 
534 #undef RUN_PHASE
535 }
536 
537 bool Plan::isStillValid()
538 {
539     CodeBlock* replacement = m_codeBlock-&gt;replacement();
540     if (!replacement)
541         return false;
542     // FIXME: This is almost certainly not necessary. There&#39;s no way for the baseline
543     // code to be replaced during a compilation, except if we delete the plan, in which
544     // case we wouldn&#39;t be here.
545     // https://bugs.webkit.org/show_bug.cgi?id=132707
546     if (m_codeBlock-&gt;alternative() != replacement-&gt;baselineVersion())
547         return false;
548     if (!m_watchpoints.areStillValid())
549         return false;
550     return true;
551 }
552 
553 void Plan::reallyAdd(CommonData* commonData)
554 {
555     m_watchpoints.reallyAdd(m_codeBlock, *commonData);
556     m_identifiers.reallyAdd(*m_vm, commonData);
557     m_weakReferences.reallyAdd(*m_vm, commonData);
558     m_transitions.reallyAdd(*m_vm, commonData);
559     m_globalProperties.reallyAdd(m_codeBlock, m_identifiers, *commonData);
560     commonData-&gt;recordedStatuses = WTFMove(m_recordedStatuses);
561 }
562 
563 void Plan::notifyCompiling()
564 {
565     m_stage = Compiling;
566 }
567 
568 void Plan::notifyReady()
569 {
570     m_callback-&gt;compilationDidBecomeReadyAsynchronously(m_codeBlock, m_profiledDFGCodeBlock);
571     m_stage = Ready;
572 }
573 
574 bool Plan::isStillValidOnMainThread()
575 {
576     return m_globalProperties.isStillValidOnMainThread(*m_vm, m_identifiers);
577 }
578 
579 CompilationResult Plan::finalizeWithoutNotifyingCallback()
580 {
581     // We will establish new references from the code block to things. So, we need a barrier.
582     m_vm-&gt;heap.writeBarrier(m_codeBlock);
583 
584     if (!isStillValidOnMainThread() || !isStillValid()) {
585         CODEBLOCK_LOG_EVENT(m_codeBlock, &quot;dfgFinalize&quot;, (&quot;invalidated&quot;));
586         return CompilationInvalidated;
587     }
588 
589     bool result;
590     if (m_codeBlock-&gt;codeType() == FunctionCode)
591         result = m_finalizer-&gt;finalizeFunction();
592     else
593         result = m_finalizer-&gt;finalize();
594 
595     if (!result) {
596         CODEBLOCK_LOG_EVENT(m_codeBlock, &quot;dfgFinalize&quot;, (&quot;failed&quot;));
597         return CompilationFailed;
598     }
599 
600     reallyAdd(m_codeBlock-&gt;jitCode()-&gt;dfgCommon());
601 
602     if (validationEnabled()) {
603         TrackedReferences trackedReferences;
604 
605         for (WriteBarrier&lt;JSCell&gt;&amp; reference : m_codeBlock-&gt;jitCode()-&gt;dfgCommon()-&gt;weakReferences)
606             trackedReferences.add(reference.get());
607         for (WriteBarrier&lt;Structure&gt;&amp; reference : m_codeBlock-&gt;jitCode()-&gt;dfgCommon()-&gt;weakStructureReferences)
608             trackedReferences.add(reference.get());
609         for (WriteBarrier&lt;Unknown&gt;&amp; constant : m_codeBlock-&gt;constants())
610             trackedReferences.add(constant.get());
611 
612         for (auto* inlineCallFrame : *m_inlineCallFrames) {
613             ASSERT(inlineCallFrame-&gt;baselineCodeBlock.get());
614             trackedReferences.add(inlineCallFrame-&gt;baselineCodeBlock.get());
615         }
616 
617         // Check that any other references that we have anywhere in the JITCode are also
618         // tracked either strongly or weakly.
619         m_codeBlock-&gt;jitCode()-&gt;validateReferences(trackedReferences);
620     }
621 
622     CODEBLOCK_LOG_EVENT(m_codeBlock, &quot;dfgFinalize&quot;, (&quot;succeeded&quot;));
623     return CompilationSuccessful;
624 }
625 
626 void Plan::finalizeAndNotifyCallback()
627 {
628     m_callback-&gt;compilationDidComplete(m_codeBlock, m_profiledDFGCodeBlock, finalizeWithoutNotifyingCallback());
629 }
630 
631 CompilationKey Plan::key()
632 {
633     return CompilationKey(m_codeBlock-&gt;alternative(), m_mode);
634 }
635 
636 void Plan::checkLivenessAndVisitChildren(SlotVisitor&amp; visitor)
637 {
638     if (!isKnownToBeLiveDuringGC())
639         return;
640 
641     cleanMustHandleValuesIfNecessary();
642     for (unsigned i = m_mustHandleValues.size(); i--;) {
643         Optional&lt;JSValue&gt; value = m_mustHandleValues[i];
644         if (value)
645             visitor.appendUnbarriered(value.value());
646     }
647 
648     m_recordedStatuses.markIfCheap(visitor);
649 
650     visitor.appendUnbarriered(m_codeBlock);
651     visitor.appendUnbarriered(m_codeBlock-&gt;alternative());
652     visitor.appendUnbarriered(m_profiledDFGCodeBlock);
653 
654     if (m_inlineCallFrames) {
655         for (auto* inlineCallFrame : *m_inlineCallFrames) {
656             ASSERT(inlineCallFrame-&gt;baselineCodeBlock.get());
657             visitor.appendUnbarriered(inlineCallFrame-&gt;baselineCodeBlock.get());
658         }
659     }
660 
661     m_weakReferences.visitChildren(visitor);
662     m_transitions.visitChildren(visitor);
663 }
664 
665 void Plan::finalizeInGC()
666 {
667     m_recordedStatuses.finalizeWithoutDeleting();
668 }
669 
670 bool Plan::isKnownToBeLiveDuringGC()
671 {
672     if (m_stage == Cancelled)
673         return false;
674     if (!Heap::isMarked(m_codeBlock-&gt;ownerExecutable()))
675         return false;
676     if (!Heap::isMarked(m_codeBlock-&gt;alternative()))
677         return false;
678     if (!!m_profiledDFGCodeBlock &amp;&amp; !Heap::isMarked(m_profiledDFGCodeBlock))
679         return false;
680     return true;
681 }
682 
683 void Plan::cancel()
684 {
685     m_vm = nullptr;
686     m_codeBlock = nullptr;
687     m_profiledDFGCodeBlock = nullptr;
688     m_mustHandleValues.clear();
689     m_compilation = nullptr;
690     m_finalizer = nullptr;
691     m_inlineCallFrames = nullptr;
692     m_watchpoints = DesiredWatchpoints();
693     m_identifiers = DesiredIdentifiers();
694     m_globalProperties = DesiredGlobalProperties();
695     m_weakReferences = DesiredWeakReferences();
696     m_transitions = DesiredTransitions();
697     m_callback = nullptr;
698     m_stage = Cancelled;
699 }
700 
701 void Plan::cleanMustHandleValuesIfNecessary()
702 {
703     LockHolder locker(m_mustHandleValueCleaningLock);
704 
705     if (!m_mustHandleValuesMayIncludeGarbage)
706         return;
707 
708     m_mustHandleValuesMayIncludeGarbage = false;
709 
710     if (!m_codeBlock)
711         return;
712 
713     if (!m_mustHandleValues.numberOfLocals())
714         return;
715 
716     CodeBlock* alternative = m_codeBlock-&gt;alternative();
717     FastBitVector liveness = alternative-&gt;livenessAnalysis().getLivenessInfoAtBytecodeOffset(alternative, m_osrEntryBytecodeIndex);
718 
719     for (unsigned local = m_mustHandleValues.numberOfLocals(); local--;) {
720         if (!liveness[local])
721             m_mustHandleValues.local(local) = WTF::nullopt;
722     }
723 }
724 
725 } } // namespace JSC::DFG
726 
727 #endif // ENABLE(DFG_JIT)
728 
    </pre>
  </body>
</html>