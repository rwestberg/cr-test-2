<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGSpeculativeJIT.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #pragma once
  27 
  28 #if ENABLE(DFG_JIT)
  29 
  30 #include &quot;BlockDirectory.h&quot;
  31 #include &quot;DFGAbstractInterpreter.h&quot;
  32 #include &quot;DFGGenerationInfo.h&quot;
  33 #include &quot;DFGInPlaceAbstractState.h&quot;
  34 #include &quot;DFGJITCompiler.h&quot;
  35 #include &quot;DFGOSRExit.h&quot;
  36 #include &quot;DFGOSRExitJumpPlaceholder.h&quot;
  37 #include &quot;DFGRegisterBank.h&quot;
  38 #include &quot;DFGSilentRegisterSavePlan.h&quot;
  39 #include &quot;JITMathIC.h&quot;
  40 #include &quot;JITOperations.h&quot;
  41 #include &quot;PutKind.h&quot;
  42 #include &quot;SpillRegistersMode.h&quot;
  43 #include &quot;StructureStubInfo.h&quot;
  44 #include &quot;ValueRecovery.h&quot;
  45 #include &quot;VirtualRegister.h&quot;
  46 
  47 namespace JSC { namespace DFG {
  48 
  49 class GPRTemporary;
  50 class JSValueOperand;
  51 class SlowPathGenerator;
  52 class SpeculativeJIT;
  53 class SpeculateInt32Operand;
  54 class SpeculateStrictInt32Operand;
  55 class SpeculateDoubleOperand;
  56 class SpeculateCellOperand;
  57 class SpeculateBooleanOperand;
  58 
  59 enum GeneratedOperandType { GeneratedOperandTypeUnknown, GeneratedOperandInteger, GeneratedOperandJSValue};
  60 
  61 // === SpeculativeJIT ===
  62 //
  63 // The SpeculativeJIT is used to generate a fast, but potentially
  64 // incomplete code path for the dataflow. When code generating
  65 // we may make assumptions about operand types, dynamically check,
  66 // and bail-out to an alternate code path if these checks fail.
  67 // Importantly, the speculative code path cannot be reentered once
  68 // a speculative check has failed. This allows the SpeculativeJIT
  69 // to propagate type information (including information that has
  70 // only speculatively been asserted) through the dataflow.
  71 class SpeculativeJIT {
  72     WTF_MAKE_FAST_ALLOCATED;
  73 
  74     friend struct OSRExit;
  75 private:
  76     typedef JITCompiler::TrustedImm32 TrustedImm32;
  77     typedef JITCompiler::Imm32 Imm32;
  78     typedef JITCompiler::ImmPtr ImmPtr;
  79     typedef JITCompiler::TrustedImm64 TrustedImm64;
  80     typedef JITCompiler::Imm64 Imm64;
  81 
  82     // These constants are used to set priorities for spill order for
  83     // the register allocator.
  84 #if USE(JSVALUE64)
  85     enum SpillOrder {
  86         SpillOrderConstant = 1, // no spill, and cheap fill
  87         SpillOrderSpilled  = 2, // no spill
  88         SpillOrderJS       = 4, // needs spill
  89         SpillOrderCell     = 4, // needs spill
  90         SpillOrderStorage  = 4, // needs spill
  91         SpillOrderInteger  = 5, // needs spill and box
  92         SpillOrderBoolean  = 5, // needs spill and box
  93         SpillOrderDouble   = 6, // needs spill and convert
  94     };
  95 #elif USE(JSVALUE32_64)
  96     enum SpillOrder {
  97         SpillOrderConstant = 1, // no spill, and cheap fill
  98         SpillOrderSpilled  = 2, // no spill
  99         SpillOrderJS       = 4, // needs spill
 100         SpillOrderStorage  = 4, // needs spill
 101         SpillOrderDouble   = 4, // needs spill
 102         SpillOrderInteger  = 5, // needs spill and box
 103         SpillOrderCell     = 5, // needs spill and box
 104         SpillOrderBoolean  = 5, // needs spill and box
 105     };
 106 #endif
 107 
 108     enum UseChildrenMode { CallUseChildren, UseChildrenCalledExplicitly };
 109 
 110 public:
 111     SpeculativeJIT(JITCompiler&amp;);
 112     ~SpeculativeJIT();
 113 
 114     VM&amp; vm()
 115     {
<a name="1" id="anc1"></a><span class="line-modified"> 116         return *m_jit.vm();</span>
 117     }
 118 
 119     struct TrustedImmPtr {
 120         template &lt;typename T&gt;
 121         explicit TrustedImmPtr(T* value)
 122             : m_value(value)
 123         {
 124             static_assert(!std::is_base_of&lt;JSCell, T&gt;::value, &quot;To use a GC pointer, the graph must be aware of it. Use SpeculativeJIT::TrustedImmPtr::weakPointer instead.&quot;);
 125         }
 126 
 127         explicit TrustedImmPtr(RegisteredStructure structure)
 128             : m_value(structure.get())
 129         { }
 130 
 131         explicit TrustedImmPtr(std::nullptr_t)
 132             : m_value(nullptr)
 133         { }
 134 
 135         explicit TrustedImmPtr(FrozenValue* value)
 136             : m_value(value-&gt;cell())
 137         {
 138             RELEASE_ASSERT(value-&gt;value().isCell());
 139         }
 140 
 141         explicit TrustedImmPtr(size_t value)
 142             : m_value(bitwise_cast&lt;void*&gt;(value))
 143         {
 144         }
 145 
 146         static TrustedImmPtr weakPointer(Graph&amp; graph, JSCell* cell)
 147         {
 148             graph.m_plan.weakReferences().addLazily(cell);
 149             return TrustedImmPtr(bitwise_cast&lt;size_t&gt;(cell));
 150         }
 151 
 152         operator MacroAssembler::TrustedImmPtr() const { return m_value; }
 153         operator MacroAssembler::TrustedImm() const { return m_value; }
 154 
 155         intptr_t asIntptr()
 156         {
 157             return m_value.asIntptr();
 158         }
 159 
 160     private:
 161         MacroAssembler::TrustedImmPtr m_value;
 162     };
 163 
 164     bool compile();
 165 
 166     void createOSREntries();
 167     void linkOSREntries(LinkBuffer&amp;);
 168 
 169     BasicBlock* nextBlock()
 170     {
 171         for (BlockIndex resultIndex = m_block-&gt;index + 1; ; resultIndex++) {
 172             if (resultIndex &gt;= m_jit.graph().numBlocks())
 173                 return 0;
 174             if (BasicBlock* result = m_jit.graph().block(resultIndex))
 175                 return result;
 176         }
 177     }
 178 
 179 #if USE(JSVALUE64)
 180     GPRReg fillJSValue(Edge);
 181 #elif USE(JSVALUE32_64)
 182     bool fillJSValue(Edge, GPRReg&amp;, GPRReg&amp;, FPRReg&amp;);
 183 #endif
 184     GPRReg fillStorage(Edge);
 185 
 186     // lock and unlock GPR &amp; FPR registers.
 187     void lock(GPRReg reg)
 188     {
 189         m_gprs.lock(reg);
 190     }
 191     void lock(FPRReg reg)
 192     {
 193         m_fprs.lock(reg);
 194     }
 195     void unlock(GPRReg reg)
 196     {
 197         m_gprs.unlock(reg);
 198     }
 199     void unlock(FPRReg reg)
 200     {
 201         m_fprs.unlock(reg);
 202     }
 203 
 204     // Used to check whether a child node is on its last use,
 205     // and its machine registers may be reused.
 206     bool canReuse(Node* node)
 207     {
 208         return generationInfo(node).useCount() == 1;
 209     }
 210     bool canReuse(Node* nodeA, Node* nodeB)
 211     {
 212         return nodeA == nodeB &amp;&amp; generationInfo(nodeA).useCount() == 2;
 213     }
 214     bool canReuse(Edge nodeUse)
 215     {
 216         return canReuse(nodeUse.node());
 217     }
 218     GPRReg reuse(GPRReg reg)
 219     {
 220         m_gprs.lock(reg);
 221         return reg;
 222     }
 223     FPRReg reuse(FPRReg reg)
 224     {
 225         m_fprs.lock(reg);
 226         return reg;
 227     }
 228 
 229     // Allocate a gpr/fpr.
 230     GPRReg allocate()
 231     {
 232 #if ENABLE(DFG_REGISTER_ALLOCATION_VALIDATION)
 233         m_jit.addRegisterAllocationAtOffset(m_jit.debugOffset());
 234 #endif
 235         VirtualRegister spillMe;
 236         GPRReg gpr = m_gprs.allocate(spillMe);
 237         if (spillMe.isValid()) {
 238 #if USE(JSVALUE32_64)
 239             GenerationInfo&amp; info = generationInfoFromVirtualRegister(spillMe);
 240             if ((info.registerFormat() &amp; DataFormatJS))
 241                 m_gprs.release(info.tagGPR() == gpr ? info.payloadGPR() : info.tagGPR());
 242 #endif
 243             spill(spillMe);
 244         }
 245         return gpr;
 246     }
 247     GPRReg allocate(GPRReg specific)
 248     {
 249 #if ENABLE(DFG_REGISTER_ALLOCATION_VALIDATION)
 250         m_jit.addRegisterAllocationAtOffset(m_jit.debugOffset());
 251 #endif
 252         VirtualRegister spillMe = m_gprs.allocateSpecific(specific);
 253         if (spillMe.isValid()) {
 254 #if USE(JSVALUE32_64)
 255             GenerationInfo&amp; info = generationInfoFromVirtualRegister(spillMe);
 256             RELEASE_ASSERT(info.registerFormat() != DataFormatJSDouble);
 257             if ((info.registerFormat() &amp; DataFormatJS))
 258                 m_gprs.release(info.tagGPR() == specific ? info.payloadGPR() : info.tagGPR());
 259 #endif
 260             spill(spillMe);
 261         }
 262         return specific;
 263     }
 264     GPRReg tryAllocate()
 265     {
 266         return m_gprs.tryAllocate();
 267     }
 268     FPRReg fprAllocate()
 269     {
 270 #if ENABLE(DFG_REGISTER_ALLOCATION_VALIDATION)
 271         m_jit.addRegisterAllocationAtOffset(m_jit.debugOffset());
 272 #endif
 273         VirtualRegister spillMe;
 274         FPRReg fpr = m_fprs.allocate(spillMe);
 275         if (spillMe.isValid())
 276             spill(spillMe);
 277         return fpr;
 278     }
 279 
 280     // Check whether a VirtualRegsiter is currently in a machine register.
 281     // We use this when filling operands to fill those that are already in
 282     // machine registers first (by locking VirtualRegsiters that are already
 283     // in machine register before filling those that are not we attempt to
 284     // avoid spilling values we will need immediately).
 285     bool isFilled(Node* node)
 286     {
 287         return generationInfo(node).registerFormat() != DataFormatNone;
 288     }
 289     bool isFilledDouble(Node* node)
 290     {
 291         return generationInfo(node).registerFormat() == DataFormatDouble;
 292     }
 293 
 294     // Called on an operand once it has been consumed by a parent node.
 295     void use(Node* node)
 296     {
 297         if (!node-&gt;hasResult())
 298             return;
 299         GenerationInfo&amp; info = generationInfo(node);
 300 
 301         // use() returns true when the value becomes dead, and any
 302         // associated resources may be freed.
 303         if (!info.use(*m_stream))
 304             return;
 305 
 306         // Release the associated machine registers.
 307         DataFormat registerFormat = info.registerFormat();
 308 #if USE(JSVALUE64)
 309         if (registerFormat == DataFormatDouble)
 310             m_fprs.release(info.fpr());
 311         else if (registerFormat != DataFormatNone)
 312             m_gprs.release(info.gpr());
 313 #elif USE(JSVALUE32_64)
 314         if (registerFormat == DataFormatDouble)
 315             m_fprs.release(info.fpr());
 316         else if (registerFormat &amp; DataFormatJS) {
 317             m_gprs.release(info.tagGPR());
 318             m_gprs.release(info.payloadGPR());
 319         } else if (registerFormat != DataFormatNone)
 320             m_gprs.release(info.gpr());
 321 #endif
 322     }
 323     void use(Edge nodeUse)
 324     {
 325         use(nodeUse.node());
 326     }
 327 
 328     RegisterSet usedRegisters();
 329 
 330     bool masqueradesAsUndefinedWatchpointIsStillValid(const CodeOrigin&amp; codeOrigin)
 331     {
 332         return m_jit.graph().masqueradesAsUndefinedWatchpointIsStillValid(codeOrigin);
 333     }
 334     bool masqueradesAsUndefinedWatchpointIsStillValid()
 335     {
 336         return masqueradesAsUndefinedWatchpointIsStillValid(m_currentNode-&gt;origin.semantic);
 337     }
 338 
 339     void compileStoreBarrier(Node*);
 340 
 341     // Called by the speculative operand types, below, to fill operand to
 342     // machine registers, implicitly generating speculation checks as needed.
 343     GPRReg fillSpeculateInt32(Edge, DataFormat&amp; returnFormat);
 344     GPRReg fillSpeculateInt32Strict(Edge);
 345     GPRReg fillSpeculateInt52(Edge, DataFormat desiredFormat);
 346     FPRReg fillSpeculateDouble(Edge);
 347     GPRReg fillSpeculateCell(Edge);
 348     GPRReg fillSpeculateBoolean(Edge);
 349     GeneratedOperandType checkGeneratedTypeForToInt32(Node*);
 350 
 351     void addSlowPathGenerator(std::unique_ptr&lt;SlowPathGenerator&gt;);
 352     void addSlowPathGeneratorLambda(Function&lt;void()&gt;&amp;&amp;);
 353     void runSlowPathGenerators(PCToCodeOriginMapBuilder&amp;);
 354 
 355     void compile(Node*);
 356     void noticeOSRBirth(Node*);
 357     void bail(AbortReason);
 358     void compileCurrentBlock();
 359 
 360     void checkArgumentTypes();
 361 
 362     void clearGenerationInfo();
 363 
 364     // These methods are used when generating &#39;unexpected&#39;
 365     // calls out from JIT code to C++ helper routines -
 366     // they spill all live values to the appropriate
 367     // slots in the JSStack without changing any state
 368     // in the GenerationInfo.
 369     SilentRegisterSavePlan silentSavePlanForGPR(VirtualRegister spillMe, GPRReg source);
 370     SilentRegisterSavePlan silentSavePlanForFPR(VirtualRegister spillMe, FPRReg source);
 371     void silentSpill(const SilentRegisterSavePlan&amp;);
 372     void silentFill(const SilentRegisterSavePlan&amp;);
 373 
 374     template&lt;typename CollectionType&gt;
 375     void silentSpill(const CollectionType&amp; savePlans)
 376     {
 377         for (unsigned i = 0; i &lt; savePlans.size(); ++i)
 378             silentSpill(savePlans[i]);
 379     }
 380 
 381     template&lt;typename CollectionType&gt;
 382     void silentFill(const CollectionType&amp; savePlans)
 383     {
 384         for (unsigned i = savePlans.size(); i--;)
 385             silentFill(savePlans[i]);
 386     }
 387 
 388     template&lt;typename CollectionType&gt;
 389     void silentSpillAllRegistersImpl(bool doSpill, CollectionType&amp; plans, GPRReg exclude, GPRReg exclude2 = InvalidGPRReg, FPRReg fprExclude = InvalidFPRReg)
 390     {
 391         ASSERT(plans.isEmpty());
 392         for (gpr_iterator iter = m_gprs.begin(); iter != m_gprs.end(); ++iter) {
 393             GPRReg gpr = iter.regID();
 394             if (iter.name().isValid() &amp;&amp; gpr != exclude &amp;&amp; gpr != exclude2) {
 395                 SilentRegisterSavePlan plan = silentSavePlanForGPR(iter.name(), gpr);
 396                 if (doSpill)
 397                     silentSpill(plan);
 398                 plans.append(plan);
 399             }
 400         }
 401         for (fpr_iterator iter = m_fprs.begin(); iter != m_fprs.end(); ++iter) {
 402             if (iter.name().isValid() &amp;&amp; iter.regID() != fprExclude) {
 403                 SilentRegisterSavePlan plan = silentSavePlanForFPR(iter.name(), iter.regID());
 404                 if (doSpill)
 405                     silentSpill(plan);
 406                 plans.append(plan);
 407             }
 408         }
 409     }
 410     template&lt;typename CollectionType&gt;
 411     void silentSpillAllRegistersImpl(bool doSpill, CollectionType&amp; plans, NoResultTag)
 412     {
 413         silentSpillAllRegistersImpl(doSpill, plans, InvalidGPRReg, InvalidGPRReg, InvalidFPRReg);
 414     }
 415     template&lt;typename CollectionType&gt;
 416     void silentSpillAllRegistersImpl(bool doSpill, CollectionType&amp; plans, FPRReg exclude)
 417     {
 418         silentSpillAllRegistersImpl(doSpill, plans, InvalidGPRReg, InvalidGPRReg, exclude);
 419     }
 420     template&lt;typename CollectionType&gt;
 421     void silentSpillAllRegistersImpl(bool doSpill, CollectionType&amp; plans, JSValueRegs exclude)
 422     {
 423 #if USE(JSVALUE32_64)
 424         silentSpillAllRegistersImpl(doSpill, plans, exclude.tagGPR(), exclude.payloadGPR());
 425 #else
 426         silentSpillAllRegistersImpl(doSpill, plans, exclude.gpr());
 427 #endif
 428     }
 429 
 430     void silentSpillAllRegisters(GPRReg exclude, GPRReg exclude2 = InvalidGPRReg, FPRReg fprExclude = InvalidFPRReg)
 431     {
 432         silentSpillAllRegistersImpl(true, m_plans, exclude, exclude2, fprExclude);
 433     }
 434     void silentSpillAllRegisters(FPRReg exclude)
 435     {
 436         silentSpillAllRegisters(InvalidGPRReg, InvalidGPRReg, exclude);
 437     }
 438     void silentSpillAllRegisters(JSValueRegs exclude)
 439     {
 440 #if USE(JSVALUE64)
 441         silentSpillAllRegisters(exclude.payloadGPR());
 442 #else
 443         silentSpillAllRegisters(exclude.payloadGPR(), exclude.tagGPR());
 444 #endif
 445     }
 446 
 447     void silentFillAllRegisters()
 448     {
 449         while (!m_plans.isEmpty()) {
 450             SilentRegisterSavePlan&amp; plan = m_plans.last();
 451             silentFill(plan);
 452             m_plans.removeLast();
 453         }
 454     }
 455 
 456     // These methods convert between doubles, and doubles boxed and JSValues.
 457 #if USE(JSVALUE64)
 458     GPRReg boxDouble(FPRReg fpr, GPRReg gpr)
 459     {
 460         return m_jit.boxDouble(fpr, gpr);
 461     }
 462     FPRReg unboxDouble(GPRReg gpr, GPRReg resultGPR, FPRReg fpr)
 463     {
 464         return m_jit.unboxDouble(gpr, resultGPR, fpr);
 465     }
 466     GPRReg boxDouble(FPRReg fpr)
 467     {
 468         return boxDouble(fpr, allocate());
 469     }
 470 
 471     void boxInt52(GPRReg sourceGPR, GPRReg targetGPR, DataFormat);
 472 #elif USE(JSVALUE32_64)
 473     void boxDouble(FPRReg fpr, GPRReg tagGPR, GPRReg payloadGPR)
 474     {
 475         m_jit.boxDouble(fpr, tagGPR, payloadGPR);
 476     }
 477     void unboxDouble(GPRReg tagGPR, GPRReg payloadGPR, FPRReg fpr, FPRReg scratchFPR)
 478     {
 479         m_jit.unboxDouble(tagGPR, payloadGPR, fpr, scratchFPR);
 480     }
 481 #endif
 482     void boxDouble(FPRReg fpr, JSValueRegs regs)
 483     {
 484         m_jit.boxDouble(fpr, regs);
 485     }
 486 
 487     // Spill a VirtualRegister to the JSStack.
 488     void spill(VirtualRegister spillMe)
 489     {
 490         GenerationInfo&amp; info = generationInfoFromVirtualRegister(spillMe);
 491 
 492 #if USE(JSVALUE32_64)
 493         if (info.registerFormat() == DataFormatNone) // it has been spilled. JS values which have two GPRs can reach here
 494             return;
 495 #endif
 496         // Check the GenerationInfo to see if this value need writing
 497         // to the JSStack - if not, mark it as spilled &amp; return.
 498         if (!info.needsSpill()) {
 499             info.setSpilled(*m_stream, spillMe);
 500             return;
 501         }
 502 
 503         DataFormat spillFormat = info.registerFormat();
 504         switch (spillFormat) {
 505         case DataFormatStorage: {
 506             // This is special, since it&#39;s not a JS value - as in it&#39;s not visible to JS
 507             // code.
 508             m_jit.storePtr(info.gpr(), JITCompiler::addressFor(spillMe));
 509             info.spill(*m_stream, spillMe, DataFormatStorage);
 510             return;
 511         }
 512 
 513         case DataFormatInt32: {
 514             m_jit.store32(info.gpr(), JITCompiler::payloadFor(spillMe));
 515             info.spill(*m_stream, spillMe, DataFormatInt32);
 516             return;
 517         }
 518 
 519 #if USE(JSVALUE64)
 520         case DataFormatDouble: {
 521             m_jit.storeDouble(info.fpr(), JITCompiler::addressFor(spillMe));
 522             info.spill(*m_stream, spillMe, DataFormatDouble);
 523             return;
 524         }
 525 
 526         case DataFormatInt52:
 527         case DataFormatStrictInt52: {
 528             m_jit.store64(info.gpr(), JITCompiler::addressFor(spillMe));
 529             info.spill(*m_stream, spillMe, spillFormat);
 530             return;
 531         }
 532 
 533         default:
 534             // The following code handles JSValues, int32s, and cells.
 535             RELEASE_ASSERT(spillFormat == DataFormatCell || spillFormat &amp; DataFormatJS);
 536 
 537             GPRReg reg = info.gpr();
 538             // We need to box int32 and cell values ...
 539             // but on JSVALUE64 boxing a cell is a no-op!
 540             if (spillFormat == DataFormatInt32)
 541                 m_jit.or64(GPRInfo::tagTypeNumberRegister, reg);
 542 
 543             // Spill the value, and record it as spilled in its boxed form.
 544             m_jit.store64(reg, JITCompiler::addressFor(spillMe));
 545             info.spill(*m_stream, spillMe, (DataFormat)(spillFormat | DataFormatJS));
 546             return;
 547 #elif USE(JSVALUE32_64)
 548         case DataFormatCell:
 549         case DataFormatBoolean: {
 550             m_jit.store32(info.gpr(), JITCompiler::payloadFor(spillMe));
 551             info.spill(*m_stream, spillMe, spillFormat);
 552             return;
 553         }
 554 
 555         case DataFormatDouble: {
 556             // On JSVALUE32_64 boxing a double is a no-op.
 557             m_jit.storeDouble(info.fpr(), JITCompiler::addressFor(spillMe));
 558             info.spill(*m_stream, spillMe, DataFormatDouble);
 559             return;
 560         }
 561 
 562         default:
 563             // The following code handles JSValues.
 564             RELEASE_ASSERT(spillFormat &amp; DataFormatJS);
 565             m_jit.store32(info.tagGPR(), JITCompiler::tagFor(spillMe));
 566             m_jit.store32(info.payloadGPR(), JITCompiler::payloadFor(spillMe));
 567             info.spill(*m_stream, spillMe, spillFormat);
 568             return;
 569 #endif
 570         }
 571     }
 572 
 573     bool isKnownInteger(Node* node) { return m_state.forNode(node).isType(SpecInt32Only); }
 574     bool isKnownCell(Node* node) { return m_state.forNode(node).isType(SpecCell); }
 575 
 576     bool isKnownNotInteger(Node* node) { return !(m_state.forNode(node).m_type &amp; SpecInt32Only); }
 577     bool isKnownNotNumber(Node* node) { return !(m_state.forNode(node).m_type &amp; SpecFullNumber); }
 578     bool isKnownNotCell(Node* node) { return !(m_state.forNode(node).m_type &amp; SpecCell); }
 579     bool isKnownNotOther(Node* node) { return !(m_state.forNode(node).m_type &amp; SpecOther); }
 580 
<a name="2" id="anc2"></a>

 581     UniquedStringImpl* identifierUID(unsigned index)
 582     {
 583         return m_jit.graph().identifiers()[index];
 584     }
 585 
 586     // Spill all VirtualRegisters back to the JSStack.
 587     void flushRegisters()
 588     {
 589         for (gpr_iterator iter = m_gprs.begin(); iter != m_gprs.end(); ++iter) {
 590             if (iter.name().isValid()) {
 591                 spill(iter.name());
 592                 iter.release();
 593             }
 594         }
 595         for (fpr_iterator iter = m_fprs.begin(); iter != m_fprs.end(); ++iter) {
 596             if (iter.name().isValid()) {
 597                 spill(iter.name());
 598                 iter.release();
 599             }
 600         }
 601     }
 602 
 603     // Used to ASSERT flushRegisters() has been called prior to
 604     // calling out from JIT code to a C helper function.
 605     bool isFlushed()
 606     {
 607         for (gpr_iterator iter = m_gprs.begin(); iter != m_gprs.end(); ++iter) {
 608             if (iter.name().isValid())
 609                 return false;
 610         }
 611         for (fpr_iterator iter = m_fprs.begin(); iter != m_fprs.end(); ++iter) {
 612             if (iter.name().isValid())
 613                 return false;
 614         }
 615         return true;
 616     }
 617 
 618 #if USE(JSVALUE64)
 619     static MacroAssembler::Imm64 valueOfJSConstantAsImm64(Node* node)
 620     {
 621         return MacroAssembler::Imm64(JSValue::encode(node-&gt;asJSValue()));
 622     }
 623 #endif
 624 
 625     // Helper functions to enable code sharing in implementations of bit/shift ops.
 626     void bitOp(NodeType op, int32_t imm, GPRReg op1, GPRReg result)
 627     {
 628         switch (op) {
 629         case ArithBitAnd:
 630             m_jit.and32(Imm32(imm), op1, result);
 631             break;
 632         case ArithBitOr:
 633             m_jit.or32(Imm32(imm), op1, result);
 634             break;
 635         case ArithBitXor:
 636             m_jit.xor32(Imm32(imm), op1, result);
 637             break;
 638         default:
 639             RELEASE_ASSERT_NOT_REACHED();
 640         }
 641     }
 642     void bitOp(NodeType op, GPRReg op1, GPRReg op2, GPRReg result)
 643     {
 644         switch (op) {
 645         case ArithBitAnd:
 646             m_jit.and32(op1, op2, result);
 647             break;
 648         case ArithBitOr:
 649             m_jit.or32(op1, op2, result);
 650             break;
 651         case ArithBitXor:
 652             m_jit.xor32(op1, op2, result);
 653             break;
 654         default:
 655             RELEASE_ASSERT_NOT_REACHED();
 656         }
 657     }
 658     void shiftOp(NodeType op, GPRReg op1, int32_t shiftAmount, GPRReg result)
 659     {
 660         switch (op) {
 661         case BitRShift:
 662             m_jit.rshift32(op1, Imm32(shiftAmount), result);
 663             break;
<a name="3" id="anc3"></a><span class="line-modified"> 664         case BitLShift:</span>
 665             m_jit.lshift32(op1, Imm32(shiftAmount), result);
 666             break;
 667         case BitURShift:
 668             m_jit.urshift32(op1, Imm32(shiftAmount), result);
 669             break;
 670         default:
 671             RELEASE_ASSERT_NOT_REACHED();
 672         }
 673     }
 674     void shiftOp(NodeType op, GPRReg op1, GPRReg shiftAmount, GPRReg result)
 675     {
 676         switch (op) {
 677         case BitRShift:
 678             m_jit.rshift32(op1, shiftAmount, result);
 679             break;
<a name="4" id="anc4"></a><span class="line-modified"> 680         case BitLShift:</span>
 681             m_jit.lshift32(op1, shiftAmount, result);
 682             break;
 683         case BitURShift:
 684             m_jit.urshift32(op1, shiftAmount, result);
 685             break;
 686         default:
 687             RELEASE_ASSERT_NOT_REACHED();
 688         }
 689     }
 690 
 691     // Returns the index of the branch node if peephole is okay, UINT_MAX otherwise.
 692     unsigned detectPeepHoleBranch()
 693     {
 694         // Check that no intervening nodes will be generated.
 695         for (unsigned index = m_indexInBlock + 1; index &lt; m_block-&gt;size() - 1; ++index) {
 696             Node* node = m_block-&gt;at(index);
 697             if (!node-&gt;shouldGenerate())
 698                 continue;
 699             // Check if it&#39;s a Phantom that can be safely ignored.
 700             if (node-&gt;op() == Phantom &amp;&amp; !node-&gt;child1())
 701                 continue;
 702             return UINT_MAX;
 703         }
 704 
 705         // Check if the lastNode is a branch on this node.
 706         Node* lastNode = m_block-&gt;terminal();
 707         return lastNode-&gt;op() == Branch &amp;&amp; lastNode-&gt;child1() == m_currentNode ? m_block-&gt;size() - 1 : UINT_MAX;
 708     }
 709 
 710     void compileCheckTraps(Node*);
 711 
 712     void compileMovHint(Node*);
 713     void compileMovHintAndCheck(Node*);
 714 
 715     void cachedGetById(CodeOrigin, JSValueRegs base, JSValueRegs result, unsigned identifierNumber, JITCompiler::Jump slowPathTarget, SpillRegistersMode, AccessType);
 716     void cachedPutById(CodeOrigin, GPRReg baseGPR, JSValueRegs valueRegs, GPRReg scratchGPR, unsigned identifierNumber, PutKind, JITCompiler::Jump slowPathTarget = JITCompiler::Jump(), SpillRegistersMode = NeedToSpill);
 717 
 718 #if USE(JSVALUE64)
 719     void cachedGetById(CodeOrigin, GPRReg baseGPR, GPRReg resultGPR, unsigned identifierNumber, JITCompiler::Jump slowPathTarget, SpillRegistersMode, AccessType);
 720     void cachedGetByIdWithThis(CodeOrigin, GPRReg baseGPR, GPRReg thisGPR, GPRReg resultGPR, unsigned identifierNumber, const JITCompiler::JumpList&amp; slowPathTarget = JITCompiler::JumpList());
 721 #elif USE(JSVALUE32_64)
 722     void cachedGetById(CodeOrigin, GPRReg baseTagGPROrNone, GPRReg basePayloadGPR, GPRReg resultTagGPR, GPRReg resultPayloadGPR, unsigned identifierNumber, JITCompiler::Jump slowPathTarget, SpillRegistersMode, AccessType);
 723     void cachedGetByIdWithThis(CodeOrigin, GPRReg baseTagGPROrNone, GPRReg basePayloadGPR, GPRReg thisTagGPROrNone, GPRReg thisPayloadGPR, GPRReg resultTagGPR, GPRReg resultPayloadGPR, unsigned identifierNumber, const JITCompiler::JumpList&amp; slowPathTarget = JITCompiler::JumpList());
 724 #endif
 725 
 726     void compileDeleteById(Node*);
 727     void compileDeleteByVal(Node*);
 728     void compilePushWithScope(Node*);
 729     void compileGetById(Node*, AccessType);
 730     void compileGetByIdFlush(Node*, AccessType);
 731     void compileInById(Node*);
 732     void compileInByVal(Node*);
 733 
 734     void nonSpeculativeNonPeepholeCompareNullOrUndefined(Edge operand);
 735     void nonSpeculativePeepholeBranchNullOrUndefined(Edge operand, Node* branchNode);
 736 
 737     void nonSpeculativePeepholeBranch(Node*, Node* branchNode, MacroAssembler::RelationalCondition, S_JITOperation_EJJ helperFunction);
 738     void nonSpeculativeNonPeepholeCompare(Node*, MacroAssembler::RelationalCondition, S_JITOperation_EJJ helperFunction);
 739 
 740     void nonSpeculativePeepholeStrictEq(Node*, Node* branchNode, bool invert = false);
 741     void nonSpeculativeNonPeepholeStrictEq(Node*, bool invert = false);
 742     bool nonSpeculativeStrictEq(Node*, bool invert = false);
 743 
 744     void compileInstanceOfForCells(Node*, JSValueRegs valueGPR, JSValueRegs prototypeGPR, GPRReg resultGPT, GPRReg scratchGPR, GPRReg scratch2GPR, JITCompiler::Jump slowCase = JITCompiler::Jump());
 745     void compileInstanceOf(Node*);
 746     void compileInstanceOfCustom(Node*);
 747     void compileOverridesHasInstance(Node*);
 748 
 749     void compileIsCellWithType(Node*);
 750     void compileIsTypedArrayView(Node*);
 751 
 752     void emitCall(Node*);
 753 
 754     void emitAllocateButterfly(GPRReg storageGPR, GPRReg sizeGPR, GPRReg scratch1, GPRReg scratch2, GPRReg scratch3, MacroAssembler::JumpList&amp; slowCases);
 755     void emitInitializeButterfly(GPRReg storageGPR, GPRReg sizeGPR, JSValueRegs emptyValueRegs, GPRReg scratchGPR);
 756     void compileAllocateNewArrayWithSize(JSGlobalObject*, GPRReg resultGPR, GPRReg sizeGPR, IndexingType, bool shouldConvertLargeSizeToArrayStorage = true);
 757 
 758     // Called once a node has completed code generation but prior to setting
 759     // its result, to free up its children. (This must happen prior to setting
 760     // the nodes result, since the node may have the same VirtualRegister as
 761     // a child, and as such will use the same GeneratioInfo).
 762     void useChildren(Node*);
 763 
 764     // These method called to initialize the GenerationInfo
 765     // to describe the result of an operation.
 766     void int32Result(GPRReg reg, Node* node, DataFormat format = DataFormatInt32, UseChildrenMode mode = CallUseChildren)
 767     {
 768         if (mode == CallUseChildren)
 769             useChildren(node);
 770 
 771         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 772         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 773 
 774         if (format == DataFormatInt32) {
 775             m_jit.jitAssertIsInt32(reg);
 776             m_gprs.retain(reg, virtualRegister, SpillOrderInteger);
 777             info.initInt32(node, node-&gt;refCount(), reg);
 778         } else {
 779 #if USE(JSVALUE64)
 780             RELEASE_ASSERT(format == DataFormatJSInt32);
 781             m_jit.jitAssertIsJSInt32(reg);
 782             m_gprs.retain(reg, virtualRegister, SpillOrderJS);
 783             info.initJSValue(node, node-&gt;refCount(), reg, format);
 784 #elif USE(JSVALUE32_64)
 785             RELEASE_ASSERT_NOT_REACHED();
 786 #endif
 787         }
 788     }
 789     void int32Result(GPRReg reg, Node* node, UseChildrenMode mode)
 790     {
 791         int32Result(reg, node, DataFormatInt32, mode);
 792     }
 793     void int52Result(GPRReg reg, Node* node, DataFormat format, UseChildrenMode mode = CallUseChildren)
 794     {
 795         if (mode == CallUseChildren)
 796             useChildren(node);
 797 
 798         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 799         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 800 
 801         m_gprs.retain(reg, virtualRegister, SpillOrderJS);
 802         info.initInt52(node, node-&gt;refCount(), reg, format);
 803     }
 804     void int52Result(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 805     {
 806         int52Result(reg, node, DataFormatInt52, mode);
 807     }
 808     void strictInt52Result(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 809     {
 810         int52Result(reg, node, DataFormatStrictInt52, mode);
 811     }
 812     void noResult(Node* node, UseChildrenMode mode = CallUseChildren)
 813     {
 814         if (mode == UseChildrenCalledExplicitly)
 815             return;
 816         useChildren(node);
 817     }
 818     void cellResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 819     {
 820         if (mode == CallUseChildren)
 821             useChildren(node);
 822 
 823         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 824         m_gprs.retain(reg, virtualRegister, SpillOrderCell);
 825         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 826         info.initCell(node, node-&gt;refCount(), reg);
 827     }
 828     void blessedBooleanResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 829     {
 830 #if USE(JSVALUE64)
 831         jsValueResult(reg, node, DataFormatJSBoolean, mode);
 832 #else
 833         booleanResult(reg, node, mode);
 834 #endif
 835     }
 836     void unblessedBooleanResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 837     {
 838 #if USE(JSVALUE64)
 839         blessBoolean(reg);
 840 #endif
 841         blessedBooleanResult(reg, node, mode);
 842     }
 843 #if USE(JSVALUE64)
 844     void jsValueResult(GPRReg reg, Node* node, DataFormat format = DataFormatJS, UseChildrenMode mode = CallUseChildren)
 845     {
 846         if (format == DataFormatJSInt32)
 847             m_jit.jitAssertIsJSInt32(reg);
 848 
 849         if (mode == CallUseChildren)
 850             useChildren(node);
 851 
 852         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 853         m_gprs.retain(reg, virtualRegister, SpillOrderJS);
 854         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 855         info.initJSValue(node, node-&gt;refCount(), reg, format);
 856     }
 857     void jsValueResult(GPRReg reg, Node* node, UseChildrenMode mode)
 858     {
 859         jsValueResult(reg, node, DataFormatJS, mode);
 860     }
 861 #elif USE(JSVALUE32_64)
 862     void booleanResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 863     {
 864         if (mode == CallUseChildren)
 865             useChildren(node);
 866 
 867         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 868         m_gprs.retain(reg, virtualRegister, SpillOrderBoolean);
 869         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 870         info.initBoolean(node, node-&gt;refCount(), reg);
 871     }
 872     void jsValueResult(GPRReg tag, GPRReg payload, Node* node, DataFormat format = DataFormatJS, UseChildrenMode mode = CallUseChildren)
 873     {
 874         if (mode == CallUseChildren)
 875             useChildren(node);
 876 
 877         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 878         m_gprs.retain(tag, virtualRegister, SpillOrderJS);
 879         m_gprs.retain(payload, virtualRegister, SpillOrderJS);
 880         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 881         info.initJSValue(node, node-&gt;refCount(), tag, payload, format);
 882     }
 883     void jsValueResult(GPRReg tag, GPRReg payload, Node* node, UseChildrenMode mode)
 884     {
 885         jsValueResult(tag, payload, node, DataFormatJS, mode);
 886     }
 887 #endif
 888     void jsValueResult(JSValueRegs regs, Node* node, DataFormat format = DataFormatJS, UseChildrenMode mode = CallUseChildren)
 889     {
 890 #if USE(JSVALUE64)
 891         jsValueResult(regs.gpr(), node, format, mode);
 892 #else
 893         jsValueResult(regs.tagGPR(), regs.payloadGPR(), node, format, mode);
 894 #endif
 895     }
 896     void storageResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 897     {
 898         if (mode == CallUseChildren)
 899             useChildren(node);
 900 
 901         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 902         m_gprs.retain(reg, virtualRegister, SpillOrderStorage);
 903         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 904         info.initStorage(node, node-&gt;refCount(), reg);
 905     }
 906     void doubleResult(FPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 907     {
 908         if (mode == CallUseChildren)
 909             useChildren(node);
 910 
 911         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 912         m_fprs.retain(reg, virtualRegister, SpillOrderDouble);
 913         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 914         info.initDouble(node, node-&gt;refCount(), reg);
 915     }
 916     void initConstantInfo(Node* node)
 917     {
 918         ASSERT(node-&gt;hasConstant());
 919         generationInfo(node).initConstant(node, node-&gt;refCount());
 920     }
 921 
 922 #define FIRST_ARGUMENT_TYPE typename FunctionTraits&lt;OperationType&gt;::template ArgumentType&lt;0&gt;
 923 
 924     template&lt;typename OperationType, typename ResultRegType, typename... Args&gt;
 925     std::enable_if_t&lt;
 926         FunctionTraits&lt;OperationType&gt;::hasResult,
 927     JITCompiler::Call&gt;
 928     callOperation(OperationType operation, ResultRegType result, Args... args)
 929     {
 930         m_jit.setupArguments&lt;OperationType&gt;(args...);
 931         return appendCallSetResult(operation, result);
 932     }
 933 
 934     template&lt;typename OperationType, typename Arg, typename... Args&gt;
 935     std::enable_if_t&lt;
 936         !FunctionTraits&lt;OperationType&gt;::hasResult
 937         &amp;&amp; !std::is_same&lt;Arg, NoResultTag&gt;::value,
 938     JITCompiler::Call&gt;
 939     callOperation(OperationType operation, Arg arg, Args... args)
 940     {
 941         m_jit.setupArguments&lt;OperationType&gt;(arg, args...);
 942         return appendCall(operation);
 943     }
 944 
 945     template&lt;typename OperationType, typename... Args&gt;
 946     std::enable_if_t&lt;
 947         !FunctionTraits&lt;OperationType&gt;::hasResult,
 948     JITCompiler::Call&gt;
 949     callOperation(OperationType operation, NoResultTag, Args... args)
 950     {
 951         m_jit.setupArguments&lt;OperationType&gt;(args...);
 952         return appendCall(operation);
 953     }
 954 
 955     template&lt;typename OperationType&gt;
 956     std::enable_if_t&lt;
 957         !FunctionTraits&lt;OperationType&gt;::hasResult,
 958     JITCompiler::Call&gt;
 959     callOperation(OperationType operation)
 960     {
 961         m_jit.setupArguments&lt;OperationType&gt;();
 962         return appendCall(operation);
 963     }
 964 
 965 #undef FIRST_ARGUMENT_TYPE
 966 
 967     JITCompiler::Call callOperationWithCallFrameRollbackOnException(V_JITOperation_ECb operation, void* pointer)
 968     {
 969         m_jit.setupArguments&lt;V_JITOperation_ECb&gt;(TrustedImmPtr(pointer));
 970         return appendCallWithCallFrameRollbackOnException(operation);
 971     }
 972 
 973     JITCompiler::Call callOperationWithCallFrameRollbackOnException(Z_JITOperation_E operation, GPRReg result)
 974     {
 975         m_jit.setupArguments&lt;Z_JITOperation_E&gt;();
 976         return appendCallWithCallFrameRollbackOnExceptionSetResult(operation, result);
 977     }
 978 
 979 #if !defined(NDEBUG) &amp;&amp; !CPU(ARM_THUMB2) &amp;&amp; !CPU(MIPS)
 980     void prepareForExternalCall()
 981     {
 982         // We&#39;re about to call out to a &quot;native&quot; helper function. The helper
 983         // function is expected to set topCallFrame itself with the ExecState
 984         // that is passed to it.
 985         //
 986         // We explicitly trash topCallFrame here so that we&#39;ll know if some of
 987         // the helper functions are not setting topCallFrame when they should
 988         // be doing so. Note: the previous value in topcallFrame was not valid
 989         // anyway since it was not being updated by JIT&#39;ed code by design.
 990 
 991         for (unsigned i = 0; i &lt; sizeof(void*) / 4; i++)
<a name="5" id="anc5"></a><span class="line-modified"> 992             m_jit.store32(TrustedImm32(0xbadbeef), reinterpret_cast&lt;char*&gt;(&amp;m_jit.vm()-&gt;topCallFrame) + i * 4);</span>
 993     }
 994 #else
 995     void prepareForExternalCall() { }
 996 #endif
 997 
 998     // These methods add call instructions, optionally setting results, and optionally rolling back the call frame on an exception.
 999     JITCompiler::Call appendCall(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
1000     {
1001         prepareForExternalCall();
1002         m_jit.emitStoreCodeOrigin(m_currentNode-&gt;origin.semantic);
1003         return m_jit.appendCall(function);
1004     }
1005 
1006     JITCompiler::Call appendCallWithCallFrameRollbackOnException(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
1007     {
1008         JITCompiler::Call call = appendCall(function);
1009         m_jit.exceptionCheckWithCallFrameRollback();
1010         return call;
1011     }
1012 
1013     JITCompiler::Call appendCallWithCallFrameRollbackOnExceptionSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, GPRReg result)
1014     {
1015         JITCompiler::Call call = appendCallWithCallFrameRollbackOnException(function);
1016         if ((result != InvalidGPRReg) &amp;&amp; (result != GPRInfo::returnValueGPR))
1017             m_jit.move(GPRInfo::returnValueGPR, result);
1018         return call;
1019     }
1020 
1021     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, GPRReg result)
1022     {
1023         JITCompiler::Call call = appendCall(function);
1024         if (result != InvalidGPRReg)
1025             m_jit.move(GPRInfo::returnValueGPR, result);
1026         return call;
1027     }
1028 
1029     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, GPRReg result1, GPRReg result2)
1030     {
1031         JITCompiler::Call call = appendCall(function);
1032         m_jit.setupResults(result1, result2);
1033         return call;
1034     }
1035 
1036     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, JSValueRegs resultRegs)
1037     {
1038 #if USE(JSVALUE64)
1039         return appendCallSetResult(function, resultRegs.gpr());
1040 #else
1041         return appendCallSetResult(function, resultRegs.payloadGPR(), resultRegs.tagGPR());
1042 #endif
1043     }
1044 
1045 #if CPU(X86)
1046     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, FPRReg result)
1047     {
1048         JITCompiler::Call call = appendCall(function);
1049         if (result != InvalidFPRReg) {
1050             m_jit.assembler().fstpl(0, JITCompiler::stackPointerRegister);
1051             m_jit.loadDouble(JITCompiler::stackPointerRegister, result);
1052         }
1053         return call;
1054     }
1055 #elif CPU(ARM_THUMB2) &amp;&amp; !CPU(ARM_HARDFP)
1056     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, FPRReg result)
1057     {
1058         JITCompiler::Call call = appendCall(function);
1059         if (result != InvalidFPRReg)
1060             m_jit.assembler().vmov(result, GPRInfo::returnValueGPR, GPRInfo::returnValueGPR2);
1061         return call;
1062     }
1063 #else // CPU(X86_64) || (CPU(ARM_THUMB2) &amp;&amp; CPU(ARM_HARDFP)) || CPU(ARM64) || CPU(MIPS)
1064     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, FPRReg result)
1065     {
1066         JITCompiler::Call call = appendCall(function);
1067         if (result != InvalidFPRReg)
1068             m_jit.moveDouble(FPRInfo::returnValueFPR, result);
1069         return call;
1070     }
1071 #endif
1072 
1073     void branchDouble(JITCompiler::DoubleCondition cond, FPRReg left, FPRReg right, BasicBlock* destination)
1074     {
1075         return addBranch(m_jit.branchDouble(cond, left, right), destination);
1076     }
1077 
1078     void branchDoubleNonZero(FPRReg value, FPRReg scratch, BasicBlock* destination)
1079     {
1080         return addBranch(m_jit.branchDoubleNonZero(value, scratch), destination);
1081     }
1082 
1083     template&lt;typename T, typename U&gt;
1084     void branch32(JITCompiler::RelationalCondition cond, T left, U right, BasicBlock* destination)
1085     {
1086         return addBranch(m_jit.branch32(cond, left, right), destination);
1087     }
1088 
1089     template&lt;typename T, typename U&gt;
1090     void branchTest32(JITCompiler::ResultCondition cond, T value, U mask, BasicBlock* destination)
1091     {
1092         return addBranch(m_jit.branchTest32(cond, value, mask), destination);
1093     }
1094 
1095     template&lt;typename T&gt;
1096     void branchTest32(JITCompiler::ResultCondition cond, T value, BasicBlock* destination)
1097     {
1098         return addBranch(m_jit.branchTest32(cond, value), destination);
1099     }
1100 
1101 #if USE(JSVALUE64)
1102     template&lt;typename T, typename U&gt;
1103     void branch64(JITCompiler::RelationalCondition cond, T left, U right, BasicBlock* destination)
1104     {
1105         return addBranch(m_jit.branch64(cond, left, right), destination);
1106     }
1107 #endif
1108 
1109     template&lt;typename T, typename U&gt;
1110     void branch8(JITCompiler::RelationalCondition cond, T left, U right, BasicBlock* destination)
1111     {
1112         return addBranch(m_jit.branch8(cond, left, right), destination);
1113     }
1114 
1115     template&lt;typename T, typename U&gt;
1116     void branchPtr(JITCompiler::RelationalCondition cond, T left, U right, BasicBlock* destination)
1117     {
1118         return addBranch(m_jit.branchPtr(cond, left, right), destination);
1119     }
1120 
1121     template&lt;typename T, typename U&gt;
1122     void branchTestPtr(JITCompiler::ResultCondition cond, T value, U mask, BasicBlock* destination)
1123     {
1124         return addBranch(m_jit.branchTestPtr(cond, value, mask), destination);
1125     }
1126 
1127     template&lt;typename T&gt;
1128     void branchTestPtr(JITCompiler::ResultCondition cond, T value, BasicBlock* destination)
1129     {
1130         return addBranch(m_jit.branchTestPtr(cond, value), destination);
1131     }
1132 
1133     template&lt;typename T, typename U&gt;
1134     void branchTest8(JITCompiler::ResultCondition cond, T value, U mask, BasicBlock* destination)
1135     {
1136         return addBranch(m_jit.branchTest8(cond, value, mask), destination);
1137     }
1138 
1139     template&lt;typename T&gt;
1140     void branchTest8(JITCompiler::ResultCondition cond, T value, BasicBlock* destination)
1141     {
1142         return addBranch(m_jit.branchTest8(cond, value), destination);
1143     }
1144 
1145     enum FallThroughMode {
1146         AtFallThroughPoint,
1147         ForceJump
1148     };
1149     void jump(BasicBlock* destination, FallThroughMode fallThroughMode = AtFallThroughPoint)
1150     {
1151         if (destination == nextBlock()
1152             &amp;&amp; fallThroughMode == AtFallThroughPoint)
1153             return;
1154         addBranch(m_jit.jump(), destination);
1155     }
1156 
1157     void addBranch(const MacroAssembler::Jump&amp; jump, BasicBlock* destination)
1158     {
1159         m_branches.append(BranchRecord(jump, destination));
1160     }
1161     void addBranch(const MacroAssembler::JumpList&amp; jump, BasicBlock* destination);
1162 
1163     void linkBranches();
1164 
1165     void dump(const char* label = 0);
1166 
1167     bool betterUseStrictInt52(Node* node)
1168     {
1169         return !generationInfo(node).isInt52();
1170     }
1171     bool betterUseStrictInt52(Edge edge)
1172     {
1173         return betterUseStrictInt52(edge.node());
1174     }
1175 
1176     bool compare(Node*, MacroAssembler::RelationalCondition, MacroAssembler::DoubleCondition, S_JITOperation_EJJ);
1177     void compileCompareUnsigned(Node*, MacroAssembler::RelationalCondition);
1178     bool compilePeepHoleBranch(Node*, MacroAssembler::RelationalCondition, MacroAssembler::DoubleCondition, S_JITOperation_EJJ);
1179     void compilePeepHoleInt32Branch(Node*, Node* branchNode, JITCompiler::RelationalCondition);
1180     void compilePeepHoleInt52Branch(Node*, Node* branchNode, JITCompiler::RelationalCondition);
1181     void compilePeepHoleBooleanBranch(Node*, Node* branchNode, JITCompiler::RelationalCondition);
1182     void compilePeepHoleDoubleBranch(Node*, Node* branchNode, JITCompiler::DoubleCondition);
1183     void compilePeepHoleObjectEquality(Node*, Node* branchNode);
1184     void compilePeepHoleObjectStrictEquality(Edge objectChild, Edge otherChild, Node* branchNode);
1185     void compilePeepHoleObjectToObjectOrOtherEquality(Edge leftChild, Edge rightChild, Node* branchNode);
1186     void compileObjectEquality(Node*);
1187     void compileObjectStrictEquality(Edge objectChild, Edge otherChild);
1188     void compileObjectToObjectOrOtherEquality(Edge leftChild, Edge rightChild);
1189     void compileObjectOrOtherLogicalNot(Edge value);
1190     void compileLogicalNot(Node*);
1191     void compileLogicalNotStringOrOther(Node*);
1192     void compileStringEquality(
1193         Node*, GPRReg leftGPR, GPRReg rightGPR, GPRReg lengthGPR,
1194         GPRReg leftTempGPR, GPRReg rightTempGPR, GPRReg leftTemp2GPR,
1195         GPRReg rightTemp2GPR, const JITCompiler::JumpList&amp; fastTrue,
1196         const JITCompiler::JumpList&amp; fastSlow);
1197     void compileStringEquality(Node*);
1198     void compileStringIdentEquality(Node*);
1199     void compileStringToUntypedEquality(Node*, Edge stringEdge, Edge untypedEdge);
1200     void compileStringIdentToNotStringVarEquality(Node*, Edge stringEdge, Edge notStringVarEdge);
1201     void compileStringZeroLength(Node*);
1202     void compileMiscStrictEq(Node*);
1203 
1204     void compileSymbolEquality(Node*);
1205     void compileBigIntEquality(Node*);
1206     void compilePeepHoleSymbolEquality(Node*, Node* branchNode);
1207     void compileSymbolUntypedEquality(Node*, Edge symbolEdge, Edge untypedEdge);
1208 
1209     void emitObjectOrOtherBranch(Edge value, BasicBlock* taken, BasicBlock* notTaken);
1210     void emitStringBranch(Edge value, BasicBlock* taken, BasicBlock* notTaken);
1211     void emitStringOrOtherBranch(Edge value, BasicBlock* taken, BasicBlock* notTaken);
1212     void emitBranch(Node*);
1213 
1214     struct StringSwitchCase {
1215         StringSwitchCase() { }
1216 
1217         StringSwitchCase(StringImpl* string, BasicBlock* target)
1218             : string(string)
1219             , target(target)
1220         {
1221         }
1222 
1223         bool operator&lt;(const StringSwitchCase&amp; other) const
1224         {
1225             return stringLessThan(*string, *other.string);
1226         }
1227 
1228         StringImpl* string;
1229         BasicBlock* target;
1230     };
1231 
1232     void emitSwitchIntJump(SwitchData*, GPRReg value, GPRReg scratch);
1233     void emitSwitchImm(Node*, SwitchData*);
1234     void emitSwitchCharStringJump(SwitchData*, GPRReg value, GPRReg scratch);
1235     void emitSwitchChar(Node*, SwitchData*);
1236     void emitBinarySwitchStringRecurse(
1237         SwitchData*, const Vector&lt;StringSwitchCase&gt;&amp;, unsigned numChecked,
1238         unsigned begin, unsigned end, GPRReg buffer, GPRReg length, GPRReg temp,
1239         unsigned alreadyCheckedLength, bool checkedExactLength);
1240     void emitSwitchStringOnString(SwitchData*, GPRReg string);
1241     void emitSwitchString(Node*, SwitchData*);
1242     void emitSwitch(Node*);
1243 
1244     void compileToStringOrCallStringConstructorOrStringValueOf(Node*);
1245     void compileNumberToStringWithRadix(Node*);
1246     void compileNumberToStringWithValidRadixConstant(Node*);
1247     void compileNumberToStringWithValidRadixConstant(Node*, int32_t radix);
1248     void compileNewStringObject(Node*);
1249     void compileNewSymbol(Node*);
1250 
1251     void compileNewTypedArrayWithSize(Node*);
1252 
1253     void compileInt32Compare(Node*, MacroAssembler::RelationalCondition);
1254     void compileInt52Compare(Node*, MacroAssembler::RelationalCondition);
1255     void compileBooleanCompare(Node*, MacroAssembler::RelationalCondition);
1256     void compileDoubleCompare(Node*, MacroAssembler::DoubleCondition);
1257     void compileStringCompare(Node*, MacroAssembler::RelationalCondition);
1258     void compileStringIdentCompare(Node*, MacroAssembler::RelationalCondition);
1259 
1260     bool compileStrictEq(Node*);
1261 
1262     void compileSameValue(Node*);
1263 
1264     void compileAllocatePropertyStorage(Node*);
1265     void compileReallocatePropertyStorage(Node*);
1266     void compileNukeStructureAndSetButterfly(Node*);
1267     void compileGetButterfly(Node*);
1268     void compileCallDOMGetter(Node*);
1269     void compileCallDOM(Node*);
1270     void compileCheckSubClass(Node*);
1271     void compileNormalizeMapKey(Node*);
1272     void compileGetMapBucketHead(Node*);
1273     void compileGetMapBucketNext(Node*);
1274     void compileSetAdd(Node*);
1275     void compileMapSet(Node*);
1276     void compileWeakMapGet(Node*);
1277     void compileWeakSetAdd(Node*);
1278     void compileWeakMapSet(Node*);
1279     void compileLoadKeyFromMapBucket(Node*);
1280     void compileLoadValueFromMapBucket(Node*);
1281     void compileExtractValueFromWeakMapGet(Node*);
1282     void compileGetPrototypeOf(Node*);
1283     void compileIdentity(Node*);
1284 
1285 #if USE(JSVALUE32_64)
1286     template&lt;typename BaseOperandType, typename PropertyOperandType, typename ValueOperandType, typename TagType&gt;
1287     void compileContiguousPutByVal(Node*, BaseOperandType&amp;, PropertyOperandType&amp;, ValueOperandType&amp;, GPRReg valuePayloadReg, TagType valueTag);
1288 #endif
1289     void compileDoublePutByVal(Node*, SpeculateCellOperand&amp; base, SpeculateStrictInt32Operand&amp; property);
1290     bool putByValWillNeedExtraRegister(ArrayMode arrayMode)
1291     {
1292         return arrayMode.mayStoreToHole();
1293     }
1294     GPRReg temporaryRegisterForPutByVal(GPRTemporary&amp;, ArrayMode);
1295     GPRReg temporaryRegisterForPutByVal(GPRTemporary&amp; temporary, Node* node)
1296     {
1297         return temporaryRegisterForPutByVal(temporary, node-&gt;arrayMode());
1298     }
1299 
1300     void compileGetCharCodeAt(Node*);
1301     void compileGetByValOnString(Node*);
1302     void compileFromCharCode(Node*);
1303 
1304     void compileGetByValOnDirectArguments(Node*);
1305     void compileGetByValOnScopedArguments(Node*);
1306 
1307     void compileGetScope(Node*);
1308     void compileSkipScope(Node*);
1309     void compileGetGlobalObject(Node*);
1310     void compileGetGlobalThis(Node*);
1311 
1312     void compileGetArrayLength(Node*);
1313 
1314     void compileCheckTypeInfoFlags(Node*);
1315     void compileCheckStringIdent(Node*);
1316 
1317     void compileParseInt(Node*);
1318 
1319     void compileValueRep(Node*);
1320     void compileDoubleRep(Node*);
1321 
1322     void compileValueToInt32(Node*);
1323     void compileUInt32ToNumber(Node*);
1324     void compileDoubleAsInt32(Node*);
1325 
<a name="6" id="anc6"></a>
1326     void compileBitwiseNot(Node*);
1327 
1328     template&lt;typename SnippetGenerator, J_JITOperation_EJJ slowPathFunction&gt;
1329     void emitUntypedBitOp(Node*);
1330     void compileBitwiseOp(Node*);
1331     void compileValueBitwiseOp(Node*);
1332 
1333     void emitUntypedRightShiftBitOp(Node*);
<a name="7" id="anc7"></a>
1334     void compileShiftOp(Node*);
1335 
1336     template &lt;typename Generator, typename RepatchingFunction, typename NonRepatchingFunction&gt;
1337     void compileMathIC(Node*, JITBinaryMathIC&lt;Generator&gt;*, bool needsScratchGPRReg, bool needsScratchFPRReg, RepatchingFunction, NonRepatchingFunction);
1338     template &lt;typename Generator, typename RepatchingFunction, typename NonRepatchingFunction&gt;
1339     void compileMathIC(Node*, JITUnaryMathIC&lt;Generator&gt;*, bool needsScratchGPRReg, RepatchingFunction, NonRepatchingFunction);
1340 
1341     void compileArithDoubleUnaryOp(Node*, double (*doubleFunction)(double), double (*operation)(ExecState*, EncodedJSValue));
1342     void compileValueAdd(Node*);
1343     void compileValueSub(Node*);
1344     void compileArithAdd(Node*);
1345     void compileMakeRope(Node*);
1346     void compileArithAbs(Node*);
1347     void compileArithClz32(Node*);
1348     void compileArithSub(Node*);
1349     void compileValueNegate(Node*);
1350     void compileArithNegate(Node*);
1351     void compileValueMul(Node*);
1352     void compileArithMul(Node*);
1353     void compileValueDiv(Node*);
1354     void compileArithDiv(Node*);
1355     void compileArithFRound(Node*);
<a name="8" id="anc8"></a>
1356     void compileArithMod(Node*);
1357     void compileArithPow(Node*);
<a name="9" id="anc9"></a>
1358     void compileArithRounding(Node*);
1359     void compileArithRandom(Node*);
1360     void compileArithUnary(Node*);
1361     void compileArithSqrt(Node*);
1362     void compileArithMinMax(Node*);
1363     void compileConstantStoragePointer(Node*);
1364     void compileGetIndexedPropertyStorage(Node*);
1365     JITCompiler::Jump jumpForTypedArrayOutOfBounds(Node*, GPRReg baseGPR, GPRReg indexGPR);
1366     JITCompiler::Jump jumpForTypedArrayIsNeuteredIfOutOfBounds(Node*, GPRReg baseGPR, JITCompiler::Jump outOfBounds);
1367     void emitTypedArrayBoundsCheck(Node*, GPRReg baseGPR, GPRReg indexGPR);
1368     void compileGetTypedArrayByteOffset(Node*);
1369     void compileGetByValOnIntTypedArray(Node*, TypedArrayType);
1370     void compilePutByValForIntTypedArray(GPRReg base, GPRReg property, Node*, TypedArrayType);
1371     void compileGetByValOnFloatTypedArray(Node*, TypedArrayType);
1372     void compilePutByValForFloatTypedArray(GPRReg base, GPRReg property, Node*, TypedArrayType);
1373     void compileGetByValForObjectWithString(Node*);
1374     void compileGetByValForObjectWithSymbol(Node*);
1375     void compilePutByValForCellWithString(Node*, Edge&amp; child1, Edge&amp; child2, Edge&amp; child3);
1376     void compilePutByValForCellWithSymbol(Node*, Edge&amp; child1, Edge&amp; child2, Edge&amp; child3);
1377     void compileGetByValWithThis(Node*);
1378     void compileGetByOffset(Node*);
1379     void compilePutByOffset(Node*);
1380     void compileMatchStructure(Node*);
1381     // If this returns false it means that we terminated speculative execution.
1382     bool getIntTypedArrayStoreOperand(
1383         GPRTemporary&amp; value,
1384         GPRReg property,
1385 #if USE(JSVALUE32_64)
1386         GPRTemporary&amp; propertyTag,
1387         GPRTemporary&amp; valueTag,
1388 #endif
1389         Edge valueUse, JITCompiler::JumpList&amp; slowPathCases, bool isClamped = false);
1390     void loadFromIntTypedArray(GPRReg storageReg, GPRReg propertyReg, GPRReg resultReg, TypedArrayType);
1391     void setIntTypedArrayLoadResult(Node*, GPRReg resultReg, TypedArrayType, bool canSpeculate = false);
1392     template &lt;typename ClassType&gt; void compileNewFunctionCommon(GPRReg, RegisteredStructure, GPRReg, GPRReg, GPRReg, MacroAssembler::JumpList&amp;, size_t, FunctionExecutable*);
1393     void compileNewFunction(Node*);
1394     void compileSetFunctionName(Node*);
1395     void compileNewRegexp(Node*);
1396     void compileForwardVarargs(Node*);
1397     void compileLoadVarargs(Node*);
1398     void compileCreateActivation(Node*);
1399     void compileCreateDirectArguments(Node*);
1400     void compileGetFromArguments(Node*);
1401     void compilePutToArguments(Node*);
1402     void compileGetArgument(Node*);
1403     void compileCreateScopedArguments(Node*);
1404     void compileCreateClonedArguments(Node*);
1405     void compileCreateRest(Node*);
1406     void compileSpread(Node*);
1407     void compileNewArray(Node*);
1408     void compileNewArrayWithSpread(Node*);
1409     void compileGetRestLength(Node*);
1410     void compileArraySlice(Node*);
1411     void compileArrayIndexOf(Node*);
1412     void compileArrayPush(Node*);
1413     void compileNotifyWrite(Node*);
1414     void compileRegExpExec(Node*);
1415     void compileRegExpExecNonGlobalOrSticky(Node*);
1416     void compileRegExpMatchFast(Node*);
1417     void compileRegExpMatchFastGlobal(Node*);
1418     void compileRegExpTest(Node*);
1419     void compileStringReplace(Node*);
1420     void compileIsObject(Node*);
1421     void compileIsObjectOrNull(Node*);
1422     void compileIsFunction(Node*);
1423     void compileTypeOf(Node*);
1424     void compileCheckCell(Node*);
1425     void compileCheckNotEmpty(Node*);
1426     void compileCheckStructure(Node*);
1427     void emitStructureCheck(Node*, GPRReg cellGPR, GPRReg tempGPR);
1428     void compilePutAccessorById(Node*);
1429     void compilePutGetterSetterById(Node*);
1430     void compilePutAccessorByVal(Node*);
1431     void compileGetRegExpObjectLastIndex(Node*);
1432     void compileSetRegExpObjectLastIndex(Node*);
1433     void compileLazyJSConstant(Node*);
1434     void compileMaterializeNewObject(Node*);
1435     void compileRecordRegExpCachedResult(Node*);
1436     void compileToObjectOrCallObjectConstructor(Node*);
1437     void compileResolveScope(Node*);
1438     void compileResolveScopeForHoistingFuncDeclInEval(Node*);
1439     void compileGetGlobalVariable(Node*);
1440     void compilePutGlobalVariable(Node*);
1441     void compileGetDynamicVar(Node*);
1442     void compilePutDynamicVar(Node*);
1443     void compileGetClosureVar(Node*);
1444     void compilePutClosureVar(Node*);
1445     void compileCompareEqPtr(Node*);
1446     void compileDefineDataProperty(Node*);
1447     void compileDefineAccessorProperty(Node*);
1448     void compileStringSlice(Node*);
1449     void compileToLowerCase(Node*);
1450     void compileThrow(Node*);
1451     void compileThrowStaticError(Node*);
1452     void compileGetEnumerableLength(Node*);
1453     void compileHasGenericProperty(Node*);
1454     void compileToIndexString(Node*);
1455     void compilePutByIdFlush(Node*);
1456     void compilePutById(Node*);
1457     void compilePutByIdDirect(Node*);
1458     void compilePutByIdWithThis(Node*);
1459     void compileHasStructureProperty(Node*);
1460     void compileGetDirectPname(Node*);
1461     void compileGetPropertyEnumerator(Node*);
1462     void compileGetEnumeratorPname(Node*);
1463     void compileGetExecutable(Node*);
1464     void compileGetGetter(Node*);
1465     void compileGetSetter(Node*);
1466     void compileGetCallee(Node*);
1467     void compileSetCallee(Node*);
1468     void compileGetArgumentCountIncludingThis(Node*);
1469     void compileSetArgumentCountIncludingThis(Node*);
1470     void compileStrCat(Node*);
1471     void compileNewArrayBuffer(Node*);
1472     void compileNewArrayWithSize(Node*);
1473     void compileNewTypedArray(Node*);
1474     void compileToThis(Node*);
1475     void compileObjectKeys(Node*);
1476     void compileObjectCreate(Node*);
1477     void compileCreateThis(Node*);
1478     void compileNewObject(Node*);
1479     void compileToPrimitive(Node*);
1480     void compileLogShadowChickenPrologue(Node*);
1481     void compileLogShadowChickenTail(Node*);
1482     void compileHasIndexedProperty(Node*);
1483     void compileExtractCatchLocal(Node*);
1484     void compileClearCatchLocals(Node*);
1485     void compileProfileType(Node*);
1486 
1487     void moveTrueTo(GPRReg);
1488     void moveFalseTo(GPRReg);
1489     void blessBoolean(GPRReg);
1490 
1491     // Allocator for a cell of a specific size.
1492     template &lt;typename StructureType&gt; // StructureType can be GPR or ImmPtr.
1493     void emitAllocateJSCell(
1494         GPRReg resultGPR, const JITAllocator&amp; allocator, GPRReg allocatorGPR, StructureType structure,
1495         GPRReg scratchGPR, MacroAssembler::JumpList&amp; slowPath)
1496     {
1497         m_jit.emitAllocateJSCell(resultGPR, allocator, allocatorGPR, structure, scratchGPR, slowPath);
1498     }
1499 
1500     // Allocator for an object of a specific size.
1501     template &lt;typename StructureType, typename StorageType&gt; // StructureType and StorageType can be GPR or ImmPtr.
1502     void emitAllocateJSObject(
1503         GPRReg resultGPR, const JITAllocator&amp; allocator, GPRReg allocatorGPR, StructureType structure,
1504         StorageType storage, GPRReg scratchGPR, MacroAssembler::JumpList&amp; slowPath)
1505     {
1506         m_jit.emitAllocateJSObject(
1507             resultGPR, allocator, allocatorGPR, structure, storage, scratchGPR, slowPath);
1508     }
1509 
1510     template &lt;typename ClassType, typename StructureType, typename StorageType&gt; // StructureType and StorageType can be GPR or ImmPtr.
1511     void emitAllocateJSObjectWithKnownSize(
1512         GPRReg resultGPR, StructureType structure, StorageType storage, GPRReg scratchGPR1,
1513         GPRReg scratchGPR2, MacroAssembler::JumpList&amp; slowPath, size_t size)
1514     {
<a name="10" id="anc10"></a><span class="line-modified">1515         m_jit.emitAllocateJSObjectWithKnownSize&lt;ClassType&gt;(*m_jit.vm(), resultGPR, structure, storage, scratchGPR1, scratchGPR2, slowPath, size);</span>
1516     }
1517 
1518     // Convenience allocator for a built-in object.
1519     template &lt;typename ClassType, typename StructureType, typename StorageType&gt; // StructureType and StorageType can be GPR or ImmPtr.
1520     void emitAllocateJSObject(GPRReg resultGPR, StructureType structure, StorageType storage,
1521         GPRReg scratchGPR1, GPRReg scratchGPR2, MacroAssembler::JumpList&amp; slowPath)
1522     {
<a name="11" id="anc11"></a><span class="line-modified">1523         m_jit.emitAllocateJSObject&lt;ClassType&gt;(*m_jit.vm(), resultGPR, structure, storage, scratchGPR1, scratchGPR2, slowPath);</span>
1524     }
1525 
1526     template &lt;typename ClassType, typename StructureType&gt; // StructureType and StorageType can be GPR or ImmPtr.
1527     void emitAllocateVariableSizedJSObject(GPRReg resultGPR, StructureType structure, GPRReg allocationSize, GPRReg scratchGPR1, GPRReg scratchGPR2, MacroAssembler::JumpList&amp; slowPath)
1528     {
<a name="12" id="anc12"></a><span class="line-modified">1529         m_jit.emitAllocateVariableSizedJSObject&lt;ClassType&gt;(*m_jit.vm(), resultGPR, structure, allocationSize, scratchGPR1, scratchGPR2, slowPath);</span>
1530     }
1531 
1532     template&lt;typename ClassType&gt;
1533     void emitAllocateDestructibleObject(GPRReg resultGPR, RegisteredStructure structure,
1534         GPRReg scratchGPR1, GPRReg scratchGPR2, MacroAssembler::JumpList&amp; slowPath)
1535     {
<a name="13" id="anc13"></a><span class="line-modified">1536         m_jit.emitAllocateDestructibleObject&lt;ClassType&gt;(*m_jit.vm(), resultGPR, structure.get(), scratchGPR1, scratchGPR2, slowPath);</span>
1537     }
1538 
1539     void emitAllocateRawObject(GPRReg resultGPR, RegisteredStructure, GPRReg storageGPR, unsigned numElements, unsigned vectorLength);
1540 
1541     void emitGetLength(InlineCallFrame*, GPRReg lengthGPR, bool includeThis = false);
1542     void emitGetLength(CodeOrigin, GPRReg lengthGPR, bool includeThis = false);
1543     void emitGetCallee(CodeOrigin, GPRReg calleeGPR);
1544     void emitGetArgumentStart(CodeOrigin, GPRReg startGPR);
1545     void emitPopulateSliceIndex(Edge&amp;, Optional&lt;GPRReg&gt; indexGPR, GPRReg lengthGPR, GPRReg resultGPR);
1546 
1547     // Generate an OSR exit fuzz check. Returns Jump() if OSR exit fuzz is not enabled, or if
1548     // it&#39;s in training mode.
1549     MacroAssembler::Jump emitOSRExitFuzzCheck();
1550 
1551     // Add a speculation check.
1552     void speculationCheck(ExitKind, JSValueSource, Node*, MacroAssembler::Jump jumpToFail);
1553     void speculationCheck(ExitKind, JSValueSource, Node*, const MacroAssembler::JumpList&amp; jumpsToFail);
1554 
1555     // Add a speculation check without additional recovery, and with a promise to supply a jump later.
1556     OSRExitJumpPlaceholder speculationCheck(ExitKind, JSValueSource, Node*);
1557     OSRExitJumpPlaceholder speculationCheck(ExitKind, JSValueSource, Edge);
1558     void speculationCheck(ExitKind, JSValueSource, Edge, MacroAssembler::Jump jumpToFail);
1559     void speculationCheck(ExitKind, JSValueSource, Edge, const MacroAssembler::JumpList&amp; jumpsToFail);
1560     // Add a speculation check with additional recovery.
1561     void speculationCheck(ExitKind, JSValueSource, Node*, MacroAssembler::Jump jumpToFail, const SpeculationRecovery&amp;);
1562     void speculationCheck(ExitKind, JSValueSource, Edge, MacroAssembler::Jump jumpToFail, const SpeculationRecovery&amp;);
1563 
1564     void emitInvalidationPoint(Node*);
1565 
1566     void unreachable(Node*);
1567 
1568     // Called when we statically determine that a speculation will fail.
1569     void terminateSpeculativeExecution(ExitKind, JSValueRegs, Node*);
1570     void terminateSpeculativeExecution(ExitKind, JSValueRegs, Edge);
1571 
1572     // Helpers for performing type checks on an edge stored in the given registers.
1573     bool needsTypeCheck(Edge edge, SpeculatedType typesPassedThrough) { return m_interpreter.needsTypeCheck(edge, typesPassedThrough); }
1574     void typeCheck(JSValueSource, Edge, SpeculatedType typesPassedThrough, MacroAssembler::Jump jumpToFail, ExitKind = BadType);
1575 
1576     void speculateCellTypeWithoutTypeFiltering(Edge, GPRReg cellGPR, JSType);
1577     void speculateCellType(Edge, GPRReg cellGPR, SpeculatedType, JSType);
1578 
1579     void speculateInt32(Edge);
1580 #if USE(JSVALUE64)
1581     void convertAnyInt(Edge, GPRReg resultGPR);
1582     void speculateAnyInt(Edge);
1583     void speculateInt32(Edge, JSValueRegs);
1584     void speculateDoubleRepAnyInt(Edge);
1585 #endif // USE(JSVALUE64)
1586     void speculateNumber(Edge);
1587     void speculateRealNumber(Edge);
1588     void speculateDoubleRepReal(Edge);
1589     void speculateBoolean(Edge);
1590     void speculateCell(Edge);
1591     void speculateCellOrOther(Edge);
1592     void speculateObject(Edge, GPRReg cell);
1593     void speculateObject(Edge);
1594     void speculateArray(Edge, GPRReg cell);
1595     void speculateArray(Edge);
1596     void speculateFunction(Edge, GPRReg cell);
1597     void speculateFunction(Edge);
1598     void speculateFinalObject(Edge, GPRReg cell);
1599     void speculateFinalObject(Edge);
1600     void speculateRegExpObject(Edge, GPRReg cell);
1601     void speculateRegExpObject(Edge);
1602     void speculateProxyObject(Edge, GPRReg cell);
1603     void speculateProxyObject(Edge);
1604     void speculateDerivedArray(Edge, GPRReg cell);
1605     void speculateDerivedArray(Edge);
1606     void speculateMapObject(Edge);
1607     void speculateMapObject(Edge, GPRReg cell);
1608     void speculateSetObject(Edge);
1609     void speculateSetObject(Edge, GPRReg cell);
1610     void speculateWeakMapObject(Edge);
1611     void speculateWeakMapObject(Edge, GPRReg cell);
1612     void speculateWeakSetObject(Edge);
1613     void speculateWeakSetObject(Edge, GPRReg cell);
1614     void speculateDataViewObject(Edge);
1615     void speculateDataViewObject(Edge, GPRReg cell);
1616     void speculateObjectOrOther(Edge);
1617     void speculateString(Edge edge, GPRReg cell);
1618     void speculateStringIdentAndLoadStorage(Edge edge, GPRReg string, GPRReg storage);
1619     void speculateStringIdent(Edge edge, GPRReg string);
1620     void speculateStringIdent(Edge);
1621     void speculateString(Edge);
1622     void speculateStringOrOther(Edge, JSValueRegs, GPRReg scratch);
1623     void speculateStringOrOther(Edge);
1624     void speculateNotStringVar(Edge);
1625     void speculateNotSymbol(Edge);
1626     void speculateStringObject(Edge, GPRReg);
1627     void speculateStringObject(Edge);
1628     void speculateStringOrStringObject(Edge);
1629     void speculateSymbol(Edge, GPRReg cell);
1630     void speculateSymbol(Edge);
1631     void speculateBigInt(Edge, GPRReg cell);
1632     void speculateBigInt(Edge);
1633     void speculateNotCell(Edge, JSValueRegs);
1634     void speculateNotCell(Edge);
1635     void speculateOther(Edge, JSValueRegs, GPRReg temp);
1636     void speculateOther(Edge, JSValueRegs);
1637     void speculateOther(Edge);
1638     void speculateMisc(Edge, JSValueRegs);
1639     void speculateMisc(Edge);
1640     void speculate(Node*, Edge);
1641 
1642     JITCompiler::JumpList jumpSlowForUnwantedArrayMode(GPRReg tempWithIndexingTypeReg, ArrayMode);
1643     void checkArray(Node*);
1644     void arrayify(Node*, GPRReg baseReg, GPRReg propertyReg);
1645     void arrayify(Node*);
1646 
1647     template&lt;bool strict&gt;
1648     GPRReg fillSpeculateInt32Internal(Edge, DataFormat&amp; returnFormat);
1649 
<a name="14" id="anc14"></a><span class="line-modified">1650     void cageTypedArrayStorage(GPRReg);</span>
<span class="line-removed">1651 </span>
<span class="line-removed">1652     // It is possible, during speculative generation, to reach a situation in which we</span>
<span class="line-removed">1653     // can statically determine a speculation will fail (for example, when two nodes</span>
<span class="line-removed">1654     // will make conflicting speculations about the same operand). In such cases this</span>
<span class="line-removed">1655     // flag is cleared, indicating no further code generation should take place.</span>
<span class="line-removed">1656     bool m_compileOkay;</span>
1657 
1658     void recordSetLocal(
1659         VirtualRegister bytecodeReg, VirtualRegister machineReg, DataFormat format)
1660     {
1661         m_stream-&gt;appendAndLog(VariableEvent::setLocal(bytecodeReg, machineReg, format));
1662     }
1663 
1664     void recordSetLocal(DataFormat format)
1665     {
1666         VariableAccessData* variable = m_currentNode-&gt;variableAccessData();
1667         recordSetLocal(variable-&gt;local(), variable-&gt;machineLocal(), format);
1668     }
1669 
1670     GenerationInfo&amp; generationInfoFromVirtualRegister(VirtualRegister virtualRegister)
1671     {
1672         return m_generationInfo[virtualRegister.toLocal()];
1673     }
1674 
1675     GenerationInfo&amp; generationInfo(Node* node)
1676     {
1677         return generationInfoFromVirtualRegister(node-&gt;virtualRegister());
1678     }
1679 
1680     GenerationInfo&amp; generationInfo(Edge edge)
1681     {
1682         return generationInfo(edge.node());
1683     }
1684 
1685     // The JIT, while also provides MacroAssembler functionality.
1686     JITCompiler&amp; m_jit;
1687     Graph&amp; m_graph;
1688 
1689     // The current node being generated.
1690     BasicBlock* m_block;
1691     Node* m_currentNode;
1692     NodeType m_lastGeneratedNode;
1693     unsigned m_indexInBlock;
1694 
1695     // Virtual and physical register maps.
1696     Vector&lt;GenerationInfo, 32&gt; m_generationInfo;
1697     RegisterBank&lt;GPRInfo&gt; m_gprs;
1698     RegisterBank&lt;FPRInfo&gt; m_fprs;
1699 
<a name="15" id="anc15"></a>





1700     Vector&lt;MacroAssembler::Label&gt; m_osrEntryHeads;
1701 
1702     struct BranchRecord {
1703         BranchRecord(MacroAssembler::Jump jump, BasicBlock* destination)
1704             : jump(jump)
1705             , destination(destination)
1706         {
1707         }
1708 
1709         MacroAssembler::Jump jump;
1710         BasicBlock* destination;
1711     };
1712     Vector&lt;BranchRecord, 8&gt; m_branches;
1713 
1714     NodeOrigin m_origin;
1715 
1716     InPlaceAbstractState m_state;
1717     AbstractInterpreter&lt;InPlaceAbstractState&gt; m_interpreter;
1718 
1719     VariableEventStream* m_stream;
1720     MinifiedGraph* m_minifiedGraph;
1721 
1722     Vector&lt;std::unique_ptr&lt;SlowPathGenerator&gt;, 8&gt; m_slowPathGenerators;
1723     struct SlowPathLambda {
1724         Function&lt;void()&gt; generator;
1725         Node* currentNode;
1726         unsigned streamIndex;
1727     };
1728     Vector&lt;SlowPathLambda&gt; m_slowPathLambdas;
1729     Vector&lt;SilentRegisterSavePlan&gt; m_plans;
1730     Optional&lt;unsigned&gt; m_outOfLineStreamIndex;
1731 };
1732 
1733 
1734 // === Operand types ===
1735 //
1736 // These classes are used to lock the operands to a node into machine
1737 // registers. These classes implement of pattern of locking a value
1738 // into register at the point of construction only if it is already in
1739 // registers, and otherwise loading it lazily at the point it is first
1740 // used. We do so in order to attempt to avoid spilling one operand
1741 // in order to make space available for another.
1742 
1743 class JSValueOperand {
<a name="16" id="anc16"></a>
1744 public:
1745     explicit JSValueOperand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
1746         : m_jit(jit)
1747         , m_edge(edge)
1748 #if USE(JSVALUE64)
1749         , m_gprOrInvalid(InvalidGPRReg)
1750 #elif USE(JSVALUE32_64)
1751         , m_isDouble(false)
1752 #endif
1753     {
1754         ASSERT(m_jit);
1755         if (!edge)
1756             return;
1757         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || edge.useKind() == UntypedUse);
1758 #if USE(JSVALUE64)
1759         if (jit-&gt;isFilled(node()))
1760             gpr();
1761 #elif USE(JSVALUE32_64)
1762         m_register.pair.tagGPR = InvalidGPRReg;
1763         m_register.pair.payloadGPR = InvalidGPRReg;
1764         if (jit-&gt;isFilled(node()))
1765             fill();
1766 #endif
1767     }
1768 
1769     explicit JSValueOperand(JSValueOperand&amp;&amp; other)
1770         : m_jit(other.m_jit)
1771         , m_edge(other.m_edge)
1772     {
1773 #if USE(JSVALUE64)
1774         m_gprOrInvalid = other.m_gprOrInvalid;
1775 #elif USE(JSVALUE32_64)
1776         m_register.pair.tagGPR = InvalidGPRReg;
1777         m_register.pair.payloadGPR = InvalidGPRReg;
1778         m_isDouble = other.m_isDouble;
1779 
1780         if (m_edge) {
1781             if (m_isDouble)
1782                 m_register.fpr = other.m_register.fpr;
1783             else
1784                 m_register.pair = other.m_register.pair;
1785         }
1786 #endif
1787         other.m_edge = Edge();
1788 #if USE(JSVALUE64)
1789         other.m_gprOrInvalid = InvalidGPRReg;
1790 #elif USE(JSVALUE32_64)
1791         other.m_isDouble = false;
1792 #endif
1793     }
1794 
1795     ~JSValueOperand()
1796     {
1797         if (!m_edge)
1798             return;
1799 #if USE(JSVALUE64)
1800         ASSERT(m_gprOrInvalid != InvalidGPRReg);
1801         m_jit-&gt;unlock(m_gprOrInvalid);
1802 #elif USE(JSVALUE32_64)
1803         if (m_isDouble) {
1804             ASSERT(m_register.fpr != InvalidFPRReg);
1805             m_jit-&gt;unlock(m_register.fpr);
1806         } else {
1807             ASSERT(m_register.pair.tagGPR != InvalidGPRReg &amp;&amp; m_register.pair.payloadGPR != InvalidGPRReg);
1808             m_jit-&gt;unlock(m_register.pair.tagGPR);
1809             m_jit-&gt;unlock(m_register.pair.payloadGPR);
1810         }
1811 #endif
1812     }
1813 
1814     Edge edge() const
1815     {
1816         return m_edge;
1817     }
1818 
1819     Node* node() const
1820     {
1821         return edge().node();
1822     }
1823 
1824 #if USE(JSVALUE64)
1825     GPRReg gpr()
1826     {
1827         if (m_gprOrInvalid == InvalidGPRReg)
1828             m_gprOrInvalid = m_jit-&gt;fillJSValue(m_edge);
1829         return m_gprOrInvalid;
1830     }
1831     JSValueRegs jsValueRegs()
1832     {
1833         return JSValueRegs(gpr());
1834     }
1835 #elif USE(JSVALUE32_64)
1836     bool isDouble() { return m_isDouble; }
1837 
1838     void fill()
1839     {
1840         if (m_register.pair.tagGPR == InvalidGPRReg &amp;&amp; m_register.pair.payloadGPR == InvalidGPRReg)
1841             m_isDouble = !m_jit-&gt;fillJSValue(m_edge, m_register.pair.tagGPR, m_register.pair.payloadGPR, m_register.fpr);
1842     }
1843 
1844     GPRReg tagGPR()
1845     {
1846         fill();
1847         ASSERT(!m_isDouble);
1848         return m_register.pair.tagGPR;
1849     }
1850 
1851     GPRReg payloadGPR()
1852     {
1853         fill();
1854         ASSERT(!m_isDouble);
1855         return m_register.pair.payloadGPR;
1856     }
1857 
1858     JSValueRegs jsValueRegs()
1859     {
1860         return JSValueRegs(tagGPR(), payloadGPR());
1861     }
1862 
1863     GPRReg gpr(WhichValueWord which)
1864     {
1865         return jsValueRegs().gpr(which);
1866     }
1867 
1868     FPRReg fpr()
1869     {
1870         fill();
1871         ASSERT(m_isDouble);
1872         return m_register.fpr;
1873     }
1874 #endif
1875 
1876     void use()
1877     {
1878         m_jit-&gt;use(node());
1879     }
1880 
1881 private:
1882     SpeculativeJIT* m_jit;
1883     Edge m_edge;
1884 #if USE(JSVALUE64)
1885     GPRReg m_gprOrInvalid;
1886 #elif USE(JSVALUE32_64)
1887     union {
1888         struct {
1889             GPRReg tagGPR;
1890             GPRReg payloadGPR;
1891         } pair;
1892         FPRReg fpr;
1893     } m_register;
1894     bool m_isDouble;
1895 #endif
1896 };
1897 
1898 class StorageOperand {
<a name="17" id="anc17"></a>
1899 public:
1900     explicit StorageOperand(SpeculativeJIT* jit, Edge edge)
1901         : m_jit(jit)
1902         , m_edge(edge)
1903         , m_gprOrInvalid(InvalidGPRReg)
1904     {
1905         ASSERT(m_jit);
1906         ASSERT(edge.useKind() == UntypedUse || edge.useKind() == KnownCellUse);
1907         if (jit-&gt;isFilled(node()))
1908             gpr();
1909     }
1910 
1911     ~StorageOperand()
1912     {
1913         ASSERT(m_gprOrInvalid != InvalidGPRReg);
1914         m_jit-&gt;unlock(m_gprOrInvalid);
1915     }
1916 
1917     Edge edge() const
1918     {
1919         return m_edge;
1920     }
1921 
1922     Node* node() const
1923     {
1924         return edge().node();
1925     }
1926 
1927     GPRReg gpr()
1928     {
1929         if (m_gprOrInvalid == InvalidGPRReg)
1930             m_gprOrInvalid = m_jit-&gt;fillStorage(edge());
1931         return m_gprOrInvalid;
1932     }
1933 
1934     void use()
1935     {
1936         m_jit-&gt;use(node());
1937     }
1938 
1939 private:
1940     SpeculativeJIT* m_jit;
1941     Edge m_edge;
1942     GPRReg m_gprOrInvalid;
1943 };
1944 
1945 
1946 // === Temporaries ===
1947 //
1948 // These classes are used to allocate temporary registers.
1949 // A mechanism is provided to attempt to reuse the registers
1950 // currently allocated to child nodes whose value is consumed
1951 // by, and not live after, this operation.
1952 
1953 enum ReuseTag { Reuse };
1954 
1955 class GPRTemporary {
<a name="18" id="anc18"></a>
1956 public:
1957     GPRTemporary();
1958     GPRTemporary(SpeculativeJIT*);
1959     GPRTemporary(SpeculativeJIT*, GPRReg specific);
1960     template&lt;typename T&gt;
1961     GPRTemporary(SpeculativeJIT* jit, ReuseTag, T&amp; operand)
1962         : m_jit(jit)
1963         , m_gpr(InvalidGPRReg)
1964     {
1965         if (m_jit-&gt;canReuse(operand.node()))
1966             m_gpr = m_jit-&gt;reuse(operand.gpr());
1967         else
1968             m_gpr = m_jit-&gt;allocate();
1969     }
1970     template&lt;typename T1, typename T2&gt;
1971     GPRTemporary(SpeculativeJIT* jit, ReuseTag, T1&amp; op1, T2&amp; op2)
1972         : m_jit(jit)
1973         , m_gpr(InvalidGPRReg)
1974     {
1975         if (m_jit-&gt;canReuse(op1.node()))
1976             m_gpr = m_jit-&gt;reuse(op1.gpr());
1977         else if (m_jit-&gt;canReuse(op2.node()))
1978             m_gpr = m_jit-&gt;reuse(op2.gpr());
1979         else if (m_jit-&gt;canReuse(op1.node(), op2.node()) &amp;&amp; op1.gpr() == op2.gpr())
1980             m_gpr = m_jit-&gt;reuse(op1.gpr());
1981         else
1982             m_gpr = m_jit-&gt;allocate();
1983     }
1984     GPRTemporary(SpeculativeJIT*, ReuseTag, JSValueOperand&amp;, WhichValueWord);
1985 
1986     GPRTemporary(GPRTemporary&amp; other) = delete;
1987 
1988     GPRTemporary(GPRTemporary&amp;&amp; other)
1989     {
1990         ASSERT(other.m_jit);
1991         ASSERT(other.m_gpr != InvalidGPRReg);
1992         m_jit = other.m_jit;
1993         m_gpr = other.m_gpr;
1994         other.m_jit = nullptr;
1995         other.m_gpr = InvalidGPRReg;
1996     }
1997 
1998     GPRTemporary&amp; operator=(GPRTemporary&amp;&amp; other)
1999     {
2000         ASSERT(!m_jit);
2001         ASSERT(m_gpr == InvalidGPRReg);
2002         std::swap(m_jit, other.m_jit);
2003         std::swap(m_gpr, other.m_gpr);
2004         return *this;
2005     }
2006 
2007     void adopt(GPRTemporary&amp;);
2008 
2009     ~GPRTemporary()
2010     {
2011         if (m_jit &amp;&amp; m_gpr != InvalidGPRReg)
2012             m_jit-&gt;unlock(gpr());
2013     }
2014 
2015     GPRReg gpr()
2016     {
2017         return m_gpr;
2018     }
2019 
2020 private:
2021     SpeculativeJIT* m_jit;
2022     GPRReg m_gpr;
2023 };
2024 
2025 class JSValueRegsTemporary {
<a name="19" id="anc19"></a>
2026 public:
2027     JSValueRegsTemporary();
2028     JSValueRegsTemporary(SpeculativeJIT*);
2029     template&lt;typename T&gt;
2030     JSValueRegsTemporary(SpeculativeJIT*, ReuseTag, T&amp; operand, WhichValueWord resultRegWord = PayloadWord);
2031     JSValueRegsTemporary(SpeculativeJIT*, ReuseTag, JSValueOperand&amp;);
2032     ~JSValueRegsTemporary();
2033 
2034     JSValueRegs regs();
2035 
2036 private:
2037 #if USE(JSVALUE64)
2038     GPRTemporary m_gpr;
2039 #else
2040     GPRTemporary m_payloadGPR;
2041     GPRTemporary m_tagGPR;
2042 #endif
2043 };
2044 
2045 class FPRTemporary {
<a name="20" id="anc20"></a><span class="line-modified">2046     WTF_MAKE_NONCOPYABLE(FPRTemporary);</span>
2047 public:
2048     FPRTemporary(FPRTemporary&amp;&amp;);
2049     FPRTemporary(SpeculativeJIT*);
2050     FPRTemporary(SpeculativeJIT*, SpeculateDoubleOperand&amp;);
2051     FPRTemporary(SpeculativeJIT*, SpeculateDoubleOperand&amp;, SpeculateDoubleOperand&amp;);
2052 #if USE(JSVALUE32_64)
2053     FPRTemporary(SpeculativeJIT*, JSValueOperand&amp;);
2054 #endif
2055 
2056     ~FPRTemporary()
2057     {
2058         if (LIKELY(m_jit))
2059             m_jit-&gt;unlock(fpr());
2060     }
2061 
2062     FPRReg fpr() const
2063     {
2064         ASSERT(m_jit);
2065         ASSERT(m_fpr != InvalidFPRReg);
2066         return m_fpr;
2067     }
2068 
2069 protected:
2070     FPRTemporary(SpeculativeJIT* jit, FPRReg lockedFPR)
2071         : m_jit(jit)
2072         , m_fpr(lockedFPR)
2073     {
2074     }
2075 
2076 private:
2077     SpeculativeJIT* m_jit;
2078     FPRReg m_fpr;
2079 };
2080 
2081 
2082 // === Results ===
2083 //
2084 // These classes lock the result of a call to a C++ helper function.
2085 
2086 class GPRFlushedCallResult : public GPRTemporary {
2087 public:
2088     GPRFlushedCallResult(SpeculativeJIT* jit)
2089         : GPRTemporary(jit, GPRInfo::returnValueGPR)
2090     {
2091     }
2092 };
2093 
2094 #if USE(JSVALUE32_64)
2095 class GPRFlushedCallResult2 : public GPRTemporary {
2096 public:
2097     GPRFlushedCallResult2(SpeculativeJIT* jit)
2098         : GPRTemporary(jit, GPRInfo::returnValueGPR2)
2099     {
2100     }
2101 };
2102 #endif
2103 
2104 class FPRResult : public FPRTemporary {
2105 public:
2106     FPRResult(SpeculativeJIT* jit)
2107         : FPRTemporary(jit, lockedResult(jit))
2108     {
2109     }
2110 
2111 private:
2112     static FPRReg lockedResult(SpeculativeJIT* jit)
2113     {
2114         jit-&gt;lock(FPRInfo::returnValueFPR);
2115         return FPRInfo::returnValueFPR;
2116     }
2117 };
2118 
2119 class JSValueRegsFlushedCallResult {
<a name="21" id="anc21"></a>
2120 public:
2121     JSValueRegsFlushedCallResult(SpeculativeJIT* jit)
2122 #if USE(JSVALUE64)
2123         : m_gpr(jit)
2124 #else
2125         : m_payloadGPR(jit)
2126         , m_tagGPR(jit)
2127 #endif
2128     {
2129     }
2130 
2131     JSValueRegs regs()
2132     {
2133 #if USE(JSVALUE64)
2134         return JSValueRegs { m_gpr.gpr() };
2135 #else
2136         return JSValueRegs { m_tagGPR.gpr(), m_payloadGPR.gpr() };
2137 #endif
2138     }
2139 
2140 private:
2141 #if USE(JSVALUE64)
2142     GPRFlushedCallResult m_gpr;
2143 #else
2144     GPRFlushedCallResult m_payloadGPR;
2145     GPRFlushedCallResult2 m_tagGPR;
2146 #endif
2147 };
2148 
2149 
2150 // === Speculative Operand types ===
2151 //
2152 // SpeculateInt32Operand, SpeculateStrictInt32Operand and SpeculateCellOperand.
2153 //
2154 // These are used to lock the operands to a node into machine registers within the
2155 // SpeculativeJIT. The classes operate like those above, however these will
2156 // perform a speculative check for a more restrictive type than we can statically
2157 // determine the operand to have. If the operand does not have the requested type,
2158 // a bail-out to the non-speculative path will be taken.
2159 
2160 class SpeculateInt32Operand {
<a name="22" id="anc22"></a>
2161 public:
2162     explicit SpeculateInt32Operand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
2163         : m_jit(jit)
2164         , m_edge(edge)
2165         , m_gprOrInvalid(InvalidGPRReg)
2166 #ifndef NDEBUG
2167         , m_format(DataFormatNone)
2168 #endif
2169     {
2170         ASSERT(m_jit);
2171         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || (edge.useKind() == Int32Use || edge.useKind() == KnownInt32Use));
2172         if (jit-&gt;isFilled(node()))
2173             gpr();
2174     }
2175 
2176     ~SpeculateInt32Operand()
2177     {
2178         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2179         m_jit-&gt;unlock(m_gprOrInvalid);
2180     }
2181 
2182     Edge edge() const
2183     {
2184         return m_edge;
2185     }
2186 
2187     Node* node() const
2188     {
2189         return edge().node();
2190     }
2191 
2192     DataFormat format()
2193     {
2194         gpr(); // m_format is set when m_gpr is locked.
2195         ASSERT(m_format == DataFormatInt32 || m_format == DataFormatJSInt32);
2196         return m_format;
2197     }
2198 
2199     GPRReg gpr()
2200     {
2201         if (m_gprOrInvalid == InvalidGPRReg)
2202             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt32(edge(), m_format);
2203         return m_gprOrInvalid;
2204     }
2205 
2206     void use()
2207     {
2208         m_jit-&gt;use(node());
2209     }
2210 
2211 private:
2212     SpeculativeJIT* m_jit;
2213     Edge m_edge;
2214     GPRReg m_gprOrInvalid;
2215     DataFormat m_format;
2216 };
2217 
2218 class SpeculateStrictInt32Operand {
<a name="23" id="anc23"></a>
2219 public:
2220     explicit SpeculateStrictInt32Operand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
2221         : m_jit(jit)
2222         , m_edge(edge)
2223         , m_gprOrInvalid(InvalidGPRReg)
2224     {
2225         ASSERT(m_jit);
2226         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || (edge.useKind() == Int32Use || edge.useKind() == KnownInt32Use));
2227         if (jit-&gt;isFilled(node()))
2228             gpr();
2229     }
2230 
2231     ~SpeculateStrictInt32Operand()
2232     {
2233         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2234         m_jit-&gt;unlock(m_gprOrInvalid);
2235     }
2236 
2237     Edge edge() const
2238     {
2239         return m_edge;
2240     }
2241 
2242     Node* node() const
2243     {
2244         return edge().node();
2245     }
2246 
2247     GPRReg gpr()
2248     {
2249         if (m_gprOrInvalid == InvalidGPRReg)
2250             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt32Strict(edge());
2251         return m_gprOrInvalid;
2252     }
2253 
2254     void use()
2255     {
2256         m_jit-&gt;use(node());
2257     }
2258 
2259 private:
2260     SpeculativeJIT* m_jit;
2261     Edge m_edge;
2262     GPRReg m_gprOrInvalid;
2263 };
2264 
2265 // Gives you a canonical Int52 (i.e. it&#39;s left-shifted by 16, low bits zero).
2266 class SpeculateInt52Operand {
<a name="24" id="anc24"></a>
2267 public:
2268     explicit SpeculateInt52Operand(SpeculativeJIT* jit, Edge edge)
2269         : m_jit(jit)
2270         , m_edge(edge)
2271         , m_gprOrInvalid(InvalidGPRReg)
2272     {
2273         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2274         if (jit-&gt;isFilled(node()))
2275             gpr();
2276     }
2277 
2278     ~SpeculateInt52Operand()
2279     {
2280         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2281         m_jit-&gt;unlock(m_gprOrInvalid);
2282     }
2283 
2284     Edge edge() const
2285     {
2286         return m_edge;
2287     }
2288 
2289     Node* node() const
2290     {
2291         return edge().node();
2292     }
2293 
2294     GPRReg gpr()
2295     {
2296         if (m_gprOrInvalid == InvalidGPRReg)
2297             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt52(edge(), DataFormatInt52);
2298         return m_gprOrInvalid;
2299     }
2300 
2301     void use()
2302     {
2303         m_jit-&gt;use(node());
2304     }
2305 
2306 private:
2307     SpeculativeJIT* m_jit;
2308     Edge m_edge;
2309     GPRReg m_gprOrInvalid;
2310 };
2311 
2312 // Gives you a strict Int52 (i.e. the payload is in the low 48 bits, high 16 bits are sign-extended).
2313 class SpeculateStrictInt52Operand {
<a name="25" id="anc25"></a>
2314 public:
2315     explicit SpeculateStrictInt52Operand(SpeculativeJIT* jit, Edge edge)
2316         : m_jit(jit)
2317         , m_edge(edge)
2318         , m_gprOrInvalid(InvalidGPRReg)
2319     {
2320         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2321         if (jit-&gt;isFilled(node()))
2322             gpr();
2323     }
2324 
2325     ~SpeculateStrictInt52Operand()
2326     {
2327         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2328         m_jit-&gt;unlock(m_gprOrInvalid);
2329     }
2330 
2331     Edge edge() const
2332     {
2333         return m_edge;
2334     }
2335 
2336     Node* node() const
2337     {
2338         return edge().node();
2339     }
2340 
2341     GPRReg gpr()
2342     {
2343         if (m_gprOrInvalid == InvalidGPRReg)
2344             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt52(edge(), DataFormatStrictInt52);
2345         return m_gprOrInvalid;
2346     }
2347 
2348     void use()
2349     {
2350         m_jit-&gt;use(node());
2351     }
2352 
2353 private:
2354     SpeculativeJIT* m_jit;
2355     Edge m_edge;
2356     GPRReg m_gprOrInvalid;
2357 };
2358 
2359 enum OppositeShiftTag { OppositeShift };
2360 
2361 class SpeculateWhicheverInt52Operand {
<a name="26" id="anc26"></a>
2362 public:
2363     explicit SpeculateWhicheverInt52Operand(SpeculativeJIT* jit, Edge edge)
2364         : m_jit(jit)
2365         , m_edge(edge)
2366         , m_gprOrInvalid(InvalidGPRReg)
2367         , m_strict(jit-&gt;betterUseStrictInt52(edge))
2368     {
2369         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2370         if (jit-&gt;isFilled(node()))
2371             gpr();
2372     }
2373 
2374     explicit SpeculateWhicheverInt52Operand(SpeculativeJIT* jit, Edge edge, const SpeculateWhicheverInt52Operand&amp; other)
2375         : m_jit(jit)
2376         , m_edge(edge)
2377         , m_gprOrInvalid(InvalidGPRReg)
2378         , m_strict(other.m_strict)
2379     {
2380         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2381         if (jit-&gt;isFilled(node()))
2382             gpr();
2383     }
2384 
2385     explicit SpeculateWhicheverInt52Operand(SpeculativeJIT* jit, Edge edge, OppositeShiftTag, const SpeculateWhicheverInt52Operand&amp; other)
2386         : m_jit(jit)
2387         , m_edge(edge)
2388         , m_gprOrInvalid(InvalidGPRReg)
2389         , m_strict(!other.m_strict)
2390     {
2391         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2392         if (jit-&gt;isFilled(node()))
2393             gpr();
2394     }
2395 
2396     ~SpeculateWhicheverInt52Operand()
2397     {
2398         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2399         m_jit-&gt;unlock(m_gprOrInvalid);
2400     }
2401 
2402     Edge edge() const
2403     {
2404         return m_edge;
2405     }
2406 
2407     Node* node() const
2408     {
2409         return edge().node();
2410     }
2411 
2412     GPRReg gpr()
2413     {
2414         if (m_gprOrInvalid == InvalidGPRReg) {
2415             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt52(
2416                 edge(), m_strict ? DataFormatStrictInt52 : DataFormatInt52);
2417         }
2418         return m_gprOrInvalid;
2419     }
2420 
2421     void use()
2422     {
2423         m_jit-&gt;use(node());
2424     }
2425 
2426     DataFormat format() const
2427     {
2428         return m_strict ? DataFormatStrictInt52 : DataFormatInt52;
2429     }
2430 
2431 private:
2432     SpeculativeJIT* m_jit;
2433     Edge m_edge;
2434     GPRReg m_gprOrInvalid;
2435     bool m_strict;
2436 };
2437 
2438 class SpeculateDoubleOperand {
<a name="27" id="anc27"></a>
2439 public:
2440     explicit SpeculateDoubleOperand(SpeculativeJIT* jit, Edge edge)
2441         : m_jit(jit)
2442         , m_edge(edge)
2443         , m_fprOrInvalid(InvalidFPRReg)
2444     {
2445         ASSERT(m_jit);
2446         RELEASE_ASSERT(isDouble(edge.useKind()));
2447         if (jit-&gt;isFilled(node()))
2448             fpr();
2449     }
2450 
2451     ~SpeculateDoubleOperand()
2452     {
2453         ASSERT(m_fprOrInvalid != InvalidFPRReg);
2454         m_jit-&gt;unlock(m_fprOrInvalid);
2455     }
2456 
2457     Edge edge() const
2458     {
2459         return m_edge;
2460     }
2461 
2462     Node* node() const
2463     {
2464         return edge().node();
2465     }
2466 
2467     FPRReg fpr()
2468     {
2469         if (m_fprOrInvalid == InvalidFPRReg)
2470             m_fprOrInvalid = m_jit-&gt;fillSpeculateDouble(edge());
2471         return m_fprOrInvalid;
2472     }
2473 
2474     void use()
2475     {
2476         m_jit-&gt;use(node());
2477     }
2478 
2479 private:
2480     SpeculativeJIT* m_jit;
2481     Edge m_edge;
2482     FPRReg m_fprOrInvalid;
2483 };
2484 
2485 class SpeculateCellOperand {
<a name="28" id="anc28"></a><span class="line-modified">2486     WTF_MAKE_NONCOPYABLE(SpeculateCellOperand);</span>
2487 
2488 public:
2489     explicit SpeculateCellOperand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
2490         : m_jit(jit)
2491         , m_edge(edge)
2492         , m_gprOrInvalid(InvalidGPRReg)
2493     {
2494         ASSERT(m_jit);
2495         if (!edge)
2496             return;
2497         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || isCell(edge.useKind()));
2498         if (jit-&gt;isFilled(node()))
2499             gpr();
2500     }
2501 
2502     explicit SpeculateCellOperand(SpeculateCellOperand&amp;&amp; other)
2503     {
2504         m_jit = other.m_jit;
2505         m_edge = other.m_edge;
2506         m_gprOrInvalid = other.m_gprOrInvalid;
2507 
2508         other.m_gprOrInvalid = InvalidGPRReg;
2509         other.m_edge = Edge();
2510     }
2511 
2512     ~SpeculateCellOperand()
2513     {
2514         if (!m_edge)
2515             return;
2516         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2517         m_jit-&gt;unlock(m_gprOrInvalid);
2518     }
2519 
2520     Edge edge() const
2521     {
2522         return m_edge;
2523     }
2524 
2525     Node* node() const
2526     {
2527         return edge().node();
2528     }
2529 
2530     GPRReg gpr()
2531     {
2532         ASSERT(m_edge);
2533         if (m_gprOrInvalid == InvalidGPRReg)
2534             m_gprOrInvalid = m_jit-&gt;fillSpeculateCell(edge());
2535         return m_gprOrInvalid;
2536     }
2537 
2538     void use()
2539     {
2540         ASSERT(m_edge);
2541         m_jit-&gt;use(node());
2542     }
2543 
2544 private:
2545     SpeculativeJIT* m_jit;
2546     Edge m_edge;
2547     GPRReg m_gprOrInvalid;
2548 };
2549 
2550 class SpeculateBooleanOperand {
<a name="29" id="anc29"></a>
2551 public:
2552     explicit SpeculateBooleanOperand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
2553         : m_jit(jit)
2554         , m_edge(edge)
2555         , m_gprOrInvalid(InvalidGPRReg)
2556     {
2557         ASSERT(m_jit);
2558         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || edge.useKind() == BooleanUse || edge.useKind() == KnownBooleanUse);
2559         if (jit-&gt;isFilled(node()))
2560             gpr();
2561     }
2562 
2563     ~SpeculateBooleanOperand()
2564     {
2565         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2566         m_jit-&gt;unlock(m_gprOrInvalid);
2567     }
2568 
2569     Edge edge() const
2570     {
2571         return m_edge;
2572     }
2573 
2574     Node* node() const
2575     {
2576         return edge().node();
2577     }
2578 
2579     GPRReg gpr()
2580     {
2581         if (m_gprOrInvalid == InvalidGPRReg)
2582             m_gprOrInvalid = m_jit-&gt;fillSpeculateBoolean(edge());
2583         return m_gprOrInvalid;
2584     }
2585 
2586     void use()
2587     {
2588         m_jit-&gt;use(node());
2589     }
2590 
2591 private:
2592     SpeculativeJIT* m_jit;
2593     Edge m_edge;
2594     GPRReg m_gprOrInvalid;
2595 };
2596 
2597 #define DFG_TYPE_CHECK_WITH_EXIT_KIND(exitKind, source, edge, typesPassedThrough, jumpToFail) do { \
2598         JSValueSource _dtc_source = (source);                           \
2599         Edge _dtc_edge = (edge);                                        \
2600         SpeculatedType _dtc_typesPassedThrough = typesPassedThrough;    \
2601         if (!needsTypeCheck(_dtc_edge, _dtc_typesPassedThrough))        \
2602             break;                                                      \
2603         typeCheck(_dtc_source, _dtc_edge, _dtc_typesPassedThrough, (jumpToFail), exitKind); \
2604     } while (0)
2605 
2606 #define DFG_TYPE_CHECK(source, edge, typesPassedThrough, jumpToFail) \
2607     DFG_TYPE_CHECK_WITH_EXIT_KIND(BadType, source, edge, typesPassedThrough, jumpToFail)
2608 
2609 } } // namespace JSC::DFG
2610 
2611 #endif
<a name="30" id="anc30"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="30" type="hidden" />
</body>
</html>