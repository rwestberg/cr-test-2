<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2018 Metrological Group B.V.
  3  * Copyright (C) 2018 Igalia S.L. All rights reserved.
  4  *
  5  * This library is free software; you can redistribute it and/or
  6  * modify it under the terms of the GNU Library General Public
  7  * License as published by the Free Software Foundation; either
  8  * version 2 of the License, or (at your option) any later version.
  9  *
 10  * This library is distributed in the hope that it will be useful,
 11  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 12  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 13  * Library General Public License for more details.
 14  *
 15  * You should have received a copy of the GNU Library General Public License
 16  * aint with this library; see the file COPYING.LIB.  If not, write to
 17  * the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
 18  * Boston, MA 02110-1301, USA.
 19  */
 20 
 21 #include &quot;config.h&quot;
 22 
 23 #if ENABLE(VIDEO) &amp;&amp; ENABLE(MEDIA_STREAM) &amp;&amp; USE(LIBWEBRTC) &amp;&amp; USE(GSTREAMER)
 24 #include &quot;GStreamerVideoDecoderFactory.h&quot;
 25 
 26 #include &quot;GStreamerVideoFrameLibWebRTC.h&quot;
 27 #include &quot;webrtc/common_video/h264/h264_common.h&quot;
 28 #include &quot;webrtc/common_video/h264/profile_level_id.h&quot;
 29 #include &quot;webrtc/media/base/codec.h&quot;
 30 #include &quot;webrtc/modules/video_coding/codecs/h264/include/h264.h&quot;
 31 #include &quot;webrtc/modules/video_coding/codecs/vp8/include/vp8.h&quot;
 32 #include &quot;webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_decoder.h&quot;
 33 #include &quot;webrtc/modules/video_coding/include/video_codec_interface.h&quot;
 34 #include &lt;gst/app/gstappsink.h&gt;
 35 #include &lt;gst/app/gstappsrc.h&gt;
 36 #include &lt;gst/video/video.h&gt;
 37 #include &lt;mutex&gt;
 38 #include &lt;wtf/Lock.h&gt;
 39 #include &lt;wtf/StdMap.h&gt;
 40 #include &lt;wtf/glib/RunLoopSourcePriority.h&gt;
 41 #include &lt;wtf/text/WTFString.h&gt;
 42 
 43 GST_DEBUG_CATEGORY(webkit_webrtcdec_debug);
 44 #define GST_CAT_DEFAULT webkit_webrtcdec_debug
 45 
 46 namespace WebCore {
 47 
 48 typedef struct {
 49     uint64_t timestamp;
 50     int64_t renderTimeMs;
 51 } InputTimestamps;
 52 
 53 class GStreamerVideoDecoder : public webrtc::VideoDecoder {
 54 public:
 55     GStreamerVideoDecoder()
 56         : m_pictureId(0)
<a name="1" id="anc1"></a><span class="line-added"> 57         , m_width(0)</span>
<span class="line-added"> 58         , m_height(0)</span>
<span class="line-added"> 59         , m_requireParse(false)</span>
<span class="line-added"> 60         , m_needsKeyframe(true)</span>
 61         , m_firstBufferPts(GST_CLOCK_TIME_NONE)
 62         , m_firstBufferDts(GST_CLOCK_TIME_NONE)
 63     {
 64     }
 65 
 66     static void decodebinPadAddedCb(GstElement*,
 67         GstPad* srcpad,
 68         GstPad* sinkpad)
 69     {
 70         GST_INFO_OBJECT(srcpad, &quot;connecting pad with %&quot; GST_PTR_FORMAT, sinkpad);
 71         if (gst_pad_link(srcpad, sinkpad) != GST_PAD_LINK_OK)
 72             ASSERT_NOT_REACHED();
 73     }
 74 
 75     GstElement* pipeline()
 76     {
 77         return m_pipeline.get();
 78     }
 79 
 80     GstElement* makeElement(const gchar* factoryName)
 81     {
 82         GUniquePtr&lt;char&gt; name(g_strdup_printf(&quot;%s_dec_%s_%p&quot;, Name(), factoryName, this));
 83 
 84         return gst_element_factory_make(factoryName, name.get());
 85     }
 86 
<a name="2" id="anc2"></a><span class="line-modified"> 87     int32_t InitDecode(const webrtc::VideoCodec* codecSettings, int32_t) override</span>
 88     {
 89         m_src = makeElement(&quot;appsrc&quot;);
 90 
<a name="3" id="anc3"></a><span class="line-added"> 91         GRefPtr&lt;GstCaps&gt; caps = nullptr;</span>
 92         auto capsfilter = CreateFilter();
 93         auto decoder = makeElement(&quot;decodebin&quot;);
 94 
<a name="4" id="anc4"></a><span class="line-added"> 95         if (codecSettings) {</span>
<span class="line-added"> 96             m_width = codecSettings-&gt;width;</span>
<span class="line-added"> 97             m_height = codecSettings-&gt;height;</span>
<span class="line-added"> 98         }</span>
<span class="line-added"> 99 </span>
<span class="line-added">100         m_pipeline = makeElement(&quot;pipeline&quot;);</span>
<span class="line-added">101         connectSimpleBusMessageCallback(m_pipeline.get());</span>
<span class="line-added">102 </span>
<span class="line-added">103         auto sinkpad = adoptGRef(gst_element_get_static_pad(capsfilter, &quot;sink&quot;));</span>
<span class="line-added">104         g_signal_connect(decoder, &quot;pad-added&quot;, G_CALLBACK(decodebinPadAddedCb), sinkpad.get());</span>
105         // Make the decoder output &quot;parsed&quot; frames only and let the main decodebin
106         // do the real decoding. This allows us to have optimized decoding/rendering
107         // happening in the main pipeline.
<a name="5" id="anc5"></a><span class="line-modified">108         if (m_requireParse) {</span>
<span class="line-modified">109             caps = gst_caps_new_simple(Caps(), &quot;parsed&quot;, G_TYPE_BOOLEAN, TRUE, nullptr);</span>
<span class="line-modified">110             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));</span>
111 
<a name="6" id="anc6"></a><span class="line-modified">112             gst_bus_enable_sync_message_emission(bus.get());</span>
<span class="line-modified">113             g_signal_connect(bus.get(), &quot;sync-message::warning&quot;,</span>
<span class="line-added">114                 G_CALLBACK(+[](GstBus*, GstMessage* message, GStreamerVideoDecoder* justThis) {</span>
<span class="line-added">115                 GUniqueOutPtr&lt;GError&gt; err;</span>
<span class="line-added">116 </span>
<span class="line-added">117                 switch (GST_MESSAGE_TYPE(message)) {</span>
<span class="line-added">118                 case GST_MESSAGE_WARNING: {</span>
<span class="line-added">119                     gst_message_parse_warning(message, &amp;err.outPtr(), nullptr);</span>
<span class="line-added">120                     FALLTHROUGH;</span>
<span class="line-added">121                 }</span>
<span class="line-added">122                 case GST_MESSAGE_ERROR: {</span>
<span class="line-added">123                     if (!err)</span>
<span class="line-added">124                         gst_message_parse_error(message, &amp;err.outPtr(), nullptr);</span>
<span class="line-added">125 </span>
<span class="line-added">126                     if (g_error_matches(err.get(), GST_STREAM_ERROR, GST_STREAM_ERROR_DECODE)) {</span>
<span class="line-added">127                         GST_INFO_OBJECT(justThis-&gt;pipeline(), &quot;--&gt; needs keyframe (%s)&quot;,</span>
<span class="line-added">128                             err-&gt;message);</span>
<span class="line-added">129                         justThis-&gt;m_needsKeyframe = true;</span>
<span class="line-added">130                     }</span>
<span class="line-added">131                     break;</span>
<span class="line-added">132                 }</span>
<span class="line-added">133                 default:</span>
<span class="line-added">134                     break;</span>
<span class="line-added">135                 }</span>
<span class="line-added">136                 }), this);</span>
<span class="line-added">137         } else {</span>
<span class="line-added">138             /* FIXME - How could we handle missing keyframes case we do not plug parsers ? */</span>
<span class="line-added">139             caps = gst_caps_new_empty_simple(Caps());</span>
<span class="line-added">140         }</span>
<span class="line-added">141         g_object_set(decoder, &quot;caps&quot;, caps.get(), nullptr);</span>
142 
<a name="7" id="anc7"></a><span class="line-modified">143         m_sink = makeElement(&quot;appsink&quot;);</span>
<span class="line-modified">144         gst_app_sink_set_emit_signals(GST_APP_SINK(m_sink), true);</span>
<span class="line-modified">145         // This is an decoder, everything should happen as fast as possible and not</span>

146         // be synced on the clock.
<a name="8" id="anc8"></a><span class="line-modified">147         g_object_set(m_sink, &quot;sync&quot;, false, nullptr);</span>
148 
<a name="9" id="anc9"></a><span class="line-modified">149         gst_bin_add_many(GST_BIN(pipeline()), m_src, decoder, capsfilter, m_sink, nullptr);</span>
150         if (!gst_element_link(m_src, decoder)) {
151             GST_ERROR_OBJECT(pipeline(), &quot;Could not link src to decoder.&quot;);
152             return WEBRTC_VIDEO_CODEC_ERROR;
153         }
154 
<a name="10" id="anc10"></a><span class="line-modified">155         if (!gst_element_link(capsfilter, m_sink)) {</span>
156             GST_ERROR_OBJECT(pipeline(), &quot;Could not link capsfilter to sink.&quot;);
157             return WEBRTC_VIDEO_CODEC_ERROR;
158         }
159 
160         if (gst_element_set_state(pipeline(), GST_STATE_PLAYING) == GST_STATE_CHANGE_FAILURE) {
161             GST_ERROR_OBJECT(pipeline(), &quot;Could not set state to PLAYING.&quot;);
162             return WEBRTC_VIDEO_CODEC_ERROR;
163         }
164 
165         return WEBRTC_VIDEO_CODEC_OK;
166     }
167 
168     int32_t RegisterDecodeCompleteCallback(webrtc::DecodedImageCallback* callback)
169     {
170         m_imageReadyCb = callback;
171 
172         return WEBRTC_VIDEO_CODEC_OK;
173     }
174 
175     virtual GstElement* CreateFilter()
176     {
177         return makeElement(&quot;identity&quot;);
178     }
179 
180     int32_t Release() final
181     {
182         if (m_pipeline.get()) {
183             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
184             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
185 
186             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
187             m_src = nullptr;
<a name="11" id="anc11"></a><span class="line-added">188             m_sink = nullptr;</span>
189             m_pipeline = nullptr;
190         }
191 
192         return WEBRTC_VIDEO_CODEC_OK;
193     }
194 
195     int32_t Decode(const webrtc::EncodedImage&amp; inputImage,
196         bool,
197         const webrtc::CodecSpecificInfo*,
198         int64_t renderTimeMs) override
199     {
<a name="12" id="anc12"></a><span class="line-added">200         if (m_needsKeyframe) {</span>
<span class="line-added">201             if (inputImage._frameType != webrtc::kVideoFrameKey) {</span>
<span class="line-added">202                 GST_ERROR(&quot;Waiting for keyframe but got a delta unit... asking for keyframe&quot;);</span>
<span class="line-added">203                 return WEBRTC_VIDEO_CODEC_ERROR;</span>
<span class="line-added">204             }</span>
<span class="line-added">205             if (inputImage._completeFrame)</span>
<span class="line-added">206                 m_needsKeyframe = false;</span>
<span class="line-added">207             else {</span>
<span class="line-added">208                 GST_ERROR(&quot;Waiting for keyframe but didn&#39;t get full frame, getting out&quot;);</span>
<span class="line-added">209                 return WEBRTC_VIDEO_CODEC_ERROR;</span>
<span class="line-added">210             }</span>
<span class="line-added">211         }</span>
<span class="line-added">212 </span>
<span class="line-added">213 </span>
214         if (!m_src) {
215             GST_ERROR(&quot;No source set, can&#39;t decode.&quot;);
216 
217             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
218         }
219 
220         if (!GST_CLOCK_TIME_IS_VALID(m_firstBufferPts)) {
221             GRefPtr&lt;GstPad&gt; srcpad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
222             m_firstBufferPts = (static_cast&lt;guint64&gt;(renderTimeMs)) * GST_MSECOND;
223             m_firstBufferDts = (static_cast&lt;guint64&gt;(inputImage.Timestamp())) * GST_MSECOND;
224         }
225 
226         // FIXME- Use a GstBufferPool.
227         auto buffer = adoptGRef(gst_buffer_new_wrapped(g_memdup(inputImage._buffer, inputImage._size),
228             inputImage._size));
229         GST_BUFFER_DTS(buffer.get()) = (static_cast&lt;guint64&gt;(inputImage.Timestamp()) * GST_MSECOND) - m_firstBufferDts;
230         GST_BUFFER_PTS(buffer.get()) = (static_cast&lt;guint64&gt;(renderTimeMs) * GST_MSECOND) - m_firstBufferPts;
<a name="13" id="anc13"></a><span class="line-modified">231         InputTimestamps timestamps = {inputImage.Timestamp(), renderTimeMs};</span>
<span class="line-modified">232         m_dtsPtsMap[GST_BUFFER_PTS(buffer.get())] = timestamps;</span>



233 
<a name="14" id="anc14"></a><span class="line-modified">234         GST_LOG_OBJECT(pipeline(), &quot;%&quot; G_GINT64_FORMAT &quot; Decoding: %&quot; GST_PTR_FORMAT, renderTimeMs, buffer.get());</span>
235         auto sample = adoptGRef(gst_sample_new(buffer.get(), GetCapsForFrame(inputImage), nullptr, nullptr));
236         switch (gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get())) {
237         case GST_FLOW_OK:
<a name="15" id="anc15"></a><span class="line-modified">238             break;</span>
239         case GST_FLOW_FLUSHING:
240             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
241         default:
242             return WEBRTC_VIDEO_CODEC_ERROR;
243         }
<a name="16" id="anc16"></a><span class="line-added">244 </span>
<span class="line-added">245         return pullSample();</span>
<span class="line-added">246     }</span>
<span class="line-added">247 </span>
<span class="line-added">248     int32_t pullSample()</span>
<span class="line-added">249     {</span>
<span class="line-added">250         auto sample = gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), GST_SECOND / 30);</span>
<span class="line-added">251         if (!sample) {</span>
<span class="line-added">252             GST_ERROR(&quot;Needs more data&quot;);</span>
<span class="line-added">253             return WEBRTC_VIDEO_CODEC_OK;</span>
<span class="line-added">254         }</span>
<span class="line-added">255         auto buffer = gst_sample_get_buffer(sample);</span>
<span class="line-added">256 </span>
<span class="line-added">257         // Make sure that the frame.timestamp == previsouly input_frame._timeStamp</span>
<span class="line-added">258         // as it is required by the VideoDecoder baseclass.</span>
<span class="line-added">259         auto timestamps = m_dtsPtsMap[GST_BUFFER_PTS(buffer)];</span>
<span class="line-added">260         m_dtsPtsMap.erase(GST_BUFFER_PTS(buffer));</span>
<span class="line-added">261 </span>
<span class="line-added">262         auto frame(LibWebRTCVideoFrameFromGStreamerSample(sample, webrtc::kVideoRotation_0,</span>
<span class="line-added">263             timestamps.timestamp, timestamps.renderTimeMs));</span>
<span class="line-added">264 </span>
<span class="line-added">265         GST_BUFFER_DTS(buffer) = GST_CLOCK_TIME_NONE;</span>
<span class="line-added">266         GST_LOG_OBJECT(pipeline(), &quot;Output decoded frame! %d -&gt; %&quot; GST_PTR_FORMAT,</span>
<span class="line-added">267             frame-&gt;timestamp(), buffer);</span>
<span class="line-added">268 </span>
<span class="line-added">269         m_imageReadyCb-&gt;Decoded(*frame.get(), absl::optional&lt;int32_t&gt;(), absl::optional&lt;uint8_t&gt;());</span>
<span class="line-added">270 </span>
<span class="line-added">271         return WEBRTC_VIDEO_CODEC_OK;</span>
272     }
273 
274     virtual GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image)
275     {
276         if (!m_caps) {
277             m_caps = adoptGRef(gst_caps_new_simple(Caps(),
<a name="17" id="anc17"></a><span class="line-modified">278                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth ? image._encodedWidth : m_width,</span>
<span class="line-modified">279                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight ? image._encodedHeight : m_height,</span>
280                 nullptr));
281         }
282 
283         return m_caps.get();
284     }
285 
286     void AddDecoderIfSupported(std::vector&lt;webrtc::SdpVideoFormat&gt; codecList)
287     {
288         if (HasGstDecoder()) {
289             webrtc::SdpVideoFormat format = ConfigureSupportedDecoder();
290 
291             codecList.push_back(format);
292         }
293     }
294 
295     virtual webrtc::SdpVideoFormat ConfigureSupportedDecoder()
296     {
297         return webrtc::SdpVideoFormat(Name());
298     }
299 
300     static GRefPtr&lt;GstElementFactory&gt; GstDecoderFactory(const char *capsStr)
301     {
302         auto all_decoders = gst_element_factory_list_get_elements(GST_ELEMENT_FACTORY_TYPE_DECODER,
303             GST_RANK_MARGINAL);
304         auto caps = adoptGRef(gst_caps_from_string(capsStr));
305         auto decoders = gst_element_factory_list_filter(all_decoders,
306             caps.get(), GST_PAD_SINK, FALSE);
307 
308         gst_plugin_feature_list_free(all_decoders);
309         GRefPtr&lt;GstElementFactory&gt; res;
310         if (decoders)
311             res = GST_ELEMENT_FACTORY(decoders-&gt;data);
312         gst_plugin_feature_list_free(decoders);
313 
314         return res;
315     }
316 
317     bool HasGstDecoder()
318     {
319         return GstDecoderFactory(Caps());
320     }
321 
<a name="18" id="anc18"></a>























322     virtual const gchar* Caps() = 0;
323     virtual webrtc::VideoCodecType CodecType() = 0;
324     const char* ImplementationName() const { return &quot;GStreamer&quot;; }
325     virtual const gchar* Name() = 0;
326 
327 protected:
328     GRefPtr&lt;GstCaps&gt; m_caps;
329     gint m_pictureId;
<a name="19" id="anc19"></a><span class="line-added">330     gint m_width;</span>
<span class="line-added">331     gint m_height;</span>
<span class="line-added">332     bool m_requireParse = false;</span>
<span class="line-added">333     bool m_needsKeyframe;</span>
334 
335 private:
<a name="20" id="anc20"></a>




336     GRefPtr&lt;GstElement&gt; m_pipeline;
<a name="21" id="anc21"></a><span class="line-added">337     GstElement* m_sink;</span>
338     GstElement* m_src;
339 
340     GstVideoInfo m_info;
341     webrtc::DecodedImageCallback* m_imageReadyCb;
342 
<a name="22" id="anc22"></a>
343     StdMap&lt;GstClockTime, InputTimestamps&gt; m_dtsPtsMap;
344     GstClockTime m_firstBufferPts;
345     GstClockTime m_firstBufferDts;
346 };
347 
348 class H264Decoder : public GStreamerVideoDecoder {
349 public:
<a name="23" id="anc23"></a><span class="line-modified">350     H264Decoder() { m_requireParse = true; }</span>
351 
352     int32_t InitDecode(const webrtc::VideoCodec* codecInfo, int32_t nCores) final
353     {
354         if (codecInfo &amp;&amp; codecInfo-&gt;codecType != webrtc::kVideoCodecH264)
355             return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
356 
357         m_profile = nullptr;
358         if (codecInfo) {
359             auto h264Info = codecInfo-&gt;H264();
360 
361             switch (h264Info.profile) {
362             case webrtc::H264::kProfileConstrainedBaseline:
363                 m_profile = &quot;constrained-baseline&quot;;
364                 break;
365             case webrtc::H264::kProfileBaseline:
366                 m_profile = &quot;baseline&quot;;
367                 break;
368             case webrtc::H264::kProfileMain:
369                 m_profile = &quot;main&quot;;
370                 break;
371             case webrtc::H264::kProfileConstrainedHigh:
372                 m_profile = &quot;constrained-high&quot;;
373                 break;
374             case webrtc::H264::kProfileHigh:
375                 m_profile = &quot;high&quot;;
376                 break;
377             }
378         }
379 
380         return GStreamerVideoDecoder::InitDecode(codecInfo, nCores);
381     }
382 
383     GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image) final
384     {
385         if (!m_caps) {
386             m_caps = adoptGRef(gst_caps_new_simple(Caps(),
<a name="24" id="anc24"></a><span class="line-modified">387                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth ? image._encodedWidth : m_width,</span>
<span class="line-modified">388                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight ? image._encodedHeight : m_height,</span>


389                 &quot;alignment&quot;, G_TYPE_STRING, &quot;au&quot;,
390                 nullptr));
391         }
392 
393         return m_caps.get();
394     }
395     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
396     const gchar* Name() final { return cricket::kH264CodecName; }
397     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
398 
399 private:
400     const gchar* m_profile;
401 };
402 
403 class VP8Decoder : public GStreamerVideoDecoder {
404 public:
405     VP8Decoder() { }
406     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
407     const gchar* Name() final { return cricket::kVp8CodecName; }
408     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
409     static std::unique_ptr&lt;webrtc::VideoDecoder&gt; Create()
410     {
411         auto factory = GstDecoderFactory(&quot;video/x-vp8&quot;);
412 
413         if (factory &amp;&amp; !g_strcmp0(GST_OBJECT_NAME(GST_OBJECT(factory.get())), &quot;vp8dec&quot;)) {
414             GST_INFO(&quot;Our best GStreamer VP8 decoder is vp8dec, better use the one from LibWebRTC&quot;);
415 
416             return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(new webrtc::LibvpxVp8Decoder());
417         }
418 
419         return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(new VP8Decoder());
420     }
421 };
422 
423 std::unique_ptr&lt;webrtc::VideoDecoder&gt; GStreamerVideoDecoderFactory::CreateVideoDecoder(const webrtc::SdpVideoFormat&amp; format)
424 {
425     webrtc::VideoDecoder* dec;
426 
427     if (format.name == cricket::kH264CodecName)
428         dec = new H264Decoder();
429     else if (format.name == cricket::kVp8CodecName)
430         return VP8Decoder::Create();
431     else {
432         GST_ERROR(&quot;Could not create decoder for %s&quot;, format.name.c_str());
433 
434         return nullptr;
435     }
436 
437     return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(dec);
438 }
439 
440 GStreamerVideoDecoderFactory::GStreamerVideoDecoderFactory()
441 {
442     static std::once_flag debugRegisteredFlag;
443 
444     std::call_once(debugRegisteredFlag, [] {
445         GST_DEBUG_CATEGORY_INIT(webkit_webrtcdec_debug, &quot;webkitlibwebrtcvideodecoder&quot;, 0, &quot;WebKit WebRTC video decoder&quot;);
446     });
447 }
448 std::vector&lt;webrtc::SdpVideoFormat&gt; GStreamerVideoDecoderFactory::GetSupportedFormats() const
449 {
450     std::vector&lt;webrtc::SdpVideoFormat&gt; formats;
451 
452     VP8Decoder().AddDecoderIfSupported(formats);
453     H264Decoder().AddDecoderIfSupported(formats);
454 
455     return formats;
456 }
457 }
458 #endif
<a name="25" id="anc25"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="25" type="hidden" />
</body>
</html>