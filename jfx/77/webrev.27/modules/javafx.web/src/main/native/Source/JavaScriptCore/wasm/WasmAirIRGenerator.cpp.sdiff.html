<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/wasm/WasmAirIRGenerator.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="../tools/VMInspector.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="WasmB3IRGenerator.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/wasm/WasmAirIRGenerator.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;WasmAirIRGenerator.h&quot;
  28 
  29 #if ENABLE(WEBASSEMBLY)
  30 
  31 #include &quot;AirCode.h&quot;
  32 #include &quot;AirGenerate.h&quot;
  33 #include &quot;AirOpcodeUtils.h&quot;
  34 #include &quot;AirValidate.h&quot;
  35 #include &quot;AllowMacroScratchRegisterUsageIf.h&quot;
  36 #include &quot;B3CCallValue.h&quot;
  37 #include &quot;B3CheckSpecial.h&quot;
  38 #include &quot;B3CheckValue.h&quot;
  39 #include &quot;B3PatchpointSpecial.h&quot;
  40 #include &quot;B3Procedure.h&quot;
  41 #include &quot;B3ProcedureInlines.h&quot;
  42 #include &quot;BinarySwitch.h&quot;



  43 #include &quot;ScratchRegisterAllocator.h&quot;
  44 #include &quot;VirtualRegister.h&quot;
  45 #include &quot;WasmCallingConvention.h&quot;
  46 #include &quot;WasmContextInlines.h&quot;
  47 #include &quot;WasmExceptionType.h&quot;
  48 #include &quot;WasmFunctionParser.h&quot;
  49 #include &quot;WasmInstance.h&quot;
  50 #include &quot;WasmMemory.h&quot;
  51 #include &quot;WasmOMGPlan.h&quot;

  52 #include &quot;WasmOpcodeOrigin.h&quot;

  53 #include &quot;WasmSignatureInlines.h&quot;
  54 #include &quot;WasmThunks.h&quot;
  55 #include &lt;limits&gt;
  56 #include &lt;wtf/Box.h&gt;
  57 #include &lt;wtf/Optional.h&gt;
  58 #include &lt;wtf/StdLibExtras.h&gt;
  59 
  60 namespace JSC { namespace Wasm {
  61 
  62 using namespace B3::Air;
  63 
  64 struct ConstrainedTmp {
  65     ConstrainedTmp(Tmp tmp)
  66         : ConstrainedTmp(tmp, tmp.isReg() ? B3::ValueRep::reg(tmp.reg()) : B3::ValueRep::SomeRegister)
  67     { }
  68 
  69     ConstrainedTmp(Tmp tmp, B3::ValueRep rep)
  70         : tmp(tmp)
  71         , rep(rep)
  72     {
</pre>
<hr />
<pre>
 183 
 184         ResultList resultForBranch() const
 185         {
 186             if (type() == BlockType::Loop)
 187                 return ResultList();
 188             return result;
 189         }
 190 
 191     private:
 192         friend class AirIRGenerator;
 193         BlockType blockType;
 194         BasicBlock* continuation;
 195         BasicBlock* special;
 196         ResultList result;
 197         Type returnType;
 198     };
 199 
 200     using ExpressionType = TypedTmp;
 201     using ControlType = ControlData;
 202     using ExpressionList = Vector&lt;ExpressionType, 1&gt;;

 203     using ResultList = ControlData::ResultList;
 204     using ControlEntry = FunctionParser&lt;AirIRGenerator&gt;::ControlEntry;
 205 
 206     static ExpressionType emptyExpression() { return { }; };

 207 
 208     using ErrorType = String;
 209     using UnexpectedResult = Unexpected&lt;ErrorType&gt;;
 210     using Result = Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, ErrorType&gt;;
 211     using PartialResult = Expected&lt;void, ErrorType&gt;;
 212 
 213     template &lt;typename ...Args&gt;
 214     NEVER_INLINE UnexpectedResult WARN_UNUSED_RETURN fail(Args... args) const
 215     {
 216         using namespace FailureHelper; // See ADL comment in WasmParser.h.
 217         return UnexpectedResult(makeString(&quot;WebAssembly.Module failed compiling: &quot;_s, makeString(args)...));
 218     }
 219 
 220 #define WASM_COMPILE_FAIL_IF(condition, ...) do { \
 221         if (UNLIKELY(condition))                  \
 222             return fail(__VA_ARGS__);             \
 223     } while (0)
 224 
 225     AirIRGenerator(const ModuleInformation&amp;, B3::Procedure&amp;, InternalFunction*, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp;, MemoryMode, unsigned functionIndex, TierUpCount*, ThrowWasmException, const Signature&amp;);
 226 
 227     PartialResult WARN_UNUSED_RETURN addArguments(const Signature&amp;);
 228     PartialResult WARN_UNUSED_RETURN addLocal(Type, uint32_t);
 229     ExpressionType addConstant(Type, uint64_t);
 230     ExpressionType addConstant(BasicBlock*, Type, uint64_t);
 231 











 232     // Locals
 233     PartialResult WARN_UNUSED_RETURN getLocal(uint32_t index, ExpressionType&amp; result);
 234     PartialResult WARN_UNUSED_RETURN setLocal(uint32_t index, ExpressionType value);
 235 
 236     // Globals
 237     PartialResult WARN_UNUSED_RETURN getGlobal(uint32_t index, ExpressionType&amp; result);
 238     PartialResult WARN_UNUSED_RETURN setGlobal(uint32_t index, ExpressionType value);
 239 
 240     // Memory
 241     PartialResult WARN_UNUSED_RETURN load(LoadOpType, ExpressionType pointer, ExpressionType&amp; result, uint32_t offset);
 242     PartialResult WARN_UNUSED_RETURN store(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 243     PartialResult WARN_UNUSED_RETURN addGrowMemory(ExpressionType delta, ExpressionType&amp; result);
 244     PartialResult WARN_UNUSED_RETURN addCurrentMemory(ExpressionType&amp; result);
 245 
 246     // Basic operators
 247     template&lt;OpType&gt;
 248     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType arg, ExpressionType&amp; result);
 249     template&lt;OpType&gt;
 250     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType left, ExpressionType right, ExpressionType&amp; result);
 251     PartialResult WARN_UNUSED_RETURN addSelect(ExpressionType condition, ExpressionType nonZero, ExpressionType zero, ExpressionType&amp; result);
 252 
 253     // Control flow
 254     ControlData WARN_UNUSED_RETURN addTopLevel(Type signature);
 255     ControlData WARN_UNUSED_RETURN addBlock(Type signature);
<span class="line-modified"> 256     ControlData WARN_UNUSED_RETURN addLoop(Type signature);</span>
 257     PartialResult WARN_UNUSED_RETURN addIf(ExpressionType condition, Type signature, ControlData&amp; result);
<span class="line-modified"> 258     PartialResult WARN_UNUSED_RETURN addElse(ControlData&amp;, const ExpressionList&amp;);</span>
 259     PartialResult WARN_UNUSED_RETURN addElseToUnreachable(ControlData&amp;);
 260 
 261     PartialResult WARN_UNUSED_RETURN addReturn(const ControlData&amp;, const ExpressionList&amp; returnValues);
<span class="line-modified"> 262     PartialResult WARN_UNUSED_RETURN addBranch(ControlData&amp;, ExpressionType condition, const ExpressionList&amp; returnValues);</span>
<span class="line-modified"> 263     PartialResult WARN_UNUSED_RETURN addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTargets, const ExpressionList&amp; expressionStack);</span>
<span class="line-modified"> 264     PartialResult WARN_UNUSED_RETURN endBlock(ControlEntry&amp;, ExpressionList&amp; expressionStack);</span>
 265     PartialResult WARN_UNUSED_RETURN addEndToUnreachable(ControlEntry&amp;);
 266 
 267     // Calls
 268     PartialResult WARN_UNUSED_RETURN addCall(uint32_t calleeIndex, const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result);
<span class="line-modified"> 269     PartialResult WARN_UNUSED_RETURN addCallIndirect(const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result);</span>
 270     PartialResult WARN_UNUSED_RETURN addUnreachable();
 271 
 272     PartialResult addShift(Type, B3::Air::Opcode, ExpressionType value, ExpressionType shift, ExpressionType&amp; result);
 273     PartialResult addIntegerSub(B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 274     PartialResult addFloatingPointAbs(B3::Air::Opcode, ExpressionType value, ExpressionType&amp; result);
 275     PartialResult addFloatingPointBinOp(Type, B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 276 
<span class="line-modified"> 277     void dump(const Vector&lt;ControlEntry&gt;&amp; controlStack, const ExpressionList* expressionStack);</span>
 278     void setParser(FunctionParser&lt;AirIRGenerator&gt;* parser) { m_parser = parser; };
 279 
 280     static Vector&lt;Tmp&gt; toTmpVector(const Vector&lt;TypedTmp&gt;&amp; vector)
 281     {
 282         Vector&lt;Tmp&gt; result;
 283         for (const auto&amp; item : vector)
 284             result.append(item.tmp());
 285         return result;
 286     }
 287 
 288     ALWAYS_INLINE void didKill(const ExpressionType&amp; typedTmp)
 289     {
 290         Tmp tmp = typedTmp.tmp();
 291         if (!tmp)
 292             return;
 293         if (tmp.isGP())
 294             m_freeGPs.append(tmp);
 295         else
 296             m_freeFPs.append(tmp);
 297     }
 298 





 299 private:
 300     ALWAYS_INLINE void validateInst(Inst&amp; inst)
 301     {
 302         if (!ASSERT_DISABLED) {
 303             if (!inst.isValidForm()) {
 304                 dataLogLn(inst);
 305                 CRASH();
 306             }
 307         }
 308     }
 309 
 310     static Arg extractArg(const TypedTmp&amp; tmp) { return tmp.tmp(); }
 311     static Arg extractArg(const Tmp&amp; tmp) { return Arg(tmp); }
 312     static Arg extractArg(const Arg&amp; arg) { return arg; }
 313 
 314     template&lt;typename... Arguments&gt;
 315     void append(BasicBlock* block, Kind kind, Arguments&amp;&amp;... arguments)
 316     {
 317         // FIXME: Find a way to use origin here.
 318         auto&amp; inst = block-&gt;append(kind, nullptr, extractArg(arguments)...);
</pre>
<hr />
<pre>
 333         append(m_currentBlock, kind, std::forward&lt;Arguments&gt;(arguments)...);
 334     }
 335 
 336     Tmp newTmp(B3::Bank bank)
 337     {
 338         switch (bank) {
 339         case B3::GP:
 340             if (m_freeGPs.size())
 341                 return m_freeGPs.takeLast();
 342             break;
 343         case B3::FP:
 344             if (m_freeFPs.size())
 345                 return m_freeFPs.takeLast();
 346             break;
 347         }
 348         return m_code.newTmp(bank);
 349     }
 350 
 351     TypedTmp g32() { return { newTmp(B3::GP), Type::I32 }; }
 352     TypedTmp g64() { return { newTmp(B3::GP), Type::I64 }; }


 353     TypedTmp f32() { return { newTmp(B3::FP), Type::F32 }; }
 354     TypedTmp f64() { return { newTmp(B3::FP), Type::F64 }; }
 355 
 356     TypedTmp tmpForType(Type type)
 357     {
 358         switch (type) {
 359         case Type::I32:
 360             return g32();
 361         case Type::I64:
 362             return g64();




 363         case Type::F32:
 364             return f32();
 365         case Type::F64:
 366             return f64();
 367         case Type::Void:
 368             return { };
 369         default:
 370             RELEASE_ASSERT_NOT_REACHED();
 371         }
 372     }
 373 
 374     B3::PatchpointValue* addPatchpoint(B3::Type type)
 375     {
<span class="line-modified"> 376         return m_proc.add&lt;B3::PatchpointValue&gt;(type, B3::Origin());</span>



 377     }
 378 
 379     template &lt;typename ...Args&gt;
 380     void emitPatchpoint(B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 381     {
 382         emitPatchpoint(m_currentBlock, patch, result, std::forward&lt;Args&gt;(theArgs)...);
 383     }
 384 
 385     template &lt;typename ...Args&gt;
 386     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 387     {
 388         emitPatchpoint(basicBlock, patch, result, Vector&lt;ConstrainedTmp, sizeof...(Args)&gt;::from(theArgs...));
 389     }
 390 
 391     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result)
 392     {
 393         emitPatchpoint(basicBlock, patch, result, Vector&lt;ConstrainedTmp&gt;());
 394     }
 395 
 396     template &lt;size_t inlineSize&gt;
 397     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Vector&lt;ConstrainedTmp, inlineSize&gt;&amp;&amp; args)
 398     {
 399         if (!m_patchpointSpecial)
<span class="line-modified"> 400             m_patchpointSpecial = static_cast&lt;B3::PatchpointSpecial*&gt;(m_code.addSpecial(std::make_unique&lt;B3::PatchpointSpecial&gt;()));</span>
 401 
 402         Inst inst(Patch, patch, Arg::special(m_patchpointSpecial));
 403         Inst resultMov;
 404         if (result) {
 405             ASSERT(patch-&gt;type() != B3::Void);
<span class="line-modified"> 406             switch (patch-&gt;resultConstraint.kind()) {</span>
 407             case B3::ValueRep::Register:
<span class="line-modified"> 408                 inst.args.append(Tmp(patch-&gt;resultConstraint.reg()));</span>
<span class="line-modified"> 409                 resultMov = Inst(result.isGP() ? Move : MoveDouble, nullptr, Tmp(patch-&gt;resultConstraint.reg()), result);</span>
 410                 break;
 411             case B3::ValueRep::SomeRegister:
 412                 inst.args.append(result);
 413                 break;
 414             default:
 415                 RELEASE_ASSERT_NOT_REACHED();
 416             }
 417         } else
 418             ASSERT(patch-&gt;type() == B3::Void);
 419 
 420         for (ConstrainedTmp&amp; tmp : args) {
 421             // FIXME: This is less than ideal to create dummy values just to satisfy Air&#39;s
 422             // validation. We should abstrcat Patch enough so ValueRep&#39;s don&#39;t need to be
 423             // backed by Values.
 424             // https://bugs.webkit.org/show_bug.cgi?id=194040
 425             B3::Value* dummyValue = m_proc.addConstant(B3::Origin(), tmp.tmp.isGP() ? B3::Int64 : B3::Double, 0);
 426             patch-&gt;append(dummyValue, tmp.rep);
 427             switch (tmp.rep.kind()) {

 428             case B3::ValueRep::SomeRegister:
 429                 inst.args.append(tmp.tmp);
 430                 break;
 431             case B3::ValueRep::Register:
 432                 patch-&gt;earlyClobbered().clear(tmp.rep.reg());
 433                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, tmp.rep.reg());
 434                 inst.args.append(Tmp(tmp.rep.reg()));
 435                 break;
 436             case B3::ValueRep::StackArgument: {
 437                 auto arg = Arg::callArg(tmp.rep.offsetFromSP());
 438                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, arg);
 439                 inst.args.append(arg);
 440                 break;
 441             }
 442             default:
 443                 RELEASE_ASSERT_NOT_REACHED();
 444             }
 445         }
 446 
<span class="line-modified"> 447         if (patch-&gt;resultConstraint.isReg())</span>
<span class="line-modified"> 448             patch-&gt;lateClobbered().clear(patch-&gt;resultConstraint.reg());</span>
 449         for (unsigned i = patch-&gt;numGPScratchRegisters; i--;)
 450             inst.args.append(g64().tmp());
 451         for (unsigned i = patch-&gt;numFPScratchRegisters; i--;)
 452             inst.args.append(f64().tmp());
 453 
 454         validateInst(inst);
 455         basicBlock-&gt;append(WTFMove(inst));
 456         if (resultMov) {
 457             validateInst(resultMov);
 458             basicBlock-&gt;append(WTFMove(resultMov));
 459         }
 460     }
 461 
 462     template &lt;typename Branch, typename Generator&gt;
 463     void emitCheck(const Branch&amp; makeBranch, const Generator&amp; generator)
 464     {
 465         // We fail along the truthy edge of &#39;branch&#39;.
 466         Inst branch = makeBranch();
 467 
 468         // FIXME: Make a hashmap of these.
 469         B3::CheckSpecial::Key key(branch);
<span class="line-modified"> 470         B3::CheckSpecial* special = static_cast&lt;B3::CheckSpecial*&gt;(m_code.addSpecial(std::make_unique&lt;B3::CheckSpecial&gt;(key)));</span>
 471 
 472         // FIXME: Remove the need for dummy values
 473         // https://bugs.webkit.org/show_bug.cgi?id=194040
 474         B3::Value* dummyPredicate = m_proc.addConstant(B3::Origin(), B3::Int32, 42);
 475         B3::CheckValue* checkValue = m_proc.add&lt;B3::CheckValue&gt;(B3::Check, B3::Origin(), dummyPredicate);
 476         checkValue-&gt;setGenerator(generator);
 477 
 478         Inst inst(Patch, checkValue, Arg::special(special));
 479         inst.args.appendVector(branch.args);
 480         m_currentBlock-&gt;append(WTFMove(inst));
 481     }
 482 
 483     template &lt;typename Func, typename ...Args&gt;
 484     void emitCCall(Func func, TypedTmp result, Args... args)
 485     {
 486         emitCCall(m_currentBlock, func, result, std::forward&lt;Args&gt;(args)...);
 487     }
 488     template &lt;typename Func, typename ...Args&gt;
 489     void emitCCall(BasicBlock* block, Func func, TypedTmp result, Args... theArgs)
 490     {
 491         B3::Type resultType = B3::Void;
 492         if (result) {
 493             switch (result.type()) {
 494             case Type::I32:
 495                 resultType = B3::Int32;
 496                 break;
 497             case Type::I64:


 498                 resultType = B3::Int64;
 499                 break;
 500             case Type::F32:
 501                 resultType = B3::Float;
 502                 break;
 503             case Type::F64:
 504                 resultType = B3::Double;
 505                 break;
 506             default:
 507                 RELEASE_ASSERT_NOT_REACHED();
 508             }
 509         }
 510 
 511         auto makeDummyValue = [&amp;] (Tmp tmp) {
 512             // FIXME: This is less than ideal to create dummy values just to satisfy Air&#39;s
 513             // validation. We should abstrcat CCall enough so we&#39;re not reliant on arguments
 514             // to the B3::CCallValue.
 515             // https://bugs.webkit.org/show_bug.cgi?id=194040
 516             if (tmp.isGP())
 517                 return m_proc.addConstant(B3::Origin(), B3::Int64, 0);
 518             return m_proc.addConstant(B3::Origin(), B3::Double, 0);
 519         };
 520 
 521         B3::Value* dummyFunc = m_proc.addConstant(B3::Origin(), B3::Int64, bitwise_cast&lt;uintptr_t&gt;(func));
 522         B3::Value* origin = m_proc.add&lt;B3::CCallValue&gt;(resultType, B3::Origin(), B3::Effects::none(), dummyFunc, makeDummyValue(theArgs)...);
 523 
 524         Inst inst(CCall, origin);
 525 
 526         Tmp callee = g64();
<span class="line-modified"> 527         append(Move, Arg::immPtr(tagCFunctionPtr&lt;void*&gt;(func, B3CCallPtrTag)), callee);</span>
 528         inst.args.append(callee);
 529 
 530         if (result)
 531             inst.args.append(result.tmp());
 532 
 533         for (Tmp tmp : Vector&lt;Tmp, sizeof...(Args)&gt;::from(theArgs.tmp()...))
 534             inst.args.append(tmp);
 535 
 536         block-&gt;append(WTFMove(inst));
 537     }
 538 
 539     static B3::Air::Opcode moveOpForValueType(Type type)
 540     {
 541         switch (type) {
 542         case Type::I32:
 543             return Move32;
 544         case Type::I64:


 545             return Move;
 546         case Type::F32:
 547             return MoveFloat;
 548         case Type::F64:
 549             return MoveDouble;
 550         default:
 551             RELEASE_ASSERT_NOT_REACHED();
 552         }
 553     }
 554 
 555     void emitThrowException(CCallHelpers&amp;, ExceptionType);
 556 
<span class="line-modified"> 557     void emitTierUpCheck(uint32_t decrementCount, B3::Origin);</span>

 558 

 559     ExpressionType emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOp);
 560     ExpressionType emitLoadOp(LoadOpType, ExpressionType pointer, uint32_t offset);
 561     void emitStoreOp(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 562 
 563     void unify(const ExpressionType&amp; dst, const ExpressionType&amp; source);
<span class="line-modified"> 564     void unifyValuesWithBlock(const ExpressionList&amp; resultStack, const ResultList&amp; stack);</span>
 565 
 566     template &lt;typename IntType&gt;
 567     void emitChecksForModOrDiv(bool isSignedDiv, ExpressionType left, ExpressionType right);
 568 
 569     template &lt;typename IntType&gt;
 570     void emitModOrDiv(bool isDiv, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 571 




 572     int32_t WARN_UNUSED_RETURN fixupPointerPlusOffset(ExpressionType&amp;, uint32_t);
 573 
 574     void restoreWasmContextInstance(BasicBlock*, TypedTmp);
 575     enum class RestoreCachedStackLimit { No, Yes };
 576     void restoreWebAssemblyGlobalState(RestoreCachedStackLimit, const MemoryInformation&amp;, TypedTmp instance, BasicBlock*);
 577 
 578     B3::Origin origin();
 579 







 580     FunctionParser&lt;AirIRGenerator&gt;* m_parser { nullptr };
 581     const ModuleInformation&amp; m_info;
 582     const MemoryMode m_mode { MemoryMode::BoundsChecking };
 583     const unsigned m_functionIndex { UINT_MAX };
<span class="line-modified"> 584     const TierUpCount* m_tierUp { nullptr };</span>
 585 
 586     B3::Procedure&amp; m_proc;
 587     Code&amp; m_code;

 588     BasicBlock* m_currentBlock { nullptr };
 589     BasicBlock* m_rootBlock { nullptr };
 590     Vector&lt;TypedTmp&gt; m_locals;
 591     Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; m_unlinkedWasmToWasmCalls; // List each call site and the function index whose address it should be patched with.
 592     GPRReg m_memoryBaseGPR { InvalidGPRReg };
 593     GPRReg m_memorySizeGPR { InvalidGPRReg };
 594     GPRReg m_wasmContextInstanceGPR { InvalidGPRReg };
 595     bool m_makesCalls { false };
 596 
 597     Vector&lt;Tmp, 8&gt; m_freeGPs;
 598     Vector&lt;Tmp, 8&gt; m_freeFPs;
 599 



 600     TypedTmp m_instanceValue; // Always use the accessor below to ensure the instance value is materialized when used.
 601     bool m_usesInstanceValue { false };
 602     TypedTmp instanceValue()
 603     {
 604         m_usesInstanceValue = true;
 605         return m_instanceValue;
 606     }
 607 
 608     uint32_t m_maxNumJSCallArguments { 0 };

 609 
 610     B3::PatchpointSpecial* m_patchpointSpecial { nullptr };
 611 };
 612 
 613 // Memory accesses in WebAssembly have unsigned 32-bit offsets, whereas they have signed 32-bit offsets in B3.
 614 int32_t AirIRGenerator::fixupPointerPlusOffset(ExpressionType&amp; ptr, uint32_t offset)
 615 {
 616     if (static_cast&lt;uint64_t&gt;(offset) &gt; static_cast&lt;uint64_t&gt;(std::numeric_limits&lt;int32_t&gt;::max())) {
 617         auto previousPtr = ptr;
 618         ptr = g64();
 619         auto constant = g64();
 620         append(Move, Arg::bigImm(offset), constant);
 621         append(Add64, constant, previousPtr, ptr);
 622         return 0;
 623     }
 624     return offset;
 625 }
 626 
 627 void AirIRGenerator::restoreWasmContextInstance(BasicBlock* block, TypedTmp instance)
 628 {
</pre>
<hr />
<pre>
 644     B3::Effects effects = B3::Effects::none();
 645     effects.writesPinned = true;
 646     effects.reads = B3::HeapRange::top();
 647     patchpoint-&gt;effects = effects;
 648     patchpoint-&gt;clobberLate(RegisterSet(m_wasmContextInstanceGPR));
 649     GPRReg wasmContextInstanceGPR = m_wasmContextInstanceGPR;
 650     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; param) {
 651         jit.move(param[0].gpr(), wasmContextInstanceGPR);
 652     });
 653     emitPatchpoint(block, patchpoint, Tmp(), instance);
 654 }
 655 
 656 AirIRGenerator::AirIRGenerator(const ModuleInformation&amp; info, B3::Procedure&amp; procedure, InternalFunction* compilation, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, MemoryMode mode, unsigned functionIndex, TierUpCount* tierUp, ThrowWasmException throwWasmException, const Signature&amp; signature)
 657     : m_info(info)
 658     , m_mode(mode)
 659     , m_functionIndex(functionIndex)
 660     , m_tierUp(tierUp)
 661     , m_proc(procedure)
 662     , m_code(m_proc.code())
 663     , m_unlinkedWasmToWasmCalls(unlinkedWasmToWasmCalls)

 664 {
 665     m_currentBlock = m_code.addBlock();
 666     m_rootBlock = m_currentBlock;
 667 
 668     // FIXME we don&#39;t really need to pin registers here if there&#39;s no memory. It makes wasm -&gt; wasm thunks simpler for now. https://bugs.webkit.org/show_bug.cgi?id=166623
 669     const PinnedRegisterInfo&amp; pinnedRegs = PinnedRegisterInfo::get();
 670 
 671     m_memoryBaseGPR = pinnedRegs.baseMemoryPointer;
 672     m_code.pinRegister(m_memoryBaseGPR);
 673 
 674     m_wasmContextInstanceGPR = pinnedRegs.wasmContextInstancePointer;
 675     if (!Context::useFastTLS())
 676         m_code.pinRegister(m_wasmContextInstanceGPR);
 677 
 678     if (mode != MemoryMode::Signaling) {
<span class="line-modified"> 679         ASSERT(!pinnedRegs.sizeRegisters[0].sizeOffset);</span>
<span class="line-modified"> 680         m_memorySizeGPR = pinnedRegs.sizeRegisters[0].sizeRegister;</span>
<span class="line-removed"> 681         for (const PinnedSizeRegisterInfo&amp; regInfo : pinnedRegs.sizeRegisters)</span>
<span class="line-removed"> 682             m_code.pinRegister(regInfo.sizeRegister);</span>
 683     }
 684 
 685     if (throwWasmException)
 686         Thunks::singleton().setThrowWasmException(throwWasmException);
 687 
 688     if (info.memory) {
 689         switch (m_mode) {
 690         case MemoryMode::BoundsChecking:
 691             break;
 692         case MemoryMode::Signaling:
 693             // Most memory accesses in signaling mode don&#39;t do an explicit
 694             // exception check because they can rely on fault handling to detect
 695             // out-of-bounds accesses. FaultSignalHandler nonetheless needs the
 696             // thunk to exist so that it can jump to that thunk.
 697             if (UNLIKELY(!Thunks::singleton().stub(throwExceptionFromWasmThunkGenerator)))
 698                 CRASH();
 699             break;
 700         }
 701     }
 702 
</pre>
<hr />
<pre>
 766     if (Context::useFastTLS()) {
 767         m_instanceValue = g64();
 768         // FIXME: Would be nice to only do this if we use instance value.
 769         append(Move, Tmp(contextInstance), m_instanceValue);
 770     } else
 771         m_instanceValue = { Tmp(contextInstance), Type::I64 };
 772 
 773     ASSERT(!m_locals.size());
 774     m_locals.grow(signature.argumentCount());
 775     for (unsigned i = 0; i &lt; signature.argumentCount(); ++i) {
 776         Type type = signature.argument(i);
 777         m_locals[i] = tmpForType(type);
 778     }
 779 
 780     wasmCallingConventionAir().loadArguments(signature, [&amp;] (const Arg&amp; arg, unsigned i) {
 781         switch (signature.argument(i)) {
 782         case Type::I32:
 783             append(Move32, arg, m_locals[i]);
 784             break;
 785         case Type::I64:


 786             append(Move, arg, m_locals[i]);
 787             break;
 788         case Type::F32:
 789             append(MoveFloat, arg, m_locals[i]);
 790             break;
 791         case Type::F64:
 792             append(MoveDouble, arg, m_locals[i]);
 793             break;
 794         default:
 795             RELEASE_ASSERT_NOT_REACHED();
 796         }
 797     });
 798 
<span class="line-modified"> 799     emitTierUpCheck(TierUpCount::functionEntryDecrement(), B3::Origin());</span>
 800 }
 801 
 802 void AirIRGenerator::restoreWebAssemblyGlobalState(RestoreCachedStackLimit restoreCachedStackLimit, const MemoryInformation&amp; memory, TypedTmp instance, BasicBlock* block)
 803 {
 804     restoreWasmContextInstance(block, instance);
 805 
 806     if (restoreCachedStackLimit == RestoreCachedStackLimit::Yes) {
 807         // The Instance caches the stack limit, but also knows where its canonical location is.
 808         static_assert(sizeof(decltype(static_cast&lt;Instance*&gt;(nullptr)-&gt;cachedStackLimit())) == sizeof(uint64_t), &quot;&quot;);
 809 
 810         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfPointerToActualStackLimit(), B3::Width64));
 811         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfCachedStackLimit(), B3::Width64));
 812         auto temp = g64();
 813         append(block, Move, Arg::addr(instanceValue(), Instance::offsetOfPointerToActualStackLimit()), temp);
 814         append(block, Move, Arg::addr(temp), temp);
 815         append(block, Move, temp, Arg::addr(instanceValue(), Instance::offsetOfCachedStackLimit()));
 816     }
 817 
 818     if (!!memory) {
 819         const PinnedRegisterInfo* pinnedRegs = &amp;PinnedRegisterInfo::get();
 820         RegisterSet clobbers;
 821         clobbers.set(pinnedRegs-&gt;baseMemoryPointer);
<span class="line-modified"> 822         for (auto info : pinnedRegs-&gt;sizeRegisters)</span>
<span class="line-modified"> 823             clobbers.set(info.sizeRegister);</span>

 824 
 825         auto* patchpoint = addPatchpoint(B3::Void);
 826         B3::Effects effects = B3::Effects::none();
 827         effects.writesPinned = true;
 828         effects.reads = B3::HeapRange::top();
 829         patchpoint-&gt;effects = effects;
 830         patchpoint-&gt;clobber(clobbers);

 831 
 832         patchpoint-&gt;setGenerator([pinnedRegs] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {

 833             GPRReg baseMemory = pinnedRegs-&gt;baseMemoryPointer;
<span class="line-modified"> 834             const auto&amp; sizeRegs = pinnedRegs-&gt;sizeRegisters;</span>
<span class="line-modified"> 835             ASSERT(sizeRegs.size() &gt;= 1);</span>
<span class="line-modified"> 836             ASSERT(!sizeRegs[0].sizeOffset); // The following code assumes we start at 0, and calculates subsequent size registers relative to 0.</span>
<span class="line-removed"> 837             jit.loadPtr(CCallHelpers::Address(params[0].gpr(), Instance::offsetOfCachedMemorySize()), sizeRegs[0].sizeRegister);</span>
 838             jit.loadPtr(CCallHelpers::Address(params[0].gpr(), Instance::offsetOfCachedMemory()), baseMemory);
<span class="line-modified"> 839             for (unsigned i = 1; i &lt; sizeRegs.size(); ++i)</span>
<span class="line-modified"> 840                 jit.add64(CCallHelpers::TrustedImm32(-sizeRegs[i].sizeOffset), sizeRegs[0].sizeRegister, sizeRegs[i].sizeRegister);</span>
 841         });
 842 
 843         emitPatchpoint(block, patchpoint, Tmp(), instance);
 844     }
 845 }
 846 
 847 void AirIRGenerator::emitThrowException(CCallHelpers&amp; jit, ExceptionType type)
 848 {
 849     jit.move(CCallHelpers::TrustedImm32(static_cast&lt;uint32_t&gt;(type)), GPRInfo::argumentGPR1);
 850     auto jumpToExceptionStub = jit.jump();
 851 
 852     jit.addLinkTask([jumpToExceptionStub] (LinkBuffer&amp; linkBuffer) {
 853         linkBuffer.link(jumpToExceptionStub, CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(throwExceptionFromWasmThunkGenerator).code()));
 854     });
 855 }
 856 
 857 auto AirIRGenerator::addLocal(Type type, uint32_t count) -&gt; PartialResult
 858 {
<span class="line-modified"> 859     Checked&lt;uint32_t, RecordOverflow&gt; totalBytesChecked = count;</span>
<span class="line-modified"> 860     totalBytesChecked += m_locals.size();</span>
<span class="line-modified"> 861     uint32_t totalBytes;</span>
<span class="line-modified"> 862     WASM_COMPILE_FAIL_IF((totalBytesChecked.safeGet(totalBytes) == CheckedState::DidOverflow) || !m_locals.tryReserveCapacity(totalBytes), &quot;can&#39;t allocate memory for &quot;, totalBytes, &quot; locals&quot;);</span>
 863 
 864     for (uint32_t i = 0; i &lt; count; ++i) {
 865         auto local = tmpForType(type);
 866         m_locals.uncheckedAppend(local);
 867         switch (type) {




 868         case Type::I32:
 869         case Type::I64: {
 870             append(Xor64, local, local);
 871             break;
 872         }
 873         case Type::F32:
 874         case Type::F64: {
 875             auto temp = g64();
 876             // IEEE 754 &quot;0&quot; is just int32/64 zero.
 877             append(Xor64, temp, temp);
 878             append(type == Type::F32 ? Move32ToFloat : Move64ToDouble, temp, local);
 879             break;
 880         }
 881         default:
 882             RELEASE_ASSERT_NOT_REACHED();
 883         }
 884     }
 885     return { };
 886 }
 887 
 888 auto AirIRGenerator::addConstant(Type type, uint64_t value) -&gt; ExpressionType
 889 {
 890     return addConstant(m_currentBlock, type, value);
 891 }
 892 
 893 auto AirIRGenerator::addConstant(BasicBlock* block, Type type, uint64_t value) -&gt; ExpressionType
 894 {
 895     auto result = tmpForType(type);
 896     switch (type) {
 897     case Type::I32:
 898     case Type::I64:


 899         append(block, Move, Arg::bigImm(value), result);
 900         break;
 901     case Type::F32:
 902     case Type::F64: {
 903         auto tmp = g64();
 904         append(block, Move, Arg::bigImm(value), tmp);
 905         append(block, type == Type::F32 ? Move32ToFloat : Move64ToDouble, tmp, result);
 906         break;
 907     }
 908 
 909     default:
 910         RELEASE_ASSERT_NOT_REACHED();
 911     }
 912 
 913     return result;
 914 }
 915 
 916 auto AirIRGenerator::addArguments(const Signature&amp; signature) -&gt; PartialResult
 917 {
 918     RELEASE_ASSERT(m_locals.size() == signature.argumentCount()); // We handle arguments in the prologue
 919     return { };
 920 }
 921 









































































































 922 auto AirIRGenerator::getLocal(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
 923 {
 924     ASSERT(m_locals[index].tmp());
 925     result = tmpForType(m_locals[index].type());
 926     append(moveOpForValueType(m_locals[index].type()), m_locals[index].tmp(), result);
 927     return { };
 928 }
 929 
 930 auto AirIRGenerator::addUnreachable() -&gt; PartialResult
 931 {
 932     B3::PatchpointValue* unreachable = addPatchpoint(B3::Void);
 933     unreachable-&gt;setGenerator([this] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
 934         this-&gt;emitThrowException(jit, ExceptionType::Unreachable);
 935     });
 936     unreachable-&gt;effects.terminal = true;
 937     emitPatchpoint(unreachable, Tmp());
 938     return { };
 939 }
 940 
 941 auto AirIRGenerator::addGrowMemory(ExpressionType delta, ExpressionType&amp; result) -&gt; PartialResult
</pre>
<hr />
<pre>
1018 
1019 auto AirIRGenerator::setGlobal(uint32_t index, ExpressionType value) -&gt; PartialResult
1020 {
1021     auto temp = g64();
1022 
1023     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfGlobals(), B3::Width64));
1024     append(Move, Arg::addr(instanceValue(), Instance::offsetOfGlobals()), temp);
1025 
1026     Type type = m_info.globals[index].type;
1027 
1028     int32_t offset = safeCast&lt;int32_t&gt;(index * sizeof(Register));
1029     if (Arg::isValidAddrForm(offset, B3::widthForType(toB3Type(type))))
1030         append(moveOpForValueType(type), value, Arg::addr(temp, offset));
1031     else {
1032         auto temp2 = g64();
1033         append(Move, Arg::bigImm(offset), temp2);
1034         append(Add64, temp2, temp, temp);
1035         append(moveOpForValueType(type), value, Arg::addr(temp));
1036     }
1037 



1038     return { };
1039 }
1040 
















































1041 inline AirIRGenerator::ExpressionType AirIRGenerator::emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOperation)
1042 {
1043     ASSERT(m_memoryBaseGPR);
1044 
1045     auto result = g64();
1046     append(Move32, pointer, result);
1047 
1048     switch (m_mode) {
1049     case MemoryMode::BoundsChecking: {
1050         // We&#39;re not using signal handling at all, we must therefore check that no memory access exceeds the current memory size.
1051         ASSERT(m_memorySizeGPR);
1052         ASSERT(sizeOfOperation + offset &gt; offset);
1053         auto temp = g64();
1054         append(Move, Arg::bigImm(static_cast&lt;uint64_t&gt;(sizeOfOperation) + offset - 1), temp);
1055         append(Add64, result, temp);
1056 
1057         emitCheck([&amp;] {
1058             return Inst(Branch64, nullptr, Arg::relCond(MacroAssembler::AboveOrEqual), temp, Tmp(m_memorySizeGPR));
1059         }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1060             this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsMemoryAccess);
</pre>
<hr />
<pre>
1366 {
1367     ASSERT(nonZero.type() == zero.type());
1368     result = tmpForType(nonZero.type());
1369     append(moveOpForValueType(nonZero.type()), nonZero, result);
1370 
1371     BasicBlock* isZero = m_code.addBlock();
1372     BasicBlock* continuation = m_code.addBlock();
1373 
1374     append(BranchTest32, Arg::resCond(MacroAssembler::Zero), condition, condition);
1375     m_currentBlock-&gt;setSuccessors(isZero, continuation);
1376 
1377     append(isZero, moveOpForValueType(zero.type()), zero, result);
1378     append(isZero, Jump);
1379     isZero-&gt;setSuccessors(continuation);
1380 
1381     m_currentBlock = continuation;
1382 
1383     return { };
1384 }
1385 
<span class="line-modified">1386 void AirIRGenerator::emitTierUpCheck(uint32_t decrementCount, B3::Origin origin)</span>
1387 {
1388     UNUSED_PARAM(origin);
1389 
1390     if (!m_tierUp)
1391         return;
1392 
1393     auto countdownPtr = g64();
<span class="line-removed">1394     auto oldCountdown = g64();</span>
<span class="line-removed">1395     auto newCountdown = g64();</span>
<span class="line-removed">1396 </span>
<span class="line-removed">1397     append(Move, Arg::bigImm(reinterpret_cast&lt;uint64_t&gt;(m_tierUp)), countdownPtr);</span>
<span class="line-removed">1398     append(Move32, Arg::addr(countdownPtr), oldCountdown);</span>
1399 
<span class="line-modified">1400     RELEASE_ASSERT(Arg::isValidImmForm(decrementCount));</span>
<span class="line-removed">1401     append(Move32, oldCountdown, newCountdown);</span>
<span class="line-removed">1402     append(Sub32, Arg::imm(decrementCount), newCountdown);</span>
<span class="line-removed">1403     append(Move32, newCountdown, Arg::addr(countdownPtr));</span>
1404 
1405     auto* patch = addPatchpoint(B3::Void);
1406     B3::Effects effects = B3::Effects::none();
1407     effects.reads = B3::HeapRange::top();
1408     effects.writes = B3::HeapRange::top();
1409     patch-&gt;effects = effects;

1410 
1411     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
<span class="line-modified">1412         MacroAssembler::Jump tierUp = jit.branch32(MacroAssembler::Above, params[0].gpr(), params[1].gpr());</span>
<span class="line-modified">1413         MacroAssembler::Label tierUpResume = jit.label();</span>


1414 
1415         params.addLatePath([=] (CCallHelpers&amp; jit) {
1416             tierUp.link(&amp;jit);
1417 
1418             const unsigned extraPaddingBytes = 0;
1419             RegisterSet registersToSpill = { };
1420             registersToSpill.add(GPRInfo::argumentGPR1);
1421             unsigned numberOfStackBytesUsedForRegisterPreservation = ScratchRegisterAllocator::preserveRegistersToStackForCall(jit, registersToSpill, extraPaddingBytes);
1422 
1423             jit.move(MacroAssembler::TrustedImm32(m_functionIndex), GPRInfo::argumentGPR1);
1424             MacroAssembler::Call call = jit.nearCall();
1425 
1426             ScratchRegisterAllocator::restoreRegistersFromStackForCall(jit, registersToSpill, RegisterSet(), numberOfStackBytesUsedForRegisterPreservation, extraPaddingBytes);
1427             jit.jump(tierUpResume);
1428 
1429             jit.addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">1430                 MacroAssembler::repatchNearCall(linkBuffer.locationOfNearCall&lt;NoPtrTag&gt;(call), CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(triggerOMGTierUpThunkGenerator).code()));</span>
<span class="line-removed">1431 </span>
1432             });
1433         });
1434     });
1435 
<span class="line-modified">1436     emitPatchpoint(patch, Tmp(), newCountdown, oldCountdown);</span>
1437 }
1438 
<span class="line-modified">1439 AirIRGenerator::ControlData AirIRGenerator::addLoop(Type signature)</span>




































































1440 {
1441     BasicBlock* body = m_code.addBlock();
1442     BasicBlock* continuation = m_code.addBlock();
1443 
1444     append(Jump);
1445     m_currentBlock-&gt;setSuccessors(body);
1446 


1447     m_currentBlock = body;
<span class="line-modified">1448     emitTierUpCheck(TierUpCount::loopDecrement(), origin());</span>
1449 
1450     return ControlData(origin(), signature, tmpForType(signature), BlockType::Loop, continuation, body);
1451 }
1452 
1453 AirIRGenerator::ControlData AirIRGenerator::addTopLevel(Type signature)
1454 {
1455     return ControlData(B3::Origin(), signature, tmpForType(signature), BlockType::TopLevel, m_code.addBlock());
1456 }
1457 
1458 AirIRGenerator::ControlData AirIRGenerator::addBlock(Type signature)
1459 {
1460     return ControlData(origin(), signature, tmpForType(signature), BlockType::Block, m_code.addBlock());
1461 }
1462 
1463 auto AirIRGenerator::addIf(ExpressionType condition, Type signature, ControlType&amp; result) -&gt; PartialResult
1464 {
1465     BasicBlock* taken = m_code.addBlock();
1466     BasicBlock* notTaken = m_code.addBlock();
1467     BasicBlock* continuation = m_code.addBlock();
1468 
1469     // Wasm bools are i32.
1470     append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1471     m_currentBlock-&gt;setSuccessors(taken, notTaken);
1472 
1473     m_currentBlock = taken;
1474     result = ControlData(origin(), signature, tmpForType(signature), BlockType::If, continuation, notTaken);
1475     return { };
1476 }
1477 
<span class="line-modified">1478 auto AirIRGenerator::addElse(ControlData&amp; data, const ExpressionList&amp; currentStack) -&gt; PartialResult</span>
1479 {
1480     unifyValuesWithBlock(currentStack, data.result);
1481     append(Jump);
1482     m_currentBlock-&gt;setSuccessors(data.continuation);
1483     return addElseToUnreachable(data);
1484 }
1485 
1486 auto AirIRGenerator::addElseToUnreachable(ControlData&amp; data) -&gt; PartialResult
1487 {
1488     ASSERT(data.type() == BlockType::If);
1489     m_currentBlock = data.special;
1490     data.convertIfToBlock();
1491     return { };
1492 }
1493 
1494 auto AirIRGenerator::addReturn(const ControlData&amp; data, const ExpressionList&amp; returnValues) -&gt; PartialResult
1495 {
1496     ASSERT(returnValues.size() &lt;= 1);
1497     if (returnValues.size()) {
1498         Tmp returnValueGPR = Tmp(GPRInfo::returnValueGPR);
1499         Tmp returnValueFPR = Tmp(FPRInfo::returnValueFPR);
1500         switch (data.signature()) {
1501         case Type::I32:
1502             append(Move32, returnValues[0], returnValueGPR);
1503             append(Ret32, returnValueGPR);
1504             break;
1505         case Type::I64:


1506             append(Move, returnValues[0], returnValueGPR);
1507             append(Ret64, returnValueGPR);
1508             break;
1509         case Type::F32:
1510             append(MoveFloat, returnValues[0], returnValueFPR);
1511             append(RetFloat, returnValueFPR);
1512             break;
1513         case Type::F64:
1514             append(MoveDouble, returnValues[0], returnValueFPR);
1515             append(RetFloat, returnValueFPR);
1516             break;
1517         default:
1518             RELEASE_ASSERT_NOT_REACHED();
1519         }
1520     } else
1521         append(RetVoid);
1522     return { };
1523 }
1524 
1525 // NOTE: All branches in Wasm are on 32-bit ints
1526 
<span class="line-modified">1527 auto AirIRGenerator::addBranch(ControlData&amp; data, ExpressionType condition, const ExpressionList&amp; returnValues) -&gt; PartialResult</span>
1528 {
1529     unifyValuesWithBlock(returnValues, data.resultForBranch());
1530 
1531     BasicBlock* target = data.targetBlockForBranch();
1532     if (condition) {
1533         BasicBlock* continuation = m_code.addBlock();
1534         append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1535         m_currentBlock-&gt;setSuccessors(target, continuation);
1536         m_currentBlock = continuation;
1537     } else {
1538         append(Jump);
1539         m_currentBlock-&gt;setSuccessors(target);
1540     }
1541 
1542     return { };
1543 }
1544 
<span class="line-modified">1545 auto AirIRGenerator::addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTarget, const ExpressionList&amp; expressionStack) -&gt; PartialResult</span>
1546 {
1547     auto&amp; successors = m_currentBlock-&gt;successors();
1548     ASSERT(successors.isEmpty());
1549     for (const auto&amp; target : targets) {
1550         unifyValuesWithBlock(expressionStack, target-&gt;resultForBranch());
1551         successors.append(target-&gt;targetBlockForBranch());
1552     }
1553     unifyValuesWithBlock(expressionStack, defaultTarget.resultForBranch());
1554     successors.append(defaultTarget.targetBlockForBranch());
1555 
1556     ASSERT(condition.type() == Type::I32);
1557 
1558     // FIXME: We should consider dynamically switching between a jump table
1559     // and a binary switch depending on the number of successors.
1560     // https://bugs.webkit.org/show_bug.cgi?id=194477
1561 
1562     size_t numTargets = targets.size();
1563 
1564     auto* patchpoint = addPatchpoint(B3::Void);
1565     patchpoint-&gt;effects = B3::Effects::none();
</pre>
<hr />
<pre>
1588             caseJumps[index] = jit.jump();
1589         }
1590 
1591         CCallHelpers::JumpList fallThrough = binarySwitch.fallThrough();
1592 
1593         Vector&lt;Box&lt;CCallHelpers::Label&gt;&gt; successorLabels = params.successorLabels();
1594         ASSERT(successorLabels.size() == caseJumps.size() + 1);
1595 
1596         params.addLatePath([=, caseJumps = WTFMove(caseJumps), successorLabels = WTFMove(successorLabels)] (CCallHelpers&amp; jit) {
1597             for (size_t i = 0; i &lt; numTargets; ++i)
1598                 caseJumps[i].linkTo(*successorLabels[i], &amp;jit);
1599             fallThrough.linkTo(*successorLabels[numTargets], &amp;jit);
1600         });
1601     });
1602 
1603     emitPatchpoint(patchpoint, TypedTmp(), condition);
1604 
1605     return { };
1606 }
1607 
<span class="line-modified">1608 auto AirIRGenerator::endBlock(ControlEntry&amp; entry, ExpressionList&amp; expressionStack) -&gt; PartialResult</span>
1609 {
1610     ControlData&amp; data = entry.controlData;
1611 
1612     unifyValuesWithBlock(expressionStack, data.result);
1613     append(Jump);
1614     m_currentBlock-&gt;setSuccessors(data.continuation);
1615 
1616     return addEndToUnreachable(entry);
1617 }
1618 
1619 
1620 auto AirIRGenerator::addEndToUnreachable(ControlEntry&amp; entry) -&gt; PartialResult
1621 {
1622     ControlData&amp; data = entry.controlData;
1623     m_currentBlock = data.continuation;
1624 
1625     if (data.type() == BlockType::If) {
1626         append(data.special, Jump);
1627         data.special-&gt;setSuccessors(m_currentBlock);
1628     }
1629 



1630     for (const auto&amp; result : data.result)
1631         entry.enclosedExpressionStack.append(result);
1632 
1633     // TopLevel does not have any code after this so we need to make sure we emit a return here.
1634     if (data.type() == BlockType::TopLevel)
1635         return addReturn(data, entry.enclosedExpressionStack);
1636 
1637     return { };
1638 }
1639 
1640 auto AirIRGenerator::addCall(uint32_t functionIndex, const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result) -&gt; PartialResult
1641 {
1642     ASSERT(signature.argumentCount() == args.size());
1643 
1644     m_makesCalls = true;
1645 
1646     Type returnType = signature.returnType();
1647     if (returnType != Type::Void)
1648         result = tmpForType(returnType);
1649 
</pre>
<hr />
<pre>
1738 
1739         Vector&lt;ConstrainedTmp&gt; patchArgs;
1740         wasmCallingConventionAir().setupCall(m_code, returnType, patchpoint, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {
1741             patchArgs.append({ tmp, rep });
1742         });
1743 
1744         patchpoint-&gt;setGenerator([unlinkedWasmToWasmCalls, functionIndex] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1745             AllowMacroScratchRegisterUsage allowScratch(jit);
1746             CCallHelpers::Call call = jit.threadSafePatchableNearCall();
1747             jit.addLinkTask([unlinkedWasmToWasmCalls, call, functionIndex] (LinkBuffer&amp; linkBuffer) {
1748                 unlinkedWasmToWasmCalls-&gt;append({ linkBuffer.locationOfNearCall&lt;WasmEntryPtrTag&gt;(call), functionIndex });
1749             });
1750         });
1751 
1752         emitPatchpoint(m_currentBlock, patchpoint, result, WTFMove(patchArgs));
1753     }
1754 
1755     return { };
1756 }
1757 
<span class="line-modified">1758 auto AirIRGenerator::addCallIndirect(const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result) -&gt; PartialResult</span>
1759 {
1760     ExpressionType calleeIndex = args.takeLast();
1761     ASSERT(signature.argumentCount() == args.size());


1762 
1763     m_makesCalls = true;
1764     // Note: call indirect can call either WebAssemblyFunction or WebAssemblyWrapperFunction. Because
1765     // WebAssemblyWrapperFunction is like calling into the embedder, we conservatively assume all call indirects
1766     // can be to the embedder for our stack check calculation.
1767     m_maxNumJSCallArguments = std::max(m_maxNumJSCallArguments, static_cast&lt;uint32_t&gt;(args.size()));
1768 
1769     auto currentInstance = g64();
1770     append(Move, instanceValue(), currentInstance);
1771 
1772     ExpressionType callableFunctionBuffer = g64();
1773     ExpressionType instancesBuffer = g64();
1774     ExpressionType callableFunctionBufferLength = g64();
1775     {
<span class="line-modified">1776         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfTable(), B3::Width64));</span>
<span class="line-modified">1777         RELEASE_ASSERT(Arg::isValidAddrForm(Table::offsetOfFunctions(), B3::Width64));</span>
<span class="line-modified">1778         RELEASE_ASSERT(Arg::isValidAddrForm(Table::offsetOfInstances(), B3::Width64));</span>
<span class="line-modified">1779         RELEASE_ASSERT(Arg::isValidAddrForm(Table::offsetOfLength(), B3::Width64));</span>
<span class="line-modified">1780 </span>
<span class="line-modified">1781         append(Move, Arg::addr(instanceValue(), Instance::offsetOfTable()), callableFunctionBufferLength);</span>
<span class="line-modified">1782         append(Move, Arg::addr(callableFunctionBufferLength, Table::offsetOfFunctions()), callableFunctionBuffer);</span>
<span class="line-modified">1783         append(Move, Arg::addr(callableFunctionBufferLength, Table::offsetOfInstances()), instancesBuffer);</span>




1784         append(Move32, Arg::addr(callableFunctionBufferLength, Table::offsetOfLength()), callableFunctionBufferLength);
1785     }
1786 
1787     append(Move32, calleeIndex, calleeIndex);
1788 
1789     // Check the index we are looking for is valid.
1790     emitCheck([&amp;] {
1791         return Inst(Branch32, nullptr, Arg::relCond(MacroAssembler::AboveOrEqual), calleeIndex, callableFunctionBufferLength);
1792     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1793         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsCallIndirect);
1794     });
1795 
1796     ExpressionType calleeCode = g64();
1797     {
1798         ExpressionType calleeSignatureIndex = g64();
1799         // Compute the offset in the table index space we are looking for.
1800         append(Move, Arg::imm(sizeof(WasmToWasmImportableFunction)), calleeSignatureIndex);
1801         append(Mul64, calleeIndex, calleeSignatureIndex);
1802         append(Add64, callableFunctionBuffer, calleeSignatureIndex);
1803 
</pre>
<hr />
<pre>
1829         });
1830     }
1831 
1832     // Do a context switch if needed.
1833     {
1834         auto newContextInstance = g64();
1835         append(Move, Arg::index(instancesBuffer, calleeIndex, 8, 0), newContextInstance);
1836 
1837         BasicBlock* doContextSwitch = m_code.addBlock();
1838         BasicBlock* continuation = m_code.addBlock();
1839 
1840         append(Branch64, Arg::relCond(MacroAssembler::Equal), newContextInstance, instanceValue());
1841         m_currentBlock-&gt;setSuccessors(continuation, doContextSwitch);
1842 
1843         auto* patchpoint = addPatchpoint(B3::Void);
1844         patchpoint-&gt;effects.writesPinned = true;
1845         // We pessimistically assume we&#39;re calling something with BoundsChecking memory.
1846         // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
1847         patchpoint-&gt;clobber(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
1848         patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());


1849         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1850             AllowMacroScratchRegisterUsage allowScratch(jit);
1851             GPRReg newContextInstance = params[0].gpr();
1852             GPRReg oldContextInstance = params[1].gpr();
1853             const PinnedRegisterInfo&amp; pinnedRegs = PinnedRegisterInfo::get();
<span class="line-removed">1854             const auto&amp; sizeRegs = pinnedRegs.sizeRegisters;</span>
1855             GPRReg baseMemory = pinnedRegs.baseMemoryPointer;
1856             ASSERT(newContextInstance != baseMemory);
1857             jit.loadPtr(CCallHelpers::Address(oldContextInstance, Instance::offsetOfCachedStackLimit()), baseMemory);
1858             jit.storePtr(baseMemory, CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedStackLimit()));
1859             jit.storeWasmContextInstance(newContextInstance);
<span class="line-removed">1860             ASSERT(sizeRegs[0].sizeRegister != baseMemory);</span>
1861             // FIXME: We should support more than one memory size register
1862             //   see: https://bugs.webkit.org/show_bug.cgi?id=162952
<span class="line-modified">1863             ASSERT(sizeRegs.size() == 1);</span>
<span class="line-modified">1864             ASSERT(sizeRegs[0].sizeRegister != newContextInstance);</span>
<span class="line-modified">1865             ASSERT(!sizeRegs[0].sizeOffset);</span>
<span class="line-modified">1866             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemorySize()), sizeRegs[0].sizeRegister); // Memory size.</span>
1867             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemory()), baseMemory); // Memory::void*.


1868         });
1869 
1870         emitPatchpoint(doContextSwitch, patchpoint, Tmp(), newContextInstance, instanceValue());
1871         append(doContextSwitch, Jump);
1872         doContextSwitch-&gt;setSuccessors(continuation);
1873 
1874         m_currentBlock = continuation;
1875     }
1876 
1877     append(Move, Arg::addr(calleeCode), calleeCode);
1878 
1879     Type returnType = signature.returnType();
1880     if (returnType != Type::Void)
1881         result = tmpForType(returnType);
1882 
1883     auto* patch = addPatchpoint(toB3Type(returnType));
1884     patch-&gt;effects.writesPinned = true;
1885     patch-&gt;effects.readsPinned = true;
1886     // We need to clobber all potential pinned registers since we might be leaving the instance.
1887     // We pessimistically assume we&#39;re always calling something that is bounds checking so
</pre>
<hr />
<pre>
1893     Vector&lt;ConstrainedTmp&gt; emitArgs;
1894     emitArgs.append(calleeCode);
1895     wasmCallingConventionAir().setupCall(m_code, returnType, patch, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {
1896         emitArgs.append({ tmp, rep });
1897     });
1898     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1899         AllowMacroScratchRegisterUsage allowScratch(jit);
1900         jit.call(params[returnType == Void ? 0 : 1].gpr(), WasmEntryPtrTag);
1901     });
1902 
1903     emitPatchpoint(m_currentBlock, patch, result, WTFMove(emitArgs));
1904 
1905     // The call could have been to another WebAssembly instance, and / or could have modified our Memory.
1906     restoreWebAssemblyGlobalState(RestoreCachedStackLimit::Yes, m_info.memory, currentInstance, m_currentBlock);
1907 
1908     return { };
1909 }
1910 
1911 void AirIRGenerator::unify(const ExpressionType&amp; dst, const ExpressionType&amp; source)
1912 {
<span class="line-modified">1913     ASSERT(dst.type() == source.type());</span>
1914     append(moveOpForValueType(dst.type()), source, dst);
1915 }
1916 
<span class="line-modified">1917 void AirIRGenerator::unifyValuesWithBlock(const ExpressionList&amp; resultStack, const ResultList&amp; result)</span>
1918 {
1919     ASSERT(result.size() &lt;= resultStack.size());
1920 
1921     for (size_t i = 0; i &lt; result.size(); ++i)
1922         unify(result[result.size() - 1 - i], resultStack[resultStack.size() - 1 - i]);
1923 }
1924 
<span class="line-modified">1925 void AirIRGenerator::dump(const Vector&lt;ControlEntry&gt;&amp;, const ExpressionList*)</span>
1926 {
1927 }
1928 
1929 auto AirIRGenerator::origin() -&gt; B3::Origin
1930 {
1931     // FIXME: We should implement a way to give Inst&#39;s an origin.
1932     return B3::Origin();
1933 }
1934 
1935 Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, String&gt; parseAndCompileAir(CompilationContext&amp; compilationContext, const uint8_t* functionStart, size_t functionLength, const Signature&amp; signature, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, const ModuleInformation&amp; info, MemoryMode mode, uint32_t functionIndex, TierUpCount* tierUp, ThrowWasmException throwWasmException)
1936 {
<span class="line-modified">1937     auto result = std::make_unique&lt;InternalFunction&gt;();</span>
1938 
<span class="line-modified">1939     compilationContext.embedderEntrypointJIT = std::make_unique&lt;CCallHelpers&gt;();</span>
<span class="line-modified">1940     compilationContext.wasmEntrypointJIT = std::make_unique&lt;CCallHelpers&gt;();</span>
1941 
1942     B3::Procedure procedure;
1943     Code&amp; code = procedure.code();
1944 
1945     procedure.setOriginPrinter([] (PrintStream&amp; out, B3::Origin origin) {
1946         if (origin.data())
1947             out.print(&quot;Wasm: &quot;, bitwise_cast&lt;OpcodeOrigin&gt;(origin));
1948     });
1949 
1950     // This means we cannot use either StackmapGenerationParams::usedRegisters() or
1951     // StackmapGenerationParams::unavailableRegisters(). In exchange for this concession, we
1952     // don&#39;t strictly need to run Air::reportUsedRegisters(), which saves a bit of CPU time at
1953     // optLevel=1.
1954     procedure.setNeedsUsedRegisters(false);
1955 
<span class="line-modified">1956     procedure.setOptLevel(Options::webAssemblyBBQOptimizationLevel());</span>
1957 
1958     AirIRGenerator irGenerator(info, procedure, result.get(), unlinkedWasmToWasmCalls, mode, functionIndex, tierUp, throwWasmException, signature);
1959     FunctionParser&lt;AirIRGenerator&gt; parser(irGenerator, functionStart, functionLength, signature, info);
1960     WASM_FAIL_IF_HELPER_FAILS(parser.parse());
1961 
1962 
1963     for (BasicBlock* block : code) {
1964         for (size_t i = 0; i &lt; block-&gt;numSuccessors(); ++i)
1965             block-&gt;successorBlock(i)-&gt;addPredecessor(block);
1966     }
1967 
1968     {






1969         B3::Air::prepareForGeneration(code);
1970         B3::Air::generate(code, *compilationContext.wasmEntrypointJIT);
1971         compilationContext.wasmEntrypointByproducts = procedure.releaseByproducts();
1972         result-&gt;entrypoint.calleeSaveRegisters = code.calleeSaveRegisterAtOffsetList();
1973     }
1974 
<span class="line-modified">1975     return WTFMove(result);</span>
1976 }
1977 
1978 template &lt;typename IntType&gt;
1979 void AirIRGenerator::emitChecksForModOrDiv(bool isSignedDiv, ExpressionType left, ExpressionType right)
1980 {
1981     static_assert(sizeof(IntType) == 4 || sizeof(IntType) == 8, &quot;&quot;);
1982 
1983     emitCheck([&amp;] {
1984         return Inst(sizeof(IntType) == 4 ? BranchTest32 : BranchTest64, nullptr, Arg::resCond(MacroAssembler::Zero), right, right);
1985     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1986         this-&gt;emitThrowException(jit, ExceptionType::DivisionByZero);
1987     });
1988 
1989     if (isSignedDiv) {
1990         ASSERT(std::is_signed&lt;IntType&gt;::value);
1991         IntType min = std::numeric_limits&lt;IntType&gt;::min();
1992 
1993         // FIXME: Better isel for compare with imms here.
1994         // https://bugs.webkit.org/show_bug.cgi?id=193999
1995         auto minTmp = sizeof(IntType) == 4 ? g32() : g64();
</pre>
<hr />
<pre>
2726 {
2727     return addIntegerSub(Sub32, arg0, arg1, result);
2728 }
2729 
2730 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Le&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2731 {
2732     result = g32();
2733     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqual), arg0, arg1, result);
2734     return { };
2735 }
2736 
2737 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32DemoteF64&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2738 {
2739     result = f32();
2740     append(ConvertDoubleToFloat, arg0, result);
2741     return { };
2742 }
2743 
2744 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Min&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2745 {
<span class="line-modified">2746     result = f32();</span>
<span class="line-removed">2747 </span>
<span class="line-removed">2748     BasicBlock* isEqual = m_code.addBlock();</span>
<span class="line-removed">2749     BasicBlock* notEqual = m_code.addBlock();</span>
<span class="line-removed">2750     BasicBlock* greaterThanOrEqual = m_code.addBlock();</span>
<span class="line-removed">2751     BasicBlock* continuation = m_code.addBlock();</span>
<span class="line-removed">2752 </span>
<span class="line-removed">2753     append(m_currentBlock, BranchFloat, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>
<span class="line-removed">2754     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);</span>
<span class="line-removed">2755 </span>
<span class="line-removed">2756     append(isEqual, OrFloat, arg0, arg1, result);</span>
<span class="line-removed">2757     append(isEqual, Jump);</span>
<span class="line-removed">2758     isEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">2759 </span>
<span class="line-removed">2760     append(notEqual, MoveFloat, arg0, result);</span>
<span class="line-removed">2761     append(notEqual, BranchFloat, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-removed">2762     notEqual-&gt;setSuccessors(continuation, greaterThanOrEqual);</span>
<span class="line-removed">2763 </span>
<span class="line-removed">2764     append(greaterThanOrEqual, MoveFloat, arg1, result);</span>
<span class="line-removed">2765     append(greaterThanOrEqual, Jump);</span>
<span class="line-removed">2766     greaterThanOrEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">2767 </span>
<span class="line-removed">2768     m_currentBlock = continuation;</span>
<span class="line-removed">2769 </span>
<span class="line-removed">2770     return { };</span>
2771 }
2772 
2773 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Ne&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2774 {
2775     result = g32();
2776     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleNotEqualOrUnordered), arg0, arg1, result);
2777     return { };
2778 }
2779 
2780 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Lt&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2781 {
2782     result = g32();
2783     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1, result);
2784     return { };
2785 }
2786 
<span class="line-modified">2787 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Max&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult</span>
2788 {
<span class="line-modified">2789     result = f32();</span>

2790 
2791     BasicBlock* isEqual = m_code.addBlock();
2792     BasicBlock* notEqual = m_code.addBlock();
<span class="line-modified">2793     BasicBlock* lessThan = m_code.addBlock();</span>



2794     BasicBlock* continuation = m_code.addBlock();
2795 
<span class="line-modified">2796     append(m_currentBlock, BranchFloat, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>

2797     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);
2798 
<span class="line-modified">2799     append(isEqual, AndFloat, arg0, arg1, result);</span>








2800     append(isEqual, Jump);
2801     isEqual-&gt;setSuccessors(continuation);
2802 
<span class="line-modified">2803     append(notEqual, MoveFloat, arg0, result);</span>
<span class="line-modified">2804     append(notEqual, BranchFloat, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-modified">2805     notEqual-&gt;setSuccessors(lessThan, continuation);</span>






2806 
<span class="line-modified">2807     append(lessThan, MoveFloat, arg1, result);</span>
<span class="line-modified">2808     append(lessThan, Jump);</span>
<span class="line-modified">2809     lessThan-&gt;setSuccessors(continuation);</span>

2810 
2811     m_currentBlock = continuation;
2812 
2813     return { };
2814 }
2815 





2816 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Mul&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2817 {
2818     return addFloatingPointBinOp(Type::F64, MulDouble, arg0, arg1, result);
2819 }
2820 
2821 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Div&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2822 {
2823     return addFloatingPointBinOp(Type::F32, DivFloat, arg0, arg1, result);
2824 }
2825 
2826 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Clz&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2827 {
2828     result = g32();
2829     append(CountLeadingZeros32, arg0, result);
2830     return { };
2831 }
2832 
2833 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Copysign&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2834 {
2835     // FIXME: We can have better codegen here for the imms and two operand forms on x86
</pre>
<hr />
<pre>
3153 {
3154     result = f64();
3155     append(FloorDouble, arg0, result);
3156     return { };
3157 }
3158 
3159 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Xor&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3160 {
3161     result = g32();
3162     append(Xor32, arg0, arg1, result);
3163     return { };
3164 }
3165 
3166 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Abs&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3167 {
3168     return addFloatingPointAbs(AbsFloat, arg0, result);
3169 }
3170 
3171 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Min&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3172 {
<span class="line-modified">3173     result = f64();</span>
<span class="line-removed">3174 </span>
<span class="line-removed">3175     BasicBlock* isEqual = m_code.addBlock();</span>
<span class="line-removed">3176     BasicBlock* notEqual = m_code.addBlock();</span>
<span class="line-removed">3177     BasicBlock* greaterThanOrEqual = m_code.addBlock();</span>
<span class="line-removed">3178     BasicBlock* continuation = m_code.addBlock();</span>
<span class="line-removed">3179 </span>
<span class="line-removed">3180     append(m_currentBlock, BranchDouble, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>
<span class="line-removed">3181     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);</span>
<span class="line-removed">3182 </span>
<span class="line-removed">3183     append(isEqual, OrDouble, arg0, arg1, result);</span>
<span class="line-removed">3184     append(isEqual, Jump);</span>
<span class="line-removed">3185     isEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">3186 </span>
<span class="line-removed">3187     append(notEqual, MoveDouble, arg0, result);</span>
<span class="line-removed">3188     append(notEqual, BranchDouble, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-removed">3189     notEqual-&gt;setSuccessors(continuation, greaterThanOrEqual);</span>
<span class="line-removed">3190 </span>
<span class="line-removed">3191     append(greaterThanOrEqual, MoveDouble, arg1, result);</span>
<span class="line-removed">3192     append(greaterThanOrEqual, Jump);</span>
<span class="line-removed">3193     greaterThanOrEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">3194 </span>
<span class="line-removed">3195     m_currentBlock = continuation;</span>
<span class="line-removed">3196 </span>
<span class="line-removed">3197     return { };</span>
3198 }
3199 
3200 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Mul&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3201 {
3202     result = f32();
3203     append(MulFloat, arg0, arg1, result);
3204     return { };
3205 }
3206 
3207 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Sub&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3208 {
3209     return addIntegerSub(Sub64, arg0, arg1, result);
3210 }
3211 
3212 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32ReinterpretF32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3213 {
3214     result = g32();
3215     append(MoveFloatTo32, arg0, result);
3216     return { };
3217 }
</pre>
<hr />
<pre>
3449     return { };
3450 }
3451 
3452 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Neg&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3453 {
3454     result = f64();
3455     if (isValidForm(NegateDouble, Arg::Tmp, Arg::Tmp))
3456         append(NegateDouble, arg0, result);
3457     else {
3458         auto constant = addConstant(Type::I64, bitwise_cast&lt;uint64_t&gt;(static_cast&lt;double&gt;(-0.0)));
3459         auto temp = g64();
3460         append(MoveDoubleTo64, arg0, temp);
3461         append(Xor64, constant, temp);
3462         append(Move64ToDouble, temp, result);
3463     }
3464     return { };
3465 }
3466 
3467 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Max&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3468 {
<span class="line-modified">3469     result = f64();</span>
<span class="line-removed">3470 </span>
<span class="line-removed">3471     BasicBlock* isEqual = m_code.addBlock();</span>
<span class="line-removed">3472     BasicBlock* notEqual = m_code.addBlock();</span>
<span class="line-removed">3473     BasicBlock* lessThan = m_code.addBlock();</span>
<span class="line-removed">3474     BasicBlock* continuation = m_code.addBlock();</span>
<span class="line-removed">3475 </span>
<span class="line-removed">3476     append(m_currentBlock, BranchDouble, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>
<span class="line-removed">3477     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);</span>
<span class="line-removed">3478 </span>
<span class="line-removed">3479     append(isEqual, AndDouble, arg0, arg1, result);</span>
<span class="line-removed">3480     append(isEqual, Jump);</span>
<span class="line-removed">3481     isEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">3482 </span>
<span class="line-removed">3483     append(notEqual, MoveDouble, arg0, result);</span>
<span class="line-removed">3484     append(notEqual, BranchDouble, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-removed">3485     notEqual-&gt;setSuccessors(lessThan, continuation);</span>
<span class="line-removed">3486 </span>
<span class="line-removed">3487     append(lessThan, MoveDouble, arg1, result);</span>
<span class="line-removed">3488     append(lessThan, Jump);</span>
<span class="line-removed">3489     lessThan-&gt;setSuccessors(continuation);</span>
<span class="line-removed">3490 </span>
<span class="line-removed">3491     m_currentBlock = continuation;</span>
<span class="line-removed">3492 </span>
<span class="line-removed">3493     return { };</span>
3494 }
3495 
3496 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64LeU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3497 {
3498     result = g32();
3499     append(Compare64, Arg::relCond(MacroAssembler::BelowOrEqual), arg0, arg1, result);
3500     return { };
3501 }
3502 
3503 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64LeS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3504 {
3505     result = g32();
3506     append(Compare64, Arg::relCond(MacroAssembler::LessThanOrEqual), arg0, arg1, result);
3507     return { };
3508 }
3509 
3510 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Add&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3511 {
3512     result = g64();
3513     append(Add64, arg0, arg1, result);
</pre>
</td>
<td>
<hr />
<pre>
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;WasmAirIRGenerator.h&quot;
  28 
  29 #if ENABLE(WEBASSEMBLY)
  30 
  31 #include &quot;AirCode.h&quot;
  32 #include &quot;AirGenerate.h&quot;
  33 #include &quot;AirOpcodeUtils.h&quot;
  34 #include &quot;AirValidate.h&quot;
  35 #include &quot;AllowMacroScratchRegisterUsageIf.h&quot;
  36 #include &quot;B3CCallValue.h&quot;
  37 #include &quot;B3CheckSpecial.h&quot;
  38 #include &quot;B3CheckValue.h&quot;
  39 #include &quot;B3PatchpointSpecial.h&quot;
  40 #include &quot;B3Procedure.h&quot;
  41 #include &quot;B3ProcedureInlines.h&quot;
  42 #include &quot;BinarySwitch.h&quot;
<span class="line-added">  43 #include &quot;DisallowMacroScratchRegisterUsage.h&quot;</span>
<span class="line-added">  44 #include &quot;JSCInlines.h&quot;</span>
<span class="line-added">  45 #include &quot;JSWebAssemblyInstance.h&quot;</span>
  46 #include &quot;ScratchRegisterAllocator.h&quot;
  47 #include &quot;VirtualRegister.h&quot;
  48 #include &quot;WasmCallingConvention.h&quot;
  49 #include &quot;WasmContextInlines.h&quot;
  50 #include &quot;WasmExceptionType.h&quot;
  51 #include &quot;WasmFunctionParser.h&quot;
  52 #include &quot;WasmInstance.h&quot;
  53 #include &quot;WasmMemory.h&quot;
  54 #include &quot;WasmOMGPlan.h&quot;
<span class="line-added">  55 #include &quot;WasmOSREntryData.h&quot;</span>
  56 #include &quot;WasmOpcodeOrigin.h&quot;
<span class="line-added">  57 #include &quot;WasmOperations.h&quot;</span>
  58 #include &quot;WasmSignatureInlines.h&quot;
  59 #include &quot;WasmThunks.h&quot;
  60 #include &lt;limits&gt;
  61 #include &lt;wtf/Box.h&gt;
  62 #include &lt;wtf/Optional.h&gt;
  63 #include &lt;wtf/StdLibExtras.h&gt;
  64 
  65 namespace JSC { namespace Wasm {
  66 
  67 using namespace B3::Air;
  68 
  69 struct ConstrainedTmp {
  70     ConstrainedTmp(Tmp tmp)
  71         : ConstrainedTmp(tmp, tmp.isReg() ? B3::ValueRep::reg(tmp.reg()) : B3::ValueRep::SomeRegister)
  72     { }
  73 
  74     ConstrainedTmp(Tmp tmp, B3::ValueRep rep)
  75         : tmp(tmp)
  76         , rep(rep)
  77     {
</pre>
<hr />
<pre>
 188 
 189         ResultList resultForBranch() const
 190         {
 191             if (type() == BlockType::Loop)
 192                 return ResultList();
 193             return result;
 194         }
 195 
 196     private:
 197         friend class AirIRGenerator;
 198         BlockType blockType;
 199         BasicBlock* continuation;
 200         BasicBlock* special;
 201         ResultList result;
 202         Type returnType;
 203     };
 204 
 205     using ExpressionType = TypedTmp;
 206     using ControlType = ControlData;
 207     using ExpressionList = Vector&lt;ExpressionType, 1&gt;;
<span class="line-added"> 208     using Stack = ExpressionList;</span>
 209     using ResultList = ControlData::ResultList;
 210     using ControlEntry = FunctionParser&lt;AirIRGenerator&gt;::ControlEntry;
 211 
 212     static ExpressionType emptyExpression() { return { }; };
<span class="line-added"> 213     Stack createStack() { return Stack(); }</span>
 214 
 215     using ErrorType = String;
 216     using UnexpectedResult = Unexpected&lt;ErrorType&gt;;
 217     using Result = Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, ErrorType&gt;;
 218     using PartialResult = Expected&lt;void, ErrorType&gt;;
 219 
 220     template &lt;typename ...Args&gt;
 221     NEVER_INLINE UnexpectedResult WARN_UNUSED_RETURN fail(Args... args) const
 222     {
 223         using namespace FailureHelper; // See ADL comment in WasmParser.h.
 224         return UnexpectedResult(makeString(&quot;WebAssembly.Module failed compiling: &quot;_s, makeString(args)...));
 225     }
 226 
 227 #define WASM_COMPILE_FAIL_IF(condition, ...) do { \
 228         if (UNLIKELY(condition))                  \
 229             return fail(__VA_ARGS__);             \
 230     } while (0)
 231 
 232     AirIRGenerator(const ModuleInformation&amp;, B3::Procedure&amp;, InternalFunction*, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp;, MemoryMode, unsigned functionIndex, TierUpCount*, ThrowWasmException, const Signature&amp;);
 233 
 234     PartialResult WARN_UNUSED_RETURN addArguments(const Signature&amp;);
 235     PartialResult WARN_UNUSED_RETURN addLocal(Type, uint32_t);
 236     ExpressionType addConstant(Type, uint64_t);
 237     ExpressionType addConstant(BasicBlock*, Type, uint64_t);
 238 
<span class="line-added"> 239     // References</span>
<span class="line-added"> 240     PartialResult WARN_UNUSED_RETURN addRefIsNull(ExpressionType&amp; value, ExpressionType&amp; result);</span>
<span class="line-added"> 241     PartialResult WARN_UNUSED_RETURN addRefFunc(uint32_t index, ExpressionType&amp; result);</span>
<span class="line-added"> 242 </span>
<span class="line-added"> 243     // Tables</span>
<span class="line-added"> 244     PartialResult WARN_UNUSED_RETURN addTableGet(unsigned, ExpressionType&amp; index, ExpressionType&amp; result);</span>
<span class="line-added"> 245     PartialResult WARN_UNUSED_RETURN addTableSet(unsigned, ExpressionType&amp; index, ExpressionType&amp; value);</span>
<span class="line-added"> 246     PartialResult WARN_UNUSED_RETURN addTableSize(unsigned, ExpressionType&amp; result);</span>
<span class="line-added"> 247     PartialResult WARN_UNUSED_RETURN addTableGrow(unsigned, ExpressionType&amp; fill, ExpressionType&amp; delta, ExpressionType&amp; result);</span>
<span class="line-added"> 248     PartialResult WARN_UNUSED_RETURN addTableFill(unsigned, ExpressionType&amp; offset, ExpressionType&amp; fill, ExpressionType&amp; count);</span>
<span class="line-added"> 249 </span>
 250     // Locals
 251     PartialResult WARN_UNUSED_RETURN getLocal(uint32_t index, ExpressionType&amp; result);
 252     PartialResult WARN_UNUSED_RETURN setLocal(uint32_t index, ExpressionType value);
 253 
 254     // Globals
 255     PartialResult WARN_UNUSED_RETURN getGlobal(uint32_t index, ExpressionType&amp; result);
 256     PartialResult WARN_UNUSED_RETURN setGlobal(uint32_t index, ExpressionType value);
 257 
 258     // Memory
 259     PartialResult WARN_UNUSED_RETURN load(LoadOpType, ExpressionType pointer, ExpressionType&amp; result, uint32_t offset);
 260     PartialResult WARN_UNUSED_RETURN store(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 261     PartialResult WARN_UNUSED_RETURN addGrowMemory(ExpressionType delta, ExpressionType&amp; result);
 262     PartialResult WARN_UNUSED_RETURN addCurrentMemory(ExpressionType&amp; result);
 263 
 264     // Basic operators
 265     template&lt;OpType&gt;
 266     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType arg, ExpressionType&amp; result);
 267     template&lt;OpType&gt;
 268     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType left, ExpressionType right, ExpressionType&amp; result);
 269     PartialResult WARN_UNUSED_RETURN addSelect(ExpressionType condition, ExpressionType nonZero, ExpressionType zero, ExpressionType&amp; result);
 270 
 271     // Control flow
 272     ControlData WARN_UNUSED_RETURN addTopLevel(Type signature);
 273     ControlData WARN_UNUSED_RETURN addBlock(Type signature);
<span class="line-modified"> 274     ControlData WARN_UNUSED_RETURN addLoop(Type signature, const Stack&amp;, uint32_t loopIndex);</span>
 275     PartialResult WARN_UNUSED_RETURN addIf(ExpressionType condition, Type signature, ControlData&amp; result);
<span class="line-modified"> 276     PartialResult WARN_UNUSED_RETURN addElse(ControlData&amp;, const Stack&amp;);</span>
 277     PartialResult WARN_UNUSED_RETURN addElseToUnreachable(ControlData&amp;);
 278 
 279     PartialResult WARN_UNUSED_RETURN addReturn(const ControlData&amp;, const ExpressionList&amp; returnValues);
<span class="line-modified"> 280     PartialResult WARN_UNUSED_RETURN addBranch(ControlData&amp;, ExpressionType condition, const Stack&amp; returnValues);</span>
<span class="line-modified"> 281     PartialResult WARN_UNUSED_RETURN addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTargets, const Stack&amp; expressionStack);</span>
<span class="line-modified"> 282     PartialResult WARN_UNUSED_RETURN endBlock(ControlEntry&amp;, Stack&amp; expressionStack);</span>
 283     PartialResult WARN_UNUSED_RETURN addEndToUnreachable(ControlEntry&amp;);
 284 
 285     // Calls
 286     PartialResult WARN_UNUSED_RETURN addCall(uint32_t calleeIndex, const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result);
<span class="line-modified"> 287     PartialResult WARN_UNUSED_RETURN addCallIndirect(unsigned tableIndex, const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result);</span>
 288     PartialResult WARN_UNUSED_RETURN addUnreachable();
 289 
 290     PartialResult addShift(Type, B3::Air::Opcode, ExpressionType value, ExpressionType shift, ExpressionType&amp; result);
 291     PartialResult addIntegerSub(B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 292     PartialResult addFloatingPointAbs(B3::Air::Opcode, ExpressionType value, ExpressionType&amp; result);
 293     PartialResult addFloatingPointBinOp(Type, B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 294 
<span class="line-modified"> 295     void dump(const Vector&lt;ControlEntry&gt;&amp; controlStack, const Stack* expressionStack);</span>
 296     void setParser(FunctionParser&lt;AirIRGenerator&gt;* parser) { m_parser = parser; };
 297 
 298     static Vector&lt;Tmp&gt; toTmpVector(const Vector&lt;TypedTmp&gt;&amp; vector)
 299     {
 300         Vector&lt;Tmp&gt; result;
 301         for (const auto&amp; item : vector)
 302             result.append(item.tmp());
 303         return result;
 304     }
 305 
 306     ALWAYS_INLINE void didKill(const ExpressionType&amp; typedTmp)
 307     {
 308         Tmp tmp = typedTmp.tmp();
 309         if (!tmp)
 310             return;
 311         if (tmp.isGP())
 312             m_freeGPs.append(tmp);
 313         else
 314             m_freeFPs.append(tmp);
 315     }
 316 
<span class="line-added"> 317     const Bag&lt;B3::PatchpointValue*&gt;&amp; patchpoints() const</span>
<span class="line-added"> 318     {</span>
<span class="line-added"> 319         return m_patchpoints;</span>
<span class="line-added"> 320     }</span>
<span class="line-added"> 321 </span>
 322 private:
 323     ALWAYS_INLINE void validateInst(Inst&amp; inst)
 324     {
 325         if (!ASSERT_DISABLED) {
 326             if (!inst.isValidForm()) {
 327                 dataLogLn(inst);
 328                 CRASH();
 329             }
 330         }
 331     }
 332 
 333     static Arg extractArg(const TypedTmp&amp; tmp) { return tmp.tmp(); }
 334     static Arg extractArg(const Tmp&amp; tmp) { return Arg(tmp); }
 335     static Arg extractArg(const Arg&amp; arg) { return arg; }
 336 
 337     template&lt;typename... Arguments&gt;
 338     void append(BasicBlock* block, Kind kind, Arguments&amp;&amp;... arguments)
 339     {
 340         // FIXME: Find a way to use origin here.
 341         auto&amp; inst = block-&gt;append(kind, nullptr, extractArg(arguments)...);
</pre>
<hr />
<pre>
 356         append(m_currentBlock, kind, std::forward&lt;Arguments&gt;(arguments)...);
 357     }
 358 
 359     Tmp newTmp(B3::Bank bank)
 360     {
 361         switch (bank) {
 362         case B3::GP:
 363             if (m_freeGPs.size())
 364                 return m_freeGPs.takeLast();
 365             break;
 366         case B3::FP:
 367             if (m_freeFPs.size())
 368                 return m_freeFPs.takeLast();
 369             break;
 370         }
 371         return m_code.newTmp(bank);
 372     }
 373 
 374     TypedTmp g32() { return { newTmp(B3::GP), Type::I32 }; }
 375     TypedTmp g64() { return { newTmp(B3::GP), Type::I64 }; }
<span class="line-added"> 376     TypedTmp gAnyref() { return { newTmp(B3::GP), Type::Anyref }; }</span>
<span class="line-added"> 377     TypedTmp gFuncref() { return { newTmp(B3::GP), Type::Funcref }; }</span>
 378     TypedTmp f32() { return { newTmp(B3::FP), Type::F32 }; }
 379     TypedTmp f64() { return { newTmp(B3::FP), Type::F64 }; }
 380 
 381     TypedTmp tmpForType(Type type)
 382     {
 383         switch (type) {
 384         case Type::I32:
 385             return g32();
 386         case Type::I64:
 387             return g64();
<span class="line-added"> 388         case Type::Funcref:</span>
<span class="line-added"> 389             return gFuncref();</span>
<span class="line-added"> 390         case Type::Anyref:</span>
<span class="line-added"> 391             return gAnyref();</span>
 392         case Type::F32:
 393             return f32();
 394         case Type::F64:
 395             return f64();
 396         case Type::Void:
 397             return { };
 398         default:
 399             RELEASE_ASSERT_NOT_REACHED();
 400         }
 401     }
 402 
 403     B3::PatchpointValue* addPatchpoint(B3::Type type)
 404     {
<span class="line-modified"> 405         auto* result = m_proc.add&lt;B3::PatchpointValue&gt;(type, B3::Origin());</span>
<span class="line-added"> 406         if (UNLIKELY(shouldDumpIRAtEachPhase(B3::AirMode)))</span>
<span class="line-added"> 407             m_patchpoints.add(result);</span>
<span class="line-added"> 408         return result;</span>
 409     }
 410 
 411     template &lt;typename ...Args&gt;
 412     void emitPatchpoint(B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 413     {
 414         emitPatchpoint(m_currentBlock, patch, result, std::forward&lt;Args&gt;(theArgs)...);
 415     }
 416 
 417     template &lt;typename ...Args&gt;
 418     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 419     {
 420         emitPatchpoint(basicBlock, patch, result, Vector&lt;ConstrainedTmp, sizeof...(Args)&gt;::from(theArgs...));
 421     }
 422 
 423     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result)
 424     {
 425         emitPatchpoint(basicBlock, patch, result, Vector&lt;ConstrainedTmp&gt;());
 426     }
 427 
 428     template &lt;size_t inlineSize&gt;
 429     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Vector&lt;ConstrainedTmp, inlineSize&gt;&amp;&amp; args)
 430     {
 431         if (!m_patchpointSpecial)
<span class="line-modified"> 432             m_patchpointSpecial = static_cast&lt;B3::PatchpointSpecial*&gt;(m_code.addSpecial(makeUnique&lt;B3::PatchpointSpecial&gt;()));</span>
 433 
 434         Inst inst(Patch, patch, Arg::special(m_patchpointSpecial));
 435         Inst resultMov;
 436         if (result) {
 437             ASSERT(patch-&gt;type() != B3::Void);
<span class="line-modified"> 438             switch (patch-&gt;resultConstraints[0].kind()) {</span>
 439             case B3::ValueRep::Register:
<span class="line-modified"> 440                 inst.args.append(Tmp(patch-&gt;resultConstraints[0].reg()));</span>
<span class="line-modified"> 441                 resultMov = Inst(result.isGP() ? Move : MoveDouble, nullptr, Tmp(patch-&gt;resultConstraints[0].reg()), result);</span>
 442                 break;
 443             case B3::ValueRep::SomeRegister:
 444                 inst.args.append(result);
 445                 break;
 446             default:
 447                 RELEASE_ASSERT_NOT_REACHED();
 448             }
 449         } else
 450             ASSERT(patch-&gt;type() == B3::Void);
 451 
 452         for (ConstrainedTmp&amp; tmp : args) {
 453             // FIXME: This is less than ideal to create dummy values just to satisfy Air&#39;s
 454             // validation. We should abstrcat Patch enough so ValueRep&#39;s don&#39;t need to be
 455             // backed by Values.
 456             // https://bugs.webkit.org/show_bug.cgi?id=194040
 457             B3::Value* dummyValue = m_proc.addConstant(B3::Origin(), tmp.tmp.isGP() ? B3::Int64 : B3::Double, 0);
 458             patch-&gt;append(dummyValue, tmp.rep);
 459             switch (tmp.rep.kind()) {
<span class="line-added"> 460             case B3::ValueRep::ColdAny: // B3::Value propagates ColdAny information and later Air will allocate appropriate stack.</span>
 461             case B3::ValueRep::SomeRegister:
 462                 inst.args.append(tmp.tmp);
 463                 break;
 464             case B3::ValueRep::Register:
 465                 patch-&gt;earlyClobbered().clear(tmp.rep.reg());
 466                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, tmp.rep.reg());
 467                 inst.args.append(Tmp(tmp.rep.reg()));
 468                 break;
 469             case B3::ValueRep::StackArgument: {
 470                 auto arg = Arg::callArg(tmp.rep.offsetFromSP());
 471                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, arg);
 472                 inst.args.append(arg);
 473                 break;
 474             }
 475             default:
 476                 RELEASE_ASSERT_NOT_REACHED();
 477             }
 478         }
 479 
<span class="line-modified"> 480         if (patch-&gt;resultConstraints[0].isReg())</span>
<span class="line-modified"> 481             patch-&gt;lateClobbered().clear(patch-&gt;resultConstraints[0].reg());</span>
 482         for (unsigned i = patch-&gt;numGPScratchRegisters; i--;)
 483             inst.args.append(g64().tmp());
 484         for (unsigned i = patch-&gt;numFPScratchRegisters; i--;)
 485             inst.args.append(f64().tmp());
 486 
 487         validateInst(inst);
 488         basicBlock-&gt;append(WTFMove(inst));
 489         if (resultMov) {
 490             validateInst(resultMov);
 491             basicBlock-&gt;append(WTFMove(resultMov));
 492         }
 493     }
 494 
 495     template &lt;typename Branch, typename Generator&gt;
 496     void emitCheck(const Branch&amp; makeBranch, const Generator&amp; generator)
 497     {
 498         // We fail along the truthy edge of &#39;branch&#39;.
 499         Inst branch = makeBranch();
 500 
 501         // FIXME: Make a hashmap of these.
 502         B3::CheckSpecial::Key key(branch);
<span class="line-modified"> 503         B3::CheckSpecial* special = static_cast&lt;B3::CheckSpecial*&gt;(m_code.addSpecial(makeUnique&lt;B3::CheckSpecial&gt;(key)));</span>
 504 
 505         // FIXME: Remove the need for dummy values
 506         // https://bugs.webkit.org/show_bug.cgi?id=194040
 507         B3::Value* dummyPredicate = m_proc.addConstant(B3::Origin(), B3::Int32, 42);
 508         B3::CheckValue* checkValue = m_proc.add&lt;B3::CheckValue&gt;(B3::Check, B3::Origin(), dummyPredicate);
 509         checkValue-&gt;setGenerator(generator);
 510 
 511         Inst inst(Patch, checkValue, Arg::special(special));
 512         inst.args.appendVector(branch.args);
 513         m_currentBlock-&gt;append(WTFMove(inst));
 514     }
 515 
 516     template &lt;typename Func, typename ...Args&gt;
 517     void emitCCall(Func func, TypedTmp result, Args... args)
 518     {
 519         emitCCall(m_currentBlock, func, result, std::forward&lt;Args&gt;(args)...);
 520     }
 521     template &lt;typename Func, typename ...Args&gt;
 522     void emitCCall(BasicBlock* block, Func func, TypedTmp result, Args... theArgs)
 523     {
 524         B3::Type resultType = B3::Void;
 525         if (result) {
 526             switch (result.type()) {
 527             case Type::I32:
 528                 resultType = B3::Int32;
 529                 break;
 530             case Type::I64:
<span class="line-added"> 531             case Type::Anyref:</span>
<span class="line-added"> 532             case Type::Funcref:</span>
 533                 resultType = B3::Int64;
 534                 break;
 535             case Type::F32:
 536                 resultType = B3::Float;
 537                 break;
 538             case Type::F64:
 539                 resultType = B3::Double;
 540                 break;
 541             default:
 542                 RELEASE_ASSERT_NOT_REACHED();
 543             }
 544         }
 545 
 546         auto makeDummyValue = [&amp;] (Tmp tmp) {
 547             // FIXME: This is less than ideal to create dummy values just to satisfy Air&#39;s
 548             // validation. We should abstrcat CCall enough so we&#39;re not reliant on arguments
 549             // to the B3::CCallValue.
 550             // https://bugs.webkit.org/show_bug.cgi?id=194040
 551             if (tmp.isGP())
 552                 return m_proc.addConstant(B3::Origin(), B3::Int64, 0);
 553             return m_proc.addConstant(B3::Origin(), B3::Double, 0);
 554         };
 555 
 556         B3::Value* dummyFunc = m_proc.addConstant(B3::Origin(), B3::Int64, bitwise_cast&lt;uintptr_t&gt;(func));
 557         B3::Value* origin = m_proc.add&lt;B3::CCallValue&gt;(resultType, B3::Origin(), B3::Effects::none(), dummyFunc, makeDummyValue(theArgs)...);
 558 
 559         Inst inst(CCall, origin);
 560 
 561         Tmp callee = g64();
<span class="line-modified"> 562         append(block, Move, Arg::immPtr(tagCFunctionPtr&lt;void*&gt;(func, B3CCallPtrTag)), callee);</span>
 563         inst.args.append(callee);
 564 
 565         if (result)
 566             inst.args.append(result.tmp());
 567 
 568         for (Tmp tmp : Vector&lt;Tmp, sizeof...(Args)&gt;::from(theArgs.tmp()...))
 569             inst.args.append(tmp);
 570 
 571         block-&gt;append(WTFMove(inst));
 572     }
 573 
 574     static B3::Air::Opcode moveOpForValueType(Type type)
 575     {
 576         switch (type) {
 577         case Type::I32:
 578             return Move32;
 579         case Type::I64:
<span class="line-added"> 580         case Type::Anyref:</span>
<span class="line-added"> 581         case Type::Funcref:</span>
 582             return Move;
 583         case Type::F32:
 584             return MoveFloat;
 585         case Type::F64:
 586             return MoveDouble;
 587         default:
 588             RELEASE_ASSERT_NOT_REACHED();
 589         }
 590     }
 591 
 592     void emitThrowException(CCallHelpers&amp;, ExceptionType);
 593 
<span class="line-modified"> 594     void emitEntryTierUpCheck(int32_t incrementCount, B3::Origin);</span>
<span class="line-added"> 595     void emitLoopTierUpCheck(int32_t incrementCount, const Stack&amp;, uint32_t, uint32_t, B3::Origin);</span>
 596 
<span class="line-added"> 597     void emitWriteBarrierForJSWrapper();</span>
 598     ExpressionType emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOp);
 599     ExpressionType emitLoadOp(LoadOpType, ExpressionType pointer, uint32_t offset);
 600     void emitStoreOp(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 601 
 602     void unify(const ExpressionType&amp; dst, const ExpressionType&amp; source);
<span class="line-modified"> 603     void unifyValuesWithBlock(const Stack&amp; resultStack, const ResultList&amp; stack);</span>
 604 
 605     template &lt;typename IntType&gt;
 606     void emitChecksForModOrDiv(bool isSignedDiv, ExpressionType left, ExpressionType right);
 607 
 608     template &lt;typename IntType&gt;
 609     void emitModOrDiv(bool isDiv, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 610 
<span class="line-added"> 611     enum class MinOrMax { Min, Max };</span>
<span class="line-added"> 612 </span>
<span class="line-added"> 613     PartialResult addFloatingPointMinOrMax(Type, MinOrMax, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);</span>
<span class="line-added"> 614 </span>
 615     int32_t WARN_UNUSED_RETURN fixupPointerPlusOffset(ExpressionType&amp;, uint32_t);
 616 
 617     void restoreWasmContextInstance(BasicBlock*, TypedTmp);
 618     enum class RestoreCachedStackLimit { No, Yes };
 619     void restoreWebAssemblyGlobalState(RestoreCachedStackLimit, const MemoryInformation&amp;, TypedTmp instance, BasicBlock*);
 620 
 621     B3::Origin origin();
 622 
<span class="line-added"> 623     uint32_t outerLoopIndex() const</span>
<span class="line-added"> 624     {</span>
<span class="line-added"> 625         if (m_outerLoops.isEmpty())</span>
<span class="line-added"> 626             return UINT32_MAX;</span>
<span class="line-added"> 627         return m_outerLoops.last();</span>
<span class="line-added"> 628     }</span>
<span class="line-added"> 629 </span>
 630     FunctionParser&lt;AirIRGenerator&gt;* m_parser { nullptr };
 631     const ModuleInformation&amp; m_info;
 632     const MemoryMode m_mode { MemoryMode::BoundsChecking };
 633     const unsigned m_functionIndex { UINT_MAX };
<span class="line-modified"> 634     TierUpCount* m_tierUp { nullptr };</span>
 635 
 636     B3::Procedure&amp; m_proc;
 637     Code&amp; m_code;
<span class="line-added"> 638     Vector&lt;uint32_t&gt; m_outerLoops;</span>
 639     BasicBlock* m_currentBlock { nullptr };
 640     BasicBlock* m_rootBlock { nullptr };
 641     Vector&lt;TypedTmp&gt; m_locals;
 642     Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; m_unlinkedWasmToWasmCalls; // List each call site and the function index whose address it should be patched with.
 643     GPRReg m_memoryBaseGPR { InvalidGPRReg };
 644     GPRReg m_memorySizeGPR { InvalidGPRReg };
 645     GPRReg m_wasmContextInstanceGPR { InvalidGPRReg };
 646     bool m_makesCalls { false };
 647 
 648     Vector&lt;Tmp, 8&gt; m_freeGPs;
 649     Vector&lt;Tmp, 8&gt; m_freeFPs;
 650 
<span class="line-added"> 651     // This is only filled if we are dumping IR.</span>
<span class="line-added"> 652     Bag&lt;B3::PatchpointValue*&gt; m_patchpoints;</span>
<span class="line-added"> 653 </span>
 654     TypedTmp m_instanceValue; // Always use the accessor below to ensure the instance value is materialized when used.
 655     bool m_usesInstanceValue { false };
 656     TypedTmp instanceValue()
 657     {
 658         m_usesInstanceValue = true;
 659         return m_instanceValue;
 660     }
 661 
 662     uint32_t m_maxNumJSCallArguments { 0 };
<span class="line-added"> 663     unsigned m_numImportFunctions;</span>
 664 
 665     B3::PatchpointSpecial* m_patchpointSpecial { nullptr };
 666 };
 667 
 668 // Memory accesses in WebAssembly have unsigned 32-bit offsets, whereas they have signed 32-bit offsets in B3.
 669 int32_t AirIRGenerator::fixupPointerPlusOffset(ExpressionType&amp; ptr, uint32_t offset)
 670 {
 671     if (static_cast&lt;uint64_t&gt;(offset) &gt; static_cast&lt;uint64_t&gt;(std::numeric_limits&lt;int32_t&gt;::max())) {
 672         auto previousPtr = ptr;
 673         ptr = g64();
 674         auto constant = g64();
 675         append(Move, Arg::bigImm(offset), constant);
 676         append(Add64, constant, previousPtr, ptr);
 677         return 0;
 678     }
 679     return offset;
 680 }
 681 
 682 void AirIRGenerator::restoreWasmContextInstance(BasicBlock* block, TypedTmp instance)
 683 {
</pre>
<hr />
<pre>
 699     B3::Effects effects = B3::Effects::none();
 700     effects.writesPinned = true;
 701     effects.reads = B3::HeapRange::top();
 702     patchpoint-&gt;effects = effects;
 703     patchpoint-&gt;clobberLate(RegisterSet(m_wasmContextInstanceGPR));
 704     GPRReg wasmContextInstanceGPR = m_wasmContextInstanceGPR;
 705     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; param) {
 706         jit.move(param[0].gpr(), wasmContextInstanceGPR);
 707     });
 708     emitPatchpoint(block, patchpoint, Tmp(), instance);
 709 }
 710 
 711 AirIRGenerator::AirIRGenerator(const ModuleInformation&amp; info, B3::Procedure&amp; procedure, InternalFunction* compilation, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, MemoryMode mode, unsigned functionIndex, TierUpCount* tierUp, ThrowWasmException throwWasmException, const Signature&amp; signature)
 712     : m_info(info)
 713     , m_mode(mode)
 714     , m_functionIndex(functionIndex)
 715     , m_tierUp(tierUp)
 716     , m_proc(procedure)
 717     , m_code(m_proc.code())
 718     , m_unlinkedWasmToWasmCalls(unlinkedWasmToWasmCalls)
<span class="line-added"> 719     , m_numImportFunctions(info.importFunctionCount())</span>
 720 {
 721     m_currentBlock = m_code.addBlock();
 722     m_rootBlock = m_currentBlock;
 723 
 724     // FIXME we don&#39;t really need to pin registers here if there&#39;s no memory. It makes wasm -&gt; wasm thunks simpler for now. https://bugs.webkit.org/show_bug.cgi?id=166623
 725     const PinnedRegisterInfo&amp; pinnedRegs = PinnedRegisterInfo::get();
 726 
 727     m_memoryBaseGPR = pinnedRegs.baseMemoryPointer;
 728     m_code.pinRegister(m_memoryBaseGPR);
 729 
 730     m_wasmContextInstanceGPR = pinnedRegs.wasmContextInstancePointer;
 731     if (!Context::useFastTLS())
 732         m_code.pinRegister(m_wasmContextInstanceGPR);
 733 
 734     if (mode != MemoryMode::Signaling) {
<span class="line-modified"> 735         m_memorySizeGPR = pinnedRegs.sizeRegister;</span>
<span class="line-modified"> 736         m_code.pinRegister(m_memorySizeGPR);</span>


 737     }
 738 
 739     if (throwWasmException)
 740         Thunks::singleton().setThrowWasmException(throwWasmException);
 741 
 742     if (info.memory) {
 743         switch (m_mode) {
 744         case MemoryMode::BoundsChecking:
 745             break;
 746         case MemoryMode::Signaling:
 747             // Most memory accesses in signaling mode don&#39;t do an explicit
 748             // exception check because they can rely on fault handling to detect
 749             // out-of-bounds accesses. FaultSignalHandler nonetheless needs the
 750             // thunk to exist so that it can jump to that thunk.
 751             if (UNLIKELY(!Thunks::singleton().stub(throwExceptionFromWasmThunkGenerator)))
 752                 CRASH();
 753             break;
 754         }
 755     }
 756 
</pre>
<hr />
<pre>
 820     if (Context::useFastTLS()) {
 821         m_instanceValue = g64();
 822         // FIXME: Would be nice to only do this if we use instance value.
 823         append(Move, Tmp(contextInstance), m_instanceValue);
 824     } else
 825         m_instanceValue = { Tmp(contextInstance), Type::I64 };
 826 
 827     ASSERT(!m_locals.size());
 828     m_locals.grow(signature.argumentCount());
 829     for (unsigned i = 0; i &lt; signature.argumentCount(); ++i) {
 830         Type type = signature.argument(i);
 831         m_locals[i] = tmpForType(type);
 832     }
 833 
 834     wasmCallingConventionAir().loadArguments(signature, [&amp;] (const Arg&amp; arg, unsigned i) {
 835         switch (signature.argument(i)) {
 836         case Type::I32:
 837             append(Move32, arg, m_locals[i]);
 838             break;
 839         case Type::I64:
<span class="line-added"> 840         case Type::Anyref:</span>
<span class="line-added"> 841         case Type::Funcref:</span>
 842             append(Move, arg, m_locals[i]);
 843             break;
 844         case Type::F32:
 845             append(MoveFloat, arg, m_locals[i]);
 846             break;
 847         case Type::F64:
 848             append(MoveDouble, arg, m_locals[i]);
 849             break;
 850         default:
 851             RELEASE_ASSERT_NOT_REACHED();
 852         }
 853     });
 854 
<span class="line-modified"> 855     emitEntryTierUpCheck(TierUpCount::functionEntryIncrement(), B3::Origin());</span>
 856 }
 857 
 858 void AirIRGenerator::restoreWebAssemblyGlobalState(RestoreCachedStackLimit restoreCachedStackLimit, const MemoryInformation&amp; memory, TypedTmp instance, BasicBlock* block)
 859 {
 860     restoreWasmContextInstance(block, instance);
 861 
 862     if (restoreCachedStackLimit == RestoreCachedStackLimit::Yes) {
 863         // The Instance caches the stack limit, but also knows where its canonical location is.
 864         static_assert(sizeof(decltype(static_cast&lt;Instance*&gt;(nullptr)-&gt;cachedStackLimit())) == sizeof(uint64_t), &quot;&quot;);
 865 
 866         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfPointerToActualStackLimit(), B3::Width64));
 867         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfCachedStackLimit(), B3::Width64));
 868         auto temp = g64();
 869         append(block, Move, Arg::addr(instanceValue(), Instance::offsetOfPointerToActualStackLimit()), temp);
 870         append(block, Move, Arg::addr(temp), temp);
 871         append(block, Move, temp, Arg::addr(instanceValue(), Instance::offsetOfCachedStackLimit()));
 872     }
 873 
 874     if (!!memory) {
 875         const PinnedRegisterInfo* pinnedRegs = &amp;PinnedRegisterInfo::get();
 876         RegisterSet clobbers;
 877         clobbers.set(pinnedRegs-&gt;baseMemoryPointer);
<span class="line-modified"> 878         clobbers.set(pinnedRegs-&gt;sizeRegister);</span>
<span class="line-modified"> 879         if (!isARM64())</span>
<span class="line-added"> 880             clobbers.set(RegisterSet::macroScratchRegisters());</span>
 881 
 882         auto* patchpoint = addPatchpoint(B3::Void);
 883         B3::Effects effects = B3::Effects::none();
 884         effects.writesPinned = true;
 885         effects.reads = B3::HeapRange::top();
 886         patchpoint-&gt;effects = effects;
 887         patchpoint-&gt;clobber(clobbers);
<span class="line-added"> 888         patchpoint-&gt;numGPScratchRegisters = Gigacage::isEnabled(Gigacage::Primitive) ? 1 : 0;</span>
 889 
 890         patchpoint-&gt;setGenerator([pinnedRegs] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
<span class="line-added"> 891             AllowMacroScratchRegisterUsage allowScratch(jit);</span>
 892             GPRReg baseMemory = pinnedRegs-&gt;baseMemoryPointer;
<span class="line-modified"> 893             GPRReg scratchOrSize = Gigacage::isEnabled(Gigacage::Primitive) ? params.gpScratch(0) : pinnedRegs-&gt;sizeRegister;</span>
<span class="line-modified"> 894 </span>
<span class="line-modified"> 895             jit.loadPtr(CCallHelpers::Address(params[0].gpr(), Instance::offsetOfCachedMemorySize()), pinnedRegs-&gt;sizeRegister);</span>

 896             jit.loadPtr(CCallHelpers::Address(params[0].gpr(), Instance::offsetOfCachedMemory()), baseMemory);
<span class="line-modified"> 897 </span>
<span class="line-modified"> 898             jit.cageConditionally(Gigacage::Primitive, baseMemory, pinnedRegs-&gt;sizeRegister, scratchOrSize);</span>
 899         });
 900 
 901         emitPatchpoint(block, patchpoint, Tmp(), instance);
 902     }
 903 }
 904 
 905 void AirIRGenerator::emitThrowException(CCallHelpers&amp; jit, ExceptionType type)
 906 {
 907     jit.move(CCallHelpers::TrustedImm32(static_cast&lt;uint32_t&gt;(type)), GPRInfo::argumentGPR1);
 908     auto jumpToExceptionStub = jit.jump();
 909 
 910     jit.addLinkTask([jumpToExceptionStub] (LinkBuffer&amp; linkBuffer) {
 911         linkBuffer.link(jumpToExceptionStub, CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(throwExceptionFromWasmThunkGenerator).code()));
 912     });
 913 }
 914 
 915 auto AirIRGenerator::addLocal(Type type, uint32_t count) -&gt; PartialResult
 916 {
<span class="line-modified"> 917     size_t newSize = m_locals.size() + count;</span>
<span class="line-modified"> 918     ASSERT(!(CheckedUint32(count) + m_locals.size()).hasOverflowed());</span>
<span class="line-modified"> 919     ASSERT(newSize &lt;= maxFunctionLocals);</span>
<span class="line-modified"> 920     WASM_COMPILE_FAIL_IF(!m_locals.tryReserveCapacity(newSize), &quot;can&#39;t allocate memory for &quot;, newSize, &quot; locals&quot;);</span>
 921 
 922     for (uint32_t i = 0; i &lt; count; ++i) {
 923         auto local = tmpForType(type);
 924         m_locals.uncheckedAppend(local);
 925         switch (type) {
<span class="line-added"> 926         case Type::Anyref:</span>
<span class="line-added"> 927         case Type::Funcref:</span>
<span class="line-added"> 928             append(Move, Arg::imm(JSValue::encode(jsNull())), local);</span>
<span class="line-added"> 929             break;</span>
 930         case Type::I32:
 931         case Type::I64: {
 932             append(Xor64, local, local);
 933             break;
 934         }
 935         case Type::F32:
 936         case Type::F64: {
 937             auto temp = g64();
 938             // IEEE 754 &quot;0&quot; is just int32/64 zero.
 939             append(Xor64, temp, temp);
 940             append(type == Type::F32 ? Move32ToFloat : Move64ToDouble, temp, local);
 941             break;
 942         }
 943         default:
 944             RELEASE_ASSERT_NOT_REACHED();
 945         }
 946     }
 947     return { };
 948 }
 949 
 950 auto AirIRGenerator::addConstant(Type type, uint64_t value) -&gt; ExpressionType
 951 {
 952     return addConstant(m_currentBlock, type, value);
 953 }
 954 
 955 auto AirIRGenerator::addConstant(BasicBlock* block, Type type, uint64_t value) -&gt; ExpressionType
 956 {
 957     auto result = tmpForType(type);
 958     switch (type) {
 959     case Type::I32:
 960     case Type::I64:
<span class="line-added"> 961     case Type::Anyref:</span>
<span class="line-added"> 962     case Type::Funcref:</span>
 963         append(block, Move, Arg::bigImm(value), result);
 964         break;
 965     case Type::F32:
 966     case Type::F64: {
 967         auto tmp = g64();
 968         append(block, Move, Arg::bigImm(value), tmp);
 969         append(block, type == Type::F32 ? Move32ToFloat : Move64ToDouble, tmp, result);
 970         break;
 971     }
 972 
 973     default:
 974         RELEASE_ASSERT_NOT_REACHED();
 975     }
 976 
 977     return result;
 978 }
 979 
 980 auto AirIRGenerator::addArguments(const Signature&amp; signature) -&gt; PartialResult
 981 {
 982     RELEASE_ASSERT(m_locals.size() == signature.argumentCount()); // We handle arguments in the prologue
 983     return { };
 984 }
 985 
<span class="line-added"> 986 auto AirIRGenerator::addRefIsNull(ExpressionType&amp; value, ExpressionType&amp; result) -&gt; PartialResult</span>
<span class="line-added"> 987 {</span>
<span class="line-added"> 988     ASSERT(value.tmp());</span>
<span class="line-added"> 989     result = tmpForType(Type::I32);</span>
<span class="line-added"> 990     auto tmp = g64();</span>
<span class="line-added"> 991 </span>
<span class="line-added"> 992     append(Move, Arg::bigImm(JSValue::encode(jsNull())), tmp);</span>
<span class="line-added"> 993     append(Compare64, Arg::relCond(MacroAssembler::Equal), value, tmp, result);</span>
<span class="line-added"> 994 </span>
<span class="line-added"> 995     return { };</span>
<span class="line-added"> 996 }</span>
<span class="line-added"> 997 </span>
<span class="line-added"> 998 auto AirIRGenerator::addRefFunc(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult</span>
<span class="line-added"> 999 {</span>
<span class="line-added">1000     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.</span>
<span class="line-added">1001     result = tmpForType(Type::Funcref);</span>
<span class="line-added">1002     emitCCall(&amp;doWasmRefFunc, result, instanceValue(), addConstant(Type::I32, index));</span>
<span class="line-added">1003 </span>
<span class="line-added">1004     return { };</span>
<span class="line-added">1005 }</span>
<span class="line-added">1006 </span>
<span class="line-added">1007 auto AirIRGenerator::addTableGet(unsigned tableIndex, ExpressionType&amp; index, ExpressionType&amp; result) -&gt; PartialResult</span>
<span class="line-added">1008 {</span>
<span class="line-added">1009     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.</span>
<span class="line-added">1010     ASSERT(index.tmp());</span>
<span class="line-added">1011     ASSERT(index.type() == Type::I32);</span>
<span class="line-added">1012     result = tmpForType(m_info.tables[tableIndex].wasmType());</span>
<span class="line-added">1013 </span>
<span class="line-added">1014     emitCCall(&amp;getWasmTableElement, result, instanceValue(), addConstant(Type::I32, tableIndex), index);</span>
<span class="line-added">1015     emitCheck([&amp;] {</span>
<span class="line-added">1016         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), result, result);</span>
<span class="line-added">1017     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {</span>
<span class="line-added">1018         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);</span>
<span class="line-added">1019     });</span>
<span class="line-added">1020 </span>
<span class="line-added">1021     return { };</span>
<span class="line-added">1022 }</span>
<span class="line-added">1023 </span>
<span class="line-added">1024 auto AirIRGenerator::addTableSet(unsigned tableIndex, ExpressionType&amp; index, ExpressionType&amp; value) -&gt; PartialResult</span>
<span class="line-added">1025 {</span>
<span class="line-added">1026     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.</span>
<span class="line-added">1027     ASSERT(index.tmp());</span>
<span class="line-added">1028     ASSERT(index.type() == Type::I32);</span>
<span class="line-added">1029     ASSERT(value.tmp());</span>
<span class="line-added">1030 </span>
<span class="line-added">1031     auto shouldThrow = g32();</span>
<span class="line-added">1032     emitCCall(&amp;setWasmTableElement, shouldThrow, instanceValue(), addConstant(Type::I32, tableIndex), index, value);</span>
<span class="line-added">1033 </span>
<span class="line-added">1034     emitCheck([&amp;] {</span>
<span class="line-added">1035         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), shouldThrow, shouldThrow);</span>
<span class="line-added">1036     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {</span>
<span class="line-added">1037         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);</span>
<span class="line-added">1038     });</span>
<span class="line-added">1039 </span>
<span class="line-added">1040     return { };</span>
<span class="line-added">1041 }</span>
<span class="line-added">1042 </span>
<span class="line-added">1043 auto AirIRGenerator::addTableSize(unsigned tableIndex, ExpressionType&amp; result) -&gt; PartialResult</span>
<span class="line-added">1044 {</span>
<span class="line-added">1045     // FIXME: Emit this inline &lt;https://bugs.webkit.org/show_bug.cgi?id=198506&gt;.</span>
<span class="line-added">1046     result = tmpForType(Type::I32);</span>
<span class="line-added">1047 </span>
<span class="line-added">1048     int32_t (*doSize)(Instance*, unsigned) = [] (Instance* instance, unsigned tableIndex) -&gt; int32_t {</span>
<span class="line-added">1049         return instance-&gt;table(tableIndex)-&gt;length();</span>
<span class="line-added">1050     };</span>
<span class="line-added">1051 </span>
<span class="line-added">1052     emitCCall(doSize, result, instanceValue(), addConstant(Type::I32, tableIndex));</span>
<span class="line-added">1053 </span>
<span class="line-added">1054     return { };</span>
<span class="line-added">1055 }</span>
<span class="line-added">1056 </span>
<span class="line-added">1057 auto AirIRGenerator::addTableGrow(unsigned tableIndex, ExpressionType&amp; fill, ExpressionType&amp; delta, ExpressionType&amp; result) -&gt; PartialResult</span>
<span class="line-added">1058 {</span>
<span class="line-added">1059     ASSERT(fill.tmp());</span>
<span class="line-added">1060     ASSERT(isSubtype(fill.type(), m_info.tables[tableIndex].wasmType()));</span>
<span class="line-added">1061     ASSERT(delta.tmp());</span>
<span class="line-added">1062     ASSERT(delta.type() == Type::I32);</span>
<span class="line-added">1063     result = tmpForType(Type::I32);</span>
<span class="line-added">1064 </span>
<span class="line-added">1065     emitCCall(&amp;doWasmTableGrow, result, instanceValue(), addConstant(Type::I32, tableIndex), fill, delta);</span>
<span class="line-added">1066 </span>
<span class="line-added">1067     return { };</span>
<span class="line-added">1068 }</span>
<span class="line-added">1069 </span>
<span class="line-added">1070 auto AirIRGenerator::addTableFill(unsigned tableIndex, ExpressionType&amp; offset, ExpressionType&amp; fill, ExpressionType&amp; count) -&gt; PartialResult</span>
<span class="line-added">1071 {</span>
<span class="line-added">1072     ASSERT(fill.tmp());</span>
<span class="line-added">1073     ASSERT(isSubtype(fill.type(), m_info.tables[tableIndex].wasmType()));</span>
<span class="line-added">1074     ASSERT(offset.tmp());</span>
<span class="line-added">1075     ASSERT(offset.type() == Type::I32);</span>
<span class="line-added">1076     ASSERT(count.tmp());</span>
<span class="line-added">1077     ASSERT(count.type() == Type::I32);</span>
<span class="line-added">1078 </span>
<span class="line-added">1079     auto result = tmpForType(Type::I32);</span>
<span class="line-added">1080     emitCCall(&amp;doWasmTableFill, result, instanceValue(), addConstant(Type::I32, tableIndex), offset, fill, count);</span>
<span class="line-added">1081 </span>
<span class="line-added">1082     emitCheck([&amp;] {</span>
<span class="line-added">1083         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::Zero), result, result);</span>
<span class="line-added">1084     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {</span>
<span class="line-added">1085         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTableAccess);</span>
<span class="line-added">1086     });</span>
<span class="line-added">1087 </span>
<span class="line-added">1088     return { };</span>
<span class="line-added">1089 }</span>
<span class="line-added">1090 </span>
1091 auto AirIRGenerator::getLocal(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
1092 {
1093     ASSERT(m_locals[index].tmp());
1094     result = tmpForType(m_locals[index].type());
1095     append(moveOpForValueType(m_locals[index].type()), m_locals[index].tmp(), result);
1096     return { };
1097 }
1098 
1099 auto AirIRGenerator::addUnreachable() -&gt; PartialResult
1100 {
1101     B3::PatchpointValue* unreachable = addPatchpoint(B3::Void);
1102     unreachable-&gt;setGenerator([this] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1103         this-&gt;emitThrowException(jit, ExceptionType::Unreachable);
1104     });
1105     unreachable-&gt;effects.terminal = true;
1106     emitPatchpoint(unreachable, Tmp());
1107     return { };
1108 }
1109 
1110 auto AirIRGenerator::addGrowMemory(ExpressionType delta, ExpressionType&amp; result) -&gt; PartialResult
</pre>
<hr />
<pre>
1187 
1188 auto AirIRGenerator::setGlobal(uint32_t index, ExpressionType value) -&gt; PartialResult
1189 {
1190     auto temp = g64();
1191 
1192     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfGlobals(), B3::Width64));
1193     append(Move, Arg::addr(instanceValue(), Instance::offsetOfGlobals()), temp);
1194 
1195     Type type = m_info.globals[index].type;
1196 
1197     int32_t offset = safeCast&lt;int32_t&gt;(index * sizeof(Register));
1198     if (Arg::isValidAddrForm(offset, B3::widthForType(toB3Type(type))))
1199         append(moveOpForValueType(type), value, Arg::addr(temp, offset));
1200     else {
1201         auto temp2 = g64();
1202         append(Move, Arg::bigImm(offset), temp2);
1203         append(Add64, temp2, temp, temp);
1204         append(moveOpForValueType(type), value, Arg::addr(temp));
1205     }
1206 
<span class="line-added">1207     if (isSubtype(type, Anyref))</span>
<span class="line-added">1208         emitWriteBarrierForJSWrapper();</span>
<span class="line-added">1209 </span>
1210     return { };
1211 }
1212 
<span class="line-added">1213 inline void AirIRGenerator::emitWriteBarrierForJSWrapper()</span>
<span class="line-added">1214 {</span>
<span class="line-added">1215     auto cell = g64();</span>
<span class="line-added">1216     auto vm = g64();</span>
<span class="line-added">1217     auto cellState = g32();</span>
<span class="line-added">1218     auto threshold = g32();</span>
<span class="line-added">1219 </span>
<span class="line-added">1220     BasicBlock* fenceCheckPath = m_code.addBlock();</span>
<span class="line-added">1221     BasicBlock* fencePath = m_code.addBlock();</span>
<span class="line-added">1222     BasicBlock* doSlowPath = m_code.addBlock();</span>
<span class="line-added">1223     BasicBlock* continuation = m_code.addBlock();</span>
<span class="line-added">1224 </span>
<span class="line-added">1225     append(Move, Arg::addr(instanceValue(), Instance::offsetOfOwner()), cell);</span>
<span class="line-added">1226     append(Move, Arg::addr(cell, JSWebAssemblyInstance::offsetOfVM()), vm);</span>
<span class="line-added">1227     append(Load8, Arg::addr(cell, JSCell::cellStateOffset()), cellState);</span>
<span class="line-added">1228     append(Move32, Arg::addr(vm, VM::offsetOfHeapBarrierThreshold()), threshold);</span>
<span class="line-added">1229 </span>
<span class="line-added">1230     append(Branch32, Arg::relCond(MacroAssembler::Above), cellState, threshold);</span>
<span class="line-added">1231     m_currentBlock-&gt;setSuccessors(continuation, fenceCheckPath);</span>
<span class="line-added">1232     m_currentBlock = fenceCheckPath;</span>
<span class="line-added">1233 </span>
<span class="line-added">1234     append(Load8, Arg::addr(vm, VM::offsetOfHeapMutatorShouldBeFenced()), threshold);</span>
<span class="line-added">1235     append(BranchTest32, Arg::resCond(MacroAssembler::Zero), threshold, threshold);</span>
<span class="line-added">1236     m_currentBlock-&gt;setSuccessors(doSlowPath, fencePath);</span>
<span class="line-added">1237     m_currentBlock = fencePath;</span>
<span class="line-added">1238 </span>
<span class="line-added">1239     auto* doFence = addPatchpoint(B3::Void);</span>
<span class="line-added">1240     doFence-&gt;setGenerator([] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {</span>
<span class="line-added">1241         jit.memoryFence();</span>
<span class="line-added">1242     });</span>
<span class="line-added">1243     emitPatchpoint(doFence, Tmp());</span>
<span class="line-added">1244 </span>
<span class="line-added">1245     append(Load8, Arg::addr(cell, JSCell::cellStateOffset()), cellState);</span>
<span class="line-added">1246     append(Branch32, Arg::relCond(MacroAssembler::Above), cellState, Arg::imm(blackThreshold));</span>
<span class="line-added">1247     m_currentBlock-&gt;setSuccessors(continuation, doSlowPath);</span>
<span class="line-added">1248     m_currentBlock = doSlowPath;</span>
<span class="line-added">1249 </span>
<span class="line-added">1250     void (*writeBarrier)(JSWebAssemblyInstance*, VM*) = [] (JSWebAssemblyInstance* cell, VM* vm) -&gt; void {</span>
<span class="line-added">1251         ASSERT(cell);</span>
<span class="line-added">1252         ASSERT(vm);</span>
<span class="line-added">1253         vm-&gt;heap.writeBarrierSlowPath(cell);</span>
<span class="line-added">1254     };</span>
<span class="line-added">1255     emitCCall(writeBarrier, TypedTmp(), cell, vm);</span>
<span class="line-added">1256     append(Jump);</span>
<span class="line-added">1257     m_currentBlock-&gt;setSuccessors(continuation);</span>
<span class="line-added">1258     m_currentBlock = continuation;</span>
<span class="line-added">1259 }</span>
<span class="line-added">1260 </span>
1261 inline AirIRGenerator::ExpressionType AirIRGenerator::emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOperation)
1262 {
1263     ASSERT(m_memoryBaseGPR);
1264 
1265     auto result = g64();
1266     append(Move32, pointer, result);
1267 
1268     switch (m_mode) {
1269     case MemoryMode::BoundsChecking: {
1270         // We&#39;re not using signal handling at all, we must therefore check that no memory access exceeds the current memory size.
1271         ASSERT(m_memorySizeGPR);
1272         ASSERT(sizeOfOperation + offset &gt; offset);
1273         auto temp = g64();
1274         append(Move, Arg::bigImm(static_cast&lt;uint64_t&gt;(sizeOfOperation) + offset - 1), temp);
1275         append(Add64, result, temp);
1276 
1277         emitCheck([&amp;] {
1278             return Inst(Branch64, nullptr, Arg::relCond(MacroAssembler::AboveOrEqual), temp, Tmp(m_memorySizeGPR));
1279         }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1280             this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsMemoryAccess);
</pre>
<hr />
<pre>
1586 {
1587     ASSERT(nonZero.type() == zero.type());
1588     result = tmpForType(nonZero.type());
1589     append(moveOpForValueType(nonZero.type()), nonZero, result);
1590 
1591     BasicBlock* isZero = m_code.addBlock();
1592     BasicBlock* continuation = m_code.addBlock();
1593 
1594     append(BranchTest32, Arg::resCond(MacroAssembler::Zero), condition, condition);
1595     m_currentBlock-&gt;setSuccessors(isZero, continuation);
1596 
1597     append(isZero, moveOpForValueType(zero.type()), zero, result);
1598     append(isZero, Jump);
1599     isZero-&gt;setSuccessors(continuation);
1600 
1601     m_currentBlock = continuation;
1602 
1603     return { };
1604 }
1605 
<span class="line-modified">1606 void AirIRGenerator::emitEntryTierUpCheck(int32_t incrementCount, B3::Origin origin)</span>
1607 {
1608     UNUSED_PARAM(origin);
1609 
1610     if (!m_tierUp)
1611         return;
1612 
1613     auto countdownPtr = g64();





1614 
<span class="line-modified">1615     append(Move, Arg::bigImm(reinterpret_cast&lt;uint64_t&gt;(&amp;m_tierUp-&gt;m_counter)), countdownPtr);</span>



1616 
1617     auto* patch = addPatchpoint(B3::Void);
1618     B3::Effects effects = B3::Effects::none();
1619     effects.reads = B3::HeapRange::top();
1620     effects.writes = B3::HeapRange::top();
1621     patch-&gt;effects = effects;
<span class="line-added">1622     patch-&gt;clobber(RegisterSet::macroScratchRegisters());</span>
1623 
1624     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
<span class="line-modified">1625         AllowMacroScratchRegisterUsage allowScratch(jit);</span>
<span class="line-modified">1626 </span>
<span class="line-added">1627         CCallHelpers::Jump tierUp = jit.branchAdd32(CCallHelpers::PositiveOrZero, CCallHelpers::TrustedImm32(incrementCount), CCallHelpers::Address(params[0].gpr()));</span>
<span class="line-added">1628         CCallHelpers::Label tierUpResume = jit.label();</span>
1629 
1630         params.addLatePath([=] (CCallHelpers&amp; jit) {
1631             tierUp.link(&amp;jit);
1632 
1633             const unsigned extraPaddingBytes = 0;
1634             RegisterSet registersToSpill = { };
1635             registersToSpill.add(GPRInfo::argumentGPR1);
1636             unsigned numberOfStackBytesUsedForRegisterPreservation = ScratchRegisterAllocator::preserveRegistersToStackForCall(jit, registersToSpill, extraPaddingBytes);
1637 
1638             jit.move(MacroAssembler::TrustedImm32(m_functionIndex), GPRInfo::argumentGPR1);
1639             MacroAssembler::Call call = jit.nearCall();
1640 
1641             ScratchRegisterAllocator::restoreRegistersFromStackForCall(jit, registersToSpill, RegisterSet(), numberOfStackBytesUsedForRegisterPreservation, extraPaddingBytes);
1642             jit.jump(tierUpResume);
1643 
1644             jit.addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
<span class="line-modified">1645                 MacroAssembler::repatchNearCall(linkBuffer.locationOfNearCall&lt;NoPtrTag&gt;(call), CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(triggerOMGEntryTierUpThunkGenerator).code()));</span>

1646             });
1647         });
1648     });
1649 
<span class="line-modified">1650     emitPatchpoint(patch, Tmp(), countdownPtr);</span>
1651 }
1652 
<span class="line-modified">1653 void AirIRGenerator::emitLoopTierUpCheck(int32_t incrementCount, const Stack&amp; expressionStack, uint32_t loopIndex, uint32_t outerLoopIndex, B3::Origin origin)</span>
<span class="line-added">1654 {</span>
<span class="line-added">1655     UNUSED_PARAM(origin);</span>
<span class="line-added">1656 </span>
<span class="line-added">1657     if (!m_tierUp)</span>
<span class="line-added">1658         return;</span>
<span class="line-added">1659 </span>
<span class="line-added">1660     ASSERT(m_tierUp-&gt;osrEntryTriggers().size() == loopIndex);</span>
<span class="line-added">1661     m_tierUp-&gt;osrEntryTriggers().append(TierUpCount::TriggerReason::DontTrigger);</span>
<span class="line-added">1662     m_tierUp-&gt;outerLoops().append(outerLoopIndex);</span>
<span class="line-added">1663 </span>
<span class="line-added">1664     auto countdownPtr = g64();</span>
<span class="line-added">1665 </span>
<span class="line-added">1666     append(Move, Arg::bigImm(reinterpret_cast&lt;uint64_t&gt;(&amp;m_tierUp-&gt;m_counter)), countdownPtr);</span>
<span class="line-added">1667 </span>
<span class="line-added">1668     auto* patch = addPatchpoint(B3::Void);</span>
<span class="line-added">1669     B3::Effects effects = B3::Effects::none();</span>
<span class="line-added">1670     effects.reads = B3::HeapRange::top();</span>
<span class="line-added">1671     effects.writes = B3::HeapRange::top();</span>
<span class="line-added">1672     effects.exitsSideways = true;</span>
<span class="line-added">1673     patch-&gt;effects = effects;</span>
<span class="line-added">1674 </span>
<span class="line-added">1675     patch-&gt;clobber(RegisterSet::macroScratchRegisters());</span>
<span class="line-added">1676     RegisterSet clobberLate;</span>
<span class="line-added">1677     clobberLate.add(GPRInfo::argumentGPR0);</span>
<span class="line-added">1678     patch-&gt;clobberLate(clobberLate);</span>
<span class="line-added">1679 </span>
<span class="line-added">1680     Vector&lt;ConstrainedTmp&gt; patchArgs;</span>
<span class="line-added">1681     patchArgs.append(countdownPtr);</span>
<span class="line-added">1682 </span>
<span class="line-added">1683     Vector&lt;B3::Type&gt; types;</span>
<span class="line-added">1684     for (auto&amp; local : m_locals) {</span>
<span class="line-added">1685         patchArgs.append(ConstrainedTmp(local, B3::ValueRep::ColdAny));</span>
<span class="line-added">1686         types.append(toB3Type(local.type()));</span>
<span class="line-added">1687     }</span>
<span class="line-added">1688     for (auto&amp; expression : expressionStack) {</span>
<span class="line-added">1689         patchArgs.append(ConstrainedTmp(expression, B3::ValueRep::ColdAny));</span>
<span class="line-added">1690         types.append(toB3Type(expression.type()));</span>
<span class="line-added">1691     }</span>
<span class="line-added">1692 </span>
<span class="line-added">1693     TierUpCount::TriggerReason* forceEntryTrigger = &amp;(m_tierUp-&gt;osrEntryTriggers().last());</span>
<span class="line-added">1694     static_assert(!static_cast&lt;uint8_t&gt;(TierUpCount::TriggerReason::DontTrigger), &quot;the JIT code assumes non-zero means &#39;enter&#39;&quot;);</span>
<span class="line-added">1695     static_assert(sizeof(TierUpCount::TriggerReason) == 1, &quot;branchTest8 assumes this size&quot;);</span>
<span class="line-added">1696     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {</span>
<span class="line-added">1697         AllowMacroScratchRegisterUsage allowScratch(jit);</span>
<span class="line-added">1698         CCallHelpers::Jump forceOSREntry = jit.branchTest8(CCallHelpers::NonZero, CCallHelpers::AbsoluteAddress(forceEntryTrigger));</span>
<span class="line-added">1699         CCallHelpers::Jump tierUp = jit.branchAdd32(CCallHelpers::PositiveOrZero, CCallHelpers::TrustedImm32(incrementCount), CCallHelpers::Address(params[0].gpr()));</span>
<span class="line-added">1700         MacroAssembler::Label tierUpResume = jit.label();</span>
<span class="line-added">1701 </span>
<span class="line-added">1702         OSREntryData&amp; osrEntryData = m_tierUp-&gt;addOSREntryData(m_functionIndex, loopIndex);</span>
<span class="line-added">1703         for (unsigned index = 0; index &lt; types.size(); ++index)</span>
<span class="line-added">1704             osrEntryData.values().constructAndAppend(params[index + 1], types[index]);</span>
<span class="line-added">1705         OSREntryData* osrEntryDataPtr = &amp;osrEntryData;</span>
<span class="line-added">1706 </span>
<span class="line-added">1707         params.addLatePath([=] (CCallHelpers&amp; jit) {</span>
<span class="line-added">1708             AllowMacroScratchRegisterUsage allowScratch(jit);</span>
<span class="line-added">1709             forceOSREntry.link(&amp;jit);</span>
<span class="line-added">1710             tierUp.link(&amp;jit);</span>
<span class="line-added">1711 </span>
<span class="line-added">1712             jit.probe(triggerOSREntryNow, osrEntryDataPtr);</span>
<span class="line-added">1713             jit.branchTestPtr(CCallHelpers::Zero, GPRInfo::argumentGPR0).linkTo(tierUpResume, &amp;jit);</span>
<span class="line-added">1714             jit.farJump(GPRInfo::argumentGPR1, WasmEntryPtrTag);</span>
<span class="line-added">1715         });</span>
<span class="line-added">1716     });</span>
<span class="line-added">1717 </span>
<span class="line-added">1718     emitPatchpoint(patch, Tmp(), WTFMove(patchArgs));</span>
<span class="line-added">1719 }</span>
<span class="line-added">1720 </span>
<span class="line-added">1721 AirIRGenerator::ControlData AirIRGenerator::addLoop(Type signature, const Stack&amp; expressionStack, uint32_t loopIndex)</span>
1722 {
1723     BasicBlock* body = m_code.addBlock();
1724     BasicBlock* continuation = m_code.addBlock();
1725 
1726     append(Jump);
1727     m_currentBlock-&gt;setSuccessors(body);
1728 
<span class="line-added">1729     uint32_t outerLoopIndex = this-&gt;outerLoopIndex();</span>
<span class="line-added">1730     m_outerLoops.append(loopIndex);</span>
1731     m_currentBlock = body;
<span class="line-modified">1732     emitLoopTierUpCheck(TierUpCount::loopIncrement(), expressionStack, loopIndex, outerLoopIndex, origin());</span>
1733 
1734     return ControlData(origin(), signature, tmpForType(signature), BlockType::Loop, continuation, body);
1735 }
1736 
1737 AirIRGenerator::ControlData AirIRGenerator::addTopLevel(Type signature)
1738 {
1739     return ControlData(B3::Origin(), signature, tmpForType(signature), BlockType::TopLevel, m_code.addBlock());
1740 }
1741 
1742 AirIRGenerator::ControlData AirIRGenerator::addBlock(Type signature)
1743 {
1744     return ControlData(origin(), signature, tmpForType(signature), BlockType::Block, m_code.addBlock());
1745 }
1746 
1747 auto AirIRGenerator::addIf(ExpressionType condition, Type signature, ControlType&amp; result) -&gt; PartialResult
1748 {
1749     BasicBlock* taken = m_code.addBlock();
1750     BasicBlock* notTaken = m_code.addBlock();
1751     BasicBlock* continuation = m_code.addBlock();
1752 
1753     // Wasm bools are i32.
1754     append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1755     m_currentBlock-&gt;setSuccessors(taken, notTaken);
1756 
1757     m_currentBlock = taken;
1758     result = ControlData(origin(), signature, tmpForType(signature), BlockType::If, continuation, notTaken);
1759     return { };
1760 }
1761 
<span class="line-modified">1762 auto AirIRGenerator::addElse(ControlData&amp; data, const Stack&amp; currentStack) -&gt; PartialResult</span>
1763 {
1764     unifyValuesWithBlock(currentStack, data.result);
1765     append(Jump);
1766     m_currentBlock-&gt;setSuccessors(data.continuation);
1767     return addElseToUnreachable(data);
1768 }
1769 
1770 auto AirIRGenerator::addElseToUnreachable(ControlData&amp; data) -&gt; PartialResult
1771 {
1772     ASSERT(data.type() == BlockType::If);
1773     m_currentBlock = data.special;
1774     data.convertIfToBlock();
1775     return { };
1776 }
1777 
1778 auto AirIRGenerator::addReturn(const ControlData&amp; data, const ExpressionList&amp; returnValues) -&gt; PartialResult
1779 {
1780     ASSERT(returnValues.size() &lt;= 1);
1781     if (returnValues.size()) {
1782         Tmp returnValueGPR = Tmp(GPRInfo::returnValueGPR);
1783         Tmp returnValueFPR = Tmp(FPRInfo::returnValueFPR);
1784         switch (data.signature()) {
1785         case Type::I32:
1786             append(Move32, returnValues[0], returnValueGPR);
1787             append(Ret32, returnValueGPR);
1788             break;
1789         case Type::I64:
<span class="line-added">1790         case Type::Anyref:</span>
<span class="line-added">1791         case Type::Funcref:</span>
1792             append(Move, returnValues[0], returnValueGPR);
1793             append(Ret64, returnValueGPR);
1794             break;
1795         case Type::F32:
1796             append(MoveFloat, returnValues[0], returnValueFPR);
1797             append(RetFloat, returnValueFPR);
1798             break;
1799         case Type::F64:
1800             append(MoveDouble, returnValues[0], returnValueFPR);
1801             append(RetFloat, returnValueFPR);
1802             break;
1803         default:
1804             RELEASE_ASSERT_NOT_REACHED();
1805         }
1806     } else
1807         append(RetVoid);
1808     return { };
1809 }
1810 
1811 // NOTE: All branches in Wasm are on 32-bit ints
1812 
<span class="line-modified">1813 auto AirIRGenerator::addBranch(ControlData&amp; data, ExpressionType condition, const Stack&amp; returnValues) -&gt; PartialResult</span>
1814 {
1815     unifyValuesWithBlock(returnValues, data.resultForBranch());
1816 
1817     BasicBlock* target = data.targetBlockForBranch();
1818     if (condition) {
1819         BasicBlock* continuation = m_code.addBlock();
1820         append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1821         m_currentBlock-&gt;setSuccessors(target, continuation);
1822         m_currentBlock = continuation;
1823     } else {
1824         append(Jump);
1825         m_currentBlock-&gt;setSuccessors(target);
1826     }
1827 
1828     return { };
1829 }
1830 
<span class="line-modified">1831 auto AirIRGenerator::addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTarget, const Stack&amp; expressionStack) -&gt; PartialResult</span>
1832 {
1833     auto&amp; successors = m_currentBlock-&gt;successors();
1834     ASSERT(successors.isEmpty());
1835     for (const auto&amp; target : targets) {
1836         unifyValuesWithBlock(expressionStack, target-&gt;resultForBranch());
1837         successors.append(target-&gt;targetBlockForBranch());
1838     }
1839     unifyValuesWithBlock(expressionStack, defaultTarget.resultForBranch());
1840     successors.append(defaultTarget.targetBlockForBranch());
1841 
1842     ASSERT(condition.type() == Type::I32);
1843 
1844     // FIXME: We should consider dynamically switching between a jump table
1845     // and a binary switch depending on the number of successors.
1846     // https://bugs.webkit.org/show_bug.cgi?id=194477
1847 
1848     size_t numTargets = targets.size();
1849 
1850     auto* patchpoint = addPatchpoint(B3::Void);
1851     patchpoint-&gt;effects = B3::Effects::none();
</pre>
<hr />
<pre>
1874             caseJumps[index] = jit.jump();
1875         }
1876 
1877         CCallHelpers::JumpList fallThrough = binarySwitch.fallThrough();
1878 
1879         Vector&lt;Box&lt;CCallHelpers::Label&gt;&gt; successorLabels = params.successorLabels();
1880         ASSERT(successorLabels.size() == caseJumps.size() + 1);
1881 
1882         params.addLatePath([=, caseJumps = WTFMove(caseJumps), successorLabels = WTFMove(successorLabels)] (CCallHelpers&amp; jit) {
1883             for (size_t i = 0; i &lt; numTargets; ++i)
1884                 caseJumps[i].linkTo(*successorLabels[i], &amp;jit);
1885             fallThrough.linkTo(*successorLabels[numTargets], &amp;jit);
1886         });
1887     });
1888 
1889     emitPatchpoint(patchpoint, TypedTmp(), condition);
1890 
1891     return { };
1892 }
1893 
<span class="line-modified">1894 auto AirIRGenerator::endBlock(ControlEntry&amp; entry, Stack&amp; expressionStack) -&gt; PartialResult</span>
1895 {
1896     ControlData&amp; data = entry.controlData;
1897 
1898     unifyValuesWithBlock(expressionStack, data.result);
1899     append(Jump);
1900     m_currentBlock-&gt;setSuccessors(data.continuation);
1901 
1902     return addEndToUnreachable(entry);
1903 }
1904 
1905 
1906 auto AirIRGenerator::addEndToUnreachable(ControlEntry&amp; entry) -&gt; PartialResult
1907 {
1908     ControlData&amp; data = entry.controlData;
1909     m_currentBlock = data.continuation;
1910 
1911     if (data.type() == BlockType::If) {
1912         append(data.special, Jump);
1913         data.special-&gt;setSuccessors(m_currentBlock);
1914     }
1915 
<span class="line-added">1916     if (data.type() == BlockType::Loop)</span>
<span class="line-added">1917         m_outerLoops.removeLast();</span>
<span class="line-added">1918 </span>
1919     for (const auto&amp; result : data.result)
1920         entry.enclosedExpressionStack.append(result);
1921 
1922     // TopLevel does not have any code after this so we need to make sure we emit a return here.
1923     if (data.type() == BlockType::TopLevel)
1924         return addReturn(data, entry.enclosedExpressionStack);
1925 
1926     return { };
1927 }
1928 
1929 auto AirIRGenerator::addCall(uint32_t functionIndex, const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result) -&gt; PartialResult
1930 {
1931     ASSERT(signature.argumentCount() == args.size());
1932 
1933     m_makesCalls = true;
1934 
1935     Type returnType = signature.returnType();
1936     if (returnType != Type::Void)
1937         result = tmpForType(returnType);
1938 
</pre>
<hr />
<pre>
2027 
2028         Vector&lt;ConstrainedTmp&gt; patchArgs;
2029         wasmCallingConventionAir().setupCall(m_code, returnType, patchpoint, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {
2030             patchArgs.append({ tmp, rep });
2031         });
2032 
2033         patchpoint-&gt;setGenerator([unlinkedWasmToWasmCalls, functionIndex] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2034             AllowMacroScratchRegisterUsage allowScratch(jit);
2035             CCallHelpers::Call call = jit.threadSafePatchableNearCall();
2036             jit.addLinkTask([unlinkedWasmToWasmCalls, call, functionIndex] (LinkBuffer&amp; linkBuffer) {
2037                 unlinkedWasmToWasmCalls-&gt;append({ linkBuffer.locationOfNearCall&lt;WasmEntryPtrTag&gt;(call), functionIndex });
2038             });
2039         });
2040 
2041         emitPatchpoint(m_currentBlock, patchpoint, result, WTFMove(patchArgs));
2042     }
2043 
2044     return { };
2045 }
2046 
<span class="line-modified">2047 auto AirIRGenerator::addCallIndirect(unsigned tableIndex, const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result) -&gt; PartialResult</span>
2048 {
2049     ExpressionType calleeIndex = args.takeLast();
2050     ASSERT(signature.argumentCount() == args.size());
<span class="line-added">2051     ASSERT(m_info.tableCount() &gt; tableIndex);</span>
<span class="line-added">2052     ASSERT(m_info.tables[tableIndex].type() == TableElementType::Funcref);</span>
2053 
2054     m_makesCalls = true;
2055     // Note: call indirect can call either WebAssemblyFunction or WebAssemblyWrapperFunction. Because
2056     // WebAssemblyWrapperFunction is like calling into the embedder, we conservatively assume all call indirects
2057     // can be to the embedder for our stack check calculation.
2058     m_maxNumJSCallArguments = std::max(m_maxNumJSCallArguments, static_cast&lt;uint32_t&gt;(args.size()));
2059 
2060     auto currentInstance = g64();
2061     append(Move, instanceValue(), currentInstance);
2062 
2063     ExpressionType callableFunctionBuffer = g64();
2064     ExpressionType instancesBuffer = g64();
2065     ExpressionType callableFunctionBufferLength = g64();
2066     {
<span class="line-modified">2067         RELEASE_ASSERT(Arg::isValidAddrForm(FuncRefTable::offsetOfFunctions(), B3::Width64));</span>
<span class="line-modified">2068         RELEASE_ASSERT(Arg::isValidAddrForm(FuncRefTable::offsetOfInstances(), B3::Width64));</span>
<span class="line-modified">2069         RELEASE_ASSERT(Arg::isValidAddrForm(FuncRefTable::offsetOfLength(), B3::Width64));</span>
<span class="line-modified">2070 </span>
<span class="line-modified">2071         if (UNLIKELY(!Arg::isValidAddrForm(Instance::offsetOfTablePtr(m_numImportFunctions, tableIndex), B3::Width64))) {</span>
<span class="line-modified">2072             append(Move, Arg::bigImm(Instance::offsetOfTablePtr(m_numImportFunctions, tableIndex)), callableFunctionBufferLength);</span>
<span class="line-modified">2073             append(Add64, instanceValue(), callableFunctionBufferLength);</span>
<span class="line-modified">2074             append(Move, Arg::addr(callableFunctionBufferLength), callableFunctionBufferLength);</span>
<span class="line-added">2075         } else</span>
<span class="line-added">2076             append(Move, Arg::addr(instanceValue(), Instance::offsetOfTablePtr(m_numImportFunctions, tableIndex)), callableFunctionBufferLength);</span>
<span class="line-added">2077         append(Move, Arg::addr(callableFunctionBufferLength, FuncRefTable::offsetOfFunctions()), callableFunctionBuffer);</span>
<span class="line-added">2078         append(Move, Arg::addr(callableFunctionBufferLength, FuncRefTable::offsetOfInstances()), instancesBuffer);</span>
2079         append(Move32, Arg::addr(callableFunctionBufferLength, Table::offsetOfLength()), callableFunctionBufferLength);
2080     }
2081 
2082     append(Move32, calleeIndex, calleeIndex);
2083 
2084     // Check the index we are looking for is valid.
2085     emitCheck([&amp;] {
2086         return Inst(Branch32, nullptr, Arg::relCond(MacroAssembler::AboveOrEqual), calleeIndex, callableFunctionBufferLength);
2087     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2088         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsCallIndirect);
2089     });
2090 
2091     ExpressionType calleeCode = g64();
2092     {
2093         ExpressionType calleeSignatureIndex = g64();
2094         // Compute the offset in the table index space we are looking for.
2095         append(Move, Arg::imm(sizeof(WasmToWasmImportableFunction)), calleeSignatureIndex);
2096         append(Mul64, calleeIndex, calleeSignatureIndex);
2097         append(Add64, callableFunctionBuffer, calleeSignatureIndex);
2098 
</pre>
<hr />
<pre>
2124         });
2125     }
2126 
2127     // Do a context switch if needed.
2128     {
2129         auto newContextInstance = g64();
2130         append(Move, Arg::index(instancesBuffer, calleeIndex, 8, 0), newContextInstance);
2131 
2132         BasicBlock* doContextSwitch = m_code.addBlock();
2133         BasicBlock* continuation = m_code.addBlock();
2134 
2135         append(Branch64, Arg::relCond(MacroAssembler::Equal), newContextInstance, instanceValue());
2136         m_currentBlock-&gt;setSuccessors(continuation, doContextSwitch);
2137 
2138         auto* patchpoint = addPatchpoint(B3::Void);
2139         patchpoint-&gt;effects.writesPinned = true;
2140         // We pessimistically assume we&#39;re calling something with BoundsChecking memory.
2141         // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
2142         patchpoint-&gt;clobber(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
2143         patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
<span class="line-added">2144         patchpoint-&gt;numGPScratchRegisters = Gigacage::isEnabled(Gigacage::Primitive) ? 1 : 0;</span>
<span class="line-added">2145 </span>
2146         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2147             AllowMacroScratchRegisterUsage allowScratch(jit);
2148             GPRReg newContextInstance = params[0].gpr();
2149             GPRReg oldContextInstance = params[1].gpr();
2150             const PinnedRegisterInfo&amp; pinnedRegs = PinnedRegisterInfo::get();

2151             GPRReg baseMemory = pinnedRegs.baseMemoryPointer;
2152             ASSERT(newContextInstance != baseMemory);
2153             jit.loadPtr(CCallHelpers::Address(oldContextInstance, Instance::offsetOfCachedStackLimit()), baseMemory);
2154             jit.storePtr(baseMemory, CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedStackLimit()));
2155             jit.storeWasmContextInstance(newContextInstance);

2156             // FIXME: We should support more than one memory size register
2157             //   see: https://bugs.webkit.org/show_bug.cgi?id=162952
<span class="line-modified">2158             ASSERT(pinnedRegs.sizeRegister != newContextInstance);</span>
<span class="line-modified">2159             GPRReg scratchOrSize = Gigacage::isEnabled(Gigacage::Primitive) ? params.gpScratch(0) : pinnedRegs.sizeRegister;</span>
<span class="line-modified">2160 </span>
<span class="line-modified">2161             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemorySize()), pinnedRegs.sizeRegister); // Memory size.</span>
2162             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemory()), baseMemory); // Memory::void*.
<span class="line-added">2163 </span>
<span class="line-added">2164             jit.cageConditionally(Gigacage::Primitive, baseMemory, pinnedRegs.sizeRegister, scratchOrSize);</span>
2165         });
2166 
2167         emitPatchpoint(doContextSwitch, patchpoint, Tmp(), newContextInstance, instanceValue());
2168         append(doContextSwitch, Jump);
2169         doContextSwitch-&gt;setSuccessors(continuation);
2170 
2171         m_currentBlock = continuation;
2172     }
2173 
2174     append(Move, Arg::addr(calleeCode), calleeCode);
2175 
2176     Type returnType = signature.returnType();
2177     if (returnType != Type::Void)
2178         result = tmpForType(returnType);
2179 
2180     auto* patch = addPatchpoint(toB3Type(returnType));
2181     patch-&gt;effects.writesPinned = true;
2182     patch-&gt;effects.readsPinned = true;
2183     // We need to clobber all potential pinned registers since we might be leaving the instance.
2184     // We pessimistically assume we&#39;re always calling something that is bounds checking so
</pre>
<hr />
<pre>
2190     Vector&lt;ConstrainedTmp&gt; emitArgs;
2191     emitArgs.append(calleeCode);
2192     wasmCallingConventionAir().setupCall(m_code, returnType, patch, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {
2193         emitArgs.append({ tmp, rep });
2194     });
2195     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2196         AllowMacroScratchRegisterUsage allowScratch(jit);
2197         jit.call(params[returnType == Void ? 0 : 1].gpr(), WasmEntryPtrTag);
2198     });
2199 
2200     emitPatchpoint(m_currentBlock, patch, result, WTFMove(emitArgs));
2201 
2202     // The call could have been to another WebAssembly instance, and / or could have modified our Memory.
2203     restoreWebAssemblyGlobalState(RestoreCachedStackLimit::Yes, m_info.memory, currentInstance, m_currentBlock);
2204 
2205     return { };
2206 }
2207 
2208 void AirIRGenerator::unify(const ExpressionType&amp; dst, const ExpressionType&amp; source)
2209 {
<span class="line-modified">2210     ASSERT(isSubtype(source.type(), dst.type()));</span>
2211     append(moveOpForValueType(dst.type()), source, dst);
2212 }
2213 
<span class="line-modified">2214 void AirIRGenerator::unifyValuesWithBlock(const Stack&amp; resultStack, const ResultList&amp; result)</span>
2215 {
2216     ASSERT(result.size() &lt;= resultStack.size());
2217 
2218     for (size_t i = 0; i &lt; result.size(); ++i)
2219         unify(result[result.size() - 1 - i], resultStack[resultStack.size() - 1 - i]);
2220 }
2221 
<span class="line-modified">2222 void AirIRGenerator::dump(const Vector&lt;ControlEntry&gt;&amp;, const Stack*)</span>
2223 {
2224 }
2225 
2226 auto AirIRGenerator::origin() -&gt; B3::Origin
2227 {
2228     // FIXME: We should implement a way to give Inst&#39;s an origin.
2229     return B3::Origin();
2230 }
2231 
2232 Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, String&gt; parseAndCompileAir(CompilationContext&amp; compilationContext, const uint8_t* functionStart, size_t functionLength, const Signature&amp; signature, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, const ModuleInformation&amp; info, MemoryMode mode, uint32_t functionIndex, TierUpCount* tierUp, ThrowWasmException throwWasmException)
2233 {
<span class="line-modified">2234     auto result = makeUnique&lt;InternalFunction&gt;();</span>
2235 
<span class="line-modified">2236     compilationContext.embedderEntrypointJIT = makeUnique&lt;CCallHelpers&gt;();</span>
<span class="line-modified">2237     compilationContext.wasmEntrypointJIT = makeUnique&lt;CCallHelpers&gt;();</span>
2238 
2239     B3::Procedure procedure;
2240     Code&amp; code = procedure.code();
2241 
2242     procedure.setOriginPrinter([] (PrintStream&amp; out, B3::Origin origin) {
2243         if (origin.data())
2244             out.print(&quot;Wasm: &quot;, bitwise_cast&lt;OpcodeOrigin&gt;(origin));
2245     });
2246 
2247     // This means we cannot use either StackmapGenerationParams::usedRegisters() or
2248     // StackmapGenerationParams::unavailableRegisters(). In exchange for this concession, we
2249     // don&#39;t strictly need to run Air::reportUsedRegisters(), which saves a bit of CPU time at
2250     // optLevel=1.
2251     procedure.setNeedsUsedRegisters(false);
2252 
<span class="line-modified">2253     procedure.setOptLevel(Options::webAssemblyBBQAirOptimizationLevel());</span>
2254 
2255     AirIRGenerator irGenerator(info, procedure, result.get(), unlinkedWasmToWasmCalls, mode, functionIndex, tierUp, throwWasmException, signature);
2256     FunctionParser&lt;AirIRGenerator&gt; parser(irGenerator, functionStart, functionLength, signature, info);
2257     WASM_FAIL_IF_HELPER_FAILS(parser.parse());
2258 
2259 
2260     for (BasicBlock* block : code) {
2261         for (size_t i = 0; i &lt; block-&gt;numSuccessors(); ++i)
2262             block-&gt;successorBlock(i)-&gt;addPredecessor(block);
2263     }
2264 
2265     {
<span class="line-added">2266         if (UNLIKELY(shouldDumpIRAtEachPhase(B3::AirMode))) {</span>
<span class="line-added">2267             dataLogLn(&quot;Generated patchpoints&quot;);</span>
<span class="line-added">2268             for (B3::PatchpointValue** patch : irGenerator.patchpoints())</span>
<span class="line-added">2269                 dataLogLn(deepDump(procedure, *patch));</span>
<span class="line-added">2270         }</span>
<span class="line-added">2271 </span>
2272         B3::Air::prepareForGeneration(code);
2273         B3::Air::generate(code, *compilationContext.wasmEntrypointJIT);
2274         compilationContext.wasmEntrypointByproducts = procedure.releaseByproducts();
2275         result-&gt;entrypoint.calleeSaveRegisters = code.calleeSaveRegisterAtOffsetList();
2276     }
2277 
<span class="line-modified">2278     return result;</span>
2279 }
2280 
2281 template &lt;typename IntType&gt;
2282 void AirIRGenerator::emitChecksForModOrDiv(bool isSignedDiv, ExpressionType left, ExpressionType right)
2283 {
2284     static_assert(sizeof(IntType) == 4 || sizeof(IntType) == 8, &quot;&quot;);
2285 
2286     emitCheck([&amp;] {
2287         return Inst(sizeof(IntType) == 4 ? BranchTest32 : BranchTest64, nullptr, Arg::resCond(MacroAssembler::Zero), right, right);
2288     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2289         this-&gt;emitThrowException(jit, ExceptionType::DivisionByZero);
2290     });
2291 
2292     if (isSignedDiv) {
2293         ASSERT(std::is_signed&lt;IntType&gt;::value);
2294         IntType min = std::numeric_limits&lt;IntType&gt;::min();
2295 
2296         // FIXME: Better isel for compare with imms here.
2297         // https://bugs.webkit.org/show_bug.cgi?id=193999
2298         auto minTmp = sizeof(IntType) == 4 ? g32() : g64();
</pre>
<hr />
<pre>
3029 {
3030     return addIntegerSub(Sub32, arg0, arg1, result);
3031 }
3032 
3033 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Le&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3034 {
3035     result = g32();
3036     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqual), arg0, arg1, result);
3037     return { };
3038 }
3039 
3040 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32DemoteF64&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3041 {
3042     result = f32();
3043     append(ConvertDoubleToFloat, arg0, result);
3044     return { };
3045 }
3046 
3047 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Min&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3048 {
<span class="line-modified">3049     return addFloatingPointMinOrMax(F32, MinOrMax::Min, arg0, arg1, result);</span>
























3050 }
3051 
3052 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Ne&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3053 {
3054     result = g32();
3055     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleNotEqualOrUnordered), arg0, arg1, result);
3056     return { };
3057 }
3058 
3059 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Lt&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3060 {
3061     result = g32();
3062     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1, result);
3063     return { };
3064 }
3065 
<span class="line-modified">3066 auto AirIRGenerator::addFloatingPointMinOrMax(Type floatType, MinOrMax minOrMax, ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult</span>
3067 {
<span class="line-modified">3068     ASSERT(floatType == F32 || floatType == F64);</span>
<span class="line-added">3069     result = tmpForType(floatType);</span>
3070 
3071     BasicBlock* isEqual = m_code.addBlock();
3072     BasicBlock* notEqual = m_code.addBlock();
<span class="line-modified">3073     BasicBlock* isLessThan = m_code.addBlock();</span>
<span class="line-added">3074     BasicBlock* notLessThan = m_code.addBlock();</span>
<span class="line-added">3075     BasicBlock* isGreaterThan = m_code.addBlock();</span>
<span class="line-added">3076     BasicBlock* isNaN = m_code.addBlock();</span>
3077     BasicBlock* continuation = m_code.addBlock();
3078 
<span class="line-modified">3079     auto branchOp = floatType == F32 ? BranchFloat : BranchDouble;</span>
<span class="line-added">3080     append(m_currentBlock, branchOp, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>
3081     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);
3082 
<span class="line-modified">3083     append(notEqual, branchOp, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-added">3084     notEqual-&gt;setSuccessors(isLessThan, notLessThan);</span>
<span class="line-added">3085 </span>
<span class="line-added">3086     append(notLessThan, branchOp, Arg::doubleCond(MacroAssembler::DoubleGreaterThan), arg0, arg1);</span>
<span class="line-added">3087     notLessThan-&gt;setSuccessors(isGreaterThan, isNaN);</span>
<span class="line-added">3088 </span>
<span class="line-added">3089     auto andOp = floatType == F32 ? AndFloat : AndDouble;</span>
<span class="line-added">3090     auto orOp = floatType == F32 ? OrFloat : OrDouble;</span>
<span class="line-added">3091     append(isEqual, minOrMax == MinOrMax::Max ? andOp : orOp, arg0, arg1, result);</span>
3092     append(isEqual, Jump);
3093     isEqual-&gt;setSuccessors(continuation);
3094 
<span class="line-modified">3095     auto isLessThanResult = minOrMax == MinOrMax::Max ? arg1 : arg0;</span>
<span class="line-modified">3096     append(isLessThan, moveOpForValueType(floatType), isLessThanResult, result);</span>
<span class="line-modified">3097     append(isLessThan, Jump);</span>
<span class="line-added">3098     isLessThan-&gt;setSuccessors(continuation);</span>
<span class="line-added">3099 </span>
<span class="line-added">3100     auto isGreaterThanResult = minOrMax == MinOrMax::Max ? arg0 : arg1;</span>
<span class="line-added">3101     append(isGreaterThan, moveOpForValueType(floatType), isGreaterThanResult, result);</span>
<span class="line-added">3102     append(isGreaterThan, Jump);</span>
<span class="line-added">3103     isGreaterThan-&gt;setSuccessors(continuation);</span>
3104 
<span class="line-modified">3105     auto addOp = floatType == F32 ? AddFloat : AddDouble;</span>
<span class="line-modified">3106     append(isNaN, addOp, arg0, arg1, result);</span>
<span class="line-modified">3107     append(isNaN, Jump);</span>
<span class="line-added">3108     isNaN-&gt;setSuccessors(continuation);</span>
3109 
3110     m_currentBlock = continuation;
3111 
3112     return { };
3113 }
3114 
<span class="line-added">3115 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Max&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult</span>
<span class="line-added">3116 {</span>
<span class="line-added">3117     return addFloatingPointMinOrMax(F32, MinOrMax::Max, arg0, arg1, result);</span>
<span class="line-added">3118 }</span>
<span class="line-added">3119 </span>
3120 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Mul&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3121 {
3122     return addFloatingPointBinOp(Type::F64, MulDouble, arg0, arg1, result);
3123 }
3124 
3125 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Div&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3126 {
3127     return addFloatingPointBinOp(Type::F32, DivFloat, arg0, arg1, result);
3128 }
3129 
3130 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Clz&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3131 {
3132     result = g32();
3133     append(CountLeadingZeros32, arg0, result);
3134     return { };
3135 }
3136 
3137 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Copysign&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3138 {
3139     // FIXME: We can have better codegen here for the imms and two operand forms on x86
</pre>
<hr />
<pre>
3457 {
3458     result = f64();
3459     append(FloorDouble, arg0, result);
3460     return { };
3461 }
3462 
3463 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Xor&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3464 {
3465     result = g32();
3466     append(Xor32, arg0, arg1, result);
3467     return { };
3468 }
3469 
3470 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Abs&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3471 {
3472     return addFloatingPointAbs(AbsFloat, arg0, result);
3473 }
3474 
3475 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Min&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3476 {
<span class="line-modified">3477     return addFloatingPointMinOrMax(F64, MinOrMax::Min, arg0, arg1, result);</span>
























3478 }
3479 
3480 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Mul&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3481 {
3482     result = f32();
3483     append(MulFloat, arg0, arg1, result);
3484     return { };
3485 }
3486 
3487 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Sub&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3488 {
3489     return addIntegerSub(Sub64, arg0, arg1, result);
3490 }
3491 
3492 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32ReinterpretF32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3493 {
3494     result = g32();
3495     append(MoveFloatTo32, arg0, result);
3496     return { };
3497 }
</pre>
<hr />
<pre>
3729     return { };
3730 }
3731 
3732 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Neg&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3733 {
3734     result = f64();
3735     if (isValidForm(NegateDouble, Arg::Tmp, Arg::Tmp))
3736         append(NegateDouble, arg0, result);
3737     else {
3738         auto constant = addConstant(Type::I64, bitwise_cast&lt;uint64_t&gt;(static_cast&lt;double&gt;(-0.0)));
3739         auto temp = g64();
3740         append(MoveDoubleTo64, arg0, temp);
3741         append(Xor64, constant, temp);
3742         append(Move64ToDouble, temp, result);
3743     }
3744     return { };
3745 }
3746 
3747 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Max&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3748 {
<span class="line-modified">3749     return addFloatingPointMinOrMax(F64, MinOrMax::Max, arg0, arg1, result);</span>
























3750 }
3751 
3752 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64LeU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3753 {
3754     result = g32();
3755     append(Compare64, Arg::relCond(MacroAssembler::BelowOrEqual), arg0, arg1, result);
3756     return { };
3757 }
3758 
3759 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64LeS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3760 {
3761     result = g32();
3762     append(Compare64, Arg::relCond(MacroAssembler::LessThanOrEqual), arg0, arg1, result);
3763     return { };
3764 }
3765 
3766 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Add&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3767 {
3768     result = g64();
3769     append(Add64, arg0, arg1, result);
</pre>
</td>
</tr>
</table>
<center><a href="../tools/VMInspector.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="WasmB3IRGenerator.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>