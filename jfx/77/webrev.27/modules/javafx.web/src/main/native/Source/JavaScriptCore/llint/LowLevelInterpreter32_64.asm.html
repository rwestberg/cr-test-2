<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter32_64.asm</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 # Copyright (C) 2011-2019 Apple Inc. All rights reserved.
   2 #
   3 # Redistribution and use in source and binary forms, with or without
   4 # modification, are permitted provided that the following conditions
   5 # are met:
   6 # 1. Redistributions of source code must retain the above copyright
   7 #    notice, this list of conditions and the following disclaimer.
   8 # 2. Redistributions in binary form must reproduce the above copyright
   9 #    notice, this list of conditions and the following disclaimer in the
  10 #    documentation and/or other materials provided with the distribution.
  11 #
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 
  25 # Utilities
  26 macro nextInstruction()
  27     loadb [PC], t0
  28     leap _g_opcodeMap, t1
  29     jmp [t1, t0, 4], BytecodePtrTag
  30 end
  31 
  32 macro nextInstructionWide16()
  33     loadh 1[PC], t0
  34     leap _g_opcodeMapWide16, t1
  35     jmp [t1, t0, 4], BytecodePtrTag
  36 end
  37 
  38 macro nextInstructionWide32()
  39     loadi 1[PC], t0
  40     leap _g_opcodeMapWide32, t1
  41     jmp [t1, t0, 4], BytecodePtrTag
  42 end
  43 
  44 macro getuOperandNarrow(opcodeStruct, fieldName, dst)
  45     loadb constexpr %opcodeStruct%_%fieldName%_index[PC], dst
  46 end
  47 
  48 macro getOperandNarrow(opcodeStruct, fieldName, dst)
  49     loadbsi constexpr %opcodeStruct%_%fieldName%_index[PC], dst
  50 end
  51 
  52 macro getuOperandWide16(opcodeStruct, fieldName, dst)
  53     loadh constexpr %opcodeStruct%_%fieldName%_index * 2 + 1[PC], dst
  54 end
  55 
  56 macro getOperandWide16(opcodeStruct, fieldName, dst)
  57     loadhsi constexpr %opcodeStruct%_%fieldName%_index * 2 + 1[PC], dst
  58 end
  59 
  60 macro getuOperandWide32(opcodeStruct, fieldName, dst)
  61     loadi constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PC], dst
  62 end
  63 
  64 macro getOperandWide32(opcodeStruct, fieldName, dst)
  65     loadis constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PC], dst
  66 end
  67 
  68 macro makeReturn(get, dispatch, fn)
  69     fn(macro(tag, payload)
  70         move tag, t5
  71         move payload, t3
  72         get(m_dst, t2)
  73         storei t5, TagOffset[cfr, t2, 8]
  74         storei t3, PayloadOffset[cfr, t2, 8]
  75         dispatch()
  76     end)
  77 end
  78 
  79 macro makeReturnProfiled(opcodeStruct, get, metadata, dispatch, fn)
  80     fn(macro (tag, payload)
  81         move tag, t1
  82         move payload, t0
  83 
  84         metadata(t5, t2)
  85         valueProfile(opcodeStruct, t5, t1, t0)
  86         get(m_dst, t2)
  87         storei t1, TagOffset[cfr, t2, 8]
  88         storei t0, PayloadOffset[cfr, t2, 8]
  89         dispatch()
  90     end)
  91 end
  92 
  93 
  94 macro dispatchAfterCall(size, opcodeStruct, dispatch)
  95     loadi ArgumentCount + TagOffset[cfr], PC
  96     get(size, opcodeStruct, m_dst, t3)
  97     storei r1, TagOffset[cfr, t3, 8]
  98     storei r0, PayloadOffset[cfr, t3, 8]
  99     metadata(size, opcodeStruct, t2, t3)
 100     valueProfile(opcodeStruct, t2, r1, r0)
 101     dispatch()
 102 end
 103 
 104 macro cCall2(function)
 105     if ARMv7 or MIPS
 106         call function
 107     elsif X86 or X86_WIN
 108         subp 8, sp
 109         push a1
 110         push a0
 111         call function
 112         addp 16, sp
 113     elsif C_LOOP or C_LOOP_WIN
 114         cloopCallSlowPath function, a0, a1
 115     else
 116         error
 117     end
 118 end
 119 
 120 macro cCall2Void(function)
 121     if C_LOOP or C_LOOP_WIN
 122         cloopCallSlowPathVoid function, a0, a1
 123     else
 124         cCall2(function)
 125     end
 126 end
 127 
 128 macro cCall4(function)
 129     if ARMv7 or MIPS
 130         call function
 131     elsif X86 or X86_WIN
 132         push a3
 133         push a2
 134         push a1
 135         push a0
 136         call function
 137         addp 16, sp
 138     elsif C_LOOP or C_LOOP_WIN
 139         error
 140     else
 141         error
 142     end
 143 end
 144 
 145 macro callSlowPath(slowPath)
 146     move cfr, a0
 147     move PC, a1
 148     cCall2(slowPath)
 149     move r0, PC
 150 end
 151 
 152 macro doVMEntry(makeCall)
 153     functionPrologue()
 154     pushCalleeSaves()
 155 
 156     # x86 needs to load arguments from the stack
 157     if X86 or X86_WIN
 158         loadp 16[cfr], a2
 159         loadp 12[cfr], a1
 160         loadp 8[cfr], a0
 161     end
 162 
 163     const entry = a0
 164     const vm = a1
 165     const protoCallFrame = a2
 166 
 167     # We are using t3, t4 and t5 as temporaries through the function.
 168     # Since we have the guarantee that tX != aY when X != Y, we are safe from
 169     # aliasing problems with our arguments.
 170 
 171     if ARMv7
 172         vmEntryRecord(cfr, t3)
 173         move t3, sp
 174     else
 175         vmEntryRecord(cfr, sp)
 176     end
 177 
 178     storep vm, VMEntryRecord::m_vm[sp]
 179     loadp VM::topCallFrame[vm], t4
 180     storep t4, VMEntryRecord::m_prevTopCallFrame[sp]
 181     loadp VM::topEntryFrame[vm], t4
 182     storep t4, VMEntryRecord::m_prevTopEntryFrame[sp]
 183     loadp ProtoCallFrame::calleeValue[protoCallFrame], t4
 184     storep t4, VMEntryRecord::m_callee[sp]
 185 
 186     # Align stack pointer
 187     if X86_WIN or MIPS
 188         addp CallFrameAlignSlots * SlotSize, sp, t3
 189         andp ~StackAlignmentMask, t3
 190         subp t3, CallFrameAlignSlots * SlotSize, sp
 191     elsif ARMv7
 192         addp CallFrameAlignSlots * SlotSize, sp, t3
 193         clrbp t3, StackAlignmentMask, t3
 194         subp t3, CallFrameAlignSlots * SlotSize, t3
 195         move t3, sp
 196     end
 197 
 198     loadi ProtoCallFrame::paddedArgCount[protoCallFrame], t4
 199     addp CallFrameHeaderSlots, t4, t4
 200     lshiftp 3, t4
 201     subp sp, t4, t3
 202     bpa t3, sp, .throwStackOverflow
 203 
 204     # Ensure that we have enough additional stack capacity for the incoming args,
 205     # and the frame for the JS code we&#39;re executing. We need to do this check
 206     # before we start copying the args from the protoCallFrame below.
 207     if C_LOOP or C_LOOP_WIN
 208         bpaeq t3, VM::m_cloopStackLimit[vm], .stackHeightOK
 209         move entry, t4
 210         move vm, t5
 211         cloopCallSlowPath _llint_stack_check_at_vm_entry, vm, t3
 212         bpeq t0, 0, .stackCheckFailed
 213         move t4, entry
 214         move t5, vm
 215         jmp .stackHeightOK
 216 
 217 .stackCheckFailed:
 218         move t4, entry
 219         move t5, vm
 220         jmp .throwStackOverflow
 221     else
 222         bpb t3, VM::m_softStackLimit[vm], .throwStackOverflow
 223     end
 224 
 225 .stackHeightOK:
 226     move t3, sp
 227     move (constexpr ProtoCallFrame::numberOfRegisters), t3
 228 
 229 .copyHeaderLoop:
 230     subi 1, t3
 231     loadi TagOffset[protoCallFrame, t3, 8], t5
 232     storei t5, TagOffset + CodeBlock[sp, t3, 8]
 233     loadi PayloadOffset[protoCallFrame, t3, 8], t5
 234     storei t5, PayloadOffset + CodeBlock[sp, t3, 8]
 235     btinz t3, .copyHeaderLoop
 236 
 237     loadi PayloadOffset + ProtoCallFrame::argCountAndCodeOriginValue[protoCallFrame], t4
 238     subi 1, t4
 239     loadi ProtoCallFrame::paddedArgCount[protoCallFrame], t5
 240     subi 1, t5
 241 
 242     bieq t4, t5, .copyArgs
 243 .fillExtraArgsLoop:
 244     subi 1, t5
 245     storei UndefinedTag, ThisArgumentOffset + 8 + TagOffset[sp, t5, 8]
 246     storei 0, ThisArgumentOffset + 8 + PayloadOffset[sp, t5, 8]
 247     bineq t4, t5, .fillExtraArgsLoop
 248 
 249 .copyArgs:
 250     loadp ProtoCallFrame::args[protoCallFrame], t3
 251 
 252 .copyArgsLoop:
 253     btiz t4, .copyArgsDone
 254     subi 1, t4
 255     loadi TagOffset[t3, t4, 8], t5
 256     storei t5, ThisArgumentOffset + 8 + TagOffset[sp, t4, 8]
 257     loadi PayloadOffset[t3, t4, 8], t5
 258     storei t5, ThisArgumentOffset + 8 + PayloadOffset[sp, t4, 8]
 259     jmp .copyArgsLoop
 260 
 261 .copyArgsDone:
 262     storep sp, VM::topCallFrame[vm]
 263     storep cfr, VM::topEntryFrame[vm]
 264 
 265     makeCall(entry, t3, t4)
 266 
 267     if ARMv7
 268         vmEntryRecord(cfr, t3)
 269         move t3, sp
 270     else
 271         vmEntryRecord(cfr, sp)
 272     end
 273 
 274     loadp VMEntryRecord::m_vm[sp], t5
 275     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 276     storep t4, VM::topCallFrame[t5]
 277     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 278     storep t4, VM::topEntryFrame[t5]
 279 
 280     if ARMv7
 281         subp cfr, CalleeRegisterSaveSize, t5
 282         move t5, sp
 283     else
 284         subp cfr, CalleeRegisterSaveSize, sp
 285     end
 286 
 287     popCalleeSaves()
 288     functionEpilogue()
 289     ret
 290 
 291 .throwStackOverflow:
 292     subp 8, sp # Align stack for cCall2() to make a call.
 293     move vm, a0
 294     move protoCallFrame, a1
 295     cCall2(_llint_throw_stack_overflow_error)
 296 
 297     if ARMv7
 298         vmEntryRecord(cfr, t3)
 299         move t3, sp
 300     else
 301         vmEntryRecord(cfr, sp)
 302     end
 303 
 304     loadp VMEntryRecord::m_vm[sp], t5
 305     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 306     storep t4, VM::topCallFrame[t5]
 307     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 308     storep t4, VM::topEntryFrame[t5]
 309 
 310     if ARMv7
 311         subp cfr, CalleeRegisterSaveSize, t5
 312         move t5, sp
 313     else
 314         subp cfr, CalleeRegisterSaveSize, sp
 315     end
 316 
 317     popCalleeSaves()
 318     functionEpilogue()
 319     ret
 320 end
 321 
 322 macro makeJavaScriptCall(entry, temp, unused)
 323     addp CallerFrameAndPCSize, sp
 324     checkStackPointerAlignment(temp, 0xbad0dc02)
 325     if C_LOOP or C_LOOP_WIN
 326         cloopCallJSFunction entry
 327     else
 328         call entry
 329     end
 330     checkStackPointerAlignment(temp, 0xbad0dc03)
 331     subp CallerFrameAndPCSize, sp
 332 end
 333 
 334 macro makeHostFunctionCall(entry, temp1, temp2)
 335     move entry, temp1
 336     storep cfr, [sp]
 337     if C_LOOP or C_LOOP_WIN
 338         move sp, a0
 339         storep lr, PtrSize[sp]
 340         cloopCallNative temp1
 341     elsif X86 or X86_WIN
 342         # Put callee frame pointer on stack as arg0, also put it in ecx for &quot;fastcall&quot; targets
 343         move 0, temp2
 344         move temp2, 4[sp] # put 0 in ReturnPC
 345         move sp, a0 # a0 is ecx
 346         push temp2 # Push dummy arg1
 347         push a0
 348         call temp1
 349         addp 8, sp
 350     else
 351         move sp, a0
 352         call temp1
 353     end
 354 end
 355 
 356 op(handleUncaughtException, macro()
 357     loadp Callee + PayloadOffset[cfr], t3
 358     andp MarkedBlockMask, t3
 359     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
 360     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
 361     storep 0, VM::callFrameForCatch[t3]
 362 
 363     loadp VM::topEntryFrame[t3], cfr
 364     if ARMv7
 365         vmEntryRecord(cfr, t3)
 366         move t3, sp
 367     else
 368         vmEntryRecord(cfr, sp)
 369     end
 370 
 371     loadp VMEntryRecord::m_vm[sp], t3
 372     loadp VMEntryRecord::m_prevTopCallFrame[sp], t5
 373     storep t5, VM::topCallFrame[t3]
 374     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t5
 375     storep t5, VM::topEntryFrame[t3]
 376 
 377     if ARMv7
 378         subp cfr, CalleeRegisterSaveSize, t3
 379         move t3, sp
 380     else
 381         subp cfr, CalleeRegisterSaveSize, sp
 382     end
 383 
 384     popCalleeSaves()
 385     functionEpilogue()
 386     ret
 387 end)
 388 
 389 macro doReturnFromHostFunction(extraStackSpace)
 390     functionEpilogue(extraStackSpace)
 391     ret
 392 end
 393 
 394 # Debugging operation if you&#39;d like to print an operand in the instruction stream. fromWhere
 395 # should be an immediate integer - any integer you like; use it to identify the place you&#39;re
 396 # debugging from. operand should likewise be an immediate, and should identify the operand
 397 # in the instruction stream you&#39;d like to print out.
 398 macro traceOperand(fromWhere, operand)
 399     move fromWhere, a2
 400     move operand, a3
 401     move cfr, a0
 402     move PC, a1
 403     cCall4(_llint_trace_operand)
 404     move r0, PC
 405     move r1, cfr
 406 end
 407 
 408 # Debugging operation if you&#39;d like to print the value of an operand in the instruction
 409 # stream. Same as traceOperand(), but assumes that the operand is a register, and prints its
 410 # value.
 411 macro traceValue(fromWhere, operand)
 412     move fromWhere, a2
 413     move operand, a3
 414     move cfr, a0
 415     move PC, a1
 416     cCall4(_llint_trace_value)
 417     move r0, PC
 418     move r1, cfr
 419 end
 420 
 421 # Call a slowPath for call opcodes.
 422 macro callCallSlowPath(slowPath, action)
 423     storep PC, ArgumentCount + TagOffset[cfr]
 424     move cfr, a0
 425     move PC, a1
 426     cCall2(slowPath)
 427     action(r0, r1)
 428 end
 429 
 430 macro callTrapHandler(throwHandler)
 431     storei PC, ArgumentCount + TagOffset[cfr]
 432     move cfr, a0
 433     move PC, a1
 434     cCall2(_llint_slow_path_handle_traps)
 435     btpnz r0, throwHandler
 436     loadi ArgumentCount + TagOffset[cfr], PC
 437 end
 438 
 439 macro checkSwitchToJITForLoop()
 440     checkSwitchToJIT(
 441         1,
 442         macro ()
 443             storei PC, ArgumentCount + TagOffset[cfr]
 444             move cfr, a0
 445             move PC, a1
 446             cCall2(_llint_loop_osr)
 447             btpz r0, .recover
 448             move r1, sp
 449             jmp r0
 450         .recover:
 451             loadi ArgumentCount + TagOffset[cfr], PC
 452         end)
 453 end
 454 
 455 macro loadVariable(get, fieldName, indexReg, tagReg, payloadReg)
 456     get(fieldName, indexReg)
 457     loadi TagOffset[cfr, indexReg, 8], tagReg
 458     loadi PayloadOffset[cfr, indexReg, 8], payloadReg
 459 end
 460 
 461 # Index, tag, and payload must be different registers. Index is not
 462 # changed.
 463 macro loadConstantOrVariable(size, index, tag, payload)
 464     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 465         bigteq index, FirstConstantRegisterIndex, .constant
 466         loadi TagOffset[cfr, index, 8], tag
 467         loadi PayloadOffset[cfr, index, 8], payload
 468         jmp .done
 469     .constant:
 470         loadp CodeBlock[cfr], payload
 471         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload
 472         subp FirstConstantRegisterIndex, index
 473         loadp TagOffset[payload, index, 8], tag
 474         loadp PayloadOffset[payload, index, 8], payload
 475     .done:
 476     end)
 477 end
 478 
 479 macro loadConstantOrVariableTag(size, index, tag)
 480     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 481         bigteq index, FirstConstantRegisterIndex, .constant
 482         loadi TagOffset[cfr, index, 8], tag
 483         jmp .done
 484     .constant:
 485         loadp CodeBlock[cfr], tag
 486         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 487         subi FirstConstantRegisterIndex, index
 488         loadp TagOffset[tag, index, 8], tag
 489     .done:
 490     end)
 491 end
 492 
 493 # Index and payload may be the same register. Index may be clobbered.
 494 macro loadConstantOrVariable2Reg(size, index, tag, payload)
 495     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 496         bigteq index, FirstConstantRegisterIndex, .constant
 497         loadi TagOffset[cfr, index, 8], tag
 498         loadi PayloadOffset[cfr, index, 8], payload
 499         jmp .done
 500     .constant:
 501         loadp CodeBlock[cfr], tag
 502         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 503         subi FirstConstantRegisterIndex, index
 504         lshifti 3, index
 505         addp index, tag
 506         loadp PayloadOffset[tag], payload
 507         loadp TagOffset[tag], tag
 508     .done:
 509     end)
 510 end
 511 
 512 macro loadConstantOrVariablePayloadTagCustom(size, index, tagCheck, payload)
 513     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)
 514         bigteq index, FirstConstantRegisterIndex, .constant
 515         tagCheck(TagOffset[cfr, index, 8])
 516         loadi PayloadOffset[cfr, index, 8], payload
 517         jmp .done
 518     .constant:
 519         loadp CodeBlock[cfr], payload
 520         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload
 521         subp FirstConstantRegisterIndex, index
 522         tagCheck(TagOffset[payload, index, 8])
 523         loadp PayloadOffset[payload, index, 8], payload
 524     .done:
 525     end)
 526 end
 527 
 528 # Index and payload must be different registers. Index is not mutated. Use
 529 # this if you know what the tag of the variable should be. Doing the tag
 530 # test as part of loading the variable reduces register use, but may not
 531 # be faster than doing loadConstantOrVariable followed by a branch on the
 532 # tag.
 533 macro loadConstantOrVariablePayload(size, index, expectedTag, payload, slow)
 534     loadConstantOrVariablePayloadTagCustom(
 535         size,
 536         index,
 537         macro (actualTag) bineq actualTag, expectedTag, slow end,
 538         payload)
 539 end
 540 
 541 macro loadConstantOrVariablePayloadUnchecked(size, index, payload)
 542     loadConstantOrVariablePayloadTagCustom(
 543         size,
 544         index,
 545         macro (actualTag) end,
 546         payload)
 547 end
 548 
 549 macro writeBarrierOnCellWithReload(cell, reloadAfterSlowPath)
 550     skipIfIsRememberedOrInEden(
 551         cell,
 552         macro()
 553             push cfr, PC
 554             # We make two extra slots because cCall2 will poke.
 555             subp 8, sp
 556             move cell, a1 # cell can be a0
 557             move cfr, a0
 558             cCall2Void(_llint_write_barrier_slow)
 559             addp 8, sp
 560             pop PC, cfr
 561             reloadAfterSlowPath()
 562         end)
 563 end
 564 
 565 macro writeBarrierOnOperand(size, get, cellFieldName)
 566     get(cellFieldName, t1)
 567     loadConstantOrVariablePayload(size, t1, CellTag, t2, .writeBarrierDone)
 568     writeBarrierOnCellWithReload(t2, macro() end)
 569 .writeBarrierDone:
 570 end
 571 
 572 macro writeBarrierOnOperands(size, get, cellFieldName, valueFieldName)
 573     get(valueFieldName, t1)
 574     loadConstantOrVariableTag(size, t1, t0)
 575     bineq t0, CellTag, .writeBarrierDone
 576 
 577     writeBarrierOnOperand(size, get, cellFieldName)
 578 .writeBarrierDone:
 579 end
 580 
 581 macro writeBarrierOnGlobal(size, get, valueFieldName, loadMacro)
 582     get(valueFieldName, t1)
 583     loadConstantOrVariableTag(size, t1, t0)
 584     bineq t0, CellTag, .writeBarrierDone
 585 
 586     loadMacro(t3)
 587 
 588     writeBarrierOnCellWithReload(t3, macro() end)
 589 .writeBarrierDone:
 590 end
 591 
 592 macro writeBarrierOnGlobalObject(size, get, valueFieldName)
 593     writeBarrierOnGlobal(size, get, valueFieldName,
 594         macro(registerToStoreGlobal)
 595             loadp CodeBlock[cfr], registerToStoreGlobal
 596             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 597         end)
 598 end
 599 
 600 macro writeBarrierOnGlobalLexicalEnvironment(size, get, valueFieldName)
 601     writeBarrierOnGlobal(size, get, valueFieldName,
 602         macro(registerToStoreGlobal)
 603             loadp CodeBlock[cfr], registerToStoreGlobal
 604             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 605             loadp JSGlobalObject::m_globalLexicalEnvironment[registerToStoreGlobal], registerToStoreGlobal
 606         end)
 607 end
 608 
 609 macro valueProfile(opcodeStruct, metadata, tag, payload)
 610     storei tag, %opcodeStruct%::Metadata::m_profile.m_buckets + TagOffset[metadata]
 611     storei payload, %opcodeStruct%::Metadata::m_profile.m_buckets + PayloadOffset[metadata]
 612 end
 613 
 614 
 615 # Entrypoints into the interpreter
 616 
 617 # Expects that CodeBlock is in t1, which is what prologue() leaves behind.
 618 macro functionArityCheck(doneLabel, slowPath)
 619     loadi PayloadOffset + ArgumentCount[cfr], t0
 620     biaeq t0, CodeBlock::m_numParameters[t1], doneLabel
 621     move cfr, a0
 622     move PC, a1
 623     cCall2(slowPath)   # This slowPath has a simple protocol: t0 = 0 =&gt; no error, t0 != 0 =&gt; error
 624     btiz r0, .noError
 625 
 626     # We&#39;re throwing before the frame is fully set up. This frame will be
 627     # ignored by the unwinder. So, let&#39;s restore the callee saves before we
 628     # start unwinding. We need to do this before we change the cfr.
 629     restoreCalleeSavesUsedByLLInt()
 630 
 631     move r1, cfr   # r1 contains caller frame
 632     jmp _llint_throw_from_slow_path_trampoline
 633 
 634 .noError:
 635     move r1, t1 # r1 contains slotsToAdd.
 636     btiz t1, .continue
 637     loadi PayloadOffset + ArgumentCount[cfr], t2
 638     addi CallFrameHeaderSlots, t2
 639 
 640     // Check if there are some unaligned slots we can use
 641     move t1, t3
 642     andi StackAlignmentSlots - 1, t3
 643     btiz t3, .noExtraSlot
 644 .fillExtraSlots:
 645     move 0, t0
 646     storei t0, PayloadOffset[cfr, t2, 8]
 647     move UndefinedTag, t0
 648     storei t0, TagOffset[cfr, t2, 8]
 649     addi 1, t2
 650     bsubinz 1, t3, .fillExtraSlots
 651     andi ~(StackAlignmentSlots - 1), t1
 652     btiz t1, .continue
 653 
 654 .noExtraSlot:
 655     // Move frame up t1 slots
 656     negi t1
 657     move cfr, t3
 658     subp CalleeSaveSpaceAsVirtualRegisters * SlotSize, t3
 659     addi CalleeSaveSpaceAsVirtualRegisters, t2
 660     move t1, t0
 661     lshiftp 3, t0
 662     addp t0, cfr
 663     addp t0, sp
 664 .copyLoop:
 665     loadi PayloadOffset[t3], t0
 666     storei t0, PayloadOffset[t3, t1, 8]
 667     loadi TagOffset[t3], t0
 668     storei t0, TagOffset[t3, t1, 8]
 669     addp 8, t3
 670     bsubinz 1, t2, .copyLoop
 671 
 672     // Fill new slots with JSUndefined
 673     move t1, t2
 674 .fillLoop:
 675     move 0, t0
 676     storei t0, PayloadOffset[t3, t1, 8]
 677     move UndefinedTag, t0
 678     storei t0, TagOffset[t3, t1, 8]
 679     addp 8, t3
 680     baddinz 1, t2, .fillLoop
 681 
 682 .continue:
 683     # Reload CodeBlock and PC, since the slow_path clobbered it.
 684     loadp CodeBlock[cfr], t1
 685     loadp CodeBlock::m_instructionsRawPointer[t1], PC
 686     jmp doneLabel
 687 end
 688 
 689 macro branchIfException(label)
 690     loadp Callee + PayloadOffset[cfr], t3
 691     andp MarkedBlockMask, t3
 692     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
 693     btpz VM::m_exception[t3], .noException
 694     jmp label
 695 .noException:
 696 end
 697 
 698 
 699 # Instruction implementations
 700 
 701 _llint_op_enter:
 702     traceExecution()
 703     checkStackPointerAlignment(t2, 0xdead00e1)
 704     loadp CodeBlock[cfr], t1                // t1&lt;CodeBlock&gt; = cfr.CodeBlock
 705     loadi CodeBlock::m_numVars[t1], t2      // t2&lt;size_t&gt; = t1&lt;CodeBlock&gt;.m_numVars
 706     subi CalleeSaveSpaceAsVirtualRegisters, t2
 707     move cfr, t3
 708     subp CalleeSaveSpaceAsVirtualRegisters * SlotSize, t3
 709     btiz t2, .opEnterDone
 710     move UndefinedTag, t0
 711     negi t2
 712 .opEnterLoop:
 713     storei t0, TagOffset[t3, t2, 8]
 714     storei 0, PayloadOffset[t3, t2, 8]
 715     addi 1, t2
 716     btinz t2, .opEnterLoop
 717 .opEnterDone:
 718     writeBarrierOnCellWithReload(t1, macro ()
 719         loadp CodeBlock[cfr], t1 # Reload CodeBlock
 720     end)
 721     # Checking traps.
 722     loadp CodeBlock::m_vm[t1], t1
 723     btpnz VM::m_traps + VMTraps::m_needTrapHandling[t1], .handleTraps
 724 .afterHandlingTraps:
 725     dispatchOp(narrow, op_enter)
 726 .handleTraps:
 727     callTrapHandler(_llint_throw_from_slow_path_trampoline)
 728     jmp .afterHandlingTraps
 729 
 730 llintOpWithProfile(op_get_argument, OpGetArgument, macro (size, get, dispatch, return)
 731     get(m_index, t2)
 732     loadi PayloadOffset + ArgumentCount[cfr], t0
 733     bilteq t0, t2, .opGetArgumentOutOfBounds
 734     loadi ThisArgumentOffset + TagOffset[cfr, t2, 8], t0
 735     loadi ThisArgumentOffset + PayloadOffset[cfr, t2, 8], t3
 736     return (t0, t3)
 737 
 738 .opGetArgumentOutOfBounds:
 739     return (UndefinedTag, 0)
 740 end)
 741 
 742 
 743 llintOpWithReturn(op_argument_count, OpArgumentCount, macro (size, get, dispatch, return)
 744     loadi PayloadOffset + ArgumentCount[cfr], t0
 745     subi 1, t0
 746     return(Int32Tag, t0)
 747 end)
 748 
 749 
 750 llintOpWithReturn(op_get_scope, OpGetScope, macro (size, get, dispatch, return)
 751     loadi Callee + PayloadOffset[cfr], t0
 752     loadp JSCallee::m_scope[t0], t0
 753     return (CellTag, t0)
 754 end)
 755 
 756 
 757 llintOpWithMetadata(op_to_this, OpToThis, macro (size, get, dispatch, metadata, return)
 758     get(m_srcDst, t0)
 759     bineq TagOffset[cfr, t0, 8], CellTag, .opToThisSlow
 760     loadi PayloadOffset[cfr, t0, 8], t0
 761     bbneq JSCell::m_type[t0], FinalObjectType, .opToThisSlow
 762     metadata(t2, t3)
 763     loadi OpToThis::Metadata::m_cachedStructureID[t2], t2
 764     bineq JSCell::m_structureID[t0], t2, .opToThisSlow
 765     dispatch()
 766 
 767 .opToThisSlow:
 768     callSlowPath(_slow_path_to_this)
 769     dispatch()
 770 end)
 771 
 772 
 773 llintOp(op_check_tdz, OpCheckTdz, macro (size, get, dispatch)
 774     get(m_targetVirtualRegister, t0)
 775     loadConstantOrVariableTag(size, t0, t1)
 776     bineq t1, EmptyValueTag, .opNotTDZ
 777     callSlowPath(_slow_path_throw_tdz_error)
 778 
 779 .opNotTDZ:
 780     dispatch()
 781 end)
 782 
 783 
 784 llintOpWithReturn(op_mov, OpMov, macro (size, get, dispatch, return)
 785     get(m_src, t1)
 786     loadConstantOrVariable(size, t1, t2, t3)
 787     return(t2, t3)
 788 end)
 789 
 790 
 791 llintOpWithReturn(op_not, OpNot, macro (size, get, dispatch, return)
 792     get(m_operand, t0)
 793     loadConstantOrVariable(size, t0, t2, t3)
 794     bineq t2, BooleanTag, .opNotSlow
 795     xori 1, t3
 796     return(t2, t3)
 797 
 798 .opNotSlow:
 799     callSlowPath(_slow_path_not)
 800     dispatch()
 801 end)
 802 
 803 
 804 macro equalityComparisonOp(opcodeName, opcodeStruct, integerComparison)
 805     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 806         get(m_rhs, t2)
 807         get(m_lhs, t0)
 808         loadConstantOrVariable(size, t2, t3, t1)
 809         loadConstantOrVariable2Reg(size, t0, t2, t0)
 810         bineq t2, t3, .opEqSlow
 811         bieq t2, CellTag, .opEqSlow
 812         bib t2, LowestTag, .opEqSlow
 813         integerComparison(t0, t1, t0)
 814         return(BooleanTag, t0)
 815 
 816     .opEqSlow:
 817         callSlowPath(_slow_path_%opcodeName%)
 818         dispatch()
 819     end)
 820 end
 821 
 822 
 823 macro equalityJumpOp(opcodeName, opcodeStruct, integerComparison)
 824     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
 825         get(m_rhs, t2)
 826         get(m_lhs, t0)
 827         loadConstantOrVariable(size, t2, t3, t1)
 828         loadConstantOrVariable2Reg(size, t0, t2, t0)
 829         bineq t2, t3, .slow
 830         bieq t2, CellTag, .slow
 831         bib t2, LowestTag, .slow
 832         integerComparison(t0, t1, .jumpTarget)
 833         dispatch()
 834 
 835     .jumpTarget:
 836         jump(m_targetLabel)
 837 
 838     .slow:
 839         callSlowPath(_llint_slow_path_%opcodeName%)
 840         nextInstruction()
 841     end)
 842 end
 843 
 844 
 845 macro equalNullComparisonOp(opcodeName, opcodeStruct, fn)
 846     llintOpWithReturn(opcodeName, opcodeStruct, macro (size, get, dispatch, return)
 847         get(m_operand, t0)
 848         assertNotConstant(size, t0)
 849         loadi TagOffset[cfr, t0, 8], t1
 850         loadi PayloadOffset[cfr, t0, 8], t0
 851         bineq t1, CellTag, .opEqNullImmediate
 852         btbnz JSCell::m_flags[t0], MasqueradesAsUndefined, .opEqNullMasqueradesAsUndefined
 853         move 0, t1
 854         jmp .opEqNullNotImmediate
 855     .opEqNullMasqueradesAsUndefined:
 856         loadi JSCell::m_structureID[t0], t1
 857         loadp CodeBlock[cfr], t0
 858         loadp CodeBlock::m_globalObject[t0], t0
 859         cpeq Structure::m_globalObject[t1], t0, t1
 860         jmp .opEqNullNotImmediate
 861     .opEqNullImmediate:
 862         cieq t1, NullTag, t2
 863         cieq t1, UndefinedTag, t1
 864         ori t2, t1
 865     .opEqNullNotImmediate:
 866         fn(t1)
 867         return(BooleanTag, t1)
 868     end)
 869 end
 870 
 871 equalNullComparisonOp(op_eq_null, OpEqNull, macro (value) end)
 872 
 873 equalNullComparisonOp(op_neq_null, OpNeqNull,
 874     macro (value) xori 1, value end)
 875 
 876 
 877 llintOpWithReturn(op_is_undefined_or_null, OpIsUndefinedOrNull, macro (size, get, dispatch, return)
 878     get(m_operand, t0)
 879     loadConstantOrVariableTag(size, t0, t1)
 880     ori 1, t1
 881     cieq t1, NullTag, t1
 882     return(BooleanTag, t1)
 883 end)
 884 
 885 
 886 macro strictEqOp(opcodeName, opcodeStruct, equalityOperation)
 887     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 888         get(m_rhs, t2)
 889         get(m_lhs, t0)
 890         loadConstantOrVariable(size, t2, t3, t1)
 891         loadConstantOrVariable2Reg(size, t0, t2, t0)
 892         bineq t2, t3, .slow
 893         bib t2, LowestTag, .slow
 894         bineq t2, CellTag, .notStringOrSymbol
 895         bbaeq JSCell::m_type[t0], ObjectType, .notStringOrSymbol
 896         bbb JSCell::m_type[t1], ObjectType, .slow
 897     .notStringOrSymbol:
 898         equalityOperation(t0, t1, t0)
 899         return(BooleanTag, t0)
 900 
 901     .slow:
 902         callSlowPath(_slow_path_%opcodeName%)
 903         dispatch()
 904     end)
 905 end
 906 
 907 
 908 macro strictEqualityJumpOp(opcodeName, opcodeStruct, equalityOperation)
 909     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
 910         get(m_rhs, t2)
 911         get(m_lhs, t0)
 912         loadConstantOrVariable(size, t2, t3, t1)
 913         loadConstantOrVariable2Reg(size, t0, t2, t0)
 914         bineq t2, t3, .slow
 915         bib t2, LowestTag, .slow
 916         bineq t2, CellTag, .notStringOrSymbol
 917         bbaeq JSCell::m_type[t0], ObjectType, .notStringOrSymbol
 918         bbb JSCell::m_type[t1], ObjectType, .slow
 919     .notStringOrSymbol:
 920         equalityOperation(t0, t1, .jumpTarget)
 921         dispatch()
 922 
 923     .jumpTarget:
 924         jump(m_targetLabel)
 925 
 926     .slow:
 927         callSlowPath(_llint_slow_path_%opcodeName%)
 928         nextInstruction()
 929     end)
 930 end
 931 
 932 
 933 strictEqOp(stricteq, OpStricteq,
 934     macro (left, right, result) cieq left, right, result end)
 935 
 936 
 937 strictEqOp(nstricteq, OpNstricteq,
 938     macro (left, right, result) cineq left, right, result end)
 939 
 940 
 941 strictEqualityJumpOp(jstricteq, OpJstricteq,
 942     macro (left, right, target) bieq left, right, target end)
 943 
 944 
 945 strictEqualityJumpOp(jnstricteq, OpJnstricteq,
 946     macro (left, right, target) bineq left, right, target end)
 947 
 948 
 949 macro preOp(opcodeName, opcodeStruct, operation)
 950     llintOp(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch)
 951         get(m_srcDst, t0)
 952         bineq TagOffset[cfr, t0, 8], Int32Tag, .slow
 953         loadi PayloadOffset[cfr, t0, 8], t1
 954         operation(t1, .slow)
 955         storei t1, PayloadOffset[cfr, t0, 8]
 956         dispatch()
 957 
 958     .slow:
 959         callSlowPath(_slow_path_%opcodeName%)
 960         dispatch()
 961     end)
 962 end
 963 
 964 
 965 llintOpWithProfile(op_to_number, OpToNumber, macro (size, get, dispatch, return)
 966     get(m_operand, t0)
 967     loadConstantOrVariable(size, t0, t2, t3)
 968     bieq t2, Int32Tag, .opToNumberIsInt
 969     biaeq t2, LowestTag, .opToNumberSlow
 970 .opToNumberIsInt:
 971     return(t2, t3)
 972 
 973 .opToNumberSlow:
 974     callSlowPath(_slow_path_to_number)
 975     dispatch()
 976 end)
 977 
 978 
 979 llintOpWithReturn(op_to_string, OpToString, macro (size, get, dispatch, return)
 980     get(m_operand, t0)
 981     loadConstantOrVariable(size, t0, t2, t3)
 982     bineq t2, CellTag, .opToStringSlow
 983     bbneq JSCell::m_type[t3], StringType, .opToStringSlow
 984 .opToStringIsString:
 985     return(t2, t3)
 986 
 987 .opToStringSlow:
 988     callSlowPath(_slow_path_to_string)
 989     dispatch()
 990 end)
 991 
 992 
 993 llintOpWithProfile(op_to_object, OpToObject, macro (size, get, dispatch, return)
 994     get(m_operand, t0)
 995     loadConstantOrVariable(size, t0, t2, t3)
 996     bineq t2, CellTag, .opToObjectSlow
 997     bbb JSCell::m_type[t3], ObjectType, .opToObjectSlow
 998     return(t2, t3)
 999 
1000 .opToObjectSlow:
1001     callSlowPath(_slow_path_to_object)
1002     dispatch()
1003 end)
1004 
1005 
1006 llintOpWithMetadata(op_negate, OpNegate, macro (size, get, dispatch, metadata, return)
1007 
1008     macro arithProfile(type)
1009         ori type, OpNegate::Metadata::m_arithProfile + ArithProfile::m_bits[t5]
1010     end
1011 
1012     metadata(t5, t0)
1013     get(m_operand, t0)
1014     loadConstantOrVariable(size, t0, t1, t2)
1015     bineq t1, Int32Tag, .opNegateSrcNotInt
1016     btiz t2, 0x7fffffff, .opNegateSlow
1017     negi t2
1018     arithProfile(ArithProfileInt)
1019     return (Int32Tag, t2)
1020 .opNegateSrcNotInt:
1021     bia t1, LowestTag, .opNegateSlow
1022     xori 0x80000000, t1
1023     arithProfile(ArithProfileNumber)
1024     return(t1, t2)
1025 
1026 .opNegateSlow:
1027     callSlowPath(_slow_path_negate)
1028     dispatch()
1029 end)
1030 
1031 
1032 macro binaryOpCustomStore(opcodeName, opcodeStruct, integerOperationAndStore, doubleOperation)
1033     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1034         macro arithProfile(type)
1035             ori type, %opcodeStruct%::Metadata::m_arithProfile + ArithProfile::m_bits[t5]
1036         end
1037 
1038         metadata(t5, t2)
1039         get(m_rhs, t2)
1040         get(m_lhs, t0)
1041         loadConstantOrVariable(size, t2, t3, t1)
1042         loadConstantOrVariable2Reg(size, t0, t2, t0)
1043         bineq t2, Int32Tag, .op1NotInt
1044         bineq t3, Int32Tag, .op2NotInt
1045         arithProfile(ArithProfileIntInt)
1046         get(m_dst, t2)
1047         integerOperationAndStore(t3, t1, t0, .slow, t2)
1048         dispatch()
1049 
1050     .op1NotInt:
1051         # First operand is definitely not an int, the second operand could be anything.
1052         bia t2, LowestTag, .slow
1053         bib t3, LowestTag, .op1NotIntOp2Double
1054         bineq t3, Int32Tag, .slow
1055         arithProfile(ArithProfileNumberInt)
1056         ci2d t1, ft1
1057         jmp .op1NotIntReady
1058     .op1NotIntOp2Double:
1059         fii2d t1, t3, ft1
1060         arithProfile(ArithProfileNumberNumber)
1061     .op1NotIntReady:
1062         get(m_dst, t1)
1063         fii2d t0, t2, ft0
1064         doubleOperation(ft1, ft0)
1065         stored ft0, [cfr, t1, 8]
1066         dispatch()
1067 
1068     .op2NotInt:
1069         # First operand is definitely an int, the second operand is definitely not.
1070         get(m_dst, t2)
1071         bia t3, LowestTag, .slow
1072         arithProfile(ArithProfileIntNumber)
1073         ci2d t0, ft0
1074         fii2d t1, t3, ft1
1075         doubleOperation(ft1, ft0)
1076         stored ft0, [cfr, t2, 8]
1077         dispatch()
1078 
1079     .slow:
1080         callSlowPath(_slow_path_%opcodeName%)
1081         dispatch()
1082     end)
1083 end
1084 
1085 macro binaryOp(opcodeName, opcodeStruct, integerOperation, doubleOperation)
1086     binaryOpCustomStore(opcodeName, opcodeStruct,
1087         macro (int32Tag, left, right, slow, index)
1088             integerOperation(left, right, slow)
1089             storei int32Tag, TagOffset[cfr, index, 8]
1090             storei right, PayloadOffset[cfr, index, 8]
1091         end,
1092         doubleOperation)
1093 end
1094 
1095 binaryOp(add, OpAdd,
1096     macro (left, right, slow) baddio left, right, slow end,
1097     macro (left, right) addd left, right end)
1098 
1099 
1100 binaryOpCustomStore(mul, OpMul,
1101     macro (int32Tag, left, right, slow, index)
1102         const scratch = int32Tag   # We know that we can reuse the int32Tag register since it has a constant.
1103         move right, scratch
1104         bmulio left, scratch, slow
1105         btinz scratch, .done
1106         bilt left, 0, slow
1107         bilt right, 0, slow
1108     .done:
1109         storei Int32Tag, TagOffset[cfr, index, 8]
1110         storei scratch, PayloadOffset[cfr, index, 8]
1111     end,
1112     macro (left, right) muld left, right end)
1113 
1114 
1115 binaryOp(sub, OpSub,
1116     macro (left, right, slow) bsubio left, right, slow end,
1117     macro (left, right) subd left, right end)
1118 
1119 
1120 binaryOpCustomStore(div, OpDiv,
1121     macro (int32Tag, left, right, slow, index)
1122         ci2d left, ft0
1123         ci2d right, ft1
1124         divd ft0, ft1
1125         bcd2i ft1, right, .notInt
1126         storei int32Tag, TagOffset[cfr, index, 8]
1127         storei right, PayloadOffset[cfr, index, 8]
1128         jmp .done
1129     .notInt:
1130         stored ft1, [cfr, index, 8]
1131     .done:
1132     end,
1133     macro (left, right) divd left, right end)
1134 
1135 
1136 llintOpWithReturn(op_unsigned, OpUnsigned, macro (size, get, dispatch, return)
1137     get(m_operand, t1)
1138     loadConstantOrVariablePayload(size, t1, Int32Tag, t2, .opUnsignedSlow)
1139     bilt t2, 0, .opUnsignedSlow
1140     return (Int32Tag, t2)
1141 .opUnsignedSlow:
1142     callSlowPath(_slow_path_unsigned)
1143     dispatch()
1144 end)
1145 
1146 
1147 macro commonBitOp(opKind, opcodeName, opcodeStruct, operation)
1148     opKind(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
1149         get(m_rhs, t2)
1150         get(m_lhs, t0)
1151         loadConstantOrVariable(size, t2, t3, t1)
1152         loadConstantOrVariable2Reg(size, t0, t2, t0)
1153         bineq t3, Int32Tag, .slow
1154         bineq t2, Int32Tag, .slow
1155         operation(t1, t0)
1156         return (t3, t0)
1157 
1158     .slow:
1159         callSlowPath(_slow_path_%opcodeName%)
1160         dispatch()
1161     end)
1162 end
1163 
1164 macro bitOp(opcodeName, opcodeStruct, operation)
1165     commonBitOp(llintOpWithReturn, opcodeName, opcodeStruct, operation)
1166 end
1167 
1168 macro bitOpProfiled(opcodeName, opcodeStruct, operation)
1169     commonBitOp(llintOpWithProfile, opcodeName, opcodeStruct, operation)
1170 end
1171 
1172 
1173 bitOpProfiled(lshift, OpLshift,
1174     macro (left, right) lshifti left, right end)
1175 
1176 
1177 bitOp(rshift, OpRshift,
1178     macro (left, right) rshifti left, right end)
1179 
1180 
1181 bitOp(urshift, OpUrshift,
1182     macro (left, right) urshifti left, right end)
1183 
1184 bitOpProfiled(bitxor, OpBitxor,
1185     macro (left, right) xori left, right end)
1186 
1187 bitOpProfiled(bitand, OpBitand,
1188     macro (left, right) andi left, right end)
1189 
1190 bitOpProfiled(bitor, OpBitor,
1191     macro (left, right) ori left, right end)
1192 
1193 llintOpWithProfile(op_bitnot, OpBitnot, macro (size, get, dispatch, return)
1194     get(m_operand, t0)
1195     loadConstantOrVariable(size, t0, t2, t3)
1196     bineq t2, Int32Tag, .opBitNotSlow
1197     noti t3
1198     return (Int32Tag, t3)
1199 
1200  .opBitNotSlow:
1201     callSlowPath(_slow_path_bitnot)
1202     dispatch()
1203 end)
1204 
1205 llintOp(op_overrides_has_instance, OpOverridesHasInstance, macro (size, get, dispatch)
1206     get(m_dst, t3)
1207     storei BooleanTag, TagOffset[cfr, t3, 8]
1208 
1209     # First check if hasInstanceValue is the one on Function.prototype[Symbol.hasInstance]
1210     get(m_hasInstanceValue, t0)
1211     loadConstantOrVariablePayload(size, t0, CellTag, t2, .opOverrideshasInstanceValueNotCell)
1212     loadConstantOrVariable(size, t0, t1, t2)
1213     bineq t1, CellTag, .opOverrideshasInstanceValueNotCell
1214 
1215     # We don&#39;t need hasInstanceValue&#39;s tag register anymore.
1216     loadp CodeBlock[cfr], t1
1217     loadp CodeBlock::m_globalObject[t1], t1
1218     loadp JSGlobalObject::m_functionProtoHasInstanceSymbolFunction[t1], t1
1219     bineq t1, t2, .opOverrideshasInstanceValueNotDefault
1220 
1221     # We know the constructor is a cell.
1222     get(m_constructor, t0)
1223     loadConstantOrVariablePayloadUnchecked(size, t0, t1)
1224     tbz JSCell::m_flags[t1], ImplementsDefaultHasInstance, t0
1225     storei t0, PayloadOffset[cfr, t3, 8]
1226     dispatch()
1227 
1228 .opOverrideshasInstanceValueNotCell:
1229 .opOverrideshasInstanceValueNotDefault:
1230     storei 1, PayloadOffset[cfr, t3, 8]
1231     dispatch()
1232 end)
1233 
1234 
1235 llintOpWithReturn(op_is_empty, OpIsEmpty, macro (size, get, dispatch, return)
1236     get(m_operand, t1)
1237     loadConstantOrVariable(size, t1, t2, t3)
1238     cieq t2, EmptyValueTag, t3
1239     return(BooleanTag, t3)
1240 end)
1241 
1242 
1243 llintOpWithReturn(op_is_undefined, OpIsUndefined, macro (size, get, dispatch, return)
1244     get(m_operand, t1)
1245     loadConstantOrVariable(size, t1, t2, t3)
1246     bieq t2, CellTag, .opIsUndefinedCell
1247     cieq t2, UndefinedTag, t3
1248     return(BooleanTag, t3)
1249 .opIsUndefinedCell:
1250     btbnz JSCell::m_flags[t3], MasqueradesAsUndefined, .opIsUndefinedMasqueradesAsUndefined
1251     return(BooleanTag, 0)
1252 .opIsUndefinedMasqueradesAsUndefined:
1253     loadi JSCell::m_structureID[t3], t1
1254     loadp CodeBlock[cfr], t3
1255     loadp CodeBlock::m_globalObject[t3], t3
1256     cpeq Structure::m_globalObject[t1], t3, t1
1257     return(BooleanTag, t1)
1258 end)
1259 
1260 
1261 llintOpWithReturn(op_is_boolean, OpIsBoolean, macro (size, get, dispatch, return)
1262     get(m_operand, t1)
1263     loadConstantOrVariableTag(size, t1, t0)
1264     cieq t0, BooleanTag, t0
1265     return(BooleanTag, t0)
1266 end)
1267 
1268 
1269 llintOpWithReturn(op_is_number, OpIsNumber, macro (size, get, dispatch, return)
1270     get(m_operand, t1)
1271     loadConstantOrVariableTag(size, t1, t0)
1272     addi 1, t0
1273     cib t0, LowestTag + 1, t1
1274     return(BooleanTag, t1)
1275 end)
1276 
1277 
1278 llintOpWithReturn(op_is_cell_with_type, OpIsCellWithType, macro (size, get, dispatch, return)
1279     get(m_operand, t1)
1280     loadConstantOrVariable(size, t1, t0, t3)
1281     bineq t0, CellTag, .notCellCase
1282     getu(size, OpIsCellWithType, m_type, t0)
1283     cbeq JSCell::m_type[t3], t0, t1
1284     return(BooleanTag, t1)
1285 .notCellCase:
1286     return(BooleanTag, 0)
1287 end)
1288 
1289 
1290 llintOpWithReturn(op_is_object, OpIsObject, macro (size, get, dispatch, return)
1291     get(m_operand, t1)
1292     loadConstantOrVariable(size, t1, t0, t3)
1293     bineq t0, CellTag, .opIsObjectNotCell
1294     cbaeq JSCell::m_type[t3], ObjectType, t1
1295     return(BooleanTag, t1)
1296 .opIsObjectNotCell:
1297     return(BooleanTag, 0)
1298 end)
1299 
1300 
1301 macro loadPropertyAtVariableOffsetKnownNotInline(propertyOffset, objectAndStorage, tag, payload)
1302     assert(macro (ok) bigteq propertyOffset, firstOutOfLineOffset, ok end)
1303     negi propertyOffset
1304     loadp JSObject::m_butterfly[objectAndStorage], objectAndStorage
1305     loadi TagOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffset, 8], tag
1306     loadi PayloadOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffset, 8], payload
1307 end
1308 
1309 macro loadPropertyAtVariableOffset(propertyOffset, objectAndStorage, tag, payload)
1310     bilt propertyOffset, firstOutOfLineOffset, .isInline
1311     loadp JSObject::m_butterfly[objectAndStorage], objectAndStorage
1312     negi propertyOffset
1313     jmp .ready
1314 .isInline:
1315     addp sizeof JSObject - (firstOutOfLineOffset - 2) * 8, objectAndStorage
1316 .ready:
1317     loadi TagOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffset, 8], tag
1318     loadi PayloadOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffset, 8], payload
1319 end
1320 
1321 macro storePropertyAtVariableOffset(propertyOffsetAsInt, objectAndStorage, tag, payload)
1322     bilt propertyOffsetAsInt, firstOutOfLineOffset, .isInline
1323     loadp JSObject::m_butterfly[objectAndStorage], objectAndStorage
1324     negi propertyOffsetAsInt
1325     jmp .ready
1326 .isInline:
1327     addp sizeof JSObject - (firstOutOfLineOffset - 2) * 8, objectAndStorage
1328 .ready:
1329     storei tag, TagOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffsetAsInt, 8]
1330     storei payload, PayloadOffset + (firstOutOfLineOffset - 2) * 8[objectAndStorage, propertyOffsetAsInt, 8]
1331 end
1332 
1333 
1334 # We only do monomorphic get_by_id caching for now, and we do not modify the
1335 # opcode for own properties. We also allow for the cache to change anytime it fails,
1336 # since ping-ponging is free. At best we get lucky and the get_by_id will continue
1337 # to take fast path on the new cache. At worst we take slow path, which is what
1338 # we would have been doing anyway. For prototype/unset properties, we will attempt to
1339 # convert opcode into a get_by_id_proto_load/get_by_id_unset, respectively, after an
1340 # execution counter hits zero.
1341 
1342 llintOpWithMetadata(op_get_by_id_direct, OpGetByIdDirect, macro (size, get, dispatch, metadata, return)
1343     metadata(t5, t0)
1344     get(m_base, t0)
1345     loadi OpGetByIdDirect::Metadata::m_structureID[t5], t1
1346     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdDirectSlow)
1347     loadi OpGetByIdDirect::Metadata::m_offset[t5], t2
1348     bineq JSCell::m_structureID[t3], t1, .opGetByIdDirectSlow
1349     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1350     valueProfile(OpGetByIdDirect, t5, t0, t1)
1351     return(t0, t1)
1352 
1353 .opGetByIdDirectSlow:
1354     callSlowPath(_llint_slow_path_get_by_id_direct)
1355     dispatch()
1356 end)
1357 
1358 
1359 llintOpWithMetadata(op_get_by_id, OpGetById, macro (size, get, dispatch, metadata, return)
1360     metadata(t5, t0)
1361     loadb OpGetById::Metadata::m_modeMetadata.mode[t5], t1
1362     get(m_base, t0)
1363 
1364 .opGetByIdProtoLoad:
1365     bbneq t1, constexpr GetByIdMode::ProtoLoad, .opGetByIdArrayLength
1366     loadi OpGetById::Metadata::m_modeMetadata.protoLoadMode.structureID[t5], t1
1367     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1368     loadis OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedOffset[t5], t2
1369     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1370     loadp OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedSlot[t5], t3
1371     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1372     valueProfile(OpGetById, t5, t0, t1)
1373     return(t0, t1)
1374 
1375 .opGetByIdArrayLength:
1376     bbneq t1, constexpr GetByIdMode::ArrayLength, .opGetByIdUnset
1377     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1378     move t3, t2
1379     arrayProfile(OpGetById::Metadata::m_modeMetadata.arrayLengthMode.arrayProfile, t2, t5, t0)
1380     btiz t2, IsArray, .opGetByIdSlow
1381     btiz t2, IndexingShapeMask, .opGetByIdSlow
1382     loadp JSObject::m_butterfly[t3], t0
1383     loadi -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], t0
1384     bilt t0, 0, .opGetByIdSlow
1385     valueProfile(OpGetById, t5, Int32Tag, t0)
1386     return(Int32Tag, t0)
1387 
1388 .opGetByIdUnset:
1389     bbneq t1, constexpr GetByIdMode::Unset, .opGetByIdDefault
1390     loadi OpGetById::Metadata::m_modeMetadata.unsetMode.structureID[t5], t1
1391     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1392     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1393     valueProfile(OpGetById, t5, UndefinedTag, 0)
1394     return(UndefinedTag, 0)
1395 
1396 .opGetByIdDefault:
1397     loadi OpGetById::Metadata::m_modeMetadata.defaultMode.structureID[t5], t1
1398     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1399     loadis OpGetById::Metadata::m_modeMetadata.defaultMode.cachedOffset[t5], t2
1400     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1401     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1402     valueProfile(OpGetById, t5, t0, t1)
1403     return(t0, t1)
1404 
1405 .opGetByIdSlow:
1406     callSlowPath(_llint_slow_path_get_by_id)
1407     dispatch()
1408 end)
1409 
1410 
1411 llintOpWithMetadata(op_put_by_id, OpPutById, macro (size, get, dispatch, metadata, return)
1412     writeBarrierOnOperands(size, get, m_base, m_value)
1413     metadata(t5, t3)
1414     get(m_base, t3)
1415     loadConstantOrVariablePayload(size, t3, CellTag, t0, .opPutByIdSlow)
1416     loadi JSCell::m_structureID[t0], t2
1417     bineq t2, OpPutById::Metadata::m_oldStructureID[t5], .opPutByIdSlow
1418 
1419     # At this point, we have:
1420     # t5 -&gt; metadata
1421     # t2 -&gt; currentStructureID
1422     # t0 -&gt; object base
1423     # We will lose currentStructureID in the shenanigans below.
1424 
1425     loadi OpPutById::Metadata::m_newStructureID[t5], t1
1426 
1427     btiz t1, .opPutByIdNotTransition
1428 
1429     # This is the transition case. t1 holds the new Structure*. If we have a chain, we need to
1430     # check it. t0 is the base. We may clobber t1 to use it as scratch.
1431     loadp OpPutById::Metadata::m_structureChain[t5], t3
1432     btpz t3, .opPutByIdTransitionDirect
1433 
1434     loadi OpPutById::Metadata::m_oldStructureID[t5], t2 # Need old structure again.
1435     loadp StructureChain::m_vector[t3], t3
1436     assert(macro (ok) btpnz t3, ok end)
1437 
1438     loadp Structure::m_prototype[t2], t2
1439     btpz t2, .opPutByIdTransitionChainDone
1440 .opPutByIdTransitionChainLoop:
1441     loadp [t3], t1
1442     bineq t1, JSCell::m_structureID[t2], .opPutByIdSlow
1443     addp 4, t3
1444     loadp Structure::m_prototype[t1], t2
1445     btpnz t2, .opPutByIdTransitionChainLoop
1446 
1447 .opPutByIdTransitionChainDone:
1448     loadi OpPutById::Metadata::m_newStructureID[t5], t1
1449 
1450 .opPutByIdTransitionDirect:
1451     storei t1, JSCell::m_structureID[t0]
1452     get(m_value, t1)
1453     loadConstantOrVariable(size, t1, t2, t3)
1454     loadi OpPutById::Metadata::m_offset[t5], t1
1455     storePropertyAtVariableOffset(t1, t0, t2, t3)
1456     writeBarrierOnOperand(size, get, m_base)
1457     dispatch()
1458 
1459 .opPutByIdNotTransition:
1460     # The only thing live right now is t0, which holds the base.
1461     get(m_value, t1)
1462     loadConstantOrVariable(size, t1, t2, t3)
1463     loadi OpPutById::Metadata::m_offset[t5], t1
1464     storePropertyAtVariableOffset(t1, t0, t2, t3)
1465     dispatch()
1466 
1467 .opPutByIdSlow:
1468     callSlowPath(_llint_slow_path_put_by_id)
1469     dispatch()
1470 end)
1471 
1472 
1473 llintOpWithMetadata(op_get_by_val, OpGetByVal, macro (size, get, dispatch, metadata, return)
1474     metadata(t5, t2)
1475     get(m_base, t2)
1476     loadConstantOrVariablePayload(size, t2, CellTag, t0, .opGetByValSlow)
1477     move t0, t2
1478     arrayProfile(OpGetByVal::Metadata::m_arrayProfile, t2, t5, t1)
1479     get(m_property, t3)
1480     loadConstantOrVariablePayload(size, t3, Int32Tag, t1, .opGetByValSlow)
1481     loadp JSObject::m_butterfly[t0], t3
1482     andi IndexingShapeMask, t2
1483     bieq t2, Int32Shape, .opGetByValIsContiguous
1484     bineq t2, ContiguousShape, .opGetByValNotContiguous
1485 
1486 .opGetByValIsContiguous:
1487     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1488     loadi TagOffset[t3, t1, 8], t2
1489     loadi PayloadOffset[t3, t1, 8], t1
1490     jmp .opGetByValDone
1491 
1492 .opGetByValNotContiguous:
1493     bineq t2, DoubleShape, .opGetByValNotDouble
1494     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t3], .opGetByValSlow
1495     loadd [t3, t1, 8], ft0
1496     bdnequn ft0, ft0, .opGetByValSlow
1497     # FIXME: This could be massively optimized.
1498     fd2ii ft0, t1, t2
1499     get(m_dst, t0)
1500     jmp .opGetByValNotEmpty
1501 
1502 .opGetByValNotDouble:
1503     subi ArrayStorageShape, t2
1504     bia t2, SlowPutArrayStorageShape - ArrayStorageShape, .opGetByValSlow
1505     biaeq t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t3], .opGetByValSlow
1506     loadi ArrayStorage::m_vector + TagOffset[t3, t1, 8], t2
1507     loadi ArrayStorage::m_vector + PayloadOffset[t3, t1, 8], t1
1508 
1509 .opGetByValDone:
1510     get(m_dst, t0)
1511     bieq t2, EmptyValueTag, .opGetByValSlow
1512 .opGetByValNotEmpty:
1513     storei t2, TagOffset[cfr, t0, 8]
1514     storei t1, PayloadOffset[cfr, t0, 8]
1515     valueProfile(OpGetByVal, t5, t2, t1)
1516     dispatch()
1517 
1518 .opGetByValSlow:
1519     callSlowPath(_llint_slow_path_get_by_val)
1520     dispatch()
1521 end)
1522 
1523 
1524 macro putByValOp(opcodeName, opcodeStruct)
1525     llintOpWithMetadata(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, metadata, return)
1526         macro contiguousPutByVal(storeCallback)
1527             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .outOfBounds
1528         .storeResult:
1529             get(m_value, t2)
1530             storeCallback(t2, t1, t0, t3)
1531             dispatch()
1532 
1533         .outOfBounds:
1534             biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1535             storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1536             addi 1, t3, t2
1537             storei t2, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1538             jmp .storeResult
1539         end
1540 
1541         writeBarrierOnOperands(size, get, m_base, m_value)
1542         metadata(t5, t0)
1543         get(m_base, t0)
1544         loadConstantOrVariablePayload(size, t0, CellTag, t1, .opPutByValSlow)
1545         move t1, t2
1546         arrayProfile(%opcodeStruct%::Metadata::m_arrayProfile, t2, t5, t0)
1547         get(m_property, t0)
1548         loadConstantOrVariablePayload(size, t0, Int32Tag, t3, .opPutByValSlow)
1549         loadp JSObject::m_butterfly[t1], t0
1550         btinz t2, CopyOnWrite, .opPutByValSlow
1551         andi IndexingShapeMask, t2
1552         bineq t2, Int32Shape, .opPutByValNotInt32
1553         contiguousPutByVal(
1554             macro (operand, scratch, base, index)
1555                 loadConstantOrVariablePayload(size, operand, Int32Tag, scratch, .opPutByValSlow)
1556                 storei Int32Tag, TagOffset[base, index, 8]
1557                 storei scratch, PayloadOffset[base, index, 8]
1558             end)
1559 
1560     .opPutByValNotInt32:
1561         bineq t2, DoubleShape, .opPutByValNotDouble
1562         contiguousPutByVal(
1563             macro (operand, scratch, base, index)
1564                 const tag = scratch
1565                 const payload = operand
1566                 loadConstantOrVariable2Reg(size, operand, tag, payload)
1567                 bineq tag, Int32Tag, .notInt
1568                 ci2d payload, ft0
1569                 jmp .ready
1570             .notInt:
1571                 fii2d payload, tag, ft0
1572                 bdnequn ft0, ft0, .opPutByValSlow
1573             .ready:
1574                 stored ft0, [base, index, 8]
1575             end)
1576 
1577     .opPutByValNotDouble:
1578         bineq t2, ContiguousShape, .opPutByValNotContiguous
1579         contiguousPutByVal(
1580             macro (operand, scratch, base, index)
1581                 const tag = scratch
1582                 const payload = operand
1583                 loadConstantOrVariable2Reg(size, operand, tag, payload)
1584                 storei tag, TagOffset[base, index, 8]
1585                 storei payload, PayloadOffset[base, index, 8]
1586             end)
1587 
1588     .opPutByValNotContiguous:
1589         bineq t2, ArrayStorageShape, .opPutByValSlow
1590         biaeq t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.vectorLength[t0], .opPutByValOutOfBounds
1591         bieq ArrayStorage::m_vector + TagOffset[t0, t3, 8], EmptyValueTag, .opPutByValArrayStorageEmpty
1592     .opPutByValArrayStorageStoreResult:
1593         get(m_value, t2)
1594         loadConstantOrVariable2Reg(size, t2, t1, t2)
1595         storei t1, ArrayStorage::m_vector + TagOffset[t0, t3, 8]
1596         storei t2, ArrayStorage::m_vector + PayloadOffset[t0, t3, 8]
1597         dispatch()
1598 
1599     .opPutByValArrayStorageEmpty:
1600         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_mayStoreToHole[t5]
1601         addi 1, ArrayStorage::m_numValuesInVector[t0]
1602         bib t3, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0], .opPutByValArrayStorageStoreResult
1603         addi 1, t3, t1
1604         storei t1, -sizeof IndexingHeader + IndexingHeader::u.lengths.publicLength[t0]
1605         jmp .opPutByValArrayStorageStoreResult
1606 
1607     .opPutByValOutOfBounds:
1608         storeb 1, %opcodeStruct%::Metadata::m_arrayProfile.m_outOfBounds[t5]
1609     .opPutByValSlow:
1610         callSlowPath(_llint_slow_path_%opcodeName%)
1611         dispatch()
1612     end)
1613 end
1614 
1615 
1616 putByValOp(put_by_val, OpPutByVal)
1617 
1618 putByValOp(put_by_val_direct, OpPutByValDirect)
1619 
1620 
1621 macro llintJumpTrueOrFalseOp(opcodeName, opcodeStruct, conditionOp)
1622     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1623         get(m_condition, t1)
1624         loadConstantOrVariablePayload(size, t1, BooleanTag, t0, .slow)
1625         conditionOp(t0, .target)
1626         dispatch()
1627 
1628     .target:
1629         jump(m_targetLabel)
1630 
1631     .slow:
1632         callSlowPath(_llint_slow_path_%opcodeName%)
1633         nextInstruction()
1634     end)
1635 end
1636 
1637 
1638 macro equalNullJumpOp(opcodeName, opcodeStruct, cellHandler, immediateHandler)
1639     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1640         get(m_value, t0)
1641         assertNotConstant(size, t0)
1642         loadi TagOffset[cfr, t0, 8], t1
1643         loadi PayloadOffset[cfr, t0, 8], t0
1644         bineq t1, CellTag, .immediate
1645         loadi JSCell::m_structureID[t0], t2
1646         cellHandler(t2, JSCell::m_flags[t0], .target)
1647         dispatch()
1648 
1649     .target:
1650         jump(m_targetLabel)
1651 
1652     .immediate:
1653         ori 1, t1
1654         immediateHandler(t1, .target)
1655         dispatch()
1656     end)
1657 end
1658 
1659 equalNullJumpOp(jeq_null, OpJeqNull,
1660     macro (structure, value, target)
1661         btbz value, MasqueradesAsUndefined, .opJeqNullNotMasqueradesAsUndefined
1662         loadp CodeBlock[cfr], t0
1663         loadp CodeBlock::m_globalObject[t0], t0
1664         bpeq Structure::m_globalObject[structure], t0, target
1665     .opJeqNullNotMasqueradesAsUndefined:
1666     end,
1667     macro (value, target) bieq value, NullTag, target end)
1668     
1669 
1670 equalNullJumpOp(jneq_null, OpJneqNull,
1671     macro (structure, value, target)
1672         btbz value, MasqueradesAsUndefined, target
1673         loadp CodeBlock[cfr], t0
1674         loadp CodeBlock::m_globalObject[t0], t0
1675         bpneq Structure::m_globalObject[structure], t0, target
1676     end,
1677     macro (value, target) bineq value, NullTag, target end)
1678 
1679 macro undefinedOrNullJumpOp(opcodeName, opcodeStruct, fn)
1680     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1681         get(m_value, t1)
1682         loadConstantOrVariableTag(size, t1, t0)
1683         ori 1, t0
1684         fn(t0, .target)
1685         dispatch()
1686 
1687     .target:
1688         jump(m_targetLabel)
1689     end)
1690 end
1691 
1692 undefinedOrNullJumpOp(jundefined_or_null, OpJundefinedOrNull,
1693     macro (value, target) bieq value, NullTag, target end)
1694 
1695 undefinedOrNullJumpOp(jnundefined_or_null, OpJnundefinedOrNull,
1696     macro (value, target) bineq value, NullTag, target end)
1697 
1698 llintOpWithMetadata(op_jneq_ptr, OpJneqPtr, macro (size, get, dispatch, metadata, return)
1699     get(m_value, t0)
1700     getu(size, OpJneqPtr, m_specialPointer, t1)
1701     loadp CodeBlock[cfr], t2
1702     loadp CodeBlock::m_globalObject[t2], t2
1703     bineq TagOffset[cfr, t0, 8], CellTag, .opJneqPtrBranch
1704     loadp JSGlobalObject::m_specialPointers[t2, t1, 4], t1
1705     bpeq PayloadOffset[cfr, t0, 8], t1, .opJneqPtrFallThrough
1706 .opJneqPtrBranch:
1707     metadata(t5, t2)
1708     storeb 1, OpJneqPtr::Metadata::m_hasJumped[t5]
1709     get(m_targetLabel, t0)
1710     jumpImpl(t0)
1711 .opJneqPtrFallThrough:
1712     dispatch()
1713 end)
1714 
1715 
1716 macro compareUnsignedJumpOp(opcodeName, opcodeStruct, integerCompare)
1717     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1718         get(m_lhs, t2)
1719         get(m_rhs, t3)
1720         loadConstantOrVariable(size, t2, t0, t1)
1721         loadConstantOrVariable2Reg(size, t3, t2, t3)
1722         integerCompare(t1, t3, .jumpTarget)
1723         dispatch()
1724 
1725     .jumpTarget:
1726         jump(m_targetLabel)
1727     end)
1728 end
1729 
1730 
1731 macro compareUnsignedOp(opcodeName, opcodeStruct, integerCompareAndSet)
1732     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
1733         get(m_rhs, t2)
1734         get(m_lhs, t0)
1735         loadConstantOrVariable(size, t2, t3, t1)
1736         loadConstantOrVariable2Reg(size, t0, t2, t0)
1737         integerCompareAndSet(t0, t1, t0)
1738         return(BooleanTag, t0)
1739     end)
1740 end
1741 
1742 
1743 macro compareJumpOp(opcodeName, opcodeStruct, integerCompare, doubleCompare)
1744     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)
1745         get(m_lhs, t2)
1746         get(m_rhs, t3)
1747         loadConstantOrVariable(size, t2, t0, t1)
1748         loadConstantOrVariable2Reg(size, t3, t2, t3)
1749         bineq t0, Int32Tag, .op1NotInt
1750         bineq t2, Int32Tag, .op2NotInt
1751         integerCompare(t1, t3, .jumpTarget)
1752         dispatch()
1753 
1754     .op1NotInt:
1755         bia t0, LowestTag, .slow
1756         bib t2, LowestTag, .op1NotIntOp2Double
1757         bineq t2, Int32Tag, .slow
1758         ci2d t3, ft1
1759         jmp .op1NotIntReady
1760     .op1NotIntOp2Double:
1761         fii2d t3, t2, ft1
1762     .op1NotIntReady:
1763         fii2d t1, t0, ft0
1764         doubleCompare(ft0, ft1, .jumpTarget)
1765         dispatch()
1766 
1767     .op2NotInt:
1768         ci2d t1, ft0
1769         bia t2, LowestTag, .slow
1770         fii2d t3, t2, ft1
1771         doubleCompare(ft0, ft1, .jumpTarget)
1772         dispatch()
1773 
1774     .jumpTarget:
1775         jump(m_targetLabel)
1776 
1777     .slow:
1778         callSlowPath(_llint_slow_path_%opcodeName%)
1779         nextInstruction()
1780     end)
1781 end
1782 
1783 
1784 llintOpWithJump(op_switch_imm, OpSwitchImm, macro (size, get, jump, dispatch)
1785     get(m_scrutinee, t2)
1786     getu(size, OpSwitchImm, m_tableIndex, t3)
1787     loadConstantOrVariable(size, t2, t1, t0)
1788     loadp CodeBlock[cfr], t2
1789     loadp CodeBlock::m_rareData[t2], t2
1790     muli sizeof SimpleJumpTable, t3
1791     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1792     addp t3, t2
1793     bineq t1, Int32Tag, .opSwitchImmNotInt
1794     subi SimpleJumpTable::min[t2], t0
1795     biaeq t0, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchImmFallThrough
1796     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t3
1797     loadi [t3, t0, 4], t1
1798     btiz t1, .opSwitchImmFallThrough
1799     dispatchIndirect(t1)
1800 
1801 .opSwitchImmNotInt:
1802     bib t1, LowestTag, .opSwitchImmSlow  # Go to slow path if it&#39;s a double.
1803 .opSwitchImmFallThrough:
1804     jump(m_defaultOffset)
1805 
1806 .opSwitchImmSlow:
1807     callSlowPath(_llint_slow_path_switch_imm)
1808     nextInstruction()
1809 end)
1810 
1811 
1812 llintOpWithJump(op_switch_char, OpSwitchChar, macro (size, get, jump, dispatch)
1813     get(m_scrutinee, t2)
1814     getu(size, OpSwitchChar, m_tableIndex, t3)
1815     loadConstantOrVariable(size, t2, t1, t0)
1816     loadp CodeBlock[cfr], t2
1817     loadp CodeBlock::m_rareData[t2], t2
1818     muli sizeof SimpleJumpTable, t3
1819     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1820     addp t3, t2
1821     bineq t1, CellTag, .opSwitchCharFallThrough
1822     bbneq JSCell::m_type[t0], StringType, .opSwitchCharFallThrough
1823     loadp JSString::m_fiber[t0], t1
1824     btpnz t1, isRopeInPointer, .opSwitchOnRope
1825     bineq StringImpl::m_length[t1], 1, .opSwitchCharFallThrough
1826     loadp StringImpl::m_data8[t1], t0
1827     btinz StringImpl::m_hashAndFlags[t1], HashFlags8BitBuffer, .opSwitchChar8Bit
1828     loadh [t0], t0
1829     jmp .opSwitchCharReady
1830 .opSwitchChar8Bit:
1831     loadb [t0], t0
1832 .opSwitchCharReady:
1833     subi SimpleJumpTable::min[t2], t0
1834     biaeq t0, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchCharFallThrough
1835     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t2
1836     loadi [t2, t0, 4], t1
1837     btiz t1, .opSwitchCharFallThrough
1838     dispatchIndirect(t1)
1839 
1840 .opSwitchCharFallThrough:
1841     jump(m_defaultOffset)
1842 
1843 .opSwitchOnRope:
1844     bineq JSRopeString::m_compactFibers + JSRopeString::CompactFibers::m_length[t0], 1, .opSwitchCharFallThrough
1845 
1846 .opSwitchOnRopeChar:
1847     callSlowPath(_llint_slow_path_switch_char)
1848     nextInstruction()
1849 end)
1850 
1851 
1852 macro arrayProfileForCall(opcodeStruct, getu)
1853     getu(m_argv, t3)
1854     negi t3
1855     bineq ThisArgumentOffset + TagOffset[cfr, t3, 8], CellTag, .done
1856     loadi ThisArgumentOffset + PayloadOffset[cfr, t3, 8], t0
1857     loadi JSCell::m_structureID[t0], t0
1858     storei t0, %opcodeStruct%::Metadata::m_callLinkInfo.m_arrayProfile.m_lastSeenStructureID[t5]
1859 .done:
1860 end
1861 
1862 macro commonCallOp(opcodeName, slowPath, opcodeStruct, prepareCall, prologue)
1863     llintOpWithMetadata(opcodeName, opcodeStruct, macro (size, get, dispatch, metadata, return)
1864         metadata(t5, t0)
1865 
1866         prologue(macro (fieldName, dst)
1867             getu(size, opcodeStruct, fieldName, dst)
1868         end, metadata)
1869 
1870         get(m_callee, t0)
1871         loadp %opcodeStruct%::Metadata::m_callLinkInfo.m_calleeOrLastSeenCalleeWithLinkBit[t5], t2
1872         loadConstantOrVariablePayload(size, t0, CellTag, t3, .opCallSlow)
1873         bineq t3, t2, .opCallSlow
1874         getu(size, opcodeStruct, m_argv, t3)
1875         lshifti 3, t3
1876         negi t3
1877         addp cfr, t3  # t3 contains the new value of cfr
1878         storei t2, Callee + PayloadOffset[t3]
1879         getu(size, opcodeStruct, m_argc, t2)
1880         storei PC, ArgumentCount + TagOffset[cfr]
1881         storei t2, ArgumentCount + PayloadOffset[t3]
1882         storei CellTag, Callee + TagOffset[t3]
1883         move t3, sp
1884         prepareCall(%opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], t2, t3, t4, JSEntryPtrTag)
1885         callTargetFunction(size, opcodeStruct, dispatch, %opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], JSEntryPtrTag)
1886 
1887     .opCallSlow:
1888         slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)
1889     end)
1890 end
1891 
1892 llintOp(op_ret, OpRet, macro (size, get, dispatch)
1893     checkSwitchToJITForEpilogue()
1894     get(m_value, t2)
1895     loadConstantOrVariable(size, t2, t1, t0)
1896     doReturn()
1897 end)
1898 
1899 
1900 llintOpWithReturn(op_to_primitive, OpToPrimitive, macro (size, get, dispatch, return)
1901     get(m_src, t2)
1902     loadConstantOrVariable(size, t2, t1, t0)
1903     bineq t1, CellTag, .opToPrimitiveIsImm
1904     bbaeq JSCell::m_type[t0], ObjectType, .opToPrimitiveSlowCase
1905 .opToPrimitiveIsImm:
1906     return(t1, t0)
1907 
1908 .opToPrimitiveSlowCase:
1909     callSlowPath(_slow_path_to_primitive)
1910     dispatch()
1911 end)
1912 
1913 
1914 commonOp(llint_op_catch, macro() end, macro (size)
1915     # This is where we end up from the JIT&#39;s throw trampoline (because the
1916     # machine code return address will be set to _llint_op_catch), and from
1917     # the interpreter&#39;s throw trampoline (see _llint_throw_trampoline).
1918     # The throwing code must have known that we were throwing to the interpreter,
1919     # and have set VM::targetInterpreterPCForThrow.
1920     loadp Callee + PayloadOffset[cfr], t3
1921     andp MarkedBlockMask, t3
1922     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
1923     restoreCalleeSavesFromVMEntryFrameCalleeSavesBuffer(t3, t0)
1924     loadp VM::callFrameForCatch[t3], cfr
1925     storep 0, VM::callFrameForCatch[t3]
1926     restoreStackPointerAfterCall()
1927 
1928     # restore metadataTable since we don&#39;t restore callee saves for CLoop during unwinding
1929     loadp CodeBlock[cfr], t1
1930     loadp CodeBlock::m_metadata[t1], metadataTable
1931 
1932     loadi VM::targetInterpreterPCForThrow[t3], PC
1933 
1934     callSlowPath(_llint_slow_path_check_if_exception_is_uncatchable_and_notify_profiler)
1935     bpeq r1, 0, .isCatchableException
1936     jmp _llint_throw_from_slow_path_trampoline
1937 
1938 .isCatchableException:
1939     loadp Callee + PayloadOffset[cfr], t3
1940     andp MarkedBlockMask, t3
1941     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
1942 
1943     loadp VM::m_exception[t3], t0
1944     storep 0, VM::m_exception[t3]
1945     get(size, OpCatch, m_exception, t2)
1946     storei t0, PayloadOffset[cfr, t2, 8]
1947     storei CellTag, TagOffset[cfr, t2, 8]
1948 
1949     loadi Exception::m_value + TagOffset[t0], t1
1950     loadi Exception::m_value + PayloadOffset[t0], t0
1951     get(size, OpCatch, m_thrownValue, t2)
1952     storei t0, PayloadOffset[cfr, t2, 8]
1953     storei t1, TagOffset[cfr, t2, 8]
1954 
1955     traceExecution()  # This needs to be here because we don&#39;t want to clobber t0, t1, t2, t3 above.
1956 
1957     callSlowPath(_llint_slow_path_profile_catch)
1958 
1959     dispatchOp(size, op_catch)
1960 end)
1961 
1962 llintOp(op_end, OpEnd, macro (size, get, dispatch)
1963     checkSwitchToJITForEpilogue()
1964     get(m_value, t0)
1965     assertNotConstant(size, t0)
1966     loadi TagOffset[cfr, t0, 8], t1
1967     loadi PayloadOffset[cfr, t0, 8], t0
1968     doReturn()
1969 end)
1970 
1971 
1972 op(llint_throw_from_slow_path_trampoline, macro()
1973     loadp Callee[cfr], t1
1974     andp MarkedBlockMask, t1
1975     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1
1976     copyCalleeSavesToVMEntryFrameCalleeSavesBuffer(t1, t2)
1977 
1978     callSlowPath(_llint_slow_path_handle_exception)
1979 
1980     # When throwing from the interpreter (i.e. throwing from LLIntSlowPaths), so
1981     # the throw target is not necessarily interpreted code, we come to here.
1982     # This essentially emulates the JIT&#39;s throwing protocol.
1983     loadp Callee[cfr], t1
1984     andp MarkedBlockMask, t1
1985     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1
1986     jmp VM::targetMachinePCForThrow[t1]
1987 end)
1988 
1989 
1990 op(llint_throw_during_call_trampoline, macro()
1991     preserveReturnAddressAfterCall(t2)
1992     jmp _llint_throw_from_slow_path_trampoline
1993 end)
1994 
1995 
1996 macro nativeCallTrampoline(executableOffsetToFunction)
1997 
1998     functionPrologue()
1999     storep 0, CodeBlock[cfr]
2000     loadi Callee + PayloadOffset[cfr], t1
2001     // Callee is still in t1 for code below
2002     if X86 or X86_WIN
2003         subp 8, sp # align stack pointer
2004         andp MarkedBlockMask, t1
2005         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t3
2006         storep cfr, VM::topCallFrame[t3]
2007         move cfr, a0  # a0 = ecx
2008         storep a0, [sp]
2009         loadi Callee + PayloadOffset[cfr], t1
2010         loadp JSFunction::m_executable[t1], t1
2011         checkStackPointerAlignment(t3, 0xdead0001)
2012         call executableOffsetToFunction[t1]
2013         loadp Callee + PayloadOffset[cfr], t3
2014         andp MarkedBlockMask, t3
2015         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2016         addp 8, sp
2017     elsif ARMv7 or C_LOOP or C_LOOP_WIN or MIPS
2018         if MIPS
2019         # calling convention says to save stack space for 4 first registers in
2020         # all cases. To match our 16-byte alignment, that means we need to
2021         # take 24 bytes
2022             subp 24, sp
2023         else
2024             subp 8, sp # align stack pointer
2025         end
2026         # t1 already contains the Callee.
2027         andp MarkedBlockMask, t1
2028         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1
2029         storep cfr, VM::topCallFrame[t1]
2030         move cfr, a0
2031         loadi Callee + PayloadOffset[cfr], t1
2032         loadp JSFunction::m_executable[t1], t1
2033         checkStackPointerAlignment(t3, 0xdead0001)
2034         if C_LOOP or C_LOOP_WIN
2035             cloopCallNative executableOffsetToFunction[t1]
2036         else
2037             call executableOffsetToFunction[t1]
2038         end
2039         loadp Callee + PayloadOffset[cfr], t3
2040         andp MarkedBlockMask, t3
2041         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2042         if MIPS
2043             addp 24, sp
2044         else
2045             addp 8, sp
2046         end
2047     else
2048         error
2049     end
2050     
2051     btpnz VM::m_exception[t3], .handleException
2052 
2053     functionEpilogue()
2054     ret
2055 
2056 .handleException:
2057 if X86 or X86_WIN
2058     subp 8, sp # align stack pointer
2059 end
2060     storep cfr, VM::topCallFrame[t3]
2061     jmp _llint_throw_from_slow_path_trampoline
2062 end
2063 
2064 
2065 macro internalFunctionCallTrampoline(offsetOfFunction)
2066     functionPrologue()
2067     storep 0, CodeBlock[cfr]
2068     loadi Callee + PayloadOffset[cfr], t1
2069     // Callee is still in t1 for code below
2070     if X86 or X86_WIN
2071         subp 8, sp # align stack pointer
2072         andp MarkedBlockMask, t1
2073         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t3
2074         storep cfr, VM::topCallFrame[t3]
2075         move cfr, a0  # a0 = ecx
2076         storep a0, [sp]
2077         loadi Callee + PayloadOffset[cfr], t1
2078         checkStackPointerAlignment(t3, 0xdead0001)
2079         call offsetOfFunction[t1]
2080         loadp Callee + PayloadOffset[cfr], t3
2081         andp MarkedBlockMask, t3
2082         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2083         addp 8, sp
2084     elsif ARMv7 or C_LOOP or C_LOOP_WIN or MIPS
2085         subp 8, sp # align stack pointer
2086         # t1 already contains the Callee.
2087         andp MarkedBlockMask, t1
2088         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1
2089         storep cfr, VM::topCallFrame[t1]
2090         move cfr, a0
2091         loadi Callee + PayloadOffset[cfr], t1
2092         checkStackPointerAlignment(t3, 0xdead0001)
2093         if C_LOOP or C_LOOP_WIN
2094             cloopCallNative offsetOfFunction[t1]
2095         else
2096             call offsetOfFunction[t1]
2097         end
2098         loadp Callee + PayloadOffset[cfr], t3
2099         andp MarkedBlockMask, t3
2100         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2101         addp 8, sp
2102     else
2103         error
2104     end
2105 
2106     btpnz VM::m_exception[t3], .handleException
2107 
2108     functionEpilogue()
2109     ret
2110 
2111 .handleException:
2112 if X86 or X86_WIN
2113     subp 8, sp # align stack pointer
2114 end
2115     storep cfr, VM::topCallFrame[t3]
2116     jmp _llint_throw_from_slow_path_trampoline
2117 end
2118 
2119 
2120 macro varInjectionCheck(slowPath)
2121     loadp CodeBlock[cfr], t0
2122     loadp CodeBlock::m_globalObject[t0], t0
2123     loadp JSGlobalObject::m_varInjectionWatchpoint[t0], t0
2124     bbeq WatchpointSet::m_state[t0], IsInvalidated, slowPath
2125 end
2126 
2127 
2128 llintOpWithMetadata(op_resolve_scope, OpResolveScope, macro (size, get, dispatch, metadata, return)
2129 
2130     macro getConstantScope(dst)
2131         loadp OpResolveScope::Metadata::m_constantScope[t5], dst
2132     end
2133 
2134     macro returnConstantScope()
2135         getConstantScope(t0)
2136         return(CellTag, t0)
2137     end
2138 
2139     macro globalLexicalBindingEpochCheck(slowPath, globalObject, scratch)
2140         loadi OpResolveScope::Metadata::m_globalLexicalBindingEpoch[t5], scratch
2141         bineq JSGlobalObject::m_globalLexicalBindingEpoch[globalObject], scratch, slowPath
2142     end
2143 
2144     macro resolveScope()
2145         loadi OpResolveScope::Metadata::m_localScopeDepth[t5], t2
2146         get(m_scope, t0)
2147         loadp PayloadOffset[cfr, t0, 8], t0
2148         btiz t2, .resolveScopeLoopEnd
2149 
2150     .resolveScopeLoop:
2151         loadp JSScope::m_next[t0], t0
2152         subi 1, t2
2153         btinz t2, .resolveScopeLoop
2154 
2155     .resolveScopeLoopEnd:
2156         return(CellTag, t0)
2157     end
2158 
2159     metadata(t5, t0)
2160     loadi OpResolveScope::Metadata::m_resolveType[t5], t0
2161 
2162 #rGlobalProperty:
2163     bineq t0, GlobalProperty, .rGlobalVar
2164     getConstantScope(t0)
2165     globalLexicalBindingEpochCheck(.rDynamic, t0, t2)
2166     return(CellTag, t0)
2167 
2168 .rGlobalVar:
2169     bineq t0, GlobalVar, .rGlobalLexicalVar
2170     returnConstantScope()
2171 
2172 .rGlobalLexicalVar:
2173     bineq t0, GlobalLexicalVar, .rClosureVar
2174     returnConstantScope()
2175 
2176 .rClosureVar:
2177     bineq t0, ClosureVar, .rModuleVar
2178     resolveScope()
2179 
2180 .rModuleVar:
2181     bineq t0, ModuleVar, .rGlobalPropertyWithVarInjectionChecks
2182     returnConstantScope()
2183 
2184 .rGlobalPropertyWithVarInjectionChecks:
2185     bineq t0, GlobalPropertyWithVarInjectionChecks, .rGlobalVarWithVarInjectionChecks
2186     varInjectionCheck(.rDynamic)
2187     getConstantScope(t0)
2188     globalLexicalBindingEpochCheck(.rDynamic, t0, t2)
2189     return(CellTag, t0)
2190 
2191 .rGlobalVarWithVarInjectionChecks:
2192     bineq t0, GlobalVarWithVarInjectionChecks, .rGlobalLexicalVarWithVarInjectionChecks
2193     varInjectionCheck(.rDynamic)
2194     returnConstantScope()
2195 
2196 .rGlobalLexicalVarWithVarInjectionChecks:
2197     bineq t0, GlobalLexicalVarWithVarInjectionChecks, .rClosureVarWithVarInjectionChecks
2198     varInjectionCheck(.rDynamic)
2199     returnConstantScope()
2200 
2201 .rClosureVarWithVarInjectionChecks:
2202     bineq t0, ClosureVarWithVarInjectionChecks, .rDynamic
2203     varInjectionCheck(.rDynamic)
2204     resolveScope()
2205 
2206 .rDynamic:
2207     callSlowPath(_slow_path_resolve_scope)
2208     dispatch()
2209 end)
2210 
2211 
2212 macro loadWithStructureCheck(opcodeStruct, get, operand, slowPath)
2213     get(m_scope, t0)
2214     loadp PayloadOffset[cfr, t0, 8], t0
2215     loadp %opcodeStruct%::Metadata::m_structure[t5], t1
2216     bineq JSCell::m_structureID[t0], t1, slowPath
2217 end
2218 
2219 
2220 llintOpWithMetadata(op_get_from_scope, OpGetFromScope, macro (size, get, dispatch, metadata, return)
2221     macro getProperty()
2222         loadp OpGetFromScope::Metadata::m_operand[t5], t3
2223         loadPropertyAtVariableOffset(t3, t0, t1, t2)
2224         valueProfile(OpGetFromScope, t5, t1, t2)
2225         return(t1, t2)
2226     end
2227 
2228     macro getGlobalVar(tdzCheckIfNecessary)
2229         loadp OpGetFromScope::Metadata::m_operand[t5], t0
2230         loadp TagOffset[t0], t1
2231         loadp PayloadOffset[t0], t2
2232         tdzCheckIfNecessary(t1)
2233         valueProfile(OpGetFromScope, t5, t1, t2)
2234         return(t1, t2)
2235     end
2236 
2237     macro getClosureVar()
2238         loadp OpGetFromScope::Metadata::m_operand[t5], t3
2239         loadp JSLexicalEnvironment_variables + TagOffset[t0, t3, 8], t1
2240         loadp JSLexicalEnvironment_variables + PayloadOffset[t0, t3, 8], t2
2241         valueProfile(OpGetFromScope, t5, t1, t2)
2242         return(t1, t2)
2243     end
2244 
2245     metadata(t5, t0)
2246     loadi OpGetFromScope::Metadata::m_getPutInfo + GetPutInfo::m_operand[t5], t0
2247     andi ResolveTypeMask, t0
2248 
2249 #gGlobalProperty:
2250     bineq t0, GlobalProperty, .gGlobalVar
2251     loadWithStructureCheck(OpGetFromScope, get, scope, .gDynamic)
2252     getProperty()
2253 
2254 .gGlobalVar:
2255     bineq t0, GlobalVar, .gGlobalLexicalVar
2256     getGlobalVar(macro(t) end)
2257 
2258 .gGlobalLexicalVar:
2259     bineq t0, GlobalLexicalVar, .gClosureVar
2260     getGlobalVar(
2261         macro(tag)
2262             bieq tag, EmptyValueTag, .gDynamic
2263         end)
2264 
2265 .gClosureVar:
2266     bineq t0, ClosureVar, .gGlobalPropertyWithVarInjectionChecks
2267     loadVariable(get, m_scope, t2, t1, t0)
2268     getClosureVar()
2269 
2270 .gGlobalPropertyWithVarInjectionChecks:
2271     bineq t0, GlobalPropertyWithVarInjectionChecks, .gGlobalVarWithVarInjectionChecks
2272     loadWithStructureCheck(OpGetFromScope, get, scope, .gDynamic)
2273     getProperty()
2274 
2275 .gGlobalVarWithVarInjectionChecks:
2276     bineq t0, GlobalVarWithVarInjectionChecks, .gGlobalLexicalVarWithVarInjectionChecks
2277     varInjectionCheck(.gDynamic)
2278     getGlobalVar(macro(t) end)
2279 
2280 .gGlobalLexicalVarWithVarInjectionChecks:
2281     bineq t0, GlobalLexicalVarWithVarInjectionChecks, .gClosureVarWithVarInjectionChecks
2282     varInjectionCheck(.gDynamic)
2283     getGlobalVar(
2284         macro(tag)
2285             bieq tag, EmptyValueTag, .gDynamic
2286         end)
2287 
2288 .gClosureVarWithVarInjectionChecks:
2289     bineq t0, ClosureVarWithVarInjectionChecks, .gDynamic
2290     varInjectionCheck(.gDynamic)
2291     loadVariable(get, m_scope, t2, t1, t0)
2292     getClosureVar()
2293 
2294 .gDynamic:
2295     callSlowPath(_llint_slow_path_get_from_scope)
2296     dispatch()
2297 end)
2298 
2299 
2300 llintOpWithMetadata(op_put_to_scope, OpPutToScope, macro (size, get, dispatch, metadata, return)
2301     macro putProperty()
2302         get(m_value, t1)
2303         loadConstantOrVariable(size, t1, t2, t3)
2304         loadp OpPutToScope::Metadata::m_operand[t5], t1
2305         storePropertyAtVariableOffset(t1, t0, t2, t3)
2306     end
2307 
2308     macro putGlobalVariable()
2309         get(m_value, t0)
2310         loadConstantOrVariable(size, t0, t1, t2)
2311         loadp OpPutToScope::Metadata::m_watchpointSet[t5], t3
2312         btpz t3, .noVariableWatchpointSet
2313         notifyWrite(t3, .pDynamic)
2314     .noVariableWatchpointSet:
2315         loadp OpPutToScope::Metadata::m_operand[t5], t0
2316         storei t1, TagOffset[t0]
2317         storei t2, PayloadOffset[t0]
2318     end
2319 
2320     macro putClosureVar()
2321         get(m_value, t1)
2322         loadConstantOrVariable(size, t1, t2, t3)
2323         loadp OpPutToScope::Metadata::m_operand[t5], t1
2324         storei t2, JSLexicalEnvironment_variables + TagOffset[t0, t1, 8]
2325         storei t3, JSLexicalEnvironment_variables + PayloadOffset[t0, t1, 8]
2326     end
2327 
2328     macro putLocalClosureVar()
2329         get(m_value, t1)
2330         loadConstantOrVariable(size, t1, t2, t3)
2331         loadp OpPutToScope::Metadata::m_watchpointSet[t5], t1
2332         btpz t1, .noVariableWatchpointSet
2333         notifyWrite(t1, .pDynamic)
2334     .noVariableWatchpointSet:
2335         loadp OpPutToScope::Metadata::m_operand[t5], t1
2336         storei t2, JSLexicalEnvironment_variables + TagOffset[t0, t1, 8]
2337         storei t3, JSLexicalEnvironment_variables + PayloadOffset[t0, t1, 8]
2338     end
2339 
2340     macro checkTDZInGlobalPutToScopeIfNecessary()
2341         loadi OpPutToScope::Metadata::m_getPutInfo + GetPutInfo::m_operand[t5], t0
2342         andi InitializationModeMask, t0
2343         rshifti InitializationModeShift, t0
2344         bineq t0, NotInitialization, .noNeedForTDZCheck
2345         loadp OpPutToScope::Metadata::m_operand[t5], t0
2346         loadi TagOffset[t0], t0
2347         bieq t0, EmptyValueTag, .pDynamic
2348     .noNeedForTDZCheck:
2349     end
2350 
2351     metadata(t5, t0)
2352     loadi OpPutToScope::Metadata::m_getPutInfo + GetPutInfo::m_operand[t5], t0
2353     andi ResolveTypeMask, t0
2354 
2355 #pLocalClosureVar:
2356     bineq t0, LocalClosureVar, .pGlobalProperty
2357     loadVariable(get, m_scope, t2, t1, t0)
2358     putLocalClosureVar()
2359     writeBarrierOnOperands(size, get, m_scope, m_value)
2360     dispatch()
2361 
2362 .pGlobalProperty:
2363     bineq t0, GlobalProperty, .pGlobalVar
2364     loadWithStructureCheck(OpPutToScope, get, scope, .pDynamic)
2365     putProperty()
2366     writeBarrierOnOperands(size, get, m_scope, m_value)
2367     dispatch()
2368 
2369 .pGlobalVar:
2370     bineq t0, GlobalVar, .pGlobalLexicalVar
2371     putGlobalVariable()
2372     writeBarrierOnGlobalObject(size, get, m_value)
2373     dispatch()
2374 
2375 .pGlobalLexicalVar:
2376     bineq t0, GlobalLexicalVar, .pClosureVar
2377     checkTDZInGlobalPutToScopeIfNecessary()
2378     putGlobalVariable()
2379     writeBarrierOnGlobalLexicalEnvironment(size, get, m_value)
2380     dispatch()
2381 
2382 .pClosureVar:
2383     bineq t0, ClosureVar, .pGlobalPropertyWithVarInjectionChecks
2384     loadVariable(get, m_scope, t2, t1, t0)
2385     putClosureVar()
2386     writeBarrierOnOperands(size, get, m_scope, m_value)
2387     dispatch()
2388 
2389 .pGlobalPropertyWithVarInjectionChecks:
2390     bineq t0, GlobalPropertyWithVarInjectionChecks, .pGlobalVarWithVarInjectionChecks
2391     loadWithStructureCheck(OpPutToScope, get, scope, .pDynamic)
2392     putProperty()
2393     writeBarrierOnOperands(size, get, m_scope, m_value)
2394     dispatch()
2395 
2396 .pGlobalVarWithVarInjectionChecks:
2397     bineq t0, GlobalVarWithVarInjectionChecks, .pGlobalLexicalVarWithVarInjectionChecks
2398     varInjectionCheck(.pDynamic)
2399     putGlobalVariable()
2400     writeBarrierOnGlobalObject(size, get, m_value)
2401     dispatch()
2402 
2403 .pGlobalLexicalVarWithVarInjectionChecks:
2404     bineq t0, GlobalLexicalVarWithVarInjectionChecks, .pClosureVarWithVarInjectionChecks
2405     varInjectionCheck(.pDynamic)
2406     checkTDZInGlobalPutToScopeIfNecessary()
2407     putGlobalVariable()
2408     writeBarrierOnGlobalLexicalEnvironment(size, get, m_value)
2409     dispatch()
2410 
2411 .pClosureVarWithVarInjectionChecks:
2412     bineq t0, ClosureVarWithVarInjectionChecks, .pModuleVar
2413     varInjectionCheck(.pDynamic)
2414     loadVariable(get, m_scope, t2, t1, t0)
2415     putClosureVar()
2416     writeBarrierOnOperands(size, get, m_scope, m_value)
2417     dispatch()
2418 
2419 .pModuleVar:
2420     bineq t0, ModuleVar, .pDynamic
2421     callSlowPath(_slow_path_throw_strict_mode_readonly_property_write_error)
2422     dispatch()
2423 
2424 .pDynamic:
2425     callSlowPath(_llint_slow_path_put_to_scope)
2426     dispatch()
2427 end)
2428 
2429 
2430 llintOpWithProfile(op_get_from_arguments, OpGetFromArguments, macro (size, get, dispatch, return)
2431     get(m_arguments, t0)
2432     loadi PayloadOffset[cfr, t0, 8], t0
2433     getu(size, OpGetFromArguments, m_index, t1)
2434     loadi DirectArguments_storage + TagOffset[t0, t1, 8], t2
2435     loadi DirectArguments_storage + PayloadOffset[t0, t1, 8], t3
2436     return(t2, t3)
2437 end)
2438 
2439 
2440 llintOp(op_put_to_arguments, OpPutToArguments, macro (size, get, dispatch)
2441     writeBarrierOnOperands(size, get, m_arguments, m_value)
2442     get(m_arguments, t0)
2443     loadi PayloadOffset[cfr, t0, 8], t0
2444     get(m_value, t1)
2445     loadConstantOrVariable(size, t1, t2, t3)
2446     getu(size, OpPutToArguments, m_index, t1)
2447     storei t2, DirectArguments_storage + TagOffset[t0, t1, 8]
2448     storei t3, DirectArguments_storage + PayloadOffset[t0, t1, 8]
2449     dispatch()
2450 end)
2451 
2452 
2453 llintOpWithReturn(op_get_parent_scope, OpGetParentScope, macro (size, get, dispatch, return)
2454     get(m_scope, t0)
2455     loadp PayloadOffset[cfr, t0, 8], t0
2456     loadp JSScope::m_next[t0], t0
2457     return(CellTag, t0)
2458 end)
2459 
2460 
2461 llintOpWithMetadata(op_profile_type, OpProfileType, macro (size, get, dispatch, metadata, return)
2462     loadp CodeBlock[cfr], t1
2463     loadp CodeBlock::m_vm[t1], t1
2464     # t1 is holding the pointer to the typeProfilerLog.
2465     loadp VM::m_typeProfilerLog[t1], t1
2466 
2467     # t0 is holding the payload, t5 is holding the tag.
2468     get(m_targetVirtualRegister, t2)
2469     loadConstantOrVariable(size, t2, t5, t0)
2470 
2471     bieq t5, EmptyValueTag, .opProfileTypeDone
2472 
2473     metadata(t3, t2)
2474     # t2 is holding the pointer to the current log entry.
2475     loadp TypeProfilerLog::m_currentLogEntryPtr[t1], t2
2476 
2477     # Store the JSValue onto the log entry.
2478     storei t5, TypeProfilerLog::LogEntry::value + TagOffset[t2]
2479     storei t0, TypeProfilerLog::LogEntry::value + PayloadOffset[t2]
2480 
2481     # Store the TypeLocation onto the log entry.
2482     loadp OpProfileType::Metadata::m_typeLocation[t3], t3
2483     storep t3, TypeProfilerLog::LogEntry::location[t2]
2484 
2485     bieq t5, CellTag, .opProfileTypeIsCell
2486     storei 0, TypeProfilerLog::LogEntry::structureID[t2]
2487     jmp .opProfileTypeSkipIsCell
2488 .opProfileTypeIsCell:
2489     loadi JSCell::m_structureID[t0], t3
2490     storei t3, TypeProfilerLog::LogEntry::structureID[t2]
2491 .opProfileTypeSkipIsCell:
2492     
2493     # Increment the current log entry.
2494     addp sizeof TypeProfilerLog::LogEntry, t2
2495     storep t2, TypeProfilerLog::m_currentLogEntryPtr[t1]
2496 
2497     loadp TypeProfilerLog::m_logEndPtr[t1], t1
2498     bpneq t2, t1, .opProfileTypeDone
2499     callSlowPath(_slow_path_profile_type_clear_log)
2500 
2501 .opProfileTypeDone:
2502     dispatch()
2503 end)
2504 
2505 
2506 llintOpWithMetadata(op_profile_control_flow, OpProfileControlFlow, macro (size, get, dispatch, metadata, return)
2507     metadata(t5, t0)
2508     loadp OpProfileControlFlow::Metadata::m_basicBlockLocation[t5], t0
2509     loadi BasicBlockLocation::m_executionCount[t0], t1
2510     baddio 1, t1, .done
2511     storei t1, BasicBlockLocation::m_executionCount[t0]
2512 .done:
2513     dispatch()
2514 end)
2515 
2516 
2517 llintOpWithReturn(op_get_rest_length, OpGetRestLength, macro (size, get, dispatch, return)
2518     loadi PayloadOffset + ArgumentCount[cfr], t0
2519     subi 1, t0
2520     getu(size, OpGetRestLength, m_numParametersToSkip, t1)
2521     bilteq t0, t1, .storeZero
2522     subi t1, t0
2523     jmp .finish
2524 .storeZero:
2525     move 0, t0
2526 .finish:
2527     return(Int32Tag, t0)
2528 end)
2529 
2530 
2531 llintOp(op_log_shadow_chicken_prologue, OpLogShadowChickenPrologue, macro (size, get, dispatch)
2532     acquireShadowChickenPacket(.opLogShadowChickenPrologueSlow)
2533     storep cfr, ShadowChicken::Packet::frame[t0]
2534     loadp CallerFrame[cfr], t1
2535     storep t1, ShadowChicken::Packet::callerFrame[t0]
2536     loadp Callee + PayloadOffset[cfr], t1
2537     storep t1, ShadowChicken::Packet::callee[t0]
2538     get(m_scope, t1)
2539     loadi PayloadOffset[cfr, t1, 8], t1
2540     storep t1, ShadowChicken::Packet::scope[t0]
2541     dispatch()
2542 .opLogShadowChickenPrologueSlow:
2543     callSlowPath(_llint_slow_path_log_shadow_chicken_prologue)
2544     dispatch()
2545 end)
2546 
2547 
2548 llintOp(op_log_shadow_chicken_tail, OpLogShadowChickenTail, macro (size, get, dispatch)
2549     acquireShadowChickenPacket(.opLogShadowChickenTailSlow)
2550     storep cfr, ShadowChicken::Packet::frame[t0]
2551     storep ShadowChickenTailMarker, ShadowChicken::Packet::callee[t0]
2552     loadVariable(get, m_thisValue, t3, t2, t1)
2553     storei t2, TagOffset + ShadowChicken::Packet::thisValue[t0]
2554     storei t1, PayloadOffset + ShadowChicken::Packet::thisValue[t0]
2555     get(m_scope, t1)
2556     loadi PayloadOffset[cfr, t1, 8], t1
2557     storep t1, ShadowChicken::Packet::scope[t0]
2558     loadp CodeBlock[cfr], t1
2559     storep t1, ShadowChicken::Packet::codeBlock[t0]
2560     storei PC, ShadowChicken::Packet::callSiteIndex[t0]
2561     dispatch()
2562 .opLogShadowChickenTailSlow:
2563     callSlowPath(_llint_slow_path_log_shadow_chicken_tail)
2564     dispatch()
2565 end)
    </pre>
  </body>
</html>