<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITOpcodes32_64.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (C) 2009-2019 Apple Inc. All rights reserved.
   3  * Copyright (C) 2010 Patrick Gansterer &lt;paroga@paroga.com&gt;
   4  *
   5  * Redistribution and use in source and binary forms, with or without
   6  * modification, are permitted provided that the following conditions
   7  * are met:
   8  * 1. Redistributions of source code must retain the above copyright
   9  *    notice, this list of conditions and the following disclaimer.
  10  * 2. Redistributions in binary form must reproduce the above copyright
  11  *    notice, this list of conditions and the following disclaimer in the
  12  *    documentation and/or other materials provided with the distribution.
  13  *
  14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  16  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  17  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  18  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  19  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  20  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  21  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  22  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  23  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  24  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  25  */
  26 
  27 #include &quot;config.h&quot;
  28 
  29 #if ENABLE(JIT)
  30 #if USE(JSVALUE32_64)
  31 #include &quot;JIT.h&quot;
  32 
  33 #include &quot;BytecodeStructs.h&quot;
  34 #include &quot;CCallHelpers.h&quot;
  35 #include &quot;Exception.h&quot;
  36 #include &quot;JITInlines.h&quot;
  37 #include &quot;JSArray.h&quot;
  38 #include &quot;JSCast.h&quot;
  39 #include &quot;JSFunction.h&quot;
  40 #include &quot;JSPropertyNameEnumerator.h&quot;
  41 #include &quot;LinkBuffer.h&quot;
  42 #include &quot;MaxFrameExtentForSlowPathCall.h&quot;
  43 #include &quot;OpcodeInlines.h&quot;
  44 #include &quot;SlowPathCall.h&quot;
  45 #include &quot;TypeProfilerLog.h&quot;
  46 #include &quot;VirtualRegister.h&quot;
  47 
  48 namespace JSC {
  49 
  50 void JIT::emit_op_mov(const Instruction* currentInstruction)
  51 {
  52     auto bytecode = currentInstruction-&gt;as&lt;OpMov&gt;();
  53     int dst = bytecode.m_dst.offset();
  54     int src = bytecode.m_src.offset();
  55 
  56     if (m_codeBlock-&gt;isConstantRegisterIndex(src))
  57         emitStore(dst, getConstantOperand(src));
  58     else {
  59         emitLoad(src, regT1, regT0);
  60         emitStore(dst, regT1, regT0);
  61     }
  62 }
  63 
  64 void JIT::emit_op_end(const Instruction* currentInstruction)
  65 {
  66     ASSERT(returnValueGPR != callFrameRegister);
  67     auto bytecode = currentInstruction-&gt;as&lt;OpEnd&gt;();
  68     emitLoad(bytecode.m_value.offset(), regT1, returnValueGPR);
  69     emitRestoreCalleeSaves();
  70     emitFunctionEpilogue();
  71     ret();
  72 }
  73 
  74 void JIT::emit_op_jmp(const Instruction* currentInstruction)
  75 {
  76     auto bytecode = currentInstruction-&gt;as&lt;OpJmp&gt;();
  77     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
  78     addJump(jump(), target);
  79 }
  80 
  81 void JIT::emit_op_new_object(const Instruction* currentInstruction)
  82 {
  83     auto bytecode = currentInstruction-&gt;as&lt;OpNewObject&gt;();
  84     auto&amp; metadata = bytecode.metadata(m_codeBlock);
  85     Structure* structure = metadata.m_objectAllocationProfile.structure();
  86     size_t allocationSize = JSFinalObject::allocationSize(structure-&gt;inlineCapacity());
  87     Allocator allocator = allocatorForNonVirtualConcurrently&lt;JSFinalObject&gt;(*m_vm, allocationSize, AllocatorForMode::AllocatorIfExists);
  88 
  89     RegisterID resultReg = returnValueGPR;
  90     RegisterID allocatorReg = regT1;
  91     RegisterID scratchReg = regT3;
  92 
  93     if (!allocator)
  94         addSlowCase(jump());
  95     else {
  96         JumpList slowCases;
  97         auto butterfly = TrustedImmPtr(nullptr);
  98         emitAllocateJSObject(resultReg, JITAllocator::constant(allocator), allocatorReg, TrustedImmPtr(structure), butterfly, scratchReg, slowCases);
  99         emitInitializeInlineStorage(resultReg, structure-&gt;inlineCapacity());
 100         addSlowCase(slowCases);
 101         emitStoreCell(bytecode.m_dst.offset(), resultReg);
 102     }
 103 }
 104 
 105 void JIT::emitSlow_op_new_object(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 106 {
 107     linkAllSlowCases(iter);
 108 
 109     auto bytecode = currentInstruction-&gt;as&lt;OpNewObject&gt;();
 110     auto&amp; metadata = bytecode.metadata(m_codeBlock);
 111     int dst = bytecode.m_dst.offset();
 112     Structure* structure = metadata.m_objectAllocationProfile.structure();
 113     callOperation(operationNewObject, structure);
 114     emitStoreCell(dst, returnValueGPR);
 115 }
 116 
 117 void JIT::emit_op_overrides_has_instance(const Instruction* currentInstruction)
 118 {
 119     auto bytecode = currentInstruction-&gt;as&lt;OpOverridesHasInstance&gt;();
 120     int dst = bytecode.m_dst.offset();
 121     int constructor = bytecode.m_constructor.offset();
 122     int hasInstanceValue = bytecode.m_hasInstanceValue.offset();
 123 
 124     emitLoadPayload(hasInstanceValue, regT0);
 125     // We don&#39;t jump if we know what Symbol.hasInstance would do.
 126     Jump hasInstanceValueNotCell = emitJumpIfNotJSCell(hasInstanceValue);
 127     Jump customhasInstanceValue = branchPtr(NotEqual, regT0, TrustedImmPtr(m_codeBlock-&gt;globalObject()-&gt;functionProtoHasInstanceSymbolFunction()));
 128 
 129     // We know that constructor is an object from the way bytecode is emitted for instanceof expressions.
 130     emitLoadPayload(constructor, regT0);
 131 
 132     // Check that constructor &#39;ImplementsDefaultHasInstance&#39; i.e. the object is not a C-API user nor a bound function.
 133     test8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(ImplementsDefaultHasInstance), regT0);
 134     Jump done = jump();
 135 
 136     hasInstanceValueNotCell.link(this);
 137     customhasInstanceValue.link(this);
 138     move(TrustedImm32(1), regT0);
 139 
 140     done.link(this);
 141     emitStoreBool(dst, regT0);
 142 
 143 }
 144 
 145 void JIT::emit_op_instanceof(const Instruction* currentInstruction)
 146 {
 147     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceof&gt;();
 148     int dst = bytecode.m_dst.offset();
 149     int value = bytecode.m_value.offset();
 150     int proto = bytecode.m_prototype.offset();
 151 
 152     // Load the operands into registers.
 153     // We use regT0 for baseVal since we will be done with this first, and we can then use it for the result.
 154     emitLoadPayload(value, regT2);
 155     emitLoadPayload(proto, regT1);
 156 
 157     // Check that proto are cells. baseVal must be a cell - this is checked by the get_by_id for Symbol.hasInstance.
 158     emitJumpSlowCaseIfNotJSCell(value);
 159     emitJumpSlowCaseIfNotJSCell(proto);
 160 
 161     JITInstanceOfGenerator gen(
 162         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset),
 163         RegisterSet::stubUnavailableRegisters(),
 164         regT0, // result
 165         regT2, // value
 166         regT1, // proto
 167         regT3, regT4); // scratch
 168     gen.generateFastPath(*this);
 169     m_instanceOfs.append(gen);
 170 
 171     emitStoreBool(dst, regT0);
 172 }
 173 
 174 void JIT::emit_op_instanceof_custom(const Instruction*)
 175 {
 176     // This always goes to slow path since we expect it to be rare.
 177     addSlowCase(jump());
 178 }
 179 
 180 void JIT::emitSlow_op_instanceof(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 181 {
 182     linkAllSlowCases(iter);
 183 
 184     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceof&gt;();
 185     int dst = bytecode.m_dst.offset();
 186     int value = bytecode.m_value.offset();
 187     int proto = bytecode.m_prototype.offset();
 188 
 189     JITInstanceOfGenerator&amp; gen = m_instanceOfs[m_instanceOfIndex++];
 190 
 191     Label coldPathBegin = label();
 192     emitLoadTag(value, regT0);
 193     emitLoadTag(proto, regT3);
 194     Call call = callOperation(operationInstanceOfOptimize, dst, gen.stubInfo(), JSValueRegs(regT0, regT2), JSValueRegs(regT3, regT1));
 195     gen.reportSlowPathCall(coldPathBegin, call);
 196 }
 197 
 198 void JIT::emitSlow_op_instanceof_custom(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 199 {
 200     linkAllSlowCases(iter);
 201 
 202     auto bytecode = currentInstruction-&gt;as&lt;OpInstanceofCustom&gt;();
 203     int dst = bytecode.m_dst.offset();
 204     int value = bytecode.m_value.offset();
 205     int constructor = bytecode.m_constructor.offset();
 206     int hasInstanceValue = bytecode.m_hasInstanceValue.offset();
 207 
 208     emitLoad(value, regT1, regT0);
 209     emitLoadPayload(constructor, regT2);
 210     emitLoad(hasInstanceValue, regT4, regT3);
 211     callOperation(operationInstanceOfCustom, JSValueRegs(regT1, regT0), regT2, JSValueRegs(regT4, regT3));
 212     emitStoreBool(dst, returnValueGPR);
 213 }
 214 
 215 void JIT::emit_op_is_empty(const Instruction* currentInstruction)
 216 {
 217     auto bytecode = currentInstruction-&gt;as&lt;OpIsEmpty&gt;();
 218     int dst = bytecode.m_dst.offset();
 219     int value = bytecode.m_operand.offset();
 220 
 221     emitLoad(value, regT1, regT0);
 222     compare32(Equal, regT1, TrustedImm32(JSValue::EmptyValueTag), regT0);
 223 
 224     emitStoreBool(dst, regT0);
 225 }
 226 
 227 void JIT::emit_op_is_undefined(const Instruction* currentInstruction)
 228 {
 229     auto bytecode = currentInstruction-&gt;as&lt;OpIsUndefined&gt;();
 230     int dst = bytecode.m_dst.offset();
 231     int value = bytecode.m_operand.offset();
 232 
 233     emitLoad(value, regT1, regT0);
 234     Jump isCell = branchIfCell(regT1);
 235 
 236     compare32(Equal, regT1, TrustedImm32(JSValue::UndefinedTag), regT0);
 237     Jump done = jump();
 238 
 239     isCell.link(this);
 240     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 241     move(TrustedImm32(0), regT0);
 242     Jump notMasqueradesAsUndefined = jump();
 243 
 244     isMasqueradesAsUndefined.link(this);
 245     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT1);
 246     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 247     loadPtr(Address(regT1, Structure::globalObjectOffset()), regT1);
 248     compare32(Equal, regT0, regT1, regT0);
 249 
 250     notMasqueradesAsUndefined.link(this);
 251     done.link(this);
 252     emitStoreBool(dst, regT0);
 253 }
 254 
 255 void JIT::emit_op_is_undefined_or_null(const Instruction* currentInstruction)
 256 {
 257     auto bytecode = currentInstruction-&gt;as&lt;OpIsUndefinedOrNull&gt;();
 258     int dst = bytecode.m_dst.offset();
 259     int value = bytecode.m_operand.offset();
 260 
 261     emitLoadTag(value, regT0);
 262     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 263     or32(TrustedImm32(1), regT0);
 264     compare32(Equal, regT0, TrustedImm32(JSValue::NullTag), regT0);
 265     emitStoreBool(dst, regT0);
 266 }
 267 
 268 void JIT::emit_op_is_boolean(const Instruction* currentInstruction)
 269 {
 270     auto bytecode = currentInstruction-&gt;as&lt;OpIsBoolean&gt;();
 271     int dst = bytecode.m_dst.offset();
 272     int value = bytecode.m_operand.offset();
 273 
 274     emitLoadTag(value, regT0);
 275     compare32(Equal, regT0, TrustedImm32(JSValue::BooleanTag), regT0);
 276     emitStoreBool(dst, regT0);
 277 }
 278 
 279 void JIT::emit_op_is_number(const Instruction* currentInstruction)
 280 {
 281     auto bytecode = currentInstruction-&gt;as&lt;OpIsNumber&gt;();
 282     int dst = bytecode.m_dst.offset();
 283     int value = bytecode.m_operand.offset();
 284 
 285     emitLoadTag(value, regT0);
 286     add32(TrustedImm32(1), regT0);
 287     compare32(Below, regT0, TrustedImm32(JSValue::LowestTag + 1), regT0);
 288     emitStoreBool(dst, regT0);
 289 }
 290 
 291 void JIT::emit_op_is_cell_with_type(const Instruction* currentInstruction)
 292 {
 293     auto bytecode = currentInstruction-&gt;as&lt;OpIsCellWithType&gt;();
 294     int dst = bytecode.m_dst.offset();
 295     int value = bytecode.m_operand.offset();
 296     int type = bytecode.m_type;
 297 
 298     emitLoad(value, regT1, regT0);
 299     Jump isNotCell = branchIfNotCell(regT1);
 300 
 301     compare8(Equal, Address(regT0, JSCell::typeInfoTypeOffset()), TrustedImm32(type), regT0);
 302     Jump done = jump();
 303 
 304     isNotCell.link(this);
 305     move(TrustedImm32(0), regT0);
 306 
 307     done.link(this);
 308     emitStoreBool(dst, regT0);
 309 }
 310 
 311 void JIT::emit_op_is_object(const Instruction* currentInstruction)
 312 {
 313     auto bytecode = currentInstruction-&gt;as&lt;OpIsObject&gt;();
 314     int dst = bytecode.m_dst.offset();
 315     int value = bytecode.m_operand.offset();
 316 
 317     emitLoad(value, regT1, regT0);
 318     Jump isNotCell = branchIfNotCell(regT1);
 319 
 320     compare8(AboveOrEqual, Address(regT0, JSCell::typeInfoTypeOffset()), TrustedImm32(ObjectType), regT0);
 321     Jump done = jump();
 322 
 323     isNotCell.link(this);
 324     move(TrustedImm32(0), regT0);
 325 
 326     done.link(this);
 327     emitStoreBool(dst, regT0);
 328 }
 329 
 330 void JIT::emit_op_to_primitive(const Instruction* currentInstruction)
 331 {
 332     auto bytecode = currentInstruction-&gt;as&lt;OpToPrimitive&gt;();
 333     int dst = bytecode.m_dst.offset();
 334     int src = bytecode.m_src.offset();
 335 
 336     emitLoad(src, regT1, regT0);
 337 
 338     Jump isImm = branchIfNotCell(regT1);
 339     addSlowCase(branchIfObject(regT0));
 340     isImm.link(this);
 341 
 342     if (dst != src)
 343         emitStore(dst, regT1, regT0);
 344 }
 345 
 346 void JIT::emit_op_set_function_name(const Instruction* currentInstruction)
 347 {
 348     auto bytecode = currentInstruction-&gt;as&lt;OpSetFunctionName&gt;();
 349     int func = bytecode.m_function.offset();
 350     int name = bytecode.m_name.offset();
 351     emitLoadPayload(func, regT1);
 352     emitLoad(name, regT3, regT2);
 353     callOperation(operationSetFunctionName, regT1, JSValueRegs(regT3, regT2));
 354 }
 355 
 356 void JIT::emit_op_not(const Instruction* currentInstruction)
 357 {
 358     auto bytecode = currentInstruction-&gt;as&lt;OpNot&gt;();
 359     int dst = bytecode.m_dst.offset();
 360     int src = bytecode.m_operand.offset();
 361 
 362     emitLoadTag(src, regT0);
 363 
 364     emitLoad(src, regT1, regT0);
 365     addSlowCase(branchIfNotBoolean(regT1, InvalidGPRReg));
 366     xor32(TrustedImm32(1), regT0);
 367 
 368     emitStoreBool(dst, regT0, (dst == src));
 369 }
 370 
 371 void JIT::emit_op_jfalse(const Instruction* currentInstruction)
 372 {
 373     auto bytecode = currentInstruction-&gt;as&lt;OpJfalse&gt;();
 374     int cond = bytecode.m_condition.offset();
 375     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 376 
 377     emitLoad(cond, regT1, regT0);
 378 
 379     JSValueRegs value(regT1, regT0);
 380     GPRReg scratch1 = regT2;
 381     GPRReg scratch2 = regT3;
 382     bool shouldCheckMasqueradesAsUndefined = true;
<a name="1" id="anc1"></a><span class="line-modified"> 383     addJump(branchIfFalsey(vm(), value, scratch1, scratch2, fpRegT0, fpRegT1, shouldCheckMasqueradesAsUndefined, m_codeBlock-&gt;globalObject()), target);</span>
 384 }
 385 
 386 void JIT::emit_op_jtrue(const Instruction* currentInstruction)
 387 {
 388     auto bytecode = currentInstruction-&gt;as&lt;OpJtrue&gt;();
 389     int cond = bytecode.m_condition.offset();
 390     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 391 
 392     emitLoad(cond, regT1, regT0);
 393     bool shouldCheckMasqueradesAsUndefined = true;
 394     JSValueRegs value(regT1, regT0);
 395     GPRReg scratch1 = regT2;
 396     GPRReg scratch2 = regT3;
<a name="2" id="anc2"></a><span class="line-modified"> 397     addJump(branchIfTruthy(vm(), value, scratch1, scratch2, fpRegT0, fpRegT1, shouldCheckMasqueradesAsUndefined, m_codeBlock-&gt;globalObject()), target);</span>
 398 }
 399 
 400 void JIT::emit_op_jeq_null(const Instruction* currentInstruction)
 401 {
 402     auto bytecode = currentInstruction-&gt;as&lt;OpJeqNull&gt;();
 403     int src = bytecode.m_value.offset();
 404     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 405 
 406     emitLoad(src, regT1, regT0);
 407 
 408     Jump isImmediate = branchIfNotCell(regT1);
 409 
 410     Jump isNotMasqueradesAsUndefined = branchTest8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 411     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 412     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 413     addJump(branchPtr(Equal, Address(regT2, Structure::globalObjectOffset()), regT0), target);
 414     Jump masqueradesGlobalObjectIsForeign = jump();
 415 
 416     // Now handle the immediate cases - undefined &amp; null
 417     isImmediate.link(this);
 418     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 419     or32(TrustedImm32(1), regT1);
 420     addJump(branchIfNull(regT1), target);
 421 
 422     isNotMasqueradesAsUndefined.link(this);
 423     masqueradesGlobalObjectIsForeign.link(this);
 424 }
 425 
 426 void JIT::emit_op_jneq_null(const Instruction* currentInstruction)
 427 {
 428     auto bytecode = currentInstruction-&gt;as&lt;OpJneqNull&gt;();
 429     int src = bytecode.m_value.offset();
 430     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 431 
 432     emitLoad(src, regT1, regT0);
 433 
 434     Jump isImmediate = branchIfNotCell(regT1);
 435 
 436     addJump(branchTest8(Zero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined)), target);
 437     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 438     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 439     addJump(branchPtr(NotEqual, Address(regT2, Structure::globalObjectOffset()), regT0), target);
 440     Jump wasNotImmediate = jump();
 441 
 442     // Now handle the immediate cases - undefined &amp; null
 443     isImmediate.link(this);
 444 
 445     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);
 446     or32(TrustedImm32(1), regT1);
 447     addJump(branchIfNotNull(regT1), target);
 448 
 449     wasNotImmediate.link(this);
 450 }
 451 
<a name="3" id="anc3"></a><span class="line-added"> 452 void JIT::emit_op_jundefined_or_null(const Instruction* currentInstruction)</span>
<span class="line-added"> 453 {</span>
<span class="line-added"> 454     auto bytecode = currentInstruction-&gt;as&lt;OpJundefinedOrNull&gt;();</span>
<span class="line-added"> 455     int value = bytecode.m_value.offset();</span>
<span class="line-added"> 456     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);</span>
<span class="line-added"> 457 </span>
<span class="line-added"> 458     emitLoadTag(value, regT0);</span>
<span class="line-added"> 459     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);</span>
<span class="line-added"> 460     or32(TrustedImm32(1), regT0);</span>
<span class="line-added"> 461     addJump(branchIfNull(regT0), target);</span>
<span class="line-added"> 462 }</span>
<span class="line-added"> 463 </span>
<span class="line-added"> 464 void JIT::emit_op_jnundefined_or_null(const Instruction* currentInstruction)</span>
<span class="line-added"> 465 {</span>
<span class="line-added"> 466     auto bytecode = currentInstruction-&gt;as&lt;OpJnundefinedOrNull&gt;();</span>
<span class="line-added"> 467     int value = bytecode.m_value.offset();</span>
<span class="line-added"> 468     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);</span>
<span class="line-added"> 469 </span>
<span class="line-added"> 470     emitLoadTag(value, regT0);</span>
<span class="line-added"> 471     static_assert((JSValue::UndefinedTag + 1 == JSValue::NullTag) &amp;&amp; (JSValue::NullTag &amp; 0x1), &quot;&quot;);</span>
<span class="line-added"> 472     or32(TrustedImm32(1), regT0);</span>
<span class="line-added"> 473     addJump(branchIfNotNull(regT0), target);</span>
<span class="line-added"> 474 }</span>
<span class="line-added"> 475 </span>
 476 void JIT::emit_op_jneq_ptr(const Instruction* currentInstruction)
 477 {
 478     auto bytecode = currentInstruction-&gt;as&lt;OpJneqPtr&gt;();
 479     auto&amp; metadata = bytecode.metadata(m_codeBlock);
 480     int src = bytecode.m_value.offset();
 481     Special::Pointer ptr = bytecode.m_specialPointer;
 482     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 483 
 484     emitLoad(src, regT1, regT0);
 485     Jump notCell = branchIfNotCell(regT1);
 486     Jump equal = branchPtr(Equal, regT0, TrustedImmPtr(actualPointerFor(m_codeBlock, ptr)));
 487     notCell.link(this);
 488     store8(TrustedImm32(1), &amp;metadata.m_hasJumped);
 489     addJump(jump(), target);
 490     equal.link(this);
 491 }
 492 
 493 void JIT::emit_op_eq(const Instruction* currentInstruction)
 494 {
 495     auto bytecode = currentInstruction-&gt;as&lt;OpEq&gt;();
 496 
 497     int dst = bytecode.m_dst.offset();
 498     int src1 = bytecode.m_lhs.offset();
 499     int src2 = bytecode.m_rhs.offset();
 500 
 501     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 502     addSlowCase(branch32(NotEqual, regT1, regT3));
 503     addSlowCase(branchIfCell(regT1));
 504     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 505 
 506     compare32(Equal, regT0, regT2, regT0);
 507 
 508     emitStoreBool(dst, regT0);
 509 }
 510 
 511 void JIT::emitSlow_op_eq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 512 {
 513     auto bytecode = currentInstruction-&gt;as&lt;OpEq&gt;();
 514     int dst = bytecode.m_dst.offset();
 515 
 516     JumpList storeResult;
 517     JumpList genericCase;
 518 
 519     genericCase.append(getSlowCase(iter)); // tags not equal
 520 
 521     linkSlowCase(iter); // tags equal and JSCell
 522     genericCase.append(branchIfNotString(regT0));
 523     genericCase.append(branchIfNotString(regT2));
 524 
 525     // String case.
 526     callOperation(operationCompareStringEq, regT0, regT2);
 527     storeResult.append(jump());
 528 
 529     // Generic case.
 530     genericCase.append(getSlowCase(iter)); // doubles
 531     genericCase.link(this);
 532     callOperation(operationCompareEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));
 533 
 534     storeResult.link(this);
 535     emitStoreBool(dst, returnValueGPR);
 536 }
 537 
 538 void JIT::emit_op_jeq(const Instruction* currentInstruction)
 539 {
 540     auto bytecode = currentInstruction-&gt;as&lt;OpJeq&gt;();
 541     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 542     int src1 = bytecode.m_lhs.offset();
 543     int src2 = bytecode.m_rhs.offset();
 544 
 545     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 546     addSlowCase(branch32(NotEqual, regT1, regT3));
 547     addSlowCase(branchIfCell(regT1));
 548     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 549 
 550     addJump(branch32(Equal, regT0, regT2), target);
 551 }
 552 
 553 void JIT::compileOpEqJumpSlow(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter, CompileOpEqType type, int jumpTarget)
 554 {
 555     JumpList done;
 556     JumpList genericCase;
 557 
 558     genericCase.append(getSlowCase(iter)); // tags not equal
 559 
 560     linkSlowCase(iter); // tags equal and JSCell
 561     genericCase.append(branchIfNotString(regT0));
 562     genericCase.append(branchIfNotString(regT2));
 563 
 564     // String case.
 565     callOperation(operationCompareStringEq, regT0, regT2);
 566     emitJumpSlowToHot(branchTest32(type == CompileOpEqType::Eq ? NonZero : Zero, returnValueGPR), jumpTarget);
 567     done.append(jump());
 568 
 569     // Generic case.
 570     genericCase.append(getSlowCase(iter)); // doubles
 571     genericCase.link(this);
 572     callOperation(operationCompareEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));
 573     emitJumpSlowToHot(branchTest32(type == CompileOpEqType::Eq ? NonZero : Zero, returnValueGPR), jumpTarget);
 574 
 575     done.link(this);
 576 }
 577 
 578 void JIT::emitSlow_op_jeq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 579 {
 580     auto bytecode = currentInstruction-&gt;as&lt;OpJeq&gt;();
 581     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 582     compileOpEqJumpSlow(iter, CompileOpEqType::Eq, target);
 583 }
 584 
 585 void JIT::emit_op_neq(const Instruction* currentInstruction)
 586 {
 587     auto bytecode = currentInstruction-&gt;as&lt;OpNeq&gt;();
 588     int dst = bytecode.m_dst.offset();
 589     int src1 = bytecode.m_lhs.offset();
 590     int src2 = bytecode.m_rhs.offset();
 591 
 592     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 593     addSlowCase(branch32(NotEqual, regT1, regT3));
 594     addSlowCase(branchIfCell(regT1));
 595     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 596 
 597     compare32(NotEqual, regT0, regT2, regT0);
 598 
 599     emitStoreBool(dst, regT0);
 600 }
 601 
 602 void JIT::emitSlow_op_neq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 603 {
 604     auto bytecode = currentInstruction-&gt;as&lt;OpNeq&gt;();
 605     int dst = bytecode.m_dst.offset();
 606 
 607     JumpList storeResult;
 608     JumpList genericCase;
 609 
 610     genericCase.append(getSlowCase(iter)); // tags not equal
 611 
 612     linkSlowCase(iter); // tags equal and JSCell
 613     genericCase.append(branchIfNotString(regT0));
 614     genericCase.append(branchIfNotString(regT2));
 615 
 616     // String case.
 617     callOperation(operationCompareStringEq, regT0, regT2);
 618     storeResult.append(jump());
 619 
 620     // Generic case.
 621     genericCase.append(getSlowCase(iter)); // doubles
 622     genericCase.link(this);
 623     callOperation(operationCompareEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));
 624 
 625     storeResult.link(this);
 626     xor32(TrustedImm32(0x1), returnValueGPR);
 627     emitStoreBool(dst, returnValueGPR);
 628 }
 629 
 630 void JIT::emit_op_jneq(const Instruction* currentInstruction)
 631 {
 632     auto bytecode = currentInstruction-&gt;as&lt;OpJneq&gt;();
 633     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 634     int src1 = bytecode.m_lhs.offset();
 635     int src2 = bytecode.m_rhs.offset();
 636 
 637     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 638     addSlowCase(branch32(NotEqual, regT1, regT3));
 639     addSlowCase(branchIfCell(regT1));
 640     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 641 
 642     addJump(branch32(NotEqual, regT0, regT2), target);
 643 }
 644 
 645 void JIT::emitSlow_op_jneq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 646 {
 647     auto bytecode = currentInstruction-&gt;as&lt;OpJneq&gt;();
 648     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 649     compileOpEqJumpSlow(iter, CompileOpEqType::NEq, target);
 650 }
 651 
 652 template &lt;typename Op&gt;
 653 void JIT::compileOpStrictEq(const Instruction* currentInstruction, CompileOpStrictEqType type)
 654 {
 655     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
 656     int dst = bytecode.m_dst.offset();
 657     int src1 = bytecode.m_lhs.offset();
 658     int src2 = bytecode.m_rhs.offset();
 659 
 660     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 661 
 662     // Bail if the tags differ, or are double.
 663     addSlowCase(branch32(NotEqual, regT1, regT3));
 664     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 665 
 666     // Jump to a slow case if both are strings or symbols (non object).
 667     Jump notCell = branchIfNotCell(regT1);
 668     Jump firstIsObject = branchIfObject(regT0);
 669     addSlowCase(branchIfNotObject(regT2));
 670     notCell.link(this);
 671     firstIsObject.link(this);
 672 
 673     // Simply compare the payloads.
 674     if (type == CompileOpStrictEqType::StrictEq)
 675         compare32(Equal, regT0, regT2, regT0);
 676     else
 677         compare32(NotEqual, regT0, regT2, regT0);
 678 
 679     emitStoreBool(dst, regT0);
 680 }
 681 
 682 void JIT::emit_op_stricteq(const Instruction* currentInstruction)
 683 {
 684     compileOpStrictEq&lt;OpStricteq&gt;(currentInstruction, CompileOpStrictEqType::StrictEq);
 685 }
 686 
 687 void JIT::emit_op_nstricteq(const Instruction* currentInstruction)
 688 {
 689     compileOpStrictEq&lt;OpNstricteq&gt;(currentInstruction, CompileOpStrictEqType::NStrictEq);
 690 }
 691 
 692 template&lt;typename Op&gt;
 693 void JIT::compileOpStrictEqJump(const Instruction* currentInstruction, CompileOpStrictEqType type)
 694 {
 695     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
 696     int target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 697     int src1 = bytecode.m_lhs.offset();
 698     int src2 = bytecode.m_rhs.offset();
 699 
 700     emitLoad2(src1, regT1, regT0, src2, regT3, regT2);
 701 
 702     // Bail if the tags differ, or are double.
 703     addSlowCase(branch32(NotEqual, regT1, regT3));
 704     addSlowCase(branch32(Below, regT1, TrustedImm32(JSValue::LowestTag)));
 705 
 706     // Jump to a slow case if both are strings or symbols (non object).
 707     Jump notCell = branchIfNotCell(regT1);
 708     Jump firstIsObject = branchIfObject(regT0);
 709     addSlowCase(branchIfNotObject(regT2));
 710     notCell.link(this);
 711     firstIsObject.link(this);
 712 
 713     // Simply compare the payloads.
 714     if (type == CompileOpStrictEqType::StrictEq)
 715         addJump(branch32(Equal, regT0, regT2), target);
 716     else
 717         addJump(branch32(NotEqual, regT0, regT2), target);
 718 }
 719 
 720 void JIT::emit_op_jstricteq(const Instruction* currentInstruction)
 721 {
 722     compileOpStrictEqJump&lt;OpJstricteq&gt;(currentInstruction, CompileOpStrictEqType::StrictEq);
 723 }
 724 
 725 void JIT::emit_op_jnstricteq(const Instruction* currentInstruction)
 726 {
 727     compileOpStrictEqJump&lt;OpJnstricteq&gt;(currentInstruction, CompileOpStrictEqType::NStrictEq);
 728 }
 729 
 730 void JIT::emitSlow_op_jstricteq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 731 {
 732     linkAllSlowCases(iter);
 733 
 734     auto bytecode = currentInstruction-&gt;as&lt;OpJstricteq&gt;();
 735     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 736     callOperation(operationCompareStrictEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));
 737     emitJumpSlowToHot(branchTest32(NonZero, returnValueGPR), target);
 738 }
 739 
 740 void JIT::emitSlow_op_jnstricteq(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
 741 {
 742     linkAllSlowCases(iter);
 743 
 744     auto bytecode = currentInstruction-&gt;as&lt;OpJnstricteq&gt;();
 745     unsigned target = jumpTarget(currentInstruction, bytecode.m_targetLabel);
 746     callOperation(operationCompareStrictEq, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2));
 747     emitJumpSlowToHot(branchTest32(Zero, returnValueGPR), target);
 748 }
 749 
 750 void JIT::emit_op_eq_null(const Instruction* currentInstruction)
 751 {
 752     auto bytecode = currentInstruction-&gt;as&lt;OpEqNull&gt;();
 753     int dst = bytecode.m_dst.offset();
 754     int src = bytecode.m_operand.offset();
 755 
 756     emitLoad(src, regT1, regT0);
 757     Jump isImmediate = branchIfNotCell(regT1);
 758 
 759     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 760     move(TrustedImm32(0), regT1);
 761     Jump wasNotMasqueradesAsUndefined = jump();
 762 
 763     isMasqueradesAsUndefined.link(this);
 764     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 765     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 766     loadPtr(Address(regT2, Structure::globalObjectOffset()), regT2);
 767     compare32(Equal, regT0, regT2, regT1);
 768     Jump wasNotImmediate = jump();
 769 
 770     isImmediate.link(this);
 771 
 772     compare32(Equal, regT1, TrustedImm32(JSValue::NullTag), regT2);
 773     compare32(Equal, regT1, TrustedImm32(JSValue::UndefinedTag), regT1);
 774     or32(regT2, regT1);
 775 
 776     wasNotImmediate.link(this);
 777     wasNotMasqueradesAsUndefined.link(this);
 778 
 779     emitStoreBool(dst, regT1);
 780 }
 781 
 782 void JIT::emit_op_neq_null(const Instruction* currentInstruction)
 783 {
 784     auto bytecode = currentInstruction-&gt;as&lt;OpNeqNull&gt;();
 785     int dst = bytecode.m_dst.offset();
 786     int src = bytecode.m_operand.offset();
 787 
 788     emitLoad(src, regT1, regT0);
 789     Jump isImmediate = branchIfNotCell(regT1);
 790 
 791     Jump isMasqueradesAsUndefined = branchTest8(NonZero, Address(regT0, JSCell::typeInfoFlagsOffset()), TrustedImm32(MasqueradesAsUndefined));
 792     move(TrustedImm32(1), regT1);
 793     Jump wasNotMasqueradesAsUndefined = jump();
 794 
 795     isMasqueradesAsUndefined.link(this);
 796     loadPtr(Address(regT0, JSCell::structureIDOffset()), regT2);
 797     move(TrustedImmPtr(m_codeBlock-&gt;globalObject()), regT0);
 798     loadPtr(Address(regT2, Structure::globalObjectOffset()), regT2);
 799     compare32(NotEqual, regT0, regT2, regT1);
 800     Jump wasNotImmediate = jump();
 801 
 802     isImmediate.link(this);
 803 
 804     compare32(NotEqual, regT1, TrustedImm32(JSValue::NullTag), regT2);
 805     compare32(NotEqual, regT1, TrustedImm32(JSValue::UndefinedTag), regT1);
 806     and32(regT2, regT1);
 807 
 808     wasNotImmediate.link(this);
 809     wasNotMasqueradesAsUndefined.link(this);
 810 
 811     emitStoreBool(dst, regT1);
 812 }
 813 
 814 void JIT::emit_op_throw(const Instruction* currentInstruction)
 815 {
 816     auto bytecode = currentInstruction-&gt;as&lt;OpThrow&gt;();
 817     ASSERT(regT0 == returnValueGPR);
<a name="4" id="anc4"></a><span class="line-modified"> 818     copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);</span>
 819     emitLoad(bytecode.m_value.offset(), regT1, regT0);
 820     callOperationNoExceptionCheck(operationThrow, JSValueRegs(regT1, regT0));
<a name="5" id="anc5"></a><span class="line-modified"> 821     jumpToExceptionHandler(vm());</span>
 822 }
 823 
 824 void JIT::emit_op_to_number(const Instruction* currentInstruction)
 825 {
 826     auto bytecode = currentInstruction-&gt;as&lt;OpToNumber&gt;();
 827     int dst = bytecode.m_dst.offset();
 828     int src = bytecode.m_operand.offset();
 829 
 830     emitLoad(src, regT1, regT0);
 831 
 832     Jump isInt32 = branchIfInt32(regT1);
 833     addSlowCase(branch32(AboveOrEqual, regT1, TrustedImm32(JSValue::LowestTag)));
 834     isInt32.link(this);
 835 
 836     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 837     if (src != dst)
 838         emitStore(dst, regT1, regT0);
 839 }
 840 
 841 void JIT::emit_op_to_string(const Instruction* currentInstruction)
 842 {
 843     auto bytecode = currentInstruction-&gt;as&lt;OpToString&gt;();
 844     int dst = bytecode.m_dst.offset();
 845     int src = bytecode.m_operand.offset();
 846 
 847     emitLoad(src, regT1, regT0);
 848 
 849     addSlowCase(branchIfNotCell(regT1));
 850     addSlowCase(branchIfNotString(regT0));
 851 
 852     if (src != dst)
 853         emitStore(dst, regT1, regT0);
 854 }
 855 
 856 void JIT::emit_op_to_object(const Instruction* currentInstruction)
 857 {
 858     auto bytecode = currentInstruction-&gt;as&lt;OpToObject&gt;();
 859     int dst = bytecode.m_dst.offset();
 860     int src = bytecode.m_operand.offset();
 861 
 862     emitLoad(src, regT1, regT0);
 863 
 864     addSlowCase(branchIfNotCell(regT1));
 865     addSlowCase(branchIfNotObject(regT0));
 866 
 867     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 868     if (src != dst)
 869         emitStore(dst, regT1, regT0);
 870 }
 871 
 872 void JIT::emit_op_catch(const Instruction* currentInstruction)
 873 {
 874     auto bytecode = currentInstruction-&gt;as&lt;OpCatch&gt;();
 875 
<a name="6" id="anc6"></a><span class="line-modified"> 876     restoreCalleeSavesFromEntryFrameCalleeSavesBuffer(vm().topEntryFrame);</span>
 877 
 878     move(TrustedImmPtr(m_vm), regT3);
 879     // operationThrow returns the callFrame for the handler.
 880     load32(Address(regT3, VM::callFrameForCatchOffset()), callFrameRegister);
 881     storePtr(TrustedImmPtr(nullptr), Address(regT3, VM::callFrameForCatchOffset()));
 882 
 883     addPtr(TrustedImm32(stackPointerOffsetFor(codeBlock()) * sizeof(Register)), callFrameRegister, stackPointerRegister);
 884 
 885     callOperationNoExceptionCheck(operationCheckIfExceptionIsUncatchableAndNotifyProfiler);
 886     Jump isCatchableException = branchTest32(Zero, returnValueGPR);
<a name="7" id="anc7"></a><span class="line-modified"> 887     jumpToExceptionHandler(vm());</span>
 888     isCatchableException.link(this);
 889 
 890     move(TrustedImmPtr(m_vm), regT3);
 891 
 892     // Now store the exception returned by operationThrow.
 893     load32(Address(regT3, VM::exceptionOffset()), regT2);
 894     move(TrustedImm32(JSValue::CellTag), regT1);
 895 
 896     store32(TrustedImm32(0), Address(regT3, VM::exceptionOffset()));
 897 
 898     unsigned exception = bytecode.m_exception.offset();
 899     emitStore(exception, regT1, regT2);
 900 
 901     load32(Address(regT2, Exception::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
 902     load32(Address(regT2, Exception::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
 903 
 904     unsigned thrownValue = bytecode.m_thrownValue.offset();
 905     emitStore(thrownValue, regT1, regT0);
 906 
 907 #if ENABLE(DFG_JIT)
 908     // FIXME: consider inline caching the process of doing OSR entry, including
 909     // argument type proofs, storing locals to the buffer, etc
 910     // https://bugs.webkit.org/show_bug.cgi?id=175598
 911 
 912     auto&amp; metadata = bytecode.metadata(m_codeBlock);
 913     ValueProfileAndOperandBuffer* buffer = metadata.m_buffer;
 914     if (buffer || !shouldEmitProfiling())
 915         callOperation(operationTryOSREnterAtCatch, m_bytecodeOffset);
 916     else
 917         callOperation(operationTryOSREnterAtCatchAndValueProfile, m_bytecodeOffset);
 918     auto skipOSREntry = branchTestPtr(Zero, returnValueGPR);
 919     emitRestoreCalleeSaves();
<a name="8" id="anc8"></a><span class="line-modified"> 920     farJump(returnValueGPR, NoPtrTag);</span>
 921     skipOSREntry.link(this);
 922     if (buffer &amp;&amp; shouldEmitProfiling()) {
 923         buffer-&gt;forEach([&amp;] (ValueProfileAndOperand&amp; profile) {
 924             JSValueRegs regs(regT1, regT0);
 925             emitGetVirtualRegister(profile.m_operand, regs);
<a name="9" id="anc9"></a><span class="line-modified"> 926             emitValueProfilingSite(static_cast&lt;ValueProfile&amp;&gt;(profile));</span>
 927         });
 928     }
 929 #endif // ENABLE(DFG_JIT)
 930 }
 931 
 932 void JIT::emit_op_identity_with_profile(const Instruction*)
 933 {
 934     // We don&#39;t need to do anything here...
 935 }
 936 
 937 void JIT::emit_op_get_parent_scope(const Instruction* currentInstruction)
 938 {
 939     auto bytecode = currentInstruction-&gt;as&lt;OpGetParentScope&gt;();
 940     int currentScope = bytecode.m_scope.offset();
 941     emitLoadPayload(currentScope, regT0);
 942     loadPtr(Address(regT0, JSScope::offsetOfNext()), regT0);
 943     emitStoreCell(bytecode.m_dst.offset(), regT0);
 944 }
 945 
 946 void JIT::emit_op_switch_imm(const Instruction* currentInstruction)
 947 {
 948     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchImm&gt;();
 949     size_t tableIndex = bytecode.m_tableIndex;
 950     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
 951     unsigned scrutinee = bytecode.m_scrutinee.offset();
 952 
 953     // create jump table for switch destinations, track this switch statement.
 954     SimpleJumpTable* jumpTable = &amp;m_codeBlock-&gt;switchJumpTable(tableIndex);
 955     m_switches.append(SwitchRecord(jumpTable, m_bytecodeOffset, defaultOffset, SwitchRecord::Immediate));
 956     jumpTable-&gt;ensureCTITable();
 957 
 958     emitLoad(scrutinee, regT1, regT0);
 959     callOperation(operationSwitchImmWithUnknownKeyType, JSValueRegs(regT1, regT0), tableIndex);
<a name="10" id="anc10"></a><span class="line-modified"> 960     farJump(returnValueGPR, NoPtrTag);</span>
 961 }
 962 
 963 void JIT::emit_op_switch_char(const Instruction* currentInstruction)
 964 {
 965     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchChar&gt;();
 966     size_t tableIndex = bytecode.m_tableIndex;
 967     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
 968     unsigned scrutinee = bytecode.m_scrutinee.offset();
 969 
 970     // create jump table for switch destinations, track this switch statement.
 971     SimpleJumpTable* jumpTable = &amp;m_codeBlock-&gt;switchJumpTable(tableIndex);
 972     m_switches.append(SwitchRecord(jumpTable, m_bytecodeOffset, defaultOffset, SwitchRecord::Character));
 973     jumpTable-&gt;ensureCTITable();
 974 
 975     emitLoad(scrutinee, regT1, regT0);
 976     callOperation(operationSwitchCharWithUnknownKeyType, JSValueRegs(regT1, regT0), tableIndex);
<a name="11" id="anc11"></a><span class="line-modified"> 977     farJump(returnValueGPR, NoPtrTag);</span>
 978 }
 979 
 980 void JIT::emit_op_switch_string(const Instruction* currentInstruction)
 981 {
 982     auto bytecode = currentInstruction-&gt;as&lt;OpSwitchString&gt;();
 983     size_t tableIndex = bytecode.m_tableIndex;
 984     unsigned defaultOffset = jumpTarget(currentInstruction, bytecode.m_defaultOffset);
 985     unsigned scrutinee = bytecode.m_scrutinee.offset();
 986 
 987     // create jump table for switch destinations, track this switch statement.
 988     StringJumpTable* jumpTable = &amp;m_codeBlock-&gt;stringSwitchJumpTable(tableIndex);
 989     m_switches.append(SwitchRecord(jumpTable, m_bytecodeOffset, defaultOffset));
 990 
 991     emitLoad(scrutinee, regT1, regT0);
 992     callOperation(operationSwitchStringWithUnknownKeyType, JSValueRegs(regT1, regT0), tableIndex);
<a name="12" id="anc12"></a><span class="line-modified"> 993     farJump(returnValueGPR, NoPtrTag);</span>
 994 }
 995 
 996 void JIT::emit_op_debug(const Instruction* currentInstruction)
 997 {
 998     auto bytecode = currentInstruction-&gt;as&lt;OpDebug&gt;();
 999     load32(codeBlock()-&gt;debuggerRequestsAddress(), regT0);
1000     Jump noDebuggerRequests = branchTest32(Zero, regT0);
1001     callOperation(operationDebug, static_cast&lt;int&gt;(bytecode.m_debugHookType));
1002     noDebuggerRequests.link(this);
1003 }
1004 
<a name="13" id="anc13"></a>














1005 void JIT::emit_op_get_scope(const Instruction* currentInstruction)
1006 {
1007     auto bytecode = currentInstruction-&gt;as&lt;OpGetScope&gt;();
1008     int dst = bytecode.m_dst.offset();
1009     emitGetFromCallFrameHeaderPtr(CallFrameSlot::callee, regT0);
1010     loadPtr(Address(regT0, JSFunction::offsetOfScopeChain()), regT0);
1011     emitStoreCell(dst, regT0);
1012 }
1013 
1014 void JIT::emit_op_create_this(const Instruction* currentInstruction)
1015 {
1016     auto bytecode = currentInstruction-&gt;as&lt;OpCreateThis&gt;();
1017     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1018     int callee = bytecode.m_callee.offset();
1019     WriteBarrierBase&lt;JSCell&gt;* cachedFunction = &amp;metadata.m_cachedCallee;
1020     RegisterID calleeReg = regT0;
1021     RegisterID rareDataReg = regT4;
1022     RegisterID resultReg = regT0;
1023     RegisterID allocatorReg = regT1;
1024     RegisterID structureReg = regT2;
1025     RegisterID cachedFunctionReg = regT4;
1026     RegisterID scratchReg = regT3;
1027 
1028     emitLoadPayload(callee, calleeReg);
1029     addSlowCase(branchIfNotFunction(calleeReg));
1030     loadPtr(Address(calleeReg, JSFunction::offsetOfRareData()), rareDataReg);
1031     addSlowCase(branchTestPtr(Zero, rareDataReg));
<a name="14" id="anc14"></a><span class="line-modified">1032     load32(Address(rareDataReg, FunctionRareData::offsetOfObjectAllocationProfile() + ObjectAllocationProfileWithPrototype::offsetOfAllocator()), allocatorReg);</span>
<span class="line-modified">1033     loadPtr(Address(rareDataReg, FunctionRareData::offsetOfObjectAllocationProfile() + ObjectAllocationProfileWithPrototype::offsetOfStructure()), structureReg);</span>
1034 
1035     loadPtr(cachedFunction, cachedFunctionReg);
1036     Jump hasSeenMultipleCallees = branchPtr(Equal, cachedFunctionReg, TrustedImmPtr(JSCell::seenMultipleCalleeObjects()));
1037     addSlowCase(branchPtr(NotEqual, calleeReg, cachedFunctionReg));
1038     hasSeenMultipleCallees.link(this);
1039 
1040     JumpList slowCases;
1041     auto butterfly = TrustedImmPtr(nullptr);
1042     emitAllocateJSObject(resultReg, JITAllocator::variable(), allocatorReg, structureReg, butterfly, scratchReg, slowCases);
<a name="15" id="anc15"></a><span class="line-modified">1043     load8(Address(structureReg, Structure::inlineCapacityOffset()), scratchReg);</span>


1044     emitInitializeInlineStorage(resultReg, scratchReg);
1045     addSlowCase(slowCases);
1046     emitStoreCell(bytecode.m_dst.offset(), resultReg);
1047 }
1048 
1049 void JIT::emit_op_to_this(const Instruction* currentInstruction)
1050 {
1051     auto bytecode = currentInstruction-&gt;as&lt;OpToThis&gt;();
1052     auto&amp; metadata = bytecode.metadata(m_codeBlock);
<a name="16" id="anc16"></a><span class="line-modified">1053     StructureID* cachedStructureID = &amp;metadata.m_cachedStructureID;</span>
1054     int thisRegister = bytecode.m_srcDst.offset();
1055 
1056     emitLoad(thisRegister, regT3, regT2);
1057 
1058     addSlowCase(branchIfNotCell(regT3));
1059     addSlowCase(branchIfNotType(regT2, FinalObjectType));
1060     loadPtr(Address(regT2, JSCell::structureIDOffset()), regT0);
<a name="17" id="anc17"></a><span class="line-modified">1061     load32(cachedStructureID, regT2);</span>
1062     addSlowCase(branchPtr(NotEqual, regT0, regT2));
1063 }
1064 
1065 void JIT::emit_op_check_tdz(const Instruction* currentInstruction)
1066 {
1067     auto bytecode = currentInstruction-&gt;as&lt;OpCheckTdz&gt;();
1068     emitLoadTag(bytecode.m_targetVirtualRegister.offset(), regT0);
1069     addSlowCase(branchIfEmpty(regT0));
1070 }
1071 
1072 void JIT::emit_op_has_structure_property(const Instruction* currentInstruction)
1073 {
1074     auto bytecode = currentInstruction-&gt;as&lt;OpHasStructureProperty&gt;();
1075     int dst = bytecode.m_dst.offset();
1076     int base = bytecode.m_base.offset();
1077     int enumerator = bytecode.m_enumerator.offset();
1078 
1079     emitLoadPayload(base, regT0);
1080     emitJumpSlowCaseIfNotJSCell(base);
1081 
1082     emitLoadPayload(enumerator, regT1);
1083 
1084     load32(Address(regT0, JSCell::structureIDOffset()), regT0);
1085     addSlowCase(branch32(NotEqual, regT0, Address(regT1, JSPropertyNameEnumerator::cachedStructureIDOffset())));
1086 
1087     move(TrustedImm32(1), regT0);
1088     emitStoreBool(dst, regT0);
1089 }
1090 
1091 void JIT::privateCompileHasIndexedProperty(ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)
1092 {
1093     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1094 
1095     PatchableJump badType;
1096 
1097     // FIXME: Add support for other types like TypedArrays and Arguments.
1098     // See https://bugs.webkit.org/show_bug.cgi?id=135033 and https://bugs.webkit.org/show_bug.cgi?id=135034.
1099     JumpList slowCases = emitLoadForArrayMode(currentInstruction, arrayMode, badType);
1100     move(TrustedImm32(1), regT0);
1101     Jump done = jump();
1102 
1103     LinkBuffer patchBuffer(*this, m_codeBlock);
1104 
1105     patchBuffer.link(badType, byValInfo-&gt;slowPathTarget);
1106     patchBuffer.link(slowCases, byValInfo-&gt;slowPathTarget);
1107 
1108     patchBuffer.link(done, byValInfo-&gt;badTypeDoneTarget);
1109 
1110     byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1111         m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1112         &quot;Baseline has_indexed_property stub for %s, return point %p&quot;, toCString(*m_codeBlock).data(), returnAddress.value());
1113 
1114     MacroAssembler::repatchJump(byValInfo-&gt;badTypeJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));
1115     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(operationHasIndexedPropertyGeneric));
1116 }
1117 
1118 void JIT::emit_op_has_indexed_property(const Instruction* currentInstruction)
1119 {
1120     auto bytecode = currentInstruction-&gt;as&lt;OpHasIndexedProperty&gt;();
1121     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1122     int dst = bytecode.m_dst.offset();
1123     int base = bytecode.m_base.offset();
1124     int property = bytecode.m_property.offset();
1125     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
1126     ByValInfo* byValInfo = m_codeBlock-&gt;addByValInfo();
1127 
1128     emitLoadPayload(base, regT0);
1129     emitJumpSlowCaseIfNotJSCell(base);
1130 
<a name="18" id="anc18"></a><span class="line-modified">1131     emitLoad(property, regT3, regT1);</span>
<span class="line-added">1132     addSlowCase(branchIfNotInt32(regT3));</span>
1133 
1134     // This is technically incorrect - we&#39;re zero-extending an int32. On the hot path this doesn&#39;t matter.
1135     // We check the value as if it was a uint32 against the m_vectorLength - which will always fail if
1136     // number was signed since m_vectorLength is always less than intmax (since the total allocation
1137     // size is always less than 4Gb). As such zero extending will have been correct (and extending the value
1138     // to 64-bits is necessary since it&#39;s used in the address calculation. We zero extend rather than sign
1139     // extending since it makes it easier to re-tag the value in the slow case.
1140     zeroExtend32ToPtr(regT1, regT1);
1141 
1142     emitArrayProfilingSiteWithCell(regT0, regT2, profile);
1143     and32(TrustedImm32(IndexingShapeMask), regT2);
1144 
1145     JITArrayMode mode = chooseArrayMode(profile);
1146     PatchableJump badType;
1147 
1148     // FIXME: Add support for other types like TypedArrays and Arguments.
1149     // See https://bugs.webkit.org/show_bug.cgi?id=135033 and https://bugs.webkit.org/show_bug.cgi?id=135034.
1150     JumpList slowCases = emitLoadForArrayMode(currentInstruction, mode, badType);
1151     move(TrustedImm32(1), regT0);
1152 
1153     addSlowCase(badType);
1154     addSlowCase(slowCases);
1155 
1156     Label done = label();
1157 
1158     emitStoreBool(dst, regT0);
1159 
1160     Label nextHotPath = label();
1161 
1162     m_byValCompilationInfo.append(ByValCompilationInfo(byValInfo, m_bytecodeOffset, PatchableJump(), badType, mode, profile, done, nextHotPath));
1163 }
1164 
1165 void JIT::emitSlow_op_has_indexed_property(const Instruction* currentInstruction, Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
1166 {
1167     linkAllSlowCases(iter);
1168 
1169     auto bytecode = currentInstruction-&gt;as&lt;OpHasIndexedProperty&gt;();
1170     int dst = bytecode.m_dst.offset();
1171     int base = bytecode.m_base.offset();
1172     int property = bytecode.m_property.offset();
1173     ByValInfo* byValInfo = m_byValCompilationInfo[m_byValInstructionIndex].byValInfo;
1174 
1175     Label slowPath = label();
1176 
1177     emitLoad(base, regT1, regT0);
1178     emitLoad(property, regT3, regT2);
1179     Call call = callOperation(operationHasIndexedPropertyDefault, dst, JSValueRegs(regT1, regT0), JSValueRegs(regT3, regT2), byValInfo);
1180 
1181     m_byValCompilationInfo[m_byValInstructionIndex].slowPathTarget = slowPath;
1182     m_byValCompilationInfo[m_byValInstructionIndex].returnAddress = call;
1183     m_byValInstructionIndex++;
1184 }
1185 
1186 void JIT::emit_op_get_direct_pname(const Instruction* currentInstruction)
1187 {
1188     auto bytecode = currentInstruction-&gt;as&lt;OpGetDirectPname&gt;();
1189     int dst = bytecode.m_dst.offset();
1190     int base = bytecode.m_base.offset();
1191     int index = bytecode.m_index.offset();
1192     int enumerator = bytecode.m_enumerator.offset();
1193 
1194     // Check that base is a cell
1195     emitLoadPayload(base, regT0);
1196     emitJumpSlowCaseIfNotJSCell(base);
1197 
1198     // Check the structure
1199     emitLoadPayload(enumerator, regT1);
1200     load32(Address(regT0, JSCell::structureIDOffset()), regT2);
1201     addSlowCase(branch32(NotEqual, regT2, Address(regT1, JSPropertyNameEnumerator::cachedStructureIDOffset())));
1202 
1203     // Compute the offset
1204     emitLoadPayload(index, regT2);
1205     // If index is less than the enumerator&#39;s cached inline storage, then it&#39;s an inline access
1206     Jump outOfLineAccess = branch32(AboveOrEqual, regT2, Address(regT1, JSPropertyNameEnumerator::cachedInlineCapacityOffset()));
1207     addPtr(TrustedImm32(JSObject::offsetOfInlineStorage()), regT0);
1208     load32(BaseIndex(regT0, regT2, TimesEight, OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
1209     load32(BaseIndex(regT0, regT2, TimesEight, OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
1210 
1211     Jump done = jump();
1212 
1213     // Otherwise it&#39;s out of line
1214     outOfLineAccess.link(this);
1215     loadPtr(Address(regT0, JSObject::butterflyOffset()), regT0);
1216     sub32(Address(regT1, JSPropertyNameEnumerator::cachedInlineCapacityOffset()), regT2);
1217     neg32(regT2);
1218     int32_t offsetOfFirstProperty = static_cast&lt;int32_t&gt;(offsetInButterfly(firstOutOfLineOffset)) * sizeof(EncodedJSValue);
1219     load32(BaseIndex(regT0, regT2, TimesEight, offsetOfFirstProperty + OBJECT_OFFSETOF(JSValue, u.asBits.tag)), regT1);
1220     load32(BaseIndex(regT0, regT2, TimesEight, offsetOfFirstProperty + OBJECT_OFFSETOF(JSValue, u.asBits.payload)), regT0);
1221 
1222     done.link(this);
1223     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
1224     emitStore(dst, regT1, regT0);
1225 }
1226 
1227 void JIT::emit_op_enumerator_structure_pname(const Instruction* currentInstruction)
1228 {
1229     auto bytecode = currentInstruction-&gt;as&lt;OpEnumeratorStructurePname&gt;();
1230     int dst = bytecode.m_dst.offset();
1231     int enumerator = bytecode.m_enumerator.offset();
1232     int index = bytecode.m_index.offset();
1233 
1234     emitLoadPayload(index, regT0);
1235     emitLoadPayload(enumerator, regT1);
1236     Jump inBounds = branch32(Below, regT0, Address(regT1, JSPropertyNameEnumerator::endStructurePropertyIndexOffset()));
1237 
1238     move(TrustedImm32(JSValue::NullTag), regT2);
1239     move(TrustedImm32(0), regT0);
1240 
1241     Jump done = jump();
1242     inBounds.link(this);
1243 
1244     loadPtr(Address(regT1, JSPropertyNameEnumerator::cachedPropertyNamesVectorOffset()), regT1);
1245     loadPtr(BaseIndex(regT1, regT0, timesPtr()), regT0);
1246     move(TrustedImm32(JSValue::CellTag), regT2);
1247 
1248     done.link(this);
1249     emitStore(dst, regT2, regT0);
1250 }
1251 
1252 void JIT::emit_op_enumerator_generic_pname(const Instruction* currentInstruction)
1253 {
1254     auto bytecode = currentInstruction-&gt;as&lt;OpEnumeratorGenericPname&gt;();
1255     int dst = bytecode.m_dst.offset();
1256     int enumerator = bytecode.m_enumerator.offset();
1257     int index = bytecode.m_index.offset();
1258 
1259     emitLoadPayload(index, regT0);
1260     emitLoadPayload(enumerator, regT1);
1261     Jump inBounds = branch32(Below, regT0, Address(regT1, JSPropertyNameEnumerator::endGenericPropertyIndexOffset()));
1262 
1263     move(TrustedImm32(JSValue::NullTag), regT2);
1264     move(TrustedImm32(0), regT0);
1265 
1266     Jump done = jump();
1267     inBounds.link(this);
1268 
1269     loadPtr(Address(regT1, JSPropertyNameEnumerator::cachedPropertyNamesVectorOffset()), regT1);
1270     loadPtr(BaseIndex(regT1, regT0, timesPtr()), regT0);
1271     move(TrustedImm32(JSValue::CellTag), regT2);
1272 
1273     done.link(this);
1274     emitStore(dst, regT2, regT0);
1275 }
1276 
1277 void JIT::emit_op_profile_type(const Instruction* currentInstruction)
1278 {
1279     auto bytecode = currentInstruction-&gt;as&lt;OpProfileType&gt;();
1280     auto&amp; metadata = bytecode.metadata(m_codeBlock);
1281     TypeLocation* cachedTypeLocation = metadata.m_typeLocation;
1282     int valueToProfile = bytecode.m_targetVirtualRegister.offset();
1283 
1284     // Load payload in T0. Load tag in T3.
1285     emitLoadPayload(valueToProfile, regT0);
1286     emitLoadTag(valueToProfile, regT3);
1287 
1288     JumpList jumpToEnd;
1289 
1290     jumpToEnd.append(branchIfEmpty(regT3));
1291 
1292     // Compile in a predictive type check, if possible, to see if we can skip writing to the log.
1293     // These typechecks are inlined to match those of the 32-bit JSValue type checks.
1294     if (cachedTypeLocation-&gt;m_lastSeenType == TypeUndefined)
1295         jumpToEnd.append(branchIfUndefined(regT3));
1296     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeNull)
1297         jumpToEnd.append(branchIfNull(regT3));
1298     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeBoolean)
1299         jumpToEnd.append(branchIfBoolean(regT3, InvalidGPRReg));
1300     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeAnyInt)
1301         jumpToEnd.append(branchIfInt32(regT3));
1302     else if (cachedTypeLocation-&gt;m_lastSeenType == TypeNumber) {
1303         jumpToEnd.append(branchIfNumber(JSValueRegs(regT3, regT0), regT1));
1304     } else if (cachedTypeLocation-&gt;m_lastSeenType == TypeString) {
1305         Jump isNotCell = branchIfNotCell(regT3);
1306         jumpToEnd.append(branchIfString(regT0));
1307         isNotCell.link(this);
1308     }
1309 
1310     // Load the type profiling log into T2.
1311     TypeProfilerLog* cachedTypeProfilerLog = m_vm-&gt;typeProfilerLog();
1312     move(TrustedImmPtr(cachedTypeProfilerLog), regT2);
1313 
1314     // Load the next log entry into T1.
1315     loadPtr(Address(regT2, TypeProfilerLog::currentLogEntryOffset()), regT1);
1316 
1317     // Store the JSValue onto the log entry.
1318     store32(regT0, Address(regT1, TypeProfilerLog::LogEntry::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.payload)));
1319     store32(regT3, Address(regT1, TypeProfilerLog::LogEntry::valueOffset() + OBJECT_OFFSETOF(JSValue, u.asBits.tag)));
1320 
1321     // Store the structureID of the cell if argument is a cell, otherwise, store 0 on the log entry.
1322     Jump notCell = branchIfNotCell(regT3);
1323     load32(Address(regT0, JSCell::structureIDOffset()), regT0);
1324     store32(regT0, Address(regT1, TypeProfilerLog::LogEntry::structureIDOffset()));
1325     Jump skipNotCell = jump();
1326     notCell.link(this);
1327     store32(TrustedImm32(0), Address(regT1, TypeProfilerLog::LogEntry::structureIDOffset()));
1328     skipNotCell.link(this);
1329 
1330     // Store the typeLocation on the log entry.
1331     move(TrustedImmPtr(cachedTypeLocation), regT0);
1332     store32(regT0, Address(regT1, TypeProfilerLog::LogEntry::locationOffset()));
1333 
1334     // Increment the current log entry.
1335     addPtr(TrustedImm32(sizeof(TypeProfilerLog::LogEntry)), regT1);
1336     store32(regT1, Address(regT2, TypeProfilerLog::currentLogEntryOffset()));
1337     jumpToEnd.append(branchPtr(NotEqual, regT1, TrustedImmPtr(cachedTypeProfilerLog-&gt;logEndPtr())));
1338     // Clear the log if we&#39;re at the end of the log.
1339     callOperation(operationProcessTypeProfilerLog);
1340 
1341     jumpToEnd.link(this);
1342 }
1343 
1344 void JIT::emit_op_log_shadow_chicken_prologue(const Instruction* currentInstruction)
1345 {
<a name="19" id="anc19"></a><span class="line-modified">1346     RELEASE_ASSERT(vm().shadowChicken());</span>
1347     updateTopCallFrame();
1348     static_assert(nonArgGPR0 != regT0 &amp;&amp; nonArgGPR0 != regT2, &quot;we will have problems if this is true.&quot;);
1349     auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenPrologue&gt;();
1350     GPRReg shadowPacketReg = regT0;
1351     GPRReg scratch1Reg = nonArgGPR0; // This must be a non-argument register.
1352     GPRReg scratch2Reg = regT2;
<a name="20" id="anc20"></a><span class="line-modified">1353     ensureShadowChickenPacket(vm(), shadowPacketReg, scratch1Reg, scratch2Reg);</span>
1354 
1355     scratch1Reg = regT4;
1356     emitLoadPayload(bytecode.m_scope.offset(), regT3);
1357     logShadowChickenProloguePacket(shadowPacketReg, scratch1Reg, regT3);
1358 }
1359 
1360 void JIT::emit_op_log_shadow_chicken_tail(const Instruction* currentInstruction)
1361 {
<a name="21" id="anc21"></a><span class="line-modified">1362     RELEASE_ASSERT(vm().shadowChicken());</span>
1363     updateTopCallFrame();
1364     static_assert(nonArgGPR0 != regT0 &amp;&amp; nonArgGPR0 != regT2, &quot;we will have problems if this is true.&quot;);
1365     auto bytecode = currentInstruction-&gt;as&lt;OpLogShadowChickenTail&gt;();
1366     GPRReg shadowPacketReg = regT0;
1367     GPRReg scratch1Reg = nonArgGPR0; // This must be a non-argument register.
1368     GPRReg scratch2Reg = regT2;
<a name="22" id="anc22"></a><span class="line-modified">1369     ensureShadowChickenPacket(vm(), shadowPacketReg, scratch1Reg, scratch2Reg);</span>
1370     emitLoadPayload(bytecode.m_thisValue.offset(), regT2);
1371     emitLoadTag(bytecode.m_thisValue.offset(), regT1);
1372     JSValueRegs thisRegs(regT1, regT2);
1373     emitLoadPayload(bytecode.m_scope.offset(), regT3);
1374     logShadowChickenTailPacket(shadowPacketReg, thisRegs, regT3, m_codeBlock, CallSiteIndex(currentInstruction));
1375 }
1376 
1377 } // namespace JSC
1378 
1379 #endif // USE(JSVALUE32_64)
1380 #endif // ENABLE(JIT)
<a name="23" id="anc23"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="23" type="hidden" />
</body>
</html>