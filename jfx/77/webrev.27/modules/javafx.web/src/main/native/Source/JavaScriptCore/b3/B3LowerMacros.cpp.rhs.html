<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/b3/B3LowerMacros.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2015-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;B3LowerMacros.h&quot;
 28 
 29 #if ENABLE(B3_JIT)
 30 
 31 #include &quot;AllowMacroScratchRegisterUsage.h&quot;
 32 #include &quot;B3AtomicValue.h&quot;
 33 #include &quot;B3BasicBlockInlines.h&quot;
 34 #include &quot;B3BlockInsertionSet.h&quot;
 35 #include &quot;B3CCallValue.h&quot;
 36 #include &quot;B3CaseCollectionInlines.h&quot;
 37 #include &quot;B3ConstPtrValue.h&quot;
 38 #include &quot;B3FenceValue.h&quot;
 39 #include &quot;B3InsertionSetInlines.h&quot;
 40 #include &quot;B3MemoryValueInlines.h&quot;
 41 #include &quot;B3PatchpointValue.h&quot;
 42 #include &quot;B3PhaseScope.h&quot;
 43 #include &quot;B3ProcedureInlines.h&quot;
 44 #include &quot;B3StackmapGenerationParams.h&quot;
 45 #include &quot;B3SwitchValue.h&quot;
 46 #include &quot;B3UpsilonValue.h&quot;
 47 #include &quot;B3UseCounts.h&quot;
 48 #include &quot;B3ValueInlines.h&quot;
 49 #include &quot;CCallHelpers.h&quot;
 50 #include &quot;LinkBuffer.h&quot;
 51 #include &lt;cmath&gt;
 52 #include &lt;wtf/BitVector.h&gt;
 53 
 54 namespace JSC { namespace B3 {
 55 
 56 namespace {
 57 
 58 class LowerMacros {
 59 public:
 60     LowerMacros(Procedure&amp; proc)
 61         : m_proc(proc)
 62         , m_blockInsertionSet(proc)
 63         , m_insertionSet(proc)
 64         , m_useCounts(proc)
 65     {
 66     }
 67 
 68     bool run()
 69     {
 70         RELEASE_ASSERT(!m_proc.hasQuirks());
 71 
 72         for (BasicBlock* block : m_proc) {
 73             m_block = block;
 74             processCurrentBlock();
 75         }
 76         m_changed |= m_blockInsertionSet.execute();
 77         if (m_changed) {
 78             m_proc.resetReachability();
 79             m_proc.invalidateCFG();
 80         }
 81 
 82         // This indicates that we&#39;ve
 83         m_proc.setHasQuirks(true);
 84 
 85         return m_changed;
 86     }
 87 
 88 private:
 89     void processCurrentBlock()
 90     {
 91         for (m_index = 0; m_index &lt; m_block-&gt;size(); ++m_index) {
 92             m_value = m_block-&gt;at(m_index);
 93             m_origin = m_value-&gt;origin();
 94             switch (m_value-&gt;opcode()) {
 95             case Mod: {
 96                 if (m_value-&gt;isChill()) {
 97                     if (isARM64()) {
 98                         BasicBlock* before = m_blockInsertionSet.splitForward(m_block, m_index, &amp;m_insertionSet);
 99                         BasicBlock* zeroDenCase = m_blockInsertionSet.insertBefore(m_block);
100                         BasicBlock* normalModCase = m_blockInsertionSet.insertBefore(m_block);
101 
102                         before-&gt;replaceLastWithNew&lt;Value&gt;(m_proc, Branch, m_origin, m_value-&gt;child(1));
103                         before-&gt;setSuccessors(
104                             FrequentedBlock(normalModCase, FrequencyClass::Normal),
105                             FrequentedBlock(zeroDenCase, FrequencyClass::Rare));
106 
107                         Value* divResult = normalModCase-&gt;appendNew&lt;Value&gt;(m_proc, chill(Div), m_origin, m_value-&gt;child(0), m_value-&gt;child(1));
108                         Value* multipliedBack = normalModCase-&gt;appendNew&lt;Value&gt;(m_proc, Mul, m_origin, divResult, m_value-&gt;child(1));
109                         Value* result = normalModCase-&gt;appendNew&lt;Value&gt;(m_proc, Sub, m_origin, m_value-&gt;child(0), multipliedBack);
110                         UpsilonValue* normalResult = normalModCase-&gt;appendNew&lt;UpsilonValue&gt;(m_proc, m_origin, result);
111                         normalModCase-&gt;appendNew&lt;Value&gt;(m_proc, Jump, m_origin);
112                         normalModCase-&gt;setSuccessors(FrequentedBlock(m_block));
113 
114                         UpsilonValue* zeroResult = zeroDenCase-&gt;appendNew&lt;UpsilonValue&gt;(
115                             m_proc, m_origin,
116                             zeroDenCase-&gt;appendIntConstant(m_proc, m_value, 0));
117                         zeroDenCase-&gt;appendNew&lt;Value&gt;(m_proc, Jump, m_origin);
118                         zeroDenCase-&gt;setSuccessors(FrequentedBlock(m_block));
119 
120                         Value* phi = m_insertionSet.insert&lt;Value&gt;(m_index, Phi, m_value-&gt;type(), m_origin);
121                         normalResult-&gt;setPhi(phi);
122                         zeroResult-&gt;setPhi(phi);
123                         m_value-&gt;replaceWithIdentity(phi);
124                         before-&gt;updatePredecessorsAfter();
125                         m_changed = true;
126                     } else
127                         makeDivisionChill(Mod);
128                     break;
129                 }
130 
131                 auto* fmodDouble = tagCFunctionPtr&lt;double (*)(double, double)&gt;(fmod, B3CCallPtrTag);
132                 if (m_value-&gt;type() == Double) {
133                     Value* functionAddress = m_insertionSet.insert&lt;ConstPtrValue&gt;(m_index, m_origin, fmodDouble);
134                     Value* result = m_insertionSet.insert&lt;CCallValue&gt;(m_index, Double, m_origin,
135                         Effects::none(),
136                         functionAddress,
137                         m_value-&gt;child(0),
138                         m_value-&gt;child(1));
139                     m_value-&gt;replaceWithIdentity(result);
140                     m_changed = true;
141                 } else if (m_value-&gt;type() == Float) {
142                     Value* numeratorAsDouble = m_insertionSet.insert&lt;Value&gt;(m_index, FloatToDouble, m_origin, m_value-&gt;child(0));
143                     Value* denominatorAsDouble = m_insertionSet.insert&lt;Value&gt;(m_index, FloatToDouble, m_origin, m_value-&gt;child(1));
144                     Value* functionAddress = m_insertionSet.insert&lt;ConstPtrValue&gt;(m_index, m_origin, fmodDouble);
145                     Value* doubleMod = m_insertionSet.insert&lt;CCallValue&gt;(m_index, Double, m_origin,
146                         Effects::none(),
147                         functionAddress,
148                         numeratorAsDouble,
149                         denominatorAsDouble);
150                     Value* result = m_insertionSet.insert&lt;Value&gt;(m_index, DoubleToFloat, m_origin, doubleMod);
151                     m_value-&gt;replaceWithIdentity(result);
152                     m_changed = true;
153                 } else if (isARM64()) {
154                     Value* divResult = m_insertionSet.insert&lt;Value&gt;(m_index, chill(Div), m_origin, m_value-&gt;child(0), m_value-&gt;child(1));
155                     Value* multipliedBack = m_insertionSet.insert&lt;Value&gt;(m_index, Mul, m_origin, divResult, m_value-&gt;child(1));
156                     Value* result = m_insertionSet.insert&lt;Value&gt;(m_index, Sub, m_origin, m_value-&gt;child(0), multipliedBack);
157                     m_value-&gt;replaceWithIdentity(result);
158                     m_changed = true;
159                 }
160                 break;
161             }
162 
163             case UMod: {
164                 if (isARM64()) {
165                     Value* divResult = m_insertionSet.insert&lt;Value&gt;(m_index, UDiv, m_origin, m_value-&gt;child(0), m_value-&gt;child(1));
166                     Value* multipliedBack = m_insertionSet.insert&lt;Value&gt;(m_index, Mul, m_origin, divResult, m_value-&gt;child(1));
167                     Value* result = m_insertionSet.insert&lt;Value&gt;(m_index, Sub, m_origin, m_value-&gt;child(0), multipliedBack);
168                     m_value-&gt;replaceWithIdentity(result);
169                     m_changed = true;
170                 }
171                 break;
172             }
173 
174             case Div: {
175                 if (m_value-&gt;isChill())
176                     makeDivisionChill(Div);
177                 break;
178             }
179 
<a name="1" id="anc1"></a><span class="line-added">180             case CheckMul: {</span>
<span class="line-added">181                 if (isARM64() &amp;&amp; m_value-&gt;child(0)-&gt;type() == Int32) {</span>
<span class="line-added">182                     CheckValue* checkMul = m_value-&gt;as&lt;CheckValue&gt;();</span>
<span class="line-added">183 </span>
<span class="line-added">184                     Value* left = m_insertionSet.insert&lt;Value&gt;(m_index, SExt32, m_origin, m_value-&gt;child(0));</span>
<span class="line-added">185                     Value* right = m_insertionSet.insert&lt;Value&gt;(m_index, SExt32, m_origin, m_value-&gt;child(1));</span>
<span class="line-added">186                     Value* mulResult = m_insertionSet.insert&lt;Value&gt;(m_index, Mul, m_origin, left, right);</span>
<span class="line-added">187                     Value* mulResult32 = m_insertionSet.insert&lt;Value&gt;(m_index, Trunc, m_origin, mulResult);</span>
<span class="line-added">188                     Value* upperResult = m_insertionSet.insert&lt;Value&gt;(m_index, Trunc, m_origin,</span>
<span class="line-added">189                         m_insertionSet.insert&lt;Value&gt;(m_index, SShr, m_origin, mulResult, m_insertionSet.insert&lt;Const32Value&gt;(m_index, m_origin, 32)));</span>
<span class="line-added">190                     Value* signBit = m_insertionSet.insert&lt;Value&gt;(m_index, SShr, m_origin,</span>
<span class="line-added">191                         mulResult32,</span>
<span class="line-added">192                         m_insertionSet.insert&lt;Const32Value&gt;(m_index, m_origin, 31));</span>
<span class="line-added">193                     Value* hasOverflowed = m_insertionSet.insert&lt;Value&gt;(m_index, NotEqual, m_origin, upperResult, signBit);</span>
<span class="line-added">194 </span>
<span class="line-added">195                     CheckValue* check = m_insertionSet.insert&lt;CheckValue&gt;(m_index, Check, m_origin, hasOverflowed);</span>
<span class="line-added">196                     check-&gt;setGenerator(checkMul-&gt;generator());</span>
<span class="line-added">197                     check-&gt;clobberEarly(checkMul-&gt;earlyClobbered());</span>
<span class="line-added">198                     check-&gt;clobberLate(checkMul-&gt;lateClobbered());</span>
<span class="line-added">199                     auto children = checkMul-&gt;constrainedChildren();</span>
<span class="line-added">200                     auto it = children.begin();</span>
<span class="line-added">201                     for (std::advance(it, 2); it != children.end(); ++it)</span>
<span class="line-added">202                         check-&gt;append(*it);</span>
<span class="line-added">203 </span>
<span class="line-added">204                     m_value-&gt;replaceWithIdentity(mulResult32);</span>
<span class="line-added">205                     m_changed = true;</span>
<span class="line-added">206                 }</span>
<span class="line-added">207                 break;</span>
<span class="line-added">208             }</span>
<span class="line-added">209 </span>
210             case Switch: {
211                 SwitchValue* switchValue = m_value-&gt;as&lt;SwitchValue&gt;();
212                 Vector&lt;SwitchCase&gt; cases;
213                 for (SwitchCase switchCase : switchValue-&gt;cases(m_block))
214                     cases.append(switchCase);
215                 std::sort(
216                     cases.begin(), cases.end(),
217                     [] (const SwitchCase&amp; left, const SwitchCase&amp; right) {
218                         return left.caseValue() &lt; right.caseValue();
219                     });
220                 FrequentedBlock fallThrough = m_block-&gt;fallThrough();
221                 m_block-&gt;values().removeLast();
222                 recursivelyBuildSwitch(cases, fallThrough, 0, false, cases.size(), m_block);
223                 m_proc.deleteValue(switchValue);
224                 m_block-&gt;updatePredecessorsAfter();
225                 m_changed = true;
226                 break;
227             }
228 
229             case Depend: {
230                 if (isX86()) {
231                     // Create a load-load fence. This codegens to nothing on X86. We use it to tell the
232                     // compiler not to block load motion.
233                     FenceValue* fence = m_insertionSet.insert&lt;FenceValue&gt;(m_index, m_origin);
234                     fence-&gt;read = HeapRange();
235                     fence-&gt;write = HeapRange::top();
236 
237                     // Kill the Depend, which should unlock a bunch of code simplification.
238                     m_value-&gt;replaceWithBottom(m_insertionSet, m_index);
239 
240                     m_changed = true;
241                 }
242                 break;
243             }
244 
245             case AtomicWeakCAS:
246             case AtomicStrongCAS: {
247                 AtomicValue* atomic = m_value-&gt;as&lt;AtomicValue&gt;();
248                 Width width = atomic-&gt;accessWidth();
249 
250                 if (isCanonicalWidth(width))
251                     break;
252 
253                 Value* expectedValue = atomic-&gt;child(0);
254 
255                 if (!isX86()) {
256                     // On ARM, the load part of the CAS does a load with zero extension. Therefore, we need
257                     // to zero-extend the input.
258                     Value* maskedExpectedValue = m_insertionSet.insert&lt;Value&gt;(
259                         m_index, BitAnd, m_origin, expectedValue,
260                         m_insertionSet.insertIntConstant(m_index, expectedValue, mask(width)));
261 
262                     atomic-&gt;child(0) = maskedExpectedValue;
263                     m_changed = true;
264                 }
265 
266                 if (atomic-&gt;opcode() == AtomicStrongCAS) {
267                     Value* newValue = m_insertionSet.insert&lt;Value&gt;(
268                         m_index, signExtendOpcode(width), m_origin,
269                         m_insertionSet.insertClone(m_index, atomic));
270 
271                     atomic-&gt;replaceWithIdentity(newValue);
272                     m_changed = true;
273                 }
274 
275                 break;
276             }
277 
278             case AtomicXchgAdd:
279             case AtomicXchgAnd:
280             case AtomicXchgOr:
281             case AtomicXchgSub:
282             case AtomicXchgXor:
283             case AtomicXchg: {
284                 // On X86, these may actually return garbage in the high bits. On ARM64, these sorta
285                 // zero-extend their high bits, except that the high bits might get polluted by high
286                 // bits in the operand. So, either way, we need to throw a sign-extend on these
287                 // things.
288 
289                 if (isX86()) {
290                     if (m_value-&gt;opcode() == AtomicXchgSub &amp;&amp; m_useCounts.numUses(m_value)) {
291                         // On x86, xchgadd is better than xchgsub if it has any users.
292                         m_value-&gt;setOpcodeUnsafely(AtomicXchgAdd);
293                         m_value-&gt;child(0) = m_insertionSet.insert&lt;Value&gt;(
294                             m_index, Neg, m_origin, m_value-&gt;child(0));
295                     }
296 
297                     bool exempt = false;
298                     switch (m_value-&gt;opcode()) {
299                     case AtomicXchgAnd:
300                     case AtomicXchgOr:
301                     case AtomicXchgSub:
302                     case AtomicXchgXor:
303                         exempt = true;
304                         break;
305                     default:
306                         break;
307                     }
308                     if (exempt)
309                         break;
310                 }
311 
312                 AtomicValue* atomic = m_value-&gt;as&lt;AtomicValue&gt;();
313                 Width width = atomic-&gt;accessWidth();
314 
315                 if (isCanonicalWidth(width))
316                     break;
317 
318                 Value* newValue = m_insertionSet.insert&lt;Value&gt;(
319                     m_index, signExtendOpcode(width), m_origin,
320                     m_insertionSet.insertClone(m_index, atomic));
321 
322                 atomic-&gt;replaceWithIdentity(newValue);
323                 m_changed = true;
324                 break;
325             }
326 
327             case Load8Z:
328             case Load16Z: {
329                 if (isX86())
330                     break;
331 
332                 MemoryValue* memory = m_value-&gt;as&lt;MemoryValue&gt;();
333                 if (!memory-&gt;hasFence())
334                     break;
335 
336                 // Sub-width load-acq on ARM64 always sign extends.
337                 Value* newLoad = m_insertionSet.insertClone(m_index, memory);
338                 newLoad-&gt;setOpcodeUnsafely(memory-&gt;opcode() == Load8Z ? Load8S : Load16S);
339 
340                 Value* newValue = m_insertionSet.insert&lt;Value&gt;(
341                     m_index, BitAnd, m_origin, newLoad,
342                     m_insertionSet.insertIntConstant(
343                         m_index, m_origin, Int32, mask(memory-&gt;accessWidth())));
344 
345                 m_value-&gt;replaceWithIdentity(newValue);
346                 m_changed = true;
347                 break;
348             }
349 
350             default:
351                 break;
352             }
353         }
354         m_insertionSet.execute(m_block);
355     }
356 
357     void makeDivisionChill(Opcode nonChillOpcode)
358     {
359         ASSERT(nonChillOpcode == Div || nonChillOpcode == Mod);
360 
361         // ARM supports this instruction natively.
362         if (isARM64())
363             return;
364 
365         // We implement &quot;res = Div&lt;Chill&gt;/Mod&lt;Chill&gt;(num, den)&quot; as follows:
366         //
367         //     if (den + 1 &lt;=_unsigned 1) {
368         //         if (!den) {
369         //             res = 0;
370         //             goto done;
371         //         }
372         //         if (num == -2147483648) {
373         //             res = isDiv ? num : 0;
374         //             goto done;
375         //         }
376         //     }
377         //     res = num (/ or %) dev;
378         // done:
379         m_changed = true;
380 
381         Value* num = m_value-&gt;child(0);
382         Value* den = m_value-&gt;child(1);
383 
384         Value* one = m_insertionSet.insertIntConstant(m_index, m_value, 1);
385         Value* isDenOK = m_insertionSet.insert&lt;Value&gt;(
386             m_index, Above, m_origin,
387             m_insertionSet.insert&lt;Value&gt;(m_index, Add, m_origin, den, one),
388             one);
389 
390         BasicBlock* before = m_blockInsertionSet.splitForward(m_block, m_index, &amp;m_insertionSet);
391 
392         BasicBlock* normalDivCase = m_blockInsertionSet.insertBefore(m_block);
393         BasicBlock* shadyDenCase = m_blockInsertionSet.insertBefore(m_block);
394         BasicBlock* zeroDenCase = m_blockInsertionSet.insertBefore(m_block);
395         BasicBlock* neg1DenCase = m_blockInsertionSet.insertBefore(m_block);
396         BasicBlock* intMinCase = m_blockInsertionSet.insertBefore(m_block);
397 
398         before-&gt;replaceLastWithNew&lt;Value&gt;(m_proc, Branch, m_origin, isDenOK);
399         before-&gt;setSuccessors(
400             FrequentedBlock(normalDivCase, FrequencyClass::Normal),
401             FrequentedBlock(shadyDenCase, FrequencyClass::Rare));
402 
403         UpsilonValue* normalResult = normalDivCase-&gt;appendNew&lt;UpsilonValue&gt;(
404             m_proc, m_origin,
405             normalDivCase-&gt;appendNew&lt;Value&gt;(m_proc, nonChillOpcode, m_origin, num, den));
406         normalDivCase-&gt;appendNew&lt;Value&gt;(m_proc, Jump, m_origin);
407         normalDivCase-&gt;setSuccessors(FrequentedBlock(m_block));
408 
409         shadyDenCase-&gt;appendNew&lt;Value&gt;(m_proc, Branch, m_origin, den);
410         shadyDenCase-&gt;setSuccessors(
411             FrequentedBlock(neg1DenCase, FrequencyClass::Normal),
412             FrequentedBlock(zeroDenCase, FrequencyClass::Rare));
413 
414         UpsilonValue* zeroResult = zeroDenCase-&gt;appendNew&lt;UpsilonValue&gt;(
415             m_proc, m_origin,
416             zeroDenCase-&gt;appendIntConstant(m_proc, m_value, 0));
417         zeroDenCase-&gt;appendNew&lt;Value&gt;(m_proc, Jump, m_origin);
418         zeroDenCase-&gt;setSuccessors(FrequentedBlock(m_block));
419 
420         int64_t badNumeratorConst = 0;
<a name="2" id="anc2"></a><span class="line-modified">421         switch (m_value-&gt;type().kind()) {</span>
422         case Int32:
423             badNumeratorConst = std::numeric_limits&lt;int32_t&gt;::min();
424             break;
425         case Int64:
426             badNumeratorConst = std::numeric_limits&lt;int64_t&gt;::min();
427             break;
428         default:
429             ASSERT_NOT_REACHED();
430             badNumeratorConst = 0;
431         }
432 
433         Value* badNumerator =
434             neg1DenCase-&gt;appendIntConstant(m_proc, m_value, badNumeratorConst);
435 
436         neg1DenCase-&gt;appendNew&lt;Value&gt;(
437             m_proc, Branch, m_origin,
438             neg1DenCase-&gt;appendNew&lt;Value&gt;(
439                 m_proc, Equal, m_origin, num, badNumerator));
440         neg1DenCase-&gt;setSuccessors(
441             FrequentedBlock(intMinCase, FrequencyClass::Rare),
442             FrequentedBlock(normalDivCase, FrequencyClass::Normal));
443 
444         Value* intMinResult = nonChillOpcode == Div ? badNumerator : intMinCase-&gt;appendIntConstant(m_proc, m_value, 0);
445         UpsilonValue* intMinResultUpsilon = intMinCase-&gt;appendNew&lt;UpsilonValue&gt;(
446             m_proc, m_origin, intMinResult);
447         intMinCase-&gt;appendNew&lt;Value&gt;(m_proc, Jump, m_origin);
448         intMinCase-&gt;setSuccessors(FrequentedBlock(m_block));
449 
450         Value* phi = m_insertionSet.insert&lt;Value&gt;(
451             m_index, Phi, m_value-&gt;type(), m_origin);
452         normalResult-&gt;setPhi(phi);
453         zeroResult-&gt;setPhi(phi);
454         intMinResultUpsilon-&gt;setPhi(phi);
455 
456         m_value-&gt;replaceWithIdentity(phi);
457         before-&gt;updatePredecessorsAfter();
458     }
459 
460     void recursivelyBuildSwitch(
461         const Vector&lt;SwitchCase&gt;&amp; cases, FrequentedBlock fallThrough, unsigned start, bool hardStart,
462         unsigned end, BasicBlock* before)
463     {
464         Value* child = m_value-&gt;child(0);
465         Type type = child-&gt;type();
466 
467         // It&#39;s a good idea to use a table-based switch in some cases: the number of cases has to be
468         // large enough and they have to be dense enough. This could probably be improved a lot. For
469         // example, we could still use a jump table in cases where the inputs are sparse so long as we
470         // shift off the uninteresting bits. On the other hand, it&#39;s not clear that this would
471         // actually be any better than what we have done here and it&#39;s not clear that it would be
472         // better than a binary switch.
473         const unsigned minCasesForTable = 7;
474         const unsigned densityLimit = 4;
475         if (end - start &gt;= minCasesForTable) {
476             int64_t firstValue = cases[start].caseValue();
477             int64_t lastValue = cases[end - 1].caseValue();
478             if ((lastValue - firstValue + 1) / (end - start) &lt; densityLimit) {
479                 BasicBlock* switchBlock = m_blockInsertionSet.insertAfter(m_block);
480                 Value* index = before-&gt;appendNew&lt;Value&gt;(
481                     m_proc, Sub, m_origin, child,
482                     before-&gt;appendIntConstant(m_proc, m_origin, type, firstValue));
483                 before-&gt;appendNew&lt;Value&gt;(
484                     m_proc, Branch, m_origin,
485                     before-&gt;appendNew&lt;Value&gt;(
486                         m_proc, Above, m_origin, index,
487                         before-&gt;appendIntConstant(m_proc, m_origin, type, lastValue - firstValue)));
488                 before-&gt;setSuccessors(fallThrough, FrequentedBlock(switchBlock));
489 
490                 size_t tableSize = lastValue - firstValue + 1;
491 
492                 if (index-&gt;type() != pointerType() &amp;&amp; index-&gt;type() == Int32)
493                     index = switchBlock-&gt;appendNew&lt;Value&gt;(m_proc, ZExt32, m_origin, index);
494 
495                 PatchpointValue* patchpoint =
496                     switchBlock-&gt;appendNew&lt;PatchpointValue&gt;(m_proc, Void, m_origin);
497 
498                 // Even though this loads from the jump table, the jump table is immutable. For the
499                 // purpose of alias analysis, reading something immutable is like reading nothing.
500                 patchpoint-&gt;effects = Effects();
501                 patchpoint-&gt;effects.terminal = true;
502 
503                 patchpoint-&gt;appendSomeRegister(index);
504                 patchpoint-&gt;numGPScratchRegisters = 2;
505                 // Technically, we don&#39;t have to clobber macro registers on X86_64. This is probably
506                 // OK though.
507                 patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
508 
509                 BitVector handledIndices;
510                 for (unsigned i = start; i &lt; end; ++i) {
511                     FrequentedBlock block = cases[i].target();
512                     int64_t value = cases[i].caseValue();
513                     switchBlock-&gt;appendSuccessor(block);
514                     size_t index = value - firstValue;
515                     ASSERT(!handledIndices.get(index));
516                     handledIndices.set(index);
517                 }
518 
519                 bool hasUnhandledIndex = false;
520                 for (unsigned i = 0; i &lt; tableSize; ++i) {
521                     if (!handledIndices.get(i)) {
522                         hasUnhandledIndex = true;
523                         break;
524                     }
525                 }
526 
527                 if (hasUnhandledIndex)
528                     switchBlock-&gt;appendSuccessor(fallThrough);
529 
530                 patchpoint-&gt;setGenerator(
531                     [=] (CCallHelpers&amp; jit, const StackmapGenerationParams&amp; params) {
532                         AllowMacroScratchRegisterUsage allowScratch(jit);
533 
534                         using JumpTableCodePtr = MacroAssemblerCodePtr&lt;JSSwitchPtrTag&gt;;
535                         JumpTableCodePtr* jumpTable = static_cast&lt;JumpTableCodePtr*&gt;(
536                             params.proc().addDataSection(sizeof(JumpTableCodePtr) * tableSize));
537 
538                         GPRReg index = params[0].gpr();
539                         GPRReg scratch = params.gpScratch(0);
540 
541                         jit.move(CCallHelpers::TrustedImmPtr(jumpTable), scratch);
542                         jit.load64(CCallHelpers::BaseIndex(scratch, index, CCallHelpers::timesPtr()), scratch);
<a name="3" id="anc3"></a><span class="line-modified">543                         jit.farJump(scratch, JSSwitchPtrTag);</span>
544 
545                         // These labels are guaranteed to be populated before either late paths or
546                         // link tasks run.
547                         Vector&lt;Box&lt;CCallHelpers::Label&gt;&gt; labels = params.successorLabels();
548 
549                         jit.addLinkTask(
550                             [=] (LinkBuffer&amp; linkBuffer) {
551                                 if (hasUnhandledIndex) {
552                                     JumpTableCodePtr fallThrough = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(*labels.last());
553                                     for (unsigned i = tableSize; i--;)
554                                         jumpTable[i] = fallThrough;
555                                 }
556 
557                                 unsigned labelIndex = 0;
558                                 for (unsigned tableIndex : handledIndices)
559                                     jumpTable[tableIndex] = linkBuffer.locationOf&lt;JSSwitchPtrTag&gt;(*labels[labelIndex++]);
560                             });
561                     });
562                 return;
563             }
564         }
565 
566         // See comments in jit/BinarySwitch.cpp for a justification of this algorithm. The only
567         // thing we do differently is that we don&#39;t use randomness.
568 
569         const unsigned leafThreshold = 3;
570 
571         unsigned size = end - start;
572 
573         if (size &lt;= leafThreshold) {
574             bool allConsecutive = false;
575 
576             if ((hardStart || (start &amp;&amp; cases[start - 1].caseValue() == cases[start].caseValue() - 1))
577                 &amp;&amp; end &lt; cases.size()
578                 &amp;&amp; cases[end - 1].caseValue() == cases[end].caseValue() - 1) {
579                 allConsecutive = true;
580                 for (unsigned i = 0; i &lt; size - 1; ++i) {
581                     if (cases[start + i].caseValue() + 1 != cases[start + i + 1].caseValue()) {
582                         allConsecutive = false;
583                         break;
584                     }
585                 }
586             }
587 
588             unsigned limit = allConsecutive ? size - 1 : size;
589 
590             for (unsigned i = 0; i &lt; limit; ++i) {
591                 BasicBlock* nextCheck = m_blockInsertionSet.insertAfter(m_block);
592                 before-&gt;appendNew&lt;Value&gt;(
593                     m_proc, Branch, m_origin,
594                     before-&gt;appendNew&lt;Value&gt;(
595                         m_proc, Equal, m_origin, child,
596                         before-&gt;appendIntConstant(
597                             m_proc, m_origin, type,
598                             cases[start + i].caseValue())));
599                 before-&gt;setSuccessors(cases[start + i].target(), FrequentedBlock(nextCheck));
600 
601                 before = nextCheck;
602             }
603 
604             before-&gt;appendNew&lt;Value&gt;(m_proc, Jump, m_origin);
605             if (allConsecutive)
606                 before-&gt;setSuccessors(cases[end - 1].target());
607             else
608                 before-&gt;setSuccessors(fallThrough);
609             return;
610         }
611 
612         unsigned medianIndex = (start + end) / 2;
613 
614         BasicBlock* left = m_blockInsertionSet.insertAfter(m_block);
615         BasicBlock* right = m_blockInsertionSet.insertAfter(m_block);
616 
617         before-&gt;appendNew&lt;Value&gt;(
618             m_proc, Branch, m_origin,
619             before-&gt;appendNew&lt;Value&gt;(
620                 m_proc, LessThan, m_origin, child,
621                 before-&gt;appendIntConstant(
622                     m_proc, m_origin, type,
623                     cases[medianIndex].caseValue())));
624         before-&gt;setSuccessors(FrequentedBlock(left), FrequentedBlock(right));
625 
626         recursivelyBuildSwitch(cases, fallThrough, start, hardStart, medianIndex, left);
627         recursivelyBuildSwitch(cases, fallThrough, medianIndex, true, end, right);
628     }
629 
630     Procedure&amp; m_proc;
631     BlockInsertionSet m_blockInsertionSet;
632     InsertionSet m_insertionSet;
633     UseCounts m_useCounts;
634     BasicBlock* m_block;
635     unsigned m_index;
636     Value* m_value;
637     Origin m_origin;
638     bool m_changed { false };
639 };
640 
641 } // anonymous namespace
642 
643 bool lowerMacros(Procedure&amp; proc)
644 {
645     PhaseScope phaseScope(proc, &quot;B3::lowerMacros&quot;);
646     LowerMacros lowerMacros(proc);
647     return lowerMacros.run();
648 }
649 
650 } } // namespace JSC::B3
651 
652 #endif // ENABLE(B3_JIT)
653 
<a name="4" id="anc4"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="4" type="hidden" />
</body>
</html>