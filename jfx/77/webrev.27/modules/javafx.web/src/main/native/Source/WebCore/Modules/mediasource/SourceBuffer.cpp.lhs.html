<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (C) 2013 Google Inc. All rights reserved.
   3  * Copyright (C) 2013-2019 Apple Inc. All rights reserved.
   4  *
   5  * Redistribution and use in source and binary forms, with or without
   6  * modification, are permitted provided that the following conditions are
   7  * met:
   8  *
   9  *     * Redistributions of source code must retain the above copyright
  10  * notice, this list of conditions and the following disclaimer.
  11  *     * Redistributions in binary form must reproduce the above
  12  * copyright notice, this list of conditions and the following disclaimer
  13  * in the documentation and/or other materials provided with the
  14  * distribution.
  15  *     * Neither the name of Google Inc. nor the names of its
  16  * contributors may be used to endorse or promote products derived from
  17  * this software without specific prior written permission.
  18  *
  19  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
  20  * &quot;AS IS&quot; AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
  21  * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
  22  * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
  23  * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
  24  * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
  25  * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
  26  * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
  27  * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  28  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  29  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  30  */
  31 
  32 #include &quot;config.h&quot;
  33 #include &quot;SourceBuffer.h&quot;
  34 
  35 #if ENABLE(MEDIA_SOURCE)
  36 
  37 #include &quot;AudioTrackList.h&quot;
  38 #include &quot;BufferSource.h&quot;
  39 #include &quot;Event.h&quot;
  40 #include &quot;EventNames.h&quot;
  41 #include &quot;GenericEventQueue.h&quot;
  42 #include &quot;HTMLMediaElement.h&quot;
  43 #include &quot;InbandTextTrack.h&quot;
  44 #include &quot;Logging.h&quot;
  45 #include &quot;MediaDescription.h&quot;
  46 #include &quot;MediaSample.h&quot;
  47 #include &quot;MediaSource.h&quot;
  48 #include &quot;SampleMap.h&quot;
  49 #include &quot;SourceBufferList.h&quot;
  50 #include &quot;SourceBufferPrivate.h&quot;
  51 #include &quot;TextTrackList.h&quot;
  52 #include &quot;TimeRanges.h&quot;
  53 #include &quot;VideoTrackList.h&quot;
  54 #include &lt;JavaScriptCore/JSCInlines.h&gt;
  55 #include &lt;JavaScriptCore/JSLock.h&gt;
  56 #include &lt;JavaScriptCore/VM.h&gt;
  57 #include &lt;limits&gt;
  58 #include &lt;wtf/CheckedArithmetic.h&gt;
<a name="1" id="anc1"></a>
  59 
  60 namespace WebCore {
  61 
<a name="2" id="anc2"></a>

  62 static const double ExponentialMovingAverageCoefficient = 0.1;
  63 
  64 struct SourceBuffer::TrackBuffer {
  65     MediaTime lastDecodeTimestamp;
  66     MediaTime greatestDecodeDuration;
  67     MediaTime lastFrameDuration;
  68     MediaTime highestPresentationTimestamp;
  69     MediaTime lastEnqueuedPresentationTime;
<a name="3" id="anc3"></a>
  70     DecodeOrderSampleMap::KeyType lastEnqueuedDecodeKey;
  71     MediaTime lastEnqueuedDecodeDuration;
  72     MediaTime roundedTimestampOffset;
  73     uint32_t lastFrameTimescale { 0 };
  74     bool needRandomAccessFlag { true };
  75     bool enabled { false };
  76     bool needsReenqueueing { false };
<a name="4" id="anc4"></a>
  77     SampleMap samples;
  78     DecodeOrderSampleMap::MapType decodeQueue;
  79     RefPtr&lt;MediaDescription&gt; description;
  80     PlatformTimeRanges buffered;
  81 
  82     TrackBuffer()
  83         : lastDecodeTimestamp(MediaTime::invalidTime())
  84         , greatestDecodeDuration(MediaTime::invalidTime())
  85         , lastFrameDuration(MediaTime::invalidTime())
  86         , highestPresentationTimestamp(MediaTime::invalidTime())
  87         , lastEnqueuedPresentationTime(MediaTime::invalidTime())
  88         , lastEnqueuedDecodeKey({MediaTime::invalidTime(), MediaTime::invalidTime()})
  89         , lastEnqueuedDecodeDuration(MediaTime::invalidTime())
  90     {
  91     }
  92 };
  93 
  94 Ref&lt;SourceBuffer&gt; SourceBuffer::create(Ref&lt;SourceBufferPrivate&gt;&amp;&amp; sourceBufferPrivate, MediaSource* source)
  95 {
  96     auto sourceBuffer = adoptRef(*new SourceBuffer(WTFMove(sourceBufferPrivate), source));
  97     sourceBuffer-&gt;suspendIfNeeded();
  98     return sourceBuffer;
  99 }
 100 
 101 SourceBuffer::SourceBuffer(Ref&lt;SourceBufferPrivate&gt;&amp;&amp; sourceBufferPrivate, MediaSource* source)
 102     : ActiveDOMObject(source-&gt;scriptExecutionContext())
 103     , m_private(WTFMove(sourceBufferPrivate))
 104     , m_source(source)
 105     , m_asyncEventQueue(*this)
 106     , m_appendBufferTimer(*this, &amp;SourceBuffer::appendBufferTimerFired)
 107     , m_appendWindowStart(MediaTime::zeroTime())
 108     , m_appendWindowEnd(MediaTime::positiveInfiniteTime())
 109     , m_groupStartTimestamp(MediaTime::invalidTime())
 110     , m_groupEndTimestamp(MediaTime::zeroTime())
 111     , m_buffered(TimeRanges::create())
 112     , m_appendState(WaitingForSegment)
 113     , m_timeOfBufferingMonitor(MonotonicTime::now())
 114     , m_pendingRemoveStart(MediaTime::invalidTime())
 115     , m_pendingRemoveEnd(MediaTime::invalidTime())
 116     , m_removeTimer(*this, &amp;SourceBuffer::removeTimerFired)
 117 #if !RELEASE_LOG_DISABLED
 118     , m_logger(m_private-&gt;sourceBufferLogger())
 119     , m_logIdentifier(m_private-&gt;sourceBufferLogIdentifier())
 120 #endif
 121 {
 122     ASSERT(m_source);
 123     ALWAYS_LOG(LOGIDENTIFIER);
 124 
 125     m_private-&gt;setClient(this);
 126 }
 127 
 128 SourceBuffer::~SourceBuffer()
 129 {
 130     ASSERT(isRemoved());
 131     ALWAYS_LOG(LOGIDENTIFIER);
 132 
 133     m_private-&gt;setClient(nullptr);
 134 }
 135 
 136 ExceptionOr&lt;Ref&lt;TimeRanges&gt;&gt; SourceBuffer::buffered() const
 137 {
 138     // Section 3.1 buffered attribute steps.
 139     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#attributes-1
 140     // 1. If this object has been removed from the sourceBuffers attribute of the parent media source then throw an
 141     //    InvalidStateError exception and abort these steps.
 142     if (isRemoved())
 143         return Exception { InvalidStateError };
 144 
 145     // 2. Return a new static normalized TimeRanges object for the media segments buffered.
 146     return m_buffered-&gt;copy();
 147 }
 148 
 149 double SourceBuffer::timestampOffset() const
 150 {
 151     return m_timestampOffset.toDouble();
 152 }
 153 
 154 ExceptionOr&lt;void&gt; SourceBuffer::setTimestampOffset(double offset)
 155 {
 156     // Section 3.1 timestampOffset attribute setter steps.
 157     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#attributes-1
 158     // 1. Let new timestamp offset equal the new value being assigned to this attribute.
 159     // 2. If this object has been removed from the sourceBuffers attribute of the parent media source, then throw an
 160     //    InvalidStateError exception and abort these steps.
 161     // 3. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 162     if (isRemoved() || m_updating)
 163         return Exception { InvalidStateError };
 164 
 165     // 4. If the readyState attribute of the parent media source is in the &quot;ended&quot; state then run the following steps:
 166     // 4.1 Set the readyState attribute of the parent media source to &quot;open&quot;
 167     // 4.2 Queue a task to fire a simple event named sourceopen at the parent media source.
 168     m_source-&gt;openIfInEndedState();
 169 
 170     // 5. If the append state equals PARSING_MEDIA_SEGMENT, then throw an InvalidStateError and abort these steps.
 171     if (m_appendState == ParsingMediaSegment)
 172         return Exception { InvalidStateError };
 173 
 174     MediaTime newTimestampOffset = MediaTime::createWithDouble(offset);
 175 
 176     // 6. If the mode attribute equals &quot;sequence&quot;, then set the group start timestamp to new timestamp offset.
 177     if (m_mode == AppendMode::Sequence)
 178         m_groupStartTimestamp = newTimestampOffset;
 179 
 180     // 7. Update the attribute to the new value.
 181     m_timestampOffset = newTimestampOffset;
 182 
 183     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
 184         trackBuffer.lastFrameTimescale = 0;
 185         trackBuffer.roundedTimestampOffset = MediaTime::invalidTime();
 186     }
 187 
 188     return { };
 189 }
 190 
 191 double SourceBuffer::appendWindowStart() const
 192 {
 193     return m_appendWindowStart.toDouble();
 194 }
 195 
 196 ExceptionOr&lt;void&gt; SourceBuffer::setAppendWindowStart(double newValue)
 197 {
 198     // Section 3.1 appendWindowStart attribute setter steps.
 199     // W3C Editor&#39;s Draft 16 September 2016
 200     // https://rawgit.com/w3c/media-source/45627646344eea0170dd1cbc5a3d508ca751abb8/media-source-respec.html#dom-sourcebuffer-appendwindowstart
 201     // 1. If this object has been removed from the sourceBuffers attribute of the parent media source,
 202     //    then throw an InvalidStateError  exception and abort these steps.
 203     // 2. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 204     if (isRemoved() || m_updating)
 205         return Exception { InvalidStateError };
 206 
 207     // 3. If the new value is less than 0 or greater than or equal to appendWindowEnd then
 208     //    throw an TypeError exception and abort these steps.
 209     if (newValue &lt; 0 || newValue &gt;= m_appendWindowEnd.toDouble())
 210         return Exception { TypeError };
 211 
 212     // 4. Update the attribute to the new value.
 213     m_appendWindowStart = MediaTime::createWithDouble(newValue);
 214 
 215     return { };
 216 }
 217 
 218 double SourceBuffer::appendWindowEnd() const
 219 {
 220     return m_appendWindowEnd.toDouble();
 221 }
 222 
 223 ExceptionOr&lt;void&gt; SourceBuffer::setAppendWindowEnd(double newValue)
 224 {
 225     // Section 3.1 appendWindowEnd attribute setter steps.
 226     // W3C Editor&#39;s Draft 16 September 2016
 227     // https://rawgit.com/w3c/media-source/45627646344eea0170dd1cbc5a3d508ca751abb8/media-source-respec.html#dom-sourcebuffer-appendwindowend
 228     // 1. If this object has been removed from the sourceBuffers attribute of the parent media source,
 229     //    then throw an InvalidStateError exception and abort these steps.
 230     // 2. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 231     if (isRemoved() || m_updating)
 232         return Exception { InvalidStateError };
 233 
 234     // 3. If the new value equals NaN, then throw an TypeError and abort these steps.
 235     // 4. If the new value is less than or equal to appendWindowStart then throw an TypeError exception
 236     //    and abort these steps.
 237     if (std::isnan(newValue) || newValue &lt;= m_appendWindowStart.toDouble())
 238         return Exception { TypeError };
 239 
 240     // 5.. Update the attribute to the new value.
 241     m_appendWindowEnd = MediaTime::createWithDouble(newValue);
 242 
 243     return { };
 244 }
 245 
 246 ExceptionOr&lt;void&gt; SourceBuffer::appendBuffer(const BufferSource&amp; data)
 247 {
 248     return appendBufferInternal(static_cast&lt;const unsigned char*&gt;(data.data()), data.length());
 249 }
 250 
 251 void SourceBuffer::resetParserState()
 252 {
 253     // Section 3.5.2 Reset Parser State algorithm steps.
 254     // http://www.w3.org/TR/2014/CR-media-source-20140717/#sourcebuffer-reset-parser-state
 255     // 1. If the append state equals PARSING_MEDIA_SEGMENT and the input buffer contains some complete coded frames,
 256     //    then run the coded frame processing algorithm until all of these complete coded frames have been processed.
 257     // FIXME: If any implementation will work in pulling mode (instead of async push to SourceBufferPrivate, and forget)
 258     //     this should be handled somehow either here, or in m_private-&gt;abort();
 259 
 260     // 2. Unset the last decode timestamp on all track buffers.
 261     // 3. Unset the last frame duration on all track buffers.
 262     // 4. Unset the highest presentation timestamp on all track buffers.
 263     // 5. Set the need random access point flag on all track buffers to true.
 264     for (auto&amp; trackBufferPair : m_trackBufferMap.values()) {
 265         trackBufferPair.lastDecodeTimestamp = MediaTime::invalidTime();
 266         trackBufferPair.greatestDecodeDuration = MediaTime::invalidTime();
 267         trackBufferPair.lastFrameDuration = MediaTime::invalidTime();
 268         trackBufferPair.highestPresentationTimestamp = MediaTime::invalidTime();
 269         trackBufferPair.needRandomAccessFlag = true;
 270     }
 271     // 6. Remove all bytes from the input buffer.
 272     // Note: this is handled by abortIfUpdating()
 273     // 7. Set append state to WAITING_FOR_SEGMENT.
 274     m_appendState = WaitingForSegment;
 275 
 276     m_private-&gt;resetParserState();
 277 }
 278 
 279 ExceptionOr&lt;void&gt; SourceBuffer::abort()
 280 {
 281     // Section 3.2 abort() method steps.
 282     // https://rawgit.com/w3c/media-source/45627646344eea0170dd1cbc5a3d508ca751abb8/media-source-respec.html#dom-sourcebuffer-abort
 283     // 1. If this object has been removed from the sourceBuffers attribute of the parent media source
 284     //    then throw an InvalidStateError exception and abort these steps.
 285     // 2. If the readyState attribute of the parent media source is not in the &quot;open&quot; state
 286     //    then throw an InvalidStateError exception and abort these steps.
 287     if (isRemoved() || !m_source-&gt;isOpen())
 288         return Exception { InvalidStateError };
 289 
 290     // 3. If the range removal algorithm is running, then throw an InvalidStateError exception and abort these steps.
 291     if (m_removeTimer.isActive())
 292         return Exception { InvalidStateError };
 293 
 294     // 4. If the sourceBuffer.updating attribute equals true, then run the following steps: ...
 295     abortIfUpdating();
 296 
 297     // 5. Run the reset parser state algorithm.
 298     resetParserState();
 299 
 300     // 6. Set appendWindowStart to the presentation start time.
 301     m_appendWindowStart = MediaTime::zeroTime();
 302 
 303     // 7. Set appendWindowEnd to positive Infinity.
 304     m_appendWindowEnd = MediaTime::positiveInfiniteTime();
 305 
 306     return { };
 307 }
 308 
 309 ExceptionOr&lt;void&gt; SourceBuffer::remove(double start, double end)
 310 {
 311     return remove(MediaTime::createWithDouble(start), MediaTime::createWithDouble(end));
 312 }
 313 
 314 ExceptionOr&lt;void&gt; SourceBuffer::remove(const MediaTime&amp; start, const MediaTime&amp; end)
 315 {
 316     DEBUG_LOG(LOGIDENTIFIER, &quot;start = &quot;, start, &quot;, end = &quot;, end);
 317 
 318     // https://rawgit.com/w3c/media-source/45627646344eea0170dd1cbc5a3d508ca751abb8/media-source-respec.html#dom-sourcebuffer-remove
 319     // Section 3.2 remove() method steps.
 320     // 1. If this object has been removed from the sourceBuffers attribute of the parent media source then throw
 321     //    an InvalidStateError exception and abort these steps.
 322     // 2. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 323     if (isRemoved() || m_updating)
 324         return Exception { InvalidStateError };
 325 
 326     // 3. If duration equals NaN, then throw a TypeError exception and abort these steps.
 327     // 4. If start is negative or greater than duration, then throw a TypeError exception and abort these steps.
 328     // 5. If end is less than or equal to start or end equals NaN, then throw a TypeError exception and abort these steps.
 329     if (m_source-&gt;duration().isInvalid()
 330         || end.isInvalid()
 331         || start.isInvalid()
 332         || start &lt; MediaTime::zeroTime()
 333         || start &gt; m_source-&gt;duration()
 334         || end &lt;= start) {
 335         return Exception { TypeError };
 336     }
 337 
 338     // 6. If the readyState attribute of the parent media source is in the &quot;ended&quot; state then run the following steps:
 339     // 6.1. Set the readyState attribute of the parent media source to &quot;open&quot;
 340     // 6.2. Queue a task to fire a simple event named sourceopen at the parent media source .
 341     m_source-&gt;openIfInEndedState();
 342 
 343     // 7. Run the range removal algorithm with start and end as the start and end of the removal range.
 344     rangeRemoval(start, end);
 345 
 346     return { };
 347 }
 348 
 349 void SourceBuffer::rangeRemoval(const MediaTime&amp; start, const MediaTime&amp; end)
 350 {
 351     // 3.5.7 Range Removal
 352     // https://rawgit.com/w3c/media-source/7bbe4aa33c61ec025bc7acbd80354110f6a000f9/media-source.html#sourcebuffer-range-removal
 353     // 1. Let start equal the starting presentation timestamp for the removal range.
 354     // 2. Let end equal the end presentation timestamp for the removal range.
 355     // 3. Set the updating attribute to true.
 356     m_updating = true;
 357 
 358     // 4. Queue a task to fire a simple event named updatestart at this SourceBuffer object.
 359     scheduleEvent(eventNames().updatestartEvent);
 360 
 361     // 5. Return control to the caller and run the rest of the steps asynchronously.
 362     m_pendingRemoveStart = start;
 363     m_pendingRemoveEnd = end;
 364     m_removeTimer.startOneShot(0_s);
 365 }
 366 
 367 ExceptionOr&lt;void&gt; SourceBuffer::changeType(const String&amp; type)
 368 {
 369     // changeType() proposed API. See issue #155: &lt;https://github.com/w3c/media-source/issues/155&gt;
 370     // https://rawgit.com/wicg/media-source/codec-switching/index.html#dom-sourcebuffer-changetype
 371 
 372     // 1. If type is an empty string then throw a TypeError exception and abort these steps.
 373     if (type.isEmpty())
 374         return Exception { TypeError };
 375 
 376     // 2. If this object has been removed from the sourceBuffers attribute of the parent media source,
 377     // then throw an InvalidStateError exception and abort these steps.
 378     // 3. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 379     if (isRemoved() || m_updating)
 380         return Exception { InvalidStateError };
 381 
 382     // 4. If type contains a MIME type that is not supported or contains a MIME type that is not supported with
 383     // the types specified (currently or previously) of SourceBuffer objects in the sourceBuffers attribute of
 384     // the parent media source, then throw a NotSupportedError exception and abort these steps.
 385     ContentType contentType(type);
 386     if (!m_private-&gt;canSwitchToType(contentType))
 387         return Exception { NotSupportedError };
 388 
 389     // 5. If the readyState attribute of the parent media source is in the &quot;ended&quot; state then run the following
 390     // steps:
 391     // 5.1. Set the readyState attribute of the parent media source to &quot;open&quot;
 392     // 5.2. Queue a task to fire a simple event named sourceopen at the parent media source.
 393     m_source-&gt;openIfInEndedState();
 394 
 395     // 6. Run the reset parser state algorithm.
 396     resetParserState();
 397 
 398     // 7. Update the generate timestamps flag on this SourceBuffer object to the value in the &quot;Generate Timestamps
 399     // Flag&quot; column of the byte stream format registry [MSE-REGISTRY] entry that is associated with type.
 400     setShouldGenerateTimestamps(MediaSource::contentTypeShouldGenerateTimestamps(contentType));
 401 
 402     // ↳ If the generate timestamps flag equals true:
 403     // Set the mode attribute on this SourceBuffer object to &quot;sequence&quot;, including running the associated steps
 404     // for that attribute being set.
 405     if (m_shouldGenerateTimestamps)
 406         setMode(AppendMode::Sequence);
 407 
 408     // ↳ Otherwise:
 409     // Keep the previous value of the mode attribute on this SourceBuffer object, without running any associated
 410     // steps for that attribute being set.
 411     // NOTE: No-op.
 412 
 413     // 9. Set pending initialization segment for changeType flag to true.
 414     m_pendingInitializationSegmentForChangeType = true;
 415 
 416     return { };
 417 }
 418 
 419 void SourceBuffer::abortIfUpdating()
 420 {
 421     // Section 3.2 abort() method step 4 substeps.
 422     // https://rawgit.com/w3c/media-source/45627646344eea0170dd1cbc5a3d508ca751abb8/media-source-respec.html#dom-sourcebuffer-abort
 423 
 424     if (!m_updating)
 425         return;
 426 
 427     // 4.1. Abort the buffer append algorithm if it is running.
 428     m_appendBufferTimer.stop();
 429     m_pendingAppendData.clear();
 430     m_private-&gt;abort();
 431 
 432     // 4.2. Set the updating attribute to false.
 433     m_updating = false;
 434 
 435     // 4.3. Queue a task to fire a simple event named abort at this SourceBuffer object.
 436     scheduleEvent(eventNames().abortEvent);
 437 
 438     // 4.4. Queue a task to fire a simple event named updateend at this SourceBuffer object.
 439     scheduleEvent(eventNames().updateendEvent);
 440 }
 441 
 442 MediaTime SourceBuffer::highestPresentationTimestamp() const
 443 {
 444     MediaTime highestTime;
 445     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
 446         auto lastSampleIter = trackBuffer.samples.presentationOrder().rbegin();
 447         if (lastSampleIter == trackBuffer.samples.presentationOrder().rend())
 448             continue;
 449         highestTime = std::max(highestTime, lastSampleIter-&gt;first);
 450     }
 451     return highestTime;
 452 }
 453 
 454 void SourceBuffer::readyStateChanged()
 455 {
 456     updateBufferedFromTrackBuffers();
 457 }
 458 
 459 void SourceBuffer::removedFromMediaSource()
 460 {
 461     if (isRemoved())
 462         return;
 463 
 464     abortIfUpdating();
 465 
 466     for (auto&amp; trackBufferPair : m_trackBufferMap.values()) {
 467         trackBufferPair.samples.clear();
 468         trackBufferPair.decodeQueue.clear();
 469     }
 470 
 471     m_private-&gt;removedFromMediaSource();
 472     m_source = nullptr;
 473 }
 474 
 475 void SourceBuffer::seekToTime(const MediaTime&amp; time)
 476 {
 477     ALWAYS_LOG(LOGIDENTIFIER, time);
 478 
 479     for (auto&amp; trackBufferPair : m_trackBufferMap) {
 480         TrackBuffer&amp; trackBuffer = trackBufferPair.value;
<a name="5" id="anc5"></a><span class="line-modified"> 481         const AtomicString&amp; trackID = trackBufferPair.key;</span>
 482 
 483         trackBuffer.needsReenqueueing = true;
 484         reenqueueMediaForTime(trackBuffer, trackID, time);
 485     }
 486 }
 487 
 488 MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(const MediaTime&amp; targetTime, const MediaTime&amp; negativeThreshold, const MediaTime&amp; positiveThreshold)
 489 {
 490     MediaTime seekTime = targetTime;
 491     MediaTime lowerBoundTime = targetTime - negativeThreshold;
 492     MediaTime upperBoundTime = targetTime + positiveThreshold;
 493 
 494     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
 495         // Find the sample which contains the target time time.
 496         auto futureSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(targetTime, positiveThreshold);
 497         auto pastSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSamplePriorToPresentationTime(targetTime, negativeThreshold);
 498         auto upperBound = trackBuffer.samples.decodeOrder().end();
 499         auto lowerBound = trackBuffer.samples.decodeOrder().rend();
 500 
 501         if (futureSyncSampleIterator == upperBound &amp;&amp; pastSyncSampleIterator == lowerBound)
 502             continue;
 503 
 504         MediaTime futureSeekTime = MediaTime::positiveInfiniteTime();
 505         if (futureSyncSampleIterator != upperBound) {
 506             RefPtr&lt;MediaSample&gt;&amp; sample = futureSyncSampleIterator-&gt;second;
 507             futureSeekTime = sample-&gt;presentationTime();
 508         }
 509 
 510         MediaTime pastSeekTime = MediaTime::negativeInfiniteTime();
 511         if (pastSyncSampleIterator != lowerBound) {
 512             RefPtr&lt;MediaSample&gt;&amp; sample = pastSyncSampleIterator-&gt;second;
 513             pastSeekTime = sample-&gt;presentationTime();
 514         }
 515 
 516         MediaTime trackSeekTime = abs(targetTime - futureSeekTime) &lt; abs(targetTime - pastSeekTime) ? futureSeekTime : pastSeekTime;
 517         if (abs(targetTime - trackSeekTime) &gt; abs(targetTime - seekTime))
 518             seekTime = trackSeekTime;
 519     }
 520 
 521     return seekTime;
 522 }
 523 
 524 bool SourceBuffer::hasPendingActivity() const
 525 {
 526     return m_source || m_asyncEventQueue.hasPendingEvents();
 527 }
 528 
 529 void SourceBuffer::suspend(ReasonForSuspension reason)
 530 {
 531     switch (reason) {
 532     case ReasonForSuspension::PageCache:
 533     case ReasonForSuspension::PageWillBeSuspended:
 534         m_asyncEventQueue.suspend();
 535         break;
 536     case ReasonForSuspension::JavaScriptDebuggerPaused:
 537     case ReasonForSuspension::WillDeferLoading:
 538         // Do nothing, we don&#39;t pause media playback in these cases.
 539         break;
 540     }
 541 }
 542 
 543 void SourceBuffer::resume()
 544 {
 545     m_asyncEventQueue.resume();
 546 }
 547 
 548 void SourceBuffer::stop()
 549 {
 550     m_asyncEventQueue.close();
 551     m_appendBufferTimer.stop();
 552     m_removeTimer.stop();
 553 }
 554 
 555 bool SourceBuffer::canSuspendForDocumentSuspension() const
 556 {
 557     return !hasPendingActivity();
 558 }
 559 
 560 const char* SourceBuffer::activeDOMObjectName() const
 561 {
 562     return &quot;SourceBuffer&quot;;
 563 }
 564 
 565 bool SourceBuffer::isRemoved() const
 566 {
 567     return !m_source;
 568 }
 569 
<a name="6" id="anc6"></a><span class="line-modified"> 570 void SourceBuffer::scheduleEvent(const AtomicString&amp; eventName)</span>
 571 {
 572     auto event = Event::create(eventName, Event::CanBubble::No, Event::IsCancelable::No);
 573     event-&gt;setTarget(this);
 574 
 575     m_asyncEventQueue.enqueueEvent(WTFMove(event));
 576 }
 577 
 578 ExceptionOr&lt;void&gt; SourceBuffer::appendBufferInternal(const unsigned char* data, unsigned size)
 579 {
 580     // Section 3.2 appendBuffer()
 581     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-appendBuffer-void-ArrayBufferView-data
 582 
 583     // Step 1 is enforced by the caller.
 584     // 2. Run the prepare append algorithm.
 585     // Section 3.5.4 Prepare AppendAlgorithm
 586 
 587     // 1. If the SourceBuffer has been removed from the sourceBuffers attribute of the parent media source
 588     // then throw an InvalidStateError exception and abort these steps.
 589     // 2. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 590     if (isRemoved() || m_updating)
 591         return Exception { InvalidStateError };
 592 
 593     // 3. If the readyState attribute of the parent media source is in the &quot;ended&quot; state then run the following steps:
 594     // 3.1. Set the readyState attribute of the parent media source to &quot;open&quot;
 595     // 3.2. Queue a task to fire a simple event named sourceopen at the parent media source .
 596     m_source-&gt;openIfInEndedState();
 597 
 598     // 4. Run the coded frame eviction algorithm.
 599     evictCodedFrames(size);
 600 
 601     // FIXME: enable this code when MSE libraries have been updated to support it.
 602 #if USE(GSTREAMER)
 603     // 5. If the buffer full flag equals true, then throw a QuotaExceededError exception and abort these step.
 604     if (m_bufferFull) {
 605         ERROR_LOG(LOGIDENTIFIER, &quot;buffer full, failing with QuotaExceededError error&quot;);
 606         return Exception { QuotaExceededError };
 607     }
 608 #endif
 609 
 610     // NOTE: Return to 3.2 appendBuffer()
 611     // 3. Add data to the end of the input buffer.
 612     m_pendingAppendData.append(data, size);
 613 
 614     // 4. Set the updating attribute to true.
 615     m_updating = true;
 616 
 617     // 5. Queue a task to fire a simple event named updatestart at this SourceBuffer object.
 618     scheduleEvent(eventNames().updatestartEvent);
 619 
 620     // 6. Asynchronously run the buffer append algorithm.
 621     m_appendBufferTimer.startOneShot(0_s);
 622 
 623     reportExtraMemoryAllocated();
 624 
 625     return { };
 626 }
 627 
 628 void SourceBuffer::appendBufferTimerFired()
 629 {
 630     if (isRemoved())
 631         return;
 632 
 633     ASSERT(m_updating);
 634 
 635     // Section 3.5.5 Buffer Append Algorithm
 636     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#sourcebuffer-buffer-append
 637 
 638     // 1. Run the segment parser loop algorithm.
 639 
 640     // Section 3.5.1 Segment Parser Loop
 641     // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-segment-parser-loop
 642     // When the segment parser loop algorithm is invoked, run the following steps:
 643 
 644     // 1. Loop Top: If the input buffer is empty, then jump to the need more data step below.
 645     if (!m_pendingAppendData.size()) {
 646         sourceBufferPrivateAppendComplete(AppendSucceeded);
 647         return;
 648     }
 649 
 650     // Manually clear out the m_pendingAppendData Vector, in case the platform implementation
 651     // rejects appending the buffer for whatever reason.
 652     // FIXME: The implementation should guarantee the move from this Vector, and we should
 653     // assert here to confirm that. See https://bugs.webkit.org/show_bug.cgi?id=178003.
 654     m_private-&gt;append(WTFMove(m_pendingAppendData));
 655     m_pendingAppendData.clear();
 656 }
 657 
 658 void SourceBuffer::sourceBufferPrivateAppendComplete(AppendResult result)
 659 {
 660     if (isRemoved())
 661         return;
 662 
 663     // Resolve the changes it TrackBuffers&#39; buffered ranges
 664     // into the SourceBuffer&#39;s buffered ranges
 665     updateBufferedFromTrackBuffers();
 666 
 667     // Section 3.5.5 Buffer Append Algorithm, ctd.
 668     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#sourcebuffer-buffer-append
 669 
 670     // 2. If the input buffer contains bytes that violate the SourceBuffer byte stream format specification,
 671     // then run the append error algorithm with the decode error parameter set to true and abort this algorithm.
 672     if (result == ParsingFailed) {
 673         ERROR_LOG(LOGIDENTIFIER, &quot;ParsingFailed&quot;);
 674         appendError(true);
 675         return;
 676     }
 677 
 678     // NOTE: Steps 3 - 6 enforced by sourceBufferPrivateDidReceiveInitializationSegment() and
 679     // sourceBufferPrivateDidReceiveSample below.
 680 
 681     // 7. Need more data: Return control to the calling algorithm.
 682 
 683     // NOTE: return to Section 3.5.5
 684     // 2.If the segment parser loop algorithm in the previous step was aborted, then abort this algorithm.
 685     if (result != AppendSucceeded)
 686         return;
 687 
 688     // 3. Set the updating attribute to false.
 689     m_updating = false;
 690 
 691     // 4. Queue a task to fire a simple event named update at this SourceBuffer object.
 692     scheduleEvent(eventNames().updateEvent);
 693 
 694     // 5. Queue a task to fire a simple event named updateend at this SourceBuffer object.
 695     scheduleEvent(eventNames().updateendEvent);
 696 
 697     if (m_source)
 698         m_source-&gt;monitorSourceBuffers();
 699 
 700     MediaTime currentMediaTime = m_source-&gt;currentTime();
 701     for (auto&amp; trackBufferPair : m_trackBufferMap) {
 702         TrackBuffer&amp; trackBuffer = trackBufferPair.value;
<a name="7" id="anc7"></a><span class="line-modified"> 703         const AtomicString&amp; trackID = trackBufferPair.key;</span>
 704 
 705         if (trackBuffer.needsReenqueueing) {
 706             DEBUG_LOG(LOGIDENTIFIER, &quot;reenqueuing at time &quot;, currentMediaTime);
 707             reenqueueMediaForTime(trackBuffer, trackID, currentMediaTime);
 708         } else
 709             provideMediaData(trackBuffer, trackID);
 710     }
 711 
 712     reportExtraMemoryAllocated();
 713     if (extraMemoryCost() &gt; this-&gt;maximumBufferSize())
 714         m_bufferFull = true;
 715 
 716     DEBUG_LOG(LOGIDENTIFIER);
 717 }
 718 
 719 void SourceBuffer::sourceBufferPrivateDidReceiveRenderingError(int error)
 720 {
 721 #if RELEASE_LOG_DISABLED
 722     UNUSED_PARAM(error);
 723 #endif
 724 
 725     ERROR_LOG(LOGIDENTIFIER, error);
 726 
 727     if (!isRemoved())
 728         m_source-&gt;streamEndedWithError(MediaSource::EndOfStreamError::Decode);
 729 }
 730 
 731 static bool decodeTimeComparator(const PresentationOrderSampleMap::MapType::value_type&amp; a, const PresentationOrderSampleMap::MapType::value_type&amp; b)
 732 {
 733     return a.second-&gt;decodeTime() &lt; b.second-&gt;decodeTime();
 734 }
 735 
 736 static PlatformTimeRanges removeSamplesFromTrackBuffer(const DecodeOrderSampleMap::MapType&amp; samples, SourceBuffer::TrackBuffer&amp; trackBuffer, const SourceBuffer* buffer, const char* logPrefix)
 737 {
 738 #if !RELEASE_LOG_DISABLED
 739     MediaTime earliestSample = MediaTime::positiveInfiniteTime();
 740     MediaTime latestSample = MediaTime::zeroTime();
 741     size_t bytesRemoved = 0;
 742     auto logIdentifier = WTF::Logger::LogSiteIdentifier(buffer-&gt;logClassName(), logPrefix, buffer-&gt;logIdentifier());
 743     auto&amp; logger = buffer-&gt;logger();
<a name="8" id="anc8"></a><span class="line-modified"> 744     auto willLog = logger.willLog(buffer-&gt;logChannel(), WTFLogLevelDebug);</span>
 745 #else
 746     UNUSED_PARAM(logPrefix);
 747     UNUSED_PARAM(buffer);
 748 #endif
 749 
 750     PlatformTimeRanges erasedRanges;
 751     for (const auto&amp; sampleIt : samples) {
 752         const DecodeOrderSampleMap::KeyType&amp; decodeKey = sampleIt.first;
 753 #if !RELEASE_LOG_DISABLED
 754         size_t startBufferSize = trackBuffer.samples.sizeInBytes();
 755 #endif
 756 
 757         const RefPtr&lt;MediaSample&gt;&amp; sample = sampleIt.second;
 758 
 759 #if !RELEASE_LOG_DISABLED
 760         if (willLog)
 761             logger.debug(buffer-&gt;logChannel(), logIdentifier, &quot;removing sample &quot;, *sampleIt.second);
 762 #endif
 763 
 764         // Remove the erased samples from the TrackBuffer sample map.
 765         trackBuffer.samples.removeSample(sample.get());
 766 
 767         // Also remove the erased samples from the TrackBuffer decodeQueue.
 768         trackBuffer.decodeQueue.erase(decodeKey);
 769 
 770         auto startTime = sample-&gt;presentationTime();
 771         auto endTime = startTime + sample-&gt;duration();
 772         erasedRanges.add(startTime, endTime);
 773 
 774 #if !RELEASE_LOG_DISABLED
 775         bytesRemoved += startBufferSize - trackBuffer.samples.sizeInBytes();
 776         if (startTime &lt; earliestSample)
 777             earliestSample = startTime;
 778         if (endTime &gt; latestSample)
 779             latestSample = endTime;
 780 #endif
 781     }
 782 
 783     // Because we may have added artificial padding in the buffered ranges when adding samples, we may
 784     // need to remove that padding when removing those same samples. Walk over the erased ranges looking
 785     // for unbuffered areas and expand erasedRanges to encompass those areas.
 786     PlatformTimeRanges additionalErasedRanges;
 787     for (unsigned i = 0; i &lt; erasedRanges.length(); ++i) {
 788         auto erasedStart = erasedRanges.start(i);
 789         auto erasedEnd = erasedRanges.end(i);
 790         auto startIterator = trackBuffer.samples.presentationOrder().reverseFindSampleBeforePresentationTime(erasedStart);
 791         if (startIterator == trackBuffer.samples.presentationOrder().rend())
 792             additionalErasedRanges.add(MediaTime::zeroTime(), erasedStart);
 793         else {
 794             auto&amp; previousSample = *startIterator-&gt;second;
 795             if (previousSample.presentationTime() + previousSample.duration() &lt; erasedStart)
 796                 additionalErasedRanges.add(previousSample.presentationTime() + previousSample.duration(), erasedStart);
 797         }
 798 
 799         auto endIterator = trackBuffer.samples.presentationOrder().findSampleStartingOnOrAfterPresentationTime(erasedEnd);
 800         if (endIterator == trackBuffer.samples.presentationOrder().end())
 801             additionalErasedRanges.add(erasedEnd, MediaTime::positiveInfiniteTime());
 802         else {
 803             auto&amp; nextSample = *endIterator-&gt;second;
 804             if (nextSample.presentationTime() &gt; erasedEnd)
 805                 additionalErasedRanges.add(erasedEnd, nextSample.presentationTime());
 806         }
 807     }
 808     if (additionalErasedRanges.length())
 809         erasedRanges.unionWith(additionalErasedRanges);
 810 
 811 #if !RELEASE_LOG_DISABLED
 812     if (bytesRemoved &amp;&amp; willLog)
 813         logger.debug(buffer-&gt;logChannel(), logIdentifier, &quot;removed &quot;, bytesRemoved, &quot;, start = &quot;, earliestSample, &quot;, end = &quot;, latestSample);
 814 #endif
 815 
 816     return erasedRanges;
 817 }
 818 
 819 void SourceBuffer::removeCodedFrames(const MediaTime&amp; start, const MediaTime&amp; end)
 820 {
 821     DEBUG_LOG(LOGIDENTIFIER, &quot;start = &quot;, start, &quot;, end = &quot;, end);
 822 
 823     // 3.5.9 Coded Frame Removal Algorithm
 824     // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-coded-frame-removal
 825 
 826     // 1. Let start be the starting presentation timestamp for the removal range.
 827     MediaTime durationMediaTime = m_source-&gt;duration();
 828     MediaTime currentMediaTime = m_source-&gt;currentTime();
 829 
 830     // 2. Let end be the end presentation timestamp for the removal range.
 831     // 3. For each track buffer in this source buffer, run the following steps:
<a name="9" id="anc9"></a><span class="line-modified"> 832     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {</span>



 833         // 3.1. Let remove end timestamp be the current value of duration
 834         // 3.2 If this track buffer has a random access point timestamp that is greater than or equal to end, then update
 835         // remove end timestamp to that random access point timestamp.
 836         // NOTE: Step 3.2 will be incorrect for any random access point timestamp whose decode time is later than the sample at end,
 837         // but whose presentation time is less than the sample at end. Skip this step until step 3.3 below.
 838 
 839         // NOTE: To handle MediaSamples which may be an amalgamation of multiple shorter samples, find samples whose presentation
 840         // interval straddles the start and end times, and divide them if possible:
 841         auto divideSampleIfPossibleAtPresentationTime = [&amp;] (const MediaTime&amp; time) {
 842             auto sampleIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
 843             if (sampleIterator == trackBuffer.samples.presentationOrder().end())
 844                 return;
 845             RefPtr&lt;MediaSample&gt; sample = sampleIterator-&gt;second;
 846             if (!sample-&gt;isDivisable())
 847                 return;
 848             std::pair&lt;RefPtr&lt;MediaSample&gt;, RefPtr&lt;MediaSample&gt;&gt; replacementSamples = sample-&gt;divide(time);
 849             if (!replacementSamples.first || !replacementSamples.second)
 850                 return;
 851             DEBUG_LOG(LOGIDENTIFIER, &quot;splitting sample &quot;, *sample, &quot; into &quot;, *replacementSamples.first, &quot; and &quot;, *replacementSamples.second);
 852             trackBuffer.samples.removeSample(sample.get());
 853             trackBuffer.samples.addSample(*replacementSamples.first);
 854             trackBuffer.samples.addSample(*replacementSamples.second);
 855         };
 856         divideSampleIfPossibleAtPresentationTime(start);
 857         divideSampleIfPossibleAtPresentationTime(end);
 858 
 859         auto removePresentationStart = trackBuffer.samples.presentationOrder().findSampleContainingOrAfterPresentationTime(start);
 860         auto removePresentationEnd = trackBuffer.samples.presentationOrder().findSampleStartingOnOrAfterPresentationTime(end);
 861         if (removePresentationStart == removePresentationEnd)
 862             continue;
 863 
 864         // 3.3 Remove all media data, from this track buffer, that contain starting timestamps greater than or equal to
 865         // start and less than the remove end timestamp.
 866         // NOTE: frames must be removed in decode order, so that all dependant frames between the frame to be removed
 867         // and the next sync sample frame are removed. But we must start from the first sample in decode order, not
 868         // presentation order.
 869         auto minmaxDecodeTimeIterPair = std::minmax_element(removePresentationStart, removePresentationEnd, decodeTimeComparator);
 870         auto&amp; firstSample = *minmaxDecodeTimeIterPair.first-&gt;second;
 871         auto&amp; lastSample = *minmaxDecodeTimeIterPair.second-&gt;second;
 872         auto removeDecodeStart = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({firstSample.decodeTime(), firstSample.presentationTime()});
 873         auto removeDecodeLast = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({lastSample.decodeTime(), lastSample.presentationTime()});
 874         auto removeDecodeEnd = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(removeDecodeLast);
 875 
 876         DecodeOrderSampleMap::MapType erasedSamples(removeDecodeStart, removeDecodeEnd);
 877         PlatformTimeRanges erasedRanges = removeSamplesFromTrackBuffer(erasedSamples, trackBuffer, this, &quot;removeCodedFrames&quot;);
 878 
 879         // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
 880         // not yet displayed samples.
 881         if (trackBuffer.lastEnqueuedPresentationTime.isValid() &amp;&amp; currentMediaTime &lt; trackBuffer.lastEnqueuedPresentationTime) {
 882             PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.lastEnqueuedPresentationTime);
 883             possiblyEnqueuedRanges.intersectWith(erasedRanges);
<a name="10" id="anc10"></a><span class="line-modified"> 884             if (possiblyEnqueuedRanges.length())</span>
 885                 trackBuffer.needsReenqueueing = true;
<a name="11" id="anc11"></a>


 886         }
 887 
 888         erasedRanges.invert();
 889         trackBuffer.buffered.intersectWith(erasedRanges);
 890         setBufferedDirty(true);
 891 
 892         // 3.4 If this object is in activeSourceBuffers, the current playback position is greater than or equal to start
 893         // and less than the remove end timestamp, and HTMLMediaElement.readyState is greater than HAVE_METADATA, then set
 894         // the HTMLMediaElement.readyState attribute to HAVE_METADATA and stall playback.
 895         if (m_active &amp;&amp; currentMediaTime &gt;= start &amp;&amp; currentMediaTime &lt; end &amp;&amp; m_private-&gt;readyState() &gt; MediaPlayer::HaveMetadata)
 896             m_private-&gt;setReadyState(MediaPlayer::HaveMetadata);
 897     }
 898 
 899     updateBufferedFromTrackBuffers();
 900 
 901     // 4. If buffer full flag equals true and this object is ready to accept more bytes, then set the buffer full flag to false.
 902     // No-op
 903 
 904     LOG(Media, &quot;SourceBuffer::removeCodedFrames(%p) - buffered = %s&quot;, this, toString(m_buffered-&gt;ranges()).utf8().data());
 905 }
 906 
 907 void SourceBuffer::removeTimerFired()
 908 {
 909     if (isRemoved())
 910         return;
 911 
 912     ASSERT(m_updating);
 913     ASSERT(m_pendingRemoveStart.isValid());
 914     ASSERT(m_pendingRemoveStart &lt; m_pendingRemoveEnd);
 915 
 916     // Section 3.5.7 Range Removal
 917     // http://w3c.github.io/media-source/#sourcebuffer-range-removal
 918 
 919     // 6. Run the coded frame removal algorithm with start and end as the start and end of the removal range.
 920     removeCodedFrames(m_pendingRemoveStart, m_pendingRemoveEnd);
 921 
 922     // 7. Set the updating attribute to false.
 923     m_updating = false;
 924     m_pendingRemoveStart = MediaTime::invalidTime();
 925     m_pendingRemoveEnd = MediaTime::invalidTime();
 926 
 927     // 8. Queue a task to fire a simple event named update at this SourceBuffer object.
 928     scheduleEvent(eventNames().updateEvent);
 929 
 930     // 9. Queue a task to fire a simple event named updateend at this SourceBuffer object.
 931     scheduleEvent(eventNames().updateendEvent);
 932 }
 933 
 934 void SourceBuffer::evictCodedFrames(size_t newDataSize)
 935 {
 936     // 3.5.13 Coded Frame Eviction Algorithm
 937     // http://www.w3.org/TR/media-source/#sourcebuffer-coded-frame-eviction
 938 
 939     if (isRemoved())
 940         return;
 941 
 942     // This algorithm is run to free up space in this source buffer when new data is appended.
 943     // 1. Let new data equal the data that is about to be appended to this SourceBuffer.
 944     // 2. If the buffer full flag equals false, then abort these steps.
 945     if (!m_bufferFull)
 946         return;
 947 
 948     size_t maximumBufferSize = this-&gt;maximumBufferSize();
 949 
 950     // 3. Let removal ranges equal a list of presentation time ranges that can be evicted from
 951     // the presentation to make room for the new data.
 952 
 953     // NOTE: begin by removing data from the beginning of the buffered ranges, 30 seconds at
 954     // a time, up to 30 seconds before currentTime.
 955     MediaTime thirtySeconds = MediaTime(30, 1);
 956     MediaTime currentTime = m_source-&gt;currentTime();
 957     MediaTime maximumRangeEnd = currentTime - thirtySeconds;
 958 
 959 #if !RELEASE_LOG_DISABLED
 960     DEBUG_LOG(LOGIDENTIFIER, &quot;currentTime = &quot;, m_source-&gt;currentTime(), &quot;, require &quot;, extraMemoryCost() + newDataSize, &quot; bytes, maximum buffer size is &quot;, maximumBufferSize);
 961     size_t initialBufferedSize = extraMemoryCost();
 962 #endif
 963 
 964     MediaTime rangeStart = MediaTime::zeroTime();
 965     MediaTime rangeEnd = rangeStart + thirtySeconds;
 966     while (rangeStart &lt; maximumRangeEnd) {
 967         // 4. For each range in removal ranges, run the coded frame removal algorithm with start and
 968         // end equal to the removal range start and end timestamp respectively.
 969         removeCodedFrames(rangeStart, std::min(rangeEnd, maximumRangeEnd));
 970         if (extraMemoryCost() + newDataSize &lt; maximumBufferSize) {
 971             m_bufferFull = false;
 972             break;
 973         }
 974 
 975         rangeStart += thirtySeconds;
 976         rangeEnd += thirtySeconds;
 977     }
 978 
 979 #if !RELEASE_LOG_DISABLED
 980     if (!m_bufferFull) {
 981         DEBUG_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost());
 982         return;
 983     }
 984 #endif
 985 
 986     // If there still isn&#39;t enough free space and there buffers in time ranges after the current range (ie. there is a gap after
 987     // the current buffered range), delete 30 seconds at a time from duration back to the current time range or 30 seconds after
 988     // currenTime whichever we hit first.
 989     auto buffered = m_buffered-&gt;ranges();
 990     size_t currentTimeRange = buffered.find(currentTime);
<a name="12" id="anc12"></a><span class="line-modified"> 991     if (currentTimeRange == notFound || currentTimeRange == buffered.length() - 1) {</span>
 992 #if !RELEASE_LOG_DISABLED
<a name="13" id="anc13"></a><span class="line-modified"> 993         ERROR_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost(), &quot; bytes but FAILED to free enough&quot;);</span>
 994 #endif
 995         return;
 996     }
 997 
 998     MediaTime minimumRangeStart = currentTime + thirtySeconds;
 999 
1000     rangeEnd = m_source-&gt;duration();
1001     rangeStart = rangeEnd - thirtySeconds;
1002     while (rangeStart &gt; minimumRangeStart) {
1003 
1004         // Do not evict data from the time range that contains currentTime.
1005         size_t startTimeRange = buffered.find(rangeStart);
<a name="14" id="anc14"></a><span class="line-modified">1006         if (startTimeRange == currentTimeRange) {</span>
1007             size_t endTimeRange = buffered.find(rangeEnd);
<a name="15" id="anc15"></a><span class="line-modified">1008             if (endTimeRange == currentTimeRange)</span>
1009                 break;
1010 
1011             rangeEnd = buffered.start(endTimeRange);
1012         }
1013 
1014         // 4. For each range in removal ranges, run the coded frame removal algorithm with start and
1015         // end equal to the removal range start and end timestamp respectively.
1016         removeCodedFrames(std::max(minimumRangeStart, rangeStart), rangeEnd);
1017         if (extraMemoryCost() + newDataSize &lt; maximumBufferSize) {
1018             m_bufferFull = false;
1019             break;
1020         }
1021 
1022         rangeStart -= thirtySeconds;
1023         rangeEnd -= thirtySeconds;
1024     }
1025 
1026 #if !RELEASE_LOG_DISABLED
1027     if (m_bufferFull)
<a name="16" id="anc16"></a><span class="line-modified">1028         ERROR_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost(), &quot; but FAILED to free enough&quot;);</span>
1029     else
1030         DEBUG_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost());
1031 #endif
1032 }
1033 
1034 size_t SourceBuffer::maximumBufferSize() const
1035 {
1036     if (isRemoved())
1037         return 0;
1038 
1039     auto* element = m_source-&gt;mediaElement();
1040     if (!element)
1041         return 0;
1042 
1043     return element-&gt;maximumSourceBufferSize(*this);
1044 }
1045 
1046 VideoTrackList&amp; SourceBuffer::videoTracks()
1047 {
1048     if (!m_videoTracks)
1049         m_videoTracks = VideoTrackList::create(m_source-&gt;mediaElement(), scriptExecutionContext());
1050     return *m_videoTracks;
1051 }
1052 
1053 AudioTrackList&amp; SourceBuffer::audioTracks()
1054 {
1055     if (!m_audioTracks)
1056         m_audioTracks = AudioTrackList::create(m_source-&gt;mediaElement(), scriptExecutionContext());
1057     return *m_audioTracks;
1058 }
1059 
1060 TextTrackList&amp; SourceBuffer::textTracks()
1061 {
1062     if (!m_textTracks)
1063         m_textTracks = TextTrackList::create(m_source-&gt;mediaElement(), scriptExecutionContext());
1064     return *m_textTracks;
1065 }
1066 
1067 void SourceBuffer::setActive(bool active)
1068 {
1069     if (m_active == active)
1070         return;
1071 
1072     m_active = active;
1073     m_private-&gt;setActive(active);
1074     if (!isRemoved())
1075         m_source-&gt;sourceBufferDidChangeActiveState(*this, active);
1076 }
1077 
1078 void SourceBuffer::sourceBufferPrivateDidReceiveInitializationSegment(const InitializationSegment&amp; segment)
1079 {
1080     if (isRemoved())
1081         return;
1082 
1083     ALWAYS_LOG(LOGIDENTIFIER);
1084 
1085     // 3.5.8 Initialization Segment Received (ctd)
1086     // https://rawgit.com/w3c/media-source/c3ad59c7a370d04430969ba73d18dc9bcde57a33/index.html#sourcebuffer-init-segment-received [Editor&#39;s Draft 09 January 2015]
1087 
1088     // 1. Update the duration attribute if it currently equals NaN:
1089     if (m_source-&gt;duration().isInvalid()) {
1090         // ↳ If the initialization segment contains a duration:
1091         //   Run the duration change algorithm with new duration set to the duration in the initialization segment.
1092         // ↳ Otherwise:
1093         //   Run the duration change algorithm with new duration set to positive Infinity.
1094         if (segment.duration.isValid() &amp;&amp; !segment.duration.isIndefinite())
1095             m_source-&gt;setDurationInternal(segment.duration);
1096         else
1097             m_source-&gt;setDurationInternal(MediaTime::positiveInfiniteTime());
1098     }
1099 
1100     // 2. If the initialization segment has no audio, video, or text tracks, then run the append error algorithm
1101     // with the decode error parameter set to true and abort these steps.
1102     if (segment.audioTracks.isEmpty() &amp;&amp; segment.videoTracks.isEmpty() &amp;&amp; segment.textTracks.isEmpty()) {
1103         appendError(true);
1104         return;
1105     }
1106 
1107     // 3. If the first initialization segment flag is true, then run the following steps:
1108     if (m_receivedFirstInitializationSegment) {
1109 
1110         // 3.1. Verify the following properties. If any of the checks fail then run the append error algorithm
1111         // with the decode error parameter set to true and abort these steps.
1112         if (!validateInitializationSegment(segment)) {
1113             appendError(true);
1114             return;
1115         }
1116         // 3.2 Add the appropriate track descriptions from this initialization segment to each of the track buffers.
1117         ASSERT(segment.audioTracks.size() == audioTracks().length());
1118         for (auto&amp; audioTrackInfo : segment.audioTracks) {
1119             if (audioTracks().length() == 1) {
1120                 audioTracks().item(0)-&gt;setPrivate(*audioTrackInfo.track);
1121                 break;
1122             }
1123 
1124             auto audioTrack = audioTracks().getTrackById(audioTrackInfo.track-&gt;id());
1125             ASSERT(audioTrack);
1126             audioTrack-&gt;setPrivate(*audioTrackInfo.track);
1127         }
1128 
1129         ASSERT(segment.videoTracks.size() == videoTracks().length());
1130         for (auto&amp; videoTrackInfo : segment.videoTracks) {
1131             if (videoTracks().length() == 1) {
1132                 videoTracks().item(0)-&gt;setPrivate(*videoTrackInfo.track);
1133                 break;
1134             }
1135 
1136             auto videoTrack = videoTracks().getTrackById(videoTrackInfo.track-&gt;id());
1137             ASSERT(videoTrack);
1138             videoTrack-&gt;setPrivate(*videoTrackInfo.track);
1139         }
1140 
1141         ASSERT(segment.textTracks.size() == textTracks().length());
1142         for (auto&amp; textTrackInfo : segment.textTracks) {
1143             if (textTracks().length() == 1) {
1144                 downcast&lt;InbandTextTrack&gt;(*textTracks().item(0)).setPrivate(*textTrackInfo.track);
1145                 break;
1146             }
1147 
1148             auto textTrack = textTracks().getTrackById(textTrackInfo.track-&gt;id());
1149             ASSERT(textTrack);
1150             downcast&lt;InbandTextTrack&gt;(*textTrack).setPrivate(*textTrackInfo.track);
1151         }
1152 
1153         // 3.3 Set the need random access point flag on all track buffers to true.
1154         for (auto&amp; trackBuffer : m_trackBufferMap.values())
1155             trackBuffer.needRandomAccessFlag = true;
1156     }
1157 
1158     // 4. Let active track flag equal false.
1159     bool activeTrackFlag = false;
1160 
1161     // 5. If the first initialization segment flag is false, then run the following steps:
1162     if (!m_receivedFirstInitializationSegment) {
1163         // 5.1 If the initialization segment contains tracks with codecs the user agent does not support,
1164         // then run the append error algorithm with the decode error parameter set to true and abort these steps.
1165         // NOTE: This check is the responsibility of the SourceBufferPrivate.
1166 
1167         // 5.2 For each audio track in the initialization segment, run following steps:
1168         for (auto&amp; audioTrackInfo : segment.audioTracks) {
1169             // FIXME: Implement steps 5.2.1-5.2.8.1 as per Editor&#39;s Draft 09 January 2015, and reorder this
1170             // 5.2.1 Let new audio track be a new AudioTrack object.
1171             // 5.2.2 Generate a unique ID and assign it to the id property on new video track.
1172             auto newAudioTrack = AudioTrack::create(*this, *audioTrackInfo.track);
1173             newAudioTrack-&gt;setSourceBuffer(this);
1174 
1175             // 5.2.3 If audioTracks.length equals 0, then run the following steps:
1176             if (!audioTracks().length()) {
1177                 // 5.2.3.1 Set the enabled property on new audio track to true.
1178                 newAudioTrack-&gt;setEnabled(true);
1179 
1180                 // 5.2.3.2 Set active track flag to true.
1181                 activeTrackFlag = true;
1182             }
1183 
1184             // 5.2.4 Add new audio track to the audioTracks attribute on this SourceBuffer object.
1185             // 5.2.5 Queue a task to fire a trusted event named addtrack, that does not bubble and is
1186             // not cancelable, and that uses the TrackEvent interface, at the AudioTrackList object
1187             // referenced by the audioTracks attribute on this SourceBuffer object.
1188             audioTracks().append(newAudioTrack.copyRef());
1189 
1190             // 5.2.6 Add new audio track to the audioTracks attribute on the HTMLMediaElement.
1191             // 5.2.7 Queue a task to fire a trusted event named addtrack, that does not bubble and is
1192             // not cancelable, and that uses the TrackEvent interface, at the AudioTrackList object
1193             // referenced by the audioTracks attribute on the HTMLMediaElement.
1194             m_source-&gt;mediaElement()-&gt;ensureAudioTracks().append(newAudioTrack.copyRef());
1195 
1196             // 5.2.8 Create a new track buffer to store coded frames for this track.
1197             ASSERT(!m_trackBufferMap.contains(newAudioTrack-&gt;id()));
1198             auto&amp; trackBuffer = m_trackBufferMap.add(newAudioTrack-&gt;id(), TrackBuffer()).iterator-&gt;value;
1199 
1200             // 5.2.9 Add the track description for this track to the track buffer.
1201             trackBuffer.description = audioTrackInfo.description;
1202 
1203             m_audioCodecs.append(trackBuffer.description-&gt;codec());
1204         }
1205 
1206         // 5.3 For each video track in the initialization segment, run following steps:
1207         for (auto&amp; videoTrackInfo : segment.videoTracks) {
1208             // FIXME: Implement steps 5.3.1-5.3.8.1 as per Editor&#39;s Draft 09 January 2015, and reorder this
1209             // 5.3.1 Let new video track be a new VideoTrack object.
1210             // 5.3.2 Generate a unique ID and assign it to the id property on new video track.
1211             auto newVideoTrack = VideoTrack::create(*this, *videoTrackInfo.track);
1212             newVideoTrack-&gt;setSourceBuffer(this);
1213 
1214             // 5.3.3 If videoTracks.length equals 0, then run the following steps:
1215             if (!videoTracks().length()) {
1216                 // 5.3.3.1 Set the selected property on new video track to true.
1217                 newVideoTrack-&gt;setSelected(true);
1218 
1219                 // 5.3.3.2 Set active track flag to true.
1220                 activeTrackFlag = true;
1221             }
1222 
1223             // 5.3.4 Add new video track to the videoTracks attribute on this SourceBuffer object.
1224             // 5.3.5 Queue a task to fire a trusted event named addtrack, that does not bubble and is
1225             // not cancelable, and that uses the TrackEvent interface, at the VideoTrackList object
1226             // referenced by the videoTracks attribute on this SourceBuffer object.
1227             videoTracks().append(newVideoTrack.copyRef());
1228 
1229             // 5.3.6 Add new video track to the videoTracks attribute on the HTMLMediaElement.
1230             // 5.3.7 Queue a task to fire a trusted event named addtrack, that does not bubble and is
1231             // not cancelable, and that uses the TrackEvent interface, at the VideoTrackList object
1232             // referenced by the videoTracks attribute on the HTMLMediaElement.
1233             m_source-&gt;mediaElement()-&gt;ensureVideoTracks().append(newVideoTrack.copyRef());
1234 
1235             // 5.3.8 Create a new track buffer to store coded frames for this track.
1236             ASSERT(!m_trackBufferMap.contains(newVideoTrack-&gt;id()));
1237             auto&amp; trackBuffer = m_trackBufferMap.add(newVideoTrack-&gt;id(), TrackBuffer()).iterator-&gt;value;
1238 
1239             // 5.3.9 Add the track description for this track to the track buffer.
1240             trackBuffer.description = videoTrackInfo.description;
1241 
1242             m_videoCodecs.append(trackBuffer.description-&gt;codec());
1243         }
1244 
1245         // 5.4 For each text track in the initialization segment, run following steps:
1246         for (auto&amp; textTrackInfo : segment.textTracks) {
1247             auto&amp; textTrackPrivate = *textTrackInfo.track;
1248 
1249             // FIXME: Implement steps 5.4.1-5.4.8.1 as per Editor&#39;s Draft 09 January 2015, and reorder this
1250             // 5.4.1 Let new text track be a new TextTrack object with its properties populated with the
1251             // appropriate information from the initialization segment.
1252             auto newTextTrack = InbandTextTrack::create(*scriptExecutionContext(), *this, textTrackPrivate);
1253 
1254             // 5.4.2 If the mode property on new text track equals &quot;showing&quot; or &quot;hidden&quot;, then set active
1255             // track flag to true.
1256             if (textTrackPrivate.mode() != InbandTextTrackPrivate::Disabled)
1257                 activeTrackFlag = true;
1258 
1259             // 5.4.3 Add new text track to the textTracks attribute on this SourceBuffer object.
1260             // 5.4.4 Queue a task to fire a trusted event named addtrack, that does not bubble and is
1261             // not cancelable, and that uses the TrackEvent interface, at textTracks attribute on this
1262             // SourceBuffer object.
1263             textTracks().append(newTextTrack.get());
1264 
1265             // 5.4.5 Add new text track to the textTracks attribute on the HTMLMediaElement.
1266             // 5.4.6 Queue a task to fire a trusted event named addtrack, that does not bubble and is
1267             // not cancelable, and that uses the TrackEvent interface, at the TextTrackList object
1268             // referenced by the textTracks attribute on the HTMLMediaElement.
1269             m_source-&gt;mediaElement()-&gt;ensureTextTracks().append(WTFMove(newTextTrack));
1270 
1271             // 5.4.7 Create a new track buffer to store coded frames for this track.
1272             ASSERT(!m_trackBufferMap.contains(textTrackPrivate.id()));
1273             auto&amp; trackBuffer = m_trackBufferMap.add(textTrackPrivate.id(), TrackBuffer()).iterator-&gt;value;
1274 
1275             // 5.4.8 Add the track description for this track to the track buffer.
1276             trackBuffer.description = textTrackInfo.description;
1277 
1278             m_textCodecs.append(trackBuffer.description-&gt;codec());
1279         }
1280 
1281         // 5.5 If active track flag equals true, then run the following steps:
1282         if (activeTrackFlag) {
1283             // 5.5.1 Add this SourceBuffer to activeSourceBuffers.
1284             // 5.5.2 Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
1285             setActive(true);
1286         }
1287 
1288         // 5.6 Set first initialization segment flag to true.
1289         m_receivedFirstInitializationSegment = true;
1290     }
1291 
1292     // (Note: Issue #155 adds this step after step 5:)
1293     // 6. Set  pending initialization segment for changeType flag  to false.
1294     m_pendingInitializationSegmentForChangeType = false;
1295 
1296     // 6. If the HTMLMediaElement.readyState attribute is HAVE_NOTHING, then run the following steps:
1297     if (m_private-&gt;readyState() == MediaPlayer::HaveNothing) {
1298         // 6.1 If one or more objects in sourceBuffers have first initialization segment flag set to false, then abort these steps.
1299         for (auto&amp; sourceBuffer : *m_source-&gt;sourceBuffers()) {
1300             if (!sourceBuffer-&gt;m_receivedFirstInitializationSegment)
1301                 return;
1302         }
1303 
1304         // 6.2 Set the HTMLMediaElement.readyState attribute to HAVE_METADATA.
1305         // 6.3 Queue a task to fire a simple event named loadedmetadata at the media element.
1306         m_private-&gt;setReadyState(MediaPlayer::HaveMetadata);
1307     }
1308 
1309     // 7. If the active track flag equals true and the HTMLMediaElement.readyState
1310     // attribute is greater than HAVE_CURRENT_DATA, then set the HTMLMediaElement.readyState
1311     // attribute to HAVE_METADATA.
1312     if (activeTrackFlag &amp;&amp; m_private-&gt;readyState() &gt; MediaPlayer::HaveCurrentData)
1313         m_private-&gt;setReadyState(MediaPlayer::HaveMetadata);
1314 }
1315 
1316 bool SourceBuffer::validateInitializationSegment(const InitializationSegment&amp; segment)
1317 {
1318     // FIXME: ordering of all 3.5.X (X&gt;=7) functions needs to be updated to post-[24 July 2014 Editor&#39;s Draft] version
1319     // 3.5.8 Initialization Segment Received (ctd)
1320     // https://rawgit.com/w3c/media-source/c3ad59c7a370d04430969ba73d18dc9bcde57a33/index.html#sourcebuffer-init-segment-received [Editor&#39;s Draft 09 January 2015]
1321 
1322     // Note: those are checks from step 3.1
1323     //   * The number of audio, video, and text tracks match what was in the first initialization segment.
1324     if (segment.audioTracks.size() != audioTracks().length()
1325         || segment.videoTracks.size() != videoTracks().length()
1326         || segment.textTracks.size() != textTracks().length())
1327         return false;
1328 
1329     //   * The codecs for each track, match what was specified in the first initialization segment.
1330     // (Note: Issue #155 strikes out this check. For broad compatibility when this experimental feature
1331     // is not enabled, only perform this check if the &quot;pending initialization segment for changeType flag&quot;
1332     // is not set.)
1333     for (auto&amp; audioTrackInfo : segment.audioTracks) {
1334         if (m_audioCodecs.contains(audioTrackInfo.description-&gt;codec()))
1335             continue;
1336 
1337         if (!m_pendingInitializationSegmentForChangeType)
1338             return false;
1339 
1340         m_audioCodecs.append(audioTrackInfo.description-&gt;codec());
1341     }
1342 
1343     for (auto&amp; videoTrackInfo : segment.videoTracks) {
1344         if (m_videoCodecs.contains(videoTrackInfo.description-&gt;codec()))
1345             continue;
1346 
1347         if (!m_pendingInitializationSegmentForChangeType)
1348             return false;
1349 
1350         m_videoCodecs.append(videoTrackInfo.description-&gt;codec());
1351     }
1352 
1353     for (auto&amp; textTrackInfo : segment.textTracks) {
1354         if (m_textCodecs.contains(textTrackInfo.description-&gt;codec()))
1355             continue;
1356 
1357         if (!m_pendingInitializationSegmentForChangeType)
1358             return false;
1359 
1360         m_textCodecs.append(textTrackInfo.description-&gt;codec());
1361     }
1362 
1363     //   * If more than one track for a single type are present (ie 2 audio tracks), then the Track
1364     //   IDs match the ones in the first initialization segment.
1365     if (segment.audioTracks.size() &gt;= 2) {
1366         for (auto&amp; audioTrackInfo : segment.audioTracks) {
1367             if (!m_trackBufferMap.contains(audioTrackInfo.track-&gt;id()))
1368                 return false;
1369         }
1370     }
1371 
1372     if (segment.videoTracks.size() &gt;= 2) {
1373         for (auto&amp; videoTrackInfo : segment.videoTracks) {
1374             if (!m_trackBufferMap.contains(videoTrackInfo.track-&gt;id()))
1375                 return false;
1376         }
1377     }
1378 
1379     if (segment.textTracks.size() &gt;= 2) {
1380         for (auto&amp; textTrackInfo : segment.videoTracks) {
1381             if (!m_trackBufferMap.contains(textTrackInfo.track-&gt;id()))
1382                 return false;
1383         }
1384     }
1385 
1386     return true;
1387 }
1388 
1389 class SampleLessThanComparator {
1390 public:
1391     bool operator()(std::pair&lt;MediaTime, RefPtr&lt;MediaSample&gt;&gt; value1, std::pair&lt;MediaTime, RefPtr&lt;MediaSample&gt;&gt; value2)
1392     {
1393         return value1.first &lt; value2.first;
1394     }
1395 
1396     bool operator()(MediaTime value1, std::pair&lt;MediaTime, RefPtr&lt;MediaSample&gt;&gt; value2)
1397     {
1398         return value1 &lt; value2.first;
1399     }
1400 
1401     bool operator()(std::pair&lt;MediaTime, RefPtr&lt;MediaSample&gt;&gt; value1, MediaTime value2)
1402     {
1403         return value1.first &lt; value2;
1404     }
1405 };
1406 
1407 void SourceBuffer::appendError(bool decodeErrorParam)
1408 {
1409     // 3.5.3 Append Error Algorithm
1410     // https://rawgit.com/w3c/media-source/c3ad59c7a370d04430969ba73d18dc9bcde57a33/index.html#sourcebuffer-append-error [Editor&#39;s Draft 09 January 2015]
1411 
1412     ASSERT(m_updating);
1413     // 1. Run the reset parser state algorithm.
1414     resetParserState();
1415 
1416     // 2. Set the updating attribute to false.
1417     m_updating = false;
1418 
1419     // 3. Queue a task to fire a simple event named error at this SourceBuffer object.
1420     scheduleEvent(eventNames().errorEvent);
1421 
1422     // 4. Queue a task to fire a simple event named updateend at this SourceBuffer object.
1423     scheduleEvent(eventNames().updateendEvent);
1424 
1425     // 5. If decode error is true, then run the end of stream algorithm with the error parameter set to &quot;decode&quot;.
1426     if (decodeErrorParam)
1427         m_source-&gt;streamEndedWithError(MediaSource::EndOfStreamError::Decode);
1428 }
1429 
1430 void SourceBuffer::sourceBufferPrivateDidReceiveSample(MediaSample&amp; sample)
1431 {
1432     if (isRemoved())
1433         return;
1434 
1435     // 3.5.1 Segment Parser Loop
1436     // 6.1 If the first initialization segment received flag is false, (Note: Issue # 155 &amp; changeType()
1437     // algorithm) or the  pending initialization segment for changeType flag  is true, (End note)
1438     // then run the append error algorithm
1439     //     with the decode error parameter set to true and abort this algorithm.
1440     // Note: current design makes SourceBuffer somehow ignorant of append state - it&#39;s more a thing
1441     //  of SourceBufferPrivate. That&#39;s why this check can&#39;t really be done in appendInternal.
1442     //  unless we force some kind of design with state machine switching.
1443     if (!m_receivedFirstInitializationSegment || m_pendingInitializationSegmentForChangeType) {
1444         appendError(true);
1445         return;
1446     }
1447 
1448     // 3.5.8 Coded Frame Processing
1449     // http://www.w3.org/TR/media-source/#sourcebuffer-coded-frame-processing
1450 
1451     // When complete coded frames have been parsed by the segment parser loop then the following steps
1452     // are run:
1453     // 1. For each coded frame in the media segment run the following steps:
1454     // 1.1. Loop Top
1455     do {
1456         MediaTime presentationTimestamp;
1457         MediaTime decodeTimestamp;
1458 
1459         // NOTE: this is out-of-order, but we need the timescale from the
1460         // sample&#39;s duration for timestamp generation.
1461         // 1.2 Let frame duration be a double precision floating point representation of the coded frame&#39;s
1462         // duration in seconds.
1463         MediaTime frameDuration = sample.duration();
1464 
1465         if (m_shouldGenerateTimestamps) {
1466             // ↳ If generate timestamps flag equals true:
1467             // 1. Let presentation timestamp equal 0.
1468             // NOTE: Use the duration timscale for the presentation timestamp, as this will eliminate
1469             // timescale rounding when generating timestamps.
1470             presentationTimestamp = { 0, frameDuration.timeScale() };
1471 
1472             // 2. Let decode timestamp equal 0.
1473             decodeTimestamp = { 0, frameDuration.timeScale() };
1474         } else {
1475             // ↳ Otherwise:
1476             // 1. Let presentation timestamp be a double precision floating point representation of
1477             // the coded frame&#39;s presentation timestamp in seconds.
1478             presentationTimestamp = sample.presentationTime();
1479 
1480             // 2. Let decode timestamp be a double precision floating point representation of the coded frame&#39;s
1481             // decode timestamp in seconds.
1482             decodeTimestamp = sample.decodeTime();
1483         }
1484 
1485         // 1.3 If mode equals &quot;sequence&quot; and group start timestamp is set, then run the following steps:
1486         if (m_mode == AppendMode::Sequence &amp;&amp; m_groupStartTimestamp.isValid()) {
1487             // 1.3.1 Set timestampOffset equal to group start timestamp - presentation timestamp.
1488             m_timestampOffset = m_groupStartTimestamp;
1489 
1490             for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
1491                 trackBuffer.lastFrameTimescale = 0;
1492                 trackBuffer.roundedTimestampOffset = MediaTime::invalidTime();
1493             }
1494 
1495             // 1.3.2 Set group end timestamp equal to group start timestamp.
1496             m_groupEndTimestamp = m_groupStartTimestamp;
1497 
1498             // 1.3.3 Set the need random access point flag on all track buffers to true.
1499             for (auto&amp; trackBuffer : m_trackBufferMap.values())
1500                 trackBuffer.needRandomAccessFlag = true;
1501 
1502             // 1.3.4 Unset group start timestamp.
1503             m_groupStartTimestamp = MediaTime::invalidTime();
1504         }
1505 
1506         // NOTE: this is out-of-order, but we need TrackBuffer to be able to cache the results of timestamp offset rounding
1507         // 1.5 Let track buffer equal the track buffer that the coded frame will be added to.
<a name="17" id="anc17"></a><span class="line-modified">1508         AtomicString trackID = sample.trackID();</span>
1509         auto it = m_trackBufferMap.find(trackID);
1510         if (it == m_trackBufferMap.end()) {
1511             // The client managed to append a sample with a trackID not present in the initialization
1512             // segment. This would be a good place to post an message to the developer console.
1513             didDropSample();
1514             return;
1515         }
1516         TrackBuffer&amp; trackBuffer = it-&gt;value;
1517 
1518         MediaTime microsecond(1, 1000000);
1519 
1520         auto roundTowardsTimeScaleWithRoundingMargin = [] (const MediaTime&amp; time, uint32_t timeScale, const MediaTime&amp; roundingMargin) {
1521             while (true) {
1522                 MediaTime roundedTime = time.toTimeScale(timeScale);
1523                 if (abs(roundedTime - time) &lt; roundingMargin || timeScale &gt;= MediaTime::MaximumTimeScale)
1524                     return roundedTime;
1525 
1526                 if (!WTF::safeMultiply(timeScale, 2, timeScale) || timeScale &gt; MediaTime::MaximumTimeScale)
1527                     timeScale = MediaTime::MaximumTimeScale;
1528             }
1529         };
1530 
1531         // 1.4 If timestampOffset is not 0, then run the following steps:
1532         if (m_timestampOffset) {
1533             if (!trackBuffer.roundedTimestampOffset.isValid() || presentationTimestamp.timeScale() != trackBuffer.lastFrameTimescale) {
1534                 trackBuffer.lastFrameTimescale = presentationTimestamp.timeScale();
1535                 trackBuffer.roundedTimestampOffset = roundTowardsTimeScaleWithRoundingMargin(m_timestampOffset, trackBuffer.lastFrameTimescale, microsecond);
1536             }
1537 
1538             // 1.4.1 Add timestampOffset to the presentation timestamp.
1539             presentationTimestamp += trackBuffer.roundedTimestampOffset;
1540 
1541             // 1.4.2 Add timestampOffset to the decode timestamp.
1542             decodeTimestamp += trackBuffer.roundedTimestampOffset;
1543         }
1544 
1545         // 1.6 ↳ If last decode timestamp for track buffer is set and decode timestamp is less than last
1546         // decode timestamp:
1547         // OR
1548         // ↳ If last decode timestamp for track buffer is set and the difference between decode timestamp and
1549         // last decode timestamp is greater than 2 times last frame duration:
1550         MediaTime decodeDurationToCheck = trackBuffer.greatestDecodeDuration;
1551 
1552         if (decodeDurationToCheck.isValid() &amp;&amp; trackBuffer.lastFrameDuration.isValid()
1553             &amp;&amp; (trackBuffer.lastFrameDuration &gt; decodeDurationToCheck))
1554             decodeDurationToCheck = trackBuffer.lastFrameDuration;
1555 
1556         if (trackBuffer.lastDecodeTimestamp.isValid() &amp;&amp; (decodeTimestamp &lt; trackBuffer.lastDecodeTimestamp
1557             || (decodeDurationToCheck.isValid() &amp;&amp; abs(decodeTimestamp - trackBuffer.lastDecodeTimestamp) &gt; (decodeDurationToCheck * 2)))) {
1558 
1559             // 1.6.1:
1560             if (m_mode == AppendMode::Segments) {
1561                 // ↳ If mode equals &quot;segments&quot;:
1562                 // Set group end timestamp to presentation timestamp.
1563                 m_groupEndTimestamp = presentationTimestamp;
1564             } else {
1565                 // ↳ If mode equals &quot;sequence&quot;:
1566                 // Set group start timestamp equal to the group end timestamp.
1567                 m_groupStartTimestamp = m_groupEndTimestamp;
1568             }
1569 
1570             for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
1571                 // 1.6.2 Unset the last decode timestamp on all track buffers.
1572                 trackBuffer.lastDecodeTimestamp = MediaTime::invalidTime();
1573                 // 1.6.3 Unset the last frame duration on all track buffers.
1574                 trackBuffer.greatestDecodeDuration = MediaTime::invalidTime();
1575                 trackBuffer.lastFrameDuration = MediaTime::invalidTime();
1576                 // 1.6.4 Unset the highest presentation timestamp on all track buffers.
1577                 trackBuffer.highestPresentationTimestamp = MediaTime::invalidTime();
1578                 // 1.6.5 Set the need random access point flag on all track buffers to true.
1579                 trackBuffer.needRandomAccessFlag = true;
1580             }
1581 
1582             // 1.6.6 Jump to the Loop Top step above to restart processing of the current coded frame.
1583             continue;
1584         }
1585 
1586         if (m_mode == AppendMode::Sequence) {
1587             // Use the generated timestamps instead of the sample&#39;s timestamps.
1588             sample.setTimestamps(presentationTimestamp, decodeTimestamp);
1589         } else if (trackBuffer.roundedTimestampOffset) {
1590             // Reflect the timestamp offset into the sample.
1591             sample.offsetTimestampsBy(trackBuffer.roundedTimestampOffset);
1592         }
1593 
1594         DEBUG_LOG(LOGIDENTIFIER, sample);
1595 
1596         // 1.7 Let frame end timestamp equal the sum of presentation timestamp and frame duration.
1597         MediaTime frameEndTimestamp = presentationTimestamp + frameDuration;
1598 
1599         // 1.8 If presentation timestamp is less than appendWindowStart, then set the need random access
1600         // point flag to true, drop the coded frame, and jump to the top of the loop to start processing
1601         // the next coded frame.
1602         // 1.9 If frame end timestamp is greater than appendWindowEnd, then set the need random access
1603         // point flag to true, drop the coded frame, and jump to the top of the loop to start processing
1604         // the next coded frame.
1605         if (presentationTimestamp &lt; m_appendWindowStart || frameEndTimestamp &gt; m_appendWindowEnd) {
1606             trackBuffer.needRandomAccessFlag = true;
1607             didDropSample();
1608             return;
1609         }
1610 
1611 
1612         // 1.10 If the decode timestamp is less than the presentation start time, then run the end of stream
1613         // algorithm with the error parameter set to &quot;decode&quot;, and abort these steps.
1614         // NOTE: Until &lt;https://www.w3.org/Bugs/Public/show_bug.cgi?id=27487&gt; is resolved, we will only check
1615         // the presentation timestamp.
1616         MediaTime presentationStartTime = MediaTime::zeroTime();
1617         if (presentationTimestamp &lt; presentationStartTime) {
1618             ERROR_LOG(LOGIDENTIFIER, &quot;failing because presentationTimestamp (&quot;, presentationTimestamp, &quot;) &lt; presentationStartTime (&quot;, presentationStartTime, &quot;)&quot;);
1619             m_source-&gt;streamEndedWithError(MediaSource::EndOfStreamError::Decode);
1620             return;
1621         }
1622 
1623         // 1.11 If the need random access point flag on track buffer equals true, then run the following steps:
1624         if (trackBuffer.needRandomAccessFlag) {
1625             // 1.11.1 If the coded frame is not a random access point, then drop the coded frame and jump
1626             // to the top of the loop to start processing the next coded frame.
1627             if (!sample.isSync()) {
1628                 didDropSample();
1629                 return;
1630             }
1631 
1632             // 1.11.2 Set the need random access point flag on track buffer to false.
1633             trackBuffer.needRandomAccessFlag = false;
1634         }
1635 
1636         // 1.12 Let spliced audio frame be an unset variable for holding audio splice information
1637         // 1.13 Let spliced timed text frame be an unset variable for holding timed text splice information
1638         // FIXME: Add support for sample splicing.
1639 
1640         SampleMap erasedSamples;
1641 
1642         // 1.14 If last decode timestamp for track buffer is unset and presentation timestamp falls
1643         // falls within the presentation interval of a coded frame in track buffer, then run the
1644         // following steps:
1645         if (trackBuffer.lastDecodeTimestamp.isInvalid()) {
1646             auto iter = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(presentationTimestamp);
1647             if (iter != trackBuffer.samples.presentationOrder().end()) {
1648                 // 1.14.1 Let overlapped frame be the coded frame in track buffer that matches the condition above.
1649                 RefPtr&lt;MediaSample&gt; overlappedFrame = iter-&gt;second;
1650 
1651                 // 1.14.2 If track buffer contains audio coded frames:
1652                 // Run the audio splice frame algorithm and if a splice frame is returned, assign it to
1653                 // spliced audio frame.
1654                 // FIXME: Add support for sample splicing.
1655 
1656                 // If track buffer contains video coded frames:
1657                 if (trackBuffer.description &amp;&amp; trackBuffer.description-&gt;isVideo()) {
1658                     // 1.14.2.1 Let overlapped frame presentation timestamp equal the presentation timestamp
1659                     // of overlapped frame.
1660                     MediaTime overlappedFramePresentationTimestamp = overlappedFrame-&gt;presentationTime();
1661 
1662                     // 1.14.2.2 Let remove window timestamp equal overlapped frame presentation timestamp
1663                     // plus 1 microsecond.
1664                     MediaTime removeWindowTimestamp = overlappedFramePresentationTimestamp + microsecond;
1665 
1666                     // 1.14.2.3 If the presentation timestamp is less than the remove window timestamp,
1667                     // then remove overlapped frame and any coded frames that depend on it from track buffer.
1668                     if (presentationTimestamp &lt; removeWindowTimestamp)
1669                         erasedSamples.addSample(*iter-&gt;second);
1670                 }
1671 
1672                 // If track buffer contains timed text coded frames:
1673                 // Run the text splice frame algorithm and if a splice frame is returned, assign it to spliced timed text frame.
1674                 // FIXME: Add support for sample splicing.
1675             }
1676         }
1677 
1678         // 1.15 Remove existing coded frames in track buffer:
1679         // If highest presentation timestamp for track buffer is not set:
1680         if (trackBuffer.highestPresentationTimestamp.isInvalid()) {
1681             // Remove all coded frames from track buffer that have a presentation timestamp greater than or
1682             // equal to presentation timestamp and less than frame end timestamp.
1683             auto iter_pair = trackBuffer.samples.presentationOrder().findSamplesBetweenPresentationTimes(presentationTimestamp, frameEndTimestamp);
1684             if (iter_pair.first != trackBuffer.samples.presentationOrder().end())
1685                 erasedSamples.addRange(iter_pair.first, iter_pair.second);
1686         }
1687 
1688         // There are many files out there where the frame times are not perfectly contiguous and may have small overlaps
1689         // between the beginning of a frame and the end of the previous one; therefore a tolerance is needed whenever
1690         // durations are considered.
1691         // For instance, most WebM files are muxed rounded to the millisecond (the default TimecodeScale of the format)
1692         // but their durations use a finer timescale (causing a sub-millisecond overlap). More rarely, there are also
1693         // MP4 files with slightly off tfdt boxes, presenting a similar problem at the beginning of each fragment.
1694         const MediaTime contiguousFrameTolerance = MediaTime(1, 1000);
1695 
1696         // If highest presentation timestamp for track buffer is set and less than or equal to presentation timestamp
1697         if (trackBuffer.highestPresentationTimestamp.isValid() &amp;&amp; trackBuffer.highestPresentationTimestamp - contiguousFrameTolerance &lt;= presentationTimestamp) {
1698             // Remove all coded frames from track buffer that have a presentation timestamp greater than highest
1699             // presentation timestamp and less than or equal to frame end timestamp.
1700             do {
1701                 // NOTE: Searching from the end of the trackBuffer will be vastly more efficient if the search range is
1702                 // near the end of the buffered range. Use a linear-backwards search if the search range is within one
1703                 // frame duration of the end:
1704                 unsigned bufferedLength = trackBuffer.buffered.length();
1705                 if (!bufferedLength)
1706                     break;
1707 
1708                 MediaTime highestBufferedTime = trackBuffer.buffered.maximumBufferedTime();
1709                 MediaTime eraseBeginTime = trackBuffer.highestPresentationTimestamp - contiguousFrameTolerance;
1710                 MediaTime eraseEndTime = frameEndTimestamp - contiguousFrameTolerance;
1711 
1712                 PresentationOrderSampleMap::iterator_range range;
1713                 if (highestBufferedTime - trackBuffer.highestPresentationTimestamp &lt; trackBuffer.lastFrameDuration)
1714                     // If the new frame is at the end of the buffered ranges, perform a sequential scan from end (O(1)).
1715                     range = trackBuffer.samples.presentationOrder().findSamplesBetweenPresentationTimesFromEnd(eraseBeginTime, eraseEndTime);
1716                 else
1717                     // In any other case, perform a binary search (O(log(n)).
1718                     range = trackBuffer.samples.presentationOrder().findSamplesBetweenPresentationTimes(eraseBeginTime, eraseEndTime);
1719 
1720                 if (range.first != trackBuffer.samples.presentationOrder().end())
1721                     erasedSamples.addRange(range.first, range.second);
1722             } while(false);
1723         }
1724 
1725         // 1.16 Remove decoding dependencies of the coded frames removed in the previous step:
1726         DecodeOrderSampleMap::MapType dependentSamples;
1727         if (!erasedSamples.empty()) {
1728             // If detailed information about decoding dependencies is available:
1729             // FIXME: Add support for detailed dependency information
1730 
1731             // Otherwise: Remove all coded frames between the coded frames removed in the previous step
1732             // and the next random access point after those removed frames.
1733             auto firstDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().begin()-&gt;first);
1734             auto lastDecodeIter = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(erasedSamples.decodeOrder().rbegin()-&gt;first);
1735             auto nextSyncIter = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(lastDecodeIter);
1736             dependentSamples.insert(firstDecodeIter, nextSyncIter);
1737 
1738             // NOTE: in the case of b-frames, the previous step may leave in place samples whose presentation
1739             // timestamp &lt; presentationTime, but whose decode timestamp &gt;= decodeTime. These will eventually cause
1740             // a decode error if left in place, so remove these samples as well.
1741             DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());
1742             auto samplesWithHigherDecodeTimes = trackBuffer.samples.decodeOrder().findSamplesBetweenDecodeKeys(decodeKey, erasedSamples.decodeOrder().begin()-&gt;first);
1743             if (samplesWithHigherDecodeTimes.first != samplesWithHigherDecodeTimes.second)
1744                 dependentSamples.insert(samplesWithHigherDecodeTimes.first, samplesWithHigherDecodeTimes.second);
1745 
1746             PlatformTimeRanges erasedRanges = removeSamplesFromTrackBuffer(dependentSamples, trackBuffer, this, &quot;sourceBufferPrivateDidReceiveSample&quot;);
1747 
1748             // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
1749             // not yet displayed samples.
1750             MediaTime currentMediaTime = m_source-&gt;currentTime();
1751             if (trackBuffer.lastEnqueuedPresentationTime.isValid() &amp;&amp; currentMediaTime &lt; trackBuffer.lastEnqueuedPresentationTime) {
1752                 PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.lastEnqueuedPresentationTime);
1753                 possiblyEnqueuedRanges.intersectWith(erasedRanges);
1754                 if (possiblyEnqueuedRanges.length())
1755                     trackBuffer.needsReenqueueing = true;
1756             }
1757 
1758             erasedRanges.invert();
1759             trackBuffer.buffered.intersectWith(erasedRanges);
1760             setBufferedDirty(true);
1761         }
1762 
1763         // 1.17 If spliced audio frame is set:
1764         // Add spliced audio frame to the track buffer.
1765         // If spliced timed text frame is set:
1766         // Add spliced timed text frame to the track buffer.
1767         // FIXME: Add support for sample splicing.
1768 
1769         // Otherwise:
1770         // Add the coded frame with the presentation timestamp, decode timestamp, and frame duration to the track buffer.
1771         trackBuffer.samples.addSample(sample);
1772 
1773         // Note: The terminology here is confusing: &quot;enqueuing&quot; means providing a frame to the inner media framework.
1774         // First, frames are inserted in the decode queue; later, at the end of the append all the frames in the decode
1775         // queue are &quot;enqueued&quot; (sent to the inner media framework) in `provideMediaData()`.
1776         //
1777         // In order to check whether a frame should be added to the decode queue we check whether it starts after the
1778         // lastEnqueuedDecodeKey.
1779         DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());
1780         if (trackBuffer.lastEnqueuedDecodeKey.first.isInvalid() || decodeKey &gt; trackBuffer.lastEnqueuedDecodeKey) {
1781             trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, &amp;sample));
<a name="18" id="anc18"></a>


1782         }
1783 
1784         // NOTE: the spec considers &quot;Coded Frame Duration&quot; to be the presentation duration, but this is not necessarily equal
1785         // to the decoded duration. When comparing deltas between decode timestamps, the decode duration, not the presentation.
1786         if (trackBuffer.lastDecodeTimestamp.isValid()) {
1787             MediaTime lastDecodeDuration = decodeTimestamp - trackBuffer.lastDecodeTimestamp;
1788             if (!trackBuffer.greatestDecodeDuration.isValid() || lastDecodeDuration &gt; trackBuffer.greatestDecodeDuration)
1789                 trackBuffer.greatestDecodeDuration = lastDecodeDuration;
1790         }
1791 
1792         // 1.18 Set last decode timestamp for track buffer to decode timestamp.
1793         trackBuffer.lastDecodeTimestamp = decodeTimestamp;
1794 
1795         // 1.19 Set last frame duration for track buffer to frame duration.
1796         trackBuffer.lastFrameDuration = frameDuration;
1797 
1798         // 1.20 If highest presentation timestamp for track buffer is unset or frame end timestamp is greater
1799         // than highest presentation timestamp, then set highest presentation timestamp for track buffer
1800         // to frame end timestamp.
1801         if (trackBuffer.highestPresentationTimestamp.isInvalid() || frameEndTimestamp &gt; trackBuffer.highestPresentationTimestamp)
1802             trackBuffer.highestPresentationTimestamp = frameEndTimestamp;
1803 
1804         // 1.21 If frame end timestamp is greater than group end timestamp, then set group end timestamp equal
1805         // to frame end timestamp.
1806         if (m_groupEndTimestamp.isInvalid() || frameEndTimestamp &gt; m_groupEndTimestamp)
1807             m_groupEndTimestamp = frameEndTimestamp;
1808 
1809         // 1.22 If generate timestamps flag equals true, then set timestampOffset equal to frame end timestamp.
1810         if (m_shouldGenerateTimestamps) {
1811             m_timestampOffset = frameEndTimestamp;
1812             for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
1813                 trackBuffer.lastFrameTimescale = 0;
1814                 trackBuffer.roundedTimestampOffset = MediaTime::invalidTime();
1815             }
1816         }
1817 
1818         // Eliminate small gaps between buffered ranges by coalescing
1819         // disjoint ranges separated by less than a &quot;fudge factor&quot;.
1820         auto presentationEndTime = presentationTimestamp + frameDuration;
1821         auto nearestToPresentationStartTime = trackBuffer.buffered.nearest(presentationTimestamp);
1822         if (nearestToPresentationStartTime.isValid() &amp;&amp; (presentationTimestamp - nearestToPresentationStartTime).isBetween(MediaTime::zeroTime(), MediaSource::currentTimeFudgeFactor()))
1823             presentationTimestamp = nearestToPresentationStartTime;
1824 
1825         auto nearestToPresentationEndTime = trackBuffer.buffered.nearest(presentationEndTime);
1826         if (nearestToPresentationEndTime.isValid() &amp;&amp; (nearestToPresentationEndTime - presentationEndTime).isBetween(MediaTime::zeroTime(), MediaSource::currentTimeFudgeFactor()))
1827             presentationEndTime = nearestToPresentationEndTime;
1828 
1829         trackBuffer.buffered.add(presentationTimestamp, presentationEndTime);
1830         m_bufferedSinceLastMonitor += frameDuration.toDouble();
1831         setBufferedDirty(true);
1832 
1833         break;
1834     } while (1);
1835 
1836     // Steps 2-4 will be handled by MediaSource::monitorSourceBuffers()
1837 
1838     // 5. If the media segment contains data beyond the current duration, then run the duration change algorithm with new
1839     // duration set to the maximum of the current duration and the group end timestamp.
1840     if (m_groupEndTimestamp &gt; m_source-&gt;duration())
1841         m_source-&gt;setDurationInternal(m_groupEndTimestamp);
1842 }
1843 
1844 bool SourceBuffer::hasAudio() const
1845 {
1846     return m_audioTracks &amp;&amp; m_audioTracks-&gt;length();
1847 }
1848 
1849 bool SourceBuffer::hasVideo() const
1850 {
1851     return m_videoTracks &amp;&amp; m_videoTracks-&gt;length();
1852 }
1853 
1854 bool SourceBuffer::sourceBufferPrivateHasAudio() const
1855 {
1856     return hasAudio();
1857 }
1858 
1859 bool SourceBuffer::sourceBufferPrivateHasVideo() const
1860 {
1861     return hasVideo();
1862 }
1863 
1864 void SourceBuffer::videoTrackSelectedChanged(VideoTrack&amp; track)
1865 {
1866     // 2.4.5 Changes to selected/enabled track state
1867     // If the selected video track changes, then run the following steps:
1868     // 1. If the SourceBuffer associated with the previously selected video track is not associated with
1869     // any other enabled tracks, run the following steps:
1870     if (!track.selected()
1871         &amp;&amp; (!m_videoTracks || !m_videoTracks-&gt;isAnyTrackEnabled())
1872         &amp;&amp; (!m_audioTracks || !m_audioTracks-&gt;isAnyTrackEnabled())
1873         &amp;&amp; (!m_textTracks || !m_textTracks-&gt;isAnyTrackEnabled())) {
1874         // 1.1 Remove the SourceBuffer from activeSourceBuffers.
1875         // 1.2 Queue a task to fire a simple event named removesourcebuffer at activeSourceBuffers
1876         setActive(false);
1877     } else if (track.selected()) {
1878         // 2. If the SourceBuffer associated with the newly selected video track is not already in activeSourceBuffers,
1879         // run the following steps:
1880         // 2.1 Add the SourceBuffer to activeSourceBuffers.
1881         // 2.2 Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
1882         setActive(true);
1883     }
1884 
1885     if (m_videoTracks &amp;&amp; m_videoTracks-&gt;contains(track))
1886         m_videoTracks-&gt;scheduleChangeEvent();
1887 
1888     if (!isRemoved())
1889         m_source-&gt;mediaElement()-&gt;videoTrackSelectedChanged(track);
1890 }
1891 
1892 void SourceBuffer::audioTrackEnabledChanged(AudioTrack&amp; track)
1893 {
1894     // 2.4.5 Changes to selected/enabled track state
1895     // If an audio track becomes disabled and the SourceBuffer associated with this track is not
1896     // associated with any other enabled or selected track, then run the following steps:
1897     if (!track.enabled()
1898         &amp;&amp; (!m_videoTracks || !m_videoTracks-&gt;isAnyTrackEnabled())
1899         &amp;&amp; (!m_audioTracks || !m_audioTracks-&gt;isAnyTrackEnabled())
1900         &amp;&amp; (!m_textTracks || !m_textTracks-&gt;isAnyTrackEnabled())) {
1901         // 1. Remove the SourceBuffer associated with the audio track from activeSourceBuffers
1902         // 2. Queue a task to fire a simple event named removesourcebuffer at activeSourceBuffers
1903         setActive(false);
1904     } else if (track.enabled()) {
1905         // If an audio track becomes enabled and the SourceBuffer associated with this track is
1906         // not already in activeSourceBuffers, then run the following steps:
1907         // 1. Add the SourceBuffer associated with the audio track to activeSourceBuffers
1908         // 2. Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
1909         setActive(true);
1910     }
1911 
1912     if (m_audioTracks &amp;&amp; m_audioTracks-&gt;contains(track))
1913         m_audioTracks-&gt;scheduleChangeEvent();
1914 
1915     if (!isRemoved())
1916         m_source-&gt;mediaElement()-&gt;audioTrackEnabledChanged(track);
1917 }
1918 
1919 void SourceBuffer::textTrackModeChanged(TextTrack&amp; track)
1920 {
1921     // 2.4.5 Changes to selected/enabled track state
1922     // If a text track mode becomes &quot;disabled&quot; and the SourceBuffer associated with this track is not
1923     // associated with any other enabled or selected track, then run the following steps:
1924     if (track.mode() == TextTrack::Mode::Disabled
1925         &amp;&amp; (!m_videoTracks || !m_videoTracks-&gt;isAnyTrackEnabled())
1926         &amp;&amp; (!m_audioTracks || !m_audioTracks-&gt;isAnyTrackEnabled())
1927         &amp;&amp; (!m_textTracks || !m_textTracks-&gt;isAnyTrackEnabled())) {
1928         // 1. Remove the SourceBuffer associated with the audio track from activeSourceBuffers
1929         // 2. Queue a task to fire a simple event named removesourcebuffer at activeSourceBuffers
1930         setActive(false);
1931     } else {
1932         // If a text track mode becomes &quot;showing&quot; or &quot;hidden&quot; and the SourceBuffer associated with this
1933         // track is not already in activeSourceBuffers, then run the following steps:
1934         // 1. Add the SourceBuffer associated with the text track to activeSourceBuffers
1935         // 2. Queue a task to fire a simple event named addsourcebuffer at activeSourceBuffers
1936         setActive(true);
1937     }
1938 
1939     if (m_textTracks &amp;&amp; m_textTracks-&gt;contains(track))
1940         m_textTracks-&gt;scheduleChangeEvent();
1941 
1942     if (!isRemoved())
1943         m_source-&gt;mediaElement()-&gt;textTrackModeChanged(track);
1944 }
1945 
1946 void SourceBuffer::textTrackAddCue(TextTrack&amp; track, TextTrackCue&amp; cue)
1947 {
1948     if (!isRemoved())
1949         m_source-&gt;mediaElement()-&gt;textTrackAddCue(track, cue);
1950 }
1951 
1952 void SourceBuffer::textTrackAddCues(TextTrack&amp; track, const TextTrackCueList&amp; cueList)
1953 {
1954     if (!isRemoved())
1955         m_source-&gt;mediaElement()-&gt;textTrackAddCues(track, cueList);
1956 }
1957 
1958 void SourceBuffer::textTrackRemoveCue(TextTrack&amp; track, TextTrackCue&amp; cue)
1959 {
1960     if (!isRemoved())
1961         m_source-&gt;mediaElement()-&gt;textTrackRemoveCue(track, cue);
1962 }
1963 
1964 void SourceBuffer::textTrackRemoveCues(TextTrack&amp; track, const TextTrackCueList&amp; cueList)
1965 {
1966     if (!isRemoved())
1967         m_source-&gt;mediaElement()-&gt;textTrackRemoveCues(track, cueList);
1968 }
1969 
1970 void SourceBuffer::textTrackKindChanged(TextTrack&amp; track)
1971 {
1972     if (!isRemoved())
1973         m_source-&gt;mediaElement()-&gt;textTrackKindChanged(track);
1974 }
1975 
<a name="19" id="anc19"></a><span class="line-modified">1976 void SourceBuffer::sourceBufferPrivateReenqueSamples(const AtomicString&amp; trackID)</span>
1977 {
1978     if (isRemoved())
1979         return;
1980 
1981     DEBUG_LOG(LOGIDENTIFIER);
1982     auto it = m_trackBufferMap.find(trackID);
1983     if (it == m_trackBufferMap.end())
1984         return;
1985 
1986     auto&amp; trackBuffer = it-&gt;value;
1987     trackBuffer.needsReenqueueing = true;
1988     reenqueueMediaForTime(trackBuffer, trackID, m_source-&gt;currentTime());
1989 }
1990 
<a name="20" id="anc20"></a><span class="line-modified">1991 void SourceBuffer::sourceBufferPrivateDidBecomeReadyForMoreSamples(const AtomicString&amp; trackID)</span>
1992 {
1993     if (isRemoved())
1994         return;
1995 
1996     DEBUG_LOG(LOGIDENTIFIER);
1997     auto it = m_trackBufferMap.find(trackID);
1998     if (it == m_trackBufferMap.end())
1999         return;
2000 
2001     auto&amp; trackBuffer = it-&gt;value;
2002     if (!trackBuffer.needsReenqueueing &amp;&amp; !m_source-&gt;isSeeking())
2003         provideMediaData(trackBuffer, trackID);
2004 }
2005 
<a name="21" id="anc21"></a><span class="line-modified">2006 void SourceBuffer::provideMediaData(TrackBuffer&amp; trackBuffer, const AtomicString&amp; trackID)</span>
2007 {
2008     if (m_source-&gt;isSeeking())
2009         return;
2010 
2011 #if !RELEASE_LOG_DISABLED
2012     unsigned enqueuedSamples = 0;
2013 #endif
2014 
<a name="22" id="anc22"></a>


2015     while (!trackBuffer.decodeQueue.empty()) {
2016         if (!m_private-&gt;isReadyForMoreSamples(trackID)) {
<a name="23" id="anc23"></a>
2017             m_private-&gt;notifyClientWhenReadyForMoreSamples(trackID);
2018             break;
2019         }
2020 
2021         // FIXME(rdar://problem/20635969): Remove this re-entrancy protection when the aforementioned radar is resolved; protecting
2022         // against re-entrancy introduces a small inefficency when removing appended samples from the decode queue one at a time
2023         // rather than when all samples have been enqueued.
2024         auto sample = trackBuffer.decodeQueue.begin()-&gt;second;
2025 
2026         // Do not enqueue samples spanning a significant unbuffered gap.
2027         // NOTE: one second is somewhat arbitrary. MediaSource::monitorSourceBuffers() is run
2028         // on the playbackTimer, which is effectively every 350ms. Allowing &gt; 350ms gap between
2029         // enqueued samples allows for situations where we overrun the end of a buffered range
2030         // but don&#39;t notice for 350s of playback time, and the client can enqueue data for the
2031         // new current time without triggering this early return.
2032         // FIXME(135867): Make this gap detection logic less arbitrary.
2033         MediaTime oneSecond(1, 1);
2034         if (trackBuffer.lastEnqueuedDecodeKey.first.isValid()
2035             &amp;&amp; trackBuffer.lastEnqueuedDecodeDuration.isValid()
<a name="24" id="anc24"></a><span class="line-modified">2036             &amp;&amp; sample-&gt;decodeTime() - trackBuffer.lastEnqueuedDecodeKey.first &gt; oneSecond + trackBuffer.lastEnqueuedDecodeDuration)</span>


2037             break;
<a name="25" id="anc25"></a>
2038 
2039         // Remove the sample from the decode queue now.
2040         trackBuffer.decodeQueue.erase(trackBuffer.decodeQueue.begin());
2041 
2042         trackBuffer.lastEnqueuedPresentationTime = sample-&gt;presentationTime();
2043         trackBuffer.lastEnqueuedDecodeKey = {sample-&gt;decodeTime(), sample-&gt;presentationTime()};
2044         trackBuffer.lastEnqueuedDecodeDuration = sample-&gt;duration();
2045         m_private-&gt;enqueueSample(sample.releaseNonNull(), trackID);
2046 #if !RELEASE_LOG_DISABLED
2047         ++enqueuedSamples;
2048 #endif
2049     }
2050 
<a name="26" id="anc26"></a>

2051 #if !RELEASE_LOG_DISABLED
<a name="27" id="anc27"></a><span class="line-modified">2052     DEBUG_LOG(LOGIDENTIFIER, &quot;Enqueued &quot;, enqueuedSamples, &quot; samples, &quot;, static_cast&lt;size_t&gt;(trackBuffer.decodeQueue.size()), &quot; remaining&quot;);</span>
2053 #endif
2054 
2055     trySignalAllSamplesInTrackEnqueued(trackID);
2056 }
2057 
<a name="28" id="anc28"></a><span class="line-modified">2058 void SourceBuffer::trySignalAllSamplesInTrackEnqueued(const AtomicString&amp; trackID)</span>



































2059 {
2060     if (m_source-&gt;isEnded() &amp;&amp; m_trackBufferMap.get(trackID).decodeQueue.empty()) {
<a name="29" id="anc29"></a><span class="line-modified">2061         DEBUG_LOG(LOGIDENTIFIER, &quot;All samples in track &quot;, trackID, &quot; enqueued&quot;);</span>
2062         m_private-&gt;allSamplesInTrackEnqueued(trackID);
2063     }
2064 }
2065 
2066 void SourceBuffer::trySignalAllSamplesEnqueued()
2067 {
<a name="30" id="anc30"></a><span class="line-modified">2068     for (const AtomicString&amp; trackID : m_trackBufferMap.keys())</span>
2069         trySignalAllSamplesInTrackEnqueued(trackID);
2070 }
2071 
<a name="31" id="anc31"></a><span class="line-modified">2072 void SourceBuffer::reenqueueMediaForTime(TrackBuffer&amp; trackBuffer, const AtomicString&amp; trackID, const MediaTime&amp; time)</span>
2073 {
2074     m_private-&gt;flush(trackID);
2075     trackBuffer.decodeQueue.clear();
2076 
2077     // Find the sample which contains the current presentation time.
2078     auto currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
2079 
2080     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end())
2081         currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleStartingOnOrAfterPresentationTime(time);
2082 
2083     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end()
2084         || (currentSamplePTSIterator-&gt;first - time) &gt; MediaSource::currentTimeFudgeFactor())
2085         return;
2086 
2087     // Seach backward for the previous sync sample.
2088     DecodeOrderSampleMap::KeyType decodeKey(currentSamplePTSIterator-&gt;second-&gt;decodeTime(), currentSamplePTSIterator-&gt;second-&gt;presentationTime());
2089     auto currentSampleDTSIterator = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
2090     ASSERT(currentSampleDTSIterator != trackBuffer.samples.decodeOrder().end());
2091 
2092     auto reverseCurrentSampleIter = --DecodeOrderSampleMap::reverse_iterator(currentSampleDTSIterator);
2093     auto reverseLastSyncSampleIter = trackBuffer.samples.decodeOrder().findSyncSamplePriorToDecodeIterator(reverseCurrentSampleIter);
2094     if (reverseLastSyncSampleIter == trackBuffer.samples.decodeOrder().rend())
2095         return;
2096 
2097     // Fill the decode queue with the non-displaying samples.
2098     for (auto iter = reverseLastSyncSampleIter; iter != reverseCurrentSampleIter; --iter) {
2099         auto copy = iter-&gt;second-&gt;createNonDisplayingCopy();
2100         DecodeOrderSampleMap::KeyType decodeKey(copy-&gt;decodeTime(), copy-&gt;presentationTime());
2101         trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, WTFMove(copy)));
2102     }
2103 
2104     if (!trackBuffer.decodeQueue.empty()) {
2105         auto lastSampleIter = trackBuffer.decodeQueue.rbegin();
2106         auto lastSampleDecodeKey = lastSampleIter-&gt;first;
2107         auto lastSampleDuration = lastSampleIter-&gt;second-&gt;duration();
2108         trackBuffer.lastEnqueuedPresentationTime = lastSampleDecodeKey.second;
2109         trackBuffer.lastEnqueuedDecodeKey = lastSampleDecodeKey;
2110         trackBuffer.lastEnqueuedDecodeDuration = lastSampleDuration;
2111     } else {
2112         trackBuffer.lastEnqueuedPresentationTime = MediaTime::invalidTime();
2113         trackBuffer.lastEnqueuedDecodeKey = {MediaTime::invalidTime(), MediaTime::invalidTime()};
2114         trackBuffer.lastEnqueuedDecodeDuration = MediaTime::invalidTime();
2115     }
2116 
2117     // Fill the decode queue with the remaining samples.
2118     for (auto iter = currentSampleDTSIterator; iter != trackBuffer.samples.decodeOrder().end(); ++iter)
2119         trackBuffer.decodeQueue.insert(*iter);
2120     provideMediaData(trackBuffer, trackID);
2121 
2122     trackBuffer.needsReenqueueing = false;
2123 }
2124 
2125 
2126 void SourceBuffer::didDropSample()
2127 {
2128     if (!isRemoved())
2129         m_source-&gt;mediaElement()-&gt;incrementDroppedFrameCount();
2130 }
2131 
2132 void SourceBuffer::monitorBufferingRate()
2133 {
2134     MonotonicTime now = MonotonicTime::now();
2135     Seconds interval = now - m_timeOfBufferingMonitor;
2136     double rateSinceLastMonitor = m_bufferedSinceLastMonitor / interval.seconds();
2137 
2138     m_timeOfBufferingMonitor = now;
2139     m_bufferedSinceLastMonitor = 0;
2140 
2141     m_averageBufferRate += (interval.seconds() * ExponentialMovingAverageCoefficient) * (rateSinceLastMonitor - m_averageBufferRate);
2142 
2143     DEBUG_LOG(LOGIDENTIFIER, m_averageBufferRate);
2144 }
2145 
2146 void SourceBuffer::updateBufferedFromTrackBuffers()
2147 {
2148     // 3.1 Attributes, buffered
2149     // https://rawgit.com/w3c/media-source/45627646344eea0170dd1cbc5a3d508ca751abb8/media-source-respec.html#dom-sourcebuffer-buffered
2150 
2151     // 2. Let highest end time be the largest track buffer ranges end time across all the track buffers managed by this SourceBuffer object.
2152     MediaTime highestEndTime = MediaTime::negativeInfiniteTime();
2153     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
2154         if (!trackBuffer.buffered.length())
2155             continue;
2156         highestEndTime = std::max(highestEndTime, trackBuffer.buffered.maximumBufferedTime());
2157     }
2158 
2159     // NOTE: Short circuit the following if none of the TrackBuffers have buffered ranges to avoid generating
2160     // a single range of {0, 0}.
2161     if (highestEndTime.isNegativeInfinite()) {
2162         m_buffered-&gt;ranges() = PlatformTimeRanges();
2163         return;
2164     }
2165 
2166     // 3. Let intersection ranges equal a TimeRange object containing a single range from 0 to highest end time.
2167     PlatformTimeRanges intersectionRanges { MediaTime::zeroTime(), highestEndTime };
2168 
2169     // 4. For each audio and video track buffer managed by this SourceBuffer, run the following steps:
2170     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
2171         // 4.1 Let track ranges equal the track buffer ranges for the current track buffer.
2172         PlatformTimeRanges trackRanges = trackBuffer.buffered;
2173         if (!trackRanges.length())
2174             continue;
2175 
2176         // 4.2 If readyState is &quot;ended&quot;, then set the end time on the last range in track ranges to highest end time.
2177         if (m_source-&gt;isEnded())
2178             trackRanges.add(trackRanges.maximumBufferedTime(), highestEndTime);
2179 
2180         // 4.3 Let new intersection ranges equal the intersection between the intersection ranges and the track ranges.
2181         // 4.4 Replace the ranges in intersection ranges with the new intersection ranges.
2182         intersectionRanges.intersectWith(trackRanges);
2183     }
2184 
2185     // 5. If intersection ranges does not contain the exact same range information as the current value of this attribute,
2186     //    then update the current value of this attribute to intersection ranges.
2187     m_buffered-&gt;ranges() = intersectionRanges;
2188     setBufferedDirty(true);
2189 }
2190 
2191 bool SourceBuffer::canPlayThroughRange(PlatformTimeRanges&amp; ranges)
2192 {
2193     if (isRemoved())
2194         return false;
2195 
2196     monitorBufferingRate();
2197 
2198     // Assuming no fluctuations in the buffering rate, loading 1 second per second or greater
2199     // means indefinite playback. This could be improved by taking jitter into account.
2200     if (m_averageBufferRate &gt; 1)
2201         return true;
2202 
2203     // Add up all the time yet to be buffered.
2204     MediaTime currentTime = m_source-&gt;currentTime();
2205     MediaTime duration = m_source-&gt;duration();
2206 
2207     PlatformTimeRanges unbufferedRanges = ranges;
2208     unbufferedRanges.invert();
2209     unbufferedRanges.intersectWith(PlatformTimeRanges(currentTime, std::max(currentTime, duration)));
2210     MediaTime unbufferedTime = unbufferedRanges.totalDuration();
2211     if (!unbufferedTime.isValid())
2212         return true;
2213 
2214     MediaTime timeRemaining = duration - currentTime;
2215     return unbufferedTime.toDouble() / m_averageBufferRate &lt; timeRemaining.toDouble();
2216 }
2217 
2218 size_t SourceBuffer::extraMemoryCost() const
2219 {
2220     size_t extraMemoryCost = m_pendingAppendData.capacity();
2221     for (auto&amp; trackBuffer : m_trackBufferMap.values())
2222         extraMemoryCost += trackBuffer.samples.sizeInBytes();
2223 
2224     return extraMemoryCost;
2225 }
2226 
2227 void SourceBuffer::reportExtraMemoryAllocated()
2228 {
2229     size_t extraMemoryCost = this-&gt;extraMemoryCost();
2230     if (extraMemoryCost &lt;= m_reportedExtraMemoryCost)
2231         return;
2232 
2233     size_t extraMemoryCostDelta = extraMemoryCost - m_reportedExtraMemoryCost;
2234     m_reportedExtraMemoryCost = extraMemoryCost;
2235 
2236     JSC::JSLockHolder lock(scriptExecutionContext()-&gt;vm());
2237     // FIXME: Adopt reportExtraMemoryVisited, and switch to reportExtraMemoryAllocated.
2238     // https://bugs.webkit.org/show_bug.cgi?id=142595
2239     scriptExecutionContext()-&gt;vm().heap.deprecatedReportExtraMemory(extraMemoryCostDelta);
2240 }
2241 
<a name="32" id="anc32"></a><span class="line-modified">2242 Vector&lt;String&gt; SourceBuffer::bufferedSamplesForTrackID(const AtomicString&amp; trackID)</span>
2243 {
2244     auto it = m_trackBufferMap.find(trackID);
2245     if (it == m_trackBufferMap.end())
2246         return Vector&lt;String&gt;();
2247 
2248     TrackBuffer&amp; trackBuffer = it-&gt;value;
2249     Vector&lt;String&gt; sampleDescriptions;
2250     for (auto&amp; pair : trackBuffer.samples.decodeOrder())
2251         sampleDescriptions.append(toString(*pair.second));
2252 
2253     return sampleDescriptions;
2254 }
2255 
<a name="33" id="anc33"></a><span class="line-modified">2256 Vector&lt;String&gt; SourceBuffer::enqueuedSamplesForTrackID(const AtomicString&amp; trackID)</span>
2257 {
2258     return m_private-&gt;enqueuedSamplesForTrackID(trackID);
2259 }
2260 
<a name="34" id="anc34"></a>









2261 Document&amp; SourceBuffer::document() const
2262 {
2263     ASSERT(scriptExecutionContext());
2264     return downcast&lt;Document&gt;(*scriptExecutionContext());
2265 }
2266 
2267 ExceptionOr&lt;void&gt; SourceBuffer::setMode(AppendMode newMode)
2268 {
2269     // 3.1 Attributes - mode
2270     // http://www.w3.org/TR/media-source/#widl-SourceBuffer-mode
2271 
2272     // On setting, run the following steps:
2273 
2274     // 1. Let new mode equal the new value being assigned to this attribute.
2275     // 2. If generate timestamps flag equals true and new mode equals &quot;segments&quot;, then throw an InvalidAccessError exception and abort these steps.
2276     if (m_shouldGenerateTimestamps &amp;&amp; newMode == AppendMode::Segments)
2277         return Exception { InvalidAccessError };
2278 
2279     // 3. If this object has been removed from the sourceBuffers attribute of the parent media source, then throw an InvalidStateError exception and abort these steps.
2280     // 4. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
2281     if (isRemoved() || m_updating)
2282         return Exception { InvalidStateError };
2283 
2284     // 5. If the readyState attribute of the parent media source is in the &quot;ended&quot; state then run the following steps:
2285     if (m_source-&gt;isEnded()) {
2286         // 5.1. Set the readyState attribute of the parent media source to &quot;open&quot;
2287         // 5.2. Queue a task to fire a simple event named sourceopen at the parent media source.
2288         m_source-&gt;openIfInEndedState();
2289     }
2290 
2291     // 6. If the append state equals PARSING_MEDIA_SEGMENT, then throw an InvalidStateError and abort these steps.
2292     if (m_appendState == ParsingMediaSegment)
2293         return Exception { InvalidStateError };
2294 
2295     // 7. If the new mode equals &quot;sequence&quot;, then set the group start timestamp to the group end timestamp.
2296     if (newMode == AppendMode::Sequence)
2297         m_groupStartTimestamp = m_groupEndTimestamp;
2298 
2299     // 8. Update the attribute to new mode.
2300     m_mode = newMode;
2301 
2302     return { };
2303 }
2304 
2305 #if !RELEASE_LOG_DISABLED
2306 WTFLogChannel&amp; SourceBuffer::logChannel() const
2307 {
2308     return LogMediaSource;
2309 }
2310 #endif
2311 
2312 } // namespace WebCore
2313 
2314 #endif
<a name="35" id="anc35"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="35" type="hidden" />
</body>
</html>