<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JIT.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (C) 2008-2018 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #if ENABLE(JIT)
 29 
 30 // We&#39;ve run into some problems where changing the size of the class JIT leads to
 31 // performance fluctuations. Try forcing alignment in an attempt to stabilize this.
 32 #if COMPILER(GCC_COMPATIBLE)
 33 #define JIT_CLASS_ALIGNMENT alignas(32)
 34 #else
 35 #define JIT_CLASS_ALIGNMENT
 36 #endif
 37 
 38 #define ASSERT_JIT_OFFSET(actual, expected) ASSERT_WITH_MESSAGE(actual == expected, &quot;JIT Offset \&quot;%s\&quot; should be %d, not %d.\n&quot;, #expected, static_cast&lt;int&gt;(expected), static_cast&lt;int&gt;(actual));
 39 
 40 #include &quot;CodeBlock.h&quot;
 41 #include &quot;CommonSlowPaths.h&quot;
 42 #include &quot;JITDisassembler.h&quot;
 43 #include &quot;JITInlineCacheGenerator.h&quot;
 44 #include &quot;JITMathIC.h&quot;
 45 #include &quot;JITRightShiftGenerator.h&quot;
 46 #include &quot;JSInterfaceJIT.h&quot;
 47 #include &quot;PCToCodeOriginMap.h&quot;
 48 #include &quot;UnusedPointer.h&quot;
 49 
 50 namespace JSC {
 51 
 52     enum OpcodeID : unsigned;
 53 
 54     class ArrayAllocationProfile;
 55     class CallLinkInfo;
 56     class CodeBlock;
 57     class FunctionExecutable;
 58     class JIT;
 59     class Identifier;
 60     class Interpreter;
 61     class BlockDirectory;
 62     class Register;
 63     class StructureChain;
 64     class StructureStubInfo;
 65 
 66     struct Instruction;
 67     struct OperandTypes;
 68     struct SimpleJumpTable;
 69     struct StringJumpTable;
 70 
 71     struct CallRecord {
 72         MacroAssembler::Call from;
 73         unsigned bytecodeOffset;
 74         FunctionPtr&lt;OperationPtrTag&gt; callee;
 75 
 76         CallRecord()
 77         {
 78         }
 79 
 80         CallRecord(MacroAssembler::Call from, unsigned bytecodeOffset, FunctionPtr&lt;OperationPtrTag&gt; callee)
 81             : from(from)
 82             , bytecodeOffset(bytecodeOffset)
 83             , callee(callee)
 84         {
 85         }
 86     };
 87 
 88     struct JumpTable {
 89         MacroAssembler::Jump from;
 90         unsigned toBytecodeOffset;
 91 
 92         JumpTable(MacroAssembler::Jump f, unsigned t)
 93             : from(f)
 94             , toBytecodeOffset(t)
 95         {
 96         }
 97     };
 98 
 99     struct SlowCaseEntry {
100         MacroAssembler::Jump from;
101         unsigned to;
102 
103         SlowCaseEntry(MacroAssembler::Jump f, unsigned t)
104             : from(f)
105             , to(t)
106         {
107         }
108     };
109 
110     struct SwitchRecord {
111         enum Type {
112             Immediate,
113             Character,
114             String
115         };
116 
117         Type type;
118 
119         union {
120             SimpleJumpTable* simpleJumpTable;
121             StringJumpTable* stringJumpTable;
122         } jumpTable;
123 
124         unsigned bytecodeOffset;
125         unsigned defaultOffset;
126 
127         SwitchRecord(SimpleJumpTable* jumpTable, unsigned bytecodeOffset, unsigned defaultOffset, Type type)
128             : type(type)
129             , bytecodeOffset(bytecodeOffset)
130             , defaultOffset(defaultOffset)
131         {
132             this-&gt;jumpTable.simpleJumpTable = jumpTable;
133         }
134 
135         SwitchRecord(StringJumpTable* jumpTable, unsigned bytecodeOffset, unsigned defaultOffset)
136             : type(String)
137             , bytecodeOffset(bytecodeOffset)
138             , defaultOffset(defaultOffset)
139         {
140             this-&gt;jumpTable.stringJumpTable = jumpTable;
141         }
142     };
143 
144     struct ByValCompilationInfo {
145         ByValCompilationInfo() { }
146 
147         ByValCompilationInfo(ByValInfo* byValInfo, unsigned bytecodeIndex, MacroAssembler::PatchableJump notIndexJump, MacroAssembler::PatchableJump badTypeJump, JITArrayMode arrayMode, ArrayProfile* arrayProfile, MacroAssembler::Label doneTarget, MacroAssembler::Label nextHotPathTarget)
148             : byValInfo(byValInfo)
149             , bytecodeIndex(bytecodeIndex)
150             , notIndexJump(notIndexJump)
151             , badTypeJump(badTypeJump)
152             , arrayMode(arrayMode)
153             , arrayProfile(arrayProfile)
154             , doneTarget(doneTarget)
155             , nextHotPathTarget(nextHotPathTarget)
156         {
157         }
158 
159         ByValInfo* byValInfo;
160         unsigned bytecodeIndex;
161         MacroAssembler::PatchableJump notIndexJump;
162         MacroAssembler::PatchableJump badTypeJump;
163         JITArrayMode arrayMode;
164         ArrayProfile* arrayProfile;
165         MacroAssembler::Label doneTarget;
166         MacroAssembler::Label nextHotPathTarget;
167         MacroAssembler::Label slowPathTarget;
168         MacroAssembler::Call returnAddress;
169     };
170 
171     struct CallCompilationInfo {
172         MacroAssembler::DataLabelPtr hotPathBegin;
173         MacroAssembler::Call hotPathOther;
174         MacroAssembler::Call callReturnLocation;
175         CallLinkInfo* callLinkInfo;
176     };
177 
178     void ctiPatchCallByReturnAddress(ReturnAddressPtr, FunctionPtr&lt;CFunctionPtrTag&gt; newCalleeFunction);
179 
180     class JIT_CLASS_ALIGNMENT JIT : private JSInterfaceJIT {
181         friend class JITSlowPathCall;
182         friend class JITStubCall;
183 
184         using MacroAssembler::Jump;
185         using MacroAssembler::JumpList;
186         using MacroAssembler::Label;
187 
188         static const uintptr_t patchGetByIdDefaultStructure = unusedPointer;
189         static const int patchGetByIdDefaultOffset = 0;
190         // Magic number - initial offset cannot be representable as a signed 8bit value, or the X86Assembler
191         // will compress the displacement, and we may not be able to fit a patched offset.
192         static const int patchPutByIdDefaultOffset = 256;
193 
194     public:
<a name="2" id="anc2"></a><span class="line-modified">195         JIT(VM*, CodeBlock* = 0, unsigned loopOSREntryBytecodeOffset = 0);</span>
196         ~JIT();
197 
<a name="3" id="anc3"></a>

198         void compileWithoutLinking(JITCompilationEffort);
199         CompilationResult link();
200 
201         void doMainThreadPreparationBeforeCompile();
202 
<a name="4" id="anc4"></a><span class="line-modified">203         static CompilationResult compile(VM* vm, CodeBlock* codeBlock, JITCompilationEffort effort, unsigned bytecodeOffset = 0)</span>
204         {
205             return JIT(vm, codeBlock, bytecodeOffset).privateCompile(effort);
206         }
207 
<a name="5" id="anc5"></a><span class="line-modified">208         static void compileGetByVal(const ConcurrentJSLocker&amp; locker, VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
209         {
210             JIT jit(vm, codeBlock);
211             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
212             jit.privateCompileGetByVal(locker, byValInfo, returnAddress, arrayMode);
213         }
214 
<a name="6" id="anc6"></a><span class="line-modified">215         static void compileGetByValWithCachedId(VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, const Identifier&amp; propertyName)</span>
216         {
217             JIT jit(vm, codeBlock);
218             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
219             jit.privateCompileGetByValWithCachedId(byValInfo, returnAddress, propertyName);
220         }
221 
<a name="7" id="anc7"></a><span class="line-modified">222         static void compilePutByVal(const ConcurrentJSLocker&amp; locker, VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
223         {
224             JIT jit(vm, codeBlock);
225             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
226             jit.privateCompilePutByVal&lt;OpPutByVal&gt;(locker, byValInfo, returnAddress, arrayMode);
227         }
228 
<a name="8" id="anc8"></a><span class="line-modified">229         static void compileDirectPutByVal(const ConcurrentJSLocker&amp; locker, VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
230         {
231             JIT jit(vm, codeBlock);
232             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
233             jit.privateCompilePutByVal&lt;OpPutByValDirect&gt;(locker, byValInfo, returnAddress, arrayMode);
234         }
235 
236         template&lt;typename Op&gt;
<a name="9" id="anc9"></a><span class="line-modified">237         static void compilePutByValWithCachedId(VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, PutKind putKind, const Identifier&amp; propertyName)</span>
238         {
239             JIT jit(vm, codeBlock);
240             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
241             jit.privateCompilePutByValWithCachedId&lt;Op&gt;(byValInfo, returnAddress, putKind, propertyName);
242         }
243 
<a name="10" id="anc10"></a><span class="line-modified">244         static void compileHasIndexedProperty(VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
245         {
246             JIT jit(vm, codeBlock);
247             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
248             jit.privateCompileHasIndexedProperty(byValInfo, returnAddress, arrayMode);
249         }
250 
251         static unsigned frameRegisterCountFor(CodeBlock*);
252         static int stackPointerOffsetFor(CodeBlock*);
253 
254         JS_EXPORT_PRIVATE static HashMap&lt;CString, Seconds&gt; compileTimeStats();
255         JS_EXPORT_PRIVATE static Seconds totalCompileTime();
256 
257     private:
258         void privateCompileMainPass();
259         void privateCompileLinkPass();
260         void privateCompileSlowCases();
261         CompilationResult privateCompile(JITCompilationEffort);
262 
263         void privateCompileGetByVal(const ConcurrentJSLocker&amp;, ByValInfo*, ReturnAddressPtr, JITArrayMode);
264         void privateCompileGetByValWithCachedId(ByValInfo*, ReturnAddressPtr, const Identifier&amp;);
265         template&lt;typename Op&gt;
266         void privateCompilePutByVal(const ConcurrentJSLocker&amp;, ByValInfo*, ReturnAddressPtr, JITArrayMode);
267         template&lt;typename Op&gt;
268         void privateCompilePutByValWithCachedId(ByValInfo*, ReturnAddressPtr, PutKind, const Identifier&amp;);
269 
270         void privateCompileHasIndexedProperty(ByValInfo*, ReturnAddressPtr, JITArrayMode);
271 
272         void privateCompilePatchGetArrayLength(ReturnAddressPtr returnAddress);
273 
274         // Add a call out from JIT code, without an exception check.
275         Call appendCall(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
276         {
277             Call functionCall = call(OperationPtrTag);
278             m_calls.append(CallRecord(functionCall, m_bytecodeOffset, function.retagged&lt;OperationPtrTag&gt;()));
279             return functionCall;
280         }
281 
282 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
283         Call appendCallWithSlowPathReturnType(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
284         {
285             Call functionCall = callWithSlowPathReturnType(OperationPtrTag);
286             m_calls.append(CallRecord(functionCall, m_bytecodeOffset, function.retagged&lt;OperationPtrTag&gt;()));
287             return functionCall;
288         }
289 #endif
290 
291         void exceptionCheck(Jump jumpToHandler)
292         {
293             m_exceptionChecks.append(jumpToHandler);
294         }
295 
296         void exceptionCheck()
297         {
<a name="11" id="anc11"></a><span class="line-modified">298             m_exceptionChecks.append(emitExceptionCheck(*vm()));</span>
299         }
300 
301         void exceptionCheckWithCallFrameRollback()
302         {
<a name="12" id="anc12"></a><span class="line-modified">303             m_exceptionChecksWithCallFrameRollback.append(emitExceptionCheck(*vm()));</span>
304         }
305 
306         void privateCompileExceptionHandlers();
307 
308         void addSlowCase(Jump);
309         void addSlowCase(const JumpList&amp;);
310         void addSlowCase();
311         void addJump(Jump, int);
312         void addJump(const JumpList&amp;, int);
313         void emitJumpSlowToHot(Jump, int);
314 
315         template&lt;typename Op&gt;
316         void compileOpCall(const Instruction*, unsigned callLinkInfoIndex);
317         template&lt;typename Op&gt;
318         void compileOpCallSlowCase(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, unsigned callLinkInfoIndex);
319         template&lt;typename Op&gt;
320         std::enable_if_t&lt;
321             Op::opcodeID != op_call_varargs &amp;&amp; Op::opcodeID != op_construct_varargs
322             &amp;&amp; Op::opcodeID != op_tail_call_varargs &amp;&amp; Op::opcodeID != op_tail_call_forward_arguments
323         , void&gt; compileSetupFrame(const Op&amp;, CallLinkInfo*);
324 
325         template&lt;typename Op&gt;
326         std::enable_if_t&lt;
327             Op::opcodeID == op_call_varargs || Op::opcodeID == op_construct_varargs
328             || Op::opcodeID == op_tail_call_varargs || Op::opcodeID == op_tail_call_forward_arguments
329         , void&gt; compileSetupFrame(const Op&amp;, CallLinkInfo*);
330 
331         template&lt;typename Op&gt;
332         bool compileTailCall(const Op&amp;, CallLinkInfo*, unsigned callLinkInfoIndex);
333         template&lt;typename Op&gt;
334         bool compileCallEval(const Op&amp;);
335         void compileCallEvalSlowCase(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
336         template&lt;typename Op&gt;
337         void emitPutCallResult(const Op&amp;);
338 
339         enum class CompileOpStrictEqType { StrictEq, NStrictEq };
340         template&lt;typename Op&gt;
341         void compileOpStrictEq(const Instruction*, CompileOpStrictEqType);
342         template&lt;typename Op&gt;
343         void compileOpStrictEqJump(const Instruction*, CompileOpStrictEqType);
344         enum class CompileOpEqType { Eq, NEq };
345         void compileOpEqJumpSlow(Vector&lt;SlowCaseEntry&gt;::iterator&amp;, CompileOpEqType, int jumpTarget);
346         bool isOperandConstantDouble(int src);
347 
348         void emitLoadDouble(int index, FPRegisterID value);
349         void emitLoadInt32ToDouble(int index, FPRegisterID value);
350 
351         enum WriteBarrierMode { UnconditionalWriteBarrier, ShouldFilterBase, ShouldFilterValue, ShouldFilterBaseAndValue };
352         // value register in write barrier is used before any scratch registers
353         // so may safely be the same as either of the scratch registers.
354         void emitWriteBarrier(unsigned owner, unsigned value, WriteBarrierMode);
355         void emitWriteBarrier(JSCell* owner, unsigned value, WriteBarrierMode);
356         void emitWriteBarrier(JSCell* owner);
357 
358         // This assumes that the value to profile is in regT0 and that regT3 is available for
359         // scratch.
360         void emitValueProfilingSite(ValueProfile&amp;);
361         template&lt;typename Metadata&gt; void emitValueProfilingSite(Metadata&amp;);
362         void emitValueProfilingSiteIfProfiledOpcode(...);
363         template&lt;typename Op&gt;
364         std::enable_if_t&lt;std::is_same&lt;decltype(Op::Metadata::m_profile), ValueProfile&gt;::value, void&gt;
365         emitValueProfilingSiteIfProfiledOpcode(Op bytecode);
366 
367         void emitArrayProfilingSiteWithCell(RegisterID cell, RegisterID indexingType, ArrayProfile*);
368         void emitArrayProfileStoreToHoleSpecialCase(ArrayProfile*);
369         void emitArrayProfileOutOfBoundsSpecialCase(ArrayProfile*);
370 
371         JITArrayMode chooseArrayMode(ArrayProfile*);
372 
373         // Property is in regT1, base is in regT0. regT2 contains indexing type.
374         // Property is int-checked and zero extended. Base is cell checked.
375         // Structure is already profiled. Returns the slow cases. Fall-through
376         // case contains result in regT0, and it is not yet profiled.
377         JumpList emitInt32Load(const Instruction* instruction, PatchableJump&amp; badType) { return emitContiguousLoad(instruction, badType, Int32Shape); }
378         JumpList emitDoubleLoad(const Instruction*, PatchableJump&amp; badType);
379         JumpList emitContiguousLoad(const Instruction*, PatchableJump&amp; badType, IndexingType expectedShape = ContiguousShape);
380         JumpList emitArrayStorageLoad(const Instruction*, PatchableJump&amp; badType);
381         JumpList emitLoadForArrayMode(const Instruction*, JITArrayMode, PatchableJump&amp; badType);
382 
383         JumpList emitInt32GetByVal(const Instruction* instruction, PatchableJump&amp; badType) { return emitContiguousGetByVal(instruction, badType, Int32Shape); }
384         JumpList emitDoubleGetByVal(const Instruction*, PatchableJump&amp; badType);
385         JumpList emitContiguousGetByVal(const Instruction*, PatchableJump&amp; badType, IndexingType expectedShape = ContiguousShape);
386         JumpList emitArrayStorageGetByVal(const Instruction*, PatchableJump&amp; badType);
387         JumpList emitDirectArgumentsGetByVal(const Instruction*, PatchableJump&amp; badType);
388         JumpList emitScopedArgumentsGetByVal(const Instruction*, PatchableJump&amp; badType);
389         JumpList emitIntTypedArrayGetByVal(const Instruction*, PatchableJump&amp; badType, TypedArrayType);
390         JumpList emitFloatTypedArrayGetByVal(const Instruction*, PatchableJump&amp; badType, TypedArrayType);
391 
392         // Property is in regT1, base is in regT0. regT2 contains indecing type.
393         // The value to store is not yet loaded. Property is int-checked and
394         // zero-extended. Base is cell checked. Structure is already profiled.
395         // returns the slow cases.
396         template&lt;typename Op&gt;
397         JumpList emitInt32PutByVal(Op bytecode, PatchableJump&amp; badType)
398         {
399             return emitGenericContiguousPutByVal(bytecode, badType, Int32Shape);
400         }
401         template&lt;typename Op&gt;
402         JumpList emitDoublePutByVal(Op bytecode, PatchableJump&amp; badType)
403         {
404             return emitGenericContiguousPutByVal(bytecode, badType, DoubleShape);
405         }
406         template&lt;typename Op&gt;
407         JumpList emitContiguousPutByVal(Op bytecode, PatchableJump&amp; badType)
408         {
409             return emitGenericContiguousPutByVal(bytecode, badType);
410         }
411         template&lt;typename Op&gt;
412         JumpList emitGenericContiguousPutByVal(Op, PatchableJump&amp; badType, IndexingType indexingShape = ContiguousShape);
413         template&lt;typename Op&gt;
414         JumpList emitArrayStoragePutByVal(Op, PatchableJump&amp; badType);
415         template&lt;typename Op&gt;
416         JumpList emitIntTypedArrayPutByVal(Op, PatchableJump&amp; badType, TypedArrayType);
417         template&lt;typename Op&gt;
418         JumpList emitFloatTypedArrayPutByVal(Op, PatchableJump&amp; badType, TypedArrayType);
419 
420         // Identifier check helper for GetByVal and PutByVal.
421         void emitByValIdentifierCheck(ByValInfo*, RegisterID cell, RegisterID scratch, const Identifier&amp;, JumpList&amp; slowCases);
422 
423         JITGetByIdGenerator emitGetByValWithCachedId(ByValInfo*, OpGetByVal, const Identifier&amp;, Jump&amp; fastDoneCase, Jump&amp; slowDoneCase, JumpList&amp; slowCases);
424         template&lt;typename Op&gt;
425         JITPutByIdGenerator emitPutByValWithCachedId(ByValInfo*, Op, PutKind, const Identifier&amp;, JumpList&amp; doneCases, JumpList&amp; slowCases);
426 
427         enum FinalObjectMode { MayBeFinal, KnownNotFinal };
428 
429         void emitGetVirtualRegister(int src, JSValueRegs dst);
430         void emitPutVirtualRegister(int dst, JSValueRegs src);
431 
432         int32_t getOperandConstantInt(int src);
433         double getOperandConstantDouble(int src);
434 
435 #if USE(JSVALUE32_64)
436         bool getOperandConstantInt(int op1, int op2, int&amp; op, int32_t&amp; constant);
437 
438         void emitLoadTag(int index, RegisterID tag);
439         void emitLoadPayload(int index, RegisterID payload);
440 
441         void emitLoad(const JSValue&amp; v, RegisterID tag, RegisterID payload);
442         void emitLoad(int index, RegisterID tag, RegisterID payload, RegisterID base = callFrameRegister);
443         void emitLoad2(int index1, RegisterID tag1, RegisterID payload1, int index2, RegisterID tag2, RegisterID payload2);
444 
445         void emitStore(int index, RegisterID tag, RegisterID payload, RegisterID base = callFrameRegister);
446         void emitStore(int index, const JSValue constant, RegisterID base = callFrameRegister);
447         void emitStoreInt32(int index, RegisterID payload, bool indexIsInt32 = false);
448         void emitStoreInt32(int index, TrustedImm32 payload, bool indexIsInt32 = false);
449         void emitStoreCell(int index, RegisterID payload, bool indexIsCell = false);
450         void emitStoreBool(int index, RegisterID payload, bool indexIsBool = false);
451         void emitStoreDouble(int index, FPRegisterID value);
452 
453         void emitJumpSlowCaseIfNotJSCell(int virtualRegisterIndex);
454         void emitJumpSlowCaseIfNotJSCell(int virtualRegisterIndex, RegisterID tag);
455 
456         void compileGetByIdHotPath(const Identifier*);
457 
458         // Arithmetic opcode helpers
459         template &lt;typename Op&gt;
460         void emitBinaryDoubleOp(const Instruction *, OperandTypes, JumpList&amp; notInt32Op1, JumpList&amp; notInt32Op2, bool op1IsInRegisters = true, bool op2IsInRegisters = true);
461 
462 #else // USE(JSVALUE32_64)
463         void emitGetVirtualRegister(int src, RegisterID dst);
464         void emitGetVirtualRegister(VirtualRegister src, RegisterID dst);
465         void emitGetVirtualRegisters(int src1, RegisterID dst1, int src2, RegisterID dst2);
466         void emitGetVirtualRegisters(VirtualRegister src1, RegisterID dst1, VirtualRegister src2, RegisterID dst2);
467         void emitPutVirtualRegister(int dst, RegisterID from = regT0);
468         void emitPutVirtualRegister(VirtualRegister dst, RegisterID from = regT0);
469         void emitStoreCell(int dst, RegisterID payload, bool /* only used in JSValue32_64 */ = false)
470         {
471             emitPutVirtualRegister(dst, payload);
472         }
473         void emitStoreCell(VirtualRegister dst, RegisterID payload)
474         {
475             emitPutVirtualRegister(dst, payload);
476         }
477 
478         Jump emitJumpIfBothJSCells(RegisterID, RegisterID, RegisterID);
479         void emitJumpSlowCaseIfJSCell(RegisterID);
480         void emitJumpSlowCaseIfNotJSCell(RegisterID);
481         void emitJumpSlowCaseIfNotJSCell(RegisterID, int VReg);
482         Jump emitJumpIfNotInt(RegisterID, RegisterID, RegisterID scratch);
483         PatchableJump emitPatchableJumpIfNotInt(RegisterID);
484         void emitJumpSlowCaseIfNotInt(RegisterID);
485         void emitJumpSlowCaseIfNotNumber(RegisterID);
486         void emitJumpSlowCaseIfNotInt(RegisterID, RegisterID, RegisterID scratch);
487 
488         void compileGetByIdHotPath(int baseVReg, const Identifier*);
489 
490 #endif // USE(JSVALUE32_64)
491 
492         template&lt;typename Op&gt;
493         void emit_compareAndJump(const Instruction*, RelationalCondition);
494         template&lt;typename Op&gt;
495         void emit_compareUnsigned(const Instruction*, RelationalCondition);
496         template&lt;typename Op&gt;
497         void emit_compareUnsignedAndJump(const Instruction*, RelationalCondition);
498         template&lt;typename Op&gt;
499         void emit_compareAndJumpSlow(const Instruction*, DoubleCondition, size_t (JIT_OPERATION *operation)(ExecState*, EncodedJSValue, EncodedJSValue), bool invert, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
500 
501         void assertStackPointerOffset();
502 
503         void emit_op_add(const Instruction*);
504         void emit_op_bitand(const Instruction*);
505         void emit_op_bitor(const Instruction*);
506         void emit_op_bitxor(const Instruction*);
507         void emit_op_bitnot(const Instruction*);
508         void emit_op_call(const Instruction*);
509         void emit_op_tail_call(const Instruction*);
510         void emit_op_call_eval(const Instruction*);
511         void emit_op_call_varargs(const Instruction*);
512         void emit_op_tail_call_varargs(const Instruction*);
513         void emit_op_tail_call_forward_arguments(const Instruction*);
514         void emit_op_construct_varargs(const Instruction*);
515         void emit_op_catch(const Instruction*);
516         void emit_op_construct(const Instruction*);
517         void emit_op_create_this(const Instruction*);
518         void emit_op_to_this(const Instruction*);
519         void emit_op_get_argument(const Instruction*);
520         void emit_op_argument_count(const Instruction*);
521         void emit_op_get_rest_length(const Instruction*);
522         void emit_op_check_tdz(const Instruction*);
523         void emit_op_identity_with_profile(const Instruction*);
524         void emit_op_debug(const Instruction*);
525         void emit_op_del_by_id(const Instruction*);
526         void emit_op_del_by_val(const Instruction*);
527         void emit_op_div(const Instruction*);
528         void emit_op_end(const Instruction*);
529         void emit_op_enter(const Instruction*);
530         void emit_op_get_scope(const Instruction*);
531         void emit_op_eq(const Instruction*);
532         void emit_op_eq_null(const Instruction*);
533         void emit_op_below(const Instruction*);
534         void emit_op_beloweq(const Instruction*);
535         void emit_op_try_get_by_id(const Instruction*);
536         void emit_op_get_by_id(const Instruction*);
537         void emit_op_get_by_id_with_this(const Instruction*);
538         void emit_op_get_by_id_direct(const Instruction*);
539         void emit_op_get_by_val(const Instruction*);
540         void emit_op_get_argument_by_val(const Instruction*);
541         void emit_op_in_by_id(const Instruction*);
542         void emit_op_init_lazy_reg(const Instruction*);
543         void emit_op_overrides_has_instance(const Instruction*);
544         void emit_op_instanceof(const Instruction*);
545         void emit_op_instanceof_custom(const Instruction*);
546         void emit_op_is_empty(const Instruction*);
547         void emit_op_is_undefined(const Instruction*);
548         void emit_op_is_undefined_or_null(const Instruction*);
549         void emit_op_is_boolean(const Instruction*);
550         void emit_op_is_number(const Instruction*);
551         void emit_op_is_object(const Instruction*);
552         void emit_op_is_cell_with_type(const Instruction*);
553         void emit_op_jeq_null(const Instruction*);
554         void emit_op_jfalse(const Instruction*);
555         void emit_op_jmp(const Instruction*);
556         void emit_op_jneq_null(const Instruction*);
<a name="13" id="anc13"></a>

557         void emit_op_jneq_ptr(const Instruction*);
558         void emit_op_jless(const Instruction*);
559         void emit_op_jlesseq(const Instruction*);
560         void emit_op_jgreater(const Instruction*);
561         void emit_op_jgreatereq(const Instruction*);
562         void emit_op_jnless(const Instruction*);
563         void emit_op_jnlesseq(const Instruction*);
564         void emit_op_jngreater(const Instruction*);
565         void emit_op_jngreatereq(const Instruction*);
566         void emit_op_jeq(const Instruction*);
567         void emit_op_jneq(const Instruction*);
568         void emit_op_jstricteq(const Instruction*);
569         void emit_op_jnstricteq(const Instruction*);
570         void emit_op_jbelow(const Instruction*);
571         void emit_op_jbeloweq(const Instruction*);
572         void emit_op_jtrue(const Instruction*);
573         void emit_op_loop_hint(const Instruction*);
<a name="14" id="anc14"></a><span class="line-removed">574         void emit_op_check_traps(const Instruction*);</span>
575         void emit_op_nop(const Instruction*);
576         void emit_op_super_sampler_begin(const Instruction*);
577         void emit_op_super_sampler_end(const Instruction*);
578         void emit_op_lshift(const Instruction*);
579         void emit_op_mod(const Instruction*);
580         void emit_op_mov(const Instruction*);
581         void emit_op_mul(const Instruction*);
582         void emit_op_negate(const Instruction*);
583         void emit_op_neq(const Instruction*);
584         void emit_op_neq_null(const Instruction*);
585         void emit_op_new_array(const Instruction*);
586         void emit_op_new_array_with_size(const Instruction*);
587         void emit_op_new_func(const Instruction*);
588         void emit_op_new_func_exp(const Instruction*);
589         void emit_op_new_generator_func(const Instruction*);
590         void emit_op_new_generator_func_exp(const Instruction*);
591         void emit_op_new_async_func(const Instruction*);
592         void emit_op_new_async_func_exp(const Instruction*);
593         void emit_op_new_async_generator_func(const Instruction*);
594         void emit_op_new_async_generator_func_exp(const Instruction*);
595         void emit_op_new_object(const Instruction*);
596         void emit_op_new_regexp(const Instruction*);
597         void emit_op_not(const Instruction*);
598         void emit_op_nstricteq(const Instruction*);
599         void emit_op_dec(const Instruction*);
600         void emit_op_inc(const Instruction*);
601         void emit_op_profile_type(const Instruction*);
602         void emit_op_profile_control_flow(const Instruction*);
603         void emit_op_get_parent_scope(const Instruction*);
604         void emit_op_put_by_id(const Instruction*);
605         template&lt;typename Op = OpPutByVal&gt;
606         void emit_op_put_by_val(const Instruction*);
607         void emit_op_put_by_val_direct(const Instruction*);
608         void emit_op_put_getter_by_id(const Instruction*);
609         void emit_op_put_setter_by_id(const Instruction*);
610         void emit_op_put_getter_setter_by_id(const Instruction*);
611         void emit_op_put_getter_by_val(const Instruction*);
612         void emit_op_put_setter_by_val(const Instruction*);
613         void emit_op_ret(const Instruction*);
614         void emit_op_rshift(const Instruction*);
615         void emit_op_set_function_name(const Instruction*);
616         void emit_op_stricteq(const Instruction*);
617         void emit_op_sub(const Instruction*);
618         void emit_op_switch_char(const Instruction*);
619         void emit_op_switch_imm(const Instruction*);
620         void emit_op_switch_string(const Instruction*);
621         void emit_op_tear_off_arguments(const Instruction*);
622         void emit_op_throw(const Instruction*);
623         void emit_op_to_number(const Instruction*);
624         void emit_op_to_string(const Instruction*);
625         void emit_op_to_object(const Instruction*);
626         void emit_op_to_primitive(const Instruction*);
627         void emit_op_unexpected_load(const Instruction*);
628         void emit_op_unsigned(const Instruction*);
629         void emit_op_urshift(const Instruction*);
630         void emit_op_has_structure_property(const Instruction*);
631         void emit_op_has_indexed_property(const Instruction*);
632         void emit_op_get_direct_pname(const Instruction*);
633         void emit_op_enumerator_structure_pname(const Instruction*);
634         void emit_op_enumerator_generic_pname(const Instruction*);
635         void emit_op_log_shadow_chicken_prologue(const Instruction*);
636         void emit_op_log_shadow_chicken_tail(const Instruction*);
637 
638         void emitSlow_op_add(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
639         void emitSlow_op_call(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
640         void emitSlow_op_tail_call(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
641         void emitSlow_op_call_eval(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
642         void emitSlow_op_call_varargs(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
643         void emitSlow_op_tail_call_varargs(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
644         void emitSlow_op_tail_call_forward_arguments(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
645         void emitSlow_op_construct_varargs(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
646         void emitSlow_op_construct(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
647         void emitSlow_op_eq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
648         void emitSlow_op_get_callee(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
649         void emitSlow_op_try_get_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
650         void emitSlow_op_get_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
651         void emitSlow_op_get_by_id_with_this(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
652         void emitSlow_op_get_by_id_direct(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
653         void emitSlow_op_get_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
654         void emitSlow_op_get_argument_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
655         void emitSlow_op_in_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
656         void emitSlow_op_instanceof(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
657         void emitSlow_op_instanceof_custom(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
658         void emitSlow_op_jless(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
659         void emitSlow_op_jlesseq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
660         void emitSlow_op_jgreater(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
661         void emitSlow_op_jgreatereq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
662         void emitSlow_op_jnless(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
663         void emitSlow_op_jnlesseq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
664         void emitSlow_op_jngreater(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
665         void emitSlow_op_jngreatereq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
666         void emitSlow_op_jeq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
667         void emitSlow_op_jneq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
668         void emitSlow_op_jstricteq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
669         void emitSlow_op_jnstricteq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
670         void emitSlow_op_jtrue(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
671         void emitSlow_op_loop_hint(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
<a name="15" id="anc15"></a><span class="line-modified">672         void emitSlow_op_check_traps(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);</span>
673         void emitSlow_op_mod(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
674         void emitSlow_op_mul(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
675         void emitSlow_op_negate(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
676         void emitSlow_op_neq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
677         void emitSlow_op_new_object(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
678         void emitSlow_op_put_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
679         void emitSlow_op_put_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
680         void emitSlow_op_sub(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
681         void emitSlow_op_has_indexed_property(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
682 
683         void emit_op_resolve_scope(const Instruction*);
684         void emit_op_get_from_scope(const Instruction*);
685         void emit_op_put_to_scope(const Instruction*);
686         void emit_op_get_from_arguments(const Instruction*);
687         void emit_op_put_to_arguments(const Instruction*);
688         void emitSlow_op_get_from_scope(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
689         void emitSlow_op_put_to_scope(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
690 
691         void emitSlowCaseCall(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, SlowPathFunction);
692 
693         void emitRightShift(const Instruction*, bool isUnsigned);
694         void emitRightShiftSlowCase(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, bool isUnsigned);
695 
696         template&lt;typename Op&gt;
697         void emitNewFuncCommon(const Instruction*);
698         template&lt;typename Op&gt;
699         void emitNewFuncExprCommon(const Instruction*);
700         void emitVarInjectionCheck(bool needsVarInjectionChecks);
701         void emitResolveClosure(int dst, int scope, bool needsVarInjectionChecks, unsigned depth);
702         void emitLoadWithStructureCheck(int scope, Structure** structureSlot);
703 #if USE(JSVALUE64)
704         void emitGetVarFromPointer(JSValue* operand, GPRReg);
705         void emitGetVarFromIndirectPointer(JSValue** operand, GPRReg);
706 #else
707         void emitGetVarFromIndirectPointer(JSValue** operand, GPRReg tag, GPRReg payload);
708         void emitGetVarFromPointer(JSValue* operand, GPRReg tag, GPRReg payload);
709 #endif
710         void emitGetClosureVar(int scope, uintptr_t operand);
711         void emitNotifyWrite(WatchpointSet*);
712         void emitNotifyWrite(GPRReg pointerToSet);
713         void emitPutGlobalVariable(JSValue* operand, int value, WatchpointSet*);
714         void emitPutGlobalVariableIndirect(JSValue** addressOfOperand, int value, WatchpointSet**);
715         void emitPutClosureVar(int scope, uintptr_t operand, int value, WatchpointSet*);
716 
717         void emitInitRegister(int dst);
718 
719         void emitPutIntToCallFrameHeader(RegisterID from, int entry);
720 
721         JSValue getConstantOperand(int src);
722         bool isOperandConstantInt(int src);
723         bool isOperandConstantChar(int src);
724 
725         template &lt;typename Op, typename Generator, typename ProfiledFunction, typename NonProfiledFunction&gt;
726         void emitMathICFast(JITUnaryMathIC&lt;Generator&gt;*, const Instruction*, ProfiledFunction, NonProfiledFunction);
727         template &lt;typename Op, typename Generator, typename ProfiledFunction, typename NonProfiledFunction&gt;
728         void emitMathICFast(JITBinaryMathIC&lt;Generator&gt;*, const Instruction*, ProfiledFunction, NonProfiledFunction);
729 
730         template &lt;typename Op, typename Generator, typename ProfiledRepatchFunction, typename ProfiledFunction, typename RepatchFunction&gt;
731         void emitMathICSlow(JITBinaryMathIC&lt;Generator&gt;*, const Instruction*, ProfiledRepatchFunction, ProfiledFunction, RepatchFunction);
732         template &lt;typename Op, typename Generator, typename ProfiledRepatchFunction, typename ProfiledFunction, typename RepatchFunction&gt;
733         void emitMathICSlow(JITUnaryMathIC&lt;Generator&gt;*, const Instruction*, ProfiledRepatchFunction, ProfiledFunction, RepatchFunction);
734 
735         Jump getSlowCase(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
736         {
737             return iter++-&gt;from;
738         }
739         void linkSlowCase(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
740         {
741             if (iter-&gt;from.isSet())
742                 iter-&gt;from.link(this);
743             ++iter;
744         }
745         void linkDummySlowCase(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
746         {
747             ASSERT(!iter-&gt;from.isSet());
748             ++iter;
749         }
750         void linkSlowCaseIfNotJSCell(Vector&lt;SlowCaseEntry&gt;::iterator&amp;, int virtualRegisterIndex);
751         void linkAllSlowCasesForBytecodeOffset(Vector&lt;SlowCaseEntry&gt;&amp; slowCases,
752             Vector&lt;SlowCaseEntry&gt;::iterator&amp;, unsigned bytecodeOffset);
753 
754         void linkAllSlowCases(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
755         {
756             linkAllSlowCasesForBytecodeOffset(m_slowCases, iter, m_bytecodeOffset);
757         }
758 
759         MacroAssembler::Call appendCallWithExceptionCheck(const FunctionPtr&lt;CFunctionPtrTag&gt;);
760 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
761         MacroAssembler::Call appendCallWithExceptionCheckAndSlowPathReturnType(const FunctionPtr&lt;CFunctionPtrTag&gt;);
762 #endif
763         MacroAssembler::Call appendCallWithCallFrameRollbackOnException(const FunctionPtr&lt;CFunctionPtrTag&gt;);
764         MacroAssembler::Call appendCallWithExceptionCheckSetJSValueResult(const FunctionPtr&lt;CFunctionPtrTag&gt;, int);
765         template&lt;typename Metadata&gt;
766         MacroAssembler::Call appendCallWithExceptionCheckSetJSValueResultWithProfile(Metadata&amp;, const FunctionPtr&lt;CFunctionPtrTag&gt;, int);
767 
768         template&lt;typename OperationType, typename... Args&gt;
769         std::enable_if_t&lt;FunctionTraits&lt;OperationType&gt;::hasResult, MacroAssembler::Call&gt;
770         callOperation(OperationType operation, int result, Args... args)
771         {
772             setupArguments&lt;OperationType&gt;(args...);
773             return appendCallWithExceptionCheckSetJSValueResult(operation, result);
774         }
775 
776 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
777         template&lt;typename OperationType, typename... Args&gt;
778         std::enable_if_t&lt;std::is_same&lt;typename FunctionTraits&lt;OperationType&gt;::ResultType, SlowPathReturnType&gt;::value, MacroAssembler::Call&gt;
779         callOperation(OperationType operation, Args... args)
780         {
781             setupArguments&lt;OperationType&gt;(args...);
782             return appendCallWithExceptionCheckAndSlowPathReturnType(operation);
783         }
784 
785         template&lt;typename Type&gt;
786         struct is64BitType {
787             static constexpr bool value = sizeof(Type) &lt;= 8;
788         };
789 
790         template&lt;&gt;
791         struct is64BitType&lt;void&gt; {
792             static constexpr bool value = true;
793         };
794 
795         template&lt;typename OperationType, typename... Args&gt;
796         std::enable_if_t&lt;!std::is_same&lt;typename FunctionTraits&lt;OperationType&gt;::ResultType, SlowPathReturnType&gt;::value, MacroAssembler::Call&gt;
797         callOperation(OperationType operation, Args... args)
798         {
799             static_assert(is64BitType&lt;typename FunctionTraits&lt;OperationType&gt;::ResultType&gt;::value, &quot;Win64 cannot use standard call when return type is larger than 64 bits.&quot;);
800             setupArguments&lt;OperationType&gt;(args...);
801             return appendCallWithExceptionCheck(operation);
802         }
803 #else // OS(WINDOWS) &amp;&amp; CPU(X86_64)
804         template&lt;typename OperationType, typename... Args&gt;
805         MacroAssembler::Call callOperation(OperationType operation, Args... args)
806         {
807             setupArguments&lt;OperationType&gt;(args...);
808             return appendCallWithExceptionCheck(operation);
809         }
810 #endif // OS(WINDOWS) &amp;&amp; CPU(X86_64)
811 
812         template&lt;typename Metadata, typename OperationType, typename... Args&gt;
813         std::enable_if_t&lt;FunctionTraits&lt;OperationType&gt;::hasResult, MacroAssembler::Call&gt;
814         callOperationWithProfile(Metadata&amp; metadata, OperationType operation, int result, Args... args)
815         {
816             setupArguments&lt;OperationType&gt;(args...);
817             return appendCallWithExceptionCheckSetJSValueResultWithProfile(metadata, operation, result);
818         }
819 
820         template&lt;typename OperationType, typename... Args&gt;
821         MacroAssembler::Call callOperationWithResult(OperationType operation, JSValueRegs resultRegs, Args... args)
822         {
823             setupArguments&lt;OperationType&gt;(args...);
824             auto result = appendCallWithExceptionCheck(operation);
825             setupResults(resultRegs);
826             return result;
827         }
828 
829         template&lt;typename OperationType, typename... Args&gt;
830         MacroAssembler::Call callOperationNoExceptionCheck(OperationType operation, Args... args)
831         {
832             setupArguments&lt;OperationType&gt;(args...);
833             updateTopCallFrame();
834             return appendCall(operation);
835         }
836 
837         template&lt;typename OperationType, typename... Args&gt;
838         MacroAssembler::Call callOperationWithCallFrameRollbackOnException(OperationType operation, Args... args)
839         {
840             setupArguments&lt;OperationType&gt;(args...);
841             return appendCallWithCallFrameRollbackOnException(operation);
842         }
843 
844         enum class ProfilingPolicy {
845             ShouldEmitProfiling,
846             NoProfiling
847         };
848 
849         template&lt;typename Op, typename SnippetGenerator&gt;
850         void emitBitBinaryOpFastPath(const Instruction* currentInstruction, ProfilingPolicy shouldEmitProfiling = ProfilingPolicy::NoProfiling);
851 
852         void emitRightShiftFastPath(const Instruction* currentInstruction, OpcodeID);
853 
854         template&lt;typename Op&gt;
855         void emitRightShiftFastPath(const Instruction* currentInstruction, JITRightShiftGenerator::ShiftType);
856 
857         void updateTopCallFrame();
858 
859         Call emitNakedCall(CodePtr&lt;NoPtrTag&gt; function = CodePtr&lt;NoPtrTag&gt;());
860         Call emitNakedTailCall(CodePtr&lt;NoPtrTag&gt; function = CodePtr&lt;NoPtrTag&gt;());
861 
862         // Loads the character value of a single character string into dst.
863         void emitLoadCharacterString(RegisterID src, RegisterID dst, JumpList&amp; failures);
864 
865         int jumpTarget(const Instruction*, int target);
866 
<a name="16" id="anc16"></a><span class="line-removed">867 #if ENABLE(DFG_JIT)</span>
<span class="line-removed">868         void emitEnterOptimizationCheck();</span>
<span class="line-removed">869 #else</span>
<span class="line-removed">870         void emitEnterOptimizationCheck() { }</span>
<span class="line-removed">871 #endif</span>
<span class="line-removed">872 </span>
873 #ifndef NDEBUG
874         void printBytecodeOperandTypes(int src1, int src2);
875 #endif
876 
877 #if ENABLE(SAMPLING_FLAGS)
878         void setSamplingFlag(int32_t);
879         void clearSamplingFlag(int32_t);
880 #endif
881 
882 #if ENABLE(SAMPLING_COUNTERS)
883         void emitCount(AbstractSamplingCounter&amp;, int32_t = 1);
884 #endif
885 
886 #if ENABLE(OPCODE_SAMPLING)
887         void sampleInstruction(const Instruction*, bool = false);
888 #endif
889 
890 #if ENABLE(CODEBLOCK_SAMPLING)
891         void sampleCodeBlock(CodeBlock*);
892 #else
893         void sampleCodeBlock(CodeBlock*) {}
894 #endif
895 
896 #if ENABLE(DFG_JIT)
897         bool canBeOptimized() { return m_canBeOptimized; }
898         bool canBeOptimizedOrInlined() { return m_canBeOptimizedOrInlined; }
899         bool shouldEmitProfiling() { return m_shouldEmitProfiling; }
900 #else
901         bool canBeOptimized() { return false; }
902         bool canBeOptimizedOrInlined() { return false; }
903         // Enables use of value profiler with tiered compilation turned off,
904         // in which case all code gets profiled.
905         bool shouldEmitProfiling() { return false; }
906 #endif
907 
908         static bool reportCompileTimes();
909         static bool computeCompileTimes();
910 
911         // If you need to check a value from the metadata table and you need it to
912         // be consistent across the fast and slow path, then you want to use this.
913         // It will give the slow path the same value read by the fast path.
914         GetPutInfo copiedGetPutInfo(OpPutToScope);
915         template&lt;typename BinaryOp&gt;
916         ArithProfile copiedArithProfile(BinaryOp);
917 
918         Interpreter* m_interpreter;
919 
920         Vector&lt;CallRecord&gt; m_calls;
921         Vector&lt;Label&gt; m_labels;
922         Vector&lt;JITGetByIdGenerator&gt; m_getByIds;
923         Vector&lt;JITGetByIdWithThisGenerator&gt; m_getByIdsWithThis;
924         Vector&lt;JITPutByIdGenerator&gt; m_putByIds;
925         Vector&lt;JITInByIdGenerator&gt; m_inByIds;
926         Vector&lt;JITInstanceOfGenerator&gt; m_instanceOfs;
927         Vector&lt;ByValCompilationInfo&gt; m_byValCompilationInfo;
928         Vector&lt;CallCompilationInfo&gt; m_callCompilationInfo;
929         Vector&lt;JumpTable&gt; m_jmpTable;
930 
931         unsigned m_bytecodeOffset;
932         Vector&lt;SlowCaseEntry&gt; m_slowCases;
933         Vector&lt;SwitchRecord&gt; m_switches;
934 
935         HashMap&lt;unsigned, unsigned&gt; m_copiedGetPutInfos;
936         HashMap&lt;uint64_t, ArithProfile&gt; m_copiedArithProfiles;
937 
938         JumpList m_exceptionChecks;
939         JumpList m_exceptionChecksWithCallFrameRollback;
940         Label m_exceptionHandler;
941 
942         unsigned m_getByIdIndex { UINT_MAX };
943         unsigned m_getByIdWithThisIndex { UINT_MAX };
944         unsigned m_putByIdIndex { UINT_MAX };
945         unsigned m_inByIdIndex { UINT_MAX };
946         unsigned m_instanceOfIndex { UINT_MAX };
947         unsigned m_byValInstructionIndex { UINT_MAX };
948         unsigned m_callLinkInfoIndex { UINT_MAX };
949 
950         Label m_arityCheck;
951         std::unique_ptr&lt;LinkBuffer&gt; m_linkBuffer;
952 
953         std::unique_ptr&lt;JITDisassembler&gt; m_disassembler;
954         RefPtr&lt;Profiler::Compilation&gt; m_compilation;
955 
956         PCToCodeOriginMapBuilder m_pcToCodeOriginMapBuilder;
957 
958         HashMap&lt;const Instruction*, void*&gt; m_instructionToMathIC;
959         HashMap&lt;const Instruction*, MathICGenerationState&gt; m_instructionToMathICGenerationState;
960 
961         bool m_canBeOptimized;
962         bool m_canBeOptimizedOrInlined;
963         bool m_shouldEmitProfiling;
964         bool m_shouldUseIndexMasking;
965         unsigned m_loopOSREntryBytecodeOffset { 0 };
966     };
967 
968 } // namespace JSC
969 
970 
971 #endif // ENABLE(JIT)
<a name="17" id="anc17"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="17" type="hidden" />
</body>
</html>