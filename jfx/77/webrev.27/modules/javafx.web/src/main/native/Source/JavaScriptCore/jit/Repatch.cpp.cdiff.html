<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/Repatch.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="RegisterSet.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="Repatch.h.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/Repatch.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 49,10 ***</span>
<span class="line-new-header">--- 49,11 ---</span>
  #include &quot;JIT.h&quot;
  #include &quot;JITInlines.h&quot;
  #include &quot;JSCInlines.h&quot;
  #include &quot;JSModuleNamespaceObject.h&quot;
  #include &quot;JSWebAssembly.h&quot;
<span class="line-added">+ #include &quot;JSWebAssemblyModule.h&quot;</span>
  #include &quot;LinkBuffer.h&quot;
  #include &quot;ModuleNamespaceAccessCase.h&quot;
  #include &quot;PolymorphicAccess.h&quot;
  #include &quot;ScopedArguments.h&quot;
  #include &quot;ScratchRegisterAllocator.h&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 60,35 ***</span>
  #include &quot;StructureRareDataInlines.h&quot;
  #include &quot;StructureStubClearingWatchpoint.h&quot;
  #include &quot;StructureStubInfo.h&quot;
  #include &quot;SuperSampler.h&quot;
  #include &quot;ThunkGenerators.h&quot;
  #include &lt;wtf/CommaPrinter.h&gt;
  #include &lt;wtf/ListDump.h&gt;
  #include &lt;wtf/StringPrintStream.h&gt;
  
  namespace JSC {
  
  static FunctionPtr&lt;CFunctionPtrTag&gt; readPutICCallTarget(CodeBlock* codeBlock, CodeLocationCall&lt;JSInternalPtrTag&gt; call)
  {
      FunctionPtr&lt;OperationPtrTag&gt; target = MacroAssembler::readCallTarget&lt;OperationPtrTag&gt;(call);
  #if ENABLE(FTL_JIT)
<span class="line-modified">!     if (codeBlock-&gt;jitType() == JITCode::FTLJIT) {</span>
          MacroAssemblerCodePtr&lt;JITThunkPtrTag&gt; thunk = MacroAssemblerCodePtr&lt;OperationPtrTag&gt;::createFromExecutableAddress(target.executableAddress()).retagged&lt;JITThunkPtrTag&gt;();
<span class="line-modified">!         return codeBlock-&gt;vm()-&gt;ftlThunks-&gt;keyForSlowPathCallThunk(thunk).callTarget().retagged&lt;CFunctionPtrTag&gt;();</span>
      }
  #else
      UNUSED_PARAM(codeBlock);
  #endif // ENABLE(FTL_JIT)
      return target.retagged&lt;CFunctionPtrTag&gt;();
  }
  
  void ftlThunkAwareRepatchCall(CodeBlock* codeBlock, CodeLocationCall&lt;JSInternalPtrTag&gt; call, FunctionPtr&lt;CFunctionPtrTag&gt; newCalleeFunction)
  {
  #if ENABLE(FTL_JIT)
<span class="line-modified">!     if (codeBlock-&gt;jitType() == JITCode::FTLJIT) {</span>
<span class="line-modified">!         VM&amp; vm = *codeBlock-&gt;vm();</span>
          FTL::Thunks&amp; thunks = *vm.ftlThunks;
          FunctionPtr&lt;OperationPtrTag&gt; target = MacroAssembler::readCallTarget&lt;OperationPtrTag&gt;(call);
          auto slowPathThunk = MacroAssemblerCodePtr&lt;JITThunkPtrTag&gt;::createFromExecutableAddress(target.retaggedExecutableAddress&lt;JITThunkPtrTag&gt;());
          FTL::SlowPathCallKey key = thunks.keyForSlowPathCallThunk(slowPathThunk);
          key = key.withCallTarget(newCalleeFunction);
<span class="line-new-header">--- 61,37 ---</span>
  #include &quot;StructureRareDataInlines.h&quot;
  #include &quot;StructureStubClearingWatchpoint.h&quot;
  #include &quot;StructureStubInfo.h&quot;
  #include &quot;SuperSampler.h&quot;
  #include &quot;ThunkGenerators.h&quot;
<span class="line-added">+ #include &quot;WebAssemblyFunction.h&quot;</span>
<span class="line-added">+ #include &quot;WebAssemblyToJSCallee.h&quot;</span>
  #include &lt;wtf/CommaPrinter.h&gt;
  #include &lt;wtf/ListDump.h&gt;
  #include &lt;wtf/StringPrintStream.h&gt;
  
  namespace JSC {
  
  static FunctionPtr&lt;CFunctionPtrTag&gt; readPutICCallTarget(CodeBlock* codeBlock, CodeLocationCall&lt;JSInternalPtrTag&gt; call)
  {
      FunctionPtr&lt;OperationPtrTag&gt; target = MacroAssembler::readCallTarget&lt;OperationPtrTag&gt;(call);
  #if ENABLE(FTL_JIT)
<span class="line-modified">!     if (codeBlock-&gt;jitType() == JITType::FTLJIT) {</span>
          MacroAssemblerCodePtr&lt;JITThunkPtrTag&gt; thunk = MacroAssemblerCodePtr&lt;OperationPtrTag&gt;::createFromExecutableAddress(target.executableAddress()).retagged&lt;JITThunkPtrTag&gt;();
<span class="line-modified">!         return codeBlock-&gt;vm().ftlThunks-&gt;keyForSlowPathCallThunk(thunk).callTarget().retagged&lt;CFunctionPtrTag&gt;();</span>
      }
  #else
      UNUSED_PARAM(codeBlock);
  #endif // ENABLE(FTL_JIT)
      return target.retagged&lt;CFunctionPtrTag&gt;();
  }
  
  void ftlThunkAwareRepatchCall(CodeBlock* codeBlock, CodeLocationCall&lt;JSInternalPtrTag&gt; call, FunctionPtr&lt;CFunctionPtrTag&gt; newCalleeFunction)
  {
  #if ENABLE(FTL_JIT)
<span class="line-modified">!     if (codeBlock-&gt;jitType() == JITType::FTLJIT) {</span>
<span class="line-modified">!         VM&amp; vm = codeBlock-&gt;vm();</span>
          FTL::Thunks&amp; thunks = *vm.ftlThunks;
          FunctionPtr&lt;OperationPtrTag&gt; target = MacroAssembler::readCallTarget&lt;OperationPtrTag&gt;(call);
          auto slowPathThunk = MacroAssemblerCodePtr&lt;JITThunkPtrTag&gt;::createFromExecutableAddress(target.retaggedExecutableAddress&lt;JITThunkPtrTag&gt;());
          FTL::SlowPathCallKey key = thunks.keyForSlowPathCallThunk(slowPathThunk);
          key = key.withCallTarget(newCalleeFunction);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 265,11 ***</span>
                  &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()
                  &amp;&amp; !loadTargetFromProxy) {
  
                  bool generatedCodeInline = InlineAccess::generateSelfPropertyAccess(stubInfo, structure, slot.cachedOffset());
                  if (generatedCodeInline) {
<span class="line-modified">!                     LOG_IC((ICEvent::GetByIdSelfPatch, structure-&gt;classInfo(), propertyName));</span>
                      structure-&gt;startWatchingPropertyForReplacements(vm, slot.cachedOffset());
                      ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingGetByIdFunction(kind));
                      stubInfo.initGetByIdSelf(codeBlock, structure, slot.cachedOffset());
                      return RetryCacheLater;
                  }
<span class="line-new-header">--- 268,11 ---</span>
                  &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()
                  &amp;&amp; !loadTargetFromProxy) {
  
                  bool generatedCodeInline = InlineAccess::generateSelfPropertyAccess(stubInfo, structure, slot.cachedOffset());
                  if (generatedCodeInline) {
<span class="line-modified">!                     LOG_IC((ICEvent::GetByIdSelfPatch, structure-&gt;classInfo(), propertyName, slot.slotBase() == baseValue));</span>
                      structure-&gt;startWatchingPropertyForReplacements(vm, slot.cachedOffset());
                      ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingGetByIdFunction(kind));
                      stubInfo.initGetByIdSelf(codeBlock, structure, slot.cachedOffset());
                      return RetryCacheLater;
                  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 374,16 ***</span>
                          domAttribute, WTFMove(prototypeAccessChain));
                  }
              }
          }
  
<span class="line-modified">!         LOG_IC((ICEvent::GetByIdAddAccessCase, baseValue.classInfoOrNull(vm), propertyName));</span>
  
          result = stubInfo.addAccessCase(locker, codeBlock, propertyName, WTFMove(newCase));
  
          if (result.generatedSomeCode()) {
<span class="line-modified">!             LOG_IC((ICEvent::GetByIdReplaceWithJump, baseValue.classInfoOrNull(vm), propertyName));</span>
  
              RELEASE_ASSERT(result.code());
              InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
          }
      }
<span class="line-new-header">--- 377,16 ---</span>
                          domAttribute, WTFMove(prototypeAccessChain));
                  }
              }
          }
  
<span class="line-modified">!         LOG_IC((ICEvent::GetByIdAddAccessCase, baseValue.classInfoOrNull(vm), propertyName, slot.slotBase() == baseValue));</span>
  
          result = stubInfo.addAccessCase(locker, codeBlock, propertyName, WTFMove(newCase));
  
          if (result.generatedSomeCode()) {
<span class="line-modified">!             LOG_IC((ICEvent::GetByIdReplaceWithJump, baseValue.classInfoOrNull(vm), propertyName, slot.slotBase() == baseValue));</span>
  
              RELEASE_ASSERT(result.code());
              InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
          }
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 473,11 ***</span>
                      &amp;&amp; InlineAccess::canGenerateSelfPropertyReplace(stubInfo, slot.cachedOffset())
                      &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
  
                      bool generatedCodeInline = InlineAccess::generateSelfPropertyReplace(stubInfo, structure, slot.cachedOffset());
                      if (generatedCodeInline) {
<span class="line-modified">!                         LOG_IC((ICEvent::PutByIdSelfPatch, structure-&gt;classInfo(), ident));</span>
                          ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingPutByIdFunction(slot, putKind));
                          stubInfo.initPutByIdReplace(codeBlock, structure, slot.cachedOffset());
                          return RetryCacheLater;
                      }
                  }
<span class="line-new-header">--- 476,11 ---</span>
                      &amp;&amp; InlineAccess::canGenerateSelfPropertyReplace(stubInfo, slot.cachedOffset())
                      &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
  
                      bool generatedCodeInline = InlineAccess::generateSelfPropertyReplace(stubInfo, structure, slot.cachedOffset());
                      if (generatedCodeInline) {
<span class="line-modified">!                         LOG_IC((ICEvent::PutByIdSelfPatch, structure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
                          ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), appropriateOptimizingPutByIdFunction(slot, putKind));
                          stubInfo.initPutByIdReplace(codeBlock, structure, slot.cachedOffset());
                          return RetryCacheLater;
                      }
                  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 574,28 ***</span>
                              generateConditionsForPrototypePropertyHit(
                                  vm, codeBlock, exec, structure, slot.base(), ident.impl());
                          if (!conditionSet.isValid())
                              return GiveUpOnCache;
  
<span class="line-modified">!                         PropertyOffset conditionSetOffset = conditionSet.slotBaseCondition().offset();</span>
<span class="line-modified">!                         if (UNLIKELY(offset != conditionSetOffset))</span>
<span class="line-modified">!                             CRASH_WITH_INFO(offset, conditionSetOffset, slot.base()-&gt;type(), baseCell-&gt;type(), conditionSet.size());</span>
                      }
  
                  }
  
                  newCase = GetterSetterAccessCase::create(
                      vm, codeBlock, AccessCase::Setter, structure, offset, conditionSet, WTFMove(prototypeAccessChain));
              }
          }
  
<span class="line-modified">!         LOG_IC((ICEvent::PutByIdAddAccessCase, structure-&gt;classInfo(), ident));</span>
  
          result = stubInfo.addAccessCase(locker, codeBlock, ident, WTFMove(newCase));
  
          if (result.generatedSomeCode()) {
<span class="line-modified">!             LOG_IC((ICEvent::PutByIdReplaceWithJump, structure-&gt;classInfo(), ident));</span>
  
              RELEASE_ASSERT(result.code());
  
              InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
          }
<span class="line-new-header">--- 577,29 ---</span>
                              generateConditionsForPrototypePropertyHit(
                                  vm, codeBlock, exec, structure, slot.base(), ident.impl());
                          if (!conditionSet.isValid())
                              return GiveUpOnCache;
  
<span class="line-modified">!                         if (!(conditionSet.slotBaseCondition().attributes() &amp; PropertyAttribute::Accessor))</span>
<span class="line-modified">!                             return GiveUpOnCache;</span>
<span class="line-modified">! </span>
<span class="line-added">+                         offset = conditionSet.slotBaseCondition().offset();</span>
                      }
  
                  }
  
                  newCase = GetterSetterAccessCase::create(
                      vm, codeBlock, AccessCase::Setter, structure, offset, conditionSet, WTFMove(prototypeAccessChain));
              }
          }
  
<span class="line-modified">!         LOG_IC((ICEvent::PutByIdAddAccessCase, structure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
  
          result = stubInfo.addAccessCase(locker, codeBlock, ident, WTFMove(newCase));
  
          if (result.generatedSomeCode()) {
<span class="line-modified">!             LOG_IC((ICEvent::PutByIdReplaceWithJump, structure-&gt;classInfo(), ident, slot.base() == baseValue));</span>
  
              RELEASE_ASSERT(result.code());
  
              InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
          }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 652,11 ***</span>
                  &amp;&amp; slot.slotBase() == base
                  &amp;&amp; !slot.watchpointSet()
                  &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
                  bool generatedCodeInline = InlineAccess::generateSelfInAccess(stubInfo, structure);
                  if (generatedCodeInline) {
<span class="line-modified">!                     LOG_IC((ICEvent::InByIdSelfPatch, structure-&gt;classInfo(), ident));</span>
                      structure-&gt;startWatchingPropertyForReplacements(vm, slot.cachedOffset());
                      ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), operationInByIdOptimize);
                      stubInfo.initInByIdSelf(codeBlock, structure, slot.cachedOffset());
                      return RetryCacheLater;
                  }
<span class="line-new-header">--- 656,11 ---</span>
                  &amp;&amp; slot.slotBase() == base
                  &amp;&amp; !slot.watchpointSet()
                  &amp;&amp; !structure-&gt;needImpurePropertyWatchpoint()) {
                  bool generatedCodeInline = InlineAccess::generateSelfInAccess(stubInfo, structure);
                  if (generatedCodeInline) {
<span class="line-modified">!                     LOG_IC((ICEvent::InByIdSelfPatch, structure-&gt;classInfo(), ident, slot.slotBase() == base));</span>
                      structure-&gt;startWatchingPropertyForReplacements(vm, slot.cachedOffset());
                      ftlThunkAwareRepatchCall(codeBlock, stubInfo.slowPathCallLocation(), operationInByIdOptimize);
                      stubInfo.initInByIdSelf(codeBlock, structure, slot.cachedOffset());
                      return RetryCacheLater;
                  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 690,19 ***</span>
              }
          }
          if (!conditionSet.isValid())
              return GiveUpOnCache;
  
<span class="line-modified">!         LOG_IC((ICEvent::InAddAccessCase, structure-&gt;classInfo(), ident));</span>
  
          std::unique_ptr&lt;AccessCase&gt; newCase = AccessCase::create(
              vm, codeBlock, wasFound ? AccessCase::InHit : AccessCase::InMiss, wasFound ? slot.cachedOffset() : invalidOffset, structure, conditionSet, WTFMove(prototypeAccessChain));
  
          result = stubInfo.addAccessCase(locker, codeBlock, ident, WTFMove(newCase));
  
          if (result.generatedSomeCode()) {
<span class="line-modified">!             LOG_IC((ICEvent::InReplaceWithJump, structure-&gt;classInfo(), ident));</span>
  
              RELEASE_ASSERT(result.code());
              InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
          }
      }
<span class="line-new-header">--- 694,19 ---</span>
              }
          }
          if (!conditionSet.isValid())
              return GiveUpOnCache;
  
<span class="line-modified">!         LOG_IC((ICEvent::InAddAccessCase, structure-&gt;classInfo(), ident, slot.slotBase() == base));</span>
  
          std::unique_ptr&lt;AccessCase&gt; newCase = AccessCase::create(
              vm, codeBlock, wasFound ? AccessCase::InHit : AccessCase::InMiss, wasFound ? slot.cachedOffset() : invalidOffset, structure, conditionSet, WTFMove(prototypeAccessChain));
  
          result = stubInfo.addAccessCase(locker, codeBlock, ident, WTFMove(newCase));
  
          if (result.generatedSomeCode()) {
<span class="line-modified">!             LOG_IC((ICEvent::InReplaceWithJump, structure-&gt;classInfo(), ident, slot.slotBase() == base));</span>
  
              RELEASE_ASSERT(result.code());
              InlineAccess::rewireStubAsJump(stubInfo, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(result.code()));
          }
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 793,25 ***</span>
      SuperSamplerScope superSamplerScope(false);
      if (tryCacheInstanceOf(exec, valueValue, prototypeValue, stubInfo, wasFound) == GiveUpOnCache)
          ftlThunkAwareRepatchCall(exec-&gt;codeBlock(), stubInfo.slowPathCallLocation(), operationInstanceOfGeneric);
  }
  
<span class="line-modified">! static void linkSlowFor(VM*, CallLinkInfo&amp; callLinkInfo, MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; codeRef)</span>
  {
      MacroAssembler::repatchNearCall(callLinkInfo.callReturnLocation(), CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(codeRef.code()));
  }
  
<span class="line-modified">! static void linkSlowFor(VM* vm, CallLinkInfo&amp; callLinkInfo, ThunkGenerator generator)</span>
  {
<span class="line-modified">!     linkSlowFor(vm, callLinkInfo, vm-&gt;getCTIStub(generator).retagged&lt;JITStubRoutinePtrTag&gt;());</span>
  }
  
<span class="line-modified">! static void linkSlowFor(VM* vm, CallLinkInfo&amp; callLinkInfo)</span>
  {
      MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, callLinkInfo);
      linkSlowFor(vm, callLinkInfo, virtualThunk);
<span class="line-modified">!     callLinkInfo.setSlowStub(createJITStubRoutine(virtualThunk, *vm, nullptr, true));</span>
  }
  
  static JSCell* webAssemblyOwner(JSCell* callee)
  {
  #if ENABLE(WEBASSEMBLY)
<span class="line-new-header">--- 797,25 ---</span>
      SuperSamplerScope superSamplerScope(false);
      if (tryCacheInstanceOf(exec, valueValue, prototypeValue, stubInfo, wasFound) == GiveUpOnCache)
          ftlThunkAwareRepatchCall(exec-&gt;codeBlock(), stubInfo.slowPathCallLocation(), operationInstanceOfGeneric);
  }
  
<span class="line-modified">! static void linkSlowFor(VM&amp;, CallLinkInfo&amp; callLinkInfo, MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; codeRef)</span>
  {
      MacroAssembler::repatchNearCall(callLinkInfo.callReturnLocation(), CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(codeRef.code()));
  }
  
<span class="line-modified">! static void linkSlowFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo, ThunkGenerator generator)</span>
  {
<span class="line-modified">!     linkSlowFor(vm, callLinkInfo, vm.getCTIStub(generator).retagged&lt;JITStubRoutinePtrTag&gt;());</span>
  }
  
<span class="line-modified">! static void linkSlowFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo)</span>
  {
      MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, callLinkInfo);
      linkSlowFor(vm, callLinkInfo, virtualThunk);
<span class="line-modified">!     callLinkInfo.setSlowStub(createJITStubRoutine(virtualThunk, vm, nullptr, true));</span>
  }
  
  static JSCell* webAssemblyOwner(JSCell* callee)
  {
  #if ENABLE(WEBASSEMBLY)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 842,39 ***</span>
      JSCell* owner = isWebAssemblyToJSCallee(callerFrame-&gt;callee().asCell()) ? webAssemblyOwner(callerFrame-&gt;callee().asCell()) : callerCodeBlock;
      ASSERT(owner);
  
      ASSERT(!callLinkInfo.isLinked());
      callLinkInfo.setCallee(vm, owner, callee);
      callLinkInfo.setLastSeenCallee(vm, owner, callee);
      if (shouldDumpDisassemblyFor(callerCodeBlock))
          dataLog(&quot;Linking call in &quot;, FullCodeOrigin(callerCodeBlock, callLinkInfo.codeOrigin()), &quot; to &quot;, pointerDump(calleeCodeBlock), &quot;, entrypoint at &quot;, codePtr, &quot;\n&quot;);
  
      MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), CodeLocationLabel&lt;JSEntryPtrTag&gt;(codePtr));
  
      if (calleeCodeBlock)
          calleeCodeBlock-&gt;linkIncomingCall(callerFrame, &amp;callLinkInfo);
  
      if (callLinkInfo.specializationKind() == CodeForCall &amp;&amp; callLinkInfo.allowStubs()) {
<span class="line-modified">!         linkSlowFor(&amp;vm, callLinkInfo, linkPolymorphicCallThunkGenerator);</span>
          return;
      }
  
<span class="line-modified">!     linkSlowFor(&amp;vm, callLinkInfo);</span>
  }
  
  void linkDirectFor(
      ExecState* exec, CallLinkInfo&amp; callLinkInfo, CodeBlock* calleeCodeBlock,
      MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr)
  {
      ASSERT(!callLinkInfo.stub());
  
      CodeBlock* callerCodeBlock = exec-&gt;codeBlock();
  
<span class="line-modified">!     VM* vm = callerCodeBlock-&gt;vm();</span>
  
      ASSERT(!callLinkInfo.isLinked());
<span class="line-modified">!     callLinkInfo.setCodeBlock(*vm, callerCodeBlock, jsCast&lt;FunctionCodeBlock*&gt;(calleeCodeBlock));</span>
      if (shouldDumpDisassemblyFor(callerCodeBlock))
          dataLog(&quot;Linking call in &quot;, FullCodeOrigin(callerCodeBlock, callLinkInfo.codeOrigin()), &quot; to &quot;, pointerDump(calleeCodeBlock), &quot;, entrypoint at &quot;, codePtr, &quot;\n&quot;);
  
      if (callLinkInfo.callType() == CallLinkInfo::DirectTailCall)
          MacroAssembler::repatchJumpToNop(callLinkInfo.patchableJump());
<span class="line-new-header">--- 846,40 ---</span>
      JSCell* owner = isWebAssemblyToJSCallee(callerFrame-&gt;callee().asCell()) ? webAssemblyOwner(callerFrame-&gt;callee().asCell()) : callerCodeBlock;
      ASSERT(owner);
  
      ASSERT(!callLinkInfo.isLinked());
      callLinkInfo.setCallee(vm, owner, callee);
<span class="line-added">+     MacroAssembler::repatchPointer(callLinkInfo.hotPathBegin(), callee);</span>
      callLinkInfo.setLastSeenCallee(vm, owner, callee);
      if (shouldDumpDisassemblyFor(callerCodeBlock))
          dataLog(&quot;Linking call in &quot;, FullCodeOrigin(callerCodeBlock, callLinkInfo.codeOrigin()), &quot; to &quot;, pointerDump(calleeCodeBlock), &quot;, entrypoint at &quot;, codePtr, &quot;\n&quot;);
  
      MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), CodeLocationLabel&lt;JSEntryPtrTag&gt;(codePtr));
  
      if (calleeCodeBlock)
          calleeCodeBlock-&gt;linkIncomingCall(callerFrame, &amp;callLinkInfo);
  
      if (callLinkInfo.specializationKind() == CodeForCall &amp;&amp; callLinkInfo.allowStubs()) {
<span class="line-modified">!         linkSlowFor(vm, callLinkInfo, linkPolymorphicCallThunkGenerator);</span>
          return;
      }
  
<span class="line-modified">!     linkSlowFor(vm, callLinkInfo);</span>
  }
  
  void linkDirectFor(
      ExecState* exec, CallLinkInfo&amp; callLinkInfo, CodeBlock* calleeCodeBlock,
      MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr)
  {
      ASSERT(!callLinkInfo.stub());
  
      CodeBlock* callerCodeBlock = exec-&gt;codeBlock();
  
<span class="line-modified">!     VM&amp; vm = callerCodeBlock-&gt;vm();</span>
  
      ASSERT(!callLinkInfo.isLinked());
<span class="line-modified">!     callLinkInfo.setCodeBlock(vm, callerCodeBlock, jsCast&lt;FunctionCodeBlock*&gt;(calleeCodeBlock));</span>
      if (shouldDumpDisassemblyFor(callerCodeBlock))
          dataLog(&quot;Linking call in &quot;, FullCodeOrigin(callerCodeBlock, callLinkInfo.codeOrigin()), &quot; to &quot;, pointerDump(calleeCodeBlock), &quot;, entrypoint at &quot;, codePtr, &quot;\n&quot;);
  
      if (callLinkInfo.callType() == CallLinkInfo::DirectTailCall)
          MacroAssembler::repatchJumpToNop(callLinkInfo.patchableJump());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 886,28 ***</span>
  
  void linkSlowFor(
      ExecState* exec, CallLinkInfo&amp; callLinkInfo)
  {
      CodeBlock* callerCodeBlock = exec-&gt;callerFrame()-&gt;codeBlock();
<span class="line-modified">!     VM* vm = callerCodeBlock-&gt;vm();</span>
  
      linkSlowFor(vm, callLinkInfo);
  }
  
<span class="line-modified">! static void revertCall(VM* vm, CallLinkInfo&amp; callLinkInfo, MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; codeRef)</span>
  {
      if (callLinkInfo.isDirect()) {
          callLinkInfo.clearCodeBlock();
<span class="line-modified">!         if (callLinkInfo.callType() == CallLinkInfo::DirectTailCall)</span>
<span class="line-modified">!             MacroAssembler::repatchJump(callLinkInfo.patchableJump(), callLinkInfo.slowPathStart());</span>
<span class="line-modified">!         else</span>
<span class="line-modified">!             MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), callLinkInfo.slowPathStart());</span>
      } else {
<span class="line-modified">!         MacroAssembler::revertJumpReplacementToBranchPtrWithPatch(</span>
<span class="line-modified">!             MacroAssembler::startOfBranchPtrWithPatchOnRegister(callLinkInfo.hotPathBegin()),</span>
<span class="line-modified">!             static_cast&lt;MacroAssembler::RegisterID&gt;(callLinkInfo.calleeGPR()), 0);</span>
<span class="line-modified">!         linkSlowFor(vm, callLinkInfo, codeRef);</span>
          callLinkInfo.clearCallee();
      }
      callLinkInfo.clearSeen();
      callLinkInfo.clearStub();
      callLinkInfo.clearSlowStub();
<span class="line-new-header">--- 891,33 ---</span>
  
  void linkSlowFor(
      ExecState* exec, CallLinkInfo&amp; callLinkInfo)
  {
      CodeBlock* callerCodeBlock = exec-&gt;callerFrame()-&gt;codeBlock();
<span class="line-modified">!     VM&amp; vm = callerCodeBlock-&gt;vm();</span>
  
      linkSlowFor(vm, callLinkInfo);
  }
  
<span class="line-modified">! static void revertCall(VM&amp; vm, CallLinkInfo&amp; callLinkInfo, MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; codeRef)</span>
  {
      if (callLinkInfo.isDirect()) {
          callLinkInfo.clearCodeBlock();
<span class="line-modified">!         if (!callLinkInfo.clearedByJettison()) {</span>
<span class="line-modified">!             if (callLinkInfo.callType() == CallLinkInfo::DirectTailCall)</span>
<span class="line-modified">!                 MacroAssembler::repatchJump(callLinkInfo.patchableJump(), callLinkInfo.slowPathStart());</span>
<span class="line-modified">!             else</span>
<span class="line-added">+                 MacroAssembler::repatchNearCall(callLinkInfo.hotPathOther(), callLinkInfo.slowPathStart());</span>
<span class="line-added">+         }</span>
      } else {
<span class="line-modified">!         if (!callLinkInfo.clearedByJettison()) {</span>
<span class="line-modified">!             MacroAssembler::revertJumpReplacementToBranchPtrWithPatch(</span>
<span class="line-modified">!                 MacroAssembler::startOfBranchPtrWithPatchOnRegister(callLinkInfo.hotPathBegin()),</span>
<span class="line-modified">!                 callLinkInfo.calleeGPR(), 0);</span>
<span class="line-added">+             linkSlowFor(vm, callLinkInfo, codeRef);</span>
<span class="line-added">+             MacroAssembler::repatchPointer(callLinkInfo.hotPathBegin(), nullptr);</span>
<span class="line-added">+         }</span>
          callLinkInfo.clearCallee();
      }
      callLinkInfo.clearSeen();
      callLinkInfo.clearStub();
      callLinkInfo.clearSlowStub();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 918,24 ***</span>
  void unlinkFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo)
  {
      if (Options::dumpDisassembly())
          dataLog(&quot;Unlinking call at &quot;, callLinkInfo.hotPathOther(), &quot;\n&quot;);
  
<span class="line-modified">!     revertCall(&amp;vm, callLinkInfo, vm.getCTIStub(linkCallThunkGenerator).retagged&lt;JITStubRoutinePtrTag&gt;());</span>
  }
  
<span class="line-modified">! void linkVirtualFor(ExecState* exec, CallLinkInfo&amp; callLinkInfo)</span>
  {
      CallFrame* callerFrame = exec-&gt;callerFrame();
      VM&amp; vm = callerFrame-&gt;vm();
      CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
  
      if (shouldDumpDisassemblyFor(callerCodeBlock))
          dataLog(&quot;Linking virtual call at &quot;, FullCodeOrigin(callerCodeBlock, callerFrame-&gt;codeOrigin()), &quot;\n&quot;);
  
<span class="line-modified">!     MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(&amp;vm, callLinkInfo);</span>
<span class="line-modified">!     revertCall(&amp;vm, callLinkInfo, virtualThunk);</span>
      callLinkInfo.setSlowStub(createJITStubRoutine(virtualThunk, vm, nullptr, true));
      callLinkInfo.setClearedByVirtual();
  }
  
  namespace {
<span class="line-new-header">--- 928,24 ---</span>
  void unlinkFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo)
  {
      if (Options::dumpDisassembly())
          dataLog(&quot;Unlinking call at &quot;, callLinkInfo.hotPathOther(), &quot;\n&quot;);
  
<span class="line-modified">!     revertCall(vm, callLinkInfo, vm.getCTIStub(linkCallThunkGenerator).retagged&lt;JITStubRoutinePtrTag&gt;());</span>
  }
  
<span class="line-modified">! static void linkVirtualFor(ExecState* exec, CallLinkInfo&amp; callLinkInfo)</span>
  {
      CallFrame* callerFrame = exec-&gt;callerFrame();
      VM&amp; vm = callerFrame-&gt;vm();
      CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
  
      if (shouldDumpDisassemblyFor(callerCodeBlock))
          dataLog(&quot;Linking virtual call at &quot;, FullCodeOrigin(callerCodeBlock, callerFrame-&gt;codeOrigin()), &quot;\n&quot;);
  
<span class="line-modified">!     MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunk = virtualThunkFor(vm, callLinkInfo);</span>
<span class="line-modified">!     revertCall(vm, callLinkInfo, virtualThunk);</span>
      callLinkInfo.setSlowStub(createJITStubRoutine(virtualThunk, vm, nullptr, true));
      callLinkInfo.setClearedByVirtual();
  }
  
  namespace {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 948,22 ***</span>
  void linkPolymorphicCall(
      ExecState* exec, CallLinkInfo&amp; callLinkInfo, CallVariant newVariant)
  {
      RELEASE_ASSERT(callLinkInfo.allowStubs());
  
      if (!newVariant) {
          linkVirtualFor(exec, callLinkInfo);
          return;
      }
  
<span class="line-removed">-     CallFrame* callerFrame = exec-&gt;callerFrame();</span>
<span class="line-removed">- </span>
      // Our caller must be have a cell for a callee. When calling
      // this from Wasm, we ensure the callee is a cell.
      ASSERT(callerFrame-&gt;callee().isCell());
  
<span class="line-removed">-     VM&amp; vm = callerFrame-&gt;vm();</span>
      CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
      bool isWebAssembly = isWebAssemblyToJSCallee(callerFrame-&gt;callee().asCell());
  
      // WebAssembly -&gt; JS stubs don&#39;t have a valid CodeBlock.
      JSCell* owner = isWebAssembly ? webAssemblyOwner(callerFrame-&gt;callee().asCell()) : callerCodeBlock;
<span class="line-new-header">--- 958,26 ---</span>
  void linkPolymorphicCall(
      ExecState* exec, CallLinkInfo&amp; callLinkInfo, CallVariant newVariant)
  {
      RELEASE_ASSERT(callLinkInfo.allowStubs());
  
<span class="line-added">+     CallFrame* callerFrame = exec-&gt;callerFrame();</span>
<span class="line-added">+     VM&amp; vm = callerFrame-&gt;vm();</span>
<span class="line-added">+ </span>
<span class="line-added">+     // During execution of linkPolymorphicCall, we strongly assume that we never do GC.</span>
<span class="line-added">+     // GC jettisons CodeBlocks, changes CallLinkInfo etc. and breaks assumption done before and after this call.</span>
<span class="line-added">+     DeferGCForAWhile deferGCForAWhile(vm.heap);</span>
<span class="line-added">+ </span>
      if (!newVariant) {
          linkVirtualFor(exec, callLinkInfo);
          return;
      }
  
      // Our caller must be have a cell for a callee. When calling
      // this from Wasm, we ensure the callee is a cell.
      ASSERT(callerFrame-&gt;callee().isCell());
  
      CodeBlock* callerCodeBlock = callerFrame-&gt;codeBlock();
      bool isWebAssembly = isWebAssemblyToJSCallee(callerFrame-&gt;callee().asCell());
  
      // WebAssembly -&gt; JS stubs don&#39;t have a valid CodeBlock.
      JSCell* owner = isWebAssembly ? webAssemblyOwner(callerFrame-&gt;callee().asCell()) : callerCodeBlock;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 971,11 ***</span>
  
      CallVariantList list;
      if (PolymorphicCallStubRoutine* stub = callLinkInfo.stub())
          list = stub-&gt;variants();
      else if (JSObject* oldCallee = callLinkInfo.callee())
<span class="line-modified">!         list = CallVariantList{ CallVariant(oldCallee) };</span>
  
      list = variantListWithVariant(list, newVariant);
  
      // If there are any closure calls then it makes sense to treat all of them as closure calls.
      // This makes switching on callee cheaper. It also produces profiling that&#39;s easier on the DFG;
<span class="line-new-header">--- 985,11 ---</span>
  
      CallVariantList list;
      if (PolymorphicCallStubRoutine* stub = callLinkInfo.stub())
          list = stub-&gt;variants();
      else if (JSObject* oldCallee = callLinkInfo.callee())
<span class="line-modified">!         list = CallVariantList { CallVariant(oldCallee) };</span>
  
      list = variantListWithVariant(list, newVariant);
  
      // If there are any closure calls then it makes sense to treat all of them as closure calls.
      // This makes switching on callee cheaper. It also produces profiling that&#39;s easier on the DFG;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 991,10 ***</span>
<span class="line-new-header">--- 1005,11 ---</span>
  
      if (isClosureCall)
          callLinkInfo.setHasSeenClosure();
  
      Vector&lt;PolymorphicCallCase&gt; callCases;
<span class="line-added">+     Vector&lt;int64_t&gt; caseValues;</span>
  
      // Figure out what our cases are.
      for (CallVariant variant : list) {
          CodeBlock* codeBlock = nullptr;
          if (variant.executable() &amp;&amp; !variant.executable()-&gt;isHostFunction()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1006,138 ***</span>
                  linkVirtualFor(exec, callLinkInfo);
                  return;
              }
          }
  
          callCases.append(PolymorphicCallCase(variant, codeBlock));
      }
  
      // If we are over the limit, just use a normal virtual call.
      unsigned maxPolymorphicCallVariantListSize;
      if (isWebAssembly)
          maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSizeForWebAssemblyToJS();
      else if (callerCodeBlock-&gt;jitType() == JITCode::topTierJIT())
          maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSizeForTopTier();
      else
          maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSize();
  
      if (list.size() &gt; maxPolymorphicCallVariantListSize) {
          linkVirtualFor(exec, callLinkInfo);
          return;
      }
  
<span class="line-modified">!     GPRReg calleeGPR = static_cast&lt;GPRReg&gt;(callLinkInfo.calleeGPR());</span>
  
<span class="line-modified">!     CCallHelpers stubJit(callerCodeBlock);</span>
  
<span class="line-modified">!     CCallHelpers::JumpList slowPath;</span>
  
      std::unique_ptr&lt;CallFrameShuffler&gt; frameShuffler;
      if (callLinkInfo.frameShuffleData()) {
          ASSERT(callLinkInfo.isTailCall());
<span class="line-modified">!         frameShuffler = std::make_unique&lt;CallFrameShuffler&gt;(stubJit, *callLinkInfo.frameShuffleData());</span>
  #if USE(JSVALUE32_64)
          // We would have already checked that the callee is a cell, and we can
          // use the additional register this buys us.
          frameShuffler-&gt;assumeCalleeIsCell();
  #endif
          frameShuffler-&gt;lockGPR(calleeGPR);
      }
<span class="line-removed">-     GPRReg comparisonValueGPR;</span>
  
      if (isClosureCall) {
<span class="line-removed">-         GPRReg scratchGPR;</span>
          if (frameShuffler)
<span class="line-modified">!             scratchGPR = frameShuffler-&gt;acquireGPR();</span>
          else
<span class="line-modified">!             scratchGPR = AssemblyHelpers::selectScratchGPR(calleeGPR);</span>
<span class="line-removed">-         // Verify that we have a function and stash the executable in scratchGPR.</span>
<span class="line-removed">- </span>
<span class="line-removed">- #if USE(JSVALUE64)</span>
<span class="line-removed">-         slowPath.append(stubJit.branchIfNotCell(calleeGPR));</span>
<span class="line-removed">- #else</span>
<span class="line-removed">-         // We would have already checked that the callee is a cell.</span>
<span class="line-removed">- #endif</span>
<span class="line-removed">- </span>
<span class="line-removed">-         // FIXME: We could add a fast path for InternalFunction with closure call.</span>
<span class="line-removed">-         slowPath.append(stubJit.branchIfNotFunction(calleeGPR));</span>
<span class="line-removed">- </span>
<span class="line-removed">-         stubJit.loadPtr(</span>
<span class="line-removed">-             CCallHelpers::Address(calleeGPR, JSFunction::offsetOfExecutable()),</span>
<span class="line-removed">-             scratchGPR);</span>
<span class="line-removed">- </span>
<span class="line-removed">-         comparisonValueGPR = scratchGPR;</span>
      } else
          comparisonValueGPR = calleeGPR;
  
<span class="line-removed">-     Vector&lt;int64_t&gt; caseValues(callCases.size());</span>
<span class="line-removed">-     Vector&lt;CallToCodePtr&gt; calls(callCases.size());</span>
<span class="line-removed">-     UniqueArray&lt;uint32_t&gt; fastCounts;</span>
<span class="line-removed">- </span>
<span class="line-removed">-     if (!isWebAssembly &amp;&amp; callerCodeBlock-&gt;jitType() != JITCode::topTierJIT())</span>
<span class="line-removed">-         fastCounts = makeUniqueArray&lt;uint32_t&gt;(callCases.size());</span>
<span class="line-removed">- </span>
<span class="line-removed">-     for (size_t i = 0; i &lt; callCases.size(); ++i) {</span>
<span class="line-removed">-         if (fastCounts)</span>
<span class="line-removed">-             fastCounts[i] = 0;</span>
<span class="line-removed">- </span>
<span class="line-removed">-         CallVariant variant = callCases[i].variant();</span>
<span class="line-removed">-         int64_t newCaseValue = 0;</span>
<span class="line-removed">-         if (isClosureCall) {</span>
<span class="line-removed">-             newCaseValue = bitwise_cast&lt;intptr_t&gt;(variant.executable());</span>
<span class="line-removed">-             // FIXME: We could add a fast path for InternalFunction with closure call.</span>
<span class="line-removed">-             // https://bugs.webkit.org/show_bug.cgi?id=179311</span>
<span class="line-removed">-             if (!newCaseValue)</span>
<span class="line-removed">-                 continue;</span>
<span class="line-removed">-         } else {</span>
<span class="line-removed">-             if (auto* function = variant.function())</span>
<span class="line-removed">-                 newCaseValue = bitwise_cast&lt;intptr_t&gt;(function);</span>
<span class="line-removed">-             else</span>
<span class="line-removed">-                 newCaseValue = bitwise_cast&lt;intptr_t&gt;(variant.internalFunction());</span>
<span class="line-removed">-         }</span>
<span class="line-removed">- </span>
<span class="line-removed">-         if (!ASSERT_DISABLED) {</span>
<span class="line-removed">-             for (size_t j = 0; j &lt; i; ++j) {</span>
<span class="line-removed">-                 if (caseValues[j] != newCaseValue)</span>
<span class="line-removed">-                     continue;</span>
<span class="line-removed">- </span>
<span class="line-removed">-                 dataLog(&quot;ERROR: Attempt to add duplicate case value.\n&quot;);</span>
<span class="line-removed">-                 dataLog(&quot;Existing case values: &quot;);</span>
<span class="line-removed">-                 CommaPrinter comma;</span>
<span class="line-removed">-                 for (size_t k = 0; k &lt; i; ++k)</span>
<span class="line-removed">-                     dataLog(comma, caseValues[k]);</span>
<span class="line-removed">-                 dataLog(&quot;\n&quot;);</span>
<span class="line-removed">-                 dataLog(&quot;Attempting to add: &quot;, newCaseValue, &quot;\n&quot;);</span>
<span class="line-removed">-                 dataLog(&quot;Variant list: &quot;, listDump(callCases), &quot;\n&quot;);</span>
<span class="line-removed">-                 RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-removed">-             }</span>
<span class="line-removed">-         }</span>
<span class="line-removed">- </span>
<span class="line-removed">-         caseValues[i] = newCaseValue;</span>
<span class="line-removed">-     }</span>
<span class="line-removed">- </span>
      GPRReg fastCountsBaseGPR;
      if (frameShuffler)
          fastCountsBaseGPR = frameShuffler-&gt;acquireGPR();
      else {
          fastCountsBaseGPR =
              AssemblyHelpers::selectScratchGPR(calleeGPR, comparisonValueGPR, GPRInfo::regT3);
      }
      stubJit.move(CCallHelpers::TrustedImmPtr(fastCounts.get()), fastCountsBaseGPR);
<span class="line-modified">!     if (!frameShuffler &amp;&amp; callLinkInfo.isTailCall())</span>
          stubJit.emitRestoreCalleeSaves();
      BinarySwitch binarySwitch(comparisonValueGPR, caseValues, BinarySwitch::IntPtr);
      CCallHelpers::JumpList done;
      while (binarySwitch.advance(stubJit)) {
          size_t caseIndex = binarySwitch.caseIndex();
  
          CallVariant variant = callCases[caseIndex].variant();
  
          MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr;
          if (variant.executable()) {
              ASSERT(variant.executable()-&gt;hasJITCodeForCall());
<span class="line-modified">!             codePtr = variant.executable()-&gt;generatedJITCodeForCall()-&gt;addressForCall(ArityCheckNotRequired);</span>
          } else {
              ASSERT(variant.internalFunction());
              codePtr = vm.getCTIInternalFunctionTrampolineFor(CodeForCall);
          }
  
<span class="line-new-header">--- 1021,139 ---</span>
                  linkVirtualFor(exec, callLinkInfo);
                  return;
              }
          }
  
<span class="line-added">+         int64_t newCaseValue = 0;</span>
<span class="line-added">+         if (isClosureCall) {</span>
<span class="line-added">+             newCaseValue = bitwise_cast&lt;intptr_t&gt;(variant.executable());</span>
<span class="line-added">+             // FIXME: We could add a fast path for InternalFunction with closure call.</span>
<span class="line-added">+             // https://bugs.webkit.org/show_bug.cgi?id=179311</span>
<span class="line-added">+             if (!newCaseValue)</span>
<span class="line-added">+                 continue;</span>
<span class="line-added">+         } else {</span>
<span class="line-added">+             if (auto* function = variant.function())</span>
<span class="line-added">+                 newCaseValue = bitwise_cast&lt;intptr_t&gt;(function);</span>
<span class="line-added">+             else</span>
<span class="line-added">+                 newCaseValue = bitwise_cast&lt;intptr_t&gt;(variant.internalFunction());</span>
<span class="line-added">+         }</span>
<span class="line-added">+ </span>
<span class="line-added">+         if (!ASSERT_DISABLED) {</span>
<span class="line-added">+             if (caseValues.contains(newCaseValue)) {</span>
<span class="line-added">+                 dataLog(&quot;ERROR: Attempt to add duplicate case value.\n&quot;);</span>
<span class="line-added">+                 dataLog(&quot;Existing case values: &quot;);</span>
<span class="line-added">+                 CommaPrinter comma;</span>
<span class="line-added">+                 for (auto&amp; value : caseValues)</span>
<span class="line-added">+                     dataLog(comma, value);</span>
<span class="line-added">+                 dataLog(&quot;\n&quot;);</span>
<span class="line-added">+                 dataLog(&quot;Attempting to add: &quot;, newCaseValue, &quot;\n&quot;);</span>
<span class="line-added">+                 dataLog(&quot;Variant list: &quot;, listDump(callCases), &quot;\n&quot;);</span>
<span class="line-added">+                 RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">+             }</span>
<span class="line-added">+         }</span>
<span class="line-added">+ </span>
          callCases.append(PolymorphicCallCase(variant, codeBlock));
<span class="line-added">+         caseValues.append(newCaseValue);</span>
      }
<span class="line-added">+     ASSERT(callCases.size() == caseValues.size());</span>
  
      // If we are over the limit, just use a normal virtual call.
      unsigned maxPolymorphicCallVariantListSize;
      if (isWebAssembly)
          maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSizeForWebAssemblyToJS();
      else if (callerCodeBlock-&gt;jitType() == JITCode::topTierJIT())
          maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSizeForTopTier();
      else
          maxPolymorphicCallVariantListSize = Options::maxPolymorphicCallVariantListSize();
  
<span class="line-added">+     // We use list.size() instead of callCases.size() because we respect CallVariant size for now.</span>
      if (list.size() &gt; maxPolymorphicCallVariantListSize) {
          linkVirtualFor(exec, callLinkInfo);
          return;
      }
  
<span class="line-modified">!     Vector&lt;CallToCodePtr&gt; calls(callCases.size());</span>
<span class="line-added">+     UniqueArray&lt;uint32_t&gt; fastCounts;</span>
  
<span class="line-modified">!     if (!isWebAssembly &amp;&amp; callerCodeBlock-&gt;jitType() != JITCode::topTierJIT()) {</span>
<span class="line-added">+         fastCounts = makeUniqueArray&lt;uint32_t&gt;(callCases.size());</span>
<span class="line-added">+         memset(fastCounts.get(), 0, callCases.size() * sizeof(uint32_t));</span>
<span class="line-added">+     }</span>
  
<span class="line-modified">!     GPRReg calleeGPR = callLinkInfo.calleeGPR();</span>
<span class="line-added">+ </span>
<span class="line-added">+     CCallHelpers stubJit(callerCodeBlock);</span>
  
      std::unique_ptr&lt;CallFrameShuffler&gt; frameShuffler;
      if (callLinkInfo.frameShuffleData()) {
          ASSERT(callLinkInfo.isTailCall());
<span class="line-modified">!         frameShuffler = makeUnique&lt;CallFrameShuffler&gt;(stubJit, *callLinkInfo.frameShuffleData());</span>
  #if USE(JSVALUE32_64)
          // We would have already checked that the callee is a cell, and we can
          // use the additional register this buys us.
          frameShuffler-&gt;assumeCalleeIsCell();
  #endif
          frameShuffler-&gt;lockGPR(calleeGPR);
      }
  
<span class="line-added">+     GPRReg comparisonValueGPR;</span>
      if (isClosureCall) {
          if (frameShuffler)
<span class="line-modified">!             comparisonValueGPR = frameShuffler-&gt;acquireGPR();</span>
          else
<span class="line-modified">!             comparisonValueGPR = AssemblyHelpers::selectScratchGPR(calleeGPR);</span>
      } else
          comparisonValueGPR = calleeGPR;
  
      GPRReg fastCountsBaseGPR;
      if (frameShuffler)
          fastCountsBaseGPR = frameShuffler-&gt;acquireGPR();
      else {
          fastCountsBaseGPR =
              AssemblyHelpers::selectScratchGPR(calleeGPR, comparisonValueGPR, GPRInfo::regT3);
      }
      stubJit.move(CCallHelpers::TrustedImmPtr(fastCounts.get()), fastCountsBaseGPR);
<span class="line-modified">! </span>
<span class="line-added">+     if (!frameShuffler &amp;&amp; callLinkInfo.isTailCall()) {</span>
<span class="line-added">+         // We strongly assume that calleeGPR is not a callee save register in the slow path.</span>
<span class="line-added">+         ASSERT(!callerCodeBlock-&gt;calleeSaveRegisters()-&gt;find(calleeGPR));</span>
          stubJit.emitRestoreCalleeSaves();
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     CCallHelpers::JumpList slowPath;</span>
<span class="line-added">+     if (isClosureCall) {</span>
<span class="line-added">+         // Verify that we have a function and stash the executable in scratchGPR.</span>
<span class="line-added">+ #if USE(JSVALUE64)</span>
<span class="line-added">+         if (callLinkInfo.isTailCall())</span>
<span class="line-added">+             slowPath.append(stubJit.branchIfNotCell(calleeGPR, DoNotHaveTagRegisters));</span>
<span class="line-added">+         else</span>
<span class="line-added">+             slowPath.append(stubJit.branchIfNotCell(calleeGPR));</span>
<span class="line-added">+ #else</span>
<span class="line-added">+         // We would have already checked that the callee is a cell.</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+         // FIXME: We could add a fast path for InternalFunction with closure call.</span>
<span class="line-added">+         slowPath.append(stubJit.branchIfNotFunction(calleeGPR));</span>
<span class="line-added">+ </span>
<span class="line-added">+         stubJit.loadPtr(</span>
<span class="line-added">+             CCallHelpers::Address(calleeGPR, JSFunction::offsetOfExecutable()),</span>
<span class="line-added">+             comparisonValueGPR);</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
      BinarySwitch binarySwitch(comparisonValueGPR, caseValues, BinarySwitch::IntPtr);
      CCallHelpers::JumpList done;
      while (binarySwitch.advance(stubJit)) {
          size_t caseIndex = binarySwitch.caseIndex();
  
          CallVariant variant = callCases[caseIndex].variant();
  
          MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; codePtr;
          if (variant.executable()) {
              ASSERT(variant.executable()-&gt;hasJITCodeForCall());
<span class="line-modified">! </span>
<span class="line-added">+             codePtr = jsToWasmICCodePtr(vm, callLinkInfo.specializationKind(), variant.function());</span>
<span class="line-added">+             if (!codePtr)</span>
<span class="line-added">+                 codePtr = variant.executable()-&gt;generatedJITCodeForCall()-&gt;addressForCall(ArityCheckNotRequired);</span>
          } else {
              ASSERT(variant.internalFunction());
              codePtr = vm.getCTIInternalFunctionTrampolineFor(CodeForCall);
          }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1220,11 ***</span>
          MacroAssembler::startOfBranchPtrWithPatchOnRegister(callLinkInfo.hotPathBegin()),
          CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(stubRoutine-&gt;code().code()));
      // The original slow path is unreachable on 64-bits, but still
      // reachable on 32-bits since a non-cell callee will always
      // trigger the slow path
<span class="line-modified">!     linkSlowFor(&amp;vm, callLinkInfo);</span>
  
      // If there had been a previous stub routine, that one will die as soon as the GC runs and sees
      // that it&#39;s no longer on stack.
      callLinkInfo.setStub(WTFMove(stubRoutine));
  
<span class="line-new-header">--- 1236,11 ---</span>
          MacroAssembler::startOfBranchPtrWithPatchOnRegister(callLinkInfo.hotPathBegin()),
          CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(stubRoutine-&gt;code().code()));
      // The original slow path is unreachable on 64-bits, but still
      // reachable on 32-bits since a non-cell callee will always
      // trigger the slow path
<span class="line-modified">!     linkSlowFor(vm, callLinkInfo);</span>
  
      // If there had been a previous stub routine, that one will die as soon as the GC runs and sees
      // that it&#39;s no longer on stack.
      callLinkInfo.setStub(WTFMove(stubRoutine));
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1273,8 ***</span>
<span class="line-new-header">--- 1289,25 ---</span>
  void resetInstanceOf(StructureStubInfo&amp; stubInfo)
  {
      resetPatchableJump(stubInfo);
  }
  
<span class="line-added">+ MacroAssemblerCodePtr&lt;JSEntryPtrTag&gt; jsToWasmICCodePtr(VM&amp; vm, CodeSpecializationKind kind, JSObject* callee)</span>
<span class="line-added">+ {</span>
<span class="line-added">+ #if ENABLE(WEBASSEMBLY)</span>
<span class="line-added">+     if (!callee)</span>
<span class="line-added">+         return nullptr;</span>
<span class="line-added">+     if (kind != CodeForCall)</span>
<span class="line-added">+         return nullptr;</span>
<span class="line-added">+     if (auto* wasmFunction = jsDynamicCast&lt;WebAssemblyFunction*&gt;(vm, callee))</span>
<span class="line-added">+         return wasmFunction-&gt;jsCallEntrypoint();</span>
<span class="line-added">+ #else</span>
<span class="line-added">+     UNUSED_PARAM(vm);</span>
<span class="line-added">+     UNUSED_PARAM(kind);</span>
<span class="line-added">+     UNUSED_PARAM(callee);</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+     return nullptr;</span>
<span class="line-added">+ }</span>
<span class="line-added">+ </span>
  } // namespace JSC
  
  #endif
</pre>
<center><a href="RegisterSet.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="Repatch.h.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>