<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGGraph.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGInPlaceAbstractState.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2011-2018 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
</pre>
<hr />
<pre>
 102     } while (false)
 103 
 104 #define DFG_CRASH(graph, node, reason, ...) do {                        \
 105         (graph).logAssertionFailure(                                    \
 106             (node), __FILE__, __LINE__, WTF_PRETTY_FUNCTION, (reason)); \
 107         CRASH_WITH_SECURITY_IMPLICATION_AND_INFO(__VA_ARGS__);          \
 108     } while (false)
 109 
 110 struct InlineVariableData {
 111     InlineCallFrame* inlineCallFrame;
 112     unsigned argumentPositionStart;
 113     VariableAccessData* calleeVariable;
 114 };
 115 
 116 enum AddSpeculationMode {
 117     DontSpeculateInt32,
 118     SpeculateInt32AndTruncateConstants,
 119     SpeculateInt32
 120 };
 121 


































 122 //
 123 // === Graph ===
 124 //
 125 // The order may be significant for nodes with side-effects (property accesses, value conversions).
 126 // Nodes that are &#39;dead&#39; remain in the vector with refCount 0.
 127 class Graph : public virtual Scannable {
 128 public:
 129     Graph(VM&amp;, Plan&amp;);
 130     ~Graph();
 131 
 132     void changeChild(Edge&amp; edge, Node* newNode)
 133     {
 134         edge.setNode(newNode);
 135     }
 136 
 137     void changeEdge(Edge&amp; edge, Edge newEdge)
 138     {
 139         edge = newEdge;
 140     }
 141 
</pre>
<hr />
<pre>
 267         return addSpeculationMode(
 268             add,
 269             add-&gt;child1()-&gt;shouldSpeculateInt32OrBooleanForArithmetic(),
 270             add-&gt;child2()-&gt;shouldSpeculateInt32OrBooleanForArithmetic(),
 271             pass);
 272     }
 273 
 274     AddSpeculationMode addSpeculationMode(Node* add, PredictionPass pass)
 275     {
 276         if (add-&gt;op() == ValueAdd)
 277             return valueAddSpeculationMode(add, pass);
 278 
 279         return arithAddSpeculationMode(add, pass);
 280     }
 281 
 282     bool addShouldSpeculateInt32(Node* add, PredictionPass pass)
 283     {
 284         return addSpeculationMode(add, pass) != DontSpeculateInt32;
 285     }
 286 
<span class="line-modified"> 287     bool addShouldSpeculateAnyInt(Node* add)</span>
 288     {
 289         if (!enableInt52())
 290             return false;
 291 
 292         Node* left = add-&gt;child1().node();
 293         Node* right = add-&gt;child2().node();
 294 
 295         if (hasExitSite(add, Int52Overflow))
 296             return false;
 297 
<span class="line-modified"> 298         if (Node::shouldSpeculateAnyInt(left, right))</span>
 299             return true;
 300 
<span class="line-modified"> 301         auto shouldSpeculateAnyIntForAdd = [](Node* node) {</span>
<span class="line-removed"> 302             auto isAnyIntSpeculationForAdd = [](SpeculatedType value) {</span>
<span class="line-removed"> 303                 return !!value &amp;&amp; (value &amp; (SpecAnyInt | SpecAnyIntAsDouble)) == value;</span>
<span class="line-removed"> 304             };</span>
<span class="line-removed"> 305 </span>
 306             // When DoubleConstant node appears, it means that users explicitly write a constant in their code with double form instead of integer form (1.0 instead of 1).
 307             // In that case, we should honor this decision: using it as integer is not appropriate.
 308             if (node-&gt;op() == DoubleConstant)
 309                 return false;
<span class="line-modified"> 310             return isAnyIntSpeculationForAdd(node-&gt;prediction());</span>
 311         };
 312 
<span class="line-modified"> 313         // Allow AnyInt ArithAdd only when the one side of the binary operation should be speculated AnyInt. It is a bit conservative</span>
 314         // decision. This is because Double to Int52 conversion is not so cheap. Frequent back-and-forth conversions between Double and Int52
 315         // rather hurt the performance. If the one side of the operation is already Int52, the cost for constructing ArithAdd becomes
 316         // cheap since only one Double to Int52 conversion could be required.
 317         // This recovers some regression in assorted tests while keeping kraken crypto improvements.
<span class="line-modified"> 318         if (!left-&gt;shouldSpeculateAnyInt() &amp;&amp; !right-&gt;shouldSpeculateAnyInt())</span>
 319             return false;
 320 
 321         auto usesAsNumbers = [](Node* node) {
 322             NodeFlags flags = node-&gt;flags() &amp; NodeBytecodeBackPropMask;
 323             if (!flags)
 324                 return false;
 325             return (flags &amp; (NodeBytecodeUsesAsNumber | NodeBytecodeNeedsNegZero | NodeBytecodeUsesAsInt | NodeBytecodeUsesAsArrayIndex)) == flags;
 326         };
 327 
 328         // Wrapping Int52 to Value is also not so cheap. Thus, we allow Int52 addition only when the node is used as number.
 329         if (!usesAsNumbers(add))
 330             return false;
 331 
<span class="line-modified"> 332         return shouldSpeculateAnyIntForAdd(left) &amp;&amp; shouldSpeculateAnyIntForAdd(right);</span>
 333     }
 334 
 335     bool binaryArithShouldSpeculateInt32(Node* node, PredictionPass pass)
 336     {
 337         Node* left = node-&gt;child1().node();
 338         Node* right = node-&gt;child2().node();
 339 
 340         return Node::shouldSpeculateInt32OrBooleanForArithmetic(left, right)
 341             &amp;&amp; node-&gt;canSpeculateInt32(node-&gt;sourceFor(pass));
 342     }
 343 
<span class="line-modified"> 344     bool binaryArithShouldSpeculateAnyInt(Node* node, PredictionPass pass)</span>
 345     {
 346         if (!enableInt52())
 347             return false;
 348 
 349         Node* left = node-&gt;child1().node();
 350         Node* right = node-&gt;child2().node();
 351 
<span class="line-modified"> 352         return Node::shouldSpeculateAnyInt(left, right)</span>
 353             &amp;&amp; node-&gt;canSpeculateInt52(pass)
 354             &amp;&amp; !hasExitSite(node, Int52Overflow);
 355     }
 356 
 357     bool unaryArithShouldSpeculateInt32(Node* node, PredictionPass pass)
 358     {
 359         return node-&gt;child1()-&gt;shouldSpeculateInt32OrBooleanForArithmetic()
 360             &amp;&amp; node-&gt;canSpeculateInt32(pass);
 361     }
 362 
<span class="line-modified"> 363     bool unaryArithShouldSpeculateAnyInt(Node* node, PredictionPass pass)</span>
 364     {
 365         if (!enableInt52())
 366             return false;
<span class="line-modified"> 367         return node-&gt;child1()-&gt;shouldSpeculateAnyInt()</span>
 368             &amp;&amp; node-&gt;canSpeculateInt52(pass)
 369             &amp;&amp; !hasExitSite(node, Int52Overflow);
 370     }
 371 
 372     bool canOptimizeStringObjectAccess(const CodeOrigin&amp;);
 373 
 374     bool getRegExpPrototypeProperty(JSObject* regExpPrototype, Structure* regExpPrototypeStructure, UniquedStringImpl* uid, JSValue&amp; returnJSValue);
 375 
 376     bool roundShouldSpeculateInt32(Node* arithRound, PredictionPass pass)
 377     {
 378         ASSERT(arithRound-&gt;op() == ArithRound || arithRound-&gt;op() == ArithFloor || arithRound-&gt;op() == ArithCeil || arithRound-&gt;op() == ArithTrunc);
 379         return arithRound-&gt;canSpeculateInt32(pass) &amp;&amp; !hasExitSite(arithRound-&gt;origin.semantic, Overflow) &amp;&amp; !hasExitSite(arithRound-&gt;origin.semantic, NegativeZero);
 380     }
 381 
 382     static const char *opName(NodeType);
 383 
 384     RegisteredStructureSet* addStructureSet(const StructureSet&amp; structureSet)
 385     {
 386         m_structureSets.append();
 387         RegisteredStructureSet* result = &amp;m_structureSets.last();
</pre>
<hr />
<pre>
 407     {
 408         return m_codeBlock-&gt;globalObjectFor(codeOrigin);
 409     }
 410 
 411     JSObject* globalThisObjectFor(CodeOrigin codeOrigin)
 412     {
 413         JSGlobalObject* object = globalObjectFor(codeOrigin);
 414         return jsCast&lt;JSObject*&gt;(object-&gt;methodTable(m_vm)-&gt;toThis(object, object-&gt;globalExec(), NotStrictMode));
 415     }
 416 
 417     ScriptExecutable* executableFor(InlineCallFrame* inlineCallFrame)
 418     {
 419         if (!inlineCallFrame)
 420             return m_codeBlock-&gt;ownerExecutable();
 421 
 422         return inlineCallFrame-&gt;baselineCodeBlock-&gt;ownerExecutable();
 423     }
 424 
 425     ScriptExecutable* executableFor(const CodeOrigin&amp; codeOrigin)
 426     {
<span class="line-modified"> 427         return executableFor(codeOrigin.inlineCallFrame);</span>
 428     }
 429 
 430     CodeBlock* baselineCodeBlockFor(InlineCallFrame* inlineCallFrame)
 431     {
 432         if (!inlineCallFrame)
 433             return m_profiledBlock;
 434         return baselineCodeBlockForInlineCallFrame(inlineCallFrame);
 435     }
 436 
 437     CodeBlock* baselineCodeBlockFor(const CodeOrigin&amp; codeOrigin)
 438     {
 439         return baselineCodeBlockForOriginAndBaselineCodeBlock(codeOrigin, m_profiledBlock);
 440     }
 441 
 442     bool isStrictModeFor(CodeOrigin codeOrigin)
 443     {
<span class="line-modified"> 444         if (!codeOrigin.inlineCallFrame)</span>
 445             return m_codeBlock-&gt;isStrictMode();
<span class="line-modified"> 446         return codeOrigin.inlineCallFrame-&gt;isStrictMode();</span>
 447     }
 448 
 449     ECMAMode ecmaModeFor(CodeOrigin codeOrigin)
 450     {
 451         return isStrictModeFor(codeOrigin) ? StrictMode : NotStrictMode;
 452     }
 453 
 454     bool masqueradesAsUndefinedWatchpointIsStillValid(const CodeOrigin&amp; codeOrigin)
 455     {
 456         return globalObjectFor(codeOrigin)-&gt;masqueradesAsUndefinedWatchpoint()-&gt;isStillValid();
 457     }
 458 
 459     bool hasGlobalExitSite(const CodeOrigin&amp; codeOrigin, ExitKind exitKind)
 460     {
 461         return baselineCodeBlockFor(codeOrigin)-&gt;unlinkedCodeBlock()-&gt;hasExitSite(FrequentExitSite(exitKind));
 462     }
 463 
 464     bool hasExitSite(const CodeOrigin&amp; codeOrigin, ExitKind exitKind)
 465     {
<span class="line-modified"> 466         return baselineCodeBlockFor(codeOrigin)-&gt;unlinkedCodeBlock()-&gt;hasExitSite(FrequentExitSite(codeOrigin.bytecodeIndex, exitKind));</span>
 467     }
 468 
 469     bool hasExitSite(Node* node, ExitKind exitKind)
 470     {
 471         return hasExitSite(node-&gt;origin.semantic, exitKind);
 472     }
 473 
 474     MethodOfGettingAValueProfile methodOfGettingAValueProfileFor(Node* currentNode, Node* operandNode);
 475 
 476     BlockIndex numBlocks() const { return m_blocks.size(); }
 477     BasicBlock* block(BlockIndex blockIndex) const { return m_blocks[blockIndex].get(); }
 478     BasicBlock* lastBlock() const { return block(numBlocks() - 1); }
 479 
 480     void appendBlock(Ref&lt;BasicBlock&gt;&amp;&amp; basicBlock)
 481     {
 482         basicBlock-&gt;index = m_blocks.size();
 483         m_blocks.append(WTFMove(basicBlock));
 484     }
 485 
 486     void killBlock(BlockIndex blockIndex)
</pre>
<hr />
<pre>
 753     {
 754         if (watchpoints().isWatched(set))
 755             return true;
 756 
 757         if (set.isStillValid()) {
 758             // Since the global object owns this watchpoint, we make ourselves have a weak pointer to it.
 759             // If the global object got deallocated, it wouldn&#39;t fire the watchpoint. It&#39;s unlikely the
 760             // global object would get deallocated without this code ever getting thrown away, however,
 761             // it&#39;s more sound logically to depend on the global object lifetime weakly.
 762             freeze(globalObject);
 763             watchpoints().addLazily(set);
 764             return true;
 765         }
 766 
 767         return false;
 768     }
 769 
 770     bool isWatchingArrayIteratorProtocolWatchpoint(Node* node)
 771     {
 772         JSGlobalObject* globalObject = globalObjectFor(node-&gt;origin.semantic);
<span class="line-modified"> 773         InlineWatchpointSet&amp; set = globalObject-&gt;arrayIteratorProtocolWatchpoint();</span>
 774         return isWatchingGlobalObjectWatchpoint(globalObject, set);
 775     }
 776 
 777     bool isWatchingNumberToStringWatchpoint(Node* node)
 778     {
 779         JSGlobalObject* globalObject = globalObjectFor(node-&gt;origin.semantic);
<span class="line-modified"> 780         InlineWatchpointSet&amp; set = globalObject-&gt;numberToStringWatchpoint();</span>
 781         return isWatchingGlobalObjectWatchpoint(globalObject, set);
 782     }
 783 
 784     Profiler::Compilation* compilation() { return m_plan.compilation(); }
 785 
 786     DesiredIdentifiers&amp; identifiers() { return m_plan.identifiers(); }
 787     DesiredWatchpoints&amp; watchpoints() { return m_plan.watchpoints(); }
 788     DesiredGlobalProperties&amp; globalProperties() { return m_plan.globalProperties(); }
 789 
 790     // Returns false if the key is already invalid or unwatchable. If this is a Presence condition,
 791     // this also makes it cheap to query if the condition holds. Also makes sure that the GC knows
 792     // what&#39;s going on.
 793     bool watchCondition(const ObjectPropertyCondition&amp;);
 794     bool watchConditions(const ObjectPropertyConditionSet&amp;);
 795 
 796     bool watchGlobalProperty(JSGlobalObject*, unsigned identifierNumber);
 797 
 798     // Checks if it&#39;s known that loading from the given object at the given offset is fine. This is
 799     // computed by tracking which conditions we track with watchCondition().
 800     bool isSafeToLoad(JSObject* base, PropertyOffset);
</pre>
<hr />
<pre>
 810     // Quickly query if a single local is live at the given point. This is faster than calling
 811     // forAllLiveInBytecode() if you will only query one local. But, if you want to know all of the
 812     // locals live, then calling this for each local is much slower than forAllLiveInBytecode().
 813     bool isLiveInBytecode(VirtualRegister, CodeOrigin);
 814 
 815     // Quickly get all of the non-argument locals live at the given point. This doesn&#39;t give you
 816     // any arguments because those are all presumed live. You can call forAllLiveInBytecode() to
 817     // also get the arguments. This is much faster than calling isLiveInBytecode() for each local.
 818     template&lt;typename Functor&gt;
 819     void forAllLocalsLiveInBytecode(CodeOrigin codeOrigin, const Functor&amp; functor)
 820     {
 821         // Support for not redundantly reporting arguments. Necessary because in case of a varargs
 822         // call, only the callee knows that arguments are live while in the case of a non-varargs
 823         // call, both callee and caller will see the variables live.
 824         VirtualRegister exclusionStart;
 825         VirtualRegister exclusionEnd;
 826 
 827         CodeOrigin* codeOriginPtr = &amp;codeOrigin;
 828 
 829         for (;;) {
<span class="line-modified"> 830             InlineCallFrame* inlineCallFrame = codeOriginPtr-&gt;inlineCallFrame;</span>
 831             VirtualRegister stackOffset(inlineCallFrame ? inlineCallFrame-&gt;stackOffset : 0);
 832 
 833             if (inlineCallFrame) {
 834                 if (inlineCallFrame-&gt;isClosureCall)
 835                     functor(stackOffset + CallFrameSlot::callee);
 836                 if (inlineCallFrame-&gt;isVarargs())
 837                     functor(stackOffset + CallFrameSlot::argumentCount);
 838             }
 839 
 840             CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
 841             FullBytecodeLiveness&amp; fullLiveness = livenessFor(codeBlock);
<span class="line-modified"> 842             const FastBitVector&amp; liveness = fullLiveness.getLiveness(codeOriginPtr-&gt;bytecodeIndex);</span>
 843             for (unsigned relativeLocal = codeBlock-&gt;numCalleeLocals(); relativeLocal--;) {
 844                 VirtualRegister reg = stackOffset + virtualRegisterForLocal(relativeLocal);
 845 
 846                 // Don&#39;t report if our callee already reported.
 847                 if (reg &gt;= exclusionStart &amp;&amp; reg &lt; exclusionEnd)
 848                     continue;
 849 
 850                 if (liveness[relativeLocal])
 851                     functor(reg);
 852             }
 853 
 854             if (!inlineCallFrame)
 855                 break;
 856 
 857             // Arguments are always live. This would be redundant if it wasn&#39;t for our
 858             // op_call_varargs inlining. See the comment above.
 859             exclusionStart = stackOffset + CallFrame::argumentOffsetIncludingThis(0);
 860             exclusionEnd = stackOffset + CallFrame::argumentOffsetIncludingThis(inlineCallFrame-&gt;argumentsWithFixup.size());
 861 
 862             // We will always have a &quot;this&quot; argument and exclusionStart should be a smaller stack
 863             // offset than exclusionEnd.
 864             ASSERT(exclusionStart &lt; exclusionEnd);
 865 
 866             for (VirtualRegister reg = exclusionStart; reg &lt; exclusionEnd; reg += 1)
 867                 functor(reg);
 868 
<span class="line-modified"> 869             codeOriginPtr = inlineCallFrame-&gt;getCallerSkippingTailCalls();</span>
<span class="line-modified"> 870 </span>
<span class="line-modified"> 871             // The first inline call frame could be an inline tail call</span>
<span class="line-removed"> 872             if (!codeOriginPtr)</span>
<span class="line-removed"> 873                 break;</span>
 874         }
 875     }
 876 
 877     // Get a BitVector of all of the non-argument locals live right now. This is mostly useful if
 878     // you want to compare two sets of live locals from two different CodeOrigins.
 879     BitVector localsLiveInBytecode(CodeOrigin);
 880 
 881     // Tells you all of the arguments and locals live at the given CodeOrigin. This is a small
 882     // extension to forAllLocalsLiveInBytecode(), since all arguments are always presumed live.
 883     template&lt;typename Functor&gt;
 884     void forAllLiveInBytecode(CodeOrigin codeOrigin, const Functor&amp; functor)
 885     {
 886         forAllLocalsLiveInBytecode(codeOrigin, functor);
 887 
 888         // Report all arguments as being live.
 889         for (unsigned argument = block(0)-&gt;variablesAtHead.numberOfArguments(); argument--;)
 890             functor(virtualRegisterForArgument(argument));
 891     }
 892 
 893     BytecodeKills&amp; killsFor(CodeBlock*);
</pre>
<hr />
<pre>
 958     bool isRoot(BasicBlock* block) const
 959     {
 960         ASSERT_WITH_MESSAGE(!m_isInSSAConversion, &quot;This is not written to work during SSA conversion.&quot;);
 961 
 962         if (m_form == SSA) {
 963             ASSERT(m_roots.size() == 1);
 964             ASSERT(m_roots.contains(this-&gt;block(0)));
 965             return block == this-&gt;block(0);
 966         }
 967 
 968         if (m_roots.size() &lt;= 4) {
 969             bool result = m_roots.contains(block);
 970             ASSERT(result == m_rootToArguments.contains(block));
 971             return result;
 972         }
 973         bool result = m_rootToArguments.contains(block);
 974         ASSERT(result == m_roots.contains(block));
 975         return result;
 976     }
 977 



 978     VM&amp; m_vm;
 979     Plan&amp; m_plan;
 980     CodeBlock* m_codeBlock;
 981     CodeBlock* m_profiledBlock;
 982 
 983     Vector&lt;RefPtr&lt;BasicBlock&gt;, 8&gt; m_blocks;
 984     Vector&lt;BasicBlock*, 1&gt; m_roots;
 985     Vector&lt;Edge, 16&gt; m_varArgChildren;
 986 
 987     HashMap&lt;EncodedJSValue, FrozenValue*, EncodedJSValueHash, EncodedJSValueHashTraits&gt; m_frozenValueMap;
 988     Bag&lt;FrozenValue&gt; m_frozenValues;
 989 
 990     Vector&lt;uint32_t&gt; m_uint32ValuesInUse;
 991 
 992     Bag&lt;StorageAccessData&gt; m_storageAccessData;
 993 
<span class="line-modified"> 994     // In CPS, this is all of the SetArgument nodes for the arguments in the machine code block</span>
 995     // that survived DCE. All of them except maybe &quot;this&quot; will survive DCE, because of the Flush
 996     // nodes. In SSA, this has no meaning. It&#39;s empty.
 997     HashMap&lt;BasicBlock*, ArgumentsVector&gt; m_rootToArguments;
 998 
 999     // In SSA, this is the argument speculation that we&#39;ve locked in for an entrypoint block.
1000     //
1001     // We must speculate on the argument types at each entrypoint even if operations involving
1002     // arguments get killed. For example:
1003     //
1004     //     function foo(x) {
1005     //        var tmp = x + 1;
1006     //     }
1007     //
1008     // Assume that x is always int during profiling. The ArithAdd for &quot;x + 1&quot; will be dead and will
1009     // have a proven check for the edge to &quot;x&quot;. So, we will not insert a Check node and we will
1010     // kill the GetStack for &quot;x&quot;. But, we must do the int check in the progolue, because that&#39;s the
1011     // thing we used to allow DCE of ArithAdd. Otherwise the add could be impure:
1012     //
1013     //     var o = {
1014     //         valueOf: function() { do side effects; }
1015     //     };
1016     //     foo(o);
1017     //
1018     // If we DCE the ArithAdd and we remove the int check on x, then this won&#39;t do the side
1019     // effects.
1020     //
1021     // By convention, entrypoint index 0 is used for the CodeBlock&#39;s op_enter entrypoint.
1022     // So argumentFormats[0] are the argument formats for the normal call entrypoint.
1023     Vector&lt;Vector&lt;FlushFormat&gt;&gt; m_argumentFormats;
1024 
<span class="line-removed">1025     // This maps an entrypoint index to a particular op_catch bytecode offset. By convention,</span>
<span class="line-removed">1026     // it&#39;ll never have zero as a key because we use zero to mean the op_enter entrypoint.</span>
<span class="line-removed">1027     HashMap&lt;unsigned, unsigned&gt; m_entrypointIndexToCatchBytecodeOffset;</span>
<span class="line-removed">1028 </span>
<span class="line-removed">1029     // This is the number of logical entrypoints that we&#39;re compiling. This is only used</span>
<span class="line-removed">1030     // in SSA. Each EntrySwitch node must have m_numberOfEntrypoints cases. Note, this is</span>
<span class="line-removed">1031     // not the same as m_roots.size(). m_roots.size() represents the number of roots in</span>
<span class="line-removed">1032     // the CFG. In SSA, m_roots.size() == 1 even if we&#39;re compiling more than one entrypoint.</span>
<span class="line-removed">1033     unsigned m_numberOfEntrypoints { UINT_MAX };</span>
<span class="line-removed">1034 </span>
1035     SegmentedVector&lt;VariableAccessData, 16&gt; m_variableAccessData;
1036     SegmentedVector&lt;ArgumentPosition, 8&gt; m_argumentPositions;
1037     Bag&lt;Transition&gt; m_transitions;
1038     Bag&lt;BranchData&gt; m_branchData;
1039     Bag&lt;SwitchData&gt; m_switchData;
1040     Bag&lt;MultiGetByOffsetData&gt; m_multiGetByOffsetData;
1041     Bag&lt;MultiPutByOffsetData&gt; m_multiPutByOffsetData;
1042     Bag&lt;MatchStructureData&gt; m_matchStructureData;
1043     Bag&lt;ObjectMaterializationData&gt; m_objectMaterializationData;
1044     Bag&lt;CallVarargsData&gt; m_callVarargsData;
1045     Bag&lt;LoadVarargsData&gt; m_loadVarargsData;
1046     Bag&lt;StackAccessData&gt; m_stackAccessData;
1047     Bag&lt;LazyJSValue&gt; m_lazyJSValues;
1048     Bag&lt;CallDOMGetterData&gt; m_callDOMGetterData;
1049     Bag&lt;BitVector&gt; m_bitVectors;
1050     Vector&lt;InlineVariableData, 4&gt; m_inlineVariableData;
1051     HashMap&lt;CodeBlock*, std::unique_ptr&lt;FullBytecodeLiveness&gt;&gt; m_bytecodeLiveness;
1052     HashMap&lt;CodeBlock*, std::unique_ptr&lt;BytecodeKills&gt;&gt; m_bytecodeKills;
1053     HashSet&lt;std::pair&lt;JSObject*, PropertyOffset&gt;&gt; m_safeToLoad;
1054     Vector&lt;Ref&lt;Snippet&gt;&gt; m_domJITSnippets;
1055     std::unique_ptr&lt;CPSDominators&gt; m_cpsDominators;
1056     std::unique_ptr&lt;SSADominators&gt; m_ssaDominators;
1057     std::unique_ptr&lt;CPSNaturalLoops&gt; m_cpsNaturalLoops;
1058     std::unique_ptr&lt;SSANaturalLoops&gt; m_ssaNaturalLoops;
1059     std::unique_ptr&lt;SSACFG&gt; m_ssaCFG;
1060     std::unique_ptr&lt;CPSCFG&gt; m_cpsCFG;
1061     std::unique_ptr&lt;BackwardsCFG&gt; m_backwardsCFG;
1062     std::unique_ptr&lt;BackwardsDominators&gt; m_backwardsDominators;
1063     std::unique_ptr&lt;ControlEquivalenceAnalysis&gt; m_controlEquivalenceAnalysis;
1064     unsigned m_localVars;
1065     unsigned m_nextMachineLocal;
1066     unsigned m_parameterSlots;
1067 










1068     HashSet&lt;String&gt; m_localStrings;
1069     HashMap&lt;const StringImpl*, String&gt; m_copiedStrings;
1070 
1071 #if USE(JSVALUE32_64)
1072     StdUnorderedMap&lt;int64_t, double*&gt; m_doubleConstantsMap;
1073     std::unique_ptr&lt;Bag&lt;double&gt;&gt; m_doubleConstants;
1074 #endif
1075 
1076     OptimizationFixpointState m_fixpointState;
1077     StructureRegistrationState m_structureRegistrationState;
1078     GraphForm m_form;
1079     UnificationState m_unificationState;
1080     PlanStage m_planStage { PlanStage::Initial };
1081     RefCountState m_refCountState;
1082     bool m_hasDebuggerEnabled;
1083     bool m_hasExceptionHandlers { false };
1084     bool m_isInSSAConversion { false };
1085     Optional&lt;uint32_t&gt; m_maxLocalsForCatchOSREntry;
1086     std::unique_ptr&lt;FlowIndexing&gt; m_indexingCache;
1087     std::unique_ptr&lt;FlowMap&lt;AbstractValue&gt;&gt; m_abstractValuesCache;
</pre>
<hr />
<pre>
1108 
1109         // Integer constants can be typed Double if they are written like a double in the source code (e.g. 42.0).
1110         // In that case, we stay conservative unless the other operand was explicitly typed as integer.
1111         NodeFlags operandResultType = operand-&gt;result();
1112         if (operandResultType != NodeResultInt32 &amp;&amp; immediateValue.isDouble())
1113             return DontSpeculateInt32;
1114 
1115         if (immediateValue.isBoolean() || jsNumber(immediateValue.asNumber()).isInt32())
1116             return add-&gt;canSpeculateInt32(source) ? SpeculateInt32 : DontSpeculateInt32;
1117 
1118         double doubleImmediate = immediateValue.asDouble();
1119         const double twoToThe48 = 281474976710656.0;
1120         if (doubleImmediate &lt; -twoToThe48 || doubleImmediate &gt; twoToThe48)
1121             return DontSpeculateInt32;
1122 
1123         return bytecodeCanTruncateInteger(add-&gt;arithNodeFlags()) ? SpeculateInt32AndTruncateConstants : DontSpeculateInt32;
1124     }
1125 
1126     B3::SparseCollection&lt;Node&gt; m_nodes;
1127     SegmentedVector&lt;RegisteredStructureSet, 16&gt; m_structureSets;

1128 };
1129 
1130 } } // namespace JSC::DFG
1131 
1132 #endif
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
</pre>
<hr />
<pre>
 102     } while (false)
 103 
 104 #define DFG_CRASH(graph, node, reason, ...) do {                        \
 105         (graph).logAssertionFailure(                                    \
 106             (node), __FILE__, __LINE__, WTF_PRETTY_FUNCTION, (reason)); \
 107         CRASH_WITH_SECURITY_IMPLICATION_AND_INFO(__VA_ARGS__);          \
 108     } while (false)
 109 
 110 struct InlineVariableData {
 111     InlineCallFrame* inlineCallFrame;
 112     unsigned argumentPositionStart;
 113     VariableAccessData* calleeVariable;
 114 };
 115 
 116 enum AddSpeculationMode {
 117     DontSpeculateInt32,
 118     SpeculateInt32AndTruncateConstants,
 119     SpeculateInt32
 120 };
 121 
<span class="line-added"> 122 struct Prefix {</span>
<span class="line-added"> 123     enum NoHeaderTag { NoHeader };</span>
<span class="line-added"> 124 </span>
<span class="line-added"> 125     Prefix() { }</span>
<span class="line-added"> 126 </span>
<span class="line-added"> 127     Prefix(const char* prefixStr, NoHeaderTag tag = NoHeader)</span>
<span class="line-added"> 128         : prefixStr(prefixStr)</span>
<span class="line-added"> 129         , noHeader(tag == NoHeader)</span>
<span class="line-added"> 130     { }</span>
<span class="line-added"> 131 </span>
<span class="line-added"> 132     Prefix(NoHeaderTag)</span>
<span class="line-added"> 133         : noHeader(true)</span>
<span class="line-added"> 134     { }</span>
<span class="line-added"> 135 </span>
<span class="line-added"> 136     void dump(PrintStream&amp; out) const;</span>
<span class="line-added"> 137 </span>
<span class="line-added"> 138     void clearBlockIndex() { blockIndex = -1; }</span>
<span class="line-added"> 139     void clearNodeIndex() { nodeIndex = -1; }</span>
<span class="line-added"> 140 </span>
<span class="line-added"> 141     void enable() { m_enabled = true; }</span>
<span class="line-added"> 142     void disable() { m_enabled = false; }</span>
<span class="line-added"> 143 </span>
<span class="line-added"> 144     int32_t phaseNumber { -1 };</span>
<span class="line-added"> 145     int32_t blockIndex { -1 };</span>
<span class="line-added"> 146     int32_t nodeIndex { -1 };</span>
<span class="line-added"> 147     const char* prefixStr { nullptr };</span>
<span class="line-added"> 148     bool noHeader { false };</span>
<span class="line-added"> 149 </span>
<span class="line-added"> 150     static constexpr const char* noString = nullptr;</span>
<span class="line-added"> 151 </span>
<span class="line-added"> 152 private:</span>
<span class="line-added"> 153     bool m_enabled { true };</span>
<span class="line-added"> 154 };</span>
<span class="line-added"> 155 </span>
 156 //
 157 // === Graph ===
 158 //
 159 // The order may be significant for nodes with side-effects (property accesses, value conversions).
 160 // Nodes that are &#39;dead&#39; remain in the vector with refCount 0.
 161 class Graph : public virtual Scannable {
 162 public:
 163     Graph(VM&amp;, Plan&amp;);
 164     ~Graph();
 165 
 166     void changeChild(Edge&amp; edge, Node* newNode)
 167     {
 168         edge.setNode(newNode);
 169     }
 170 
 171     void changeEdge(Edge&amp; edge, Edge newEdge)
 172     {
 173         edge = newEdge;
 174     }
 175 
</pre>
<hr />
<pre>
 301         return addSpeculationMode(
 302             add,
 303             add-&gt;child1()-&gt;shouldSpeculateInt32OrBooleanForArithmetic(),
 304             add-&gt;child2()-&gt;shouldSpeculateInt32OrBooleanForArithmetic(),
 305             pass);
 306     }
 307 
 308     AddSpeculationMode addSpeculationMode(Node* add, PredictionPass pass)
 309     {
 310         if (add-&gt;op() == ValueAdd)
 311             return valueAddSpeculationMode(add, pass);
 312 
 313         return arithAddSpeculationMode(add, pass);
 314     }
 315 
 316     bool addShouldSpeculateInt32(Node* add, PredictionPass pass)
 317     {
 318         return addSpeculationMode(add, pass) != DontSpeculateInt32;
 319     }
 320 
<span class="line-modified"> 321     bool addShouldSpeculateInt52(Node* add)</span>
 322     {
 323         if (!enableInt52())
 324             return false;
 325 
 326         Node* left = add-&gt;child1().node();
 327         Node* right = add-&gt;child2().node();
 328 
 329         if (hasExitSite(add, Int52Overflow))
 330             return false;
 331 
<span class="line-modified"> 332         if (Node::shouldSpeculateInt52(left, right))</span>
 333             return true;
 334 
<span class="line-modified"> 335         auto shouldSpeculateInt52ForAdd = [] (Node* node) {</span>




 336             // When DoubleConstant node appears, it means that users explicitly write a constant in their code with double form instead of integer form (1.0 instead of 1).
 337             // In that case, we should honor this decision: using it as integer is not appropriate.
 338             if (node-&gt;op() == DoubleConstant)
 339                 return false;
<span class="line-modified"> 340             return isIntAnyFormat(node-&gt;prediction());</span>
 341         };
 342 
<span class="line-modified"> 343         // Allow Int52 ArithAdd only when the one side of the binary operation should be speculated Int52. It is a bit conservative</span>
 344         // decision. This is because Double to Int52 conversion is not so cheap. Frequent back-and-forth conversions between Double and Int52
 345         // rather hurt the performance. If the one side of the operation is already Int52, the cost for constructing ArithAdd becomes
 346         // cheap since only one Double to Int52 conversion could be required.
 347         // This recovers some regression in assorted tests while keeping kraken crypto improvements.
<span class="line-modified"> 348         if (!left-&gt;shouldSpeculateInt52() &amp;&amp; !right-&gt;shouldSpeculateInt52())</span>
 349             return false;
 350 
 351         auto usesAsNumbers = [](Node* node) {
 352             NodeFlags flags = node-&gt;flags() &amp; NodeBytecodeBackPropMask;
 353             if (!flags)
 354                 return false;
 355             return (flags &amp; (NodeBytecodeUsesAsNumber | NodeBytecodeNeedsNegZero | NodeBytecodeUsesAsInt | NodeBytecodeUsesAsArrayIndex)) == flags;
 356         };
 357 
 358         // Wrapping Int52 to Value is also not so cheap. Thus, we allow Int52 addition only when the node is used as number.
 359         if (!usesAsNumbers(add))
 360             return false;
 361 
<span class="line-modified"> 362         return shouldSpeculateInt52ForAdd(left) &amp;&amp; shouldSpeculateInt52ForAdd(right);</span>
 363     }
 364 
 365     bool binaryArithShouldSpeculateInt32(Node* node, PredictionPass pass)
 366     {
 367         Node* left = node-&gt;child1().node();
 368         Node* right = node-&gt;child2().node();
 369 
 370         return Node::shouldSpeculateInt32OrBooleanForArithmetic(left, right)
 371             &amp;&amp; node-&gt;canSpeculateInt32(node-&gt;sourceFor(pass));
 372     }
 373 
<span class="line-modified"> 374     bool binaryArithShouldSpeculateInt52(Node* node, PredictionPass pass)</span>
 375     {
 376         if (!enableInt52())
 377             return false;
 378 
 379         Node* left = node-&gt;child1().node();
 380         Node* right = node-&gt;child2().node();
 381 
<span class="line-modified"> 382         return Node::shouldSpeculateInt52(left, right)</span>
 383             &amp;&amp; node-&gt;canSpeculateInt52(pass)
 384             &amp;&amp; !hasExitSite(node, Int52Overflow);
 385     }
 386 
 387     bool unaryArithShouldSpeculateInt32(Node* node, PredictionPass pass)
 388     {
 389         return node-&gt;child1()-&gt;shouldSpeculateInt32OrBooleanForArithmetic()
 390             &amp;&amp; node-&gt;canSpeculateInt32(pass);
 391     }
 392 
<span class="line-modified"> 393     bool unaryArithShouldSpeculateInt52(Node* node, PredictionPass pass)</span>
 394     {
 395         if (!enableInt52())
 396             return false;
<span class="line-modified"> 397         return node-&gt;child1()-&gt;shouldSpeculateInt52()</span>
 398             &amp;&amp; node-&gt;canSpeculateInt52(pass)
 399             &amp;&amp; !hasExitSite(node, Int52Overflow);
 400     }
 401 
 402     bool canOptimizeStringObjectAccess(const CodeOrigin&amp;);
 403 
 404     bool getRegExpPrototypeProperty(JSObject* regExpPrototype, Structure* regExpPrototypeStructure, UniquedStringImpl* uid, JSValue&amp; returnJSValue);
 405 
 406     bool roundShouldSpeculateInt32(Node* arithRound, PredictionPass pass)
 407     {
 408         ASSERT(arithRound-&gt;op() == ArithRound || arithRound-&gt;op() == ArithFloor || arithRound-&gt;op() == ArithCeil || arithRound-&gt;op() == ArithTrunc);
 409         return arithRound-&gt;canSpeculateInt32(pass) &amp;&amp; !hasExitSite(arithRound-&gt;origin.semantic, Overflow) &amp;&amp; !hasExitSite(arithRound-&gt;origin.semantic, NegativeZero);
 410     }
 411 
 412     static const char *opName(NodeType);
 413 
 414     RegisteredStructureSet* addStructureSet(const StructureSet&amp; structureSet)
 415     {
 416         m_structureSets.append();
 417         RegisteredStructureSet* result = &amp;m_structureSets.last();
</pre>
<hr />
<pre>
 437     {
 438         return m_codeBlock-&gt;globalObjectFor(codeOrigin);
 439     }
 440 
 441     JSObject* globalThisObjectFor(CodeOrigin codeOrigin)
 442     {
 443         JSGlobalObject* object = globalObjectFor(codeOrigin);
 444         return jsCast&lt;JSObject*&gt;(object-&gt;methodTable(m_vm)-&gt;toThis(object, object-&gt;globalExec(), NotStrictMode));
 445     }
 446 
 447     ScriptExecutable* executableFor(InlineCallFrame* inlineCallFrame)
 448     {
 449         if (!inlineCallFrame)
 450             return m_codeBlock-&gt;ownerExecutable();
 451 
 452         return inlineCallFrame-&gt;baselineCodeBlock-&gt;ownerExecutable();
 453     }
 454 
 455     ScriptExecutable* executableFor(const CodeOrigin&amp; codeOrigin)
 456     {
<span class="line-modified"> 457         return executableFor(codeOrigin.inlineCallFrame());</span>
 458     }
 459 
 460     CodeBlock* baselineCodeBlockFor(InlineCallFrame* inlineCallFrame)
 461     {
 462         if (!inlineCallFrame)
 463             return m_profiledBlock;
 464         return baselineCodeBlockForInlineCallFrame(inlineCallFrame);
 465     }
 466 
 467     CodeBlock* baselineCodeBlockFor(const CodeOrigin&amp; codeOrigin)
 468     {
 469         return baselineCodeBlockForOriginAndBaselineCodeBlock(codeOrigin, m_profiledBlock);
 470     }
 471 
 472     bool isStrictModeFor(CodeOrigin codeOrigin)
 473     {
<span class="line-modified"> 474         if (!codeOrigin.inlineCallFrame())</span>
 475             return m_codeBlock-&gt;isStrictMode();
<span class="line-modified"> 476         return codeOrigin.inlineCallFrame()-&gt;isStrictMode();</span>
 477     }
 478 
 479     ECMAMode ecmaModeFor(CodeOrigin codeOrigin)
 480     {
 481         return isStrictModeFor(codeOrigin) ? StrictMode : NotStrictMode;
 482     }
 483 
 484     bool masqueradesAsUndefinedWatchpointIsStillValid(const CodeOrigin&amp; codeOrigin)
 485     {
 486         return globalObjectFor(codeOrigin)-&gt;masqueradesAsUndefinedWatchpoint()-&gt;isStillValid();
 487     }
 488 
 489     bool hasGlobalExitSite(const CodeOrigin&amp; codeOrigin, ExitKind exitKind)
 490     {
 491         return baselineCodeBlockFor(codeOrigin)-&gt;unlinkedCodeBlock()-&gt;hasExitSite(FrequentExitSite(exitKind));
 492     }
 493 
 494     bool hasExitSite(const CodeOrigin&amp; codeOrigin, ExitKind exitKind)
 495     {
<span class="line-modified"> 496         return baselineCodeBlockFor(codeOrigin)-&gt;unlinkedCodeBlock()-&gt;hasExitSite(FrequentExitSite(codeOrigin.bytecodeIndex(), exitKind));</span>
 497     }
 498 
 499     bool hasExitSite(Node* node, ExitKind exitKind)
 500     {
 501         return hasExitSite(node-&gt;origin.semantic, exitKind);
 502     }
 503 
 504     MethodOfGettingAValueProfile methodOfGettingAValueProfileFor(Node* currentNode, Node* operandNode);
 505 
 506     BlockIndex numBlocks() const { return m_blocks.size(); }
 507     BasicBlock* block(BlockIndex blockIndex) const { return m_blocks[blockIndex].get(); }
 508     BasicBlock* lastBlock() const { return block(numBlocks() - 1); }
 509 
 510     void appendBlock(Ref&lt;BasicBlock&gt;&amp;&amp; basicBlock)
 511     {
 512         basicBlock-&gt;index = m_blocks.size();
 513         m_blocks.append(WTFMove(basicBlock));
 514     }
 515 
 516     void killBlock(BlockIndex blockIndex)
</pre>
<hr />
<pre>
 783     {
 784         if (watchpoints().isWatched(set))
 785             return true;
 786 
 787         if (set.isStillValid()) {
 788             // Since the global object owns this watchpoint, we make ourselves have a weak pointer to it.
 789             // If the global object got deallocated, it wouldn&#39;t fire the watchpoint. It&#39;s unlikely the
 790             // global object would get deallocated without this code ever getting thrown away, however,
 791             // it&#39;s more sound logically to depend on the global object lifetime weakly.
 792             freeze(globalObject);
 793             watchpoints().addLazily(set);
 794             return true;
 795         }
 796 
 797         return false;
 798     }
 799 
 800     bool isWatchingArrayIteratorProtocolWatchpoint(Node* node)
 801     {
 802         JSGlobalObject* globalObject = globalObjectFor(node-&gt;origin.semantic);
<span class="line-modified"> 803         InlineWatchpointSet&amp; set = globalObject-&gt;arrayIteratorProtocolWatchpointSet();</span>
 804         return isWatchingGlobalObjectWatchpoint(globalObject, set);
 805     }
 806 
 807     bool isWatchingNumberToStringWatchpoint(Node* node)
 808     {
 809         JSGlobalObject* globalObject = globalObjectFor(node-&gt;origin.semantic);
<span class="line-modified"> 810         InlineWatchpointSet&amp; set = globalObject-&gt;numberToStringWatchpointSet();</span>
 811         return isWatchingGlobalObjectWatchpoint(globalObject, set);
 812     }
 813 
 814     Profiler::Compilation* compilation() { return m_plan.compilation(); }
 815 
 816     DesiredIdentifiers&amp; identifiers() { return m_plan.identifiers(); }
 817     DesiredWatchpoints&amp; watchpoints() { return m_plan.watchpoints(); }
 818     DesiredGlobalProperties&amp; globalProperties() { return m_plan.globalProperties(); }
 819 
 820     // Returns false if the key is already invalid or unwatchable. If this is a Presence condition,
 821     // this also makes it cheap to query if the condition holds. Also makes sure that the GC knows
 822     // what&#39;s going on.
 823     bool watchCondition(const ObjectPropertyCondition&amp;);
 824     bool watchConditions(const ObjectPropertyConditionSet&amp;);
 825 
 826     bool watchGlobalProperty(JSGlobalObject*, unsigned identifierNumber);
 827 
 828     // Checks if it&#39;s known that loading from the given object at the given offset is fine. This is
 829     // computed by tracking which conditions we track with watchCondition().
 830     bool isSafeToLoad(JSObject* base, PropertyOffset);
</pre>
<hr />
<pre>
 840     // Quickly query if a single local is live at the given point. This is faster than calling
 841     // forAllLiveInBytecode() if you will only query one local. But, if you want to know all of the
 842     // locals live, then calling this for each local is much slower than forAllLiveInBytecode().
 843     bool isLiveInBytecode(VirtualRegister, CodeOrigin);
 844 
 845     // Quickly get all of the non-argument locals live at the given point. This doesn&#39;t give you
 846     // any arguments because those are all presumed live. You can call forAllLiveInBytecode() to
 847     // also get the arguments. This is much faster than calling isLiveInBytecode() for each local.
 848     template&lt;typename Functor&gt;
 849     void forAllLocalsLiveInBytecode(CodeOrigin codeOrigin, const Functor&amp; functor)
 850     {
 851         // Support for not redundantly reporting arguments. Necessary because in case of a varargs
 852         // call, only the callee knows that arguments are live while in the case of a non-varargs
 853         // call, both callee and caller will see the variables live.
 854         VirtualRegister exclusionStart;
 855         VirtualRegister exclusionEnd;
 856 
 857         CodeOrigin* codeOriginPtr = &amp;codeOrigin;
 858 
 859         for (;;) {
<span class="line-modified"> 860             InlineCallFrame* inlineCallFrame = codeOriginPtr-&gt;inlineCallFrame();</span>
 861             VirtualRegister stackOffset(inlineCallFrame ? inlineCallFrame-&gt;stackOffset : 0);
 862 
 863             if (inlineCallFrame) {
 864                 if (inlineCallFrame-&gt;isClosureCall)
 865                     functor(stackOffset + CallFrameSlot::callee);
 866                 if (inlineCallFrame-&gt;isVarargs())
 867                     functor(stackOffset + CallFrameSlot::argumentCount);
 868             }
 869 
 870             CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
 871             FullBytecodeLiveness&amp; fullLiveness = livenessFor(codeBlock);
<span class="line-modified"> 872             const FastBitVector&amp; liveness = fullLiveness.getLiveness(codeOriginPtr-&gt;bytecodeIndex());</span>
 873             for (unsigned relativeLocal = codeBlock-&gt;numCalleeLocals(); relativeLocal--;) {
 874                 VirtualRegister reg = stackOffset + virtualRegisterForLocal(relativeLocal);
 875 
 876                 // Don&#39;t report if our callee already reported.
 877                 if (reg &gt;= exclusionStart &amp;&amp; reg &lt; exclusionEnd)
 878                     continue;
 879 
 880                 if (liveness[relativeLocal])
 881                     functor(reg);
 882             }
 883 
 884             if (!inlineCallFrame)
 885                 break;
 886 
 887             // Arguments are always live. This would be redundant if it wasn&#39;t for our
 888             // op_call_varargs inlining. See the comment above.
 889             exclusionStart = stackOffset + CallFrame::argumentOffsetIncludingThis(0);
 890             exclusionEnd = stackOffset + CallFrame::argumentOffsetIncludingThis(inlineCallFrame-&gt;argumentsWithFixup.size());
 891 
 892             // We will always have a &quot;this&quot; argument and exclusionStart should be a smaller stack
 893             // offset than exclusionEnd.
 894             ASSERT(exclusionStart &lt; exclusionEnd);
 895 
 896             for (VirtualRegister reg = exclusionStart; reg &lt; exclusionEnd; reg += 1)
 897                 functor(reg);
 898 
<span class="line-modified"> 899             // We need to handle tail callers because we may decide to exit to the</span>
<span class="line-modified"> 900             // the return bytecode following the tail call.</span>
<span class="line-modified"> 901             codeOriginPtr = &amp;inlineCallFrame-&gt;directCaller;</span>


 902         }
 903     }
 904 
 905     // Get a BitVector of all of the non-argument locals live right now. This is mostly useful if
 906     // you want to compare two sets of live locals from two different CodeOrigins.
 907     BitVector localsLiveInBytecode(CodeOrigin);
 908 
 909     // Tells you all of the arguments and locals live at the given CodeOrigin. This is a small
 910     // extension to forAllLocalsLiveInBytecode(), since all arguments are always presumed live.
 911     template&lt;typename Functor&gt;
 912     void forAllLiveInBytecode(CodeOrigin codeOrigin, const Functor&amp; functor)
 913     {
 914         forAllLocalsLiveInBytecode(codeOrigin, functor);
 915 
 916         // Report all arguments as being live.
 917         for (unsigned argument = block(0)-&gt;variablesAtHead.numberOfArguments(); argument--;)
 918             functor(virtualRegisterForArgument(argument));
 919     }
 920 
 921     BytecodeKills&amp; killsFor(CodeBlock*);
</pre>
<hr />
<pre>
 986     bool isRoot(BasicBlock* block) const
 987     {
 988         ASSERT_WITH_MESSAGE(!m_isInSSAConversion, &quot;This is not written to work during SSA conversion.&quot;);
 989 
 990         if (m_form == SSA) {
 991             ASSERT(m_roots.size() == 1);
 992             ASSERT(m_roots.contains(this-&gt;block(0)));
 993             return block == this-&gt;block(0);
 994         }
 995 
 996         if (m_roots.size() &lt;= 4) {
 997             bool result = m_roots.contains(block);
 998             ASSERT(result == m_rootToArguments.contains(block));
 999             return result;
1000         }
1001         bool result = m_rootToArguments.contains(block);
1002         ASSERT(result == m_roots.contains(block));
1003         return result;
1004     }
1005 
<span class="line-added">1006     Prefix&amp; prefix() { return m_prefix; }</span>
<span class="line-added">1007     void nextPhase() { m_prefix.phaseNumber++; }</span>
<span class="line-added">1008 </span>
1009     VM&amp; m_vm;
1010     Plan&amp; m_plan;
1011     CodeBlock* m_codeBlock;
1012     CodeBlock* m_profiledBlock;
1013 
1014     Vector&lt;RefPtr&lt;BasicBlock&gt;, 8&gt; m_blocks;
1015     Vector&lt;BasicBlock*, 1&gt; m_roots;
1016     Vector&lt;Edge, 16&gt; m_varArgChildren;
1017 
1018     HashMap&lt;EncodedJSValue, FrozenValue*, EncodedJSValueHash, EncodedJSValueHashTraits&gt; m_frozenValueMap;
1019     Bag&lt;FrozenValue&gt; m_frozenValues;
1020 
1021     Vector&lt;uint32_t&gt; m_uint32ValuesInUse;
1022 
1023     Bag&lt;StorageAccessData&gt; m_storageAccessData;
1024 
<span class="line-modified">1025     // In CPS, this is all of the SetArgumentDefinitely nodes for the arguments in the machine code block</span>
1026     // that survived DCE. All of them except maybe &quot;this&quot; will survive DCE, because of the Flush
1027     // nodes. In SSA, this has no meaning. It&#39;s empty.
1028     HashMap&lt;BasicBlock*, ArgumentsVector&gt; m_rootToArguments;
1029 
1030     // In SSA, this is the argument speculation that we&#39;ve locked in for an entrypoint block.
1031     //
1032     // We must speculate on the argument types at each entrypoint even if operations involving
1033     // arguments get killed. For example:
1034     //
1035     //     function foo(x) {
1036     //        var tmp = x + 1;
1037     //     }
1038     //
1039     // Assume that x is always int during profiling. The ArithAdd for &quot;x + 1&quot; will be dead and will
1040     // have a proven check for the edge to &quot;x&quot;. So, we will not insert a Check node and we will
1041     // kill the GetStack for &quot;x&quot;. But, we must do the int check in the progolue, because that&#39;s the
1042     // thing we used to allow DCE of ArithAdd. Otherwise the add could be impure:
1043     //
1044     //     var o = {
1045     //         valueOf: function() { do side effects; }
1046     //     };
1047     //     foo(o);
1048     //
1049     // If we DCE the ArithAdd and we remove the int check on x, then this won&#39;t do the side
1050     // effects.
1051     //
1052     // By convention, entrypoint index 0 is used for the CodeBlock&#39;s op_enter entrypoint.
1053     // So argumentFormats[0] are the argument formats for the normal call entrypoint.
1054     Vector&lt;Vector&lt;FlushFormat&gt;&gt; m_argumentFormats;
1055 










1056     SegmentedVector&lt;VariableAccessData, 16&gt; m_variableAccessData;
1057     SegmentedVector&lt;ArgumentPosition, 8&gt; m_argumentPositions;
1058     Bag&lt;Transition&gt; m_transitions;
1059     Bag&lt;BranchData&gt; m_branchData;
1060     Bag&lt;SwitchData&gt; m_switchData;
1061     Bag&lt;MultiGetByOffsetData&gt; m_multiGetByOffsetData;
1062     Bag&lt;MultiPutByOffsetData&gt; m_multiPutByOffsetData;
1063     Bag&lt;MatchStructureData&gt; m_matchStructureData;
1064     Bag&lt;ObjectMaterializationData&gt; m_objectMaterializationData;
1065     Bag&lt;CallVarargsData&gt; m_callVarargsData;
1066     Bag&lt;LoadVarargsData&gt; m_loadVarargsData;
1067     Bag&lt;StackAccessData&gt; m_stackAccessData;
1068     Bag&lt;LazyJSValue&gt; m_lazyJSValues;
1069     Bag&lt;CallDOMGetterData&gt; m_callDOMGetterData;
1070     Bag&lt;BitVector&gt; m_bitVectors;
1071     Vector&lt;InlineVariableData, 4&gt; m_inlineVariableData;
1072     HashMap&lt;CodeBlock*, std::unique_ptr&lt;FullBytecodeLiveness&gt;&gt; m_bytecodeLiveness;
1073     HashMap&lt;CodeBlock*, std::unique_ptr&lt;BytecodeKills&gt;&gt; m_bytecodeKills;
1074     HashSet&lt;std::pair&lt;JSObject*, PropertyOffset&gt;&gt; m_safeToLoad;
1075     Vector&lt;Ref&lt;Snippet&gt;&gt; m_domJITSnippets;
1076     std::unique_ptr&lt;CPSDominators&gt; m_cpsDominators;
1077     std::unique_ptr&lt;SSADominators&gt; m_ssaDominators;
1078     std::unique_ptr&lt;CPSNaturalLoops&gt; m_cpsNaturalLoops;
1079     std::unique_ptr&lt;SSANaturalLoops&gt; m_ssaNaturalLoops;
1080     std::unique_ptr&lt;SSACFG&gt; m_ssaCFG;
1081     std::unique_ptr&lt;CPSCFG&gt; m_cpsCFG;
1082     std::unique_ptr&lt;BackwardsCFG&gt; m_backwardsCFG;
1083     std::unique_ptr&lt;BackwardsDominators&gt; m_backwardsDominators;
1084     std::unique_ptr&lt;ControlEquivalenceAnalysis&gt; m_controlEquivalenceAnalysis;
1085     unsigned m_localVars;
1086     unsigned m_nextMachineLocal;
1087     unsigned m_parameterSlots;
1088 
<span class="line-added">1089     // This is the number of logical entrypoints that we&#39;re compiling. This is only used</span>
<span class="line-added">1090     // in SSA. Each EntrySwitch node must have m_numberOfEntrypoints cases. Note, this is</span>
<span class="line-added">1091     // not the same as m_roots.size(). m_roots.size() represents the number of roots in</span>
<span class="line-added">1092     // the CFG. In SSA, m_roots.size() == 1 even if we&#39;re compiling more than one entrypoint.</span>
<span class="line-added">1093     unsigned m_numberOfEntrypoints { UINT_MAX };</span>
<span class="line-added">1094 </span>
<span class="line-added">1095     // This maps an entrypoint index to a particular op_catch bytecode offset. By convention,</span>
<span class="line-added">1096     // it&#39;ll never have zero as a key because we use zero to mean the op_enter entrypoint.</span>
<span class="line-added">1097     HashMap&lt;unsigned, unsigned&gt; m_entrypointIndexToCatchBytecodeOffset;</span>
<span class="line-added">1098 </span>
1099     HashSet&lt;String&gt; m_localStrings;
1100     HashMap&lt;const StringImpl*, String&gt; m_copiedStrings;
1101 
1102 #if USE(JSVALUE32_64)
1103     StdUnorderedMap&lt;int64_t, double*&gt; m_doubleConstantsMap;
1104     std::unique_ptr&lt;Bag&lt;double&gt;&gt; m_doubleConstants;
1105 #endif
1106 
1107     OptimizationFixpointState m_fixpointState;
1108     StructureRegistrationState m_structureRegistrationState;
1109     GraphForm m_form;
1110     UnificationState m_unificationState;
1111     PlanStage m_planStage { PlanStage::Initial };
1112     RefCountState m_refCountState;
1113     bool m_hasDebuggerEnabled;
1114     bool m_hasExceptionHandlers { false };
1115     bool m_isInSSAConversion { false };
1116     Optional&lt;uint32_t&gt; m_maxLocalsForCatchOSREntry;
1117     std::unique_ptr&lt;FlowIndexing&gt; m_indexingCache;
1118     std::unique_ptr&lt;FlowMap&lt;AbstractValue&gt;&gt; m_abstractValuesCache;
</pre>
<hr />
<pre>
1139 
1140         // Integer constants can be typed Double if they are written like a double in the source code (e.g. 42.0).
1141         // In that case, we stay conservative unless the other operand was explicitly typed as integer.
1142         NodeFlags operandResultType = operand-&gt;result();
1143         if (operandResultType != NodeResultInt32 &amp;&amp; immediateValue.isDouble())
1144             return DontSpeculateInt32;
1145 
1146         if (immediateValue.isBoolean() || jsNumber(immediateValue.asNumber()).isInt32())
1147             return add-&gt;canSpeculateInt32(source) ? SpeculateInt32 : DontSpeculateInt32;
1148 
1149         double doubleImmediate = immediateValue.asDouble();
1150         const double twoToThe48 = 281474976710656.0;
1151         if (doubleImmediate &lt; -twoToThe48 || doubleImmediate &gt; twoToThe48)
1152             return DontSpeculateInt32;
1153 
1154         return bytecodeCanTruncateInteger(add-&gt;arithNodeFlags()) ? SpeculateInt32AndTruncateConstants : DontSpeculateInt32;
1155     }
1156 
1157     B3::SparseCollection&lt;Node&gt; m_nodes;
1158     SegmentedVector&lt;RegisteredStructureSet, 16&gt; m_structureSets;
<span class="line-added">1159     Prefix m_prefix;</span>
1160 };
1161 
1162 } } // namespace JSC::DFG
1163 
1164 #endif
</pre>
</td>
</tr>
</table>
<center><a href="DFGGraph.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGInPlaceAbstractState.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>