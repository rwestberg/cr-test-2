<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/Modules/speech/SpeechSynthesis.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2013-2017 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;SpeechSynthesis.h&quot;
 28 
 29 #if ENABLE(SPEECH_SYNTHESIS)
 30 
 31 #include &quot;EventNames.h&quot;
 32 #include &quot;PlatformSpeechSynthesisVoice.h&quot;
 33 #include &quot;PlatformSpeechSynthesizer.h&quot;
 34 #include &quot;SpeechSynthesisEvent.h&quot;
 35 #include &quot;SpeechSynthesisUtterance.h&quot;
 36 #include &quot;UserGestureIndicator.h&quot;
 37 #include &lt;wtf/NeverDestroyed.h&gt;
 38 
 39 namespace WebCore {
 40 
<a name="1" id="anc1"></a><span class="line-modified"> 41 Ref&lt;SpeechSynthesis&gt; SpeechSynthesis::create()</span>
 42 {
<a name="2" id="anc2"></a><span class="line-modified"> 43     return adoptRef(*new SpeechSynthesis);</span>
 44 }
 45 
<a name="3" id="anc3"></a><span class="line-modified"> 46 SpeechSynthesis::SpeechSynthesis()</span>
 47     : m_currentSpeechUtterance(nullptr)
 48     , m_isPaused(false)
 49 #if PLATFORM(IOS_FAMILY)
 50     , m_restrictions(RequireUserGestureForSpeechStartRestriction)
 51 #endif
<a name="4" id="anc4"></a>
 52 {
<a name="5" id="anc5"></a>

 53 }
 54 
 55 void SpeechSynthesis::setPlatformSynthesizer(std::unique_ptr&lt;PlatformSpeechSynthesizer&gt; synthesizer)
 56 {
 57     m_platformSpeechSynthesizer = WTFMove(synthesizer);
 58     m_voiceList.clear();
 59     m_currentSpeechUtterance = nullptr;
 60     m_utteranceQueue.clear();
 61     m_isPaused = false;
<a name="6" id="anc6"></a>
 62 }
 63 
 64 void SpeechSynthesis::voicesDidChange()
 65 {
 66     m_voiceList.clear();
 67 }
 68 
<a name="7" id="anc7"></a>






 69 const Vector&lt;Ref&lt;SpeechSynthesisVoice&gt;&gt;&amp; SpeechSynthesis::getVoices()
 70 {
<a name="8" id="anc8"></a><span class="line-modified"> 71     if (m_voiceList.size())</span>
 72         return m_voiceList;
 73 
<a name="9" id="anc9"></a><span class="line-removed"> 74     if (!m_platformSpeechSynthesizer)</span>
<span class="line-removed"> 75         m_platformSpeechSynthesizer = std::make_unique&lt;PlatformSpeechSynthesizer&gt;(this);</span>
<span class="line-removed"> 76 </span>
 77     // If the voiceList is empty, that&#39;s the cue to get the voices from the platform again.
<a name="10" id="anc10"></a><span class="line-modified"> 78     for (auto&amp; voice : m_platformSpeechSynthesizer-&gt;voiceList())</span>
 79         m_voiceList.append(SpeechSynthesisVoice::create(*voice));
 80 
 81     return m_voiceList;
 82 }
 83 
 84 bool SpeechSynthesis::speaking() const
 85 {
 86     // If we have a current speech utterance, then that means we&#39;re assumed to be in a speaking state.
 87     // This state is independent of whether the utterance happens to be paused.
 88     return m_currentSpeechUtterance;
 89 }
 90 
 91 bool SpeechSynthesis::pending() const
 92 {
 93     // This is true if there are any utterances that have not started.
 94     // That means there will be more than one in the queue.
 95     return m_utteranceQueue.size() &gt; 1;
 96 }
 97 
 98 bool SpeechSynthesis::paused() const
 99 {
100     return m_isPaused;
101 }
102 
103 void SpeechSynthesis::startSpeakingImmediately(SpeechSynthesisUtterance&amp; utterance)
104 {
<a name="11" id="anc11"></a><span class="line-removed">105     ASSERT(!m_currentSpeechUtterance);</span>
106     utterance.setStartTime(MonotonicTime::now());
107     m_currentSpeechUtterance = &amp;utterance;
108     m_isPaused = false;
109 
110     // Zero lengthed strings should immediately notify that the event is complete.
111     if (utterance.text().isEmpty()) {
112         handleSpeakingCompleted(utterance, false);
113         return;
114     }
115 
<a name="12" id="anc12"></a><span class="line-modified">116     if (!m_platformSpeechSynthesizer)</span>
<span class="line-modified">117         m_platformSpeechSynthesizer = std::make_unique&lt;PlatformSpeechSynthesizer&gt;(this);</span>
<span class="line-modified">118     m_platformSpeechSynthesizer-&gt;speak(utterance.platformUtterance());</span>

119 }
120 
121 void SpeechSynthesis::speak(SpeechSynthesisUtterance&amp; utterance)
122 {
123     // Like Audio, we should require that the user interact to start a speech synthesis session.
124 #if PLATFORM(IOS_FAMILY)
125     if (UserGestureIndicator::processingUserGesture())
126         removeBehaviorRestriction(RequireUserGestureForSpeechStartRestriction);
127     else if (userGestureRequiredForSpeechStart())
128         return;
129 #endif
130 
131     m_utteranceQueue.append(utterance);
132 
133     // If the queue was empty, speak this immediately and add it to the queue.
134     if (m_utteranceQueue.size() == 1)
135         startSpeakingImmediately(m_utteranceQueue.first());
136 }
137 
138 void SpeechSynthesis::cancel()
139 {
140     // Remove all the items from the utterance queue.
141     // Hold on to the current utterance so the platform synthesizer can have a chance to clean up.
142     RefPtr&lt;SpeechSynthesisUtterance&gt; current = m_currentSpeechUtterance;
143     m_utteranceQueue.clear();
<a name="13" id="anc13"></a><span class="line-modified">144     if (m_platformSpeechSynthesizer)</span>


145         m_platformSpeechSynthesizer-&gt;cancel();
<a name="14" id="anc14"></a>


146     current = nullptr;
<a name="15" id="anc15"></a><span class="line-removed">147 </span>
<span class="line-removed">148     // The platform should have called back immediately and cleared the current utterance.</span>
<span class="line-removed">149     ASSERT(!m_currentSpeechUtterance);</span>
150 }
151 
152 void SpeechSynthesis::pause()
153 {
<a name="16" id="anc16"></a><span class="line-modified">154     if (!m_isPaused &amp;&amp; m_platformSpeechSynthesizer)</span>
<span class="line-modified">155         m_platformSpeechSynthesizer-&gt;pause();</span>




156 }
157 
158 void SpeechSynthesis::resume()
159 {
<a name="17" id="anc17"></a><span class="line-modified">160     if (m_currentSpeechUtterance &amp;&amp; m_platformSpeechSynthesizer)</span>
<span class="line-modified">161         m_platformSpeechSynthesizer-&gt;resume();</span>




162 }
163 
<a name="18" id="anc18"></a><span class="line-modified">164 void SpeechSynthesis::fireEvent(const AtomicString&amp; type, SpeechSynthesisUtterance&amp; utterance, unsigned long charIndex, const String&amp; name)</span>
165 {
166     utterance.dispatchEvent(SpeechSynthesisEvent::create(type, charIndex, (MonotonicTime::now() - utterance.startTime()).seconds(), name));
167 }
168 
169 void SpeechSynthesis::handleSpeakingCompleted(SpeechSynthesisUtterance&amp; utterance, bool errorOccurred)
170 {
171     ASSERT(m_currentSpeechUtterance);
172     Ref&lt;SpeechSynthesisUtterance&gt; protect(utterance);
173 
174     m_currentSpeechUtterance = nullptr;
175 
176     fireEvent(errorOccurred ? eventNames().errorEvent : eventNames().endEvent, utterance, 0, String());
177 
178     if (m_utteranceQueue.size()) {
179         Ref&lt;SpeechSynthesisUtterance&gt; firstUtterance = m_utteranceQueue.takeFirst();
180         ASSERT(&amp;utterance == firstUtterance.ptr());
181 
182         // Start the next job if there is one pending.
183         if (!m_utteranceQueue.isEmpty())
184             startSpeakingImmediately(m_utteranceQueue.first());
185     }
186 }
187 
188 void SpeechSynthesis::boundaryEventOccurred(PlatformSpeechSynthesisUtterance&amp; utterance, SpeechBoundary boundary, unsigned charIndex)
189 {
190     static NeverDestroyed&lt;const String&gt; wordBoundaryString(MAKE_STATIC_STRING_IMPL(&quot;word&quot;));
191     static NeverDestroyed&lt;const String&gt; sentenceBoundaryString(MAKE_STATIC_STRING_IMPL(&quot;sentence&quot;));
192 
193     ASSERT(utterance.client());
194 
195     switch (boundary) {
<a name="19" id="anc19"></a><span class="line-modified">196     case SpeechWordBoundary:</span>
197         fireEvent(eventNames().boundaryEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), charIndex, wordBoundaryString);
198         break;
<a name="20" id="anc20"></a><span class="line-modified">199     case SpeechSentenceBoundary:</span>
200         fireEvent(eventNames().boundaryEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), charIndex, sentenceBoundaryString);
201         break;
202     default:
203         ASSERT_NOT_REACHED();
204     }
205 }
206 
<a name="21" id="anc21"></a>














































207 void SpeechSynthesis::didStartSpeaking(PlatformSpeechSynthesisUtterance&amp; utterance)
208 {
209     if (utterance.client())
210         fireEvent(eventNames().startEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), 0, String());
211 }
212 
213 void SpeechSynthesis::didPauseSpeaking(PlatformSpeechSynthesisUtterance&amp; utterance)
214 {
215     m_isPaused = true;
216     if (utterance.client())
217         fireEvent(eventNames().pauseEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), 0, String());
218 }
219 
220 void SpeechSynthesis::didResumeSpeaking(PlatformSpeechSynthesisUtterance&amp; utterance)
221 {
222     m_isPaused = false;
223     if (utterance.client())
224         fireEvent(eventNames().resumeEvent, static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), 0, String());
225 }
226 
227 void SpeechSynthesis::didFinishSpeaking(PlatformSpeechSynthesisUtterance&amp; utterance)
228 {
229     if (utterance.client())
230         handleSpeakingCompleted(static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), false);
231 }
232 
233 void SpeechSynthesis::speakingErrorOccurred(PlatformSpeechSynthesisUtterance&amp; utterance)
234 {
235     if (utterance.client())
236         handleSpeakingCompleted(static_cast&lt;SpeechSynthesisUtterance&amp;&gt;(*utterance.client()), true);
237 }
238 
239 } // namespace WebCore
240 
241 #endif // ENABLE(SPEECH_SYNTHESIS)
<a name="22" id="anc22"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="22" type="hidden" />
</body>
</html>