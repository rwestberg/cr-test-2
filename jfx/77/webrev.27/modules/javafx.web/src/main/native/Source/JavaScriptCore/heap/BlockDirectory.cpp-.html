<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/BlockDirectory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2012-2018 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;BlockDirectory.h&quot;
 28 
 29 #include &quot;BlockDirectoryInlines.h&quot;
 30 #include &quot;GCActivityCallback.h&quot;
 31 #include &quot;Heap.h&quot;
 32 #include &quot;IncrementalSweeper.h&quot;
 33 #include &quot;JSCInlines.h&quot;
 34 #include &quot;MarkedBlockInlines.h&quot;
 35 #include &quot;SubspaceInlines.h&quot;
 36 #include &quot;SuperSampler.h&quot;
 37 #include &quot;VM.h&quot;
 38 
 39 namespace JSC {
 40 
 41 BlockDirectory::BlockDirectory(Heap* heap, size_t cellSize)
 42     : m_cellSize(static_cast&lt;unsigned&gt;(cellSize))
 43     , m_heap(heap)
 44 {
 45 }
 46 
 47 BlockDirectory::~BlockDirectory()
 48 {
 49     auto locker = holdLock(m_localAllocatorsLock);
 50     while (!m_localAllocators.isEmpty())
 51         m_localAllocators.begin()-&gt;remove();
 52 }
 53 
 54 void BlockDirectory::setSubspace(Subspace* subspace)
 55 {
 56     m_attributes = subspace-&gt;attributes();
 57     m_subspace = subspace;
 58 }
 59 
 60 bool BlockDirectory::isPagedOut(MonotonicTime deadline)
 61 {
 62     unsigned itersSinceLastTimeCheck = 0;
 63     for (auto* block : m_blocks) {
 64         if (block)
 65             holdLock(block-&gt;block().lock());
 66         ++itersSinceLastTimeCheck;
 67         if (itersSinceLastTimeCheck &gt;= Heap::s_timeCheckResolution) {
 68             MonotonicTime currentTime = MonotonicTime::now();
 69             if (currentTime &gt; deadline)
 70                 return true;
 71             itersSinceLastTimeCheck = 0;
 72         }
 73     }
 74     return false;
 75 }
 76 
 77 MarkedBlock::Handle* BlockDirectory::findEmptyBlockToSteal()
 78 {
 79     m_emptyCursor = m_empty.findBit(m_emptyCursor, true);
 80     if (m_emptyCursor &gt;= m_blocks.size())
 81         return nullptr;
 82     return m_blocks[m_emptyCursor];
 83 }
 84 
 85 MarkedBlock::Handle* BlockDirectory::findBlockForAllocation(LocalAllocator&amp; allocator)
 86 {
 87     for (;;) {
 88         allocator.m_allocationCursor = (m_canAllocateButNotEmpty | m_empty).findBit(allocator.m_allocationCursor, true);
 89         if (allocator.m_allocationCursor &gt;= m_blocks.size())
 90             return nullptr;
 91 
 92         size_t blockIndex = allocator.m_allocationCursor++;
 93         MarkedBlock::Handle* result = m_blocks[blockIndex];
 94         setIsCanAllocateButNotEmpty(NoLockingNecessary, blockIndex, false);
 95         return result;
 96     }
 97 }
 98 
 99 MarkedBlock::Handle* BlockDirectory::tryAllocateBlock()
100 {
101     SuperSamplerScope superSamplerScope(false);
102 
103     MarkedBlock::Handle* handle = MarkedBlock::tryCreate(*m_heap, subspace()-&gt;alignedMemoryAllocator());
104     if (!handle)
105         return nullptr;
106 
107     markedSpace().didAddBlock(handle);
108 
109     return handle;
110 }
111 
112 void BlockDirectory::addBlock(MarkedBlock::Handle* block)
113 {
114     size_t index;
115     if (m_freeBlockIndices.isEmpty()) {
116         index = m_blocks.size();
117 
118         size_t oldCapacity = m_blocks.capacity();
119         m_blocks.append(block);
120         if (m_blocks.capacity() != oldCapacity) {
121             forEachBitVector(
122                 NoLockingNecessary,
123                 [&amp;] (FastBitVector&amp; vector) {
124                     ASSERT_UNUSED(vector, vector.numBits() == oldCapacity);
125                 });
126 
127             ASSERT(m_blocks.capacity() &gt; oldCapacity);
128 
129             LockHolder locker(m_bitvectorLock);
130             subspace()-&gt;didResizeBits(m_blocks.capacity());
131             forEachBitVector(
132                 locker,
133                 [&amp;] (FastBitVector&amp; vector) {
134                     vector.resize(m_blocks.capacity());
135                 });
136         }
137     } else {
138         index = m_freeBlockIndices.takeLast();
139         ASSERT(!m_blocks[index]);
140         m_blocks[index] = block;
141     }
142 
143     forEachBitVector(
144         NoLockingNecessary,
145         [&amp;] (FastBitVector&amp; vector) {
146             ASSERT_UNUSED(vector, !vector[index]);
147         });
148 
149     // This is the point at which the block learns of its cellSize() and attributes().
150     block-&gt;didAddToDirectory(this, index);
151 
152     setIsLive(NoLockingNecessary, index, true);
153     setIsEmpty(NoLockingNecessary, index, true);
154 }
155 
156 void BlockDirectory::removeBlock(MarkedBlock::Handle* block)
157 {
158     ASSERT(block-&gt;directory() == this);
159     ASSERT(m_blocks[block-&gt;index()] == block);
160 
161     subspace()-&gt;didRemoveBlock(block-&gt;index());
162 
163     m_blocks[block-&gt;index()] = nullptr;
164     m_freeBlockIndices.append(block-&gt;index());
165 
166     forEachBitVector(
167         holdLock(m_bitvectorLock),
168         [&amp;] (FastBitVector&amp; vector) {
169             vector[block-&gt;index()] = false;
170         });
171 
172     block-&gt;didRemoveFromDirectory();
173 }
174 
175 void BlockDirectory::stopAllocating()
176 {
177     if (false)
178         dataLog(RawPointer(this), &quot;: BlockDirectory::stopAllocating!\n&quot;);
179     m_localAllocators.forEach(
180         [&amp;] (LocalAllocator* allocator) {
181             allocator-&gt;stopAllocating();
182         });
183 }
184 
185 void BlockDirectory::prepareForAllocation()
186 {
187     m_localAllocators.forEach(
188         [&amp;] (LocalAllocator* allocator) {
189             allocator-&gt;prepareForAllocation();
190         });
191 
192     m_unsweptCursor = 0;
193     m_emptyCursor = 0;
194 
195     m_eden.clearAll();
196 
197     if (UNLIKELY(Options::useImmortalObjects())) {
198         // FIXME: Make this work again.
199         // https://bugs.webkit.org/show_bug.cgi?id=162296
200         RELEASE_ASSERT_NOT_REACHED();
201     }
202 }
203 
204 void BlockDirectory::stopAllocatingForGood()
205 {
206     if (false)
207         dataLog(RawPointer(this), &quot;: BlockDirectory::stopAllocatingForGood!\n&quot;);
208 
209     m_localAllocators.forEach(
210         [&amp;] (LocalAllocator* allocator) {
211             allocator-&gt;stopAllocatingForGood();
212         });
213 
214     auto locker = holdLock(m_localAllocatorsLock);
215     while (!m_localAllocators.isEmpty())
216         m_localAllocators.begin()-&gt;remove();
217 }
218 
219 void BlockDirectory::lastChanceToFinalize()
220 {
221     forEachBlock(
222         [&amp;] (MarkedBlock::Handle* block) {
223             block-&gt;lastChanceToFinalize();
224         });
225 }
226 
227 void BlockDirectory::resumeAllocating()
228 {
229     m_localAllocators.forEach(
230         [&amp;] (LocalAllocator* allocator) {
231             allocator-&gt;resumeAllocating();
232         });
233 }
234 
235 void BlockDirectory::beginMarkingForFullCollection()
236 {
237     // Mark bits are sticky and so is our summary of mark bits. We only clear these during full
238     // collections, so if you survived the last collection you will survive the next one so long
239     // as the next one is eden.
240     m_markingNotEmpty.clearAll();
241     m_markingRetired.clearAll();
242 }
243 
244 void BlockDirectory::endMarking()
245 {
246     m_allocated.clearAll();
247 
248     // It&#39;s surprising and frustrating to comprehend, but the end-of-marking flip does not need to
249     // know what kind of collection it is. That knowledge is already encoded in the m_markingXYZ
250     // vectors.
251 
252     if (!Options::tradeDestructorBlocks() &amp;&amp; needsDestruction()) {
253         ASSERT(m_empty.isEmpty());
254         m_canAllocateButNotEmpty = m_live &amp; ~m_markingRetired;
255     } else {
256         m_empty = m_live &amp; ~m_markingNotEmpty;
257         m_canAllocateButNotEmpty = m_live &amp; m_markingNotEmpty &amp; ~m_markingRetired;
258     }
259 
260     if (needsDestruction()) {
261         // There are some blocks that we didn&#39;t allocate out of in the last cycle, but we swept them. This
262         // will forget that we did that and we will end up sweeping them again and attempting to call their
263         // destructors again. That&#39;s fine because of zapping. The only time when we cannot forget is when
264         // we just allocate a block or when we move a block from one size class to another. That doesn&#39;t
265         // happen here.
266         m_destructible = m_live;
267     }
268 
269     if (false) {
270         dataLog(&quot;Bits for &quot;, m_cellSize, &quot;, &quot;, m_attributes, &quot; after endMarking:\n&quot;);
271         dumpBits(WTF::dataFile());
272     }
273 }
274 
275 void BlockDirectory::snapshotUnsweptForEdenCollection()
276 {
277     m_unswept |= m_eden;
278 }
279 
280 void BlockDirectory::snapshotUnsweptForFullCollection()
281 {
282     m_unswept = m_live;
283 }
284 
285 MarkedBlock::Handle* BlockDirectory::findBlockToSweep()
286 {
287     m_unsweptCursor = m_unswept.findBit(m_unsweptCursor, true);
288     if (m_unsweptCursor &gt;= m_blocks.size())
289         return nullptr;
290     return m_blocks[m_unsweptCursor];
291 }
292 
293 void BlockDirectory::sweep()
294 {
295     m_unswept.forEachSetBit(
296         [&amp;] (size_t index) {
297             MarkedBlock::Handle* block = m_blocks[index];
298             block-&gt;sweep(nullptr);
299         });
300 }
301 
302 void BlockDirectory::shrink()
303 {
304     (m_empty &amp; ~m_destructible).forEachSetBit(
305         [&amp;] (size_t index) {
306             markedSpace().freeBlock(m_blocks[index]);
307         });
308 }
309 
310 void BlockDirectory::assertNoUnswept()
311 {
312     if (ASSERT_DISABLED)
313         return;
314 
315     if (m_unswept.isEmpty())
316         return;
317 
318     dataLog(&quot;Assertion failed: unswept not empty in &quot;, *this, &quot;.\n&quot;);
319     dumpBits();
320     ASSERT_NOT_REACHED();
321 }
322 
323 RefPtr&lt;SharedTask&lt;MarkedBlock::Handle*()&gt;&gt; BlockDirectory::parallelNotEmptyBlockSource()
324 {
325     class Task : public SharedTask&lt;MarkedBlock::Handle*()&gt; {
326     public:
327         Task(BlockDirectory&amp; directory)
328             : m_directory(directory)
329         {
330         }
331 
332         MarkedBlock::Handle* run() override
333         {
334             if (m_done)
335                 return nullptr;
336             auto locker = holdLock(m_lock);
337             m_index = m_directory.m_markingNotEmpty.findBit(m_index, true);
338             if (m_index &gt;= m_directory.m_blocks.size()) {
339                 m_done = true;
340                 return nullptr;
341             }
342             return m_directory.m_blocks[m_index++];
343         }
344 
345     private:
346         BlockDirectory&amp; m_directory;
347         size_t m_index { 0 };
348         Lock m_lock;
349         bool m_done { false };
350     };
351 
352     return adoptRef(new Task(*this));
353 }
354 
355 void BlockDirectory::dump(PrintStream&amp; out) const
356 {
357     out.print(RawPointer(this), &quot;:&quot;, m_cellSize, &quot;/&quot;, m_attributes);
358 }
359 
360 void BlockDirectory::dumpBits(PrintStream&amp; out)
361 {
362     unsigned maxNameLength = 0;
363     forEachBitVectorWithName(
364         NoLockingNecessary,
365         [&amp;] (FastBitVector&amp;, const char* name) {
366             unsigned length = strlen(name);
367             maxNameLength = std::max(maxNameLength, length);
368         });
369 
370     forEachBitVectorWithName(
371         NoLockingNecessary,
372         [&amp;] (FastBitVector&amp; vector, const char* name) {
373             out.print(&quot;    &quot;, name, &quot;: &quot;);
374             for (unsigned i = maxNameLength - strlen(name); i--;)
375                 out.print(&quot; &quot;);
376             out.print(vector, &quot;\n&quot;);
377         });
378 }
379 
380 MarkedSpace&amp; BlockDirectory::markedSpace() const
381 {
382     return m_subspace-&gt;space();
383 }
384 
385 bool BlockDirectory::isFreeListedCell(const void* target)
386 {
387     bool result = false;
388     m_localAllocators.forEach(
389         [&amp;] (LocalAllocator* allocator) {
390             result |= allocator-&gt;isFreeListedCell(target);
391         });
392     return result;
393 }
394 
395 } // namespace JSC
396 
    </pre>
  </body>
</html>