diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGArgumentsEliminationPhase.cpp b/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGArgumentsEliminationPhase.cpp
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGArgumentsEliminationPhase.cpp
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGArgumentsEliminationPhase.cpp
@@ -1,7 +1,7 @@
 /*
- * Copyright (C) 2015-2018 Apple Inc. All rights reserved.
+ * Copyright (C) 2015-2019 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
  * are met:
  * 1. Redistributions of source code must retain the above copyright
@@ -500,10 +500,37 @@
                     },
                     NoOpClobberize());
             }
         }
 
+        using InlineCallFrames = HashSet<InlineCallFrame*, WTF::DefaultHash<InlineCallFrame*>::Hash, WTF::NullableHashTraits<InlineCallFrame*>>;
+        using InlineCallFramesForCanditates = HashMap<Node*, InlineCallFrames>;
+        InlineCallFramesForCanditates inlineCallFramesForCandidate;
+        auto forEachDependentNode = recursableLambda([&](auto self, Node* node, const auto& functor) -> void {
+            functor(node);
+
+            if (node->op() == Spread) {
+                self(node->child1().node(), functor);
+                return;
+            }
+
+            if (node->op() == NewArrayWithSpread) {
+                BitVector* bitVector = node->bitVector();
+                for (unsigned i = node->numChildren(); i--; ) {
+                    if (bitVector->get(i))
+                        self(m_graph.varArgChild(node, i).node(), functor);
+                }
+                return;
+            }
+        });
+        for (Node* candidate : m_candidates) {
+            auto& set = inlineCallFramesForCandidate.add(candidate, InlineCallFrames()).iterator->value;
+            forEachDependentNode(candidate, [&](Node* dependent) {
+                set.add(dependent->origin.semantic.inlineCallFrame());
+            });
+        }
+
         for (BasicBlock* block : m_graph.blocksInNaturalOrder()) {
             // Stop if we've already removed all candidates.
             if (m_candidates.isEmpty())
                 return;
 
@@ -522,86 +549,101 @@
                 m_graph, combinedLiveness, block,
                 [&] (unsigned nodeIndex, Node* candidate) {
                     if (!m_candidates.contains(candidate))
                         return;
 
-                    // Check if this block has any clobbers that affect this candidate. This is a fairly
-                    // fast check.
-                    bool isClobberedByBlock = false;
-                    Operands<bool>& clobberedByThisBlock = clobberedByBlock[block];
+                    for (InlineCallFrame* inlineCallFrame : inlineCallFramesForCandidate.get(candidate)) {
+                        // Check if this block has any clobbers that affect this candidate. This is a fairly
+                        // fast check.
+                        bool isClobberedByBlock = false;
+                        Operands<bool>& clobberedByThisBlock = clobberedByBlock[block];
 
-                    if (InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame) {
-                        if (inlineCallFrame->isVarargs()) {
-                            isClobberedByBlock |= clobberedByThisBlock.operand(
-                                inlineCallFrame->stackOffset + CallFrameSlot::argumentCount);
-                        }
+                        if (inlineCallFrame) {
+                            if (inlineCallFrame->isVarargs()) {
+                                isClobberedByBlock |= clobberedByThisBlock.operand(
+                                    inlineCallFrame->stackOffset + CallFrameSlot::argumentCount);
+                            }
 
-                        if (!isClobberedByBlock || inlineCallFrame->isClosureCall) {
-                            isClobberedByBlock |= clobberedByThisBlock.operand(
-                                inlineCallFrame->stackOffset + CallFrameSlot::callee);
-                        }
+                            if (!isClobberedByBlock || inlineCallFrame->isClosureCall) {
+                                isClobberedByBlock |= clobberedByThisBlock.operand(
+                                    inlineCallFrame->stackOffset + CallFrameSlot::callee);
+                            }
 
-                        if (!isClobberedByBlock) {
-                            for (unsigned i = 0; i < inlineCallFrame->argumentCountIncludingThis - 1; ++i) {
-                                VirtualRegister reg =
-                                    VirtualRegister(inlineCallFrame->stackOffset) +
-                                    CallFrame::argumentOffset(i);
-                                if (clobberedByThisBlock.operand(reg)) {
+                            if (!isClobberedByBlock) {
+                                for (unsigned i = 0; i < inlineCallFrame->argumentCountIncludingThis - 1; ++i) {
+                                    VirtualRegister reg =
+                                        VirtualRegister(inlineCallFrame->stackOffset) +
+                                        CallFrame::argumentOffset(i);
+                                    if (clobberedByThisBlock.operand(reg)) {
+                                        isClobberedByBlock = true;
+                                        break;
+                                    }
+                                }
+                            }
+                        } else {
+                            // We don't include the ArgumentCount or Callee in this case because we can be
+                            // damn sure that this won't be clobbered.
+                            for (unsigned i = 1; i < static_cast<unsigned>(codeBlock()->numParameters()); ++i) {
+                                if (clobberedByThisBlock.argument(i)) {
                                     isClobberedByBlock = true;
                                     break;
                                 }
                             }
                         }
-                    } else {
-                        // We don't include the ArgumentCount or Callee in this case because we can be
-                        // damn sure that this won't be clobbered.
-                        for (unsigned i = 1; i < static_cast<unsigned>(codeBlock()->numParameters()); ++i) {
-                            if (clobberedByThisBlock.argument(i)) {
-                                isClobberedByBlock = true;
-                                break;
-                            }
-                        }
-                    }
 
-                    if (!isClobberedByBlock)
-                        return;
+                        if (!isClobberedByBlock)
+                            continue;
 
-                    // Check if we can immediately eliminate this candidate. If the block has a clobber
-                    // for this arguments allocation, and we'd have to examine every node in the block,
-                    // then we can just eliminate the candidate.
-                    if (nodeIndex == block->size() && candidate->owner != block) {
-                        if (DFGArgumentsEliminationPhaseInternal::verbose)
-                            dataLog("eliminating candidate: ", candidate, " because it is clobbered by: ", block->at(nodeIndex), "\n");
-                        transitivelyRemoveCandidate(candidate);
-                        return;
-                    }
+                        // Check if we can immediately eliminate this candidate. If the block has a clobber
+                        // for this arguments allocation, and we'd have to examine every node in the block,
+                        // then we can just eliminate the candidate.
+                        if (nodeIndex == block->size() && candidate->owner != block) {
+                            if (DFGArgumentsEliminationPhaseInternal::verbose)
+                                dataLog("eliminating candidate: ", candidate, " because it is clobbered by: ", block->at(nodeIndex), "\n");
+                            transitivelyRemoveCandidate(candidate);
+                            return;
+                        }
 
-                    // This loop considers all nodes up to the nodeIndex, excluding the nodeIndex.
-                    while (nodeIndex--) {
-                        Node* node = block->at(nodeIndex);
-                        if (node == candidate)
-                            break;
+                        // This loop considers all nodes up to the nodeIndex, excluding the nodeIndex.
+                        //
+                        // Note: nodeIndex here has a double meaning. Before entering this
+                        // while loop, it refers to the remaining number of nodes that have
+                        // yet to be processed. Inside the look, it refers to the index
+                        // of the current node to process (after we decrement it).
+                        //
+                        // If the remaining number of nodes is 0, we should not decrement nodeIndex.
+                        // Hence, we must only decrement nodeIndex inside the while loop instead of
+                        // in its condition statement. Note that this while loop is embedded in an
+                        // outer for loop. If we decrement nodeIndex in the condition statement, a
+                        // nodeIndex of 0 will become UINT_MAX, and the outer loop will wrongly
+                        // treat this as there being UINT_MAX remaining nodes to process.
+                        while (nodeIndex) {
+                            --nodeIndex;
+                            Node* node = block->at(nodeIndex);
+                            if (node == candidate)
+                                break;
 
-                        bool found = false;
-                        clobberize(
-                            m_graph, node, NoOpClobberize(),
-                            [&] (AbstractHeap heap) {
-                                if (heap.kind() == Stack && !heap.payload().isTop()) {
-                                    if (argumentsInvolveStackSlot(candidate, VirtualRegister(heap.payload().value32())))
+                            bool found = false;
+                            clobberize(
+                                m_graph, node, NoOpClobberize(),
+                                [&] (AbstractHeap heap) {
+                                    if (heap.kind() == Stack && !heap.payload().isTop()) {
+                                        if (argumentsInvolveStackSlot(inlineCallFrame, VirtualRegister(heap.payload().value32())))
+                                            found = true;
+                                        return;
+                                    }
+                                    if (heap.overlaps(Stack))
                                         found = true;
-                                    return;
-                                }
-                                if (heap.overlaps(Stack))
-                                    found = true;
-                            },
-                            NoOpClobberize());
+                                },
+                                NoOpClobberize());
 
-                        if (found) {
-                            if (DFGArgumentsEliminationPhaseInternal::verbose)
-                                dataLog("eliminating candidate: ", candidate, " because it is clobbered by ", block->at(nodeIndex), "\n");
-                            transitivelyRemoveCandidate(candidate);
-                            return;
+                            if (found) {
+                                if (DFGArgumentsEliminationPhaseInternal::verbose)
+                                    dataLog("eliminating candidate: ", candidate, " because it is clobbered by ", block->at(nodeIndex), "\n");
+                                transitivelyRemoveCandidate(candidate);
+                                return;
+                            }
                         }
                     }
                 });
         }
 
@@ -659,10 +701,16 @@
 
                 case CreateRest:
                     if (!m_candidates.contains(node))
                         break;
 
+                    ASSERT(node->origin.exitOK);
+                    ASSERT(node->child1().useKind() == Int32Use);
+                    insertionSet.insertNode(
+                        nodeIndex, SpecNone, Check, node->origin,
+                        node->child1());
+
                     node->setOpAndDefaultFlags(PhantomCreateRest);
                     // We don't need this parameter for OSR exit, we can find out all the information
                     // we need via the static parameter count and the dynamic argument count.
                     node->child1() = Edge();
                     break;
@@ -751,11 +799,11 @@
                         numberOfArgumentsToSkip = candidate->numberOfArgumentsToSkip();
 
                     Node* result = nullptr;
                     if (m_graph.varArgChild(node, 1)->isInt32Constant()) {
                         unsigned index = m_graph.varArgChild(node, 1)->asUInt32();
-                        InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame;
+                        InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame();
                         index += numberOfArgumentsToSkip;
 
                         bool safeToGetStack = index >= numberOfArgumentsToSkip;
                         if (inlineCallFrame)
                             safeToGetStack &= index < inlineCallFrame->argumentCountIncludingThis - 1;
@@ -810,10 +858,13 @@
 
                     auto storeArgumentCountIncludingThis = [&] (unsigned argumentCountIncludingThis) {
                         Node* argumentCountIncludingThisNode = insertionSet.insertConstant(
                             nodeIndex, node->origin.withExitOK(canExit),
                             jsNumber(argumentCountIncludingThis));
+                        insertionSet.insertNode(
+                            nodeIndex, SpecNone, KillStack, node->origin.takeValidExit(canExit),
+                            OpInfo(varargsData->count.offset()));
                         insertionSet.insertNode(
                             nodeIndex, SpecNone, MovHint, node->origin.takeValidExit(canExit),
                             OpInfo(varargsData->count.offset()), Edge(argumentCountIncludingThisNode));
                         insertionSet.insertNode(
                             nodeIndex, SpecNone, PutStack, node->origin.withExitOK(canExit),
@@ -824,10 +875,12 @@
                     auto storeValue = [&] (Node* value, unsigned storeIndex) {
                         VirtualRegister reg = varargsData->start + storeIndex;
                         StackAccessData* data =
                             m_graph.m_stackAccessData.add(reg, FlushedJSValue);
 
+                        insertionSet.insertNode(
+                            nodeIndex, SpecNone, KillStack, node->origin.takeValidExit(canExit), OpInfo(reg.offset()));
                         insertionSet.insertNode(
                             nodeIndex, SpecNone, MovHint, node->origin.takeValidExit(canExit),
                             OpInfo(reg.offset()), Edge(value));
                         insertionSet.insertNode(
                             nodeIndex, SpecNone, PutStack, node->origin.withExitOK(canExit),
@@ -853,11 +906,11 @@
                             // PhantomNewArrayBuffer only contains constants. It can always convert LoadVarargs to static load stores.
                             if (candidate->op() == PhantomNewArrayBuffer)
                                 return true;
 
                             ASSERT(candidate->op() == PhantomCreateRest);
-                            InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame;
+                            InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame();
                             return inlineCallFrame && !inlineCallFrame->isVarargs();
                         });
 
                         if (canConvertToStaticLoadStores(candidate)) {
                             auto countNumberOfArguments = recursableLambda([&](auto self, Node* candidate) -> unsigned {
@@ -879,11 +932,11 @@
                                 if (candidate->op() == PhantomNewArrayBuffer)
                                     return candidate->castOperand<JSImmutableButterfly*>()->length();
 
                                 ASSERT(candidate->op() == PhantomCreateRest);
                                 unsigned numberOfArgumentsToSkip = candidate->numberOfArgumentsToSkip();
-                                InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame;
+                                InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame();
                                 unsigned frameArgumentCount = inlineCallFrame->argumentCountIncludingThis - 1;
                                 if (frameArgumentCount >= numberOfArgumentsToSkip)
                                     return frameArgumentCount - numberOfArgumentsToSkip;
                                 return 0;
                             });
@@ -927,11 +980,11 @@
                                         return storeIndex;
                                     }
 
                                     ASSERT(candidate->op() == PhantomCreateRest);
                                     unsigned numberOfArgumentsToSkip = candidate->numberOfArgumentsToSkip();
-                                    InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame;
+                                    InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame();
                                     unsigned frameArgumentCount = inlineCallFrame->argumentCountIncludingThis - 1;
                                     for (unsigned loadIndex = numberOfArgumentsToSkip; loadIndex < frameArgumentCount; ++loadIndex) {
                                         VirtualRegister reg = virtualRegisterForArgument(loadIndex + 1) + inlineCallFrame->stackOffset;
                                         StackAccessData* data = m_graph.m_stackAccessData.add(reg, FlushedJSValue);
                                         Node* value = insertionSet.insertNode(
@@ -962,11 +1015,11 @@
                         unsigned numberOfArgumentsToSkip = 0;
                         if (candidate->op() == PhantomCreateRest)
                             numberOfArgumentsToSkip = candidate->numberOfArgumentsToSkip();
                         varargsData->offset += numberOfArgumentsToSkip;
 
-                        InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame;
+                        InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame();
 
                         if (inlineCallFrame
                             && !inlineCallFrame->isVarargs()) {
 
                             unsigned argumentCountIncludingThis = inlineCallFrame->argumentCountIncludingThis;
@@ -1103,11 +1156,11 @@
                             // PhantomNewArrayBuffer only contains constants. It can always convert LoadVarargs to static load stores.
                             if (candidate->op() == PhantomNewArrayBuffer)
                                 return true;
 
                             ASSERT(candidate->op() == PhantomCreateRest);
-                            InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame;
+                            InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame();
                             return inlineCallFrame && !inlineCallFrame->isVarargs();
                         });
 
                         if (canTransformToStaticArgumentCountCall(candidate)) {
                             Vector<Node*> arguments;
@@ -1142,11 +1195,11 @@
                                     }
                                     return;
                                 }
 
                                 ASSERT(candidate->op() == PhantomCreateRest);
-                                InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame;
+                                InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame();
                                 unsigned numberOfArgumentsToSkip = candidate->numberOfArgumentsToSkip();
                                 for (unsigned i = 1 + numberOfArgumentsToSkip; i < inlineCallFrame->argumentCountIncludingThis; ++i) {
                                     StackAccessData* data = m_graph.m_stackAccessData.add(
                                         virtualRegisterForArgument(i) + inlineCallFrame->stackOffset,
                                         FlushedJSValue);
@@ -1167,11 +1220,11 @@
                         if (candidate->op() == PhantomCreateRest)
                             numberOfArgumentsToSkip = candidate->numberOfArgumentsToSkip();
                         CallVarargsData* varargsData = node->callVarargsData();
                         varargsData->firstVarArgOffset += numberOfArgumentsToSkip;
 
-                        InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame;
+                        InlineCallFrame* inlineCallFrame = candidate->origin.semantic.inlineCallFrame();
                         if (inlineCallFrame && !inlineCallFrame->isVarargs()) {
                             Vector<Node*> arguments;
                             for (unsigned i = 1 + varargsData->firstVarArgOffset; i < inlineCallFrame->argumentCountIncludingThis; ++i) {
                                 StackAccessData* data = m_graph.m_stackAccessData.add(
                                     virtualRegisterForArgument(i) + inlineCallFrame->stackOffset,
