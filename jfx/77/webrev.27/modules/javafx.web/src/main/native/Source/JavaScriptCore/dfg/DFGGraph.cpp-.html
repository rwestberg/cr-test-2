<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 /*
   2  * Copyright (C) 2011-2018 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;DFGGraph.h&quot;
  28 
  29 #if ENABLE(DFG_JIT)
  30 
  31 #include &quot;BytecodeKills.h&quot;
  32 #include &quot;BytecodeLivenessAnalysisInlines.h&quot;
  33 #include &quot;CodeBlock.h&quot;
  34 #include &quot;CodeBlockWithJITType.h&quot;
  35 #include &quot;DFGBackwardsCFG.h&quot;
  36 #include &quot;DFGBackwardsDominators.h&quot;
  37 #include &quot;DFGBlockWorklist.h&quot;
  38 #include &quot;DFGCFG.h&quot;
  39 #include &quot;DFGClobberSet.h&quot;
  40 #include &quot;DFGClobbersExitState.h&quot;
  41 #include &quot;DFGControlEquivalenceAnalysis.h&quot;
  42 #include &quot;DFGDominators.h&quot;
  43 #include &quot;DFGFlowIndexing.h&quot;
  44 #include &quot;DFGFlowMap.h&quot;
  45 #include &quot;DFGJITCode.h&quot;
  46 #include &quot;DFGMayExit.h&quot;
  47 #include &quot;DFGNaturalLoops.h&quot;
  48 #include &quot;DFGVariableAccessDataDump.h&quot;
  49 #include &quot;FullBytecodeLiveness.h&quot;
  50 #include &quot;FunctionExecutableDump.h&quot;
  51 #include &quot;GetterSetter.h&quot;
  52 #include &quot;JIT.h&quot;
  53 #include &quot;JSLexicalEnvironment.h&quot;
  54 #include &quot;MaxFrameExtentForSlowPathCall.h&quot;
  55 #include &quot;OperandsInlines.h&quot;
  56 #include &quot;JSCInlines.h&quot;
  57 #include &quot;StackAlignment.h&quot;
  58 #include &lt;wtf/CommaPrinter.h&gt;
  59 #include &lt;wtf/ListDump.h&gt;
  60 
  61 namespace JSC { namespace DFG {
  62 
  63 static constexpr bool dumpOSRAvailabilityData = false;
  64 
  65 // Creates an array of stringized names.
  66 static const char* dfgOpNames[] = {
  67 #define STRINGIZE_DFG_OP_ENUM(opcode, flags) #opcode ,
  68     FOR_EACH_DFG_OP(STRINGIZE_DFG_OP_ENUM)
  69 #undef STRINGIZE_DFG_OP_ENUM
  70 };
  71 
  72 Graph::Graph(VM&amp; vm, Plan&amp; plan)
  73     : m_vm(vm)
  74     , m_plan(plan)
  75     , m_codeBlock(m_plan.codeBlock())
  76     , m_profiledBlock(m_codeBlock-&gt;alternative())
  77     , m_ssaCFG(std::make_unique&lt;SSACFG&gt;(*this))
  78     , m_nextMachineLocal(0)
  79     , m_fixpointState(BeforeFixpoint)
  80     , m_structureRegistrationState(HaveNotStartedRegistering)
  81     , m_form(LoadStore)
  82     , m_unificationState(LocallyUnified)
  83     , m_refCountState(EverythingIsLive)
  84 {
  85     ASSERT(m_profiledBlock);
  86 
  87     m_hasDebuggerEnabled = m_profiledBlock-&gt;wasCompiledWithDebuggingOpcodes() || Options::forceDebuggerBytecodeGeneration();
  88 
  89     m_indexingCache = std::make_unique&lt;FlowIndexing&gt;(*this);
  90     m_abstractValuesCache = std::make_unique&lt;FlowMap&lt;AbstractValue&gt;&gt;(*this);
  91 
  92     registerStructure(vm.structureStructure.get());
  93     this-&gt;stringStructure = registerStructure(vm.stringStructure.get());
  94     this-&gt;symbolStructure = registerStructure(vm.symbolStructure.get());
  95 }
  96 
  97 Graph::~Graph()
  98 {
  99 }
 100 
 101 const char *Graph::opName(NodeType op)
 102 {
 103     return dfgOpNames[op];
 104 }
 105 
 106 static void printWhiteSpace(PrintStream&amp; out, unsigned amount)
 107 {
 108     while (amount-- &gt; 0)
 109         out.print(&quot; &quot;);
 110 }
 111 
 112 bool Graph::dumpCodeOrigin(PrintStream&amp; out, const char* prefix, Node*&amp; previousNodeRef, Node* currentNode, DumpContext* context)
 113 {
 114     if (!currentNode-&gt;origin.semantic)
 115         return false;
 116 
 117     Node* previousNode = previousNodeRef;
 118     previousNodeRef = currentNode;
 119 
 120     if (!previousNode)
 121         return false;
 122 
 123     if (previousNode-&gt;origin.semantic.inlineCallFrame == currentNode-&gt;origin.semantic.inlineCallFrame)
 124         return false;
 125 
 126     Vector&lt;CodeOrigin&gt; previousInlineStack = previousNode-&gt;origin.semantic.inlineStack();
 127     Vector&lt;CodeOrigin&gt; currentInlineStack = currentNode-&gt;origin.semantic.inlineStack();
 128     unsigned commonSize = std::min(previousInlineStack.size(), currentInlineStack.size());
 129     unsigned indexOfDivergence = commonSize;
 130     for (unsigned i = 0; i &lt; commonSize; ++i) {
 131         if (previousInlineStack[i].inlineCallFrame != currentInlineStack[i].inlineCallFrame) {
 132             indexOfDivergence = i;
 133             break;
 134         }
 135     }
 136 
 137     bool hasPrinted = false;
 138 
 139     // Print the pops.
 140     for (unsigned i = previousInlineStack.size(); i-- &gt; indexOfDivergence;) {
 141         out.print(prefix);
 142         printWhiteSpace(out, i * 2);
 143         out.print(&quot;&lt;-- &quot;, inContext(*previousInlineStack[i].inlineCallFrame, context), &quot;\n&quot;);
 144         hasPrinted = true;
 145     }
 146 
 147     // Print the pushes.
 148     for (unsigned i = indexOfDivergence; i &lt; currentInlineStack.size(); ++i) {
 149         out.print(prefix);
 150         printWhiteSpace(out, i * 2);
 151         out.print(&quot;--&gt; &quot;, inContext(*currentInlineStack[i].inlineCallFrame, context), &quot;\n&quot;);
 152         hasPrinted = true;
 153     }
 154 
 155     return hasPrinted;
 156 }
 157 
 158 int Graph::amountOfNodeWhiteSpace(Node* node)
 159 {
 160     return (node-&gt;origin.semantic.inlineDepth() - 1) * 2;
 161 }
 162 
 163 void Graph::printNodeWhiteSpace(PrintStream&amp; out, Node* node)
 164 {
 165     printWhiteSpace(out, amountOfNodeWhiteSpace(node));
 166 }
 167 
 168 void Graph::dump(PrintStream&amp; out, const char* prefix, Node* node, DumpContext* context)
 169 {
 170     NodeType op = node-&gt;op();
 171 
 172     unsigned refCount = node-&gt;refCount();
 173     bool mustGenerate = node-&gt;mustGenerate();
 174     if (mustGenerate)
 175         --refCount;
 176 
 177     out.print(prefix);
 178     printNodeWhiteSpace(out, node);
 179 
 180     // Example/explanation of dataflow dump output
 181     //
 182     //   14:   &lt;!2:7&gt;  GetByVal(@3, @13)
 183     //   ^1     ^2 ^3     ^4       ^5
 184     //
 185     // (1) The nodeIndex of this operation.
 186     // (2) The reference count. The number printed is the &#39;real&#39; count,
 187     //     not including the &#39;mustGenerate&#39; ref. If the node is
 188     //     &#39;mustGenerate&#39; then the count it prefixed with &#39;!&#39;.
 189     // (3) The virtual register slot assigned to this node.
 190     // (4) The name of the operation.
 191     // (5) The arguments to the operation. The may be of the form:
 192     //         @#   - a NodeIndex referencing a prior node in the graph.
 193     //         arg# - an argument number.
 194     //         id#  - the index in the CodeBlock of an identifier { if codeBlock is passed to dump(), the string representation is displayed }.
 195     //         var# - the index of a var on the global object, used by GetGlobalVar/GetGlobalLexicalVariable/PutGlobalVariable operations.
 196     out.printf(&quot;% 4d:&lt;%c%u:&quot;, (int)node-&gt;index(), mustGenerate ? &#39;!&#39; : &#39; &#39;, refCount);
 197     if (node-&gt;hasResult() &amp;&amp; node-&gt;hasVirtualRegister() &amp;&amp; node-&gt;virtualRegister().isValid())
 198         out.print(node-&gt;virtualRegister());
 199     else
 200         out.print(&quot;-&quot;);
 201     out.print(&quot;&gt;\t&quot;, opName(op), &quot;(&quot;);
 202     CommaPrinter comma;
 203     if (node-&gt;flags() &amp; NodeHasVarArgs) {
 204         for (unsigned childIdx = node-&gt;firstChild(); childIdx &lt; node-&gt;firstChild() + node-&gt;numChildren(); childIdx++) {
 205             if (!m_varArgChildren[childIdx])
 206                 continue;
 207             out.print(comma, m_varArgChildren[childIdx]);
 208         }
 209     } else {
 210         if (!!node-&gt;child1() || !!node-&gt;child2() || !!node-&gt;child3())
 211             out.print(comma, node-&gt;child1());
 212         if (!!node-&gt;child2() || !!node-&gt;child3())
 213             out.print(comma, node-&gt;child2());
 214         if (!!node-&gt;child3())
 215             out.print(comma, node-&gt;child3());
 216     }
 217 
 218     if (toCString(NodeFlagsDump(node-&gt;flags())) != &quot;&lt;empty&gt;&quot;)
 219         out.print(comma, NodeFlagsDump(node-&gt;flags()));
 220     if (node-&gt;prediction())
 221         out.print(comma, SpeculationDump(node-&gt;prediction()));
 222     if (node-&gt;hasNumberOfArgumentsToSkip())
 223         out.print(comma, &quot;numberOfArgumentsToSkip = &quot;, node-&gt;numberOfArgumentsToSkip());
 224     if (node-&gt;hasArrayMode())
 225         out.print(comma, node-&gt;arrayMode());
 226     if (node-&gt;hasArithUnaryType())
 227         out.print(comma, &quot;Type:&quot;, node-&gt;arithUnaryType());
 228     if (node-&gt;hasArithMode())
 229         out.print(comma, node-&gt;arithMode());
 230     if (node-&gt;hasArithRoundingMode())
 231         out.print(comma, &quot;Rounding:&quot;, node-&gt;arithRoundingMode());
 232     if (node-&gt;hasScopeOffset())
 233         out.print(comma, node-&gt;scopeOffset());
 234     if (node-&gt;hasDirectArgumentsOffset())
 235         out.print(comma, node-&gt;capturedArgumentsOffset());
 236     if (node-&gt;hasArgumentIndex())
 237         out.print(comma, node-&gt;argumentIndex());
 238     if (node-&gt;hasRegisterPointer())
 239         out.print(comma, &quot;global&quot;, &quot;(&quot;, RawPointer(node-&gt;variablePointer()), &quot;)&quot;);
 240     if (node-&gt;hasIdentifier())
 241         out.print(comma, &quot;id&quot;, node-&gt;identifierNumber(), &quot;{&quot;, identifiers()[node-&gt;identifierNumber()], &quot;}&quot;);
 242     if (node-&gt;hasPromotedLocationDescriptor())
 243         out.print(comma, node-&gt;promotedLocationDescriptor());
 244     if (node-&gt;hasClassInfo())
 245         out.print(comma, *node-&gt;classInfo());
 246     if (node-&gt;hasStructureSet())
 247         out.print(comma, inContext(node-&gt;structureSet().toStructureSet(), context));
 248     if (node-&gt;hasStructure())
 249         out.print(comma, inContext(*node-&gt;structure().get(), context));
 250     if (node-&gt;op() == CPUIntrinsic)
 251         out.print(comma, intrinsicName(node-&gt;intrinsic()));
 252     if (node-&gt;hasTransition()) {
 253         out.print(comma, pointerDumpInContext(node-&gt;transition(), context));
 254 #if USE(JSVALUE64)
 255         out.print(&quot;, ID:&quot;, node-&gt;transition()-&gt;next-&gt;id());
 256 #else
 257         out.print(&quot;, ID:&quot;, RawPointer(node-&gt;transition()-&gt;next.get()));
 258 #endif
 259     }
 260     if (node-&gt;hasCellOperand()) {
 261         if (!node-&gt;cellOperand()-&gt;value() || !node-&gt;cellOperand()-&gt;value().isCell())
 262             out.print(comma, &quot;invalid cell operand: &quot;, node-&gt;cellOperand()-&gt;value());
 263         else {
 264             out.print(comma, pointerDump(node-&gt;cellOperand()-&gt;value().asCell()));
 265             if (node-&gt;cellOperand()-&gt;value().isCell()) {
 266                 CallVariant variant(node-&gt;cellOperand()-&gt;value().asCell());
 267                 if (ExecutableBase* executable = variant.executable()) {
 268                     if (executable-&gt;isHostFunction())
 269                         out.print(comma, &quot;&lt;host function&gt;&quot;);
 270                     else if (FunctionExecutable* functionExecutable = jsDynamicCast&lt;FunctionExecutable*&gt;(m_vm, executable))
 271                         out.print(comma, FunctionExecutableDump(functionExecutable));
 272                     else
 273                         out.print(comma, &quot;&lt;non-function executable&gt;&quot;);
 274                 }
 275             }
 276         }
 277     }
 278     if (node-&gt;hasSpeculatedTypeForQuery())
 279         out.print(comma, SpeculationDump(node-&gt;speculatedTypeForQuery()));
 280     if (node-&gt;hasStorageAccessData()) {
 281         StorageAccessData&amp; storageAccessData = node-&gt;storageAccessData();
 282         out.print(comma, &quot;id&quot;, storageAccessData.identifierNumber, &quot;{&quot;, identifiers()[storageAccessData.identifierNumber], &quot;}&quot;);
 283         out.print(&quot;, &quot;, static_cast&lt;ptrdiff_t&gt;(storageAccessData.offset));
 284     }
 285     if (node-&gt;hasMultiGetByOffsetData()) {
 286         MultiGetByOffsetData&amp; data = node-&gt;multiGetByOffsetData();
 287         out.print(comma, &quot;id&quot;, data.identifierNumber, &quot;{&quot;, identifiers()[data.identifierNumber], &quot;}&quot;);
 288         for (unsigned i = 0; i &lt; data.cases.size(); ++i)
 289             out.print(comma, inContext(data.cases[i], context));
 290     }
 291     if (node-&gt;hasMultiPutByOffsetData()) {
 292         MultiPutByOffsetData&amp; data = node-&gt;multiPutByOffsetData();
 293         out.print(comma, &quot;id&quot;, data.identifierNumber, &quot;{&quot;, identifiers()[data.identifierNumber], &quot;}&quot;);
 294         for (unsigned i = 0; i &lt; data.variants.size(); ++i)
 295             out.print(comma, inContext(data.variants[i], context));
 296     }
 297     if (node-&gt;hasMatchStructureData()) {
 298         for (MatchStructureVariant&amp; variant : node-&gt;matchStructureData().variants)
 299             out.print(comma, inContext(*variant.structure.get(), context), &quot;=&gt;&quot;, variant.result);
 300     }
 301     ASSERT(node-&gt;hasVariableAccessData(*this) == node-&gt;accessesStack(*this));
 302     if (node-&gt;hasVariableAccessData(*this)) {
 303         VariableAccessData* variableAccessData = node-&gt;tryGetVariableAccessData();
 304         if (variableAccessData) {
 305             VirtualRegister operand = variableAccessData-&gt;local();
 306             out.print(comma, variableAccessData-&gt;local(), &quot;(&quot;, VariableAccessDataDump(*this, variableAccessData), &quot;)&quot;);
 307             operand = variableAccessData-&gt;machineLocal();
 308             if (operand.isValid())
 309                 out.print(comma, &quot;machine:&quot;, operand);
 310         }
 311     }
 312     if (node-&gt;hasStackAccessData()) {
 313         StackAccessData* data = node-&gt;stackAccessData();
 314         out.print(comma, data-&gt;local);
 315         if (data-&gt;machineLocal.isValid())
 316             out.print(comma, &quot;machine:&quot;, data-&gt;machineLocal);
 317         out.print(comma, data-&gt;format);
 318     }
 319     if (node-&gt;hasUnlinkedLocal())
 320         out.print(comma, node-&gt;unlinkedLocal());
 321     if (node-&gt;hasVectorLengthHint())
 322         out.print(comma, &quot;vectorLengthHint = &quot;, node-&gt;vectorLengthHint());
 323     if (node-&gt;hasLazyJSValue())
 324         out.print(comma, node-&gt;lazyJSValue());
 325     if (node-&gt;hasIndexingType())
 326         out.print(comma, IndexingTypeDump(node-&gt;indexingMode()));
 327     if (node-&gt;hasTypedArrayType())
 328         out.print(comma, node-&gt;typedArrayType());
 329     if (node-&gt;hasPhi())
 330         out.print(comma, &quot;^&quot;, node-&gt;phi()-&gt;index());
 331     if (node-&gt;hasExecutionCounter())
 332         out.print(comma, RawPointer(node-&gt;executionCounter()));
 333     if (node-&gt;hasWatchpointSet())
 334         out.print(comma, RawPointer(node-&gt;watchpointSet()));
 335     if (node-&gt;hasStoragePointer())
 336         out.print(comma, RawPointer(node-&gt;storagePointer()));
 337     if (node-&gt;hasObjectMaterializationData())
 338         out.print(comma, node-&gt;objectMaterializationData());
 339     if (node-&gt;hasCallVarargsData())
 340         out.print(comma, &quot;firstVarArgOffset = &quot;, node-&gt;callVarargsData()-&gt;firstVarArgOffset);
 341     if (node-&gt;hasLoadVarargsData()) {
 342         LoadVarargsData* data = node-&gt;loadVarargsData();
 343         out.print(comma, &quot;start = &quot;, data-&gt;start, &quot;, count = &quot;, data-&gt;count);
 344         if (data-&gt;machineStart.isValid())
 345             out.print(&quot;, machineStart = &quot;, data-&gt;machineStart);
 346         if (data-&gt;machineCount.isValid())
 347             out.print(&quot;, machineCount = &quot;, data-&gt;machineCount);
 348         out.print(&quot;, offset = &quot;, data-&gt;offset, &quot;, mandatoryMinimum = &quot;, data-&gt;mandatoryMinimum);
 349         out.print(&quot;, limit = &quot;, data-&gt;limit);
 350     }
 351     if (node-&gt;hasCallDOMGetterData()) {
 352         CallDOMGetterData* data = node-&gt;callDOMGetterData();
 353         out.print(comma, &quot;id&quot;, data-&gt;identifierNumber, &quot;{&quot;, identifiers()[data-&gt;identifierNumber], &quot;}&quot;);
 354         out.print(&quot;, domJIT = &quot;, RawPointer(data-&gt;domJIT));
 355     }
 356     if (node-&gt;hasIgnoreLastIndexIsWritable())
 357         out.print(comma, &quot;ignoreLastIndexIsWritable = &quot;, node-&gt;ignoreLastIndexIsWritable());
 358     if (node-&gt;isConstant())
 359         out.print(comma, pointerDumpInContext(node-&gt;constant(), context));
 360     if (node-&gt;hasCallLinkStatus())
 361         out.print(comma, *node-&gt;callLinkStatus());
 362     if (node-&gt;hasGetByIdStatus())
 363         out.print(comma, *node-&gt;getByIdStatus());
 364     if (node-&gt;hasInByIdStatus())
 365         out.print(comma, *node-&gt;inByIdStatus());
 366     if (node-&gt;hasPutByIdStatus())
 367         out.print(comma, *node-&gt;putByIdStatus());
 368     if (node-&gt;isJump())
 369         out.print(comma, &quot;T:&quot;, *node-&gt;targetBlock());
 370     if (node-&gt;isBranch())
 371         out.print(comma, &quot;T:&quot;, node-&gt;branchData()-&gt;taken, &quot;, F:&quot;, node-&gt;branchData()-&gt;notTaken);
 372     if (node-&gt;isSwitch()) {
 373         SwitchData* data = node-&gt;switchData();
 374         out.print(comma, data-&gt;kind);
 375         for (unsigned i = 0; i &lt; data-&gt;cases.size(); ++i)
 376             out.print(comma, inContext(data-&gt;cases[i].value, context), &quot;:&quot;, data-&gt;cases[i].target);
 377         out.print(comma, &quot;default:&quot;, data-&gt;fallThrough);
 378     }
 379     if (node-&gt;isEntrySwitch()) {
 380         EntrySwitchData* data = node-&gt;entrySwitchData();
 381         for (unsigned i = 0; i &lt; data-&gt;cases.size(); ++i)
 382             out.print(comma, BranchTarget(data-&gt;cases[i]));
 383     }
 384     ClobberSet reads;
 385     ClobberSet writes;
 386     addReadsAndWrites(*this, node, reads, writes);
 387     if (!reads.isEmpty())
 388         out.print(comma, &quot;R:&quot;, sortedListDump(reads.direct(), &quot;,&quot;));
 389     if (!writes.isEmpty())
 390         out.print(comma, &quot;W:&quot;, sortedListDump(writes.direct(), &quot;,&quot;));
 391     ExitMode exitMode = mayExit(*this, node);
 392     if (exitMode != DoesNotExit)
 393         out.print(comma, exitMode);
 394     if (clobbersExitState(*this, node))
 395         out.print(comma, &quot;ClobbersExit&quot;);
 396     if (node-&gt;origin.isSet()) {
 397         out.print(comma, &quot;bc#&quot;, node-&gt;origin.semantic.bytecodeIndex);
 398         if (node-&gt;origin.semantic != node-&gt;origin.forExit &amp;&amp; node-&gt;origin.forExit.isSet())
 399             out.print(comma, &quot;exit: &quot;, node-&gt;origin.forExit);
 400     }
 401     out.print(comma, node-&gt;origin.exitOK ? &quot;ExitValid&quot; : &quot;ExitInvalid&quot;);
 402     if (node-&gt;origin.wasHoisted)
 403         out.print(comma, &quot;WasHoisted&quot;);
 404     out.print(&quot;)&quot;);
 405 
 406     if (node-&gt;accessesStack(*this) &amp;&amp; node-&gt;tryGetVariableAccessData())
 407         out.print(&quot;  predicting &quot;, SpeculationDump(node-&gt;tryGetVariableAccessData()-&gt;prediction()));
 408     else if (node-&gt;hasHeapPrediction())
 409         out.print(&quot;  predicting &quot;, SpeculationDump(node-&gt;getHeapPrediction()));
 410 
 411     out.print(&quot;\n&quot;);
 412 }
 413 
 414 bool Graph::terminalsAreValid()
 415 {
 416     for (BasicBlock* block : blocksInNaturalOrder()) {
 417         if (!block-&gt;terminal())
 418             return false;
 419     }
 420     return true;
 421 }
 422 
 423 static BasicBlock* unboxLoopNode(const CPSCFG::Node&amp; node) { return node.node(); }
 424 static BasicBlock* unboxLoopNode(BasicBlock* block) { return block; }
 425 
 426 void Graph::dumpBlockHeader(PrintStream&amp; out, const char* prefix, BasicBlock* block, PhiNodeDumpMode phiNodeDumpMode, DumpContext* context)
 427 {
 428     out.print(prefix, &quot;Block &quot;, *block, &quot; (&quot;, inContext(block-&gt;at(0)-&gt;origin.semantic, context), &quot;):&quot;,
 429         block-&gt;isReachable ? &quot;&quot; : &quot; (skipped)&quot;, block-&gt;isOSRTarget ? &quot; (OSR target)&quot; : &quot;&quot;, block-&gt;isCatchEntrypoint ? &quot; (Catch Entrypoint)&quot; : &quot;&quot;, &quot;\n&quot;);
 430     if (block-&gt;executionCount == block-&gt;executionCount)
 431         out.print(prefix, &quot;  Execution count: &quot;, block-&gt;executionCount, &quot;\n&quot;);
 432     out.print(prefix, &quot;  Predecessors:&quot;);
 433     for (size_t i = 0; i &lt; block-&gt;predecessors.size(); ++i)
 434         out.print(&quot; &quot;, *block-&gt;predecessors[i]);
 435     out.print(&quot;\n&quot;);
 436     out.print(prefix, &quot;  Successors:&quot;);
 437     if (block-&gt;terminal()) {
 438         for (BasicBlock* successor : block-&gt;successors()) {
 439             out.print(&quot; &quot;, *successor);
 440         }
 441     } else
 442         out.print(&quot; &lt;invalid&gt;&quot;);
 443     out.print(&quot;\n&quot;);
 444 
 445     auto printDominators = [&amp;] (auto&amp; dominators) {
 446         out.print(prefix, &quot;  Dominated by: &quot;, dominators.dominatorsOf(block), &quot;\n&quot;);
 447         out.print(prefix, &quot;  Dominates: &quot;, dominators.blocksDominatedBy(block), &quot;\n&quot;);
 448         out.print(prefix, &quot;  Dominance Frontier: &quot;, dominators.dominanceFrontierOf(block), &quot;\n&quot;);
 449         out.print(prefix, &quot;  Iterated Dominance Frontier: &quot;,
 450             dominators.iteratedDominanceFrontierOf(typename std::remove_reference&lt;decltype(dominators)&gt;::type::List { block }), &quot;\n&quot;);
 451     };
 452 
 453     if (terminalsAreValid()) {
 454         if (m_ssaDominators)
 455             printDominators(*m_ssaDominators);
 456         else if (m_cpsDominators)
 457             printDominators(*m_cpsDominators);
 458     }
 459 
 460     if (m_backwardsDominators &amp;&amp; terminalsAreValid()) {
 461         out.print(prefix, &quot;  Backwards dominates by: &quot;, m_backwardsDominators-&gt;dominatorsOf(block), &quot;\n&quot;);
 462         out.print(prefix, &quot;  Backwards dominates: &quot;, m_backwardsDominators-&gt;blocksDominatedBy(block), &quot;\n&quot;);
 463     }
 464     if (m_controlEquivalenceAnalysis &amp;&amp; terminalsAreValid()) {
 465         out.print(prefix, &quot;  Control equivalent to:&quot;);
 466         for (BasicBlock* otherBlock : blocksInNaturalOrder()) {
 467             if (m_controlEquivalenceAnalysis-&gt;areEquivalent(block, otherBlock))
 468                 out.print(&quot; &quot;, *otherBlock);
 469         }
 470         out.print(&quot;\n&quot;);
 471     }
 472 
 473     auto printNaturalLoops = [&amp;] (auto&amp; naturalLoops) {
 474         if (const auto* loop = naturalLoops-&gt;headerOf(block)) {
 475             out.print(prefix, &quot;  Loop header, contains:&quot;);
 476             Vector&lt;BlockIndex&gt; sortedBlockList;
 477             for (unsigned i = 0; i &lt; loop-&gt;size(); ++i)
 478                 sortedBlockList.append(unboxLoopNode(loop-&gt;at(i))-&gt;index);
 479             std::sort(sortedBlockList.begin(), sortedBlockList.end());
 480             for (unsigned i = 0; i &lt; sortedBlockList.size(); ++i)
 481                 out.print(&quot; #&quot;, sortedBlockList[i]);
 482             out.print(&quot;\n&quot;);
 483         }
 484 
 485         auto containingLoops = naturalLoops-&gt;loopsOf(block);
 486         if (!containingLoops.isEmpty()) {
 487             out.print(prefix, &quot;  Containing loop headers:&quot;);
 488             for (unsigned i = 0; i &lt; containingLoops.size(); ++i)
 489                 out.print(&quot; &quot;, *unboxLoopNode(containingLoops[i]-&gt;header()));
 490             out.print(&quot;\n&quot;);
 491         }
 492     };
 493 
 494     if (m_ssaNaturalLoops)
 495         printNaturalLoops(m_ssaNaturalLoops);
 496     else if (m_cpsNaturalLoops)
 497         printNaturalLoops(m_cpsNaturalLoops);
 498 
 499     if (!block-&gt;phis.isEmpty()) {
 500         out.print(prefix, &quot;  Phi Nodes:&quot;);
 501         for (size_t i = 0; i &lt; block-&gt;phis.size(); ++i) {
 502             Node* phiNode = block-&gt;phis[i];
 503             if (!phiNode-&gt;shouldGenerate() &amp;&amp; phiNodeDumpMode == DumpLivePhisOnly)
 504                 continue;
 505             out.print(&quot; @&quot;, phiNode-&gt;index(), &quot;&lt;&quot;, phiNode-&gt;local(), &quot;,&quot;, phiNode-&gt;refCount(), &quot;&gt;-&gt;(&quot;);
 506             if (phiNode-&gt;child1()) {
 507                 out.print(&quot;@&quot;, phiNode-&gt;child1()-&gt;index());
 508                 if (phiNode-&gt;child2()) {
 509                     out.print(&quot;, @&quot;, phiNode-&gt;child2()-&gt;index());
 510                     if (phiNode-&gt;child3())
 511                         out.print(&quot;, @&quot;, phiNode-&gt;child3()-&gt;index());
 512                 }
 513             }
 514             out.print(&quot;)&quot;, i + 1 &lt; block-&gt;phis.size() ? &quot;,&quot; : &quot;&quot;);
 515         }
 516         out.print(&quot;\n&quot;);
 517     }
 518 }
 519 
 520 void Graph::dump(PrintStream&amp; out, DumpContext* context)
 521 {
 522     DumpContext myContext;
 523     myContext.graph = this;
 524     if (!context)
 525         context = &amp;myContext;
 526 
 527     out.print(&quot;\n&quot;);
 528     out.print(&quot;DFG for &quot;, CodeBlockWithJITType(m_codeBlock, JITCode::DFGJIT), &quot;:\n&quot;);
 529     out.print(&quot;  Fixpoint state: &quot;, m_fixpointState, &quot;; Form: &quot;, m_form, &quot;; Unification state: &quot;, m_unificationState, &quot;; Ref count state: &quot;, m_refCountState, &quot;\n&quot;);
 530     if (m_form == SSA) {
 531         for (unsigned entrypointIndex = 0; entrypointIndex &lt; m_argumentFormats.size(); ++entrypointIndex)
 532             out.print(&quot;  Argument formats for entrypoint index: &quot;, entrypointIndex, &quot; : &quot;, listDump(m_argumentFormats[entrypointIndex]), &quot;\n&quot;);
 533     }
 534     else {
 535         for (auto pair : m_rootToArguments)
 536             out.print(&quot;  Arguments for block#&quot;, pair.key-&gt;index, &quot;: &quot;, listDump(pair.value), &quot;\n&quot;);
 537     }
 538     out.print(&quot;\n&quot;);
 539 
 540     Node* lastNode = nullptr;
 541     for (size_t b = 0; b &lt; m_blocks.size(); ++b) {
 542         BasicBlock* block = m_blocks[b].get();
 543         if (!block)
 544             continue;
 545         dumpBlockHeader(out, &quot;&quot;, block, DumpAllPhis, context);
 546         out.print(&quot;  States: &quot;, block-&gt;cfaStructureClobberStateAtHead);
 547         if (!block-&gt;cfaHasVisited)
 548             out.print(&quot;, CurrentlyCFAUnreachable&quot;);
 549         if (!block-&gt;intersectionOfCFAHasVisited)
 550             out.print(&quot;, CFAUnreachable&quot;);
 551         out.print(&quot;\n&quot;);
 552         switch (m_form) {
 553         case LoadStore:
 554         case ThreadedCPS: {
 555             out.print(&quot;  Vars Before: &quot;);
 556             if (block-&gt;cfaHasVisited)
 557                 out.print(inContext(block-&gt;valuesAtHead, context));
 558             else
 559                 out.print(&quot;&lt;empty&gt;&quot;);
 560             out.print(&quot;\n&quot;);
 561             out.print(&quot;  Intersected Vars Before: &quot;);
 562             if (block-&gt;intersectionOfCFAHasVisited)
 563                 out.print(inContext(block-&gt;intersectionOfPastValuesAtHead, context));
 564             else
 565                 out.print(&quot;&lt;empty&gt;&quot;);
 566             out.print(&quot;\n&quot;);
 567             out.print(&quot;  Var Links: &quot;, block-&gt;variablesAtHead, &quot;\n&quot;);
 568             break;
 569         }
 570 
 571         case SSA: {
 572             RELEASE_ASSERT(block-&gt;ssa);
 573             if (dumpOSRAvailabilityData)
 574                 out.print(&quot;  Availability: &quot;, block-&gt;ssa-&gt;availabilityAtHead, &quot;\n&quot;);
 575             out.print(&quot;  Live: &quot;, nodeListDump(block-&gt;ssa-&gt;liveAtHead), &quot;\n&quot;);
 576             out.print(&quot;  Values: &quot;, nodeValuePairListDump(block-&gt;ssa-&gt;valuesAtHead, context), &quot;\n&quot;);
 577             break;
 578         } }
 579         for (size_t i = 0; i &lt; block-&gt;size(); ++i) {
 580             dumpCodeOrigin(out, &quot;&quot;, lastNode, block-&gt;at(i), context);
 581             dump(out, &quot;&quot;, block-&gt;at(i), context);
 582         }
 583         out.print(&quot;  States: &quot;, block-&gt;cfaBranchDirection, &quot;, &quot;, block-&gt;cfaStructureClobberStateAtTail);
 584         if (!block-&gt;cfaDidFinish)
 585             out.print(&quot;, CFAInvalidated&quot;);
 586         out.print(&quot;\n&quot;);
 587         switch (m_form) {
 588         case LoadStore:
 589         case ThreadedCPS: {
 590             out.print(&quot;  Vars After: &quot;);
 591             if (block-&gt;cfaHasVisited)
 592                 out.print(inContext(block-&gt;valuesAtTail, context));
 593             else
 594                 out.print(&quot;&lt;empty&gt;&quot;);
 595             out.print(&quot;\n&quot;);
 596             out.print(&quot;  Var Links: &quot;, block-&gt;variablesAtTail, &quot;\n&quot;);
 597             break;
 598         }
 599 
 600         case SSA: {
 601             RELEASE_ASSERT(block-&gt;ssa);
 602             if (dumpOSRAvailabilityData)
 603                 out.print(&quot;  Availability: &quot;, block-&gt;ssa-&gt;availabilityAtTail, &quot;\n&quot;);
 604             out.print(&quot;  Live: &quot;, nodeListDump(block-&gt;ssa-&gt;liveAtTail), &quot;\n&quot;);
 605             out.print(&quot;  Values: &quot;, nodeValuePairListDump(block-&gt;ssa-&gt;valuesAtTail, context), &quot;\n&quot;);
 606             break;
 607         } }
 608         out.print(&quot;\n&quot;);
 609     }
 610 
 611     out.print(&quot;GC Values:\n&quot;);
 612     for (FrozenValue* value : m_frozenValues) {
 613         if (value-&gt;pointsToHeap())
 614             out.print(&quot;    &quot;, inContext(*value, &amp;myContext), &quot;\n&quot;);
 615     }
 616 
 617     out.print(inContext(watchpoints(), &amp;myContext));
 618 
 619     if (!myContext.isEmpty()) {
 620         myContext.dump(out);
 621         out.print(&quot;\n&quot;);
 622     }
 623 }
 624 
 625 void Graph::deleteNode(Node* node)
 626 {
 627     if (validationEnabled() &amp;&amp; m_form == SSA) {
 628         for (BasicBlock* block : blocksInNaturalOrder()) {
 629             DFG_ASSERT(*this, node, !block-&gt;ssa-&gt;liveAtHead.contains(node));
 630             DFG_ASSERT(*this, node, !block-&gt;ssa-&gt;liveAtTail.contains(node));
 631         }
 632     }
 633 
 634     m_nodes.remove(node);
 635 }
 636 
 637 void Graph::packNodeIndices()
 638 {
 639     m_nodes.packIndices();
 640 }
 641 
 642 void Graph::dethread()
 643 {
 644     if (m_form == LoadStore || m_form == SSA)
 645         return;
 646 
 647     if (logCompilationChanges())
 648         dataLog(&quot;Dethreading DFG graph.\n&quot;);
 649 
 650     for (BlockIndex blockIndex = m_blocks.size(); blockIndex--;) {
 651         BasicBlock* block = m_blocks[blockIndex].get();
 652         if (!block)
 653             continue;
 654         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;) {
 655             Node* phi = block-&gt;phis[phiIndex];
 656             phi-&gt;children.reset();
 657         }
 658     }
 659 
 660     m_form = LoadStore;
 661 }
 662 
 663 void Graph::handleSuccessor(Vector&lt;BasicBlock*, 16&gt;&amp; worklist, BasicBlock* block, BasicBlock* successor)
 664 {
 665     if (!successor-&gt;isReachable) {
 666         successor-&gt;isReachable = true;
 667         worklist.append(successor);
 668     }
 669 
 670     if (!successor-&gt;predecessors.contains(block))
 671         successor-&gt;predecessors.append(block);
 672 }
 673 
 674 void Graph::determineReachability()
 675 {
 676     Vector&lt;BasicBlock*, 16&gt; worklist;
 677     for (BasicBlock* entrypoint : m_roots) {
 678         entrypoint-&gt;isReachable = true;
 679         worklist.append(entrypoint);
 680     }
 681     while (!worklist.isEmpty()) {
 682         BasicBlock* block = worklist.takeLast();
 683         for (unsigned i = block-&gt;numSuccessors(); i--;)
 684             handleSuccessor(worklist, block, block-&gt;successor(i));
 685     }
 686 }
 687 
 688 void Graph::resetReachability()
 689 {
 690     for (BlockIndex blockIndex = m_blocks.size(); blockIndex--;) {
 691         BasicBlock* block = m_blocks[blockIndex].get();
 692         if (!block)
 693             continue;
 694         block-&gt;isReachable = false;
 695         block-&gt;predecessors.clear();
 696     }
 697 
 698     determineReachability();
 699 }
 700 
 701 namespace {
 702 
 703 class RefCountCalculator {
 704 public:
 705     RefCountCalculator(Graph&amp; graph)
 706         : m_graph(graph)
 707     {
 708     }
 709 
 710     void calculate()
 711     {
 712         // First reset the counts to 0 for all nodes.
 713         for (BlockIndex blockIndex = 0; blockIndex &lt; m_graph.numBlocks(); ++blockIndex) {
 714             BasicBlock* block = m_graph.block(blockIndex);
 715             if (!block)
 716                 continue;
 717             for (unsigned indexInBlock = block-&gt;size(); indexInBlock--;)
 718                 block-&gt;at(indexInBlock)-&gt;setRefCount(0);
 719             for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
 720                 block-&gt;phis[phiIndex]-&gt;setRefCount(0);
 721         }
 722 
 723         // Now find the roots:
 724         // - Nodes that are must-generate.
 725         // - Nodes that are reachable from type checks.
 726         // Set their ref counts to 1 and put them on the worklist.
 727         for (BlockIndex blockIndex = 0; blockIndex &lt; m_graph.numBlocks(); ++blockIndex) {
 728             BasicBlock* block = m_graph.block(blockIndex);
 729             if (!block)
 730                 continue;
 731             for (unsigned indexInBlock = block-&gt;size(); indexInBlock--;) {
 732                 Node* node = block-&gt;at(indexInBlock);
 733                 DFG_NODE_DO_TO_CHILDREN(m_graph, node, findTypeCheckRoot);
 734                 if (!(node-&gt;flags() &amp; NodeMustGenerate))
 735                     continue;
 736                 if (!node-&gt;postfixRef())
 737                     m_worklist.append(node);
 738             }
 739         }
 740 
 741         while (!m_worklist.isEmpty()) {
 742             while (!m_worklist.isEmpty()) {
 743                 Node* node = m_worklist.last();
 744                 m_worklist.removeLast();
 745                 ASSERT(node-&gt;shouldGenerate()); // It should not be on the worklist unless it&#39;s ref&#39;ed.
 746                 DFG_NODE_DO_TO_CHILDREN(m_graph, node, countEdge);
 747             }
 748 
 749             if (m_graph.m_form == SSA) {
 750                 // Find Phi-&gt;Upsilon edges, which are represented as meta-data in the
 751                 // Upsilon.
 752                 for (BlockIndex blockIndex = m_graph.numBlocks(); blockIndex--;) {
 753                     BasicBlock* block = m_graph.block(blockIndex);
 754                     if (!block)
 755                         continue;
 756                     for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;) {
 757                         Node* node = block-&gt;at(nodeIndex);
 758                         if (node-&gt;op() != Upsilon)
 759                             continue;
 760                         if (node-&gt;shouldGenerate())
 761                             continue;
 762                         if (node-&gt;phi()-&gt;shouldGenerate())
 763                             countNode(node);
 764                     }
 765                 }
 766             }
 767         }
 768     }
 769 
 770 private:
 771     void findTypeCheckRoot(Node*, Edge edge)
 772     {
 773         // We may have an &quot;unproved&quot; untyped use for code that is unreachable. The CFA
 774         // will just not have gotten around to it.
 775         if (edge.isProved() || edge.willNotHaveCheck())
 776             return;
 777         if (!edge-&gt;postfixRef())
 778             m_worklist.append(edge.node());
 779     }
 780 
 781     void countNode(Node* node)
 782     {
 783         if (node-&gt;postfixRef())
 784             return;
 785         m_worklist.append(node);
 786     }
 787 
 788     void countEdge(Node*, Edge edge)
 789     {
 790         // Don&#39;t count edges that are already counted for their type checks.
 791         if (!(edge.isProved() || edge.willNotHaveCheck()))
 792             return;
 793         countNode(edge.node());
 794     }
 795 
 796     Graph&amp; m_graph;
 797     Vector&lt;Node*, 128&gt; m_worklist;
 798 };
 799 
 800 } // anonymous namespace
 801 
 802 void Graph::computeRefCounts()
 803 {
 804     RefCountCalculator calculator(*this);
 805     calculator.calculate();
 806 }
 807 
 808 void Graph::killBlockAndItsContents(BasicBlock* block)
 809 {
 810     if (auto&amp; ssaData = block-&gt;ssa)
 811         ssaData-&gt;invalidate();
 812     for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
 813         deleteNode(block-&gt;phis[phiIndex]);
 814     for (Node* node : *block)
 815         deleteNode(node);
 816 
 817     killBlock(block);
 818 }
 819 
 820 void Graph::killUnreachableBlocks()
 821 {
 822     invalidateNodeLiveness();
 823 
 824     for (BlockIndex blockIndex = 0; blockIndex &lt; numBlocks(); ++blockIndex) {
 825         BasicBlock* block = this-&gt;block(blockIndex);
 826         if (!block)
 827             continue;
 828         if (block-&gt;isReachable)
 829             continue;
 830 
 831         dataLogIf(Options::verboseDFGBytecodeParsing(), &quot;Basic block #&quot;, blockIndex, &quot; was killed because it was unreachable\n&quot;);
 832         killBlockAndItsContents(block);
 833     }
 834 }
 835 
 836 void Graph::invalidateCFG()
 837 {
 838     m_cpsDominators = nullptr;
 839     m_ssaDominators = nullptr;
 840     m_cpsNaturalLoops = nullptr;
 841     m_ssaNaturalLoops = nullptr;
 842     m_controlEquivalenceAnalysis = nullptr;
 843     m_backwardsDominators = nullptr;
 844     m_backwardsCFG = nullptr;
 845     m_cpsCFG = nullptr;
 846 }
 847 
 848 void Graph::invalidateNodeLiveness()
 849 {
 850     if (m_form != SSA)
 851         return;
 852 
 853     for (BasicBlock* block : blocksInNaturalOrder())
 854         block-&gt;ssa-&gt;invalidate();
 855 }
 856 
 857 void Graph::substituteGetLocal(BasicBlock&amp; block, unsigned startIndexInBlock, VariableAccessData* variableAccessData, Node* newGetLocal)
 858 {
 859     for (unsigned indexInBlock = startIndexInBlock; indexInBlock &lt; block.size(); ++indexInBlock) {
 860         Node* node = block[indexInBlock];
 861         bool shouldContinue = true;
 862         switch (node-&gt;op()) {
 863         case SetLocal: {
 864             if (node-&gt;local() == variableAccessData-&gt;local())
 865                 shouldContinue = false;
 866             break;
 867         }
 868 
 869         case GetLocal: {
 870             if (node-&gt;variableAccessData() != variableAccessData)
 871                 continue;
 872             substitute(block, indexInBlock, node, newGetLocal);
 873             Node* oldTailNode = block.variablesAtTail.operand(variableAccessData-&gt;local());
 874             if (oldTailNode == node)
 875                 block.variablesAtTail.operand(variableAccessData-&gt;local()) = newGetLocal;
 876             shouldContinue = false;
 877             break;
 878         }
 879 
 880         default:
 881             break;
 882         }
 883         if (!shouldContinue)
 884             break;
 885     }
 886 }
 887 
 888 BlockList Graph::blocksInPreOrder()
 889 {
 890     BlockList result;
 891     BlockWorklist worklist;
 892     for (BasicBlock* entrypoint : m_roots)
 893         worklist.push(entrypoint);
 894     while (BasicBlock* block = worklist.pop()) {
 895         result.append(block);
 896         for (unsigned i = block-&gt;numSuccessors(); i--;)
 897             worklist.push(block-&gt;successor(i));
 898     }
 899 
 900     if (validationEnabled()) {
 901         // When iterating over pre order, we should see dominators
 902         // before things they dominate.
 903         auto validateResults = [&amp;] (auto&amp; dominators) {
 904             for (unsigned i = 0; i &lt; result.size(); ++i) {
 905                 BasicBlock* a = result[i];
 906                 if (!a)
 907                     continue;
 908                 for (unsigned j = 0; j &lt; result.size(); ++j) {
 909                     BasicBlock* b = result[j];
 910                     if (!b || a == b)
 911                         continue;
 912                     if (dominators.dominates(a, b))
 913                         RELEASE_ASSERT(i &lt; j);
 914                 }
 915             }
 916         };
 917 
 918         if (m_form == SSA || m_isInSSAConversion)
 919             validateResults(ensureSSADominators());
 920         else
 921             validateResults(ensureCPSDominators());
 922     }
 923     return result;
 924 }
 925 
 926 BlockList Graph::blocksInPostOrder(bool isSafeToValidate)
 927 {
 928     BlockList result;
 929     PostOrderBlockWorklist worklist;
 930     for (BasicBlock* entrypoint : m_roots)
 931         worklist.push(entrypoint);
 932     while (BlockWithOrder item = worklist.pop()) {
 933         switch (item.order) {
 934         case VisitOrder::Pre:
 935             worklist.pushPost(item.node);
 936             for (unsigned i = item.node-&gt;numSuccessors(); i--;)
 937                 worklist.push(item.node-&gt;successor(i));
 938             break;
 939         case VisitOrder::Post:
 940             result.append(item.node);
 941             break;
 942         }
 943     }
 944 
 945     if (isSafeToValidate &amp;&amp; validationEnabled()) { // There are users of this where we haven&#39;t yet built of the CFG enough to be able to run dominators.
 946         auto validateResults = [&amp;] (auto&amp; dominators) {
 947             // When iterating over reverse post order, we should see dominators
 948             // before things they dominate.
 949             for (unsigned i = 0; i &lt; result.size(); ++i) {
 950                 BasicBlock* a = result[i];
 951                 if (!a)
 952                     continue;
 953                 for (unsigned j = 0; j &lt; result.size(); ++j) {
 954                     BasicBlock* b = result[j];
 955                     if (!b || a == b)
 956                         continue;
 957                     if (dominators.dominates(a, b))
 958                         RELEASE_ASSERT(i &gt; j);
 959                 }
 960             }
 961         };
 962 
 963         if (m_form == SSA || m_isInSSAConversion)
 964             validateResults(ensureSSADominators());
 965         else
 966             validateResults(ensureCPSDominators());
 967     }
 968 
 969     return result;
 970 }
 971 
 972 void Graph::clearReplacements()
 973 {
 974     for (BlockIndex blockIndex = numBlocks(); blockIndex--;) {
 975         BasicBlock* block = m_blocks[blockIndex].get();
 976         if (!block)
 977             continue;
 978         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
 979             block-&gt;phis[phiIndex]-&gt;setReplacement(nullptr);
 980         for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;)
 981             block-&gt;at(nodeIndex)-&gt;setReplacement(nullptr);
 982     }
 983 }
 984 
 985 void Graph::clearEpochs()
 986 {
 987     for (BlockIndex blockIndex = numBlocks(); blockIndex--;) {
 988         BasicBlock* block = m_blocks[blockIndex].get();
 989         if (!block)
 990             continue;
 991         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
 992             block-&gt;phis[phiIndex]-&gt;setEpoch(Epoch());
 993         for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;)
 994             block-&gt;at(nodeIndex)-&gt;setEpoch(Epoch());
 995     }
 996 }
 997 
 998 void Graph::initializeNodeOwners()
 999 {
1000     for (BlockIndex blockIndex = numBlocks(); blockIndex--;) {
1001         BasicBlock* block = m_blocks[blockIndex].get();
1002         if (!block)
1003             continue;
1004         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
1005             block-&gt;phis[phiIndex]-&gt;owner = block;
1006         for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;)
1007             block-&gt;at(nodeIndex)-&gt;owner = block;
1008     }
1009 }
1010 
1011 void Graph::clearFlagsOnAllNodes(NodeFlags flags)
1012 {
1013     for (BlockIndex blockIndex = numBlocks(); blockIndex--;) {
1014         BasicBlock* block = m_blocks[blockIndex].get();
1015         if (!block)
1016             continue;
1017         for (unsigned phiIndex = block-&gt;phis.size(); phiIndex--;)
1018             block-&gt;phis[phiIndex]-&gt;clearFlags(flags);
1019         for (unsigned nodeIndex = block-&gt;size(); nodeIndex--;)
1020             block-&gt;at(nodeIndex)-&gt;clearFlags(flags);
1021     }
1022 }
1023 
1024 bool Graph::watchCondition(const ObjectPropertyCondition&amp; key)
1025 {
1026     if (!key.isWatchable())
1027         return false;
1028 
1029     DesiredWeakReferences&amp; weakReferences = m_plan.weakReferences();
1030     weakReferences.addLazily(key.object());
1031     if (key.hasPrototype())
1032         weakReferences.addLazily(key.prototype());
1033     if (key.hasRequiredValue())
1034         weakReferences.addLazily(key.requiredValue());
1035 
1036     m_plan.watchpoints().addLazily(key);
1037 
1038     if (key.kind() == PropertyCondition::Presence)
1039         m_safeToLoad.add(std::make_pair(key.object(), key.offset()));
1040 
1041     return true;
1042 }
1043 
1044 bool Graph::watchConditions(const ObjectPropertyConditionSet&amp; keys)
1045 {
1046     if (!keys.isValid())
1047         return false;
1048 
1049     for (const ObjectPropertyCondition&amp; key : keys) {
1050         if (!watchCondition(key))
1051             return false;
1052     }
1053     return true;
1054 }
1055 
1056 bool Graph::isSafeToLoad(JSObject* base, PropertyOffset offset)
1057 {
1058     return m_safeToLoad.contains(std::make_pair(base, offset));
1059 }
1060 
1061 bool Graph::watchGlobalProperty(JSGlobalObject* globalObject, unsigned identifierNumber)
1062 {
1063     UniquedStringImpl* uid = identifiers()[identifierNumber];
1064     // If we already have a WatchpointSet, and it is already invalidated, it means that this scope operation must be changed from GlobalProperty to GlobalLexicalVar,
1065     // but we still have stale metadata here since we have not yet executed this bytecode operation since the invalidation. Just emitting ForceOSRExit to update the
1066     // metadata when it reaches to this code.
1067     if (auto* watchpoint = globalObject-&gt;getReferencedPropertyWatchpointSet(uid)) {
1068         if (!watchpoint-&gt;isStillValid())
1069             return false;
1070     }
1071     globalProperties().addLazily(DesiredGlobalProperty(globalObject, identifierNumber));
1072     return true;
1073 }
1074 
1075 FullBytecodeLiveness&amp; Graph::livenessFor(CodeBlock* codeBlock)
1076 {
1077     HashMap&lt;CodeBlock*, std::unique_ptr&lt;FullBytecodeLiveness&gt;&gt;::iterator iter = m_bytecodeLiveness.find(codeBlock);
1078     if (iter != m_bytecodeLiveness.end())
1079         return *iter-&gt;value;
1080 
1081     std::unique_ptr&lt;FullBytecodeLiveness&gt; liveness = std::make_unique&lt;FullBytecodeLiveness&gt;();
1082     codeBlock-&gt;livenessAnalysis().computeFullLiveness(codeBlock, *liveness);
1083     FullBytecodeLiveness&amp; result = *liveness;
1084     m_bytecodeLiveness.add(codeBlock, WTFMove(liveness));
1085     return result;
1086 }
1087 
1088 FullBytecodeLiveness&amp; Graph::livenessFor(InlineCallFrame* inlineCallFrame)
1089 {
1090     return livenessFor(baselineCodeBlockFor(inlineCallFrame));
1091 }
1092 
1093 BytecodeKills&amp; Graph::killsFor(CodeBlock* codeBlock)
1094 {
1095     HashMap&lt;CodeBlock*, std::unique_ptr&lt;BytecodeKills&gt;&gt;::iterator iter = m_bytecodeKills.find(codeBlock);
1096     if (iter != m_bytecodeKills.end())
1097         return *iter-&gt;value;
1098 
1099     std::unique_ptr&lt;BytecodeKills&gt; kills = std::make_unique&lt;BytecodeKills&gt;();
1100     codeBlock-&gt;livenessAnalysis().computeKills(codeBlock, *kills);
1101     BytecodeKills&amp; result = *kills;
1102     m_bytecodeKills.add(codeBlock, WTFMove(kills));
1103     return result;
1104 }
1105 
1106 BytecodeKills&amp; Graph::killsFor(InlineCallFrame* inlineCallFrame)
1107 {
1108     return killsFor(baselineCodeBlockFor(inlineCallFrame));
1109 }
1110 
1111 bool Graph::isLiveInBytecode(VirtualRegister operand, CodeOrigin codeOrigin)
1112 {
1113     static const bool verbose = false;
1114 
1115     if (verbose)
1116         dataLog(&quot;Checking of operand is live: &quot;, operand, &quot;\n&quot;);
1117     CodeOrigin* codeOriginPtr = &amp;codeOrigin;
1118     for (;;) {
1119         VirtualRegister reg = VirtualRegister(
1120             operand.offset() - codeOriginPtr-&gt;stackOffset());
1121 
1122         if (verbose)
1123             dataLog(&quot;reg = &quot;, reg, &quot;\n&quot;);
1124 
1125         if (operand.offset() &lt; codeOriginPtr-&gt;stackOffset() + CallFrame::headerSizeInRegisters) {
1126             if (reg.isArgument()) {
1127                 RELEASE_ASSERT(reg.offset() &lt; CallFrame::headerSizeInRegisters);
1128 
1129                 if (codeOriginPtr-&gt;inlineCallFrame-&gt;isClosureCall
1130                     &amp;&amp; reg.offset() == CallFrameSlot::callee) {
1131                     if (verbose)
1132                         dataLog(&quot;Looks like a callee.\n&quot;);
1133                     return true;
1134                 }
1135 
1136                 if (codeOriginPtr-&gt;inlineCallFrame-&gt;isVarargs()
1137                     &amp;&amp; reg.offset() == CallFrameSlot::argumentCount) {
1138                     if (verbose)
1139                         dataLog(&quot;Looks like the argument count.\n&quot;);
1140                     return true;
1141                 }
1142 
1143                 return false;
1144             }
1145 
1146             if (verbose)
1147                 dataLog(&quot;Asking the bytecode liveness.\n&quot;);
1148             return livenessFor(codeOriginPtr-&gt;inlineCallFrame).operandIsLive(
1149                 reg.offset(), codeOriginPtr-&gt;bytecodeIndex);
1150         }
1151 
1152         InlineCallFrame* inlineCallFrame = codeOriginPtr-&gt;inlineCallFrame;
1153         if (!inlineCallFrame) {
1154             if (verbose)
1155                 dataLog(&quot;Ran out of stack, returning true.\n&quot;);
1156             return true;
1157         }
1158 
1159         // Arguments are always live. This would be redundant if it wasn&#39;t for our
1160         // op_call_varargs inlining.
1161         if (reg.isArgument()
1162             &amp;&amp; static_cast&lt;size_t&gt;(reg.toArgument()) &lt; inlineCallFrame-&gt;argumentsWithFixup.size()) {
1163             if (verbose)
1164                 dataLog(&quot;Argument is live.\n&quot;);
1165             return true;
1166         }
1167 
1168         codeOriginPtr = inlineCallFrame-&gt;getCallerSkippingTailCalls();
1169 
1170         // The first inline call frame could be an inline tail call
1171         if (!codeOriginPtr) {
1172             if (verbose)
1173                 dataLog(&quot;Dead because of tail inlining.\n&quot;);
1174             return false;
1175         }
1176     }
1177 
1178     RELEASE_ASSERT_NOT_REACHED();
1179 }
1180 
1181 BitVector Graph::localsLiveInBytecode(CodeOrigin codeOrigin)
1182 {
1183     BitVector result;
1184     result.ensureSize(block(0)-&gt;variablesAtHead.numberOfLocals());
1185     forAllLocalsLiveInBytecode(
1186         codeOrigin,
1187         [&amp;] (VirtualRegister reg) {
1188             ASSERT(reg.isLocal());
1189             result.quickSet(reg.toLocal());
1190         });
1191     return result;
1192 }
1193 
1194 unsigned Graph::parameterSlotsForArgCount(unsigned argCount)
1195 {
1196     size_t frameSize = CallFrame::headerSizeInRegisters + argCount;
1197     size_t alignedFrameSize = WTF::roundUpToMultipleOf(stackAlignmentRegisters(), frameSize);
1198     return alignedFrameSize - CallerFrameAndPC::sizeInRegisters;
1199 }
1200 
1201 unsigned Graph::frameRegisterCount()
1202 {
1203     unsigned result = m_nextMachineLocal + std::max(m_parameterSlots, static_cast&lt;unsigned&gt;(maxFrameExtentForSlowPathCallInRegisters));
1204     return roundLocalRegisterCountForFramePointerOffset(result);
1205 }
1206 
1207 unsigned Graph::stackPointerOffset()
1208 {
1209     return virtualRegisterForLocal(frameRegisterCount() - 1).offset();
1210 }
1211 
1212 unsigned Graph::requiredRegisterCountForExit()
1213 {
1214     unsigned count = JIT::frameRegisterCountFor(m_profiledBlock);
1215     for (InlineCallFrameSet::iterator iter = m_plan.inlineCallFrames()-&gt;begin(); !!iter; ++iter) {
1216         InlineCallFrame* inlineCallFrame = *iter;
1217         CodeBlock* codeBlock = baselineCodeBlockForInlineCallFrame(inlineCallFrame);
1218         unsigned requiredCount = VirtualRegister(inlineCallFrame-&gt;stackOffset).toLocal() + 1 + JIT::frameRegisterCountFor(codeBlock);
1219         count = std::max(count, requiredCount);
1220     }
1221     return count;
1222 }
1223 
1224 unsigned Graph::requiredRegisterCountForExecutionAndExit()
1225 {
1226     // FIXME: We should make sure that frameRegisterCount() and requiredRegisterCountForExit()
1227     // never overflows. https://bugs.webkit.org/show_bug.cgi?id=173852
1228     return std::max(frameRegisterCount(), requiredRegisterCountForExit());
1229 }
1230 
1231 JSValue Graph::tryGetConstantProperty(
1232     JSValue base, const RegisteredStructureSet&amp; structureSet, PropertyOffset offset)
1233 {
1234     if (!base || !base.isObject())
1235         return JSValue();
1236 
1237     JSObject* object = asObject(base);
1238 
1239     for (unsigned i = structureSet.size(); i--;) {
1240         RegisteredStructure structure = structureSet[i];
1241 
1242         WatchpointSet* set = structure-&gt;propertyReplacementWatchpointSet(offset);
1243         if (!set || !set-&gt;isStillValid())
1244             return JSValue();
1245 
1246         ASSERT(structure-&gt;isValidOffset(offset));
1247         ASSERT(!structure-&gt;isUncacheableDictionary());
1248 
1249         watchpoints().addLazily(set);
1250     }
1251 
1252     // What follows may require some extra thought. We need this load to load a valid JSValue. If
1253     // our profiling makes sense and we&#39;re still on track to generate code that won&#39;t be
1254     // invalidated, then we have nothing to worry about. We do, however, have to worry about
1255     // loading - and then using - an invalid JSValue in the case that unbeknownst to us our code
1256     // is doomed.
1257     //
1258     // One argument in favor of this code is that it should definitely work because the butterfly
1259     // is always set before the structure. However, we don&#39;t currently have a fence between those
1260     // stores. It&#39;s not clear if this matters, however. We only shrink the propertyStorage while
1261     // holding the Structure&#39;s lock. So, for this to fail, you&#39;d need an access on a constant
1262     // object pointer such that the inline caches told us that the object had a structure that it
1263     // did not *yet* have, and then later,the object transitioned to that structure that the inline
1264     // caches had already seen. And then the processor reordered the stores. Seems unlikely and
1265     // difficult to test. I believe that this is worth revisiting but it isn&#39;t worth losing sleep
1266     // over. Filed:
1267     // https://bugs.webkit.org/show_bug.cgi?id=134641
1268     //
1269     // For now, we just do the minimal thing: defend against the structure right now being
1270     // incompatible with the getDirect we&#39;re trying to do. The easiest way to do that is to
1271     // determine if the structure belongs to the proven set.
1272 
1273     Structure* structure = object-&gt;structure(m_vm);
1274     if (!structureSet.toStructureSet().contains(structure))
1275         return JSValue();
1276 
1277     return object-&gt;getDirectConcurrently(structure, offset);
1278 }
1279 
1280 JSValue Graph::tryGetConstantProperty(JSValue base, Structure* structure, PropertyOffset offset)
1281 {
1282     return tryGetConstantProperty(base, RegisteredStructureSet(registerStructure(structure)), offset);
1283 }
1284 
1285 JSValue Graph::tryGetConstantProperty(
1286     JSValue base, const StructureAbstractValue&amp; structure, PropertyOffset offset)
1287 {
1288     if (structure.isInfinite()) {
1289         // FIXME: If we just converted the offset to a uid, we could do ObjectPropertyCondition
1290         // watching to constant-fold the property.
1291         // https://bugs.webkit.org/show_bug.cgi?id=147271
1292         return JSValue();
1293     }
1294 
1295     return tryGetConstantProperty(base, structure.set(), offset);
1296 }
1297 
1298 JSValue Graph::tryGetConstantProperty(const AbstractValue&amp; base, PropertyOffset offset)
1299 {
1300     return tryGetConstantProperty(base.m_value, base.m_structure, offset);
1301 }
1302 
1303 AbstractValue Graph::inferredValueForProperty(
1304     const AbstractValue&amp; base, PropertyOffset offset,
1305     StructureClobberState clobberState)
1306 {
1307     if (JSValue value = tryGetConstantProperty(base, offset)) {
1308         AbstractValue result;
1309         result.set(*this, *freeze(value), clobberState);
1310         return result;
1311     }
1312 
1313     return AbstractValue::heapTop();
1314 }
1315 
1316 JSValue Graph::tryGetConstantClosureVar(JSValue base, ScopeOffset offset)
1317 {
1318     // This has an awesome concurrency story. See comment for GetGlobalVar in ByteCodeParser.
1319 
1320     if (!base)
1321         return JSValue();
1322 
1323     JSLexicalEnvironment* activation = jsDynamicCast&lt;JSLexicalEnvironment*&gt;(m_vm, base);
1324     if (!activation)
1325         return JSValue();
1326 
1327     SymbolTable* symbolTable = activation-&gt;symbolTable();
1328     JSValue value;
1329     WatchpointSet* set;
1330     {
1331         ConcurrentJSLocker locker(symbolTable-&gt;m_lock);
1332 
1333         SymbolTableEntry* entry = symbolTable-&gt;entryFor(locker, offset);
1334         if (!entry)
1335             return JSValue();
1336 
1337         set = entry-&gt;watchpointSet();
1338         if (!set)
1339             return JSValue();
1340 
1341         if (set-&gt;state() != IsWatched)
1342             return JSValue();
1343 
1344         ASSERT(entry-&gt;scopeOffset() == offset);
1345         value = activation-&gt;variableAt(offset).get();
1346         if (!value)
1347             return JSValue();
1348     }
1349 
1350     watchpoints().addLazily(set);
1351 
1352     return value;
1353 }
1354 
1355 JSValue Graph::tryGetConstantClosureVar(const AbstractValue&amp; value, ScopeOffset offset)
1356 {
1357     return tryGetConstantClosureVar(value.m_value, offset);
1358 }
1359 
1360 JSValue Graph::tryGetConstantClosureVar(Node* node, ScopeOffset offset)
1361 {
1362     if (!node-&gt;hasConstant())
1363         return JSValue();
1364     return tryGetConstantClosureVar(node-&gt;asJSValue(), offset);
1365 }
1366 
1367 JSArrayBufferView* Graph::tryGetFoldableView(JSValue value)
1368 {
1369     if (!value)
1370         return nullptr;
1371     JSArrayBufferView* view = jsDynamicCast&lt;JSArrayBufferView*&gt;(m_vm, value);
1372     if (!view)
1373         return nullptr;
1374     if (!view-&gt;length())
1375         return nullptr;
1376     WTF::loadLoadFence();
1377     watchpoints().addLazily(view);
1378     return view;
1379 }
1380 
1381 JSArrayBufferView* Graph::tryGetFoldableView(JSValue value, ArrayMode arrayMode)
1382 {
1383     if (arrayMode.type() != Array::AnyTypedArray &amp;&amp; arrayMode.typedArrayType() == NotTypedArray)
1384         return nullptr;
1385     return tryGetFoldableView(value);
1386 }
1387 
1388 void Graph::registerFrozenValues()
1389 {
1390     m_codeBlock-&gt;constants().shrink(0);
1391     m_codeBlock-&gt;constantsSourceCodeRepresentation().resize(0);
1392     for (FrozenValue* value : m_frozenValues) {
1393         if (!value-&gt;pointsToHeap())
1394             continue;
1395 
1396         ASSERT(value-&gt;structure());
1397         ASSERT(m_plan.weakReferences().contains(value-&gt;structure()));
1398 
1399         switch (value-&gt;strength()) {
1400         case WeakValue: {
1401             m_plan.weakReferences().addLazily(value-&gt;value().asCell());
1402             break;
1403         }
1404         case StrongValue: {
1405             unsigned constantIndex = m_codeBlock-&gt;addConstantLazily();
1406             // We already have a barrier on the code block.
1407             m_codeBlock-&gt;constants()[constantIndex].setWithoutWriteBarrier(value-&gt;value());
1408             break;
1409         } }
1410     }
1411     m_codeBlock-&gt;constants().shrinkToFit();
1412     m_codeBlock-&gt;constantsSourceCodeRepresentation().shrinkToFit();
1413 }
1414 
1415 void Graph::visitChildren(SlotVisitor&amp; visitor)
1416 {
1417     for (FrozenValue* value : m_frozenValues) {
1418         visitor.appendUnbarriered(value-&gt;value());
1419         visitor.appendUnbarriered(value-&gt;structure());
1420     }
1421 }
1422 
1423 FrozenValue* Graph::freeze(JSValue value)
1424 {
1425     if (UNLIKELY(!value))
1426         return FrozenValue::emptySingleton();
1427 
1428     // There are weird relationships in how optimized CodeBlocks
1429     // point to other CodeBlocks. We don&#39;t want to have them be
1430     // part of the weak pointer set. For example, an optimized CodeBlock
1431     // having a weak pointer to itself will cause it to get collected.
1432     RELEASE_ASSERT(!jsDynamicCast&lt;CodeBlock*&gt;(m_vm, value));
1433 
1434     auto result = m_frozenValueMap.add(JSValue::encode(value), nullptr);
1435     if (LIKELY(!result.isNewEntry))
1436         return result.iterator-&gt;value;
1437 
1438     if (value.isUInt32())
1439         m_uint32ValuesInUse.append(value.asUInt32());
1440 
1441     FrozenValue frozenValue = FrozenValue::freeze(value);
1442     if (Structure* structure = frozenValue.structure())
1443         registerStructure(structure);
1444 
1445     return result.iterator-&gt;value = m_frozenValues.add(frozenValue);
1446 }
1447 
1448 FrozenValue* Graph::freezeStrong(JSValue value)
1449 {
1450     FrozenValue* result = freeze(value);
1451     result-&gt;strengthenTo(StrongValue);
1452     return result;
1453 }
1454 
1455 void Graph::convertToConstant(Node* node, FrozenValue* value)
1456 {
1457     if (value-&gt;structure())
1458         assertIsRegistered(value-&gt;structure());
1459     node-&gt;convertToConstant(value);
1460 }
1461 
1462 void Graph::convertToConstant(Node* node, JSValue value)
1463 {
1464     convertToConstant(node, freeze(value));
1465 }
1466 
1467 void Graph::convertToStrongConstant(Node* node, JSValue value)
1468 {
1469     convertToConstant(node, freezeStrong(value));
1470 }
1471 
1472 RegisteredStructure Graph::registerStructure(Structure* structure, StructureRegistrationResult&amp; result)
1473 {
1474     m_plan.weakReferences().addLazily(structure);
1475     if (m_plan.watchpoints().consider(structure))
1476         result = StructureRegisteredAndWatched;
1477     else
1478         result = StructureRegisteredNormally;
1479     return RegisteredStructure::createPrivate(structure);
1480 }
1481 
1482 void Graph::registerAndWatchStructureTransition(Structure* structure)
1483 {
1484     m_plan.weakReferences().addLazily(structure);
1485     m_plan.watchpoints().addLazily(structure-&gt;transitionWatchpointSet());
1486 }
1487 
1488 void Graph::assertIsRegistered(Structure* structure)
1489 {
1490     // It&#39;s convenient to be able to call this with a maybe-null structure.
1491     if (!structure)
1492         return;
1493 
1494     DFG_ASSERT(*this, nullptr, m_plan.weakReferences().contains(structure));
1495 
1496     if (!structure-&gt;dfgShouldWatch())
1497         return;
1498     if (watchpoints().isWatched(structure-&gt;transitionWatchpointSet()))
1499         return;
1500 
1501     DFG_CRASH(*this, nullptr, toCString(&quot;Structure &quot;, pointerDump(structure), &quot; is watchable but isn&#39;t being watched.&quot;).data());
1502 }
1503 
1504 static void logDFGAssertionFailure(
1505     Graph&amp; graph, const CString&amp; whileText, const char* file, int line, const char* function,
1506     const char* assertion)
1507 {
1508     startCrashing();
1509     dataLog(&quot;DFG ASSERTION FAILED: &quot;, assertion, &quot;\n&quot;);
1510     dataLog(file, &quot;(&quot;, line, &quot;) : &quot;, function, &quot;\n&quot;);
1511     dataLog(&quot;\n&quot;);
1512     dataLog(whileText);
1513     dataLog(&quot;Graph at time of failure:\n&quot;);
1514     graph.dump();
1515     dataLog(&quot;\n&quot;);
1516     dataLog(&quot;DFG ASSERTION FAILED: &quot;, assertion, &quot;\n&quot;);
1517     dataLog(file, &quot;(&quot;, line, &quot;) : &quot;, function, &quot;\n&quot;);
1518 }
1519 
1520 void Graph::logAssertionFailure(
1521     std::nullptr_t, const char* file, int line, const char* function, const char* assertion)
1522 {
1523     logDFGAssertionFailure(*this, &quot;&quot;, file, line, function, assertion);
1524 }
1525 
1526 void Graph::logAssertionFailure(
1527     Node* node, const char* file, int line, const char* function, const char* assertion)
1528 {
1529     logDFGAssertionFailure(*this, toCString(&quot;While handling node &quot;, node, &quot;\n\n&quot;), file, line, function, assertion);
1530 }
1531 
1532 void Graph::logAssertionFailure(
1533     BasicBlock* block, const char* file, int line, const char* function, const char* assertion)
1534 {
1535     logDFGAssertionFailure(*this, toCString(&quot;While handling block &quot;, pointerDump(block), &quot;\n\n&quot;), file, line, function, assertion);
1536 }
1537 
1538 CPSCFG&amp; Graph::ensureCPSCFG()
1539 {
1540     RELEASE_ASSERT(m_form != SSA &amp;&amp; !m_isInSSAConversion);
1541     if (!m_cpsCFG)
1542         m_cpsCFG = std::make_unique&lt;CPSCFG&gt;(*this);
1543     return *m_cpsCFG;
1544 }
1545 
1546 CPSDominators&amp; Graph::ensureCPSDominators()
1547 {
1548     RELEASE_ASSERT(m_form != SSA &amp;&amp; !m_isInSSAConversion);
1549     if (!m_cpsDominators)
1550         m_cpsDominators = std::make_unique&lt;CPSDominators&gt;(*this);
1551     return *m_cpsDominators;
1552 }
1553 
1554 SSADominators&amp; Graph::ensureSSADominators()
1555 {
1556     RELEASE_ASSERT(m_form == SSA || m_isInSSAConversion);
1557     if (!m_ssaDominators)
1558         m_ssaDominators = std::make_unique&lt;SSADominators&gt;(*this);
1559     return *m_ssaDominators;
1560 }
1561 
1562 CPSNaturalLoops&amp; Graph::ensureCPSNaturalLoops()
1563 {
1564     RELEASE_ASSERT(m_form != SSA &amp;&amp; !m_isInSSAConversion);
1565     ensureCPSDominators();
1566     if (!m_cpsNaturalLoops)
1567         m_cpsNaturalLoops = std::make_unique&lt;CPSNaturalLoops&gt;(*this);
1568     return *m_cpsNaturalLoops;
1569 }
1570 
1571 SSANaturalLoops&amp; Graph::ensureSSANaturalLoops()
1572 {
1573     RELEASE_ASSERT(m_form == SSA);
1574     ensureSSADominators();
1575     if (!m_ssaNaturalLoops)
1576         m_ssaNaturalLoops = std::make_unique&lt;SSANaturalLoops&gt;(*this);
1577     return *m_ssaNaturalLoops;
1578 }
1579 
1580 BackwardsCFG&amp; Graph::ensureBackwardsCFG()
1581 {
1582     // We could easily relax this in the future to work over CPS, but today, it&#39;s only used in SSA.
1583     RELEASE_ASSERT(m_form == SSA);
1584     if (!m_backwardsCFG)
1585         m_backwardsCFG = std::make_unique&lt;BackwardsCFG&gt;(*this);
1586     return *m_backwardsCFG;
1587 }
1588 
1589 BackwardsDominators&amp; Graph::ensureBackwardsDominators()
1590 {
1591     RELEASE_ASSERT(m_form == SSA);
1592     if (!m_backwardsDominators)
1593         m_backwardsDominators = std::make_unique&lt;BackwardsDominators&gt;(*this);
1594     return *m_backwardsDominators;
1595 }
1596 
1597 ControlEquivalenceAnalysis&amp; Graph::ensureControlEquivalenceAnalysis()
1598 {
1599     RELEASE_ASSERT(m_form == SSA);
1600     if (!m_controlEquivalenceAnalysis)
1601         m_controlEquivalenceAnalysis = std::make_unique&lt;ControlEquivalenceAnalysis&gt;(*this);
1602     return *m_controlEquivalenceAnalysis;
1603 }
1604 
1605 MethodOfGettingAValueProfile Graph::methodOfGettingAValueProfileFor(Node* currentNode, Node* operandNode)
1606 {
1607     // This represents IR like `CurrentNode(@operandNode)`. For example: `GetByVal(..., Int32:@GetLocal)`.
1608 
1609     for (Node* node = operandNode; node;) {
1610         // currentNode is null when we&#39;re doing speculation checks for checkArgumentTypes().
1611         if (!currentNode || node-&gt;origin.semantic != currentNode-&gt;origin.semantic || !currentNode-&gt;hasResult()) {
1612             CodeBlock* profiledBlock = baselineCodeBlockFor(node-&gt;origin.semantic);
1613 
1614             if (node-&gt;accessesStack(*this)) {
1615                 if (m_form != SSA &amp;&amp; node-&gt;local().isArgument()) {
1616                     int argument = node-&gt;local().toArgument();
1617                     Node* argumentNode = m_rootToArguments.find(block(0))-&gt;value[argument];
1618                     // FIXME: We should match SetArgument nodes at other entrypoints as well:
1619                     // https://bugs.webkit.org/show_bug.cgi?id=175841
1620                     if (argumentNode &amp;&amp; node-&gt;variableAccessData() == argumentNode-&gt;variableAccessData())
1621                         return &amp;profiledBlock-&gt;valueProfileForArgument(argument);
1622                 }
1623 
1624                 if (node-&gt;op() == GetLocal) {
1625                     return MethodOfGettingAValueProfile::fromLazyOperand(
1626                         profiledBlock,
1627                         LazyOperandValueProfileKey(
1628                             node-&gt;origin.semantic.bytecodeIndex, node-&gt;local()));
1629                 }
1630             }
1631 
1632             if (node-&gt;hasHeapPrediction())
1633                 return &amp;profiledBlock-&gt;valueProfileForBytecodeOffset(node-&gt;origin.semantic.bytecodeIndex);
1634 
1635             if (profiledBlock-&gt;hasBaselineJITProfiling()) {
1636                 if (ArithProfile* result = profiledBlock-&gt;arithProfileForBytecodeOffset(node-&gt;origin.semantic.bytecodeIndex))
1637                     return result;
1638             }
1639         }
1640 
1641         switch (node-&gt;op()) {
1642         case BooleanToNumber:
1643         case Identity:
1644         case ValueRep:
1645         case DoubleRep:
1646         case Int52Rep:
1647             node = node-&gt;child1().node();
1648             break;
1649         default:
1650             node = nullptr;
1651         }
1652     }
1653 
1654     return MethodOfGettingAValueProfile();
1655 }
1656 
1657 bool Graph::getRegExpPrototypeProperty(JSObject* regExpPrototype, Structure* regExpPrototypeStructure, UniquedStringImpl* uid, JSValue&amp; returnJSValue)
1658 {
1659     unsigned attributesUnused;
1660     PropertyOffset offset = regExpPrototypeStructure-&gt;getConcurrently(uid, attributesUnused);
1661     if (!isValidOffset(offset))
1662         return false;
1663 
1664     JSValue value = tryGetConstantProperty(regExpPrototype, regExpPrototypeStructure, offset);
1665     if (!value)
1666         return false;
1667 
1668     // We only care about functions and getters at this point. If you want to access other properties
1669     // you&#39;ll have to add code for those types.
1670     JSFunction* function = jsDynamicCast&lt;JSFunction*&gt;(m_vm, value);
1671     if (!function) {
1672         GetterSetter* getterSetter = jsDynamicCast&lt;GetterSetter*&gt;(m_vm, value);
1673 
1674         if (!getterSetter)
1675             return false;
1676 
1677         returnJSValue = JSValue(getterSetter);
1678         return true;
1679     }
1680 
1681     returnJSValue = value;
1682     return true;
1683 }
1684 
1685 bool Graph::isStringPrototypeMethodSane(JSGlobalObject* globalObject, UniquedStringImpl* uid)
1686 {
1687     ObjectPropertyConditionSet conditions = generateConditionsForPrototypeEquivalenceConcurrently(m_vm, globalObject, globalObject-&gt;stringObjectStructure(), globalObject-&gt;stringPrototype(), uid);
1688 
1689     if (!conditions.isValid())
1690         return false;
1691 
1692     ObjectPropertyCondition equivalenceCondition = conditions.slotBaseCondition();
1693     RELEASE_ASSERT(equivalenceCondition.hasRequiredValue());
1694     JSFunction* function = jsDynamicCast&lt;JSFunction*&gt;(m_vm, equivalenceCondition.condition().requiredValue());
1695     if (!function)
1696         return false;
1697 
1698     if (function-&gt;executable()-&gt;intrinsicFor(CodeForCall) != StringPrototypeValueOfIntrinsic)
1699         return false;
1700 
1701     return watchConditions(conditions);
1702 }
1703 
1704 
1705 bool Graph::canOptimizeStringObjectAccess(const CodeOrigin&amp; codeOrigin)
1706 {
1707     if (hasExitSite(codeOrigin, BadCache) || hasExitSite(codeOrigin, BadConstantCache))
1708         return false;
1709 
1710     JSGlobalObject* globalObject = globalObjectFor(codeOrigin);
1711     Structure* stringObjectStructure = globalObjectFor(codeOrigin)-&gt;stringObjectStructure();
1712     registerStructure(stringObjectStructure);
1713     ASSERT(stringObjectStructure-&gt;storedPrototype().isObject());
1714     ASSERT(stringObjectStructure-&gt;storedPrototype().asCell()-&gt;classInfo(*stringObjectStructure-&gt;storedPrototype().asCell()-&gt;vm()) == StringPrototype::info());
1715 
1716     if (!watchConditions(generateConditionsForPropertyMissConcurrently(m_vm, globalObject, stringObjectStructure, m_vm.propertyNames-&gt;toPrimitiveSymbol.impl())))
1717         return false;
1718 
1719     // We&#39;re being conservative here. We want DFG&#39;s ToString on StringObject to be
1720     // used in both numeric contexts (that would call valueOf()) and string contexts
1721     // (that would call toString()). We don&#39;t want the DFG to have to distinguish
1722     // between the two, just because that seems like it would get confusing. So we
1723     // just require both methods to be sane.
1724     if (!isStringPrototypeMethodSane(globalObject, m_vm.propertyNames-&gt;valueOf.impl()))
1725         return false;
1726     return isStringPrototypeMethodSane(globalObject, m_vm.propertyNames-&gt;toString.impl());
1727 }
1728 
1729 bool Graph::willCatchExceptionInMachineFrame(CodeOrigin codeOrigin, CodeOrigin&amp; opCatchOriginOut, HandlerInfo*&amp; catchHandlerOut)
1730 {
1731     if (!m_hasExceptionHandlers)
1732         return false;
1733 
1734     unsigned bytecodeIndexToCheck = codeOrigin.bytecodeIndex;
1735     while (1) {
1736         InlineCallFrame* inlineCallFrame = codeOrigin.inlineCallFrame;
1737         CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
1738         if (HandlerInfo* handler = codeBlock-&gt;handlerForBytecodeOffset(bytecodeIndexToCheck)) {
1739             opCatchOriginOut = CodeOrigin(handler-&gt;target, inlineCallFrame);
1740             catchHandlerOut = handler;
1741             return true;
1742         }
1743 
1744         if (!inlineCallFrame)
1745             return false;
1746 
1747         bytecodeIndexToCheck = inlineCallFrame-&gt;directCaller.bytecodeIndex;
1748         codeOrigin = codeOrigin.inlineCallFrame-&gt;directCaller;
1749     }
1750 
1751     RELEASE_ASSERT_NOT_REACHED();
1752 }
1753 
1754 bool Graph::canDoFastSpread(Node* node, const AbstractValue&amp; value)
1755 {
1756     // The parameter &#39;value&#39; is the AbstractValue for child1 (the thing being spread).
1757     ASSERT(node-&gt;op() == Spread);
1758 
1759     if (node-&gt;child1().useKind() != ArrayUse) {
1760         // Note: we only speculate on ArrayUse when we&#39;ve set up the necessary watchpoints
1761         // to prove that the iteration protocol is non-observable starting from ArrayPrototype.
1762         return false;
1763     }
1764 
1765     // FIXME: We should add profiling of the incoming operand to Spread
1766     // so we can speculate in such a way that we guarantee that this
1767     // function would return true:
1768     // https://bugs.webkit.org/show_bug.cgi?id=171198
1769 
1770     if (!value.m_structure.isFinite())
1771         return false;
1772 
1773     ArrayPrototype* arrayPrototype = globalObjectFor(node-&gt;child1()-&gt;origin.semantic)-&gt;arrayPrototype();
1774     bool allGood = true;
1775     value.m_structure.forEach([&amp;] (RegisteredStructure structure) {
1776         allGood &amp;= structure-&gt;hasMonoProto()
1777             &amp;&amp; structure-&gt;storedPrototype() == arrayPrototype
1778             &amp;&amp; !structure-&gt;isDictionary()
1779             &amp;&amp; structure-&gt;getConcurrently(m_vm.propertyNames-&gt;iteratorSymbol.impl()) == invalidOffset
1780             &amp;&amp; !structure-&gt;mayInterceptIndexedAccesses();
1781     });
1782 
1783     return allGood;
1784 }
1785 
1786 void Graph::clearCPSCFGData()
1787 {
1788     m_cpsNaturalLoops = nullptr;
1789     m_cpsDominators = nullptr;
1790     m_cpsCFG = nullptr;
1791 }
1792 
1793 } } // namespace JSC::DFG
1794 
1795 #endif // ENABLE(DFG_JIT)
    </pre>
  </body>
</html>