diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp b/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediastream/MediaStreamTrack.cpp
@@ -1,9 +1,9 @@
 /*
  * Copyright (C) 2011 Google Inc. All rights reserved.
  * Copyright (C) 2011, 2015 Ericsson AB. All rights reserved.
- * Copyright (C) 2013-2016 Apple Inc. All rights reserved.
+ * Copyright (C) 2013-2019 Apple Inc. All rights reserved.
  * Copyright (C) 2013 Nokia Corporation and/or its subsidiary(-ies).
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
  * are met:
@@ -40,44 +40,75 @@
 #include "NotImplemented.h"
 #include "OverconstrainedError.h"
 #include "Page.h"
 #include "RealtimeMediaSourceCenter.h"
 #include "ScriptExecutionContext.h"
+#include <wtf/CompletionHandler.h>
+#include <wtf/IsoMallocInlines.h>
 #include <wtf/NeverDestroyed.h>
 
 namespace WebCore {
 
+static HashSet<MediaStreamTrack*>& allCaptureTracks()
+{
+    static NeverDestroyed<HashSet<MediaStreamTrack*>> captureTracks;
+    return captureTracks;
+}
+
+static MediaProducer::MediaStateFlags sourceCaptureState(RealtimeMediaSource&);
+
+WTF_MAKE_ISO_ALLOCATED_IMPL(MediaStreamTrack);
+
 Ref<MediaStreamTrack> MediaStreamTrack::create(ScriptExecutionContext& context, Ref<MediaStreamTrackPrivate>&& privateTrack)
 {
     return adoptRef(*new MediaStreamTrack(context, WTFMove(privateTrack)));
 }
 
 MediaStreamTrack::MediaStreamTrack(ScriptExecutionContext& context, Ref<MediaStreamTrackPrivate>&& privateTrack)
     : ActiveDOMObject(&context)
     , m_private(WTFMove(privateTrack))
     , m_taskQueue(context)
+    , m_isCaptureTrack(m_private->isCaptureTrack())
 {
+    ALWAYS_LOG(LOGIDENTIFIER);
     suspendIfNeeded();
 
     m_private->addObserver(*this);
 
-    if (auto document = this->document())
+    if (!isCaptureTrack())
+        return;
+
+    allCaptureTracks().add(this);
+
+    if (auto document = this->document()) {
+        if (document->page() && document->page()->mutedState())
+            setMuted(true);
+#if !PLATFORM(IOS_FAMILY)
         document->addAudioProducer(*this);
+#endif
+    }
 }
 
 MediaStreamTrack::~MediaStreamTrack()
 {
     m_private->removeObserver(*this);
 
+    if (!isCaptureTrack())
+        return;
+
+    allCaptureTracks().remove(this);
+
+#if !PLATFORM(IOS_FAMILY)
     if (auto document = this->document())
         document->removeAudioProducer(*this);
+#endif
 }
 
-const AtomicString& MediaStreamTrack::kind() const
+const AtomString& MediaStreamTrack::kind() const
 {
-    static NeverDestroyed<AtomicString> audioKind("audio", AtomicString::ConstructFromLiteral);
-    static NeverDestroyed<AtomicString> videoKind("video", AtomicString::ConstructFromLiteral);
+    static NeverDestroyed<AtomString> audioKind("audio", AtomString::ConstructFromLiteral);
+    static NeverDestroyed<AtomString> videoKind("video", AtomString::ConstructFromLiteral);
 
     if (m_private->type() == RealtimeMediaSource::Type::Audio)
         return audioKind;
     return videoKind;
 }
@@ -90,17 +121,17 @@
 const String& MediaStreamTrack::label() const
 {
     return m_private->label();
 }
 
-const AtomicString& MediaStreamTrack::contentHint() const
+const AtomString& MediaStreamTrack::contentHint() const
 {
-    static NeverDestroyed<const AtomicString> speechHint("speech", AtomicString::ConstructFromLiteral);
-    static NeverDestroyed<const AtomicString> musicHint("music", AtomicString::ConstructFromLiteral);
-    static NeverDestroyed<const AtomicString> detailHint("detail", AtomicString::ConstructFromLiteral);
-    static NeverDestroyed<const AtomicString> textHint("text", AtomicString::ConstructFromLiteral);
-    static NeverDestroyed<const AtomicString> motionHint("motion", AtomicString::ConstructFromLiteral);
+    static NeverDestroyed<const AtomString> speechHint("speech", AtomString::ConstructFromLiteral);
+    static NeverDestroyed<const AtomString> musicHint("music", AtomString::ConstructFromLiteral);
+    static NeverDestroyed<const AtomString> detailHint("detail", AtomString::ConstructFromLiteral);
+    static NeverDestroyed<const AtomString> textHint("text", AtomString::ConstructFromLiteral);
+    static NeverDestroyed<const AtomString> motionHint("motion", AtomString::ConstructFromLiteral);
 
     switch (m_private->contentHint()) {
     case MediaStreamTrackPrivate::HintValue::Empty:
         return emptyAtom();
     case MediaStreamTrackPrivate::HintValue::Speech:
@@ -158,10 +189,30 @@
 bool MediaStreamTrack::muted() const
 {
     return m_private->muted();
 }
 
+void MediaStreamTrack::setMuted(MediaProducer::MutedStateFlags state)
+{
+    bool trackMuted = false;
+    switch (source().deviceType()) {
+    case CaptureDevice::DeviceType::Microphone:
+    case CaptureDevice::DeviceType::Camera:
+        trackMuted = state & AudioAndVideoCaptureIsMuted;
+        break;
+    case CaptureDevice::DeviceType::Screen:
+    case CaptureDevice::DeviceType::Window:
+        trackMuted = state & ScreenCaptureIsMuted;
+        break;
+    case CaptureDevice::DeviceType::Unknown:
+        ASSERT_NOT_REACHED();
+        break;
+    }
+
+    m_private->setMuted(trackMuted);
+}
+
 auto MediaStreamTrack::readyState() const -> State
 {
     return ended() ? State::Ended : State::Live;
 }
 
@@ -360,11 +411,11 @@
 
     Document* document = this->document();
     if (!document || !document->page())
         return;
 
-    m_private->setMuted(document->page()->isMediaCaptureMuted());
+    setMuted(document->page()->mutedState());
 }
 
 MediaProducer::MediaStateFlags MediaStreamTrack::mediaState() const
 {
     if (m_ended || !isCaptureTrack())
@@ -372,31 +423,75 @@
 
     Document* document = this->document();
     if (!document || !document->page())
         return IsNotPlaying;
 
-    bool pageCaptureMuted = document->page()->isMediaCaptureMuted();
+    return sourceCaptureState(source());
+}
 
-    if (source().type() == RealtimeMediaSource::Type::Audio) {
-        if (source().interrupted() && !pageCaptureMuted)
-            return HasInterruptedAudioCaptureDevice;
-        if (muted())
-            return HasMutedAudioCaptureDevice;
-        if (m_private->isProducingData())
-            return HasActiveAudioCaptureDevice;
-    } else {
-        auto deviceType = source().deviceType();
-        ASSERT(deviceType == CaptureDevice::DeviceType::Camera || deviceType == CaptureDevice::DeviceType::Screen || deviceType == CaptureDevice::DeviceType::Window);
-        if (source().interrupted() && !pageCaptureMuted)
-            return deviceType == CaptureDevice::DeviceType::Camera ? HasInterruptedVideoCaptureDevice : HasInterruptedDisplayCaptureDevice;
-        if (muted())
-            return deviceType == CaptureDevice::DeviceType::Camera ? HasMutedVideoCaptureDevice : HasMutedDisplayCaptureDevice;
-        if (m_private->isProducingData())
-            return deviceType == CaptureDevice::DeviceType::Camera ? HasActiveVideoCaptureDevice : HasActiveDisplayCaptureDevice;
+MediaProducer::MediaStateFlags sourceCaptureState(RealtimeMediaSource& source)
+{
+    switch (source.deviceType()) {
+    case CaptureDevice::DeviceType::Microphone:
+        if (source.muted())
+            return MediaProducer::HasMutedAudioCaptureDevice;
+        if (source.interrupted())
+            return MediaProducer::HasInterruptedAudioCaptureDevice;
+        if (source.isProducingData())
+            return MediaProducer::HasActiveAudioCaptureDevice;
+        break;
+    case CaptureDevice::DeviceType::Camera:
+        if (source.muted())
+            return MediaProducer::HasMutedVideoCaptureDevice;
+        if (source.interrupted())
+            return MediaProducer::HasInterruptedVideoCaptureDevice;
+        if (source.isProducingData())
+            return MediaProducer::HasActiveVideoCaptureDevice;
+        break;
+    case CaptureDevice::DeviceType::Screen:
+    case CaptureDevice::DeviceType::Window:
+        if (source.muted())
+            return MediaProducer::HasMutedDisplayCaptureDevice;
+        if (source.interrupted())
+            return MediaProducer::HasInterruptedDisplayCaptureDevice;
+        if (source.isProducingData())
+            return MediaProducer::HasActiveDisplayCaptureDevice;
+        break;
+    case CaptureDevice::DeviceType::Unknown:
+        ASSERT_NOT_REACHED();
     }
 
-    return IsNotPlaying;
+    return MediaProducer::IsNotPlaying;
+}
+
+#if PLATFORM(IOS_FAMILY)
+MediaProducer::MediaStateFlags MediaStreamTrack::captureState()
+{
+    MediaProducer::MediaStateFlags state = MediaProducer::IsNotPlaying;
+    if (auto* source = RealtimeMediaSourceCenter::singleton().audioCaptureFactory().activeSource())
+        state |= sourceCaptureState(*source);
+    if (auto* source = RealtimeMediaSourceCenter::singleton().videoCaptureFactory().activeSource())
+        state |= sourceCaptureState(*source);
+    return state;
+}
+
+void MediaStreamTrack::muteCapture()
+{
+    if (auto* source = RealtimeMediaSourceCenter::singleton().audioCaptureFactory().activeSource())
+        source->setMuted(true);
+    if (auto* source = RealtimeMediaSourceCenter::singleton().videoCaptureFactory().activeSource())
+        source->setMuted(true);
+}
+#endif
+
+void MediaStreamTrack::endCapture(Document& document)
+{
+    for (auto* captureTrack : allCaptureTracks()) {
+        if (captureTrack->document() != &document)
+            continue;
+        captureTrack->stopTrack(MediaStreamTrack::StopMode::PostEvent);
+    }
 }
 
 void MediaStreamTrack::trackStarted(MediaStreamTrackPrivate&)
 {
     configureTrackRendering();
@@ -429,12 +524,14 @@
 void MediaStreamTrack::trackMutedChanged(MediaStreamTrackPrivate&)
 {
     if (scriptExecutionContext()->activeDOMObjectsAreSuspended() || scriptExecutionContext()->activeDOMObjectsAreStopped() || m_ended)
         return;
 
-    AtomicString eventType = muted() ? eventNames().muteEvent : eventNames().unmuteEvent;
-    dispatchEvent(Event::create(eventType, Event::CanBubble::No, Event::IsCancelable::No));
+    m_eventTaskQueue.enqueueTask([this, muted = this->muted()] {
+        AtomString eventType = muted ? eventNames().muteEvent : eventNames().unmuteEvent;
+        dispatchEvent(Event::create(eventType, Event::CanBubble::No, Event::IsCancelable::No));
+    });
 
     configureTrackRendering();
 }
 
 void MediaStreamTrack::trackSettingsChanged(MediaStreamTrackPrivate&)
@@ -487,8 +584,15 @@
 Document* MediaStreamTrack::document() const
 {
     return downcast<Document>(scriptExecutionContext());
 }
 
+#if !RELEASE_LOG_DISABLED
+WTFLogChannel& MediaStreamTrack::logChannel() const
+{
+    return LogWebRTC;
+}
+#endif
+
 } // namespace WebCore
 
 #endif // ENABLE(MEDIA_STREAM)
