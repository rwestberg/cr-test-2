diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h b/modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h
@@ -1449,110 +1449,93 @@
         m_assembler.movw_im(static_cast<int16_t>(imm.m_value), address.offset, address.base);
     }
 
     // Floating-point operation:
     //
-    // Presently only supports SSE, not x87 floating point.
-
     void moveDouble(FPRegisterID src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         if (src != dest)
             m_assembler.movaps_rr(src, dest);
     }
 
     void loadDouble(TrustedImmPtr address, FPRegisterID dest)
     {
 #if CPU(X86)
-        ASSERT(isSSE2Present());
         m_assembler.movsd_mr(address.asPtr(), dest);
 #else
         move(address, scratchRegister());
         loadDouble(scratchRegister(), dest);
 #endif
     }
 
     void loadDouble(ImplicitAddress address, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movsd_mr(address.offset, address.base, dest);
     }
 
     void loadDouble(BaseIndex address, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movsd_mr(address.offset, address.base, address.index, address.scale, dest);
     }
 
     void loadFloat(TrustedImmPtr address, FPRegisterID dest)
     {
 #if CPU(X86)
-        ASSERT(isSSE2Present());
         m_assembler.movss_mr(address.asPtr(), dest);
 #else
         move(address, scratchRegister());
         loadFloat(scratchRegister(), dest);
 #endif
     }
 
     void loadFloat(ImplicitAddress address, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movss_mr(address.offset, address.base, dest);
     }
 
     void loadFloat(BaseIndex address, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movss_mr(address.offset, address.base, address.index, address.scale, dest);
     }
 
     void storeDouble(FPRegisterID src, ImplicitAddress address)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movsd_rm(src, address.offset, address.base);
     }
 
     void storeDouble(FPRegisterID src, BaseIndex address)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movsd_rm(src, address.offset, address.base, address.index, address.scale);
     }
 
     void storeFloat(FPRegisterID src, ImplicitAddress address)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movss_rm(src, address.offset, address.base);
     }
 
     void storeFloat(FPRegisterID src, BaseIndex address)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movss_rm(src, address.offset, address.base, address.index, address.scale);
     }
 
     void convertDoubleToFloat(FPRegisterID src, FPRegisterID dst)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvtsd2ss_rr(src, dst);
     }
 
     void convertDoubleToFloat(Address address, FPRegisterID dst)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvtsd2ss_mr(address.offset, address.base, dst);
     }
 
     void convertFloatToDouble(FPRegisterID src, FPRegisterID dst)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvtss2sd_rr(src, dst);
     }
 
     void convertFloatToDouble(Address address, FPRegisterID dst)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvtss2sd_mr(address.offset, address.base, dst);
     }
 
     void addDouble(FPRegisterID src, FPRegisterID dest)
     {
@@ -1562,11 +1545,10 @@
     void addDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vaddsd_rr(op1, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op1 == dest)
                 m_assembler.addsd_rr(op2, dest);
             else {
                 moveDouble(op2, dest);
                 m_assembler.addsd_rr(op1, dest);
@@ -1582,11 +1564,10 @@
     void addDouble(Address op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vaddsd_mr(op1.offset, op1.base, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op2 == dest) {
                 m_assembler.addsd_mr(op1.offset, op1.base, dest);
                 return;
             }
 
@@ -1603,11 +1584,10 @@
     void addDouble(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vaddsd_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op2 == dest) {
                 m_assembler.addsd_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
                 return;
             }
             loadDouble(op1, dest);
@@ -1628,11 +1608,10 @@
     void addFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vaddss_rr(op1, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op1 == dest)
                 m_assembler.addss_rr(op2, dest);
             else {
                 moveDouble(op2, dest);
                 m_assembler.addss_rr(op1, dest);
@@ -1643,11 +1622,10 @@
     void addFloat(Address op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vaddss_mr(op1.offset, op1.base, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op2 == dest) {
                 m_assembler.addss_mr(op1.offset, op1.base, dest);
                 return;
             }
 
@@ -1664,11 +1642,10 @@
     void addFloat(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vaddss_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op2 == dest) {
                 m_assembler.addss_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
                 return;
             }
             loadFloat(op1, dest);
@@ -1676,11 +1653,10 @@
         }
     }
 
     void divDouble(FPRegisterID src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.divsd_rr(src, dest);
     }
 
     void divDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
     {
@@ -1691,23 +1667,20 @@
         divDouble(op2, dest);
     }
 
     void divDouble(Address src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.divsd_mr(src.offset, src.base, dest);
     }
 
     void divFloat(FPRegisterID src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.divss_rr(src, dest);
     }
 
     void divFloat(Address src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.divss_mr(src.offset, src.base, dest);
     }
 
     void subDouble(FPRegisterID src, FPRegisterID dest)
     {
@@ -1717,12 +1690,10 @@
     void subDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vsubsd_rr(op1, op2, dest);
         else {
-            ASSERT(isSSE2Present());
-
             // B := A - B is invalid.
             ASSERT(op1 == dest || op2 != dest);
             moveDouble(op1, dest);
             m_assembler.subsd_rr(op2, dest);
         }
@@ -1761,11 +1732,10 @@
     void subFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vsubss_rr(op1, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             // B := A - B is invalid.
             ASSERT(op1 == dest || op2 != dest);
             moveDouble(op1, dest);
             m_assembler.subss_rr(op2, dest);
         }
@@ -1804,11 +1774,10 @@
     void mulDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vmulsd_rr(op1, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op1 == dest)
                 m_assembler.mulsd_rr(op2, dest);
             else {
                 moveDouble(op2, dest);
                 m_assembler.mulsd_rr(op1, dest);
@@ -1824,11 +1793,10 @@
     void mulDouble(Address op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vmulsd_mr(op1.offset, op1.base, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op2 == dest) {
                 m_assembler.mulsd_mr(op1.offset, op1.base, dest);
                 return;
             }
             loadDouble(op1, dest);
@@ -1844,11 +1812,10 @@
     void mulDouble(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vmulsd_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op2 == dest) {
                 m_assembler.mulsd_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
                 return;
             }
             loadDouble(op1, dest);
@@ -1869,11 +1836,10 @@
     void mulFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vmulss_rr(op1, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op1 == dest)
                 m_assembler.mulss_rr(op2, dest);
             else {
                 moveDouble(op2, dest);
                 m_assembler.mulss_rr(op1, dest);
@@ -1884,11 +1850,10 @@
     void mulFloat(Address op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vmulss_mr(op1.offset, op1.base, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op2 == dest) {
                 m_assembler.mulss_mr(op1.offset, op1.base, dest);
                 return;
             }
             loadFloat(op1, dest);
@@ -1904,11 +1869,10 @@
     void mulFloat(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
     {
         if (supportsAVX())
             m_assembler.vmulss_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
         else {
-            ASSERT(isSSE2Present());
             if (op2 == dest) {
                 m_assembler.mulss_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
                 return;
             }
             loadFloat(op1, dest);
@@ -2007,65 +1971,55 @@
         }
     }
 
     void convertInt32ToDouble(RegisterID src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvtsi2sd_rr(src, dest);
     }
 
     void convertInt32ToDouble(Address src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvtsi2sd_mr(src.offset, src.base, dest);
     }
 
     void convertInt32ToFloat(RegisterID src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvtsi2ss_rr(src, dest);
     }
 
     void convertInt32ToFloat(Address src, FPRegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvtsi2ss_mr(src.offset, src.base, dest);
     }
 
     Jump branchDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
     {
-        ASSERT(isSSE2Present());
-
         if (cond & DoubleConditionBitInvert)
             m_assembler.ucomisd_rr(left, right);
         else
             m_assembler.ucomisd_rr(right, left);
         return jumpAfterFloatingPointCompare(cond, left, right);
     }
 
     Jump branchFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
     {
-        ASSERT(isSSE2Present());
-
         if (cond & DoubleConditionBitInvert)
             m_assembler.ucomiss_rr(left, right);
         else
             m_assembler.ucomiss_rr(right, left);
         return jumpAfterFloatingPointCompare(cond, left, right);
     }
 
     void compareDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
             m_assembler.ucomisd_rr(arg1, arg2);
         });
     }
 
     void compareFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
             m_assembler.ucomiss_rr(arg1, arg2);
         });
     }
 
@@ -2074,34 +2028,30 @@
     // May also branch for some values that are representable in 32 bits
     // (specifically, in this case, INT_MIN).
     enum BranchTruncateType { BranchIfTruncateFailed, BranchIfTruncateSuccessful };
     Jump branchTruncateDoubleToInt32(FPRegisterID src, RegisterID dest, BranchTruncateType branchType = BranchIfTruncateFailed)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvttsd2si_rr(src, dest);
         return branch32(branchType ? NotEqual : Equal, dest, TrustedImm32(0x80000000));
     }
 
     void truncateDoubleToInt32(FPRegisterID src, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvttsd2si_rr(src, dest);
     }
 
     void truncateFloatToInt32(FPRegisterID src, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvttss2si_rr(src, dest);
     }
 
     // Convert 'src' to an integer, and places the resulting 'dest'.
     // If the result is not representable as a 32 bit value, branch.
     // May also branch for some values that are representable in 32 bits
     // (specifically, in this case, 0).
     void branchConvertDoubleToInt32(FPRegisterID src, RegisterID dest, JumpList& failureCases, FPRegisterID fpTemp, bool negZeroCheck = true)
     {
-        ASSERT(isSSE2Present());
         m_assembler.cvttsd2si_rr(src, dest);
 
         // If the result is zero, it might have been -0.0, and the double comparison won't catch this!
 #if CPU(X86_64)
         if (negZeroCheck) {
@@ -2127,49 +2077,42 @@
         m_assembler.xorps_rr(reg, reg);
     }
 
     Jump branchDoubleNonZero(FPRegisterID reg, FPRegisterID scratch)
     {
-        ASSERT(isSSE2Present());
         m_assembler.xorpd_rr(scratch, scratch);
         return branchDouble(DoubleNotEqual, reg, scratch);
     }
 
     Jump branchDoubleZeroOrNaN(FPRegisterID reg, FPRegisterID scratch)
     {
-        ASSERT(isSSE2Present());
         m_assembler.xorpd_rr(scratch, scratch);
         return branchDouble(DoubleEqualOrUnordered, reg, scratch);
     }
 
     void lshiftPacked(TrustedImm32 imm, XMMRegisterID reg)
     {
-        ASSERT(isSSE2Present());
         m_assembler.psllq_i8r(imm.m_value, reg);
     }
 
     void rshiftPacked(TrustedImm32 imm, XMMRegisterID reg)
     {
-        ASSERT(isSSE2Present());
         m_assembler.psrlq_i8r(imm.m_value, reg);
     }
 
     void orPacked(XMMRegisterID src, XMMRegisterID dst)
     {
-        ASSERT(isSSE2Present());
         m_assembler.por_rr(src, dst);
     }
 
     void move32ToFloat(RegisterID src, XMMRegisterID dst)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movd_rr(src, dst);
     }
 
     void moveFloatTo32(XMMRegisterID src, RegisterID dst)
     {
-        ASSERT(isSSE2Present());
         m_assembler.movd_rr(src, dst);
     }
 
     // Stack manipulation operations:
     //
@@ -2250,23 +2193,19 @@
             m_assembler.movq_i64r(imm.m_value, dest);
     }
 
     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
-
         if (cond & DoubleConditionBitInvert)
             m_assembler.ucomisd_rr(left, right);
         else
             m_assembler.ucomisd_rr(right, left);
         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
     }
 
     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
-
         if (thenCase != dest && elseCase != dest) {
             move(elseCase, dest);
             elseCase = dest;
         }
 
@@ -2285,23 +2224,19 @@
         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
     }
 
     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
-
         if (cond & DoubleConditionBitInvert)
             m_assembler.ucomiss_rr(left, right);
         else
             m_assembler.ucomiss_rr(right, left);
         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
     }
 
     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
-
         if (thenCase != dest && elseCase != dest) {
             move(elseCase, dest);
             elseCase = dest;
         }
 
@@ -2382,12 +2317,10 @@
         UNREACHABLE_FOR_PLATFORM();
     }
 
     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
     {
-        ASSERT(isSSE2Present());
-
         if (cond & DoubleConditionBitInvert)
             m_assembler.ucomisd_rr(left, right);
         else
             m_assembler.ucomisd_rr(right, left);
 
@@ -2709,10 +2642,40 @@
     {
         m_assembler.testl_rr(reg, mask);
         return Jump(m_assembler.jCC(x86Condition(cond)));
     }
 
+    Jump branchTestBit32(ResultCondition cond, RegisterID reg, TrustedImm32 bit)
+    {
+        m_assembler.bt_ir(static_cast<unsigned>(bit.m_value) % 32, reg);
+        if (cond == NonZero)
+            return Jump(m_assembler.jb());
+        if (cond == Zero)
+            return Jump(m_assembler.jae());
+        RELEASE_ASSERT_NOT_REACHED();
+    }
+
+    Jump branchTestBit32(ResultCondition cond, Address testValue, TrustedImm32 bit)
+    {
+        m_assembler.bt_im(static_cast<unsigned>(bit.m_value) % 32, testValue.offset, testValue.base);
+        if (cond == NonZero)
+            return Jump(m_assembler.jb());
+        if (cond == Zero)
+            return Jump(m_assembler.jae());
+        RELEASE_ASSERT_NOT_REACHED();
+    }
+
+    Jump branchTestBit32(ResultCondition cond, RegisterID reg, RegisterID bit)
+    {
+        m_assembler.bt_ir(bit, reg);
+        if (cond == NonZero)
+            return Jump(m_assembler.jb());
+        if (cond == Zero)
+            return Jump(m_assembler.jae());
+        RELEASE_ASSERT_NOT_REACHED();
+    }
+
     void test32(RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
     {
         if (mask.m_value == -1)
             m_assembler.testl_rr(reg, reg);
         else if (!(mask.m_value & ~0xff) && reg < X86Registers::esp) { // Using esp and greater as a byte register yields the upper half of the 16 bit registers ax, cx, dx and bx, e.g. esp, register 4, is actually ah.
@@ -2780,30 +2743,30 @@
     Jump jump()
     {
         return Jump(m_assembler.jmp());
     }
 
-    void jump(RegisterID target, PtrTag)
+    void farJump(RegisterID target, PtrTag)
     {
         m_assembler.jmp_r(target);
     }
 
     // Address is a memory location containing the address to jump to
-    void jump(Address address, PtrTag)
+    void farJump(Address address, PtrTag)
     {
         m_assembler.jmp_m(address.offset, address.base);
     }
 
     // Address is a memory location containing the address to jump to
-    void jump(BaseIndex address, PtrTag)
+    void farJump(BaseIndex address, PtrTag)
     {
         m_assembler.jmp_m(address.offset, address.base, address.index, address.scale);
     }
 
-    ALWAYS_INLINE void jump(RegisterID target, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(target, NoPtrTag); }
-    ALWAYS_INLINE void jump(Address address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(address, NoPtrTag); }
-    ALWAYS_INLINE void jump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(address, NoPtrTag); }
+    ALWAYS_INLINE void farJump(RegisterID target, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(target, NoPtrTag); }
+    ALWAYS_INLINE void farJump(Address address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
+    ALWAYS_INLINE void farJump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }
 
     // Arithmetic control flow operations:
     //
     // This set of conditional branch operations branch based
     // on the result of an arithmetic operation.  The operation
@@ -4260,20 +4223,10 @@
         }
 
         ASSERT(!(cond & DoubleConditionBitSpecial));
         cmov(static_cast<X86Assembler::Condition>(cond & ~DoubleConditionBits), src, dest);
     }
-#endif
-#if !defined(NDEBUG) // CPU(X86)
-
-    // On x86-64 we should never be checking for SSE2 in a non-debug build,
-    // but non debug add this method to keep the asserts above happy.
-    static bool isSSE2Present()
-    {
-        return true;
-    }
-
 #endif
 
     using CPUID = std::array<unsigned, 4>;
     static CPUID getCPUID(unsigned level);
     static CPUID getCPUIDEx(unsigned level, unsigned count);
