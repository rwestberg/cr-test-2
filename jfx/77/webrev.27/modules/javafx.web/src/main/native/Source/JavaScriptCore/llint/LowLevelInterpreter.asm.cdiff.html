<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.asm</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="LLIntThunks.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.asm</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,6 ***</span>
<span class="line-modified">! # Copyright (C) 2011-2019 Apple Inc. All rights reserved.</span>
  #
  # Redistribution and use in source and binary forms, with or without
  # modification, are permitted provided that the following conditions
  # are met:
  # 1. Redistributions of source code must retain the above copyright
<span class="line-new-header">--- 1,6 ---</span>
<span class="line-modified">! # Copyrsght (C) 2011-2019 Apple Inc. All rights reserved.</span>
  #
  # Redistribution and use in source and binary forms, with or without
  # modification, are permitted provided that the following conditions
  # are met:
  # 1. Redistributions of source code must retain the above copyright
</pre>
<hr />
<pre>
<span class="line-old-header">*** 74,11 ***</span>
  #  - lr is defined on non-X86 architectures (ARM64, ARM64E, ARMv7, MIPS and CLOOP)
  #  and holds the return PC
  #
  #  - pc holds the (native) program counter on 32-bits ARM architectures (ARMv7)
  #
<span class="line-modified">! #  - t0, t1, t2, t3, t4 and optionally t5 are temporary registers that can get trashed on</span>
  #  calls, and are pairwise distinct registers. t4 holds the JS program counter, so use
  #  with caution in opcodes (actually, don&#39;t use it in opcodes at all, except as PC).
  #
  #  - r0 and r1 are the platform&#39;s customary return registers, and thus are
  #  two distinct registers
<span class="line-new-header">--- 74,11 ---</span>
  #  - lr is defined on non-X86 architectures (ARM64, ARM64E, ARMv7, MIPS and CLOOP)
  #  and holds the return PC
  #
  #  - pc holds the (native) program counter on 32-bits ARM architectures (ARMv7)
  #
<span class="line-modified">! #  - t0, t1, t2, t3, t4, and optionally t5, t6, and t7 are temporary registers that can get trashed on</span>
  #  calls, and are pairwise distinct registers. t4 holds the JS program counter, so use
  #  with caution in opcodes (actually, don&#39;t use it in opcodes at all, except as PC).
  #
  #  - r0 and r1 are the platform&#39;s customary return registers, and thus are
  #  two distinct registers
</pre>
<hr />
<pre>
<span class="line-old-header">*** 179,10 ***</span>
<span class="line-new-header">--- 179,13 ---</span>
  const ArgumentCount = Callee + SlotSize
  const ThisArgumentOffset = ArgumentCount + SlotSize
  const FirstArgumentOffset = ThisArgumentOffset + SlotSize
  const CallFrameHeaderSize = ThisArgumentOffset
  
<span class="line-added">+ const MetadataOffsetTable16Offset = 0</span>
<span class="line-added">+ const MetadataOffsetTable32Offset = constexpr UnlinkedMetadataTable::s_offset16TableSize</span>
<span class="line-added">+ </span>
  # Some value representation constants.
  if JSVALUE64
      const TagBitTypeOther = constexpr TagBitTypeOther
      const TagBitBool      = constexpr TagBitBool
      const TagBitUndefined = constexpr TagBitUndefined
</pre>
<hr />
<pre>
<span class="line-old-header">*** 213,11 ***</span>
  
  const maxFrameExtentForSlowPathCall = constexpr maxFrameExtentForSlowPathCall
  
  if X86_64 or X86_64_WIN or ARM64 or ARM64E
      const CalleeSaveSpaceAsVirtualRegisters = 4
<span class="line-modified">! elsif C_LOOP</span>
      const CalleeSaveSpaceAsVirtualRegisters = 1
  elsif ARMv7
      const CalleeSaveSpaceAsVirtualRegisters = 1
  elsif MIPS
      const CalleeSaveSpaceAsVirtualRegisters = 1
<span class="line-new-header">--- 216,11 ---</span>
  
  const maxFrameExtentForSlowPathCall = constexpr maxFrameExtentForSlowPathCall
  
  if X86_64 or X86_64_WIN or ARM64 or ARM64E
      const CalleeSaveSpaceAsVirtualRegisters = 4
<span class="line-modified">! elsif C_LOOP or C_LOOP_WIN</span>
      const CalleeSaveSpaceAsVirtualRegisters = 1
  elsif ARMv7
      const CalleeSaveSpaceAsVirtualRegisters = 1
  elsif MIPS
      const CalleeSaveSpaceAsVirtualRegisters = 1
</pre>
<hr />
<pre>
<span class="line-old-header">*** 272,20 ***</span>
      elsif X86_64_WIN
          const metadataTable = csr3
          const PB = csr4
          const tagTypeNumber = csr5
          const tagMask = csr6
<span class="line-modified">!     elsif C_LOOP</span>
          const PB = csr0
          const tagTypeNumber = csr1
          const tagMask = csr2
          const metadataTable = csr3
      end
  
  else
      const PC = t4 # When changing this, make sure LLIntPC is up to date in LLIntPCRanges.h
<span class="line-modified">!     if C_LOOP</span>
          const metadataTable = csr3
      elsif ARMv7
          const metadataTable = csr0
      elsif MIPS
          const metadataTable = csr0
<span class="line-new-header">--- 275,20 ---</span>
      elsif X86_64_WIN
          const metadataTable = csr3
          const PB = csr4
          const tagTypeNumber = csr5
          const tagMask = csr6
<span class="line-modified">!     elsif C_LOOP or C_LOOP_WIN</span>
          const PB = csr0
          const tagTypeNumber = csr1
          const tagMask = csr2
          const metadataTable = csr3
      end
  
  else
      const PC = t4 # When changing this, make sure LLIntPC is up to date in LLIntPCRanges.h
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN</span>
          const metadataTable = csr3
      elsif ARMv7
          const metadataTable = csr0
      elsif MIPS
          const metadataTable = csr0
</pre>
<hr />
<pre>
<span class="line-old-header">*** 306,39 ***</span>
  macro dispatchOp(size, opcodeName)
      macro dispatchNarrow()
          dispatch(constexpr %opcodeName%_length)
      end
  
<span class="line-modified">!     macro dispatchWide()</span>
          dispatch(constexpr %opcodeName%_length * 4 + 1)
      end
  
<span class="line-modified">!     size(dispatchNarrow, dispatchWide, macro (dispatch) dispatch() end)</span>
  end
  
  macro getu(size, opcodeStruct, fieldName, dst)
<span class="line-modified">!     size(getuOperandNarrow, getuOperandWide, macro (getu)</span>
          getu(opcodeStruct, fieldName, dst)
      end)
  end
  
  macro get(size, opcodeStruct, fieldName, dst)
<span class="line-modified">!     size(getOperandNarrow, getOperandWide, macro (get)</span>
          get(opcodeStruct, fieldName, dst)
      end)
  end
  
<span class="line-modified">! macro narrow(narrowFn, wideFn, k)</span>
      k(narrowFn)
  end
  
<span class="line-modified">! macro wide(narrowFn, wideFn, k)</span>
<span class="line-modified">!     k(wideFn)</span>
  end
  
  macro metadata(size, opcode, dst, scratch)
<span class="line-modified">!     loadi constexpr %opcode%::opcodeID * 4[metadataTable], dst # offset = metadataTable&lt;unsigned*&gt;[opcodeID]</span>
      getu(size, opcode, m_metadataID, scratch) # scratch = bytecode.m_metadataID
      muli sizeof %opcode%::Metadata, scratch # scratch *= sizeof(Op::Metadata)
      addi scratch, dst # offset += scratch
      addp metadataTable, dst # return &amp;metadataTable[offset]
  end
<span class="line-new-header">--- 309,50 ---</span>
  macro dispatchOp(size, opcodeName)
      macro dispatchNarrow()
          dispatch(constexpr %opcodeName%_length)
      end
  
<span class="line-modified">!     macro dispatchWide16()</span>
<span class="line-added">+         dispatch(constexpr %opcodeName%_length * 2 + 1)</span>
<span class="line-added">+     end</span>
<span class="line-added">+ </span>
<span class="line-added">+     macro dispatchWide32()</span>
          dispatch(constexpr %opcodeName%_length * 4 + 1)
      end
  
<span class="line-modified">!     size(dispatchNarrow, dispatchWide16, dispatchWide32, macro (dispatch) dispatch() end)</span>
  end
  
  macro getu(size, opcodeStruct, fieldName, dst)
<span class="line-modified">!     size(getuOperandNarrow, getuOperandWide16, getuOperandWide32, macro (getu)</span>
          getu(opcodeStruct, fieldName, dst)
      end)
  end
  
  macro get(size, opcodeStruct, fieldName, dst)
<span class="line-modified">!     size(getOperandNarrow, getOperandWide16, getOperandWide32, macro (get)</span>
          get(opcodeStruct, fieldName, dst)
      end)
  end
  
<span class="line-modified">! macro narrow(narrowFn, wide16Fn, wide32Fn, k)</span>
      k(narrowFn)
  end
  
<span class="line-modified">! macro wide16(narrowFn, wide16Fn, wide32Fn, k)</span>
<span class="line-modified">!     k(wide16Fn)</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ macro wide32(narrowFn, wide16Fn, wide32Fn, k)</span>
<span class="line-added">+     k(wide32Fn)</span>
  end
  
  macro metadata(size, opcode, dst, scratch)
<span class="line-modified">!     loadh (constexpr %opcode%::opcodeID * 2 + MetadataOffsetTable16Offset)[metadataTable], dst # offset = metadataTable&lt;uint16_t*&gt;[opcodeID]</span>
<span class="line-added">+     btinz dst, .setUpOffset</span>
<span class="line-added">+     loadi (constexpr %opcode%::opcodeID * 4 + MetadataOffsetTable32Offset)[metadataTable], dst # offset = metadataTable&lt;uint32_t*&gt;[opcodeID]</span>
<span class="line-added">+ .setUpOffset:</span>
      getu(size, opcode, m_metadataID, scratch) # scratch = bytecode.m_metadataID
      muli sizeof %opcode%::Metadata, scratch # scratch *= sizeof(Op::Metadata)
      addi scratch, dst # offset += scratch
      addp metadataTable, dst # return &amp;metadataTable[offset]
  end
</pre>
<hr />
<pre>
<span class="line-old-header">*** 354,18 ***</span>
  macro commonOp(label, prologue, fn)
  _%label%:
      prologue()
      fn(narrow)
  
<span class="line-modified">! _%label%_wide:</span>
      prologue()
<span class="line-modified">!     fn(wide)</span>
  end
  
  macro op(l, fn)
<span class="line-modified">!     commonOp(l, macro () end, macro (unused)</span>
<span class="line-modified">!         fn()</span>
      end)
  end
  
  macro llintOp(opcodeName, opcodeStruct, fn)
      commonOp(llint_%opcodeName%, traceExecution, macro(size)
<span class="line-new-header">--- 368,28 ---</span>
  macro commonOp(label, prologue, fn)
  _%label%:
      prologue()
      fn(narrow)
  
<span class="line-modified">! # FIXME: We cannot enable wide16 bytecode in Windows CLoop. With MSVC, as CLoop::execute gets larger code</span>
<span class="line-added">+ # size, CLoop::execute gets higher stack height requirement. This makes CLoop::execute takes 160KB stack</span>
<span class="line-added">+ # per call, causes stack overflow error easily. For now, we disable wide16 optimization for Windows CLoop.</span>
<span class="line-added">+ # https://bugs.webkit.org/show_bug.cgi?id=198283</span>
<span class="line-added">+ if not C_LOOP_WIN</span>
<span class="line-added">+ _%label%_wide16:</span>
      prologue()
<span class="line-modified">!     fn(wide16)</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ _%label%_wide32:</span>
<span class="line-added">+     prologue()</span>
<span class="line-added">+     fn(wide32)</span>
  end
  
  macro op(l, fn)
<span class="line-modified">!     commonOp(l, macro () end, macro (size)</span>
<span class="line-modified">!         size(fn, macro() end, macro() end, macro(gen) gen() end)</span>
      end)
  end
  
  macro llintOp(opcodeName, opcodeStruct, fn)
      commonOp(llint_%opcodeName%, traceExecution, macro(size)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 467,12 ***</span>
  # Type flags constants.
  const MasqueradesAsUndefined = constexpr MasqueradesAsUndefined
  const ImplementsDefaultHasInstance = constexpr ImplementsDefaultHasInstance
  
  # Bytecode operand constants.
<span class="line-modified">! const FirstConstantRegisterIndexNarrow = 16</span>
<span class="line-modified">! const FirstConstantRegisterIndexWide = constexpr FirstConstantRegisterIndex</span>
  
  # Code type constants.
  const GlobalCode = constexpr GlobalCode
  const EvalCode = constexpr EvalCode
  const FunctionCode = constexpr FunctionCode
<span class="line-new-header">--- 491,13 ---</span>
  # Type flags constants.
  const MasqueradesAsUndefined = constexpr MasqueradesAsUndefined
  const ImplementsDefaultHasInstance = constexpr ImplementsDefaultHasInstance
  
  # Bytecode operand constants.
<span class="line-modified">! const FirstConstantRegisterIndexNarrow = constexpr FirstConstantRegisterIndex8</span>
<span class="line-modified">! const FirstConstantRegisterIndexWide16 = constexpr FirstConstantRegisterIndex16</span>
<span class="line-added">+ const FirstConstantRegisterIndexWide32 = constexpr FirstConstantRegisterIndex</span>
  
  # Code type constants.
  const GlobalCode = constexpr GlobalCode
  const EvalCode = constexpr EvalCode
  const FunctionCode = constexpr FunctionCode
</pre>
<hr />
<pre>
<span class="line-old-header">*** 514,11 ***</span>
  const VectorBufferOffset = Vector::m_buffer
  const VectorSizeOffset = Vector::m_size
  
  # Some common utilities.
  macro crash()
<span class="line-modified">!     if C_LOOP</span>
          cloopCrash
      else
          call _llint_crash
      end
  end
<span class="line-new-header">--- 539,11 ---</span>
  const VectorBufferOffset = Vector::m_buffer
  const VectorSizeOffset = Vector::m_size
  
  # Some common utilities.
  macro crash()
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN</span>
          cloopCrash
      else
          call _llint_crash
      end
  end
</pre>
<hr />
<pre>
<span class="line-old-header">*** 597,13 ***</span>
      end
  end
  
  macro checkStackPointerAlignment(tempReg, location)
      if ASSERT_ENABLED
<span class="line-modified">!         if ARM64 or ARM64E or C_LOOP</span>
              # ARM64 and ARM64E will check for us!
<span class="line-modified">!             # C_LOOP does not need the alignment, and can use a little perf</span>
              # improvement from avoiding useless work.
          else
              if ARMv7
                  # ARM can&#39;t do logical ops with the sp as a source
                  move sp, tempReg
<span class="line-new-header">--- 622,13 ---</span>
      end
  end
  
  macro checkStackPointerAlignment(tempReg, location)
      if ASSERT_ENABLED
<span class="line-modified">!         if ARM64 or ARM64E or C_LOOP or C_LOOP_WIN</span>
              # ARM64 and ARM64E will check for us!
<span class="line-modified">!             # C_LOOP or C_LOOP_WIN does not need the alignment, and can use a little perf</span>
              # improvement from avoiding useless work.
          else
              if ARMv7
                  # ARM can&#39;t do logical ops with the sp as a source
                  move sp, tempReg
</pre>
<hr />
<pre>
<span class="line-old-header">*** 617,11 ***</span>
          .stackPointerOkay:
          end
      end
  end
  
<span class="line-modified">! if C_LOOP or ARM64 or ARM64E or X86_64 or X86_64_WIN</span>
      const CalleeSaveRegisterCount = 0
  elsif ARMv7
      const CalleeSaveRegisterCount = 7
  elsif MIPS
      const CalleeSaveRegisterCount = 2
<span class="line-new-header">--- 642,11 ---</span>
          .stackPointerOkay:
          end
      end
  end
  
<span class="line-modified">! if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN</span>
      const CalleeSaveRegisterCount = 0
  elsif ARMv7
      const CalleeSaveRegisterCount = 7
  elsif MIPS
      const CalleeSaveRegisterCount = 2
</pre>
<hr />
<pre>
<span class="line-old-header">*** 634,11 ***</span>
  # VMEntryTotalFrameSize includes the space for struct VMEntryRecord and the
  # callee save registers rounded up to keep the stack aligned
  const VMEntryTotalFrameSize = (CalleeRegisterSaveSize + sizeof VMEntryRecord + StackAlignment - 1) &amp; ~StackAlignmentMask
  
  macro pushCalleeSaves()
<span class="line-modified">!     if C_LOOP or ARM64 or ARM64E or X86_64 or X86_64_WIN</span>
      elsif ARMv7
          emit &quot;push {r4-r6, r8-r11}&quot;
      elsif MIPS
          emit &quot;addiu $sp, $sp, -8&quot;
          emit &quot;sw $s0, 0($sp)&quot; # csr0/metaData
<span class="line-new-header">--- 659,11 ---</span>
  # VMEntryTotalFrameSize includes the space for struct VMEntryRecord and the
  # callee save registers rounded up to keep the stack aligned
  const VMEntryTotalFrameSize = (CalleeRegisterSaveSize + sizeof VMEntryRecord + StackAlignment - 1) &amp; ~StackAlignmentMask
  
  macro pushCalleeSaves()
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN</span>
      elsif ARMv7
          emit &quot;push {r4-r6, r8-r11}&quot;
      elsif MIPS
          emit &quot;addiu $sp, $sp, -8&quot;
          emit &quot;sw $s0, 0($sp)&quot; # csr0/metaData
</pre>
<hr />
<pre>
<span class="line-old-header">*** 655,11 ***</span>
          emit &quot;push ebx&quot;
      end
  end
  
  macro popCalleeSaves()
<span class="line-modified">!     if C_LOOP or ARM64 or ARM64E or X86_64 or X86_64_WIN</span>
      elsif ARMv7
          emit &quot;pop {r4-r6, r8-r11}&quot;
      elsif MIPS
          emit &quot;lw $s0, 0($sp)&quot;
          emit &quot;lw $s4, 4($sp)&quot;
<span class="line-new-header">--- 680,11 ---</span>
          emit &quot;push ebx&quot;
      end
  end
  
  macro popCalleeSaves()
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN or ARM64 or ARM64E or X86_64 or X86_64_WIN</span>
      elsif ARMv7
          emit &quot;pop {r4-r6, r8-r11}&quot;
      elsif MIPS
          emit &quot;lw $s0, 0($sp)&quot;
          emit &quot;lw $s4, 4($sp)&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 674,11 ***</span>
          emit &quot;pop esi&quot;
      end
  end
  
  macro preserveCallerPCAndCFR()
<span class="line-modified">!     if C_LOOP or ARMv7 or MIPS</span>
          push lr
          push cfr
      elsif X86 or X86_WIN or X86_64 or X86_64_WIN
          push cfr
      elsif ARM64 or ARM64E
<span class="line-new-header">--- 699,11 ---</span>
          emit &quot;pop esi&quot;
      end
  end
  
  macro preserveCallerPCAndCFR()
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN or ARMv7 or MIPS</span>
          push lr
          push cfr
      elsif X86 or X86_WIN or X86_64 or X86_64_WIN
          push cfr
      elsif ARM64 or ARM64E
</pre>
<hr />
<pre>
<span class="line-old-header">*** 689,11 ***</span>
      move sp, cfr
  end
  
  macro restoreCallerPCAndCFR()
      move cfr, sp
<span class="line-modified">!     if C_LOOP or ARMv7 or MIPS</span>
          pop cfr
          pop lr
      elsif X86 or X86_WIN or X86_64 or X86_64_WIN
          pop cfr
      elsif ARM64 or ARM64E
<span class="line-new-header">--- 714,11 ---</span>
      move sp, cfr
  end
  
  macro restoreCallerPCAndCFR()
      move cfr, sp
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN or ARMv7 or MIPS</span>
          pop cfr
          pop lr
      elsif X86 or X86_WIN or X86_64 or X86_64_WIN
          pop cfr
      elsif ARM64 or ARM64E
</pre>
<hr />
<pre>
<span class="line-old-header">*** 701,11 ***</span>
      end
  end
  
  macro preserveCalleeSavesUsedByLLInt()
      subp CalleeSaveSpaceStackAligned, sp
<span class="line-modified">!     if C_LOOP</span>
          storep metadataTable, -PtrSize[cfr]
      elsif ARMv7 or MIPS
          storep metadataTable, -4[cfr]
      elsif ARM64 or ARM64E
          emit &quot;stp x27, x28, [x29, #-16]&quot;
<span class="line-new-header">--- 726,11 ---</span>
      end
  end
  
  macro preserveCalleeSavesUsedByLLInt()
      subp CalleeSaveSpaceStackAligned, sp
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN</span>
          storep metadataTable, -PtrSize[cfr]
      elsif ARMv7 or MIPS
          storep metadataTable, -4[cfr]
      elsif ARM64 or ARM64E
          emit &quot;stp x27, x28, [x29, #-16]&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 724,11 ***</span>
          storep csr3, -32[cfr]
      end
  end
  
  macro restoreCalleeSavesUsedByLLInt()
<span class="line-modified">!     if C_LOOP</span>
          loadp -PtrSize[cfr], metadataTable
      elsif ARMv7 or MIPS
          loadp -4[cfr], metadataTable
      elsif ARM64 or ARM64E
          emit &quot;ldp x25, x26, [x29, #-32]&quot;
<span class="line-new-header">--- 749,11 ---</span>
          storep csr3, -32[cfr]
      end
  end
  
  macro restoreCalleeSavesUsedByLLInt()
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN</span>
          loadp -PtrSize[cfr], metadataTable
      elsif ARMv7 or MIPS
          loadp -4[cfr], metadataTable
      elsif ARM64 or ARM64E
          emit &quot;ldp x25, x26, [x29, #-32]&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 835,12 ***</span>
          end
      end
  end
  
  macro preserveReturnAddressAfterCall(destinationRegister)
<span class="line-modified">!     if C_LOOP or ARMv7 or ARM64 or ARM64E or MIPS</span>
<span class="line-modified">!         # In C_LOOP case, we&#39;re only preserving the bytecode vPC.</span>
          move lr, destinationRegister
      elsif X86 or X86_WIN or X86_64 or X86_64_WIN
          pop destinationRegister
      else
          error
<span class="line-new-header">--- 860,12 ---</span>
          end
      end
  end
  
  macro preserveReturnAddressAfterCall(destinationRegister)
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN or ARMv7 or ARM64 or ARM64E or MIPS</span>
<span class="line-modified">!         # In C_LOOP or C_LOOP_WIN case, we&#39;re only preserving the bytecode vPC.</span>
          move lr, destinationRegister
      elsif X86 or X86_WIN or X86_64 or X86_64_WIN
          pop destinationRegister
      else
          error
</pre>
<hr />
<pre>
<span class="line-old-header">*** 851,11 ***</span>
      tagReturnAddress sp
      if X86 or X86_WIN or X86_64 or X86_64_WIN
          push cfr
      elsif ARM64 or ARM64E
          push cfr, lr
<span class="line-modified">!     elsif C_LOOP or ARMv7 or MIPS</span>
          push lr
          push cfr
      end
      move sp, cfr
  end
<span class="line-new-header">--- 876,11 ---</span>
      tagReturnAddress sp
      if X86 or X86_WIN or X86_64 or X86_64_WIN
          push cfr
      elsif ARM64 or ARM64E
          push cfr, lr
<span class="line-modified">!     elsif C_LOOP or C_LOOP_WIN or ARMv7 or MIPS</span>
          push lr
          push cfr
      end
      move sp, cfr
  end
</pre>
<hr />
<pre>
<span class="line-old-header">*** 863,11 ***</span>
  macro functionEpilogue()
      if X86 or X86_WIN or X86_64 or X86_64_WIN
          pop cfr
      elsif ARM64 or ARM64E
          pop lr, cfr
<span class="line-modified">!     elsif C_LOOP or ARMv7 or MIPS</span>
          pop cfr
          pop lr
      end
  end
  
<span class="line-new-header">--- 888,11 ---</span>
  macro functionEpilogue()
      if X86 or X86_WIN or X86_64 or X86_64_WIN
          pop cfr
      elsif ARM64 or ARM64E
          pop lr, cfr
<span class="line-modified">!     elsif C_LOOP or C_LOOP_WIN or ARMv7 or MIPS</span>
          pop cfr
          pop lr
      end
  end
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 897,11 ***</span>
          callSlowPath(_llint_trace)
      end
  end
  
  macro callTargetFunction(size, opcodeStruct, dispatch, callee, callPtrTag)
<span class="line-modified">!     if C_LOOP</span>
          cloopCallJSFunction callee
      else
          call callee, callPtrTag
      end
      restoreStackPointerAfterCall()
<span class="line-new-header">--- 922,11 ---</span>
          callSlowPath(_llint_trace)
      end
  end
  
  macro callTargetFunction(size, opcodeStruct, dispatch, callee, callPtrTag)
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN</span>
          cloopCallJSFunction callee
      else
          call callee, callPtrTag
      end
      restoreStackPointerAfterCall()
</pre>
<hr />
<pre>
<span class="line-old-header">*** 935,22 ***</span>
      # We assume &lt; 2^28 arguments
      muli SlotSize, temp2
      addi StackAlignment - 1 + CallFrameHeaderSize, temp2
      andi ~StackAlignmentMask, temp2
  
<span class="line-modified">!     if ARMv7 or ARM64 or ARM64E or C_LOOP or MIPS</span>
          addp CallerFrameAndPCSize, sp
          subi CallerFrameAndPCSize, temp2
          loadp CallerFrameAndPC::returnPC[cfr], lr
      else
          addp PtrSize, sp
          subi PtrSize, temp2
          loadp PtrSize[cfr], temp3
          storep temp3, [sp]
      end
  
<span class="line-modified">!     if POINTER_PROFILING</span>
          addp 16, cfr, temp3
          untagReturnAddress temp3
      end
  
      subp temp2, temp1
<span class="line-new-header">--- 960,22 ---</span>
      # We assume &lt; 2^28 arguments
      muli SlotSize, temp2
      addi StackAlignment - 1 + CallFrameHeaderSize, temp2
      andi ~StackAlignmentMask, temp2
  
<span class="line-modified">!     if ARMv7 or ARM64 or ARM64E or C_LOOP or C_LOOP_WIN or MIPS</span>
          addp CallerFrameAndPCSize, sp
          subi CallerFrameAndPCSize, temp2
          loadp CallerFrameAndPC::returnPC[cfr], lr
      else
          addp PtrSize, sp
          subi PtrSize, temp2
          loadp PtrSize[cfr], temp3
          storep temp3, [sp]
      end
  
<span class="line-modified">!     if ARM64E</span>
          addp 16, cfr, temp3
          untagReturnAddress temp3
      end
  
      subp temp2, temp1
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1019,11 ***</span>
              callSlowPath(_llint_replace)
          end)
  end
  
  macro assertNotConstant(size, index)
<span class="line-modified">!     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide, macro (FirstConstantRegisterIndex)</span>
          assert(macro (ok) bilt index, FirstConstantRegisterIndex, ok end)
      end)
  end
  
  macro functionForCallCodeBlockGetter(targetRegister)
<span class="line-new-header">--- 1044,11 ---</span>
              callSlowPath(_llint_replace)
          end)
  end
  
  macro assertNotConstant(size, index)
<span class="line-modified">!     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)</span>
          assert(macro (ok) bilt index, FirstConstantRegisterIndex, ok end)
      end)
  end
  
  macro functionForCallCodeBlockGetter(targetRegister)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1071,11 ***</span>
          subp maxFrameExtentForSlowPathCall, sp
          callSlowPath(traceSlowPath)
          addp maxFrameExtentForSlowPathCall, sp
      end
      codeBlockGetter(t1)
<span class="line-modified">!     if not C_LOOP</span>
          baddis 5, CodeBlock::m_llintExecuteCounter + BaselineExecutionCounter::m_counter[t1], .continue
          if JSVALUE64
              move cfr, a0
              move PC, a1
              cCall2(osrSlowPath)
<span class="line-new-header">--- 1096,11 ---</span>
          subp maxFrameExtentForSlowPathCall, sp
          callSlowPath(traceSlowPath)
          addp maxFrameExtentForSlowPathCall, sp
      end
      codeBlockGetter(t1)
<span class="line-modified">!     if not (C_LOOP or C_LOOP_WIN)</span>
          baddis 5, CodeBlock::m_llintExecuteCounter + BaselineExecutionCounter::m_counter[t1], .continue
          if JSVALUE64
              move cfr, a0
              move PC, a1
              cCall2(osrSlowPath)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1121,11 ***</span>
      # Get new sp in t0 and check stack height.
      getFrameRegisterSizeForCodeBlock(t1, t0)
      subp cfr, t0, t0
      bpa t0, cfr, .needStackCheck
      loadp CodeBlock::m_vm[t1], t2
<span class="line-modified">!     if C_LOOP</span>
          bpbeq VM::m_cloopStackLimit[t2], t0, .stackHeightOK
      else
          bpbeq VM::m_softStackLimit[t2], t0, .stackHeightOK
      end
  
<span class="line-new-header">--- 1146,11 ---</span>
      # Get new sp in t0 and check stack height.
      getFrameRegisterSizeForCodeBlock(t1, t0)
      subp cfr, t0, t0
      bpa t0, cfr, .needStackCheck
      loadp CodeBlock::m_vm[t1], t2
<span class="line-modified">!     if C_LOOP or C_LOOP_WIN</span>
          bpbeq VM::m_cloopStackLimit[t2], t0, .stackHeightOK
      else
          bpbeq VM::m_softStackLimit[t2], t0, .stackHeightOK
      end
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1224,29 ***</span>
  
  # stub to call into JavaScript or Native functions
  # EncodedJSValue vmEntryToJavaScript(void* code, VM* vm, ProtoCallFrame* protoFrame)
  # EncodedJSValue vmEntryToNativeFunction(void* code, VM* vm, ProtoCallFrame* protoFrame)
  
<span class="line-modified">! if C_LOOP</span>
      _llint_vm_entry_to_javascript:
  else
      global _vmEntryToJavaScript
      _vmEntryToJavaScript:
  end
      doVMEntry(makeJavaScriptCall)
  
  
<span class="line-modified">! if C_LOOP</span>
      _llint_vm_entry_to_native:
  else
      global _vmEntryToNative
      _vmEntryToNative:
  end
      doVMEntry(makeHostFunctionCall)
  
  
<span class="line-modified">! if not C_LOOP</span>
      # void sanitizeStackForVMImpl(VM* vm)
      global _sanitizeStackForVMImpl
      _sanitizeStackForVMImpl:
          tagReturnAddress sp
          # We need three non-aliased caller-save registers. We are guaranteed
<span class="line-new-header">--- 1249,29 ---</span>
  
  # stub to call into JavaScript or Native functions
  # EncodedJSValue vmEntryToJavaScript(void* code, VM* vm, ProtoCallFrame* protoFrame)
  # EncodedJSValue vmEntryToNativeFunction(void* code, VM* vm, ProtoCallFrame* protoFrame)
  
<span class="line-modified">! if C_LOOP or C_LOOP_WIN</span>
      _llint_vm_entry_to_javascript:
  else
      global _vmEntryToJavaScript
      _vmEntryToJavaScript:
  end
      doVMEntry(makeJavaScriptCall)
  
  
<span class="line-modified">! if C_LOOP or C_LOOP_WIN</span>
      _llint_vm_entry_to_native:
  else
      global _vmEntryToNative
      _vmEntryToNative:
  end
      doVMEntry(makeHostFunctionCall)
  
  
<span class="line-modified">! if not (C_LOOP or C_LOOP_WIN)</span>
      # void sanitizeStackForVMImpl(VM* vm)
      global _sanitizeStackForVMImpl
      _sanitizeStackForVMImpl:
          tagReturnAddress sp
          # We need three non-aliased caller-save registers. We are guaranteed
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1282,11 ***</span>
  
          vmEntryRecord(a0, r0)
          ret
  end
  
<span class="line-modified">! if C_LOOP</span>
      # Dummy entry point the C Loop uses to initialize.
      _llint_entry:
          crash()
  else
      macro initPCRelative(pcBase)
<span class="line-new-header">--- 1307,11 ---</span>
  
          vmEntryRecord(a0, r0)
          ret
  end
  
<span class="line-modified">! if C_LOOP or C_LOOP_WIN</span>
      # Dummy entry point the C Loop uses to initialize.
      _llint_entry:
          crash()
  else
      macro initPCRelative(pcBase)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1304,45 ***</span>
              setcallreg pcBase # needed to set $t9 to the right value for the .cpload created by the label.
          _relativePCBase:
          end
  end
  
<span class="line-modified">! # The PC base is in t2, as this is what _llint_entry leaves behind through</span>
<span class="line-modified">! # initPCRelative(t2)</span>
  macro setEntryAddress(index, label)
      setEntryAddressCommon(index, label, a0)
  end
  
<span class="line-modified">! macro setEntryAddressWide(index, label)</span>
       setEntryAddressCommon(index, label, a1)
  end
  
  macro setEntryAddressCommon(index, label, map)
<span class="line-modified">!     if X86_64 or X86_64_WIN</span>
<span class="line-modified">!         leap (label - _relativePCBase)[t2], t3</span>
<span class="line-modified">!         move index, t4</span>
<span class="line-modified">!         storep t3, [map, t4, 8]</span>
      elsif X86 or X86_WIN
<span class="line-modified">!         leap (label - _relativePCBase)[t2], t3</span>
<span class="line-modified">!         move index, t4</span>
<span class="line-modified">!         storep t3, [map, t4, 4]</span>
      elsif ARM64 or ARM64E
<span class="line-modified">!         pcrtoaddr label, t2</span>
          move index, t4
<span class="line-modified">!         storep t2, [map, t4, PtrSize]</span>
      elsif ARMv7
          mvlbl (label - _relativePCBase), t4
<span class="line-modified">!         addp t4, t2, t4</span>
<span class="line-modified">!         move index, t3</span>
<span class="line-modified">!         storep t4, [map, t3, 4]</span>
      elsif MIPS
          la label, t4
          la _relativePCBase, t3
          subp t3, t4
<span class="line-modified">!         addp t4, t2, t4</span>
<span class="line-modified">!         move index, t3</span>
<span class="line-modified">!         storep t4, [map, t3, 4]</span>
      end
  end
  
  global _llint_entry
  # Entry point for the llint to initialize.
<span class="line-new-header">--- 1329,53 ---</span>
              setcallreg pcBase # needed to set $t9 to the right value for the .cpload created by the label.
          _relativePCBase:
          end
  end
  
<span class="line-modified">! # The PC base is in t3, as this is what _llint_entry leaves behind through</span>
<span class="line-modified">! # initPCRelative(t3)</span>
  macro setEntryAddress(index, label)
      setEntryAddressCommon(index, label, a0)
  end
  
<span class="line-modified">! macro setEntryAddressWide16(index, label)</span>
       setEntryAddressCommon(index, label, a1)
  end
  
<span class="line-added">+ macro setEntryAddressWide32(index, label)</span>
<span class="line-added">+      setEntryAddressCommon(index, label, a2)</span>
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
  macro setEntryAddressCommon(index, label, map)
<span class="line-modified">!     if X86_64</span>
<span class="line-modified">!         leap (label - _relativePCBase)[t3], t4</span>
<span class="line-modified">!         move index, t5</span>
<span class="line-modified">!         storep t4, [map, t5, 8]</span>
<span class="line-added">+     elsif X86_64_WIN</span>
<span class="line-added">+         leap (label - _relativePCBase)[t3], t4</span>
<span class="line-added">+         move index, t0</span>
<span class="line-added">+         storep t4, [map, t0, 8]</span>
      elsif X86 or X86_WIN
<span class="line-modified">!         leap (label - _relativePCBase)[t3], t4</span>
<span class="line-modified">!         move index, t5</span>
<span class="line-modified">!         storep t4, [map, t5, 4]</span>
      elsif ARM64 or ARM64E
<span class="line-modified">!         pcrtoaddr label, t3</span>
          move index, t4
<span class="line-modified">!         storep t3, [map, t4, PtrSize]</span>
      elsif ARMv7
          mvlbl (label - _relativePCBase), t4
<span class="line-modified">!         addp t4, t3, t4</span>
<span class="line-modified">!         move index, t5</span>
<span class="line-modified">!         storep t4, [map, t5, 4]</span>
      elsif MIPS
          la label, t4
          la _relativePCBase, t3
          subp t3, t4
<span class="line-modified">!         addp t4, t3, t4</span>
<span class="line-modified">!         move index, t5</span>
<span class="line-modified">!         storep t4, [map, t5, 4]</span>
      end
  end
  
  global _llint_entry
  # Entry point for the llint to initialize.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1350,30 ***</span>
      functionPrologue()
      pushCalleeSaves()
      if X86 or X86_WIN
          loadp 20[sp], a0
          loadp 24[sp], a1
      end
  
<span class="line-modified">!     initPCRelative(t2)</span>
  
      # Include generated bytecode initialization file.
      include InitBytecodes
  
      popCalleeSaves()
      functionEpilogue()
      ret
  end
  
<span class="line-modified">! _llint_op_wide:</span>
<span class="line-modified">!     nextInstructionWide()</span>
  
<span class="line-modified">! _llint_op_wide_wide:</span>
      crash()
  
<span class="line-modified">! _llint_op_enter_wide:</span>
      crash()
  
  op(llint_program_prologue, macro ()
      prologue(notFunctionCodeBlockGetter, notFunctionCodeBlockSetter, _llint_entry_osr, _llint_trace_prologue)
      dispatch(0)
  end)
<span class="line-new-header">--- 1383,40 ---</span>
      functionPrologue()
      pushCalleeSaves()
      if X86 or X86_WIN
          loadp 20[sp], a0
          loadp 24[sp], a1
<span class="line-added">+         loadp 28[sp], a2</span>
      end
  
<span class="line-modified">!     initPCRelative(t3)</span>
  
      # Include generated bytecode initialization file.
      include InitBytecodes
  
      popCalleeSaves()
      functionEpilogue()
      ret
  end
  
<span class="line-modified">! _llint_op_wide16:</span>
<span class="line-modified">!     nextInstructionWide16()</span>
  
<span class="line-modified">! _llint_op_wide32:</span>
<span class="line-added">+     nextInstructionWide32()</span>
<span class="line-added">+ </span>
<span class="line-added">+ macro noWide(label)</span>
<span class="line-added">+ _llint_%label%_wide16:</span>
      crash()
  
<span class="line-modified">! _llint_%label%_wide32:</span>
      crash()
<span class="line-added">+ end</span>
<span class="line-added">+ </span>
<span class="line-added">+ noWide(op_wide16)</span>
<span class="line-added">+ noWide(op_wide32)</span>
<span class="line-added">+ noWide(op_enter)</span>
  
  op(llint_program_prologue, macro ()
      prologue(notFunctionCodeBlockGetter, notFunctionCodeBlockSetter, _llint_entry_osr, _llint_trace_prologue)
      dispatch(0)
  end)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1626,27 ***</span>
  preOp(dec, OpDec,
      macro (value, slow) bsubio 1, value, slow end)
  
  
  llintOp(op_loop_hint, OpLoopHint, macro (unused, unused, dispatch)
<span class="line-modified">!     checkSwitchToJITForLoop()</span>
<span class="line-removed">-     dispatch()</span>
<span class="line-removed">- end)</span>
<span class="line-removed">- </span>
<span class="line-removed">- </span>
<span class="line-removed">- llintOp(op_check_traps, OpCheckTraps, macro (unused, unused, dispatch)</span>
      loadp CodeBlock[cfr], t1
      loadp CodeBlock::m_vm[t1], t1
<span class="line-modified">!     loadb VM::m_traps+VMTraps::m_needTrapHandling[t1], t0</span>
<span class="line-removed">-     btpnz t0, .handleTraps</span>
  .afterHandlingTraps:
      dispatch()
  .handleTraps:
<span class="line-modified">!     callTrapHandler(.throwHandler)</span>
      jmp .afterHandlingTraps
<span class="line-removed">- .throwHandler:</span>
<span class="line-removed">-     jmp _llint_throw_from_slow_path_trampoline</span>
  end)
  
  
  # Returns the packet pointer in t0.
  macro acquireShadowChickenPacket(slow)
<span class="line-new-header">--- 1669,20 ---</span>
  preOp(dec, OpDec,
      macro (value, slow) bsubio 1, value, slow end)
  
  
  llintOp(op_loop_hint, OpLoopHint, macro (unused, unused, dispatch)
<span class="line-modified">!     # CheckTraps.</span>
      loadp CodeBlock[cfr], t1
      loadp CodeBlock::m_vm[t1], t1
<span class="line-modified">!     btbnz VM::m_traps + VMTraps::m_needTrapHandling[t1], .handleTraps</span>
  .afterHandlingTraps:
<span class="line-added">+     checkSwitchToJITForLoop()</span>
      dispatch()
  .handleTraps:
<span class="line-modified">!     callTrapHandler(_llint_throw_from_slow_path_trampoline)</span>
      jmp .afterHandlingTraps
  end)
  
  
  # Returns the packet pointer in t0.
  macro acquireShadowChickenPacket(slow)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1770,27 ***</span>
          OpCallEval,
          macro () dispatchOp(narrow, op_call_eval) end,
          _llint_slow_path_call_eval,
          prepareForRegularCall)
  
<span class="line-modified">! _llint_op_call_eval_wide:</span>
      slowPathForCall(
<span class="line-modified">!         wide,</span>
          OpCallEval,
<span class="line-modified">!         macro () dispatchOp(wide, op_call_eval) end,</span>
<span class="line-modified">!         _llint_slow_path_call_eval_wide,</span>
          prepareForRegularCall)
  
<span class="line-removed">- _llint_generic_return_point:</span>
<span class="line-removed">-     dispatchAfterCall(narrow, OpCallEval, macro ()</span>
<span class="line-removed">-         dispatchOp(narrow, op_call_eval)</span>
<span class="line-removed">-     end)</span>
  
<span class="line-modified">! _llint_generic_return_point_wide:</span>
<span class="line-modified">!     dispatchAfterCall(wide, OpCallEval, macro()</span>
<span class="line-modified">!         dispatchOp(wide, op_call_eval)</span>
      end)
  
  llintOp(op_identity_with_profile, OpIdentityWithProfile, macro (unused, unused, dispatch)
      dispatch()
  end)
  
<span class="line-new-header">--- 1806,33 ---</span>
          OpCallEval,
          macro () dispatchOp(narrow, op_call_eval) end,
          _llint_slow_path_call_eval,
          prepareForRegularCall)
  
<span class="line-modified">! _llint_op_call_eval_wide16:</span>
      slowPathForCall(
<span class="line-modified">!         wide16,</span>
          OpCallEval,
<span class="line-modified">!         macro () dispatchOp(wide16, op_call_eval) end,</span>
<span class="line-modified">!         _llint_slow_path_call_eval_wide16,</span>
<span class="line-added">+         prepareForRegularCall)</span>
<span class="line-added">+ </span>
<span class="line-added">+ _llint_op_call_eval_wide32:</span>
<span class="line-added">+     slowPathForCall(</span>
<span class="line-added">+         wide32,</span>
<span class="line-added">+         OpCallEval,</span>
<span class="line-added">+         macro () dispatchOp(wide32, op_call_eval) end,</span>
<span class="line-added">+         _llint_slow_path_call_eval_wide32,</span>
          prepareForRegularCall)
  
  
<span class="line-modified">! commonOp(llint_generic_return_point, macro () end, macro (size)</span>
<span class="line-modified">!     dispatchAfterCall(size, OpCallEval, macro ()</span>
<span class="line-modified">!         dispatchOp(size, op_call_eval)</span>
      end)
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
  
  llintOp(op_identity_with_profile, OpIdentityWithProfile, macro (unused, unused, dispatch)
      dispatch()
  end)
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1798,10 ***</span>
<span class="line-new-header">--- 1840,15 ---</span>
  llintOp(op_yield, OpYield, macro (unused, unused, unused)
      notSupported()
  end)
  
  
<span class="line-added">+ llintOp(op_create_generator_frame_environment, OpYield, macro (unused, unused, unused)</span>
<span class="line-added">+     notSupported()</span>
<span class="line-added">+ end)</span>
<span class="line-added">+ </span>
<span class="line-added">+ </span>
  llintOp(op_debug, OpDebug, macro (unused, unused, dispatch)
      loadp CodeBlock[cfr], t0
      loadi CodeBlock::m_debuggerRequests[t0], t0
      btiz t0, .opDebugDone
      callSlowPath(_llint_slow_path_debug)
</pre>
<center><a href="LLIntThunks.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>