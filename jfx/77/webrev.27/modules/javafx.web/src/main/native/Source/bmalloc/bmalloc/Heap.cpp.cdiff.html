<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/Heap.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="Gigacage.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="Heap.h.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/Heap.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 52,26 ***</span>
      RELEASE_BASSERT(vmPageSize() &gt;= vmPageSizePhysical());
  
      initializeLineMetadata();
      initializePageMetadata();
  
<span class="line-modified">!     BASSERT(!PerProcess&lt;Environment&gt;::get()-&gt;isDebugHeapEnabled());</span>
  
<span class="line-modified">!         Gigacage::ensureGigacage();</span>
  #if GIGACAGE_ENABLED
<span class="line-modified">!         if (usingGigacage()) {</span>
<span class="line-modified">!             RELEASE_BASSERT(gigacageBasePtr());</span>
<span class="line-modified">!             uint64_t random[2];</span>
<span class="line-modified">!             cryptoRandom(reinterpret_cast&lt;unsigned char*&gt;(random), sizeof(random));</span>
<span class="line-modified">!             size_t size = roundDownToMultipleOf(vmPageSize(), gigacageSize() - (random[0] % Gigacage::maximumCageSizeReductionForSlide));</span>
<span class="line-modified">!             ptrdiff_t offset = roundDownToMultipleOf(vmPageSize(), random[1] % (gigacageSize() - size));</span>
<span class="line-modified">!             void* base = reinterpret_cast&lt;unsigned char*&gt;(gigacageBasePtr()) + offset;</span>
<span class="line-modified">!             m_largeFree.add(LargeRange(base, size, 0, 0));</span>
<span class="line-modified">!         }</span>
  #endif
  
<span class="line-modified">!     m_scavenger = PerProcess&lt;Scavenger&gt;::get();</span>
  }
  
  bool Heap::usingGigacage()
  {
      return isGigacage(m_kind) &amp;&amp; gigacageBasePtr();
<span class="line-new-header">--- 52,26 ---</span>
      RELEASE_BASSERT(vmPageSize() &gt;= vmPageSizePhysical());
  
      initializeLineMetadata();
      initializePageMetadata();
  
<span class="line-modified">!     BASSERT(!Environment::get()-&gt;isDebugHeapEnabled());</span>
  
<span class="line-modified">!     Gigacage::ensureGigacage();</span>
  #if GIGACAGE_ENABLED
<span class="line-modified">!     if (usingGigacage()) {</span>
<span class="line-modified">!         RELEASE_BASSERT(gigacageBasePtr());</span>
<span class="line-modified">!         uint64_t random[2];</span>
<span class="line-modified">!         cryptoRandom(reinterpret_cast&lt;unsigned char*&gt;(random), sizeof(random));</span>
<span class="line-modified">!         size_t size = roundDownToMultipleOf(vmPageSize(), gigacageSize() - (random[0] % Gigacage::maximumCageSizeReductionForSlide));</span>
<span class="line-modified">!         ptrdiff_t offset = roundDownToMultipleOf(vmPageSize(), random[1] % (gigacageSize() - size));</span>
<span class="line-modified">!         void* base = reinterpret_cast&lt;unsigned char*&gt;(gigacageBasePtr()) + offset;</span>
<span class="line-modified">!         m_largeFree.add(LargeRange(base, size, 0, 0));</span>
<span class="line-modified">!     }</span>
  #endif
  
<span class="line-modified">!     m_scavenger = Scavenger::get();</span>
  }
  
  bool Heap::usingGigacage()
  {
      return isGigacage(m_kind) &amp;&amp; gigacageBasePtr();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 173,17 ***</span>
  #if ENABLE_PHYSICAL_PAGE_MAP
      m_physicalPageMap.decommit(range.begin(), range.size());
  #endif
  }
  
<span class="line-modified">! void Heap::scavenge(std::lock_guard&lt;Mutex&gt;&amp; lock, BulkDecommit&amp; decommitter)</span>
  {
      for (auto&amp; list : m_freePages) {
          for (auto* chunk : list) {
              for (auto* page : chunk-&gt;freePages()) {
                  if (!page-&gt;hasPhysicalPages())
                      continue;
  
                  size_t pageSize = bmalloc::pageSize(&amp;list - &amp;m_freePages[0]);
                  size_t decommitSize = physicalPageSizeSloppy(page-&gt;begin()-&gt;begin(), pageSize);
                  m_freeableMemory -= decommitSize;
                  m_footprint -= decommitSize;
<span class="line-new-header">--- 173,22 ---</span>
  #if ENABLE_PHYSICAL_PAGE_MAP
      m_physicalPageMap.decommit(range.begin(), range.size());
  #endif
  }
  
<span class="line-modified">! void Heap::scavenge(std::lock_guard&lt;Mutex&gt;&amp; lock, BulkDecommit&amp; decommitter, size_t&amp; deferredDecommits)</span>
  {
      for (auto&amp; list : m_freePages) {
          for (auto* chunk : list) {
              for (auto* page : chunk-&gt;freePages()) {
                  if (!page-&gt;hasPhysicalPages())
                      continue;
<span class="line-added">+                 if (page-&gt;usedSinceLastScavenge()) {</span>
<span class="line-added">+                     page-&gt;clearUsedSinceLastScavenge();</span>
<span class="line-added">+                     deferredDecommits++;</span>
<span class="line-added">+                     continue;</span>
<span class="line-added">+                 }</span>
  
                  size_t pageSize = bmalloc::pageSize(&amp;list - &amp;m_freePages[0]);
                  size_t decommitSize = physicalPageSizeSloppy(page-&gt;begin()-&gt;begin(), pageSize);
                  m_freeableMemory -= decommitSize;
                  m_footprint -= decommitSize;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 200,27 ***</span>
          while (!list.isEmpty())
              deallocateSmallChunk(list.pop(), &amp;list - &amp;m_chunkCache[0]);
      }
  
      for (LargeRange&amp; range : m_largeFree) {
<span class="line-modified">!         m_highWatermark = std::min(m_highWatermark, static_cast&lt;void*&gt;(range.begin()));</span>
          decommitLargeRange(lock, range, decommitter);
      }
<span class="line-removed">- </span>
<span class="line-removed">-     m_freeableMemory = 0;</span>
<span class="line-removed">- }</span>
<span class="line-removed">- </span>
<span class="line-removed">- void Heap::scavengeToHighWatermark(std::lock_guard&lt;Mutex&gt;&amp; lock, BulkDecommit&amp; decommitter)</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     void* newHighWaterMark = nullptr;</span>
<span class="line-removed">-     for (LargeRange&amp; range : m_largeFree) {</span>
<span class="line-removed">-         if (range.begin() &lt;= m_highWatermark)</span>
<span class="line-removed">-             newHighWaterMark = std::min(newHighWaterMark, static_cast&lt;void*&gt;(range.begin()));</span>
<span class="line-removed">-         else</span>
<span class="line-removed">-             decommitLargeRange(lock, range, decommitter);</span>
<span class="line-removed">-     }</span>
<span class="line-removed">-     m_highWatermark = newHighWaterMark;</span>
  }
  
  void Heap::deallocateLineCache(std::unique_lock&lt;Mutex&gt;&amp;, LineCache&amp; lineCache)
  {
      for (auto&amp; list : lineCache) {
<span class="line-new-header">--- 205,17 ---</span>
          while (!list.isEmpty())
              deallocateSmallChunk(list.pop(), &amp;list - &amp;m_chunkCache[0]);
      }
  
      for (LargeRange&amp; range : m_largeFree) {
<span class="line-modified">!         if (range.usedSinceLastScavenge()) {</span>
<span class="line-added">+             range.clearUsedSinceLastScavenge();</span>
<span class="line-added">+             deferredDecommits++;</span>
<span class="line-added">+             continue;</span>
<span class="line-added">+         }</span>
          decommitLargeRange(lock, range, decommitter);
      }
  }
  
  void Heap::deallocateLineCache(std::unique_lock&lt;Mutex&gt;&amp;, LineCache&amp; lineCache)
  {
      for (auto&amp; list : lineCache) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 247,10 ***</span>
<span class="line-new-header">--- 242,11 ---</span>
  
          m_objectTypes.set(chunk, ObjectType::Small);
  
          forEachPage(chunk, pageSize, [&amp;](SmallPage* page) {
              page-&gt;setHasPhysicalPages(true);
<span class="line-added">+             page-&gt;setUsedSinceLastScavenge();</span>
              page-&gt;setHasFreeLines(lock, true);
              chunk-&gt;freePages().push(page);
          });
  
          m_freeableMemory += chunkSize;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 326,10 ***</span>
<span class="line-new-header">--- 322,11 ---</span>
              page-&gt;setHasPhysicalPages(true);
  #if ENABLE_PHYSICAL_PAGE_MAP
              m_physicalPageMap.commit(page-&gt;begin()-&gt;begin(), pageSize);
  #endif
          }
<span class="line-added">+         page-&gt;setUsedSinceLastScavenge();</span>
  
          return page;
      }();
  
      page-&gt;setSizeClass(sizeClass);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 572,22 ***</span>
          }
  
          if (usingGigacage())
              return nullptr;
  
<span class="line-modified">!         range = PerProcess&lt;VMHeap&gt;::get()-&gt;tryAllocateLargeChunk(alignment, size);</span>
          if (!range)
              return nullptr;
  
          m_largeFree.add(range);
          range = m_largeFree.remove(alignment, size);
      }
  
      m_freeableMemory -= range.totalPhysicalSize();
  
      void* result = splitAndAllocate(lock, range, alignment, size).begin();
<span class="line-removed">-     m_highWatermark = std::max(m_highWatermark, result);</span>
      return result;
  }
  
  void* Heap::allocateLarge(std::unique_lock&lt;Mutex&gt;&amp; lock, size_t alignment, size_t size)
  {
<span class="line-new-header">--- 569,21 ---</span>
          }
  
          if (usingGigacage())
              return nullptr;
  
<span class="line-modified">!         range = VMHeap::get()-&gt;tryAllocateLargeChunk(alignment, size);</span>
          if (!range)
              return nullptr;
  
          m_largeFree.add(range);
          range = m_largeFree.remove(alignment, size);
      }
  
      m_freeableMemory -= range.totalPhysicalSize();
  
      void* result = splitAndAllocate(lock, range, alignment, size).begin();
      return result;
  }
  
  void* Heap::allocateLarge(std::unique_lock&lt;Mutex&gt;&amp; lock, size_t alignment, size_t size)
  {
</pre>
<center><a href="Gigacage.h.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="Heap.h.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>