diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/ScriptProcessorNode.cpp b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/ScriptProcessorNode.cpp
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/ScriptProcessorNode.cpp
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/ScriptProcessorNode.cpp
@@ -35,14 +35,17 @@
 #include "AudioNodeOutput.h"
 #include "AudioProcessingEvent.h"
 #include "Document.h"
 #include "EventNames.h"
 #include <JavaScriptCore/Float32Array.h>
+#include <wtf/IsoMallocInlines.h>
 #include <wtf/MainThread.h>
 
 namespace WebCore {
 
+WTF_MAKE_ISO_ALLOCATED_IMPL(ScriptProcessorNode);
+
 Ref<ScriptProcessorNode> ScriptProcessorNode::create(AudioContext& context, float sampleRate, size_t bufferSize, unsigned numberOfInputChannels, unsigned numberOfOutputChannels)
 {
     return adoptRef(*new ScriptProcessorNode(context, sampleRate, bufferSize, numberOfInputChannels, numberOfOutputChannels));
 }
 
@@ -62,14 +65,13 @@
     if (m_bufferSize < AudioNode::ProcessingSizeInFrames)
         m_bufferSize = AudioNode::ProcessingSizeInFrames;
 
     ASSERT(numberOfInputChannels <= AudioContext::maxNumberOfChannels());
 
-    addInput(std::make_unique<AudioNodeInput>(this));
-    addOutput(std::make_unique<AudioNodeOutput>(this, numberOfOutputChannels));
-
     setNodeType(NodeTypeJavaScript);
+    addInput(makeUnique<AudioNodeInput>(this));
+    addOutput(makeUnique<AudioNodeOutput>(this, numberOfOutputChannels));
 
     initialize();
 }
 
 ScriptProcessorNode::~ScriptProcessorNode()
@@ -218,11 +220,11 @@
     ASSERT(outputBuffer);
     if (!outputBuffer)
         return;
 
     // Avoid firing the event if the document has already gone away.
-    if (context().scriptExecutionContext()) {
+    if (!context().isStopped()) {
         // Let the audio thread know we've gotten to the point where it's OK for it to make another request.
         m_isRequestOutstanding = false;
 
         // Calculate playbackTime with the buffersize which needs to be processed each time when onaudioprocess is called.
         // The outputBuffer being passed to JS will be played after exhausting previous outputBuffer by double-buffering.
@@ -252,19 +254,19 @@
 double ScriptProcessorNode::latencyTime() const
 {
     return std::numeric_limits<double>::infinity();
 }
 
-bool ScriptProcessorNode::addEventListener(const AtomicString& eventType, Ref<EventListener>&& listener, const AddEventListenerOptions& options)
+bool ScriptProcessorNode::addEventListener(const AtomString& eventType, Ref<EventListener>&& listener, const AddEventListenerOptions& options)
 {
     bool success = AudioNode::addEventListener(eventType, WTFMove(listener), options);
     if (success && eventType == eventNames().audioprocessEvent)
         m_hasAudioProcessListener = hasEventListeners(eventNames().audioprocessEvent);
     return success;
 }
 
-bool ScriptProcessorNode::removeEventListener(const AtomicString& eventType, EventListener& listener, const ListenerOptions& options)
+bool ScriptProcessorNode::removeEventListener(const AtomString& eventType, EventListener& listener, const ListenerOptions& options)
 {
     bool success = AudioNode::removeEventListener(eventType, listener, options);
     if (success && eventType == eventNames().audioprocessEvent)
         m_hasAudioProcessListener = hasEventListeners(eventNames().audioprocessEvent);
     return success;
