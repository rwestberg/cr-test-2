<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGOSRExit.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGOSREntrypointCreationPhase.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGOSRExit.h.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGOSRExit.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 349,11 ***</span>
          context.fp() = exec;
      }
  
      CodeBlock* codeBlock = exec-&gt;codeBlock();
      ASSERT(codeBlock);
<span class="line-modified">!     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
  
      // It&#39;s sort of preferable that we don&#39;t GC while in here. Anyways, doing so wouldn&#39;t
      // really be profitable.
      DeferGCForAWhile deferGC(vm.heap);
  
<span class="line-new-header">--- 349,11 ---</span>
          context.fp() = exec;
      }
  
      CodeBlock* codeBlock = exec-&gt;codeBlock();
      ASSERT(codeBlock);
<span class="line-modified">!     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
  
      // It&#39;s sort of preferable that we don&#39;t GC while in here. Anyways, doing so wouldn&#39;t
      // really be profitable.
      DeferGCForAWhile deferGC(vm.heap);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 373,11 ***</span>
  
          // Ensure we have baseline codeBlocks to OSR exit to.
          prepareCodeOriginForOSRExit(exec, exit.m_codeOrigin);
  
          CodeBlock* baselineCodeBlock = codeBlock-&gt;baselineAlternative();
<span class="line-modified">!         ASSERT(baselineCodeBlock-&gt;jitType() == JITCode::BaselineJIT);</span>
  
          SpeculationRecovery* recovery = nullptr;
          if (exit.m_recoveryIndex != UINT_MAX) {
              recovery = &amp;dfgJITCode-&gt;speculationRecovery[exit.m_recoveryIndex];
              extraInitializationLevel = std::max(extraInitializationLevel, ExtraInitializationLevel::SpeculationRecovery);
<span class="line-new-header">--- 373,11 ---</span>
  
          // Ensure we have baseline codeBlocks to OSR exit to.
          prepareCodeOriginForOSRExit(exec, exit.m_codeOrigin);
  
          CodeBlock* baselineCodeBlock = codeBlock-&gt;baselineAlternative();
<span class="line-modified">!         ASSERT(baselineCodeBlock-&gt;jitType() == JITType::BaselineJIT);</span>
  
          SpeculationRecovery* recovery = nullptr;
          if (exit.m_recoveryIndex != UINT_MAX) {
              recovery = &amp;dfgJITCode-&gt;speculationRecovery[exit.m_recoveryIndex];
              extraInitializationLevel = std::max(extraInitializationLevel, ExtraInitializationLevel::SpeculationRecovery);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 391,11 ***</span>
              if (exit.m_valueProfile)
                  extraInitializationLevel = std::max(extraInitializationLevel, ExtraInitializationLevel::ValueProfileUpdate);
              if (exit.m_kind == BadCache || exit.m_kind == BadIndexingType) {
                  CodeOrigin codeOrigin = exit.m_codeOriginForExitProfile;
                  CodeBlock* profiledCodeBlock = baselineCodeBlockForOriginAndBaselineCodeBlock(codeOrigin, baselineCodeBlock);
<span class="line-modified">!                 arrayProfile = profiledCodeBlock-&gt;getArrayProfile(codeOrigin.bytecodeIndex);</span>
                  if (arrayProfile)
                      extraInitializationLevel = std::max(extraInitializationLevel, ExtraInitializationLevel::ArrayProfileUpdate);
              }
          }
  
<span class="line-new-header">--- 391,11 ---</span>
              if (exit.m_valueProfile)
                  extraInitializationLevel = std::max(extraInitializationLevel, ExtraInitializationLevel::ValueProfileUpdate);
              if (exit.m_kind == BadCache || exit.m_kind == BadIndexingType) {
                  CodeOrigin codeOrigin = exit.m_codeOriginForExitProfile;
                  CodeBlock* profiledCodeBlock = baselineCodeBlockForOriginAndBaselineCodeBlock(codeOrigin, baselineCodeBlock);
<span class="line-modified">!                 arrayProfile = profiledCodeBlock-&gt;getArrayProfile(codeOrigin.bytecodeIndex());</span>
                  if (arrayProfile)
                      extraInitializationLevel = std::max(extraInitializationLevel, ExtraInitializationLevel::ArrayProfileUpdate);
              }
          }
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 404,11 ***</span>
          ASSERT(adjustedThreshold &gt; 0);
          adjustedThreshold = BaselineExecutionCounter::clippedThreshold(codeBlock-&gt;globalObject(), adjustedThreshold);
  
          CodeBlock* codeBlockForExit = baselineCodeBlockForOriginAndBaselineCodeBlock(exit.m_codeOrigin, baselineCodeBlock);
          const JITCodeMap&amp; codeMap = codeBlockForExit-&gt;jitCodeMap();
<span class="line-modified">!         CodeLocationLabel&lt;JSEntryPtrTag&gt; codeLocation = codeMap.find(exit.m_codeOrigin.bytecodeIndex);</span>
          ASSERT(codeLocation);
  
          void* jumpTarget = codeLocation.executableAddress();
  
          // Compute the value recoveries.
<span class="line-new-header">--- 404,11 ---</span>
          ASSERT(adjustedThreshold &gt; 0);
          adjustedThreshold = BaselineExecutionCounter::clippedThreshold(codeBlock-&gt;globalObject(), adjustedThreshold);
  
          CodeBlock* codeBlockForExit = baselineCodeBlockForOriginAndBaselineCodeBlock(exit.m_codeOrigin, baselineCodeBlock);
          const JITCodeMap&amp; codeMap = codeBlockForExit-&gt;jitCodeMap();
<span class="line-modified">!         CodeLocationLabel&lt;JSEntryPtrTag&gt; codeLocation = codeMap.find(exit.m_codeOrigin.bytecodeIndex());</span>
          ASSERT(codeLocation);
  
          void* jumpTarget = codeLocation.executableAddress();
  
          // Compute the value recoveries.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 443,18 ***</span>
          }
      }
  
      OSRExitState&amp; exitState = *exit.exitState.get();
      CodeBlock* baselineCodeBlock = exitState.baselineCodeBlock;
<span class="line-modified">!     ASSERT(baselineCodeBlock-&gt;jitType() == JITCode::BaselineJIT);</span>
  
      Operands&lt;ValueRecovery&gt;&amp; operands = exitState.operands;
      Vector&lt;UndefinedOperandSpan&gt;&amp; undefinedOperandSpans = exitState.undefinedOperandSpans;
  
      context.sp() = context.fp&lt;uint8_t*&gt;() + exitState.stackPointerOffset;
  
<span class="line-modified">!     // The only reason for using this do while look is so we can break out midway when appropriate.</span>
      do {
          auto extraInitializationLevel = static_cast&lt;ExtraInitializationLevel&gt;(exitState.extraInitializationLevel);
  
          if (extraInitializationLevel == ExtraInitializationLevel::None)
              break;
<span class="line-new-header">--- 443,18 ---</span>
          }
      }
  
      OSRExitState&amp; exitState = *exit.exitState.get();
      CodeBlock* baselineCodeBlock = exitState.baselineCodeBlock;
<span class="line-modified">!     ASSERT(baselineCodeBlock-&gt;jitType() == JITType::BaselineJIT);</span>
  
      Operands&lt;ValueRecovery&gt;&amp; operands = exitState.operands;
      Vector&lt;UndefinedOperandSpan&gt;&amp; undefinedOperandSpans = exitState.undefinedOperandSpans;
  
      context.sp() = context.fp&lt;uint8_t*&gt;() + exitState.stackPointerOffset;
  
<span class="line-modified">!     // The only reason for using this do while loop is so we can break out midway when appropriate.</span>
      do {
          auto extraInitializationLevel = static_cast&lt;ExtraInitializationLevel&gt;(exitState.extraInitializationLevel);
  
          if (extraInitializationLevel == ExtraInitializationLevel::None)
              break;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 473,10 ***</span>
<span class="line-new-header">--- 473,18 ---</span>
                  ASSERT(!(cpu.gpr(recovery-&gt;dest()) &gt;&gt; 32));
                  cpu.gpr(recovery-&gt;dest()) |= TagTypeNumber;
  #endif
                  break;
  
<span class="line-added">+             case SpeculativeAddSelf:</span>
<span class="line-added">+                 cpu.gpr(recovery-&gt;dest()) = static_cast&lt;uint32_t&gt;(cpu.gpr&lt;int32_t&gt;(recovery-&gt;dest()) &gt;&gt; 1) ^ 0x80000000U;</span>
<span class="line-added">+ #if USE(JSVALUE64)</span>
<span class="line-added">+                 ASSERT(!(cpu.gpr(recovery-&gt;dest()) &gt;&gt; 32));</span>
<span class="line-added">+                 cpu.gpr(recovery-&gt;dest()) |= TagTypeNumber;</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+                 break;</span>
<span class="line-added">+ </span>
              case SpeculativeAddImmediate:
                  cpu.gpr(recovery-&gt;dest()) = (cpu.gpr&lt;uint32_t&gt;(recovery-&gt;dest()) - recovery-&gt;immediate());
  #if USE(JSVALUE64)
                  ASSERT(!(cpu.gpr(recovery-&gt;dest()) &gt;&gt; 32));
                  cpu.gpr(recovery-&gt;dest()) |= TagTypeNumber;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 742,34 ***</span>
      Frame frame(cpu.fp(), context.stack());
  
      // FIXME: We shouldn&#39;t leave holes on the stack when performing an OSR exit
      // in presence of inlined tail calls.
      // https://bugs.webkit.org/show_bug.cgi?id=147511
<span class="line-modified">!     ASSERT(outermostBaselineCodeBlock-&gt;jitType() == JITCode::BaselineJIT);</span>
      frame.setOperand&lt;CodeBlock*&gt;(CallFrameSlot::codeBlock, outermostBaselineCodeBlock);
  
      const CodeOrigin* codeOrigin;
<span class="line-modified">!     for (codeOrigin = &amp;exit.m_codeOrigin; codeOrigin &amp;&amp; codeOrigin-&gt;inlineCallFrame; codeOrigin = codeOrigin-&gt;inlineCallFrame-&gt;getCallerSkippingTailCalls()) {</span>
<span class="line-modified">!         InlineCallFrame* inlineCallFrame = codeOrigin-&gt;inlineCallFrame;</span>
          CodeBlock* baselineCodeBlock = baselineCodeBlockForOriginAndBaselineCodeBlock(*codeOrigin, outermostBaselineCodeBlock);
          InlineCallFrame::Kind trueCallerCallKind;
          CodeOrigin* trueCaller = inlineCallFrame-&gt;getCallerSkippingTailCalls(&amp;trueCallerCallKind);
          void* callerFrame = cpu.fp();
  
          if (!trueCaller) {
              ASSERT(inlineCallFrame-&gt;isTail());
              void* returnPC = frame.get&lt;void*&gt;(CallFrame::returnPCOffset());
<span class="line-modified">! #if USE(POINTER_PROFILING)</span>
              void* oldEntrySP = cpu.fp&lt;uint8_t*&gt;() + sizeof(CallerFrameAndPC);
              void* newEntrySP = cpu.fp&lt;uint8_t*&gt;() + inlineCallFrame-&gt;returnPCOffset() + sizeof(void*);
              returnPC = retagCodePtr(returnPC, bitwise_cast&lt;PtrTag&gt;(oldEntrySP), bitwise_cast&lt;PtrTag&gt;(newEntrySP));
  #endif
              frame.set&lt;void*&gt;(inlineCallFrame-&gt;returnPCOffset(), returnPC);
              callerFrame = frame.get&lt;void*&gt;(CallFrame::callerFrameOffset());
          } else {
              CodeBlock* baselineCodeBlockForCaller = baselineCodeBlockForOriginAndBaselineCodeBlock(*trueCaller, outermostBaselineCodeBlock);
<span class="line-modified">!             unsigned callBytecodeIndex = trueCaller-&gt;bytecodeIndex;</span>
              MacroAssemblerCodePtr&lt;JSInternalPtrTag&gt; jumpTarget;
  
              switch (trueCallerCallKind) {
              case InlineCallFrame::Call:
              case InlineCallFrame::Construct:
<span class="line-new-header">--- 750,34 ---</span>
      Frame frame(cpu.fp(), context.stack());
  
      // FIXME: We shouldn&#39;t leave holes on the stack when performing an OSR exit
      // in presence of inlined tail calls.
      // https://bugs.webkit.org/show_bug.cgi?id=147511
<span class="line-modified">!     ASSERT(outermostBaselineCodeBlock-&gt;jitType() == JITType::BaselineJIT);</span>
      frame.setOperand&lt;CodeBlock*&gt;(CallFrameSlot::codeBlock, outermostBaselineCodeBlock);
  
      const CodeOrigin* codeOrigin;
<span class="line-modified">!     for (codeOrigin = &amp;exit.m_codeOrigin; codeOrigin &amp;&amp; codeOrigin-&gt;inlineCallFrame(); codeOrigin = codeOrigin-&gt;inlineCallFrame()-&gt;getCallerSkippingTailCalls()) {</span>
<span class="line-modified">!         InlineCallFrame* inlineCallFrame = codeOrigin-&gt;inlineCallFrame();</span>
          CodeBlock* baselineCodeBlock = baselineCodeBlockForOriginAndBaselineCodeBlock(*codeOrigin, outermostBaselineCodeBlock);
          InlineCallFrame::Kind trueCallerCallKind;
          CodeOrigin* trueCaller = inlineCallFrame-&gt;getCallerSkippingTailCalls(&amp;trueCallerCallKind);
          void* callerFrame = cpu.fp();
  
          if (!trueCaller) {
              ASSERT(inlineCallFrame-&gt;isTail());
              void* returnPC = frame.get&lt;void*&gt;(CallFrame::returnPCOffset());
<span class="line-modified">! #if CPU(ARM64E)</span>
              void* oldEntrySP = cpu.fp&lt;uint8_t*&gt;() + sizeof(CallerFrameAndPC);
              void* newEntrySP = cpu.fp&lt;uint8_t*&gt;() + inlineCallFrame-&gt;returnPCOffset() + sizeof(void*);
              returnPC = retagCodePtr(returnPC, bitwise_cast&lt;PtrTag&gt;(oldEntrySP), bitwise_cast&lt;PtrTag&gt;(newEntrySP));
  #endif
              frame.set&lt;void*&gt;(inlineCallFrame-&gt;returnPCOffset(), returnPC);
              callerFrame = frame.get&lt;void*&gt;(CallFrame::callerFrameOffset());
          } else {
              CodeBlock* baselineCodeBlockForCaller = baselineCodeBlockForOriginAndBaselineCodeBlock(*trueCaller, outermostBaselineCodeBlock);
<span class="line-modified">!             unsigned callBytecodeIndex = trueCaller-&gt;bytecodeIndex();</span>
              MacroAssemblerCodePtr&lt;JSInternalPtrTag&gt; jumpTarget;
  
              switch (trueCallerCallKind) {
              case InlineCallFrame::Call:
              case InlineCallFrame::Construct:
</pre>
<hr />
<pre>
<span class="line-old-header">*** 797,15 ***</span>
  
              default:
                  RELEASE_ASSERT_NOT_REACHED();
              }
  
<span class="line-modified">!             if (trueCaller-&gt;inlineCallFrame)</span>
<span class="line-modified">!                 callerFrame = cpu.fp&lt;uint8_t*&gt;() + trueCaller-&gt;inlineCallFrame-&gt;stackOffset * sizeof(EncodedJSValue);</span>
  
              void* targetAddress = jumpTarget.executableAddress();
<span class="line-modified">! #if USE(POINTER_PROFILING)</span>
              void* newEntrySP = cpu.fp&lt;uint8_t*&gt;() + inlineCallFrame-&gt;returnPCOffset() + sizeof(void*);
              targetAddress = retagCodePtr(targetAddress, JSInternalPtrTag, bitwise_cast&lt;PtrTag&gt;(newEntrySP));
  #endif
              frame.set&lt;void*&gt;(inlineCallFrame-&gt;returnPCOffset(), targetAddress);
          }
<span class="line-new-header">--- 805,15 ---</span>
  
              default:
                  RELEASE_ASSERT_NOT_REACHED();
              }
  
<span class="line-modified">!             if (trueCaller-&gt;inlineCallFrame())</span>
<span class="line-modified">!                 callerFrame = cpu.fp&lt;uint8_t*&gt;() + trueCaller-&gt;inlineCallFrame()-&gt;stackOffset * sizeof(EncodedJSValue);</span>
  
              void* targetAddress = jumpTarget.executableAddress();
<span class="line-modified">! #if CPU(ARM64E)</span>
              void* newEntrySP = cpu.fp&lt;uint8_t*&gt;() + inlineCallFrame-&gt;returnPCOffset() + sizeof(void*);
              targetAddress = retagCodePtr(targetAddress, JSInternalPtrTag, bitwise_cast&lt;PtrTag&gt;(newEntrySP));
  #endif
              frame.set&lt;void*&gt;(inlineCallFrame-&gt;returnPCOffset(), targetAddress);
          }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 820,16 ***</span>
          if (!inlineCallFrame-&gt;isVarargs())
              frame.setOperand&lt;uint32_t&gt;(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount, PayloadOffset, inlineCallFrame-&gt;argumentCountIncludingThis);
          ASSERT(callerFrame);
          frame.set&lt;void*&gt;(inlineCallFrame-&gt;callerFrameOffset(), callerFrame);
  #if USE(JSVALUE64)
<span class="line-modified">!         uint32_t locationBits = CallSiteIndex(codeOrigin-&gt;bytecodeIndex).bits();</span>
          frame.setOperand&lt;uint32_t&gt;(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount, TagOffset, locationBits);
          if (!inlineCallFrame-&gt;isClosureCall)
              frame.setOperand(inlineCallFrame-&gt;stackOffset + CallFrameSlot::callee, JSValue(inlineCallFrame-&gt;calleeConstant()));
  #else // USE(JSVALUE64) // so this is the 32-bit part
<span class="line-modified">!         const Instruction* instruction = baselineCodeBlock-&gt;instructions().at(codeOrigin-&gt;bytecodeIndex).ptr();</span>
          uint32_t locationBits = CallSiteIndex(instruction).bits();
          frame.setOperand&lt;uint32_t&gt;(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount, TagOffset, locationBits);
          frame.setOperand&lt;uint32_t&gt;(inlineCallFrame-&gt;stackOffset + CallFrameSlot::callee, TagOffset, static_cast&lt;uint32_t&gt;(JSValue::CellTag));
          if (!inlineCallFrame-&gt;isClosureCall)
              frame.setOperand(inlineCallFrame-&gt;stackOffset + CallFrameSlot::callee, PayloadOffset, inlineCallFrame-&gt;calleeConstant());
<span class="line-new-header">--- 828,16 ---</span>
          if (!inlineCallFrame-&gt;isVarargs())
              frame.setOperand&lt;uint32_t&gt;(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount, PayloadOffset, inlineCallFrame-&gt;argumentCountIncludingThis);
          ASSERT(callerFrame);
          frame.set&lt;void*&gt;(inlineCallFrame-&gt;callerFrameOffset(), callerFrame);
  #if USE(JSVALUE64)
<span class="line-modified">!         uint32_t locationBits = CallSiteIndex(codeOrigin-&gt;bytecodeIndex()).bits();</span>
          frame.setOperand&lt;uint32_t&gt;(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount, TagOffset, locationBits);
          if (!inlineCallFrame-&gt;isClosureCall)
              frame.setOperand(inlineCallFrame-&gt;stackOffset + CallFrameSlot::callee, JSValue(inlineCallFrame-&gt;calleeConstant()));
  #else // USE(JSVALUE64) // so this is the 32-bit part
<span class="line-modified">!         const Instruction* instruction = baselineCodeBlock-&gt;instructions().at(codeOrigin-&gt;bytecodeIndex()).ptr();</span>
          uint32_t locationBits = CallSiteIndex(instruction).bits();
          frame.setOperand&lt;uint32_t&gt;(inlineCallFrame-&gt;stackOffset + CallFrameSlot::argumentCount, TagOffset, locationBits);
          frame.setOperand&lt;uint32_t&gt;(inlineCallFrame-&gt;stackOffset + CallFrameSlot::callee, TagOffset, static_cast&lt;uint32_t&gt;(JSValue::CellTag));
          if (!inlineCallFrame-&gt;isClosureCall)
              frame.setOperand(inlineCallFrame-&gt;stackOffset + CallFrameSlot::callee, PayloadOffset, inlineCallFrame-&gt;calleeConstant());
</pre>
<hr />
<pre>
<span class="line-old-header">*** 837,13 ***</span>
      }
  
      // Don&#39;t need to set the toplevel code origin if we only did inline tail calls
      if (codeOrigin) {
  #if USE(JSVALUE64)
<span class="line-modified">!         uint32_t locationBits = CallSiteIndex(codeOrigin-&gt;bytecodeIndex).bits();</span>
  #else
<span class="line-modified">!         const Instruction* instruction = outermostBaselineCodeBlock-&gt;instructions().at(codeOrigin-&gt;bytecodeIndex).ptr();</span>
          uint32_t locationBits = CallSiteIndex(instruction).bits();
  #endif
          frame.setOperand&lt;uint32_t&gt;(CallFrameSlot::argumentCount, TagOffset, locationBits);
      }
  }
<span class="line-new-header">--- 845,13 ---</span>
      }
  
      // Don&#39;t need to set the toplevel code origin if we only did inline tail calls
      if (codeOrigin) {
  #if USE(JSVALUE64)
<span class="line-modified">!         uint32_t locationBits = CallSiteIndex(codeOrigin-&gt;bytecodeIndex()).bits();</span>
  #else
<span class="line-modified">!         const Instruction* instruction = outermostBaselineCodeBlock-&gt;instructions().at(codeOrigin-&gt;bytecodeIndex()).ptr();</span>
          uint32_t locationBits = CallSiteIndex(instruction).bits();
  #endif
          frame.setOperand&lt;uint32_t&gt;(CallFrameSlot::argumentCount, TagOffset, locationBits);
      }
  }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 866,12 ***</span>
      if (inlineCallFrames) {
          for (InlineCallFrame* inlineCallFrame : *inlineCallFrames)
              vm.heap.writeBarrier(inlineCallFrame-&gt;baselineCodeBlock.get());
      }
  
<span class="line-modified">!     if (exit.m_codeOrigin.inlineCallFrame)</span>
<span class="line-modified">!         context.fp() = context.fp&lt;uint8_t*&gt;() + exit.m_codeOrigin.inlineCallFrame-&gt;stackOffset * sizeof(EncodedJSValue);</span>
  
      void* jumpTarget = exitState-&gt;jumpTarget;
      ASSERT(jumpTarget);
  
      if (exit.isExceptionHandler()) {
<span class="line-new-header">--- 874,13 ---</span>
      if (inlineCallFrames) {
          for (InlineCallFrame* inlineCallFrame : *inlineCallFrames)
              vm.heap.writeBarrier(inlineCallFrame-&gt;baselineCodeBlock.get());
      }
  
<span class="line-modified">!     auto* exitInlineCallFrame = exit.m_codeOrigin.inlineCallFrame();</span>
<span class="line-modified">!     if (exitInlineCallFrame)</span>
<span class="line-added">+         context.fp() = context.fp&lt;uint8_t*&gt;() + exitInlineCallFrame-&gt;stackOffset * sizeof(EncodedJSValue);</span>
  
      void* jumpTarget = exitState-&gt;jumpTarget;
      ASSERT(jumpTarget);
  
      if (exit.isExceptionHandler()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 887,11 ***</span>
  {
      ExecState* exec = context.fp&lt;ExecState*&gt;();
      CodeBlock* codeBlock = exec-&gt;codeBlock();
      CodeBlock* alternative = codeBlock-&gt;alternative();
      ExitKind kind = exit.m_kind;
<span class="line-modified">!     unsigned bytecodeOffset = exit.m_codeOrigin.bytecodeIndex;</span>
  
      dataLog(&quot;Speculation failure in &quot;, *codeBlock);
      dataLog(&quot; @ exit #&quot;, osrExitIndex, &quot; (bc#&quot;, bytecodeOffset, &quot;, &quot;, exitKindToString(kind), &quot;) with &quot;);
      if (alternative) {
          dataLog(
<span class="line-new-header">--- 896,11 ---</span>
  {
      ExecState* exec = context.fp&lt;ExecState*&gt;();
      CodeBlock* codeBlock = exec-&gt;codeBlock();
      CodeBlock* alternative = codeBlock-&gt;alternative();
      ExitKind kind = exit.m_kind;
<span class="line-modified">!     unsigned bytecodeOffset = exit.m_codeOrigin.bytecodeIndex();</span>
  
      dataLog(&quot;Speculation failure in &quot;, *codeBlock);
      dataLog(&quot; @ exit #&quot;, osrExitIndex, &quot; (bc#&quot;, bytecodeOffset, &quot;, &quot;, exitKindToString(kind), &quot;) with &quot;);
      if (alternative) {
          dataLog(
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1010,34 ***</span>
      }
  }
  
  void JIT_OPERATION OSRExit::compileOSRExit(ExecState* exec)
  {
<span class="line-modified">!     VM* vm = &amp;exec-&gt;vm();</span>
<span class="line-modified">!     auto scope = DECLARE_THROW_SCOPE(*vm);</span>
  
      if (validateDFGDoesGC) {
          // We&#39;re about to exit optimized code. So, there&#39;s no longer any optimized
          // code running that expects no GC.
<span class="line-modified">!         vm-&gt;heap.setExpectDoesGC(true);</span>
      }
  
<span class="line-modified">!     if (vm-&gt;callFrameForCatch)</span>
<span class="line-modified">!         RELEASE_ASSERT(vm-&gt;callFrameForCatch == exec);</span>
  
      CodeBlock* codeBlock = exec-&gt;codeBlock();
      ASSERT(codeBlock);
<span class="line-modified">!     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
  
      // It&#39;s sort of preferable that we don&#39;t GC while in here. Anyways, doing so wouldn&#39;t
      // really be profitable.
<span class="line-modified">!     DeferGCForAWhile deferGC(vm-&gt;heap);</span>
  
<span class="line-modified">!     uint32_t exitIndex = vm-&gt;osrExitIndex;</span>
      OSRExit&amp; exit = codeBlock-&gt;jitCode()-&gt;dfg()-&gt;osrExit[exitIndex];
  
<span class="line-modified">!     ASSERT(!vm-&gt;callFrameForCatch || exit.m_kind == GenericUnwind);</span>
      EXCEPTION_ASSERT_UNUSED(scope, !!scope.exception() || !exit.isExceptionHandler());
  
      prepareCodeOriginForOSRExit(exec, exit.m_codeOrigin);
  
      // Compute the value recoveries.
<span class="line-new-header">--- 1019,34 ---</span>
      }
  }
  
  void JIT_OPERATION OSRExit::compileOSRExit(ExecState* exec)
  {
<span class="line-modified">!     VM&amp; vm = exec-&gt;vm();</span>
<span class="line-modified">!     auto scope = DECLARE_THROW_SCOPE(vm);</span>
  
      if (validateDFGDoesGC) {
          // We&#39;re about to exit optimized code. So, there&#39;s no longer any optimized
          // code running that expects no GC.
<span class="line-modified">!         vm.heap.setExpectDoesGC(true);</span>
      }
  
<span class="line-modified">!     if (vm.callFrameForCatch)</span>
<span class="line-modified">!         RELEASE_ASSERT(vm.callFrameForCatch == exec);</span>
  
      CodeBlock* codeBlock = exec-&gt;codeBlock();
      ASSERT(codeBlock);
<span class="line-modified">!     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
  
      // It&#39;s sort of preferable that we don&#39;t GC while in here. Anyways, doing so wouldn&#39;t
      // really be profitable.
<span class="line-modified">!     DeferGCForAWhile deferGC(vm.heap);</span>
  
<span class="line-modified">!     uint32_t exitIndex = vm.osrExitIndex;</span>
      OSRExit&amp; exit = codeBlock-&gt;jitCode()-&gt;dfg()-&gt;osrExit[exitIndex];
  
<span class="line-modified">!     ASSERT(!vm.callFrameForCatch || exit.m_kind == GenericUnwind);</span>
      EXCEPTION_ASSERT_UNUSED(scope, !!scope.exception() || !exit.isExceptionHandler());
  
      prepareCodeOriginForOSRExit(exec, exit.m_codeOrigin);
  
      // Compute the value recoveries.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1052,30 ***</span>
          CCallHelpers jit(codeBlock);
  
          if (exit.m_kind == GenericUnwind) {
              // We are acting as a defacto op_catch because we arrive here from genericUnwind().
              // So, we must restore our call frame and stack pointer.
<span class="line-modified">!             jit.restoreCalleeSavesFromEntryFrameCalleeSavesBuffer(vm-&gt;topEntryFrame);</span>
<span class="line-modified">!             jit.loadPtr(vm-&gt;addressOfCallFrameForCatch(), GPRInfo::callFrameRegister);</span>
          }
          jit.addPtr(
              CCallHelpers::TrustedImm32(codeBlock-&gt;stackPointerOffset() * sizeof(Register)),
              GPRInfo::callFrameRegister, CCallHelpers::stackPointerRegister);
  
          jit.jitAssertHasValidCallFrame();
  
<span class="line-modified">!         if (UNLIKELY(vm-&gt;m_perBytecodeProfiler &amp;&amp; codeBlock-&gt;jitCode()-&gt;dfgCommon()-&gt;compilation)) {</span>
<span class="line-modified">!             Profiler::Database&amp; database = *vm-&gt;m_perBytecodeProfiler;</span>
              Profiler::Compilation* compilation = codeBlock-&gt;jitCode()-&gt;dfgCommon()-&gt;compilation.get();
  
              Profiler::OSRExit* profilerExit = compilation-&gt;addOSRExit(
                  exitIndex, Profiler::OriginStack(database, codeBlock, exit.m_codeOrigin),
                  exit.m_kind, exit.m_kind == UncountableInvalidation);
              jit.add64(CCallHelpers::TrustedImm32(1), CCallHelpers::AbsoluteAddress(profilerExit-&gt;counterAddress()));
          }
  
<span class="line-modified">!         compileExit(jit, *vm, exit, operands, recovery);</span>
  
          LinkBuffer patchBuffer(jit, codeBlock);
          exit.m_code = FINALIZE_CODE_IF(
              shouldDumpDisassembly() || Options::verboseOSR() || Options::verboseDFGOSRExit(),
              patchBuffer, OSRExitPtrTag,
<span class="line-new-header">--- 1061,30 ---</span>
          CCallHelpers jit(codeBlock);
  
          if (exit.m_kind == GenericUnwind) {
              // We are acting as a defacto op_catch because we arrive here from genericUnwind().
              // So, we must restore our call frame and stack pointer.
<span class="line-modified">!             jit.restoreCalleeSavesFromEntryFrameCalleeSavesBuffer(vm.topEntryFrame);</span>
<span class="line-modified">!             jit.loadPtr(vm.addressOfCallFrameForCatch(), GPRInfo::callFrameRegister);</span>
          }
          jit.addPtr(
              CCallHelpers::TrustedImm32(codeBlock-&gt;stackPointerOffset() * sizeof(Register)),
              GPRInfo::callFrameRegister, CCallHelpers::stackPointerRegister);
  
          jit.jitAssertHasValidCallFrame();
  
<span class="line-modified">!         if (UNLIKELY(vm.m_perBytecodeProfiler &amp;&amp; codeBlock-&gt;jitCode()-&gt;dfgCommon()-&gt;compilation)) {</span>
<span class="line-modified">!             Profiler::Database&amp; database = *vm.m_perBytecodeProfiler;</span>
              Profiler::Compilation* compilation = codeBlock-&gt;jitCode()-&gt;dfgCommon()-&gt;compilation.get();
  
              Profiler::OSRExit* profilerExit = compilation-&gt;addOSRExit(
                  exitIndex, Profiler::OriginStack(database, codeBlock, exit.m_codeOrigin),
                  exit.m_kind, exit.m_kind == UncountableInvalidation);
              jit.add64(CCallHelpers::TrustedImm32(1), CCallHelpers::AbsoluteAddress(profilerExit-&gt;counterAddress()));
          }
  
<span class="line-modified">!         compileExit(jit, vm, exit, operands, recovery);</span>
  
          LinkBuffer patchBuffer(jit, codeBlock);
          exit.m_code = FINALIZE_CODE_IF(
              shouldDumpDisassembly() || Options::verboseOSR() || Options::verboseDFGOSRExit(),
              patchBuffer, OSRExitPtrTag,
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1085,11 ***</span>
                  toCString(ignoringContext&lt;DumpContext&gt;(operands)).data());
      }
  
      MacroAssembler::repatchJump(exit.codeLocationForRepatch(), CodeLocationLabel&lt;OSRExitPtrTag&gt;(exit.m_code.code()));
  
<span class="line-modified">!     vm-&gt;osrExitJumpDestination = exit.m_code.code().executableAddress();</span>
  }
  
  void OSRExit::compileExit(CCallHelpers&amp; jit, VM&amp; vm, const OSRExit&amp; exit, const Operands&lt;ValueRecovery&gt;&amp; operands, SpeculationRecovery* recovery)
  {
      jit.jitAssertTagsInPlace();
<span class="line-new-header">--- 1094,11 ---</span>
                  toCString(ignoringContext&lt;DumpContext&gt;(operands)).data());
      }
  
      MacroAssembler::repatchJump(exit.codeLocationForRepatch(), CodeLocationLabel&lt;OSRExitPtrTag&gt;(exit.m_code.code()));
  
<span class="line-modified">!     vm.osrExitJumpDestination = exit.m_code.code().executableAddress();</span>
  }
  
  void OSRExit::compileExit(CCallHelpers&amp; jit, VM&amp; vm, const OSRExit&amp; exit, const Operands&lt;ValueRecovery&gt;&amp; operands, SpeculationRecovery* recovery)
  {
      jit.jitAssertTagsInPlace();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1097,11 ***</span>
      // Pro-forma stuff.
      if (Options::printEachOSRExit()) {
          SpeculationFailureDebugInfo* debugInfo = new SpeculationFailureDebugInfo;
          debugInfo-&gt;codeBlock = jit.codeBlock();
          debugInfo-&gt;kind = exit.m_kind;
<span class="line-modified">!         debugInfo-&gt;bytecodeOffset = exit.m_codeOrigin.bytecodeIndex;</span>
  
          jit.debugCall(vm, debugOperationPrintSpeculationFailure, debugInfo);
      }
  
      // Perform speculation recovery. This only comes into play when an operation
<span class="line-new-header">--- 1106,11 ---</span>
      // Pro-forma stuff.
      if (Options::printEachOSRExit()) {
          SpeculationFailureDebugInfo* debugInfo = new SpeculationFailureDebugInfo;
          debugInfo-&gt;codeBlock = jit.codeBlock();
          debugInfo-&gt;kind = exit.m_kind;
<span class="line-modified">!         debugInfo-&gt;bytecodeOffset = exit.m_codeOrigin.bytecodeIndex();</span>
  
          jit.debugCall(vm, debugOperationPrintSpeculationFailure, debugInfo);
      }
  
      // Perform speculation recovery. This only comes into play when an operation
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1114,10 ***</span>
<span class="line-new-header">--- 1123,19 ---</span>
  #if USE(JSVALUE64)
              jit.or64(GPRInfo::tagTypeNumberRegister, recovery-&gt;dest());
  #endif
              break;
  
<span class="line-added">+         case SpeculativeAddSelf:</span>
<span class="line-added">+             // If A + A = A (int32_t) overflows, A can be recovered by ((static_cast&lt;int32_t&gt;(A) &gt;&gt; 1) ^ 0x8000000).</span>
<span class="line-added">+             jit.rshift32(AssemblyHelpers::TrustedImm32(1), recovery-&gt;dest());</span>
<span class="line-added">+             jit.xor32(AssemblyHelpers::TrustedImm32(0x80000000), recovery-&gt;dest());</span>
<span class="line-added">+ #if USE(JSVALUE64)</span>
<span class="line-added">+             jit.or64(GPRInfo::tagTypeNumberRegister, recovery-&gt;dest());</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+             break;</span>
<span class="line-added">+ </span>
          case SpeculativeAddImmediate:
              jit.sub32(AssemblyHelpers::Imm32(recovery-&gt;immediate()), recovery-&gt;dest());
  #if USE(JSVALUE64)
              jit.or64(GPRInfo::tagTypeNumberRegister, recovery-&gt;dest());
  #endif
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1146,11 ***</span>
              // while the former case is an outcome of a CheckStructure not knowing why
              // it was emitted (could be either due to an inline cache of a property
              // property access, or due to an array profile).
  
              CodeOrigin codeOrigin = exit.m_codeOriginForExitProfile;
<span class="line-modified">!             if (ArrayProfile* arrayProfile = jit.baselineCodeBlockFor(codeOrigin)-&gt;getArrayProfile(codeOrigin.bytecodeIndex)) {</span>
  #if USE(JSVALUE64)
                  GPRReg usedRegister;
                  if (exit.m_jsValueSource.isAddress())
                      usedRegister = exit.m_jsValueSource.base();
                  else
<span class="line-new-header">--- 1164,11 ---</span>
              // while the former case is an outcome of a CheckStructure not knowing why
              // it was emitted (could be either due to an inline cache of a property
              // property access, or due to an array profile).
  
              CodeOrigin codeOrigin = exit.m_codeOriginForExitProfile;
<span class="line-modified">!             if (ArrayProfile* arrayProfile = jit.baselineCodeBlockFor(codeOrigin)-&gt;getArrayProfile(codeOrigin.bytecodeIndex())) {</span>
  #if USE(JSVALUE64)
                  GPRReg usedRegister;
                  if (exit.m_jsValueSource.isAddress())
                      usedRegister = exit.m_jsValueSource.base();
                  else
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1627,18 ***</span>
      adjustAndJumpToTarget(vm, jit, exit);
  }
  
  void JIT_OPERATION OSRExit::debugOperationPrintSpeculationFailure(ExecState* exec, void* debugInfoRaw, void* scratch)
  {
<span class="line-modified">!     VM* vm = &amp;exec-&gt;vm();</span>
      NativeCallFrameTracer tracer(vm, exec);
  
      SpeculationFailureDebugInfo* debugInfo = static_cast&lt;SpeculationFailureDebugInfo*&gt;(debugInfoRaw);
      CodeBlock* codeBlock = debugInfo-&gt;codeBlock;
      CodeBlock* alternative = codeBlock-&gt;alternative();
      dataLog(&quot;Speculation failure in &quot;, *codeBlock);
<span class="line-modified">!     dataLog(&quot; @ exit #&quot;, vm-&gt;osrExitIndex, &quot; (bc#&quot;, debugInfo-&gt;bytecodeOffset, &quot;, &quot;, exitKindToString(debugInfo-&gt;kind), &quot;) with &quot;);</span>
      if (alternative) {
          dataLog(
              &quot;executeCounter = &quot;, alternative-&gt;jitExecuteCounter(),
              &quot;, reoptimizationRetryCounter = &quot;, alternative-&gt;reoptimizationRetryCounter(),
              &quot;, optimizationDelayCounter = &quot;, alternative-&gt;optimizationDelayCounter());
<span class="line-new-header">--- 1645,18 ---</span>
      adjustAndJumpToTarget(vm, jit, exit);
  }
  
  void JIT_OPERATION OSRExit::debugOperationPrintSpeculationFailure(ExecState* exec, void* debugInfoRaw, void* scratch)
  {
<span class="line-modified">!     VM&amp; vm = exec-&gt;vm();</span>
      NativeCallFrameTracer tracer(vm, exec);
  
      SpeculationFailureDebugInfo* debugInfo = static_cast&lt;SpeculationFailureDebugInfo*&gt;(debugInfoRaw);
      CodeBlock* codeBlock = debugInfo-&gt;codeBlock;
      CodeBlock* alternative = codeBlock-&gt;alternative();
      dataLog(&quot;Speculation failure in &quot;, *codeBlock);
<span class="line-modified">!     dataLog(&quot; @ exit #&quot;, vm.osrExitIndex, &quot; (bc#&quot;, debugInfo-&gt;bytecodeOffset, &quot;, &quot;, exitKindToString(debugInfo-&gt;kind), &quot;) with &quot;);</span>
      if (alternative) {
          dataLog(
              &quot;executeCounter = &quot;, alternative-&gt;jitExecuteCounter(),
              &quot;, reoptimizationRetryCounter = &quot;, alternative-&gt;reoptimizationRetryCounter(),
              &quot;, optimizationDelayCounter = &quot;, alternative-&gt;optimizationDelayCounter());
</pre>
<center><a href="DFGOSREntrypointCreationPhase.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGOSRExit.h.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>