<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="LowLevelInterpreter.asm.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter32_64.asm.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 247,25 ***</span>
      // caller (or one of its ancestors) is responsible for ensuring that this
      // is only called once during the initialization of the VM before threads
      // are at play.
      if (UNLIKELY(isInitializationPass)) {
          Opcode* opcodeMap = LLInt::opcodeMap();
<span class="line-modified">!         Opcode* opcodeMapWide = LLInt::opcodeMapWide();</span>
  
  #if ENABLE(COMPUTED_GOTO_OPCODES)
          #define OPCODE_ENTRY(__opcode, length) \
              opcodeMap[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode); \
<span class="line-modified">!             opcodeMapWide[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode##_wide);</span>
  
          #define LLINT_OPCODE_ENTRY(__opcode, length) \
              opcodeMap[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode);
  #else
          // FIXME: this mapping is unnecessarily expensive in the absence of COMPUTED_GOTO
          //   narrow opcodes don&#39;t need any mapping and wide opcodes just need to add numOpcodeIDs
          #define OPCODE_ENTRY(__opcode, length) \
              opcodeMap[__opcode] = __opcode; \
<span class="line-modified">!             opcodeMapWide[__opcode] = static_cast&lt;OpcodeID&gt;(__opcode##_wide);</span>
  
          #define LLINT_OPCODE_ENTRY(__opcode, length) \
              opcodeMap[__opcode] = __opcode;
  #endif
          FOR_EACH_BYTECODE_ID(OPCODE_ENTRY)
<span class="line-new-header">--- 247,28 ---</span>
      // caller (or one of its ancestors) is responsible for ensuring that this
      // is only called once during the initialization of the VM before threads
      // are at play.
      if (UNLIKELY(isInitializationPass)) {
          Opcode* opcodeMap = LLInt::opcodeMap();
<span class="line-modified">!         Opcode* opcodeMapWide16 = LLInt::opcodeMapWide16();</span>
<span class="line-added">+         Opcode* opcodeMapWide32 = LLInt::opcodeMapWide32();</span>
  
  #if ENABLE(COMPUTED_GOTO_OPCODES)
          #define OPCODE_ENTRY(__opcode, length) \
              opcodeMap[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode); \
<span class="line-modified">!             opcodeMapWide16[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode##_wide16); \</span>
<span class="line-added">+             opcodeMapWide32[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode##_wide32);</span>
  
          #define LLINT_OPCODE_ENTRY(__opcode, length) \
              opcodeMap[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode);
  #else
          // FIXME: this mapping is unnecessarily expensive in the absence of COMPUTED_GOTO
          //   narrow opcodes don&#39;t need any mapping and wide opcodes just need to add numOpcodeIDs
          #define OPCODE_ENTRY(__opcode, length) \
              opcodeMap[__opcode] = __opcode; \
<span class="line-modified">!             opcodeMapWide16[__opcode] = static_cast&lt;OpcodeID&gt;(__opcode##_wide16); \</span>
<span class="line-added">+             opcodeMapWide32[__opcode] = static_cast&lt;OpcodeID&gt;(__opcode##_wide32);</span>
  
          #define LLINT_OPCODE_ENTRY(__opcode, length) \
              opcodeMap[__opcode] = __opcode;
  #endif
          FOR_EACH_BYTECODE_ID(OPCODE_ENTRY)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 283,11 ***</span>
  
          return JSValue();
      }
  
      // Define the pseudo registers used by the LLINT C Loop backend:
<span class="line-modified">!     ASSERT(sizeof(CLoopRegister) == sizeof(intptr_t));</span>
  
      // The CLoop llint backend is initially based on the ARMv7 backend, and
      // then further enhanced with a few instructions from the x86 backend to
      // support building for X64 targets. Hence, the shape of the generated
      // code and the usage convention of registers will look a lot like the
<span class="line-new-header">--- 286,11 ---</span>
  
          return JSValue();
      }
  
      // Define the pseudo registers used by the LLINT C Loop backend:
<span class="line-modified">!     static_assert(sizeof(CLoopRegister) == sizeof(intptr_t));</span>
  
      // The CLoop llint backend is initially based on the ARMv7 backend, and
      // then further enhanced with a few instructions from the x86 backend to
      // support building for X64 targets. Hence, the shape of the generated
      // code and the usage convention of registers will look a lot like the
</pre>
<center><a href="LowLevelInterpreter.asm.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter32_64.asm.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>