<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.web/src/main/native/Source/JavaScriptCore/b3/air/AirOpcode.opcodes</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 # Copyright (C) 2015-2017 Apple Inc. All rights reserved.
   2 #
   3 # Redistribution and use in source and binary forms, with or without
   4 # modification, are permitted provided that the following conditions
   5 # are met:
   6 # 1. Redistributions of source code must retain the above copyright
   7 #    notice, this list of conditions and the following disclaimer.
   8 # 2. Redistributions in binary form must reproduce the above copyright
   9 #    notice, this list of conditions and the following disclaimer in the
  10 #    documentation and/or other materials provided with the distribution.
  11 #
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 # Syllabus:
  25 #
  26 # Examples of some roles, types, and widths:
  27 # U:G:32 =&gt; use of the low 32 bits of a general-purpose register or value
  28 # D:G:32 =&gt; def of the low 32 bits of a general-purpose register or value
  29 # UD:G:32 =&gt; use and def of the low 32 bits of a general-purpose register or value
  30 # U:G:64 =&gt; use of the low 64 bits of a general-purpose register or value
  31 # ZD:G:32 =&gt; def of all bits of a general-purpose register, where all but the low 32 bits are guaranteed to be zeroed.
  32 # UA:G:Ptr =&gt; UseAddr (see comment in Arg.h)
  33 # U:F:32 =&gt; use of a float register or value
  34 # U:F:64 =&gt; use of a double register or value
  35 # D:F:32 =&gt; def of a float register or value
  36 # UD:F:32 =&gt; use and def of a float register or value
  37 # S:F:32 =&gt; scratch float register.
  38 #
  39 # Argument kinds:
  40 # Tmp =&gt; temporary or register
  41 # Imm =&gt; 32-bit immediate int
  42 # BigImm =&gt; TrustedImm64
  43 # Addr =&gt; address as temporary/register+offset
  44 # Index =&gt; BaseIndex address
  45 # Abs =&gt; AbsoluteAddress
  46 #
  47 # The parser views these things as keywords, and understands that they fall into two distinct classes
  48 # of things. So, although this file uses a particular indentation style, none of the whitespace or
  49 # even newlines are meaningful to the parser. For example, you could write:
  50 #
  51 # Foo42 U:G:32, UD:F:32 Imm, Tmp Addr, Tmp
  52 #
  53 # And the parser would know that this is the same as:
  54 #
  55 # Foo42 U:G:32, UD:F:32
  56 #     Imm, Tmp
  57 #     Addr, Tmp
  58 #
  59 # I.e. a two-form instruction that uses a GPR or an int immediate and uses+defs a float register.
  60 #
  61 # Any opcode or opcode form can be preceded with an architecture list, which restricts the opcode to the
  62 # union of those architectures. For example, if this is the only overload of the opcode, then it makes the
  63 # opcode only available on x86_64:
  64 #
  65 # x86_64: Fuzz UD:G:64, D:G:64
  66 #     Tmp, Tmp
  67 #     Tmp, Addr
  68 #
  69 # But this only restricts the two-operand form, the other form is allowed on all architectures:
  70 #
  71 # x86_64: Fuzz UD:G:64, D:G:64
  72 #     Tmp, Tmp
  73 #     Tmp, Addr
  74 # Fuzz UD:G:Ptr, D:G:Ptr, U:F:Ptr
  75 #     Tmp, Tmp, Tmp
  76 #     Tmp, Addr, Tmp
  77 #
  78 # And you can also restrict individual forms:
  79 #
  80 # Thingy UD:G:32, D:G:32
  81 #     Tmp, Tmp
  82 #     arm64: Tmp, Addr
  83 #
  84 # Additionally, you can have an intersection between the architectures of the opcode overload and the
  85 # form. In this example, the version that takes an address is only available on armv7 while the other
  86 # versions are available on armv7 or x86_64:
  87 #
  88 # x86_64 armv7: Buzz U:G:32, UD:F:32
  89 #     Tmp, Tmp
  90 #     Imm, Tmp
  91 #     armv7: Addr, Tmp
  92 #
  93 # Finally, you can specify architectures using helpful architecture groups. Here are all of the
  94 # architecture keywords that we support:
  95 #
  96 # x86: means x86-32 or x86-64.
  97 # x86_32: means just x86-32.
  98 # x86_64: means just x86-64.
  99 # arm: means armv7 or arm64.
 100 # armv7: means just armv7.
 101 # arm64: means just arm64.
 102 # 32: means x86-32 or armv7.
 103 # 64: means x86-64 or arm64.
 104 
 105 # Note that the opcodes here have a leading capital (Add32) but must correspond to MacroAssembler
 106 # API that has a leading lower-case (add32).
 107 
 108 Nop
 109 
 110 Add32 U:G:32, U:G:32, ZD:G:32
 111     Imm, Tmp, Tmp
 112     Tmp, Tmp, Tmp
 113 
 114 Add32 U:G:32, UZD:G:32
 115     Tmp, Tmp
 116     x86: Imm, Addr
 117     x86: Imm, Index
 118     Imm, Tmp
 119     x86: Addr, Tmp
 120     x86: Index, Tmp
 121     x86: Tmp, Addr
 122     x86: Tmp, Index
 123 
 124 x86: Add8 U:G:8, UD:G:8
 125     Imm, Addr
 126     Imm, Index
 127     Tmp, Addr
 128     Tmp, Index
 129 
 130 x86: Add16 U:G:16, UD:G:16
 131     Imm, Addr
 132     Imm, Index
 133     Tmp, Addr
 134     Tmp, Index
 135 
 136 64: Add64 U:G:64, UD:G:64
 137     Tmp, Tmp
 138     x86: Imm, Addr
 139     x86: Imm, Index
 140     Imm, Tmp
 141     x86: Addr, Tmp
 142     x86: Index, Tmp
 143     x86: Tmp, Addr
 144     x86: Tmp, Index
 145 
 146 64: Add64 U:G:64, U:G:64, D:G:64
 147     Imm, Tmp, Tmp
 148     Tmp, Tmp, Tmp
 149 
 150 AddDouble U:F:64, U:F:64, D:F:64
 151     Tmp, Tmp, Tmp
 152     x86: Addr, Tmp, Tmp
 153     x86: Tmp, Addr, Tmp
 154     x86: Index, Tmp, Tmp
 155 
 156 x86: AddDouble U:F:64, UD:F:64
 157     Tmp, Tmp
 158     Addr, Tmp
 159 
 160 AddFloat U:F:32, U:F:32, D:F:32
 161     Tmp, Tmp, Tmp
 162     x86: Addr, Tmp, Tmp
 163     x86: Tmp, Addr, Tmp
 164     x86: Index, Tmp, Tmp
 165 
 166 x86: AddFloat U:F:32, UD:F:32
 167     Tmp, Tmp
 168     Addr, Tmp
 169 
 170 Sub32 U:G:32, UZD:G:32
 171     Tmp, Tmp
 172     x86: Imm, Addr
 173     x86: Imm, Index
 174     Imm, Tmp
 175     x86: Addr, Tmp
 176     x86: Index, Tmp
 177     x86: Tmp, Addr
 178     x86: Tmp, Index
 179 
 180 arm64: Sub32 U:G:32, U:G:32, D:G:32
 181     Tmp, Tmp, Tmp
 182 
 183 64: Sub64 U:G:64, UD:G:64
 184     Tmp, Tmp
 185     x86: Imm, Addr
 186     x86: Imm, Index
 187     Imm, Tmp
 188     x86: Addr, Tmp
 189     x86: Index, Tmp
 190     x86: Tmp, Addr
 191     x86: Tmp, Index
 192 
 193 arm64: Sub64 U:G:64, U:G:64, D:G:64
 194     Tmp, Tmp, Tmp
 195 
 196 SubDouble U:F:64, U:F:64, D:F:64
 197     arm64: Tmp, Tmp, Tmp
 198     x86: Tmp, Addr, Tmp
 199     x86: Tmp, Index, Tmp
 200 
 201 x86: SubDouble U:F:64, UD:F:64
 202     Tmp, Tmp
 203     Addr, Tmp
 204 
 205 SubFloat U:F:32, U:F:32, D:F:32
 206     arm64: Tmp, Tmp, Tmp
 207     x86: Tmp, Addr, Tmp
 208     x86: Tmp, Index, Tmp
 209 
 210 x86: SubFloat U:F:32, UD:F:32
 211     Tmp, Tmp
 212     Addr, Tmp
 213 
 214 Neg32 UZD:G:32
 215     Tmp
 216     x86: Addr
 217     x86: Index
 218 
 219 64: Neg64 UD:G:64
 220     Tmp
 221     x86: Addr
 222     x86: Index
 223 
 224 arm64: NegateDouble U:F:64, D:F:64
 225     Tmp, Tmp
 226 
 227 arm64: NegateFloat U:F:32, D:F:32
 228     Tmp, Tmp
 229 
 230 Mul32 U:G:32, UZD:G:32
 231     Tmp, Tmp
 232     x86: Addr, Tmp
 233 
 234 Mul32 U:G:32, U:G:32, ZD:G:32
 235     Tmp, Tmp, Tmp
 236     x86: Addr, Tmp, Tmp
 237     x86: Tmp, Addr, Tmp
 238     x86: Imm, Tmp, Tmp
 239 
 240 64: Mul64 U:G:64, UD:G:64
 241     Tmp, Tmp
 242 
 243 Mul64 U:G:64, U:G:64, D:G:64
 244     Tmp, Tmp, Tmp
 245 
 246 arm64: MultiplyAdd32 U:G:32, U:G:32, U:G:32, ZD:G:32
 247     Tmp, Tmp, Tmp, Tmp
 248 
 249 arm64: MultiplyAdd64 U:G:64, U:G:64, U:G:64, D:G:64
 250     Tmp, Tmp, Tmp, Tmp
 251 
 252 arm64: MultiplySub32 U:G:32, U:G:32, U:G:32, ZD:G:32
 253     Tmp, Tmp, Tmp, Tmp
 254 
 255 arm64: MultiplySub64 U:G:64, U:G:64, U:G:64, D:G:64
 256     Tmp, Tmp, Tmp, Tmp
 257 
 258 arm64: MultiplyNeg32 U:G:32, U:G:32, ZD:G:32
 259     Tmp, Tmp, Tmp
 260 
 261 arm64: MultiplyNeg64 U:G:64, U:G:64, ZD:G:64
 262     Tmp, Tmp, Tmp
 263 
 264 arm64: Div32 U:G:32, U:G:32, ZD:G:32
 265     Tmp, Tmp, Tmp
 266 
 267 arm64: UDiv32 U:G:32, U:G:32, ZD:G:32
 268     Tmp, Tmp, Tmp
 269 
 270 arm64: Div64 U:G:64, U:G:64, D:G:64
 271     Tmp, Tmp, Tmp
 272 
 273 arm64: UDiv64 U:G:64, U:G:64, D:G:64
 274     Tmp, Tmp, Tmp
 275 
 276 MulDouble U:F:64, U:F:64, D:F:64
 277     Tmp, Tmp, Tmp
 278     x86: Addr, Tmp, Tmp
 279     x86: Tmp, Addr, Tmp
 280     x86: Index, Tmp, Tmp
 281 
 282 x86: MulDouble U:F:64, UD:F:64
 283     Tmp, Tmp
 284     Addr, Tmp
 285 
 286 MulFloat U:F:32, U:F:32, D:F:32
 287     Tmp, Tmp, Tmp
 288     x86: Addr, Tmp, Tmp
 289     x86: Tmp, Addr, Tmp
 290     x86: Index, Tmp, Tmp
 291 
 292 x86: MulFloat U:F:32, UD:F:32
 293     Tmp, Tmp
 294     Addr, Tmp
 295 
 296 arm64: DivDouble U:F:64, U:F:32, D:F:64
 297     Tmp, Tmp, Tmp
 298 
 299 x86: DivDouble U:F:64, UD:F:64
 300     Tmp, Tmp
 301     Addr, Tmp
 302 
 303 arm64: DivFloat U:F:32, U:F:32, D:F:32
 304     Tmp, Tmp, Tmp
 305 
 306 x86: DivFloat U:F:32, UD:F:32
 307     Tmp, Tmp
 308     Addr, Tmp
 309 
 310 x86: X86ConvertToDoubleWord32 U:G:32, ZD:G:32
 311     Tmp*, Tmp*
 312 
 313 x86_64: X86ConvertToQuadWord64 U:G:64, D:G:64
 314     Tmp*, Tmp*
 315 
 316 x86: X86Div32 UZD:G:32, UZD:G:32, U:G:32
 317     Tmp*, Tmp*, Tmp
 318 
 319 x86: X86UDiv32 UZD:G:32, UZD:G:32, U:G:32
 320     Tmp*, Tmp*, Tmp
 321 
 322 x86_64: X86Div64 UZD:G:64, UZD:G:64, U:G:64
 323     Tmp*, Tmp*, Tmp
 324 
 325 x86_64: X86UDiv64 UZD:G:64, UZD:G:64, U:G:64
 326     Tmp*, Tmp*, Tmp
 327 
 328 # If we add other things like Lea that are UA, we may need to lower
 329 # them on arm64 similarly to how we do for Lea. In lowerStackArgs,
 330 # we lower Lea to add on arm64.
 331 Lea32 UA:G:32, D:G:32
 332     Addr, Tmp
 333     x86: Index, Tmp as x86Lea32
 334 
 335 Lea64 UA:G:64, D:G:64
 336     Addr, Tmp
 337     x86: Index, Tmp as x86Lea64
 338 
 339 And32 U:G:32, U:G:32, ZD:G:32
 340     Tmp, Tmp, Tmp
 341     arm64: BitImm, Tmp, Tmp
 342     x86: Tmp, Addr, Tmp
 343     x86: Addr, Tmp, Tmp
 344 
 345 And32 U:G:32, UZD:G:32
 346     Tmp, Tmp
 347     x86: Imm, Tmp
 348     x86: Tmp, Addr
 349     x86: Tmp, Index
 350     x86: Addr, Tmp
 351     x86: Index, Tmp
 352     x86: Imm, Addr
 353     x86: Imm, Index
 354 
 355 64: And64 U:G:64, U:G:64, D:G:64
 356     Tmp, Tmp, Tmp
 357     arm64: BitImm64, Tmp, Tmp
 358 
 359 x86_64: And64 U:G:64, UD:G:64
 360     Tmp, Tmp
 361     Imm, Tmp
 362     Imm, Addr
 363     Imm, Index
 364     Tmp, Addr
 365     Tmp, Index
 366     Addr, Tmp
 367     Index, Tmp
 368 
 369 AndDouble U:F:64, U:F:64, D:F:64
 370     Tmp, Tmp, Tmp
 371 
 372 x86: AndDouble U:F:64, UD:F:64
 373     Tmp, Tmp
 374 
 375 AndFloat U:F:32, U:F:32, D:F:32
 376     Tmp, Tmp, Tmp
 377 
 378 x86: AndFloat U:F:32, UD:F:32
 379     Tmp, Tmp
 380 
 381 OrDouble U:F:64, U:F:64, D:F:64
 382     Tmp, Tmp, Tmp
 383 
 384 x86: OrDouble U:F:64, UD:F:64
 385     Tmp, Tmp
 386 
 387 OrFloat U:F:32, U:F:32, D:F:32
 388     Tmp, Tmp, Tmp
 389 
 390 x86: OrFloat U:F:32, UD:F:32
 391     Tmp, Tmp
 392 
 393 x86: XorDouble U:F:64, U:F:64, D:F:64
 394     Tmp, Tmp, Tmp
 395 
 396 x86: XorDouble U:F:64, UD:F:64
 397     Tmp, Tmp
 398 
 399 x86: XorFloat U:F:32, U:F:32, D:F:32
 400     Tmp, Tmp, Tmp
 401 
 402 x86: XorFloat U:F:32, UD:F:32
 403     Tmp, Tmp
 404 
 405 arm64: Lshift32 U:G:32, U:G:32, ZD:G:32
 406     Tmp, Tmp, Tmp
 407     Tmp, Imm, Tmp
 408 
 409 x86:Lshift32 U:G:32, UZD:G:32
 410     Tmp*, Tmp
 411     Imm, Tmp
 412 
 413 arm64: Lshift64 U:G:64, U:G:64, D:G:64
 414     Tmp, Tmp, Tmp
 415     Tmp, Imm, Tmp
 416 
 417 x86_64: Lshift64 U:G:64, UD:G:64
 418     Tmp*, Tmp
 419     Imm, Tmp
 420 
 421 arm64: Rshift32 U:G:32, U:G:32, ZD:G:32
 422     Tmp, Tmp, Tmp
 423     Tmp, Imm, Tmp
 424 
 425 x86: Rshift32 U:G:32, UZD:G:32
 426     Tmp*, Tmp
 427     Imm, Tmp
 428 
 429 arm64: Rshift64 U:G:64, U:G:64, D:G:64
 430     Tmp, Tmp, Tmp
 431     Tmp, Imm, Tmp
 432 
 433 x86_64: Rshift64 U:G:64, UD:G:64
 434     Tmp*, Tmp
 435     Imm, Tmp
 436 
 437 arm64: Urshift32 U:G:32, U:G:32, ZD:G:32
 438     Tmp, Tmp, Tmp
 439     Tmp, Imm, Tmp
 440 
 441 x86: Urshift32 U:G:32, UZD:G:32
 442     Tmp*, Tmp
 443     Imm, Tmp
 444 
 445 arm64: Urshift64 U:G:64, U:G:64, D:G:64
 446     Tmp, Tmp, Tmp
 447     Tmp, Imm, Tmp
 448 
 449 x86_64: Urshift64 U:G:64, UD:G:64
 450     Tmp*, Tmp
 451     Imm, Tmp
 452 
 453 x86_64: RotateRight32 U:G:32, UZD:G:32
 454     Tmp*, Tmp
 455     Imm, Tmp
 456 
 457 arm64: RotateRight32 U:G:32, U:G:32, ZD:G:32
 458     Tmp, Tmp, Tmp
 459     Tmp, Imm, Tmp
 460 
 461 x86_64: RotateRight64 U:G:64, UD:G:64
 462     Tmp*, Tmp
 463     Imm, Tmp
 464 
 465 arm64: RotateRight64 U:G:64, U:G:64, D:G:64
 466     Tmp, Tmp, Tmp
 467     Tmp, Imm, Tmp
 468 
 469 x86_64: RotateLeft32 U:G:32, UZD:G:32
 470     Tmp*, Tmp
 471     Imm, Tmp
 472 
 473 x86_64: RotateLeft64 U:G:64, UD:G:64
 474     Tmp*, Tmp
 475     Imm, Tmp
 476 
 477 Or32 U:G:32, U:G:32, ZD:G:32
 478     Tmp, Tmp, Tmp
 479     arm64: BitImm, Tmp, Tmp
 480     x86: Tmp, Addr, Tmp
 481     x86: Addr, Tmp, Tmp
 482 
 483 Or32 U:G:32, UZD:G:32
 484     Tmp, Tmp
 485     x86: Imm, Tmp
 486     x86: Tmp, Addr
 487     x86: Tmp, Index
 488     x86: Addr, Tmp
 489     x86: Index, Tmp
 490     x86: Imm, Addr
 491     x86: Imm, Index
 492 
 493 64: Or64 U:G:64, U:G:64, D:G:64
 494     Tmp, Tmp, Tmp
 495     arm64: BitImm64, Tmp, Tmp
 496 
 497 64: Or64 U:G:64, UD:G:64
 498     Tmp, Tmp
 499     x86: Imm, Tmp
 500     x86: Imm, Addr
 501     x86: Imm, Index
 502     x86: Tmp, Addr
 503     x86: Tmp, Index
 504     x86: Addr, Tmp
 505     x86: Index, Tmp
 506 
 507 Xor32 U:G:32, U:G:32, ZD:G:32
 508     Tmp, Tmp, Tmp
 509     arm64: BitImm, Tmp, Tmp
 510     x86: Tmp, Addr, Tmp
 511     x86: Addr, Tmp, Tmp
 512 
 513 Xor32 U:G:32, UZD:G:32
 514     Tmp, Tmp
 515     x86: Imm, Tmp
 516     x86: Tmp, Addr
 517     x86: Tmp, Index
 518     x86: Addr, Tmp
 519     x86: Index, Tmp
 520     x86: Imm, Addr
 521     x86: Imm, Index
 522 
 523 64: Xor64 U:G:64, U:G:64, D:G:64
 524     Tmp, Tmp, Tmp
 525     arm64: BitImm64, Tmp, Tmp
 526 
 527 64: Xor64 U:G:64, UD:G:64
 528     Tmp, Tmp
 529     x86: Tmp, Addr
 530     x86: Tmp, Index
 531     x86: Addr, Tmp
 532     x86: Index, Tmp
 533     x86: Imm, Addr
 534     x86: Imm, Index
 535     x86: Imm, Tmp
 536 
 537 arm64: Not32 U:G:32, ZD:G:32
 538     Tmp, Tmp
 539 
 540 x86: Not32 UZD:G:32
 541     Tmp
 542     Addr
 543     Index
 544 
 545 arm64: Not64 U:G:64, D:G:64
 546     Tmp, Tmp
 547 
 548 x86_64: Not64 UD:G:64
 549     Tmp
 550     Addr
 551     Index
 552 
 553 arm64: AbsDouble U:F:64, D:F:64
 554     Tmp, Tmp
 555 
 556 arm64: AbsFloat U:F:32, D:F:32
 557     Tmp, Tmp
 558 
 559 CeilDouble U:F:64, D:F:64
 560     Tmp, Tmp
 561     x86: Addr, Tmp
 562 
 563 CeilFloat U:F:32, D:F:32
 564     Tmp, Tmp
 565     x86: Addr, Tmp
 566 
 567 FloorDouble U:F:64, D:F:64
 568     Tmp, Tmp
 569     x86: Addr, Tmp
 570 
 571 FloorFloat U:F:32, D:F:32
 572     Tmp, Tmp
 573     x86: Addr, Tmp
 574 
 575 SqrtDouble U:F:64, D:F:64
 576     Tmp, Tmp
 577     x86: Addr, Tmp
 578 
 579 SqrtFloat U:F:32, D:F:32
 580     Tmp, Tmp
 581     x86: Addr, Tmp
 582 
 583 ConvertInt32ToDouble U:G:32, D:F:64
 584     Tmp, Tmp
 585     x86: Addr, Tmp
 586 
 587 64: ConvertInt64ToDouble U:G:64, D:F:64
 588     Tmp, Tmp
 589     x86_64: Addr, Tmp
 590 
 591 ConvertInt32ToFloat U:G:32, D:F:32
 592     Tmp, Tmp
 593     x86: Addr, Tmp
 594 
 595 64: ConvertInt64ToFloat U:G:64, D:F:32
 596     Tmp, Tmp
 597     x86_64: Addr, Tmp
 598 
 599 CountLeadingZeros32 U:G:32, ZD:G:32
 600     Tmp, Tmp
 601     x86: Addr, Tmp
 602 
 603 64: CountLeadingZeros64 U:G:64, D:G:64
 604     Tmp, Tmp
 605     x86: Addr, Tmp
 606 
 607 ConvertDoubleToFloat U:F:64, D:F:32
 608     Tmp, Tmp
 609     x86: Addr, Tmp
 610 
 611 ConvertFloatToDouble U:F:32, D:F:64
 612     Tmp, Tmp
 613     x86: Addr, Tmp
 614 
 615 # Note that Move operates over the full register size, which is either 32-bit or 64-bit depending on
 616 # the platform. I&#39;m not entirely sure that this is a good thing; it might be better to just have a
 617 # Move64 instruction. OTOH, our MacroAssemblers already have this notion of &quot;move()&quot; that basically
 618 # means movePtr.
 619 Move U:G:Ptr, D:G:Ptr
 620     Tmp, Tmp
 621     Imm, Tmp as signExtend32ToPtr
 622     BigImm, Tmp
 623     Addr, Tmp as loadPtr # This means that &quot;Move Addr, Tmp&quot; is code-generated as &quot;load&quot; not &quot;move&quot;.
 624     Index, Tmp as loadPtr
 625     Tmp, Addr as storePtr
 626     Tmp, Index as storePtr
 627     x86: Imm, Addr as storePtr
 628 
 629 # This is for moving between spill slots.
 630 Move U:G:Ptr, D:G:Ptr, S:G:Ptr
 631     Addr, Addr, Tmp
 632 
 633 x86: Swap32 UD:G:32, UD:G:32
 634     Tmp, Tmp
 635     Tmp, Addr
 636 
 637 x86_64: Swap64 UD:G:64, UD:G:64
 638     Tmp, Tmp
 639     Tmp, Addr
 640 
 641 Move32 U:G:32, ZD:G:32
 642     Tmp, Tmp as zeroExtend32ToPtr
 643     Addr, Tmp as load32
 644     Index, Tmp as load32
 645     Tmp, Addr as store32
 646     Tmp, Index as store32
 647     x86: Imm, Tmp as zeroExtend32ToPtr
 648     x86: Imm, Addr as store32
 649     x86: Imm, Index as store32
 650 
 651 # This is for moving between spill slots.
 652 Move32 U:G:32, ZD:G:32, S:G:32
 653     Addr, Addr, Tmp
 654 
 655 # FIXME: StoreZero32 and StoreZero64 are hacks on ARM64, we can do better: https://bugs.webkit.org/show_bug.cgi?id=174821
 656 StoreZero32 D:G:32
 657     Addr
 658     Index
 659 
 660 64: StoreZero64 D:G:64
 661     Addr
 662     Index
 663 
 664 SignExtend32ToPtr U:G:32, D:G:Ptr
 665     Tmp, Tmp
 666 
 667 ZeroExtend8To32 U:G:8, ZD:G:32
 668     Tmp, Tmp
 669     x86: Addr, Tmp as load8
 670     x86: Index, Tmp as load8
 671 
 672 SignExtend8To32 U:G:8, ZD:G:32
 673     Tmp, Tmp
 674     x86: Addr, Tmp as load8SignedExtendTo32
 675     x86: Index, Tmp as load8SignedExtendTo32
 676 
 677 ZeroExtend16To32 U:G:16, ZD:G:32
 678     Tmp, Tmp
 679     x86: Addr, Tmp as load16
 680     x86: Index, Tmp as load16
 681 
 682 SignExtend16To32 U:G:16, ZD:G:32
 683     Tmp, Tmp
 684     x86: Addr, Tmp as load16SignedExtendTo32
 685     x86: Index, Tmp as load16SignedExtendTo32
 686 
 687 MoveFloat U:F:32, D:F:32
 688     Tmp, Tmp as moveDouble
 689     Addr, Tmp as loadFloat
 690     Index, Tmp as loadFloat
 691     Tmp, Addr as storeFloat
 692     Tmp, Index as storeFloat
 693 
 694 MoveFloat U:F:32, D:F:32, S:F:32
 695     Addr, Addr, Tmp
 696 
 697 MoveDouble U:F:64, D:F:64
 698     Tmp, Tmp
 699     Addr, Tmp as loadDouble
 700     Index, Tmp as loadDouble
 701     Tmp, Addr as storeDouble
 702     Tmp, Index as storeDouble
 703 
 704 MoveDouble U:F:64, D:F:64, S:F:64
 705     Addr, Addr, Tmp
 706 
 707 MoveZeroToDouble D:F:64
 708     Tmp
 709 
 710 64: Move64ToDouble U:G:64, D:F:64
 711     Tmp, Tmp
 712     x86: Addr, Tmp as loadDouble
 713     Index, Tmp as loadDouble
 714 
 715 Move32ToFloat U:G:32, D:F:32
 716     Tmp, Tmp
 717     x86: Addr, Tmp as loadFloat
 718     Index, Tmp as loadFloat
 719 
 720 64: MoveDoubleTo64 U:F:64, D:G:64
 721     Tmp, Tmp
 722     Addr, Tmp as load64
 723     Index, Tmp as load64
 724 
 725 MoveFloatTo32 U:F:32, D:G:32
 726     Tmp, Tmp
 727     Addr, Tmp as load32
 728     Index, Tmp as load32
 729 
 730 Load8 U:G:8, ZD:G:32
 731     Addr, Tmp
 732     Index, Tmp
 733 
 734 arm: LoadAcq8 U:G:8, ZD:G:32 /effects
 735     SimpleAddr, Tmp
 736 
 737 Store8 U:G:8, D:G:8
 738     Tmp, Index
 739     Tmp, Addr
 740     x86: Imm, Index
 741     x86: Imm, Addr
 742 
 743 arm: StoreRel8 U:G:8, D:G:8 /effects
 744     Tmp, SimpleAddr
 745 
 746 Load8SignedExtendTo32 U:G:8, ZD:G:32
 747     Addr, Tmp
 748     Index, Tmp
 749 
 750 arm: LoadAcq8SignedExtendTo32 U:G:8, ZD:G:32 /effects
 751     SimpleAddr, Tmp
 752 
 753 Load16 U:G:16, ZD:G:32
 754     Addr, Tmp
 755     Index, Tmp
 756 
 757 arm: LoadAcq16 U:G:16, ZD:G:32 /effects
 758     SimpleAddr, Tmp
 759 
 760 Load16SignedExtendTo32 U:G:16, ZD:G:32
 761     Addr, Tmp
 762     Index, Tmp
 763 
 764 arm: LoadAcq16SignedExtendTo32 U:G:16, ZD:G:32 /effects
 765     SimpleAddr, Tmp
 766 
 767 Store16 U:G:16, D:G:16
 768     Tmp, Index
 769     Tmp, Addr
 770     x86: Imm, Index
 771     x86: Imm, Addr
 772 
 773 arm: StoreRel16 U:G:16, D:G:16 /effects
 774     Tmp, SimpleAddr
 775 
 776 arm: LoadAcq32 U:G:32, ZD:G:32 /effects
 777     SimpleAddr, Tmp
 778 
 779 arm: StoreRel32 U:G:32, ZD:G:32 /effects
 780     Tmp, SimpleAddr
 781 
 782 arm64: LoadAcq64 U:G:64, ZD:G:64 /effects
 783     SimpleAddr, Tmp
 784 
 785 arm64: StoreRel64 U:G:64, ZD:G:64 /effects
 786     Tmp, SimpleAddr
 787 
 788 x86: Xchg8 UD:G:8, UD:G:8 /effects
 789     Tmp, Addr
 790     Tmp, Index
 791 
 792 x86: Xchg16 UD:G:16, UD:G:16 /effects
 793     Tmp, Addr
 794     Tmp, Index
 795 
 796 x86: Xchg32 UD:G:32, UD:G:32 /effects
 797     Tmp, Addr
 798     Tmp, Index
 799 
 800 x86_64: Xchg64 UD:G:64, UD:G:64 /effects
 801     Tmp, Addr
 802     Tmp, Index
 803 
 804 # The first operand is rax.
 805 # FIXME: This formulation means that the boolean result cannot be put in eax, even though all users
 806 # of this would be OK with that.
 807 # https://bugs.webkit.org/show_bug.cgi?id=169254
 808 x86: AtomicStrongCAS8 U:G:32, UD:G:8, U:G:8, UD:G:8, ZD:G:8 /effects
 809     StatusCond, Tmp*, Tmp, Addr, Tmp
 810     StatusCond, Tmp*, Tmp, Index, Tmp
 811 
 812 x86: AtomicStrongCAS16 U:G:32, UD:G:16, U:G:32, UD:G:16, ZD:G:8 /effects
 813     StatusCond, Tmp*, Tmp, Addr, Tmp
 814     StatusCond, Tmp*, Tmp, Index, Tmp
 815 
 816 x86: AtomicStrongCAS32 U:G:32, UD:G:32, U:G:32, UD:G:32, ZD:G:8 /effects
 817     StatusCond, Tmp*, Tmp, Addr, Tmp
 818     StatusCond, Tmp*, Tmp, Index, Tmp
 819 
 820 x86_64: AtomicStrongCAS64 U:G:32, UD:G:64, U:G:64, UD:G:64, ZD:G:8 /effects
 821     StatusCond, Tmp*, Tmp, Addr, Tmp
 822     StatusCond, Tmp*, Tmp, Index, Tmp
 823 
 824 x86: AtomicStrongCAS8 UD:G:8, U:G:8, UD:G:8 /effects
 825     Tmp*, Tmp, Addr
 826     Tmp*, Tmp, Index
 827 
 828 x86: AtomicStrongCAS16 UD:G:16, U:G:32, UD:G:16 /effects
 829     Tmp*, Tmp, Addr
 830     Tmp*, Tmp, Index
 831 
 832 x86: AtomicStrongCAS32 UD:G:32, U:G:32, UD:G:32 /effects
 833     Tmp*, Tmp, Addr
 834     Tmp*, Tmp, Index
 835 
 836 x86_64: AtomicStrongCAS64 UD:G:64, U:G:64, UD:G:64 /effects
 837     Tmp*, Tmp, Addr
 838     Tmp*, Tmp, Index
 839 
 840 x86: BranchAtomicStrongCAS8 U:G:32, UD:G:8, U:G:8, UD:G:8 /branch /effects
 841     StatusCond, Tmp*, Tmp, Addr
 842     StatusCond, Tmp*, Tmp, Index
 843 
 844 x86: BranchAtomicStrongCAS16 U:G:32, UD:G:16, U:G:32, UD:G:16 /branch /effects
 845     StatusCond, Tmp*, Tmp, Addr
 846     StatusCond, Tmp*, Tmp, Index
 847 
 848 x86: BranchAtomicStrongCAS32 U:G:32, UD:G:32, U:G:32, UD:G:32 /branch /effects
 849     StatusCond, Tmp*, Tmp, Addr
 850     StatusCond, Tmp*, Tmp, Index
 851 
 852 x86_64: BranchAtomicStrongCAS64 U:G:32, UD:G:64, U:G:64, UD:G:64 /branch /effects
 853     StatusCond, Tmp*, Tmp, Addr
 854     StatusCond, Tmp*, Tmp, Index
 855 
 856 x86: AtomicAdd8 U:G:8, UD:G:8 /effects
 857     Imm, Addr
 858     Imm, Index
 859     Tmp, Addr
 860     Tmp, Index
 861 
 862 x86: AtomicAdd16 U:G:16, UD:G:16 /effects
 863     Imm, Addr
 864     Imm, Index
 865     Tmp, Addr
 866     Tmp, Index
 867 
 868 x86: AtomicAdd32 U:G:32, UD:G:32 /effects
 869     Imm, Addr
 870     Imm, Index
 871     Tmp, Addr
 872     Tmp, Index
 873 
 874 x86_64: AtomicAdd64 U:G:64, UD:G:64 /effects
 875     Imm, Addr
 876     Imm, Index
 877     Tmp, Addr
 878     Tmp, Index
 879 
 880 x86: AtomicSub8 U:G:8, UD:G:8 /effects
 881     Imm, Addr
 882     Imm, Index
 883     Tmp, Addr
 884     Tmp, Index
 885 
 886 x86: AtomicSub16 U:G:16, UD:G:16 /effects
 887     Imm, Addr
 888     Imm, Index
 889     Tmp, Addr
 890     Tmp, Index
 891 
 892 x86: AtomicSub32 U:G:32, UD:G:32 /effects
 893     Imm, Addr
 894     Imm, Index
 895     Tmp, Addr
 896     Tmp, Index
 897 
 898 x86_64: AtomicSub64 U:G:64, UD:G:64 /effects
 899     Imm, Addr
 900     Imm, Index
 901     Tmp, Addr
 902     Tmp, Index
 903 
 904 x86: AtomicAnd8 U:G:8, UD:G:8 /effects
 905     Imm, Addr
 906     Imm, Index
 907     Tmp, Addr
 908     Tmp, Index
 909 
 910 x86: AtomicAnd16 U:G:16, UD:G:16 /effects
 911     Imm, Addr
 912     Imm, Index
 913     Tmp, Addr
 914     Tmp, Index
 915 
 916 x86: AtomicAnd32 U:G:32, UD:G:32 /effects
 917     Imm, Addr
 918     Imm, Index
 919     Tmp, Addr
 920     Tmp, Index
 921 
 922 x86_64: AtomicAnd64 U:G:64, UD:G:64 /effects
 923     Imm, Addr
 924     Imm, Index
 925     Tmp, Addr
 926     Tmp, Index
 927 
 928 x86: AtomicOr8 U:G:8, UD:G:8 /effects
 929     Imm, Addr
 930     Imm, Index
 931     Tmp, Addr
 932     Tmp, Index
 933 
 934 x86: AtomicOr16 U:G:16, UD:G:16 /effects
 935     Imm, Addr
 936     Imm, Index
 937     Tmp, Addr
 938     Tmp, Index
 939 
 940 x86: AtomicOr32 U:G:32, UD:G:32 /effects
 941     Imm, Addr
 942     Imm, Index
 943     Tmp, Addr
 944     Tmp, Index
 945 
 946 x86_64: AtomicOr64 U:G:64, UD:G:64 /effects
 947     Imm, Addr
 948     Imm, Index
 949     Tmp, Addr
 950     Tmp, Index
 951 
 952 x86: AtomicXor8 U:G:8, UD:G:8 /effects
 953     Imm, Addr
 954     Imm, Index
 955     Tmp, Addr
 956     Tmp, Index
 957 
 958 x86: AtomicXor16 U:G:16, UD:G:16 /effects
 959     Imm, Addr
 960     Imm, Index
 961     Tmp, Addr
 962     Tmp, Index
 963 
 964 x86: AtomicXor32 U:G:32, UD:G:32 /effects
 965     Imm, Addr
 966     Imm, Index
 967     Tmp, Addr
 968     Tmp, Index
 969 
 970 x86_64: AtomicXor64 U:G:64, UD:G:64 /effects
 971     Imm, Addr
 972     Imm, Index
 973     Tmp, Addr
 974     Tmp, Index
 975 
 976 x86: AtomicNeg8 UD:G:8 /effects
 977     Addr
 978     Index
 979 
 980 x86: AtomicNeg16 UD:G:16 /effects
 981     Addr
 982     Index
 983 
 984 x86: AtomicNeg32 UD:G:32 /effects
 985     Addr
 986     Index
 987 
 988 x86_64: AtomicNeg64 UD:G:64 /effects
 989     Addr
 990     Index
 991 
 992 x86: AtomicNot8 UD:G:8 /effects
 993     Addr
 994     Index
 995 
 996 x86: AtomicNot16 UD:G:16 /effects
 997     Addr
 998     Index
 999 
1000 x86: AtomicNot32 UD:G:32 /effects
1001     Addr
1002     Index
1003 
1004 x86_64: AtomicNot64 UD:G:64 /effects
1005     Addr
1006     Index
1007 
1008 x86: AtomicXchgAdd8 UD:G:8, UD:G:8 /effects
1009     Tmp, Addr
1010     Tmp, Index
1011 
1012 x86: AtomicXchgAdd16 UD:G:16, UD:G:16 /effects
1013     Tmp, Addr
1014     Tmp, Index
1015 
1016 x86: AtomicXchgAdd32 UD:G:32, UD:G:32 /effects
1017     Tmp, Addr
1018     Tmp, Index
1019 
1020 x86_64: AtomicXchgAdd64 UD:G:64, UD:G:64 /effects
1021     Tmp, Addr
1022     Tmp, Index
1023 
1024 x86: AtomicXchg8 UD:G:8, UD:G:8 /effects
1025     Tmp, Addr
1026     Tmp, Index
1027 
1028 x86: AtomicXchg16 UD:G:16, UD:G:16 /effects
1029     Tmp, Addr
1030     Tmp, Index
1031 
1032 x86: AtomicXchg32 UD:G:32, UD:G:32 /effects
1033     Tmp, Addr
1034     Tmp, Index
1035 
1036 x86_64: AtomicXchg64 UD:G:64, UD:G:64 /effects
1037     Tmp, Addr
1038     Tmp, Index
1039 
1040 arm64: LoadLink8 U:G:8, ZD:G:8 /effects
1041     SimpleAddr, Tmp
1042 
1043 arm64: LoadLinkAcq8 U:G:8, ZD:G:8 /effects
1044     SimpleAddr, Tmp
1045 
1046 # Super confusing fact: this returns 0 to mean success, 1 to mean failure.
1047 arm64: StoreCond8 U:G:8, D:G:8, EZD:G:8 /effects
1048     Tmp, SimpleAddr, Tmp
1049 
1050 arm64: StoreCondRel8 U:G:8, D:G:8, EZD:G:8 /effects
1051     Tmp, SimpleAddr, Tmp
1052 
1053 arm64: LoadLink16 U:G:16, ZD:G:16 /effects
1054     SimpleAddr, Tmp
1055 
1056 arm64: LoadLinkAcq16 U:G:16, ZD:G:16 /effects
1057     SimpleAddr, Tmp
1058 
1059 arm64: StoreCond16 U:G:16, D:G:16, EZD:G:8 /effects
1060     Tmp, SimpleAddr, Tmp
1061 
1062 arm64: StoreCondRel16 U:G:16, D:G:16, EZD:G:8 /effects
1063     Tmp, SimpleAddr, Tmp
1064 
1065 arm64: LoadLink32 U:G:32, ZD:G:32 /effects
1066     SimpleAddr, Tmp
1067 
1068 arm64: LoadLinkAcq32 U:G:32, ZD:G:32 /effects
1069     SimpleAddr, Tmp
1070 
1071 arm64: StoreCond32 U:G:32, D:G:32, EZD:G:8 /effects
1072     Tmp, SimpleAddr, Tmp
1073 
1074 arm64: StoreCondRel32 U:G:32, D:G:32, EZD:G:8 /effects
1075     Tmp, SimpleAddr, Tmp
1076 
1077 arm64: LoadLink64 U:G:64, ZD:G:64 /effects
1078     SimpleAddr, Tmp
1079 
1080 arm64: LoadLinkAcq64 U:G:64, ZD:G:64 /effects
1081     SimpleAddr, Tmp
1082 
1083 arm64: StoreCond64 U:G:64, D:G:64, EZD:G:8 /effects
1084     Tmp, SimpleAddr, Tmp
1085 
1086 arm64: StoreCondRel64 U:G:64, D:G:64, EZD:G:8 /effects
1087     Tmp, SimpleAddr, Tmp
1088 
1089 arm64: Depend32 U:G:32, ZD:G:32
1090     Tmp, Tmp
1091 
1092 arm64: Depend64 U:G:64, ZD:G:64
1093     Tmp, Tmp
1094 
1095 Compare32 U:G:32, U:G:32, U:G:32, ZD:G:32
1096     RelCond, Tmp, Tmp, Tmp
1097     RelCond, Tmp, Imm, Tmp
1098 
1099 64: Compare64 U:G:32, U:G:64, U:G:64, ZD:G:32
1100     RelCond, Tmp, Tmp, Tmp
1101     x86: RelCond, Tmp, Imm, Tmp
1102 
1103 Test32 U:G:32, U:G:32, U:G:32, ZD:G:32
1104     x86: ResCond, Addr, Imm, Tmp
1105     ResCond, Tmp, Tmp, Tmp
1106     ResCond, Tmp, BitImm, Tmp
1107 
1108 64: Test64 U:G:32, U:G:64, U:G:64, ZD:G:32
1109     x86: ResCond, Tmp, Imm, Tmp
1110     ResCond, Tmp, Tmp, Tmp
1111 
1112 CompareDouble U:G:32, U:F:64, U:F:64, ZD:G:32
1113     DoubleCond, Tmp, Tmp, Tmp
1114 
1115 CompareFloat U:G:32, U:F:32, U:F:32, ZD:G:32
1116     DoubleCond, Tmp, Tmp, Tmp
1117 
1118 # Note that branches have some logic in AirOptimizeBlockOrder.cpp. If you add new branches, please make sure
1119 # you opt them into the block order optimizations.
1120 
1121 Branch8 U:G:32, U:G:8, U:G:8 /branch
1122     x86: RelCond, Addr, Imm
1123     x86: RelCond, Index, Imm
1124 
1125 Branch32 U:G:32, U:G:32, U:G:32 /branch
1126     x86: RelCond, Addr, Imm
1127     RelCond, Tmp, Tmp
1128     RelCond, Tmp, Imm
1129     x86: RelCond, Tmp, Addr
1130     x86: RelCond, Addr, Tmp
1131     x86: RelCond, Index, Imm
1132 
1133 64: Branch64 U:G:32, U:G:64, U:G:64 /branch
1134     RelCond, Tmp, Tmp
1135     RelCond, Tmp, Imm
1136     x86: RelCond, Tmp, Addr
1137     x86: RelCond, Addr, Tmp
1138     x86: RelCond, Addr, Imm
1139     x86: RelCond, Index, Tmp
1140 
1141 BranchTest8 U:G:32, U:G:8, U:G:8 /branch
1142     x86: ResCond, Addr, BitImm
1143     x86: ResCond, Index, BitImm
1144 
1145 BranchTest32 U:G:32, U:G:32, U:G:32 /branch
1146     ResCond, Tmp, Tmp
1147     ResCond, Tmp, BitImm
1148     x86: ResCond, Addr, BitImm
1149     x86: ResCond, Index, BitImm
1150 
1151 # Warning: forms that take an immediate will sign-extend their immediate. You probably want
1152 # BranchTest32 in most cases where you use an immediate.
1153 64: BranchTest64 U:G:32, U:G:64, U:G:64 /branch
1154     ResCond, Tmp, Tmp
1155     arm64: ResCond, Tmp, BitImm64
1156     x86: ResCond, Tmp, BitImm
1157     x86: ResCond, Addr, BitImm
1158     x86: ResCond, Addr, Tmp
1159     x86: ResCond, Index, BitImm
1160 
1161 BranchDouble U:G:32, U:F:64, U:F:64 /branch
1162     DoubleCond, Tmp, Tmp
1163 
1164 BranchFloat U:G:32, U:F:32, U:F:32 /branch
1165     DoubleCond, Tmp, Tmp
1166 
1167 BranchAdd32 U:G:32, U:G:32, U:G:32, ZD:G:32 /branch
1168     ResCond, Tmp, Tmp, Tmp
1169     x86:ResCond, Tmp, Addr, Tmp
1170     x86:ResCond, Addr, Tmp, Tmp
1171 
1172 BranchAdd32 U:G:32, U:G:32, UZD:G:32 /branch
1173     ResCond, Tmp, Tmp
1174     ResCond, Imm, Tmp
1175     x86: ResCond, Imm, Addr
1176     x86: ResCond, Tmp, Addr
1177     x86: ResCond, Addr, Tmp
1178 
1179 BranchAdd64 U:G:32, U:G:64, U:G:64, ZD:G:64 /branch
1180     ResCond, Tmp, Tmp, Tmp
1181     x86:ResCond, Tmp, Addr, Tmp
1182     x86:ResCond, Addr, Tmp, Tmp
1183 
1184 64: BranchAdd64 U:G:32, U:G:64, UD:G:64 /branch
1185     ResCond, Imm, Tmp
1186     ResCond, Tmp, Tmp
1187     x86:ResCond, Addr, Tmp
1188 
1189 x86: BranchMul32 U:G:32, U:G:32, UZD:G:32 /branch
1190     ResCond, Tmp, Tmp
1191     ResCond, Addr, Tmp
1192 
1193 x86: BranchMul32 U:G:32, U:G:32, U:G:32, ZD:G:32 /branch
1194     ResCond, Tmp, Imm, Tmp
1195 
1196 arm64: BranchMul32 U:G:32, U:G:32, U:G:32, S:G:32, S:G:32, ZD:G:32 /branch
1197     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1198 
1199 x86_64: BranchMul64 U:G:32, U:G:64, UZD:G:64 /branch
1200     ResCond, Tmp, Tmp
1201 
1202 arm64: BranchMul64 U:G:32, U:G:64, U:G:64, S:G:64, S:G:64, ZD:G:64 /branch
1203     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1204 
1205 BranchSub32 U:G:32, U:G:32, UZD:G:32 /branch
1206     ResCond, Tmp, Tmp
1207     ResCond, Imm, Tmp
1208     x86: ResCond, Imm, Addr
1209     x86: ResCond, Tmp, Addr
1210     x86: ResCond, Addr, Tmp
1211 
1212 64: BranchSub64 U:G:32, U:G:64, UD:G:64 /branch
1213     ResCond, Imm, Tmp
1214     ResCond, Tmp, Tmp
1215 
1216 BranchNeg32 U:G:32, UZD:G:32 /branch
1217     ResCond, Tmp
1218 
1219 64: BranchNeg64 U:G:32, UZD:G:64 /branch
1220     ResCond, Tmp
1221 
1222 MoveConditionally32 U:G:32, U:G:32, U:G:32, U:G:Ptr, UD:G:Ptr
1223     RelCond, Tmp, Tmp, Tmp, Tmp
1224 
1225 MoveConditionally32 U:G:32, U:G:32, U:G:32, U:G:Ptr, U:G:Ptr, D:G:Ptr
1226     RelCond, Tmp, Tmp, Tmp, Tmp, Tmp
1227     RelCond, Tmp, Imm, Tmp, Tmp, Tmp
1228 
1229 64: MoveConditionally64 U:G:32, U:G:64, U:G:64, U:G:Ptr, UD:G:Ptr
1230     RelCond, Tmp, Tmp, Tmp, Tmp
1231 
1232 64: MoveConditionally64 U:G:32, U:G:64, U:G:64, U:G:Ptr, U:G:Ptr, D:G:Ptr
1233     RelCond, Tmp, Tmp, Tmp, Tmp, Tmp
1234     RelCond, Tmp, Imm, Tmp, Tmp, Tmp
1235 
1236 MoveConditionallyTest32 U:G:32, U:G:32, U:G:32, U:G:Ptr, UD:G:Ptr
1237     ResCond, Tmp, Tmp, Tmp, Tmp
1238     x86: ResCond, Tmp, Imm, Tmp, Tmp
1239 
1240 MoveConditionallyTest32 U:G:32, U:G:32, U:G:32, U:G:Ptr, U:G:Ptr, D:G:Ptr
1241     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1242     ResCond, Tmp, BitImm, Tmp, Tmp, Tmp
1243 
1244 64: MoveConditionallyTest64 U:G:32, U:G:64, U:G:64, U:G:Ptr, UD:G:Ptr
1245     ResCond, Tmp, Tmp, Tmp, Tmp
1246     x86: ResCond, Tmp, Imm, Tmp, Tmp
1247 
1248 64: MoveConditionallyTest64 U:G:32, U:G:32, U:G:32, U:G:Ptr, U:G:Ptr, D:G:Ptr
1249     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1250     x86_64: ResCond, Tmp, Imm, Tmp, Tmp, Tmp
1251 
1252 MoveConditionallyDouble U:G:32, U:F:64, U:F:64, U:G:Ptr, U:G:Ptr, D:G:Ptr
1253     DoubleCond, Tmp, Tmp, Tmp, Tmp, Tmp
1254 
1255 MoveConditionallyDouble U:G:32, U:F:64, U:F:64, U:G:Ptr, UD:G:Ptr
1256     DoubleCond, Tmp, Tmp, Tmp, Tmp
1257 
1258 MoveConditionallyFloat U:G:32, U:F:32, U:F:32, U:G:Ptr, U:G:Ptr, D:G:Ptr
1259     DoubleCond, Tmp, Tmp, Tmp, Tmp, Tmp
1260 
1261 MoveConditionallyFloat U:G:32, U:F:32, U:F:32, U:G:Ptr, UD:G:Ptr
1262     DoubleCond, Tmp, Tmp, Tmp, Tmp
1263 
1264 MoveDoubleConditionally32 U:G:32, U:G:32, U:G:32, U:F:64, U:F:64, D:F:64
1265     RelCond, Tmp, Tmp, Tmp, Tmp, Tmp
1266     RelCond, Tmp, Imm, Tmp, Tmp, Tmp
1267     x86: RelCond, Addr, Imm, Tmp, Tmp, Tmp
1268     x86: RelCond, Tmp, Addr, Tmp, Tmp, Tmp
1269     x86: RelCond, Addr, Tmp, Tmp, Tmp, Tmp
1270     x86: RelCond, Index, Imm, Tmp, Tmp, Tmp
1271 
1272 64: MoveDoubleConditionally64 U:G:32, U:G:64, U:G:64, U:F:64, U:F:64, D:F:64
1273     RelCond, Tmp, Tmp, Tmp, Tmp, Tmp
1274     RelCond, Tmp, Imm, Tmp, Tmp, Tmp
1275     x86_64: RelCond, Tmp, Addr, Tmp, Tmp, Tmp
1276     x86_64: RelCond, Addr, Tmp, Tmp, Tmp, Tmp
1277     x86_64: RelCond, Addr, Imm, Tmp, Tmp, Tmp
1278     x86_64: RelCond, Index, Tmp, Tmp, Tmp, Tmp
1279 
1280 MoveDoubleConditionallyTest32 U:G:32, U:G:32, U:G:32, U:F:64, U:F:64, D:F:64
1281     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1282     ResCond, Tmp, BitImm, Tmp, Tmp, Tmp
1283     x86: ResCond, Addr, Imm, Tmp, Tmp, Tmp
1284     x86: ResCond, Index, Imm, Tmp, Tmp, Tmp
1285 
1286 # Warning: forms that take an immediate will sign-extend their immediate. You probably want
1287 # MoveDoubleConditionallyTest32 in most cases where you use an immediate.
1288 64: MoveDoubleConditionallyTest64 U:G:32, U:G:64, U:G:64, U:F:64, U:F:64, D:F:64
1289     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1290     x86_64: ResCond, Tmp, Imm, Tmp, Tmp, Tmp
1291     x86_64: ResCond, Addr, Imm, Tmp, Tmp, Tmp
1292     x86_64: ResCond, Addr, Tmp, Tmp, Tmp, Tmp
1293     x86_64: ResCond, Index, Imm, Tmp, Tmp, Tmp
1294 
1295 MoveDoubleConditionallyDouble U:G:32, U:F:64, U:F:64, U:F:64, U:F:64, D:F:64
1296     DoubleCond, Tmp, Tmp, Tmp, Tmp, Tmp
1297 
1298 MoveDoubleConditionallyFloat U:G:32, U:F:32, U:F:32, U:F:64, U:F:64, D:F:64
1299     DoubleCond, Tmp, Tmp, Tmp, Tmp, Tmp
1300 
1301 MemoryFence /effects
1302 StoreFence /effects
1303 LoadFence /effects
1304 
1305 Jump /branch
1306 
1307 RetVoid /return
1308 
1309 Ret32 U:G:32 /return
1310     Tmp
1311 
1312 64: Ret64 U:G:64 /return
1313     Tmp
1314 
1315 RetFloat U:F:32 /return
1316     Tmp
1317 
1318 RetDouble U:F:64 /return
1319     Tmp
1320 
1321 Oops /terminal
1322 
1323 # This is a terminal but we express it as a Custom because we don&#39;t want it to have a code
1324 # generator.
1325 custom EntrySwitch
1326 
1327 # A Shuffle is a multi-source, multi-destination move. It simultaneously does multiple moves at once.
1328 # The moves are specified as triplets of src, dst, and width. For example you can request a swap this
1329 # way:
1330 #     Shuffle %tmp1, %tmp2, 64, %tmp2, %tmp1, 64
1331 custom Shuffle
1332 
1333 # Air allows for exotic behavior. A Patch&#39;s behavior is determined entirely by the Special operand,
1334 # which must be the first operand.
1335 custom Patch
1336 
1337 # Instructions used for lowering C calls. These don&#39;t make it to Air generation. They get lowered to
1338 # something else first. The origin Value must be a CCallValue.
1339 custom CCall
1340 custom ColdCCall
1341 
1342 # This is a special wasm opcode that branches to a trap handler. This uses the generator located to Air::Code
1343 # to produce the side-exit code.
1344 custom WasmBoundsCheck
1345 
    </pre>
  </body>
</html>