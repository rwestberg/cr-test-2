<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGJITCode.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGIntegerRangeOptimizationPhase.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGJITCode.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGJITCode.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;DFGJITCode.h&quot;
 28 
 29 #if ENABLE(DFG_JIT)
 30 
 31 #include &quot;CodeBlock.h&quot;
 32 #include &quot;FTLForOSREntryJITCode.h&quot;
 33 #include &quot;JSCInlines.h&quot;
 34 #include &quot;TrackedReferences.h&quot;
 35 
 36 namespace JSC { namespace DFG {
 37 
 38 JITCode::JITCode()
<span class="line-modified"> 39     : DirectJITCode(DFGJIT)</span>
 40 #if ENABLE(FTL_JIT)
 41     , osrEntryRetry(0)
 42     , abandonOSREntry(false)
 43 #endif // ENABLE(FTL_JIT)
 44 {
 45 }
 46 
 47 JITCode::~JITCode()
 48 {
 49 }
 50 
 51 CommonData* JITCode::dfgCommon()
 52 {
 53     return &amp;common;
 54 }
 55 
 56 JITCode* JITCode::dfg()
 57 {
 58     return this;
 59 }
</pre>
<hr />
<pre>
106                     else if (recovery.isInJSValueRegs()) {
107                         liveAtOSRExit.set(recovery.payloadGPR());
108                         liveAtOSRExit.set(recovery.tagGPR());
109                     }
110 #endif
111                     else
112                         RELEASE_ASSERT_NOT_REACHED();
113                 }
114             }
115 
116             return liveAtOSRExit;
117         }
118     }
119 
120     return { };
121 }
122 
123 #if ENABLE(FTL_JIT)
124 bool JITCode::checkIfOptimizationThresholdReached(CodeBlock* codeBlock)
125 {
<span class="line-modified">126     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
127     return tierUpCounter.checkIfThresholdCrossedAndSet(codeBlock);
128 }
129 
130 void JITCode::optimizeNextInvocation(CodeBlock* codeBlock)
131 {
<span class="line-modified">132     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
133     if (Options::verboseOSR())
134         dataLog(*codeBlock, &quot;: FTL-optimizing next invocation.\n&quot;);
135     tierUpCounter.setNewThreshold(0, codeBlock);
136 }
137 
138 void JITCode::dontOptimizeAnytimeSoon(CodeBlock* codeBlock)
139 {
<span class="line-modified">140     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
141     if (Options::verboseOSR())
142         dataLog(*codeBlock, &quot;: Not FTL-optimizing anytime soon.\n&quot;);
143     tierUpCounter.deferIndefinitely();
144 }
145 
146 void JITCode::optimizeAfterWarmUp(CodeBlock* codeBlock)
147 {
<span class="line-modified">148     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
149     if (Options::verboseOSR())
150         dataLog(*codeBlock, &quot;: FTL-optimizing after warm-up.\n&quot;);
151     CodeBlock* baseline = codeBlock-&gt;baselineVersion();
152     tierUpCounter.setNewThreshold(
153         baseline-&gt;adjustedCounterValue(Options::thresholdForFTLOptimizeAfterWarmUp()),
154         baseline);
155 }
156 
157 void JITCode::optimizeSoon(CodeBlock* codeBlock)
158 {
<span class="line-modified">159     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
160     if (Options::verboseOSR())
161         dataLog(*codeBlock, &quot;: FTL-optimizing soon.\n&quot;);
162     CodeBlock* baseline = codeBlock-&gt;baselineVersion();
163     tierUpCounter.setNewThreshold(
164         baseline-&gt;adjustedCounterValue(Options::thresholdForFTLOptimizeSoon()),
165         codeBlock);
166 }
167 
168 void JITCode::forceOptimizationSlowPathConcurrently(CodeBlock* codeBlock)
169 {
<span class="line-modified">170     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
171     if (Options::verboseOSR())
172         dataLog(*codeBlock, &quot;: Forcing slow path concurrently for FTL entry.\n&quot;);
173     tierUpCounter.forceSlowPathConcurrently();
174 }
175 
176 void JITCode::setOptimizationThresholdBasedOnCompilationResult(
177     CodeBlock* codeBlock, CompilationResult result)
178 {
<span class="line-modified">179     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT);</span>
180     switch (result) {
181     case CompilationSuccessful:
182         optimizeNextInvocation(codeBlock);
183         codeBlock-&gt;baselineVersion()-&gt;m_hasBeenCompiledWithFTL = true;
184         return;
185     case CompilationFailed:
186         dontOptimizeAnytimeSoon(codeBlock);
187         codeBlock-&gt;baselineVersion()-&gt;m_didFailFTLCompilation = true;
188         return;
189     case CompilationDeferred:
190         optimizeAfterWarmUp(codeBlock);
191         return;
192     case CompilationInvalidated:
193         // This is weird - it will only happen in cases when the DFG code block (i.e.
194         // the code block that this JITCode belongs to) is also invalidated. So it
195         // doesn&#39;t really matter what we do. But, we do the right thing anyway. Note
196         // that us counting the reoptimization actually means that we might count it
197         // twice. But that&#39;s generally OK. It&#39;s better to overcount reoptimizations
198         // than it is to undercount them.
199         codeBlock-&gt;baselineVersion()-&gt;countReoptimization();
200         optimizeAfterWarmUp(codeBlock);
201         return;
202     }
203     RELEASE_ASSERT_NOT_REACHED();
204 }
205 
206 void JITCode::setOSREntryBlock(VM&amp; vm, const JSCell* owner, CodeBlock* osrEntryBlock)
207 {
208     if (Options::verboseOSR()) {
209         dataLog(RawPointer(this), &quot;: Setting OSR entry block to &quot;, RawPointer(osrEntryBlock), &quot;\n&quot;);
210         dataLog(&quot;OSR entries will go to &quot;, osrEntryBlock-&gt;jitCode()-&gt;ftlForOSREntry()-&gt;addressForCall(ArityCheckNotRequired), &quot;\n&quot;);
211     }
212     m_osrEntryBlock.set(vm, owner, osrEntryBlock);
213 }











214 #endif // ENABLE(FTL_JIT)
215 
216 void JITCode::validateReferences(const TrackedReferences&amp; trackedReferences)
217 {
218     common.validateReferences(trackedReferences);
219 
220     for (OSREntryData&amp; entry : osrEntry) {
221         for (unsigned i = entry.m_expectedValues.size(); i--;)
222             entry.m_expectedValues[i].validateReferences(trackedReferences);
223     }
224 
225     minifiedDFG.validateReferences(trackedReferences);
226 }
227 
228 Optional&lt;CodeOrigin&gt; JITCode::findPC(CodeBlock*, void* pc)
229 {
230     for (OSRExit&amp; exit : osrExit) {
231         if (ExecutableMemoryHandle* handle = exit.m_code.executableMemory()) {
232             if (handle-&gt;start().untaggedPtr() &lt;= pc &amp;&amp; pc &lt; handle-&gt;end().untaggedPtr())
233                 return Optional&lt;CodeOrigin&gt;(exit.m_codeOriginForExitProfile);
</pre>
</td>
<td>
<hr />
<pre>
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;DFGJITCode.h&quot;
 28 
 29 #if ENABLE(DFG_JIT)
 30 
 31 #include &quot;CodeBlock.h&quot;
 32 #include &quot;FTLForOSREntryJITCode.h&quot;
 33 #include &quot;JSCInlines.h&quot;
 34 #include &quot;TrackedReferences.h&quot;
 35 
 36 namespace JSC { namespace DFG {
 37 
 38 JITCode::JITCode()
<span class="line-modified"> 39     : DirectJITCode(JITType::DFGJIT)</span>
 40 #if ENABLE(FTL_JIT)
 41     , osrEntryRetry(0)
 42     , abandonOSREntry(false)
 43 #endif // ENABLE(FTL_JIT)
 44 {
 45 }
 46 
 47 JITCode::~JITCode()
 48 {
 49 }
 50 
 51 CommonData* JITCode::dfgCommon()
 52 {
 53     return &amp;common;
 54 }
 55 
 56 JITCode* JITCode::dfg()
 57 {
 58     return this;
 59 }
</pre>
<hr />
<pre>
106                     else if (recovery.isInJSValueRegs()) {
107                         liveAtOSRExit.set(recovery.payloadGPR());
108                         liveAtOSRExit.set(recovery.tagGPR());
109                     }
110 #endif
111                     else
112                         RELEASE_ASSERT_NOT_REACHED();
113                 }
114             }
115 
116             return liveAtOSRExit;
117         }
118     }
119 
120     return { };
121 }
122 
123 #if ENABLE(FTL_JIT)
124 bool JITCode::checkIfOptimizationThresholdReached(CodeBlock* codeBlock)
125 {
<span class="line-modified">126     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
127     return tierUpCounter.checkIfThresholdCrossedAndSet(codeBlock);
128 }
129 
130 void JITCode::optimizeNextInvocation(CodeBlock* codeBlock)
131 {
<span class="line-modified">132     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
133     if (Options::verboseOSR())
134         dataLog(*codeBlock, &quot;: FTL-optimizing next invocation.\n&quot;);
135     tierUpCounter.setNewThreshold(0, codeBlock);
136 }
137 
138 void JITCode::dontOptimizeAnytimeSoon(CodeBlock* codeBlock)
139 {
<span class="line-modified">140     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
141     if (Options::verboseOSR())
142         dataLog(*codeBlock, &quot;: Not FTL-optimizing anytime soon.\n&quot;);
143     tierUpCounter.deferIndefinitely();
144 }
145 
146 void JITCode::optimizeAfterWarmUp(CodeBlock* codeBlock)
147 {
<span class="line-modified">148     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
149     if (Options::verboseOSR())
150         dataLog(*codeBlock, &quot;: FTL-optimizing after warm-up.\n&quot;);
151     CodeBlock* baseline = codeBlock-&gt;baselineVersion();
152     tierUpCounter.setNewThreshold(
153         baseline-&gt;adjustedCounterValue(Options::thresholdForFTLOptimizeAfterWarmUp()),
154         baseline);
155 }
156 
157 void JITCode::optimizeSoon(CodeBlock* codeBlock)
158 {
<span class="line-modified">159     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
160     if (Options::verboseOSR())
161         dataLog(*codeBlock, &quot;: FTL-optimizing soon.\n&quot;);
162     CodeBlock* baseline = codeBlock-&gt;baselineVersion();
163     tierUpCounter.setNewThreshold(
164         baseline-&gt;adjustedCounterValue(Options::thresholdForFTLOptimizeSoon()),
165         codeBlock);
166 }
167 
168 void JITCode::forceOptimizationSlowPathConcurrently(CodeBlock* codeBlock)
169 {
<span class="line-modified">170     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
171     if (Options::verboseOSR())
172         dataLog(*codeBlock, &quot;: Forcing slow path concurrently for FTL entry.\n&quot;);
173     tierUpCounter.forceSlowPathConcurrently();
174 }
175 
176 void JITCode::setOptimizationThresholdBasedOnCompilationResult(
177     CodeBlock* codeBlock, CompilationResult result)
178 {
<span class="line-modified">179     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT);</span>
180     switch (result) {
181     case CompilationSuccessful:
182         optimizeNextInvocation(codeBlock);
183         codeBlock-&gt;baselineVersion()-&gt;m_hasBeenCompiledWithFTL = true;
184         return;
185     case CompilationFailed:
186         dontOptimizeAnytimeSoon(codeBlock);
187         codeBlock-&gt;baselineVersion()-&gt;m_didFailFTLCompilation = true;
188         return;
189     case CompilationDeferred:
190         optimizeAfterWarmUp(codeBlock);
191         return;
192     case CompilationInvalidated:
193         // This is weird - it will only happen in cases when the DFG code block (i.e.
194         // the code block that this JITCode belongs to) is also invalidated. So it
195         // doesn&#39;t really matter what we do. But, we do the right thing anyway. Note
196         // that us counting the reoptimization actually means that we might count it
197         // twice. But that&#39;s generally OK. It&#39;s better to overcount reoptimizations
198         // than it is to undercount them.
199         codeBlock-&gt;baselineVersion()-&gt;countReoptimization();
200         optimizeAfterWarmUp(codeBlock);
201         return;
202     }
203     RELEASE_ASSERT_NOT_REACHED();
204 }
205 
206 void JITCode::setOSREntryBlock(VM&amp; vm, const JSCell* owner, CodeBlock* osrEntryBlock)
207 {
208     if (Options::verboseOSR()) {
209         dataLog(RawPointer(this), &quot;: Setting OSR entry block to &quot;, RawPointer(osrEntryBlock), &quot;\n&quot;);
210         dataLog(&quot;OSR entries will go to &quot;, osrEntryBlock-&gt;jitCode()-&gt;ftlForOSREntry()-&gt;addressForCall(ArityCheckNotRequired), &quot;\n&quot;);
211     }
212     m_osrEntryBlock.set(vm, owner, osrEntryBlock);
213 }
<span class="line-added">214 </span>
<span class="line-added">215 void JITCode::clearOSREntryBlockAndResetThresholds(CodeBlock *dfgCodeBlock)</span>
<span class="line-added">216 {</span>
<span class="line-added">217     ASSERT(m_osrEntryBlock);</span>
<span class="line-added">218 </span>
<span class="line-added">219     unsigned osrEntryBytecode = m_osrEntryBlock-&gt;jitCode()-&gt;ftlForOSREntry()-&gt;bytecodeIndex();</span>
<span class="line-added">220     m_osrEntryBlock.clear();</span>
<span class="line-added">221     osrEntryRetry = 0;</span>
<span class="line-added">222     tierUpEntryTriggers.set(osrEntryBytecode, JITCode::TriggerReason::DontTrigger);</span>
<span class="line-added">223     setOptimizationThresholdBasedOnCompilationResult(dfgCodeBlock, CompilationDeferred);</span>
<span class="line-added">224 }</span>
225 #endif // ENABLE(FTL_JIT)
226 
227 void JITCode::validateReferences(const TrackedReferences&amp; trackedReferences)
228 {
229     common.validateReferences(trackedReferences);
230 
231     for (OSREntryData&amp; entry : osrEntry) {
232         for (unsigned i = entry.m_expectedValues.size(); i--;)
233             entry.m_expectedValues[i].validateReferences(trackedReferences);
234     }
235 
236     minifiedDFG.validateReferences(trackedReferences);
237 }
238 
239 Optional&lt;CodeOrigin&gt; JITCode::findPC(CodeBlock*, void* pc)
240 {
241     for (OSRExit&amp; exit : osrExit) {
242         if (ExecutableMemoryHandle* handle = exit.m_code.executableMemory()) {
243             if (handle-&gt;start().untaggedPtr() &lt;= pc &amp;&amp; pc &lt; handle-&gt;end().untaggedPtr())
244                 return Optional&lt;CodeOrigin&gt;(exit.m_codeOriginForExitProfile);
</pre>
</td>
</tr>
</table>
<center><a href="DFGIntegerRangeOptimizationPhase.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGJITCode.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>