<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AudioContext.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioContext.idl.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
  2  * Copyright (C) 2010 Google Inc. All rights reserved.
<span class="line-modified">  3  * Copyright (C) 2016 Apple Inc. All rights reserved.</span>
  4  *
  5  * Redistribution and use in source and binary forms, with or without
  6  * modification, are permitted provided that the following conditions
  7  * are met:
  8  * 1.  Redistributions of source code must retain the above copyright
  9  *    notice, this list of conditions and the following disclaimer.
 10  * 2.  Redistributions in binary form must reproduce the above copyright
 11  *    notice, this list of conditions and the following disclaimer in the
 12  *    documentation and/or other materials provided with the distribution.
 13  *
 14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 16  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 17  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 18  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 19  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 20  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 21  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 23  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;ActiveDOMObject.h&quot;
 29 #include &quot;AsyncAudioDecoder.h&quot;
 30 #include &quot;AudioBus.h&quot;
 31 #include &quot;AudioDestinationNode.h&quot;
 32 #include &quot;EventTarget.h&quot;
 33 #include &quot;JSDOMPromiseDeferred.h&quot;
 34 #include &quot;MediaCanStartListener.h&quot;
 35 #include &quot;MediaProducer.h&quot;
 36 #include &quot;PlatformMediaSession.h&quot;

 37 #include &quot;VisibilityChangeClient.h&quot;

 38 #include &lt;JavaScriptCore/Float32Array.h&gt;
 39 #include &lt;atomic&gt;
 40 #include &lt;wtf/HashSet.h&gt;

 41 #include &lt;wtf/MainThread.h&gt;
 42 #include &lt;wtf/RefPtr.h&gt;
 43 #include &lt;wtf/ThreadSafeRefCounted.h&gt;
 44 #include &lt;wtf/Threading.h&gt;
 45 #include &lt;wtf/Vector.h&gt;
<span class="line-modified"> 46 #include &lt;wtf/text/AtomicStringHash.h&gt;</span>
 47 
 48 namespace WebCore {
 49 
 50 class AnalyserNode;
 51 class AudioBuffer;
 52 class AudioBufferCallback;
 53 class AudioBufferSourceNode;
 54 class AudioListener;
 55 class AudioSummingJunction;
 56 class BiquadFilterNode;
 57 class ChannelMergerNode;
 58 class ChannelSplitterNode;
 59 class ConvolverNode;
 60 class DelayNode;
 61 class Document;
 62 class DynamicsCompressorNode;
 63 class GainNode;
 64 class GenericEventQueue;
 65 class HTMLMediaElement;
 66 class MediaElementAudioSourceNode;
 67 class MediaStream;
 68 class MediaStreamAudioDestinationNode;
 69 class MediaStreamAudioSourceNode;
 70 class OscillatorNode;
 71 class PannerNode;
 72 class PeriodicWave;
 73 class ScriptProcessorNode;

 74 class WaveShaperNode;
 75 
 76 // AudioContext is the cornerstone of the web audio API and all AudioNodes are created from it.
 77 // For thread safety between the audio thread and the main thread, it has a rendering graph locking mechanism.
 78 
<span class="line-modified"> 79 class AudioContext : public ActiveDOMObject, public ThreadSafeRefCounted&lt;AudioContext&gt;, public EventTargetWithInlineData, public MediaCanStartListener, public MediaProducer, private PlatformMediaSessionClient, private VisibilityChangeClient {</span>












 80 public:
 81     // Create an AudioContext for rendering to the audio hardware.
 82     static RefPtr&lt;AudioContext&gt; create(Document&amp;);
 83 
 84     virtual ~AudioContext();
 85 
 86     bool isInitialized() const;
 87 
 88     bool isOfflineContext() const { return m_isOfflineContext; }
 89 
 90     Document* document() const; // ASSERTs if document no longer exists.
 91 
 92     Document* hostingDocument() const final;
 93 
 94     AudioDestinationNode* destination() { return m_destinationNode.get(); }
<span class="line-modified"> 95     size_t currentSampleFrame() const { return m_destinationNode-&gt;currentSampleFrame(); }</span>
<span class="line-modified"> 96     double currentTime() const { return m_destinationNode-&gt;currentTime(); }</span>
<span class="line-modified"> 97     float sampleRate() const { return m_destinationNode-&gt;sampleRate(); }</span>
 98     unsigned long activeSourceCount() const { return static_cast&lt;unsigned long&gt;(m_activeSourceCount); }
 99 
100     void incrementActiveSourceCount();
101     void decrementActiveSourceCount();
102 
103     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
104     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(ArrayBuffer&amp;, bool mixToMono);
105 
106     // Asynchronous audio file data decoding.
107     void decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;);
108 
109     AudioListener* listener() { return m_listener.get(); }
110 
111     using ActiveDOMObject::suspend;
112     using ActiveDOMObject::resume;
113 
114     void suspend(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
115     void resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
116     void close(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
117 
118     enum class State { Suspended, Running, Interrupted, Closed };
119     State state() const;

120 
121     bool wouldTaintOrigin(const URL&amp;) const;
122 
123     // The AudioNode create methods are called on the main thread (from JavaScript).
<span class="line-modified">124     Ref&lt;AudioBufferSourceNode&gt; createBufferSource();</span>
125 #if ENABLE(VIDEO)
126     ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; createMediaElementSource(HTMLMediaElement&amp;);
127 #endif
128 #if ENABLE(MEDIA_STREAM)
129     ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; createMediaStreamSource(MediaStream&amp;);
<span class="line-modified">130     Ref&lt;MediaStreamAudioDestinationNode&gt; createMediaStreamDestination();</span>
131 #endif
<span class="line-modified">132     Ref&lt;GainNode&gt; createGain();</span>
<span class="line-modified">133     Ref&lt;BiquadFilterNode&gt; createBiquadFilter();</span>
<span class="line-modified">134     Ref&lt;WaveShaperNode&gt; createWaveShaper();</span>
135     ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; createDelay(double maxDelayTime);
<span class="line-modified">136     Ref&lt;PannerNode&gt; createPanner();</span>
<span class="line-modified">137     Ref&lt;ConvolverNode&gt; createConvolver();</span>
<span class="line-modified">138     Ref&lt;DynamicsCompressorNode&gt; createDynamicsCompressor();</span>
<span class="line-modified">139     Ref&lt;AnalyserNode&gt; createAnalyser();</span>
140     ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels);
141     ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; createChannelSplitter(size_t numberOfOutputs);
142     ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; createChannelMerger(size_t numberOfInputs);
<span class="line-modified">143     Ref&lt;OscillatorNode&gt; createOscillator();</span>
144     ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary);
145 
146     // When a source node has no more processing to do (has finished playing), then it tells the context to dereference it.
147     void notifyNodeFinishedProcessing(AudioNode*);
148 
149     // Called at the start of each render quantum.
150     void handlePreRenderTasks();
151 
152     // Called at the end of each render quantum.
153     void handlePostRenderTasks();
154 
155     // Called periodically at the end of each render quantum to dereference finished source nodes.
156     void derefFinishedSourceNodes();
157 
158     // We schedule deletion of all marked nodes at the end of each realtime render quantum.
159     void markForDeletion(AudioNode&amp;);
160     void deleteMarkedNodes();
161 
162     // AudioContext can pull node(s) at the end of each render quantum even when they are not connected to any downstream nodes.
163     // These two methods are called by the nodes who want to add/remove themselves into/from the automatic pull lists.
</pre>
<hr />
<pre>
219     private:
220         AudioContext&amp; m_context;
221         bool m_mustReleaseLock;
222     };
223 
224     // In AudioNode::deref() a tryLock() is used for calling finishDeref(), but if it fails keep track here.
225     void addDeferredFinishDeref(AudioNode*);
226 
227     // In the audio thread at the start of each render cycle, we&#39;ll call handleDeferredFinishDerefs().
228     void handleDeferredFinishDerefs();
229 
230     // Only accessed when the graph lock is held.
231     void markSummingJunctionDirty(AudioSummingJunction*);
232     void markAudioNodeOutputDirty(AudioNodeOutput*);
233 
234     // Must be called on main thread.
235     void removeMarkedSummingJunction(AudioSummingJunction*);
236 
237     // EventTarget
238     EventTargetInterface eventTargetInterface() const final { return AudioContextEventTargetInterfaceType; }
<span class="line-removed">239     ScriptExecutionContext* scriptExecutionContext() const final;</span>
240 
241     // Reconcile ref/deref which are defined both in ThreadSafeRefCounted and EventTarget.
242     using ThreadSafeRefCounted::ref;
243     using ThreadSafeRefCounted::deref;
244 
245     void startRendering();
<span class="line-modified">246     void fireCompletionEvent();</span>
247 
248     static unsigned s_hardwareContextCount;
249 
250     // Restrictions to change default behaviors.
251     enum BehaviorRestrictionFlags {
252         NoRestrictions = 0,
253         RequireUserGestureForAudioStartRestriction = 1 &lt;&lt; 0,
254         RequirePageConsentForAudioStartRestriction = 1 &lt;&lt; 1,
255     };
256     typedef unsigned BehaviorRestrictions;
257 
258     BehaviorRestrictions behaviorRestrictions() const { return m_restrictions; }
259     void addBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions |= restriction; }
260     void removeBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions &amp;= ~restriction; }
261 
262     void isPlayingAudioDidChange();
263 
264     void nodeWillBeginPlayback();
265 













266 protected:
267     explicit AudioContext(Document&amp;);
268     AudioContext(Document&amp;, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
269 
270     static bool isSampleRateRangeGood(float sampleRate);


271 
272 private:
273     void constructCommon();
274 
275     void lazyInitialize();
276     void uninitialize();
277 
278     bool willBeginPlayback();
279     bool willPausePlayback();
280 
281     bool userGestureRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequireUserGestureForAudioStartRestriction; }
282     bool pageConsentRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequirePageConsentForAudioStartRestriction; }
283 
284     void setState(State);
285 
286     void clear();
287 
288     void scheduleNodeDeletion();
289 
290     void mediaCanStart(Document&amp;) override;
291 




292     // MediaProducer
293     MediaProducer::MediaStateFlags mediaState() const override;
294     void pageMutedStateDidChange() override;
295 
296     // The context itself keeps a reference to all source nodes.  The source nodes, then reference all nodes they&#39;re connected to.
297     // In turn, these nodes reference all nodes they&#39;re connected to.  All nodes are ultimately connected to the AudioDestinationNode.
298     // When the context dereferences a source node, it will be deactivated from the rendering graph along with all other nodes it is
299     // uniquely connected to.  See the AudioNode::ref() and AudioNode::deref() methods for more details.
300     void refNode(AudioNode&amp;);
301     void derefNode(AudioNode&amp;);
302 
303     // ActiveDOMObject API.
304     void stop() override;
305     bool canSuspendForDocumentSuspension() const override;
306     const char* activeDOMObjectName() const override;
307 
308     // When the context goes away, there might still be some sources which haven&#39;t finished playing.
309     // Make sure to dereference them here.
310     void derefUnfinishedSourceNodes();
311 
</pre>
<hr />
<pre>
319     void didReceiveRemoteControlCommand(PlatformMediaSession::RemoteControlCommandType, const PlatformMediaSession::RemoteCommandArgument*) override { }
320     bool supportsSeeking() const override { return false; }
321     bool shouldOverrideBackgroundPlaybackRestriction(PlatformMediaSession::InterruptionType) const override { return false; }
322     String sourceApplicationIdentifier() const override;
323     bool canProduceAudio() const final { return true; }
324     bool isSuspended() const final;
325     bool processingUserGestureForMedia() const final;
326 
327     void visibilityStateChanged() final;
328 
329     // EventTarget
330     void refEventTarget() override { ref(); }
331     void derefEventTarget() override { deref(); }
332 
333     void handleDirtyAudioSummingJunctions();
334     void handleDirtyAudioNodeOutputs();
335 
336     void addReaction(State, DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
337     void updateAutomaticPullNodes();
338 









339     // Only accessed in the audio thread.
340     Vector&lt;AudioNode*&gt; m_finishedNodes;
341 
342     // We don&#39;t use RefPtr&lt;AudioNode&gt; here because AudioNode has a more complex ref() / deref() implementation
343     // with an optional argument for refType.  We need to use the special refType: RefTypeConnection
344     // Either accessed when the graph lock is held, or on the main thread when the audio thread has finished.
345     Vector&lt;AudioNode*&gt; m_referencedNodes;
346 
347     // Accumulate nodes which need to be deleted here.
348     // This is copied to m_nodesToDelete at the end of a render cycle in handlePostRenderTasks(), where we&#39;re assured of a stable graph
349     // state which will have no references to any of the nodes in m_nodesToDelete once the context lock is released
350     // (when handlePostRenderTasks() has completed).
351     Vector&lt;AudioNode*&gt; m_nodesMarkedForDeletion;
352 
353     // They will be scheduled for deletion (on the main thread) at the end of a render cycle (in realtime thread).
354     Vector&lt;AudioNode*&gt; m_nodesToDelete;
355 
356     bool m_isDeletionScheduled { false };
357     bool m_isStopScheduled { false };
358     bool m_isInitialized { false };
</pre>
<hr />
<pre>
371     // Only accessed in the audio thread.
372     Vector&lt;AudioNode*&gt; m_deferredFinishDerefList;
373     Vector&lt;Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt;&gt; m_stateReactions;
374 
375     std::unique_ptr&lt;PlatformMediaSession&gt; m_mediaSession;
376     std::unique_ptr&lt;GenericEventQueue&gt; m_eventQueue;
377 
378     RefPtr&lt;AudioBuffer&gt; m_renderTarget;
379     RefPtr&lt;AudioDestinationNode&gt; m_destinationNode;
380     RefPtr&lt;AudioListener&gt; m_listener;
381 
382     unsigned m_connectionCount { 0 };
383 
384     // Graph locking.
385     Lock m_contextGraphMutex;
386     // FIXME: Using volatile seems incorrect.
387     // https://bugs.webkit.org/show_bug.cgi?id=180332
388     Thread* volatile m_audioThread { nullptr };
389     Thread* volatile m_graphOwnerThread { nullptr }; // if the lock is held then this is the thread which owns it, otherwise == nullptr.
390 
<span class="line-modified">391     AsyncAudioDecoder m_audioDecoder;</span>
392 
393     // This is considering 32 is large enough for multiple channels audio.
394     // It is somewhat arbitrary and could be increased if necessary.
395     enum { MaxNumberOfChannels = 32 };
396 
397     // Number of AudioBufferSourceNodes that are active (playing).
398     std::atomic&lt;int&gt; m_activeSourceCount { 0 };
399 
400     BehaviorRestrictions m_restrictions { NoRestrictions };
401 
402     State m_state { State::Suspended };

403 };
404 
405 // FIXME: Find out why these ==/!= functions are needed and remove them if possible.
406 
407 inline bool operator==(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
408 {
409     return &amp;lhs == &amp;rhs;
410 }
411 
412 inline bool operator!=(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
413 {
414     return &amp;lhs != &amp;rhs;
415 }
416 
417 inline AudioContext::State AudioContext::state() const
418 {
419     return m_state;
420 }
421 
422 } // WebCore
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
  2  * Copyright (C) 2010 Google Inc. All rights reserved.
<span class="line-modified">  3  * Copyright (C) 2016-2019 Apple Inc. All rights reserved.</span>
  4  *
  5  * Redistribution and use in source and binary forms, with or without
  6  * modification, are permitted provided that the following conditions
  7  * are met:
  8  * 1.  Redistributions of source code must retain the above copyright
  9  *    notice, this list of conditions and the following disclaimer.
 10  * 2.  Redistributions in binary form must reproduce the above copyright
 11  *    notice, this list of conditions and the following disclaimer in the
 12  *    documentation and/or other materials provided with the distribution.
 13  *
 14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 16  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 17  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 18  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 19  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 20  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 21  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 23  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;ActiveDOMObject.h&quot;
 29 #include &quot;AsyncAudioDecoder.h&quot;
 30 #include &quot;AudioBus.h&quot;
 31 #include &quot;AudioDestinationNode.h&quot;
 32 #include &quot;EventTarget.h&quot;
 33 #include &quot;JSDOMPromiseDeferred.h&quot;
 34 #include &quot;MediaCanStartListener.h&quot;
 35 #include &quot;MediaProducer.h&quot;
 36 #include &quot;PlatformMediaSession.h&quot;
<span class="line-added"> 37 #include &quot;ScriptExecutionContext.h&quot;</span>
 38 #include &quot;VisibilityChangeClient.h&quot;
<span class="line-added"> 39 #include &lt;JavaScriptCore/ConsoleTypes.h&gt;</span>
 40 #include &lt;JavaScriptCore/Float32Array.h&gt;
 41 #include &lt;atomic&gt;
 42 #include &lt;wtf/HashSet.h&gt;
<span class="line-added"> 43 #include &lt;wtf/LoggerHelper.h&gt;</span>
 44 #include &lt;wtf/MainThread.h&gt;
 45 #include &lt;wtf/RefPtr.h&gt;
 46 #include &lt;wtf/ThreadSafeRefCounted.h&gt;
 47 #include &lt;wtf/Threading.h&gt;
 48 #include &lt;wtf/Vector.h&gt;
<span class="line-modified"> 49 #include &lt;wtf/text/AtomStringHash.h&gt;</span>
 50 
 51 namespace WebCore {
 52 
 53 class AnalyserNode;
 54 class AudioBuffer;
 55 class AudioBufferCallback;
 56 class AudioBufferSourceNode;
 57 class AudioListener;
 58 class AudioSummingJunction;
 59 class BiquadFilterNode;
 60 class ChannelMergerNode;
 61 class ChannelSplitterNode;
 62 class ConvolverNode;
 63 class DelayNode;
 64 class Document;
 65 class DynamicsCompressorNode;
 66 class GainNode;
 67 class GenericEventQueue;
 68 class HTMLMediaElement;
 69 class MediaElementAudioSourceNode;
 70 class MediaStream;
 71 class MediaStreamAudioDestinationNode;
 72 class MediaStreamAudioSourceNode;
 73 class OscillatorNode;
 74 class PannerNode;
 75 class PeriodicWave;
 76 class ScriptProcessorNode;
<span class="line-added"> 77 class SecurityOrigin;</span>
 78 class WaveShaperNode;
 79 
 80 // AudioContext is the cornerstone of the web audio API and all AudioNodes are created from it.
 81 // For thread safety between the audio thread and the main thread, it has a rendering graph locking mechanism.
 82 
<span class="line-modified"> 83 class AudioContext</span>
<span class="line-added"> 84     : public ActiveDOMObject</span>
<span class="line-added"> 85     , public ThreadSafeRefCounted&lt;AudioContext&gt;</span>
<span class="line-added"> 86     , public EventTargetWithInlineData</span>
<span class="line-added"> 87     , public MediaCanStartListener</span>
<span class="line-added"> 88     , public MediaProducer</span>
<span class="line-added"> 89     , private PlatformMediaSessionClient</span>
<span class="line-added"> 90     , private VisibilityChangeClient</span>
<span class="line-added"> 91 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added"> 92     , private LoggerHelper</span>
<span class="line-added"> 93 #endif</span>
<span class="line-added"> 94 {</span>
<span class="line-added"> 95     WTF_MAKE_ISO_ALLOCATED(AudioContext);</span>
 96 public:
 97     // Create an AudioContext for rendering to the audio hardware.
 98     static RefPtr&lt;AudioContext&gt; create(Document&amp;);
 99 
100     virtual ~AudioContext();
101 
102     bool isInitialized() const;
103 
104     bool isOfflineContext() const { return m_isOfflineContext; }
105 
106     Document* document() const; // ASSERTs if document no longer exists.
107 
108     Document* hostingDocument() const final;
109 
110     AudioDestinationNode* destination() { return m_destinationNode.get(); }
<span class="line-modified">111     size_t currentSampleFrame() const { return m_destinationNode ? m_destinationNode-&gt;currentSampleFrame() : 0; }</span>
<span class="line-modified">112     double currentTime() const { return m_destinationNode ? m_destinationNode-&gt;currentTime() : 0.; }</span>
<span class="line-modified">113     float sampleRate() const { return m_destinationNode ? m_destinationNode-&gt;sampleRate() : 0.f; }</span>
114     unsigned long activeSourceCount() const { return static_cast&lt;unsigned long&gt;(m_activeSourceCount); }
115 
116     void incrementActiveSourceCount();
117     void decrementActiveSourceCount();
118 
119     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
120     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(ArrayBuffer&amp;, bool mixToMono);
121 
122     // Asynchronous audio file data decoding.
123     void decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;);
124 
125     AudioListener* listener() { return m_listener.get(); }
126 
127     using ActiveDOMObject::suspend;
128     using ActiveDOMObject::resume;
129 
130     void suspend(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
131     void resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
132     void close(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
133 
134     enum class State { Suspended, Running, Interrupted, Closed };
135     State state() const;
<span class="line-added">136     bool isClosed() const { return m_state == State::Closed; }</span>
137 
138     bool wouldTaintOrigin(const URL&amp;) const;
139 
140     // The AudioNode create methods are called on the main thread (from JavaScript).
<span class="line-modified">141     ExceptionOr&lt;Ref&lt;AudioBufferSourceNode&gt;&gt; createBufferSource();</span>
142 #if ENABLE(VIDEO)
143     ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; createMediaElementSource(HTMLMediaElement&amp;);
144 #endif
145 #if ENABLE(MEDIA_STREAM)
146     ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; createMediaStreamSource(MediaStream&amp;);
<span class="line-modified">147     ExceptionOr&lt;Ref&lt;MediaStreamAudioDestinationNode&gt;&gt; createMediaStreamDestination();</span>
148 #endif
<span class="line-modified">149     ExceptionOr&lt;Ref&lt;GainNode&gt;&gt; createGain();</span>
<span class="line-modified">150     ExceptionOr&lt;Ref&lt;BiquadFilterNode&gt;&gt; createBiquadFilter();</span>
<span class="line-modified">151     ExceptionOr&lt;Ref&lt;WaveShaperNode&gt;&gt; createWaveShaper();</span>
152     ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; createDelay(double maxDelayTime);
<span class="line-modified">153     ExceptionOr&lt;Ref&lt;PannerNode&gt;&gt; createPanner();</span>
<span class="line-modified">154     ExceptionOr&lt;Ref&lt;ConvolverNode&gt;&gt; createConvolver();</span>
<span class="line-modified">155     ExceptionOr&lt;Ref&lt;DynamicsCompressorNode&gt;&gt; createDynamicsCompressor();</span>
<span class="line-modified">156     ExceptionOr&lt;Ref&lt;AnalyserNode&gt;&gt; createAnalyser();</span>
157     ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels);
158     ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; createChannelSplitter(size_t numberOfOutputs);
159     ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; createChannelMerger(size_t numberOfInputs);
<span class="line-modified">160     ExceptionOr&lt;Ref&lt;OscillatorNode&gt;&gt; createOscillator();</span>
161     ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary);
162 
163     // When a source node has no more processing to do (has finished playing), then it tells the context to dereference it.
164     void notifyNodeFinishedProcessing(AudioNode*);
165 
166     // Called at the start of each render quantum.
167     void handlePreRenderTasks();
168 
169     // Called at the end of each render quantum.
170     void handlePostRenderTasks();
171 
172     // Called periodically at the end of each render quantum to dereference finished source nodes.
173     void derefFinishedSourceNodes();
174 
175     // We schedule deletion of all marked nodes at the end of each realtime render quantum.
176     void markForDeletion(AudioNode&amp;);
177     void deleteMarkedNodes();
178 
179     // AudioContext can pull node(s) at the end of each render quantum even when they are not connected to any downstream nodes.
180     // These two methods are called by the nodes who want to add/remove themselves into/from the automatic pull lists.
</pre>
<hr />
<pre>
236     private:
237         AudioContext&amp; m_context;
238         bool m_mustReleaseLock;
239     };
240 
241     // In AudioNode::deref() a tryLock() is used for calling finishDeref(), but if it fails keep track here.
242     void addDeferredFinishDeref(AudioNode*);
243 
244     // In the audio thread at the start of each render cycle, we&#39;ll call handleDeferredFinishDerefs().
245     void handleDeferredFinishDerefs();
246 
247     // Only accessed when the graph lock is held.
248     void markSummingJunctionDirty(AudioSummingJunction*);
249     void markAudioNodeOutputDirty(AudioNodeOutput*);
250 
251     // Must be called on main thread.
252     void removeMarkedSummingJunction(AudioSummingJunction*);
253 
254     // EventTarget
255     EventTargetInterface eventTargetInterface() const final { return AudioContextEventTargetInterfaceType; }

256 
257     // Reconcile ref/deref which are defined both in ThreadSafeRefCounted and EventTarget.
258     using ThreadSafeRefCounted::ref;
259     using ThreadSafeRefCounted::deref;
260 
261     void startRendering();
<span class="line-modified">262     void finishedRendering(bool didRendering);</span>
263 
264     static unsigned s_hardwareContextCount;
265 
266     // Restrictions to change default behaviors.
267     enum BehaviorRestrictionFlags {
268         NoRestrictions = 0,
269         RequireUserGestureForAudioStartRestriction = 1 &lt;&lt; 0,
270         RequirePageConsentForAudioStartRestriction = 1 &lt;&lt; 1,
271     };
272     typedef unsigned BehaviorRestrictions;
273 
274     BehaviorRestrictions behaviorRestrictions() const { return m_restrictions; }
275     void addBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions |= restriction; }
276     void removeBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions &amp;= ~restriction; }
277 
278     void isPlayingAudioDidChange();
279 
280     void nodeWillBeginPlayback();
281 
<span class="line-added">282 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">283     const Logger&amp; logger() const final { return m_logger.get(); }</span>
<span class="line-added">284     const void* logIdentifier() const final { return m_logIdentifier; }</span>
<span class="line-added">285     WTFLogChannel&amp; logChannel() const final;</span>
<span class="line-added">286     const void* nextAudioNodeLogIdentifier() { return childLogIdentifier(++m_nextAudioNodeIdentifier); }</span>
<span class="line-added">287     const void* nextAudioParameterLogIdentifier() { return childLogIdentifier(++m_nextAudioParameterIdentifier); }</span>
<span class="line-added">288 #endif</span>
<span class="line-added">289 </span>
<span class="line-added">290     void postTask(WTF::Function&lt;void()&gt;&amp;&amp;);</span>
<span class="line-added">291     bool isStopped() const { return m_isStopScheduled; }</span>
<span class="line-added">292     const SecurityOrigin* origin() const;</span>
<span class="line-added">293     void addConsoleMessage(MessageSource, MessageLevel, const String&amp; message);</span>
<span class="line-added">294 </span>
295 protected:
296     explicit AudioContext(Document&amp;);
297     AudioContext(Document&amp;, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
298 
299     static bool isSampleRateRangeGood(float sampleRate);
<span class="line-added">300     void clearPendingActivity();</span>
<span class="line-added">301     void makePendingActivity();</span>
302 
303 private:
304     void constructCommon();
305 
306     void lazyInitialize();
307     void uninitialize();
308 
309     bool willBeginPlayback();
310     bool willPausePlayback();
311 
312     bool userGestureRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequireUserGestureForAudioStartRestriction; }
313     bool pageConsentRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequirePageConsentForAudioStartRestriction; }
314 
315     void setState(State);
316 
317     void clear();
318 
319     void scheduleNodeDeletion();
320 
321     void mediaCanStart(Document&amp;) override;
322 
<span class="line-added">323     // EventTarget</span>
<span class="line-added">324     ScriptExecutionContext* scriptExecutionContext() const final;</span>
<span class="line-added">325     void dispatchEvent(Event&amp;) final;</span>
<span class="line-added">326 </span>
327     // MediaProducer
328     MediaProducer::MediaStateFlags mediaState() const override;
329     void pageMutedStateDidChange() override;
330 
331     // The context itself keeps a reference to all source nodes.  The source nodes, then reference all nodes they&#39;re connected to.
332     // In turn, these nodes reference all nodes they&#39;re connected to.  All nodes are ultimately connected to the AudioDestinationNode.
333     // When the context dereferences a source node, it will be deactivated from the rendering graph along with all other nodes it is
334     // uniquely connected to.  See the AudioNode::ref() and AudioNode::deref() methods for more details.
335     void refNode(AudioNode&amp;);
336     void derefNode(AudioNode&amp;);
337 
338     // ActiveDOMObject API.
339     void stop() override;
340     bool canSuspendForDocumentSuspension() const override;
341     const char* activeDOMObjectName() const override;
342 
343     // When the context goes away, there might still be some sources which haven&#39;t finished playing.
344     // Make sure to dereference them here.
345     void derefUnfinishedSourceNodes();
346 
</pre>
<hr />
<pre>
354     void didReceiveRemoteControlCommand(PlatformMediaSession::RemoteControlCommandType, const PlatformMediaSession::RemoteCommandArgument*) override { }
355     bool supportsSeeking() const override { return false; }
356     bool shouldOverrideBackgroundPlaybackRestriction(PlatformMediaSession::InterruptionType) const override { return false; }
357     String sourceApplicationIdentifier() const override;
358     bool canProduceAudio() const final { return true; }
359     bool isSuspended() const final;
360     bool processingUserGestureForMedia() const final;
361 
362     void visibilityStateChanged() final;
363 
364     // EventTarget
365     void refEventTarget() override { ref(); }
366     void derefEventTarget() override { deref(); }
367 
368     void handleDirtyAudioSummingJunctions();
369     void handleDirtyAudioNodeOutputs();
370 
371     void addReaction(State, DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
372     void updateAutomaticPullNodes();
373 
<span class="line-added">374 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">375     const char* logClassName() const final { return &quot;AudioContext&quot;; }</span>
<span class="line-added">376 </span>
<span class="line-added">377     Ref&lt;Logger&gt; m_logger;</span>
<span class="line-added">378     const void* m_logIdentifier;</span>
<span class="line-added">379     uint64_t m_nextAudioNodeIdentifier { 0 };</span>
<span class="line-added">380     uint64_t m_nextAudioParameterIdentifier { 0 };</span>
<span class="line-added">381 #endif</span>
<span class="line-added">382 </span>
383     // Only accessed in the audio thread.
384     Vector&lt;AudioNode*&gt; m_finishedNodes;
385 
386     // We don&#39;t use RefPtr&lt;AudioNode&gt; here because AudioNode has a more complex ref() / deref() implementation
387     // with an optional argument for refType.  We need to use the special refType: RefTypeConnection
388     // Either accessed when the graph lock is held, or on the main thread when the audio thread has finished.
389     Vector&lt;AudioNode*&gt; m_referencedNodes;
390 
391     // Accumulate nodes which need to be deleted here.
392     // This is copied to m_nodesToDelete at the end of a render cycle in handlePostRenderTasks(), where we&#39;re assured of a stable graph
393     // state which will have no references to any of the nodes in m_nodesToDelete once the context lock is released
394     // (when handlePostRenderTasks() has completed).
395     Vector&lt;AudioNode*&gt; m_nodesMarkedForDeletion;
396 
397     // They will be scheduled for deletion (on the main thread) at the end of a render cycle (in realtime thread).
398     Vector&lt;AudioNode*&gt; m_nodesToDelete;
399 
400     bool m_isDeletionScheduled { false };
401     bool m_isStopScheduled { false };
402     bool m_isInitialized { false };
</pre>
<hr />
<pre>
415     // Only accessed in the audio thread.
416     Vector&lt;AudioNode*&gt; m_deferredFinishDerefList;
417     Vector&lt;Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt;&gt; m_stateReactions;
418 
419     std::unique_ptr&lt;PlatformMediaSession&gt; m_mediaSession;
420     std::unique_ptr&lt;GenericEventQueue&gt; m_eventQueue;
421 
422     RefPtr&lt;AudioBuffer&gt; m_renderTarget;
423     RefPtr&lt;AudioDestinationNode&gt; m_destinationNode;
424     RefPtr&lt;AudioListener&gt; m_listener;
425 
426     unsigned m_connectionCount { 0 };
427 
428     // Graph locking.
429     Lock m_contextGraphMutex;
430     // FIXME: Using volatile seems incorrect.
431     // https://bugs.webkit.org/show_bug.cgi?id=180332
432     Thread* volatile m_audioThread { nullptr };
433     Thread* volatile m_graphOwnerThread { nullptr }; // if the lock is held then this is the thread which owns it, otherwise == nullptr.
434 
<span class="line-modified">435     std::unique_ptr&lt;AsyncAudioDecoder&gt; m_audioDecoder;</span>
436 
437     // This is considering 32 is large enough for multiple channels audio.
438     // It is somewhat arbitrary and could be increased if necessary.
439     enum { MaxNumberOfChannels = 32 };
440 
441     // Number of AudioBufferSourceNodes that are active (playing).
442     std::atomic&lt;int&gt; m_activeSourceCount { 0 };
443 
444     BehaviorRestrictions m_restrictions { NoRestrictions };
445 
446     State m_state { State::Suspended };
<span class="line-added">447     RefPtr&lt;PendingActivity&lt;AudioContext&gt;&gt; m_pendingActivity;</span>
448 };
449 
450 // FIXME: Find out why these ==/!= functions are needed and remove them if possible.
451 
452 inline bool operator==(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
453 {
454     return &amp;lhs == &amp;rhs;
455 }
456 
457 inline bool operator!=(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
458 {
459     return &amp;lhs != &amp;rhs;
460 }
461 
462 inline AudioContext::State AudioContext::state() const
463 {
464     return m_state;
465 }
466 
467 } // WebCore
</pre>
</td>
</tr>
</table>
<center><a href="AudioContext.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioContext.idl.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>