diff a/modules/javafx.web/src/main/native/Source/WTF/wtf/MetaAllocator.cpp b/modules/javafx.web/src/main/native/Source/WTF/wtf/MetaAllocator.cpp
--- a/modules/javafx.web/src/main/native/Source/WTF/wtf/MetaAllocator.cpp
+++ b/modules/javafx.web/src/main/native/Source/WTF/wtf/MetaAllocator.cpp
@@ -192,11 +192,11 @@
     auto handle = adoptRef(*new MetaAllocatorHandle(this, start.untaggedPtr(), sizeInBytes, ownerUID));
 
     if (UNLIKELY(!!m_tracker))
         m_tracker->notify(handle.ptr());
 
-    return WTFMove(handle);
+    return handle;
 }
 
 MetaAllocator::Statistics MetaAllocator::currentStatistics()
 {
     LockHolder locker(&m_lock);
@@ -396,35 +396,63 @@
 void MetaAllocator::incrementPageOccupancy(void* address, size_t sizeInBytes)
 {
     uintptr_t firstPage = reinterpret_cast<uintptr_t>(address) >> m_logPageSize;
     uintptr_t lastPage = (reinterpret_cast<uintptr_t>(address) + sizeInBytes - 1) >> m_logPageSize;
 
+    uintptr_t currentPageStart = 0;
+    size_t count = 0;
+    auto flushNeedPages = [&] {
+        if (!currentPageStart)
+            return;
+        notifyNeedPage(reinterpret_cast<void*>(currentPageStart << m_logPageSize), count);
+        currentPageStart = 0;
+        count = 0;
+    };
+
     for (uintptr_t page = firstPage; page <= lastPage; ++page) {
-        HashMap<uintptr_t, size_t>::iterator iter = m_pageOccupancyMap.find(page);
-        if (iter == m_pageOccupancyMap.end()) {
-            m_pageOccupancyMap.add(page, 1);
+        auto result = m_pageOccupancyMap.add(page, 1);
+        if (result.isNewEntry) {
             m_bytesCommitted += m_pageSize;
-            notifyNeedPage(reinterpret_cast<void*>(page << m_logPageSize));
-        } else
-            iter->value++;
+            if (!currentPageStart)
+                currentPageStart = page;
+            ++count;
+        } else {
+            result.iterator->value++;
+            flushNeedPages();
+        }
     }
+    flushNeedPages();
 }
 
 void MetaAllocator::decrementPageOccupancy(void* address, size_t sizeInBytes)
 {
     uintptr_t firstPage = reinterpret_cast<uintptr_t>(address) >> m_logPageSize;
     uintptr_t lastPage = (reinterpret_cast<uintptr_t>(address) + sizeInBytes - 1) >> m_logPageSize;
 
+    uintptr_t currentPageStart = 0;
+    size_t count = 0;
+    auto flushFreePages = [&] {
+        if (!currentPageStart)
+            return;
+        notifyPageIsFree(reinterpret_cast<void*>(currentPageStart << m_logPageSize), count);
+        currentPageStart = 0;
+        count = 0;
+    };
+
     for (uintptr_t page = firstPage; page <= lastPage; ++page) {
         HashMap<uintptr_t, size_t>::iterator iter = m_pageOccupancyMap.find(page);
         ASSERT(iter != m_pageOccupancyMap.end());
         if (!--(iter->value)) {
             m_pageOccupancyMap.remove(iter);
             m_bytesCommitted -= m_pageSize;
-            notifyPageIsFree(reinterpret_cast<void*>(page << m_logPageSize));
-        }
+            if (!currentPageStart)
+                currentPageStart = page;
+            ++count;
+        } else
+            flushFreePages();
     }
+    flushFreePages();
 }
 
 bool MetaAllocator::isInAllocatedMemory(const AbstractLocker&, void* address)
 {
     ASSERT(m_lock.isLocked());
