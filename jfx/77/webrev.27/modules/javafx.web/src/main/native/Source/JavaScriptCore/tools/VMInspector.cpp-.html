<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.web/src/main/native/Source/JavaScriptCore/tools/VMInspector.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2017-2018 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;VMInspector.h&quot;
 28 
 29 #include &quot;CodeBlock.h&quot;
 30 #include &quot;CodeBlockSet.h&quot;
 31 #include &quot;HeapInlines.h&quot;
 32 #include &quot;HeapIterationScope.h&quot;
 33 #include &quot;JSCInlines.h&quot;
 34 #include &quot;MachineContext.h&quot;
 35 #include &quot;MarkedSpaceInlines.h&quot;
 36 #include &quot;StackVisitor.h&quot;
 37 #include &lt;mutex&gt;
 38 #include &lt;wtf/Expected.h&gt;
 39 
 40 #if !OS(WINDOWS)
 41 #include &lt;unistd.h&gt;
 42 #endif
 43 
 44 namespace JSC {
 45 
 46 VMInspector&amp; VMInspector::instance()
 47 {
 48     static VMInspector* manager;
 49     static std::once_flag once;
 50     std::call_once(once, [] {
 51         manager = new VMInspector();
 52     });
 53     return *manager;
 54 }
 55 
 56 void VMInspector::add(VM* vm)
 57 {
 58     auto locker = holdLock(m_lock);
 59     m_list.append(vm);
 60 }
 61 
 62 void VMInspector::remove(VM* vm)
 63 {
 64     auto locker = holdLock(m_lock);
 65     m_list.remove(vm);
 66 }
 67 
 68 auto VMInspector::lock(Seconds timeout) -&gt; Expected&lt;Locker, Error&gt;
 69 {
 70     // This function may be called from a signal handler (e.g. via visit()). Hence,
 71     // it should only use APIs that are safe to call from signal handlers. This is
 72     // why we use unistd.h&#39;s sleep() instead of its alternatives.
 73 
 74     // We&#39;ll be doing sleep(1) between tries below. Hence, sleepPerRetry is 1.
 75     unsigned maxRetries = (timeout &lt; Seconds::infinity()) ? timeout.value() : UINT_MAX;
 76 
 77     Expected&lt;Locker, Error&gt; locker = Locker::tryLock(m_lock);
 78     unsigned tryCount = 0;
 79     while (!locker &amp;&amp; tryCount &lt; maxRetries) {
 80         // We want the version of sleep from unistd.h. Cast to disambiguate.
 81 #if !OS(WINDOWS)
 82         (static_cast&lt;unsigned (*)(unsigned)&gt;(sleep))(1);
 83 #endif
 84         locker = Locker::tryLock(m_lock);
 85     }
 86 
 87     if (!locker)
 88         return makeUnexpected(Error::TimedOut);
 89     return locker;
 90 }
 91 
 92 #if ENABLE(JIT)
 93 static bool ensureIsSafeToLock(Lock&amp; lock)
 94 {
 95     unsigned maxRetries = 2;
 96     unsigned tryCount = 0;
 97     while (tryCount &lt;= maxRetries) {
 98         bool success = lock.tryLock();
 99         if (success) {
100             lock.unlock();
101             return true;
102         }
103         tryCount++;
104     }
105     return false;
106 };
107 #endif // ENABLE(JIT)
108 
109 auto VMInspector::isValidExecutableMemory(const VMInspector::Locker&amp;, void* machinePC) -&gt; Expected&lt;bool, Error&gt;
110 {
111 #if ENABLE(JIT)
112     bool found = false;
113     bool hasTimeout = false;
114     iterate([&amp;] (VM&amp;) -&gt; FunctorStatus {
115         auto&amp; allocator = ExecutableAllocator::singleton();
116         auto&amp; lock = allocator.getLock();
117 
118         bool isSafeToLock = ensureIsSafeToLock(lock);
119         if (!isSafeToLock) {
120             hasTimeout = true;
121             return FunctorStatus::Continue; // Skip this VM.
122         }
123 
124         LockHolder executableAllocatorLocker(lock);
125         if (allocator.isValidExecutableMemory(executableAllocatorLocker, machinePC)) {
126             found = true;
127             return FunctorStatus::Done;
128         }
129         return FunctorStatus::Continue;
130     });
131 
132     if (!found &amp;&amp; hasTimeout)
133         return makeUnexpected(Error::TimedOut);
134     return found;
135 #else
136     UNUSED_PARAM(machinePC);
137     return false;
138 #endif
139 }
140 
141 auto VMInspector::codeBlockForMachinePC(const VMInspector::Locker&amp;, void* machinePC) -&gt; Expected&lt;CodeBlock*, Error&gt;
142 {
143 #if ENABLE(JIT)
144     CodeBlock* codeBlock = nullptr;
145     bool hasTimeout = false;
146     iterate([&amp;] (VM&amp; vm) {
147         if (!vm.currentThreadIsHoldingAPILock())
148             return FunctorStatus::Continue;
149 
150         // It is safe to call Heap::forEachCodeBlockIgnoringJITPlans here because:
151         // 1. CodeBlocks are added to the CodeBlockSet from the main thread before
152         //    they are handed to the JIT plans. Those codeBlocks will have a null jitCode,
153         //    but we check for that in our lambda functor.
154         // 2. We will acquire the CodeBlockSet lock before iterating.
155         //    This ensures that a CodeBlock won&#39;t be GCed while we&#39;re iterating.
156         // 3. We do a tryLock on the CodeBlockSet&#39;s lock first to ensure that it is
157         //    safe for the current thread to lock it before calling
158         //    Heap::forEachCodeBlockIgnoringJITPlans(). Hence, there&#39;s no risk of
159         //    re-entering the lock and deadlocking on it.
160 
161         auto&amp; codeBlockSetLock = vm.heap.codeBlockSet().getLock();
162         bool isSafeToLock = ensureIsSafeToLock(codeBlockSetLock);
163         if (!isSafeToLock) {
164             hasTimeout = true;
165             return FunctorStatus::Continue; // Skip this VM.
166         }
167 
168         auto locker = holdLock(codeBlockSetLock);
169         vm.heap.forEachCodeBlockIgnoringJITPlans(locker, [&amp;] (CodeBlock* cb) {
170             JITCode* jitCode = cb-&gt;jitCode().get();
171             if (!jitCode) {
172                 // If the codeBlock is a replacement codeBlock which is in the process of being
173                 // compiled, its jitCode will be null, and we can disregard it as a match for
174                 // the machinePC we&#39;re searching for.
175                 return;
176             }
177 
178             if (!JITCode::isJIT(jitCode-&gt;jitType()))
179                 return;
180 
181             if (jitCode-&gt;contains(machinePC)) {
182                 codeBlock = cb;
183                 return;
184             }
185         });
186         if (codeBlock)
187             return FunctorStatus::Done;
188         return FunctorStatus::Continue;
189     });
190 
191     if (!codeBlock &amp;&amp; hasTimeout)
192         return makeUnexpected(Error::TimedOut);
193     return codeBlock;
194 #else
195     UNUSED_PARAM(machinePC);
196     return nullptr;
197 #endif
198 }
199 
200 bool VMInspector::currentThreadOwnsJSLock(ExecState* exec)
201 {
202     return exec-&gt;vm().currentThreadIsHoldingAPILock();
203 }
204 
205 static bool ensureCurrentThreadOwnsJSLock(ExecState* exec)
206 {
207     if (VMInspector::currentThreadOwnsJSLock(exec))
208         return true;
209     dataLog(&quot;ERROR: current thread does not own the JSLock\n&quot;);
210     return false;
211 }
212 
213 void VMInspector::gc(ExecState* exec)
214 {
215     VM&amp; vm = exec-&gt;vm();
216     if (!ensureCurrentThreadOwnsJSLock(exec))
217         return;
218     vm.heap.collectNow(Sync, CollectionScope::Full);
219 }
220 
221 void VMInspector::edenGC(ExecState* exec)
222 {
223     VM&amp; vm = exec-&gt;vm();
224     if (!ensureCurrentThreadOwnsJSLock(exec))
225         return;
226     vm.heap.collectSync(CollectionScope::Eden);
227 }
228 
229 bool VMInspector::isInHeap(Heap* heap, void* ptr)
230 {
231     MarkedBlock* candidate = MarkedBlock::blockFor(ptr);
232     if (heap-&gt;objectSpace().blocks().set().contains(candidate))
233         return true;
234     for (LargeAllocation* allocation : heap-&gt;objectSpace().largeAllocations()) {
235         if (allocation-&gt;contains(ptr))
236             return true;
237     }
238     return false;
239 }
240 
241 struct CellAddressCheckFunctor : MarkedBlock::CountFunctor {
242     CellAddressCheckFunctor(JSCell* candidate)
243         : candidate(candidate)
244     {
245     }
246 
247     IterationStatus operator()(HeapCell* cell, HeapCell::Kind) const
248     {
249         if (cell == candidate) {
250             found = true;
251             return IterationStatus::Done;
252         }
253         return IterationStatus::Continue;
254     }
255 
256     JSCell* candidate;
257     mutable bool found { false };
258 };
259 
260 bool VMInspector::isValidCell(Heap* heap, JSCell* candidate)
261 {
262     HeapIterationScope iterationScope(*heap);
263     CellAddressCheckFunctor functor(candidate);
264     heap-&gt;objectSpace().forEachLiveCell(iterationScope, functor);
265     return functor.found;
266 }
267 
268 bool VMInspector::isValidCodeBlock(ExecState* exec, CodeBlock* candidate)
269 {
270     if (!ensureCurrentThreadOwnsJSLock(exec))
271         return false;
272 
273     struct CodeBlockValidationFunctor {
274         CodeBlockValidationFunctor(CodeBlock* candidate)
275             : candidate(candidate)
276         {
277         }
278 
279         void operator()(CodeBlock* codeBlock) const
280         {
281             if (codeBlock == candidate)
282                 found = true;
283         }
284 
285         CodeBlock* candidate;
286         mutable bool found { false };
287     };
288 
289     VM&amp; vm = exec-&gt;vm();
290     CodeBlockValidationFunctor functor(candidate);
291     vm.heap.forEachCodeBlock(functor);
292     return functor.found;
293 }
294 
295 CodeBlock* VMInspector::codeBlockForFrame(CallFrame* topCallFrame, unsigned frameNumber)
296 {
297     if (!ensureCurrentThreadOwnsJSLock(topCallFrame))
298         return nullptr;
299 
300     if (!topCallFrame)
301         return nullptr;
302 
303     struct FetchCodeBlockFunctor {
304     public:
305         FetchCodeBlockFunctor(unsigned targetFrameNumber)
306             : targetFrame(targetFrameNumber)
307         {
308         }
309 
310         StackVisitor::Status operator()(StackVisitor&amp; visitor) const
311         {
312             auto currentFrame = nextFrame++;
313             if (currentFrame == targetFrame) {
314                 codeBlock = visitor-&gt;codeBlock();
315                 return StackVisitor::Done;
316             }
317             return StackVisitor::Continue;
318         }
319 
320         unsigned targetFrame;
321         mutable unsigned nextFrame { 0 };
322         mutable CodeBlock* codeBlock { nullptr };
323     };
324 
325     FetchCodeBlockFunctor functor(frameNumber);
326     topCallFrame-&gt;iterate(functor);
327     return functor.codeBlock;
328 }
329 
330 class DumpFrameFunctor {
331 public:
332     enum Action {
333         DumpOne,
334         DumpAll
335     };
336 
337     DumpFrameFunctor(Action action, unsigned framesToSkip)
338         : m_action(action)
339         , m_framesToSkip(framesToSkip)
340     {
341     }
342 
343     StackVisitor::Status operator()(StackVisitor&amp; visitor) const
344     {
345         m_currentFrame++;
346         if (m_currentFrame &gt; m_framesToSkip) {
347             visitor-&gt;dump(WTF::dataFile(), Indenter(2), [&amp;] (PrintStream&amp; out) {
348                 out.print(&quot;[&quot;, (m_currentFrame - m_framesToSkip - 1), &quot;] &quot;);
349             });
350         }
351         if (m_action == DumpOne &amp;&amp; m_currentFrame &gt; m_framesToSkip)
352             return StackVisitor::Done;
353         return StackVisitor::Continue;
354     }
355 
356 private:
357     Action m_action;
358     unsigned m_framesToSkip;
359     mutable unsigned m_currentFrame { 0 };
360 };
361 
362 void VMInspector::dumpCallFrame(CallFrame* callFrame, unsigned framesToSkip)
363 {
364     if (!ensureCurrentThreadOwnsJSLock(callFrame))
365         return;
366     DumpFrameFunctor functor(DumpFrameFunctor::DumpOne, framesToSkip);
367     callFrame-&gt;iterate(functor);
368 }
369 
370 void VMInspector::dumpRegisters(CallFrame* callFrame)
371 {
372     CodeBlock* codeBlock = callFrame-&gt;codeBlock();
373     if (!codeBlock) {
374         dataLog(&quot;Dumping host frame registers not supported.\n&quot;);
375         return;
376     }
377     VM&amp; vm = *codeBlock-&gt;vm();
378     auto valueAsString = [&amp;] (JSValue v) -&gt; CString {
379         if (!v.isCell() || VMInspector::isValidCell(&amp;vm.heap, reinterpret_cast&lt;JSCell*&gt;(JSValue::encode(v))))
380             return toCString(v);
381         return &quot;&quot;;
382     };
383 
384     dataLogF(&quot;Register frame: \n\n&quot;);
385     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
386     dataLogF(&quot;            use            |   address  |                value               \n&quot;);
387     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
388 
389     const Register* it;
390     const Register* end;
391 
392     it = callFrame-&gt;registers() + CallFrameSlot::thisArgument + callFrame-&gt;argumentCount();
393     end = callFrame-&gt;registers() + CallFrameSlot::thisArgument - 1;
394     while (it &gt; end) {
395         JSValue v = it-&gt;jsValue();
396         int registerNumber = it - callFrame-&gt;registers();
397         String name = codeBlock-&gt;nameForRegister(VirtualRegister(registerNumber));
398         dataLogF(&quot;[r% 3d %14s]      | %10p | 0x%-16llx %s\n&quot;, registerNumber, name.ascii().data(), it, (long long)JSValue::encode(v), valueAsString(v).data());
399         --it;
400     }
401 
402     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
403     dataLogF(&quot;[ArgumentCount]            | %10p | %lu \n&quot;, it, (unsigned long) callFrame-&gt;argumentCount());
404 
405     callFrame-&gt;iterate([&amp;] (StackVisitor&amp; visitor) {
406         if (visitor-&gt;callFrame() == callFrame) {
407             unsigned line = 0;
408             unsigned unusedColumn = 0;
409             visitor-&gt;computeLineAndColumn(line, unusedColumn);
410             dataLogF(&quot;[ReturnVPC]                | %10p | %d (line %d)\n&quot;, it, visitor-&gt;bytecodeOffset(), line);
411             return StackVisitor::Done;
412         }
413         return StackVisitor::Continue;
414     });
415 
416     --it;
417     dataLogF(&quot;[Callee]                   | %10p | 0x%-16llx %s\n&quot;, it, (long long)callFrame-&gt;callee().rawPtr(), valueAsString(it-&gt;jsValue()).data());
418     --it;
419     dataLogF(&quot;[CodeBlock]                | %10p | 0x%-16llx &quot;, it, (long long)codeBlock);
420     dataLogLn(codeBlock);
421     --it;
422 #if ENABLE(JIT)
423     AbstractPC pc = callFrame-&gt;abstractReturnPC(callFrame-&gt;vm());
424     if (pc.hasJITReturnAddress())
425         dataLogF(&quot;[ReturnPC]                 | %10p | %p \n&quot;, it, pc.jitReturnAddress().value());
426     --it;
427 #endif
428     dataLogF(&quot;[CallerFrame]              | %10p | %p \n&quot;, it, callFrame-&gt;callerFrame());
429     --it;
430     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
431 
432     size_t numberOfCalleeSaveSlots = codeBlock-&gt;calleeSaveSpaceAsVirtualRegisters();
433     const Register* endOfCalleeSaves = it - numberOfCalleeSaveSlots;
434 
435     end = it - codeBlock-&gt;numVars();
436     if (it != end) {
437         do {
438             JSValue v = it-&gt;jsValue();
439             int registerNumber = it - callFrame-&gt;registers();
440             String name = (it &gt; endOfCalleeSaves)
441                 ? &quot;CalleeSaveReg&quot;
442                 : codeBlock-&gt;nameForRegister(VirtualRegister(registerNumber));
443             dataLogF(&quot;[r% 3d %14s]      | %10p | 0x%-16llx %s\n&quot;, registerNumber, name.ascii().data(), it, (long long)JSValue::encode(v), valueAsString(v).data());
444             --it;
445         } while (it != end);
446     }
447     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
448 
449     end = it - codeBlock-&gt;numCalleeLocals() + codeBlock-&gt;numVars();
450     if (it != end) {
451         do {
452             JSValue v = (*it).jsValue();
453             int registerNumber = it - callFrame-&gt;registers();
454             dataLogF(&quot;[r% 3d]                     | %10p | 0x%-16llx %s\n&quot;, registerNumber, it, (long long)JSValue::encode(v), valueAsString(v).data());
455             --it;
456         } while (it != end);
457     }
458     dataLogF(&quot;-----------------------------------------------------------------------------\n&quot;);
459 }
460 
461 void VMInspector::dumpStack(CallFrame* topCallFrame, unsigned framesToSkip)
462 {
463     if (!ensureCurrentThreadOwnsJSLock(topCallFrame))
464         return;
465     if (!topCallFrame)
466         return;
467     DumpFrameFunctor functor(DumpFrameFunctor::DumpAll, framesToSkip);
468     topCallFrame-&gt;iterate(functor);
469 }
470 
471 void VMInspector::dumpValue(JSValue value)
472 {
473     dataLog(value);
474 }
475 
476 void VMInspector::dumpCellMemory(JSCell* cell)
477 {
478     dumpCellMemoryToStream(cell, WTF::dataFile());
479 }
480 
481 class IndentationScope {
482 public:
483     IndentationScope(unsigned&amp; indentation)
484         : m_indentation(indentation)
485     {
486         ++m_indentation;
487     }
488 
489     ~IndentationScope()
490     {
491         --m_indentation;
492     }
493 
494 private:
495     unsigned&amp; m_indentation;
496 };
497 
498 void VMInspector::dumpCellMemoryToStream(JSCell* cell, PrintStream&amp; out)
499 {
500     VM&amp; vm = *cell-&gt;vm();
501     StructureID structureID = cell-&gt;structureID();
502     Structure* structure = cell-&gt;structure(vm);
503     IndexingType indexingTypeAndMisc = cell-&gt;indexingTypeAndMisc();
504     IndexingType indexingType = structure-&gt;indexingType();
505     IndexingType indexingMode = structure-&gt;indexingMode();
506     JSType type = cell-&gt;type();
507     TypeInfo::InlineTypeFlags inlineTypeFlags = cell-&gt;inlineTypeFlags();
508     CellState cellState = cell-&gt;cellState();
509     size_t cellSize = cell-&gt;cellSize();
510     size_t slotCount = cellSize / sizeof(EncodedJSValue);
511 
512     EncodedJSValue* slots = bitwise_cast&lt;EncodedJSValue*&gt;(cell);
513     unsigned indentation = 0;
514 
515     auto indent = [&amp;] {
516         for (unsigned i = 0 ; i &lt; indentation; ++i)
517             out.print(&quot;  &quot;);
518     };
519 
520 #define INDENT indent(),
521 
522     auto dumpSlot = [&amp;] (EncodedJSValue* slots, unsigned index, const char* label = nullptr) {
523         out.print(&quot;[&quot;, index, &quot;] &quot;, format(&quot;%p : 0x%016&quot; PRIx64, &amp;slots[index], slots[index]));
524         if (label)
525             out.print(&quot; &quot;, label);
526         out.print(&quot;\n&quot;);
527     };
528 
529     out.printf(&quot;&lt;%p, %s&gt;\n&quot;, cell, cell-&gt;className(vm));
530     IndentationScope scope(indentation);
531 
532     INDENT dumpSlot(slots, 0, &quot;header&quot;);
533     {
534         IndentationScope scope(indentation);
535         INDENT out.println(&quot;structureID &quot;, format(&quot;%d 0x%&quot; PRIx32, structureID, structureID), &quot; structure &quot;, RawPointer(structure));
536         INDENT out.println(&quot;indexingTypeAndMisc &quot;, format(&quot;%d 0x%&quot; PRIx8, indexingTypeAndMisc, indexingTypeAndMisc), &quot; &quot;, IndexingTypeDump(indexingMode));
537         INDENT out.println(&quot;type &quot;, format(&quot;%d 0x%&quot; PRIx8, type, type));
538         INDENT out.println(&quot;flags &quot;, format(&quot;%d 0x%&quot; PRIx8, inlineTypeFlags, inlineTypeFlags));
539         INDENT out.println(&quot;cellState &quot;, format(&quot;%d&quot;, cellState));
540     }
541 
542     unsigned slotIndex = 1;
543     if (cell-&gt;isObject()) {
544         JSObject* obj = static_cast&lt;JSObject*&gt;(const_cast&lt;JSCell*&gt;(cell));
545         Butterfly* butterfly = obj-&gt;butterfly();
546         size_t butterflySize = obj-&gt;butterflyTotalSize();
547 
548         INDENT dumpSlot(slots, slotIndex, &quot;butterfly&quot;);
549         slotIndex++;
550 
551         if (butterfly) {
552             IndentationScope scope(indentation);
553 
554             bool hasIndexingHeader = structure-&gt;hasIndexingHeader(cell);
555             bool hasAnyArrayStorage = JSC::hasAnyArrayStorage(indexingType);
556 
557             size_t preCapacity = obj-&gt;butterflyPreCapacity();
558             size_t propertyCapacity = structure-&gt;outOfLineCapacity();
559 
560             void* base = hasIndexingHeader
561                 ? butterfly-&gt;base(preCapacity, propertyCapacity)
562                 : butterfly-&gt;base(structure);
563 
564             unsigned publicLength = butterfly-&gt;publicLength();
565             unsigned vectorLength = butterfly-&gt;vectorLength();
566             size_t butterflyCellSize = MarkedSpace::optimalSizeFor(butterflySize);
567 
568             size_t endOfIndexedPropertiesIndex = butterflySize / sizeof(EncodedJSValue);
569             size_t endOfButterflyIndex = butterflyCellSize / sizeof(EncodedJSValue);
570 
571             INDENT out.println(&quot;base &quot;, RawPointer(base));
572             INDENT out.println(&quot;hasIndexingHeader &quot;, (hasIndexingHeader ? &quot;YES&quot; : &quot;NO&quot;), &quot; hasAnyArrayStorage &quot;, (hasAnyArrayStorage ? &quot;YES&quot; : &quot;NO&quot;));
573             if (hasIndexingHeader) {
574                 INDENT out.print(&quot;publicLength &quot;, publicLength, &quot; vectorLength &quot;, vectorLength);
575                 if (hasAnyArrayStorage)
576                     out.print(&quot; indexBias &quot;, butterfly-&gt;arrayStorage()-&gt;m_indexBias);
577                 out.print(&quot;\n&quot;);
578             }
579             INDENT out.println(&quot;preCapacity &quot;, preCapacity, &quot; propertyCapacity &quot;, propertyCapacity);
580 
581             unsigned index = 0;
582             EncodedJSValue* slots = reinterpret_cast&lt;EncodedJSValue*&gt;(base);
583 
584             auto asVoidPtr = [] (void* p) {
585                 return p;
586             };
587 
588             auto dumpSectionHeader = [&amp;] (const char* name) {
589                 out.println(&quot;&lt;--- &quot;, name);
590             };
591 
592             auto dumpSection = [&amp;] (unsigned startIndex, unsigned endIndex, const char* name) -&gt; unsigned {
593                 for (unsigned index = startIndex; index &lt; endIndex; ++index) {
594                     if (name &amp;&amp; index == startIndex)
595                         INDENT dumpSectionHeader(name);
596                     INDENT dumpSlot(slots, index);
597                 }
598                 return endIndex;
599             };
600 
601             {
602                 IndentationScope scope(indentation);
603 
604                 index = dumpSection(index, preCapacity, &quot;preCapacity&quot;);
605                 index = dumpSection(index, preCapacity + propertyCapacity, &quot;propertyCapacity&quot;);
606 
607                 if (hasIndexingHeader)
608                     index = dumpSection(index, index + 1, &quot;indexingHeader&quot;);
609 
610                 INDENT dumpSectionHeader(&quot;butterfly&quot;);
611                 if (hasAnyArrayStorage) {
612                     RELEASE_ASSERT(asVoidPtr(butterfly-&gt;arrayStorage()) == asVoidPtr(&amp;slots[index]));
613                     RELEASE_ASSERT(ArrayStorage::vectorOffset() == 2 * sizeof(EncodedJSValue));
614                     index = dumpSection(index, index + 2, &quot;arrayStorage&quot;);
615                 }
616 
617                 index = dumpSection(index, endOfIndexedPropertiesIndex, &quot;indexedProperties&quot;);
618                 index = dumpSection(index, endOfButterflyIndex, &quot;unallocated capacity&quot;);
619             }
620         }
621     }
622 
623     for (; slotIndex &lt; slotCount; ++slotIndex)
624         INDENT dumpSlot(slots, slotIndex);
625 
626 #undef INDENT
627 }
628 
629 } // namespace JSC
    </pre>
  </body>
</html>