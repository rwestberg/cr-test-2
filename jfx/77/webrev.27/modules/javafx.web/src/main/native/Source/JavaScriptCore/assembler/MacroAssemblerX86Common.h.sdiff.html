<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="MacroAssemblerX86.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MacroAssemblerX86_64.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
1434         m_assembler.movw_rm(src, address.offset, address.base, address.index, address.scale);
1435     }
1436 
1437     void store16(RegisterID src, Address address)
1438     {
1439         m_assembler.movw_rm(src, address.offset, address.base);
1440     }
1441 
1442     void store16(TrustedImm32 imm, BaseIndex address)
1443     {
1444         m_assembler.movw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
1445     }
1446 
1447     void store16(TrustedImm32 imm, ImplicitAddress address)
1448     {
1449         m_assembler.movw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base);
1450     }
1451 
1452     // Floating-point operation:
1453     //
<span class="line-removed">1454     // Presently only supports SSE, not x87 floating point.</span>
<span class="line-removed">1455 </span>
1456     void moveDouble(FPRegisterID src, FPRegisterID dest)
1457     {
<span class="line-removed">1458         ASSERT(isSSE2Present());</span>
1459         if (src != dest)
1460             m_assembler.movaps_rr(src, dest);
1461     }
1462 
1463     void loadDouble(TrustedImmPtr address, FPRegisterID dest)
1464     {
1465 #if CPU(X86)
<span class="line-removed">1466         ASSERT(isSSE2Present());</span>
1467         m_assembler.movsd_mr(address.asPtr(), dest);
1468 #else
1469         move(address, scratchRegister());
1470         loadDouble(scratchRegister(), dest);
1471 #endif
1472     }
1473 
1474     void loadDouble(ImplicitAddress address, FPRegisterID dest)
1475     {
<span class="line-removed">1476         ASSERT(isSSE2Present());</span>
1477         m_assembler.movsd_mr(address.offset, address.base, dest);
1478     }
1479 
1480     void loadDouble(BaseIndex address, FPRegisterID dest)
1481     {
<span class="line-removed">1482         ASSERT(isSSE2Present());</span>
1483         m_assembler.movsd_mr(address.offset, address.base, address.index, address.scale, dest);
1484     }
1485 
1486     void loadFloat(TrustedImmPtr address, FPRegisterID dest)
1487     {
1488 #if CPU(X86)
<span class="line-removed">1489         ASSERT(isSSE2Present());</span>
1490         m_assembler.movss_mr(address.asPtr(), dest);
1491 #else
1492         move(address, scratchRegister());
1493         loadFloat(scratchRegister(), dest);
1494 #endif
1495     }
1496 
1497     void loadFloat(ImplicitAddress address, FPRegisterID dest)
1498     {
<span class="line-removed">1499         ASSERT(isSSE2Present());</span>
1500         m_assembler.movss_mr(address.offset, address.base, dest);
1501     }
1502 
1503     void loadFloat(BaseIndex address, FPRegisterID dest)
1504     {
<span class="line-removed">1505         ASSERT(isSSE2Present());</span>
1506         m_assembler.movss_mr(address.offset, address.base, address.index, address.scale, dest);
1507     }
1508 
1509     void storeDouble(FPRegisterID src, ImplicitAddress address)
1510     {
<span class="line-removed">1511         ASSERT(isSSE2Present());</span>
1512         m_assembler.movsd_rm(src, address.offset, address.base);
1513     }
1514 
1515     void storeDouble(FPRegisterID src, BaseIndex address)
1516     {
<span class="line-removed">1517         ASSERT(isSSE2Present());</span>
1518         m_assembler.movsd_rm(src, address.offset, address.base, address.index, address.scale);
1519     }
1520 
1521     void storeFloat(FPRegisterID src, ImplicitAddress address)
1522     {
<span class="line-removed">1523         ASSERT(isSSE2Present());</span>
1524         m_assembler.movss_rm(src, address.offset, address.base);
1525     }
1526 
1527     void storeFloat(FPRegisterID src, BaseIndex address)
1528     {
<span class="line-removed">1529         ASSERT(isSSE2Present());</span>
1530         m_assembler.movss_rm(src, address.offset, address.base, address.index, address.scale);
1531     }
1532 
1533     void convertDoubleToFloat(FPRegisterID src, FPRegisterID dst)
1534     {
<span class="line-removed">1535         ASSERT(isSSE2Present());</span>
1536         m_assembler.cvtsd2ss_rr(src, dst);
1537     }
1538 
1539     void convertDoubleToFloat(Address address, FPRegisterID dst)
1540     {
<span class="line-removed">1541         ASSERT(isSSE2Present());</span>
1542         m_assembler.cvtsd2ss_mr(address.offset, address.base, dst);
1543     }
1544 
1545     void convertFloatToDouble(FPRegisterID src, FPRegisterID dst)
1546     {
<span class="line-removed">1547         ASSERT(isSSE2Present());</span>
1548         m_assembler.cvtss2sd_rr(src, dst);
1549     }
1550 
1551     void convertFloatToDouble(Address address, FPRegisterID dst)
1552     {
<span class="line-removed">1553         ASSERT(isSSE2Present());</span>
1554         m_assembler.cvtss2sd_mr(address.offset, address.base, dst);
1555     }
1556 
1557     void addDouble(FPRegisterID src, FPRegisterID dest)
1558     {
1559         addDouble(src, dest, dest);
1560     }
1561 
1562     void addDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1563     {
1564         if (supportsAVX())
1565             m_assembler.vaddsd_rr(op1, op2, dest);
1566         else {
<span class="line-removed">1567             ASSERT(isSSE2Present());</span>
1568             if (op1 == dest)
1569                 m_assembler.addsd_rr(op2, dest);
1570             else {
1571                 moveDouble(op2, dest);
1572                 m_assembler.addsd_rr(op1, dest);
1573             }
1574         }
1575     }
1576 
1577     void addDouble(Address src, FPRegisterID dest)
1578     {
1579         addDouble(src, dest, dest);
1580     }
1581 
1582     void addDouble(Address op1, FPRegisterID op2, FPRegisterID dest)
1583     {
1584         if (supportsAVX())
1585             m_assembler.vaddsd_mr(op1.offset, op1.base, op2, dest);
1586         else {
<span class="line-removed">1587             ASSERT(isSSE2Present());</span>
1588             if (op2 == dest) {
1589                 m_assembler.addsd_mr(op1.offset, op1.base, dest);
1590                 return;
1591             }
1592 
1593             loadDouble(op1, dest);
1594             addDouble(op2, dest);
1595         }
1596     }
1597 
1598     void addDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1599     {
1600         addDouble(op2, op1, dest);
1601     }
1602 
1603     void addDouble(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1604     {
1605         if (supportsAVX())
1606             m_assembler.vaddsd_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1607         else {
<span class="line-removed">1608             ASSERT(isSSE2Present());</span>
1609             if (op2 == dest) {
1610                 m_assembler.addsd_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1611                 return;
1612             }
1613             loadDouble(op1, dest);
1614             addDouble(op2, dest);
1615         }
1616     }
1617 
1618     void addFloat(FPRegisterID src, FPRegisterID dest)
1619     {
1620         addFloat(src, dest, dest);
1621     }
1622 
1623     void addFloat(Address src, FPRegisterID dest)
1624     {
1625         addFloat(src, dest, dest);
1626     }
1627 
1628     void addFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1629     {
1630         if (supportsAVX())
1631             m_assembler.vaddss_rr(op1, op2, dest);
1632         else {
<span class="line-removed">1633             ASSERT(isSSE2Present());</span>
1634             if (op1 == dest)
1635                 m_assembler.addss_rr(op2, dest);
1636             else {
1637                 moveDouble(op2, dest);
1638                 m_assembler.addss_rr(op1, dest);
1639             }
1640         }
1641     }
1642 
1643     void addFloat(Address op1, FPRegisterID op2, FPRegisterID dest)
1644     {
1645         if (supportsAVX())
1646             m_assembler.vaddss_mr(op1.offset, op1.base, op2, dest);
1647         else {
<span class="line-removed">1648             ASSERT(isSSE2Present());</span>
1649             if (op2 == dest) {
1650                 m_assembler.addss_mr(op1.offset, op1.base, dest);
1651                 return;
1652             }
1653 
1654             loadFloat(op1, dest);
1655             addFloat(op2, dest);
1656         }
1657     }
1658 
1659     void addFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1660     {
1661         addFloat(op2, op1, dest);
1662     }
1663 
1664     void addFloat(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1665     {
1666         if (supportsAVX())
1667             m_assembler.vaddss_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1668         else {
<span class="line-removed">1669             ASSERT(isSSE2Present());</span>
1670             if (op2 == dest) {
1671                 m_assembler.addss_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1672                 return;
1673             }
1674             loadFloat(op1, dest);
1675             addFloat(op2, dest);
1676         }
1677     }
1678 
1679     void divDouble(FPRegisterID src, FPRegisterID dest)
1680     {
<span class="line-removed">1681         ASSERT(isSSE2Present());</span>
1682         m_assembler.divsd_rr(src, dest);
1683     }
1684 
1685     void divDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1686     {
1687         // B := A / B is invalid.
1688         ASSERT(op1 == dest || op2 != dest);
1689 
1690         moveDouble(op1, dest);
1691         divDouble(op2, dest);
1692     }
1693 
1694     void divDouble(Address src, FPRegisterID dest)
1695     {
<span class="line-removed">1696         ASSERT(isSSE2Present());</span>
1697         m_assembler.divsd_mr(src.offset, src.base, dest);
1698     }
1699 
1700     void divFloat(FPRegisterID src, FPRegisterID dest)
1701     {
<span class="line-removed">1702         ASSERT(isSSE2Present());</span>
1703         m_assembler.divss_rr(src, dest);
1704     }
1705 
1706     void divFloat(Address src, FPRegisterID dest)
1707     {
<span class="line-removed">1708         ASSERT(isSSE2Present());</span>
1709         m_assembler.divss_mr(src.offset, src.base, dest);
1710     }
1711 
1712     void subDouble(FPRegisterID src, FPRegisterID dest)
1713     {
1714         subDouble(dest, src, dest);
1715     }
1716 
1717     void subDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1718     {
1719         if (supportsAVX())
1720             m_assembler.vsubsd_rr(op1, op2, dest);
1721         else {
<span class="line-removed">1722             ASSERT(isSSE2Present());</span>
<span class="line-removed">1723 </span>
1724             // B := A - B is invalid.
1725             ASSERT(op1 == dest || op2 != dest);
1726             moveDouble(op1, dest);
1727             m_assembler.subsd_rr(op2, dest);
1728         }
1729     }
1730 
1731     void subDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1732     {
1733         if (supportsAVX())
1734             m_assembler.vsubsd_mr(op1, op2.offset, op2.base, dest);
1735         else {
1736             moveDouble(op1, dest);
1737             m_assembler.subsd_mr(op2.offset, op2.base, dest);
1738         }
1739     }
1740 
1741     void subDouble(FPRegisterID op1, BaseIndex op2, FPRegisterID dest)
1742     {
1743         if (supportsAVX())
</pre>
<hr />
<pre>
1746             moveDouble(op1, dest);
1747             m_assembler.subsd_mr(op2.offset, op2.base, op2.index, op2.scale, dest);
1748         }
1749     }
1750 
1751     void subDouble(Address src, FPRegisterID dest)
1752     {
1753         subDouble(dest, src, dest);
1754     }
1755 
1756     void subFloat(FPRegisterID src, FPRegisterID dest)
1757     {
1758         subFloat(dest, src, dest);
1759     }
1760 
1761     void subFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1762     {
1763         if (supportsAVX())
1764             m_assembler.vsubss_rr(op1, op2, dest);
1765         else {
<span class="line-removed">1766             ASSERT(isSSE2Present());</span>
1767             // B := A - B is invalid.
1768             ASSERT(op1 == dest || op2 != dest);
1769             moveDouble(op1, dest);
1770             m_assembler.subss_rr(op2, dest);
1771         }
1772     }
1773 
1774     void subFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1775     {
1776         if (supportsAVX())
1777             m_assembler.vsubss_mr(op1, op2.offset, op2.base, dest);
1778         else {
1779             moveDouble(op1, dest);
1780             m_assembler.subss_mr(op2.offset, op2.base, dest);
1781         }
1782     }
1783 
1784     void subFloat(FPRegisterID op1, BaseIndex op2, FPRegisterID dest)
1785     {
1786         if (supportsAVX())
</pre>
<hr />
<pre>
1789             moveDouble(op1, dest);
1790             m_assembler.subss_mr(op2.offset, op2.base, op2.index, op2.scale, dest);
1791         }
1792     }
1793 
1794     void subFloat(Address src, FPRegisterID dest)
1795     {
1796         subFloat(dest, src, dest);
1797     }
1798 
1799     void mulDouble(FPRegisterID src, FPRegisterID dest)
1800     {
1801         mulDouble(src, dest, dest);
1802     }
1803 
1804     void mulDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1805     {
1806         if (supportsAVX())
1807             m_assembler.vmulsd_rr(op1, op2, dest);
1808         else {
<span class="line-removed">1809             ASSERT(isSSE2Present());</span>
1810             if (op1 == dest)
1811                 m_assembler.mulsd_rr(op2, dest);
1812             else {
1813                 moveDouble(op2, dest);
1814                 m_assembler.mulsd_rr(op1, dest);
1815             }
1816         }
1817     }
1818 
1819     void mulDouble(Address src, FPRegisterID dest)
1820     {
1821         mulDouble(src, dest, dest);
1822     }
1823 
1824     void mulDouble(Address op1, FPRegisterID op2, FPRegisterID dest)
1825     {
1826         if (supportsAVX())
1827             m_assembler.vmulsd_mr(op1.offset, op1.base, op2, dest);
1828         else {
<span class="line-removed">1829             ASSERT(isSSE2Present());</span>
1830             if (op2 == dest) {
1831                 m_assembler.mulsd_mr(op1.offset, op1.base, dest);
1832                 return;
1833             }
1834             loadDouble(op1, dest);
1835             mulDouble(op2, dest);
1836         }
1837     }
1838 
1839     void mulDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1840     {
1841         return mulDouble(op2, op1, dest);
1842     }
1843 
1844     void mulDouble(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1845     {
1846         if (supportsAVX())
1847             m_assembler.vmulsd_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1848         else {
<span class="line-removed">1849             ASSERT(isSSE2Present());</span>
1850             if (op2 == dest) {
1851                 m_assembler.mulsd_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1852                 return;
1853             }
1854             loadDouble(op1, dest);
1855             mulDouble(op2, dest);
1856         }
1857     }
1858 
1859     void mulFloat(FPRegisterID src, FPRegisterID dest)
1860     {
1861         mulFloat(src, dest, dest);
1862     }
1863 
1864     void mulFloat(Address src, FPRegisterID dest)
1865     {
1866         mulFloat(src, dest, dest);
1867     }
1868 
1869     void mulFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1870     {
1871         if (supportsAVX())
1872             m_assembler.vmulss_rr(op1, op2, dest);
1873         else {
<span class="line-removed">1874             ASSERT(isSSE2Present());</span>
1875             if (op1 == dest)
1876                 m_assembler.mulss_rr(op2, dest);
1877             else {
1878                 moveDouble(op2, dest);
1879                 m_assembler.mulss_rr(op1, dest);
1880             }
1881         }
1882     }
1883 
1884     void mulFloat(Address op1, FPRegisterID op2, FPRegisterID dest)
1885     {
1886         if (supportsAVX())
1887             m_assembler.vmulss_mr(op1.offset, op1.base, op2, dest);
1888         else {
<span class="line-removed">1889             ASSERT(isSSE2Present());</span>
1890             if (op2 == dest) {
1891                 m_assembler.mulss_mr(op1.offset, op1.base, dest);
1892                 return;
1893             }
1894             loadFloat(op1, dest);
1895             mulFloat(op2, dest);
1896         }
1897     }
1898 
1899     void mulFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1900     {
1901         mulFloat(op2, op1, dest);
1902     }
1903 
1904     void mulFloat(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1905     {
1906         if (supportsAVX())
1907             m_assembler.vmulss_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1908         else {
<span class="line-removed">1909             ASSERT(isSSE2Present());</span>
1910             if (op2 == dest) {
1911                 m_assembler.mulss_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1912                 return;
1913             }
1914             loadFloat(op1, dest);
1915             mulFloat(op2, dest);
1916         }
1917     }
1918 
1919     void andDouble(FPRegisterID src, FPRegisterID dst)
1920     {
1921         // ANDPS is defined on 128bits and is shorter than ANDPD.
1922         m_assembler.andps_rr(src, dst);
1923     }
1924 
1925     void andDouble(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
1926     {
1927         if (src1 == dst)
1928             andDouble(src2, dst);
1929         else {
</pre>
<hr />
<pre>
1992         }
1993     }
1994 
1995     void xorFloat(FPRegisterID src, FPRegisterID dst)
1996     {
1997         m_assembler.xorps_rr(src, dst);
1998     }
1999 
2000     void xorFloat(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
2001     {
2002         if (src1 == dst)
2003             xorFloat(src2, dst);
2004         else {
2005             moveDouble(src2, dst);
2006             xorFloat(src1, dst);
2007         }
2008     }
2009 
2010     void convertInt32ToDouble(RegisterID src, FPRegisterID dest)
2011     {
<span class="line-removed">2012         ASSERT(isSSE2Present());</span>
2013         m_assembler.cvtsi2sd_rr(src, dest);
2014     }
2015 
2016     void convertInt32ToDouble(Address src, FPRegisterID dest)
2017     {
<span class="line-removed">2018         ASSERT(isSSE2Present());</span>
2019         m_assembler.cvtsi2sd_mr(src.offset, src.base, dest);
2020     }
2021 
2022     void convertInt32ToFloat(RegisterID src, FPRegisterID dest)
2023     {
<span class="line-removed">2024         ASSERT(isSSE2Present());</span>
2025         m_assembler.cvtsi2ss_rr(src, dest);
2026     }
2027 
2028     void convertInt32ToFloat(Address src, FPRegisterID dest)
2029     {
<span class="line-removed">2030         ASSERT(isSSE2Present());</span>
2031         m_assembler.cvtsi2ss_mr(src.offset, src.base, dest);
2032     }
2033 
2034     Jump branchDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
2035     {
<span class="line-removed">2036         ASSERT(isSSE2Present());</span>
<span class="line-removed">2037 </span>
2038         if (cond &amp; DoubleConditionBitInvert)
2039             m_assembler.ucomisd_rr(left, right);
2040         else
2041             m_assembler.ucomisd_rr(right, left);
2042         return jumpAfterFloatingPointCompare(cond, left, right);
2043     }
2044 
2045     Jump branchFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
2046     {
<span class="line-removed">2047         ASSERT(isSSE2Present());</span>
<span class="line-removed">2048 </span>
2049         if (cond &amp; DoubleConditionBitInvert)
2050             m_assembler.ucomiss_rr(left, right);
2051         else
2052             m_assembler.ucomiss_rr(right, left);
2053         return jumpAfterFloatingPointCompare(cond, left, right);
2054     }
2055 
2056     void compareDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
2057     {
<span class="line-removed">2058         ASSERT(isSSE2Present());</span>
2059         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
2060             m_assembler.ucomisd_rr(arg1, arg2);
2061         });
2062     }
2063 
2064     void compareFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
2065     {
<span class="line-removed">2066         ASSERT(isSSE2Present());</span>
2067         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
2068             m_assembler.ucomiss_rr(arg1, arg2);
2069         });
2070     }
2071 
2072     // Truncates &#39;src&#39; to an integer, and places the resulting &#39;dest&#39;.
2073     // If the result is not representable as a 32 bit value, branch.
2074     // May also branch for some values that are representable in 32 bits
2075     // (specifically, in this case, INT_MIN).
2076     enum BranchTruncateType { BranchIfTruncateFailed, BranchIfTruncateSuccessful };
2077     Jump branchTruncateDoubleToInt32(FPRegisterID src, RegisterID dest, BranchTruncateType branchType = BranchIfTruncateFailed)
2078     {
<span class="line-removed">2079         ASSERT(isSSE2Present());</span>
2080         m_assembler.cvttsd2si_rr(src, dest);
2081         return branch32(branchType ? NotEqual : Equal, dest, TrustedImm32(0x80000000));
2082     }
2083 
2084     void truncateDoubleToInt32(FPRegisterID src, RegisterID dest)
2085     {
<span class="line-removed">2086         ASSERT(isSSE2Present());</span>
2087         m_assembler.cvttsd2si_rr(src, dest);
2088     }
2089 
2090     void truncateFloatToInt32(FPRegisterID src, RegisterID dest)
2091     {
<span class="line-removed">2092         ASSERT(isSSE2Present());</span>
2093         m_assembler.cvttss2si_rr(src, dest);
2094     }
2095 
2096     // Convert &#39;src&#39; to an integer, and places the resulting &#39;dest&#39;.
2097     // If the result is not representable as a 32 bit value, branch.
2098     // May also branch for some values that are representable in 32 bits
2099     // (specifically, in this case, 0).
2100     void branchConvertDoubleToInt32(FPRegisterID src, RegisterID dest, JumpList&amp; failureCases, FPRegisterID fpTemp, bool negZeroCheck = true)
2101     {
<span class="line-removed">2102         ASSERT(isSSE2Present());</span>
2103         m_assembler.cvttsd2si_rr(src, dest);
2104 
2105         // If the result is zero, it might have been -0.0, and the double comparison won&#39;t catch this!
2106 #if CPU(X86_64)
2107         if (negZeroCheck) {
2108             Jump valueIsNonZero = branchTest32(NonZero, dest);
2109             m_assembler.movmskpd_rr(src, scratchRegister());
2110             failureCases.append(branchTest32(NonZero, scratchRegister(), TrustedImm32(1)));
2111             valueIsNonZero.link(this);
2112         }
2113 #else
2114         if (negZeroCheck)
2115             failureCases.append(branchTest32(Zero, dest));
2116 #endif
2117 
2118         // Convert the integer result back to float &amp; compare to the original value - if not equal or unordered (NaN) then jump.
2119         convertInt32ToDouble(dest, fpTemp);
2120         m_assembler.ucomisd_rr(fpTemp, src);
2121         failureCases.append(m_assembler.jp());
2122         failureCases.append(m_assembler.jne());
2123     }
2124 
2125     void moveZeroToDouble(FPRegisterID reg)
2126     {
2127         m_assembler.xorps_rr(reg, reg);
2128     }
2129 
2130     Jump branchDoubleNonZero(FPRegisterID reg, FPRegisterID scratch)
2131     {
<span class="line-removed">2132         ASSERT(isSSE2Present());</span>
2133         m_assembler.xorpd_rr(scratch, scratch);
2134         return branchDouble(DoubleNotEqual, reg, scratch);
2135     }
2136 
2137     Jump branchDoubleZeroOrNaN(FPRegisterID reg, FPRegisterID scratch)
2138     {
<span class="line-removed">2139         ASSERT(isSSE2Present());</span>
2140         m_assembler.xorpd_rr(scratch, scratch);
2141         return branchDouble(DoubleEqualOrUnordered, reg, scratch);
2142     }
2143 
2144     void lshiftPacked(TrustedImm32 imm, XMMRegisterID reg)
2145     {
<span class="line-removed">2146         ASSERT(isSSE2Present());</span>
2147         m_assembler.psllq_i8r(imm.m_value, reg);
2148     }
2149 
2150     void rshiftPacked(TrustedImm32 imm, XMMRegisterID reg)
2151     {
<span class="line-removed">2152         ASSERT(isSSE2Present());</span>
2153         m_assembler.psrlq_i8r(imm.m_value, reg);
2154     }
2155 
2156     void orPacked(XMMRegisterID src, XMMRegisterID dst)
2157     {
<span class="line-removed">2158         ASSERT(isSSE2Present());</span>
2159         m_assembler.por_rr(src, dst);
2160     }
2161 
2162     void move32ToFloat(RegisterID src, XMMRegisterID dst)
2163     {
<span class="line-removed">2164         ASSERT(isSSE2Present());</span>
2165         m_assembler.movd_rr(src, dst);
2166     }
2167 
2168     void moveFloatTo32(XMMRegisterID src, RegisterID dst)
2169     {
<span class="line-removed">2170         ASSERT(isSSE2Present());</span>
2171         m_assembler.movd_rr(src, dst);
2172     }
2173 
2174     // Stack manipulation operations:
2175     //
2176     // The ABI is assumed to provide a stack abstraction to memory,
2177     // containing machine word sized units of data.  Push and pop
2178     // operations add and remove a single register sized unit of data
2179     // to or from the stack.  Peek and poke operations read or write
2180     // values on the stack, without moving the current stack position.
2181 
2182     void pop(RegisterID dest)
2183     {
2184         m_assembler.pop_r(dest);
2185     }
2186 
2187     void push(RegisterID src)
2188     {
2189         m_assembler.push_r(src);
2190     }
</pre>
<hr />
<pre>
2235     }
2236 
2237     void move(TrustedImmPtr imm, RegisterID dest)
2238     {
2239         if (!imm.m_value)
2240             m_assembler.xorq_rr(dest, dest);
2241         else
2242             m_assembler.movq_i64r(imm.asIntptr(), dest);
2243     }
2244 
2245     void move(TrustedImm64 imm, RegisterID dest)
2246     {
2247         if (!imm.m_value)
2248             m_assembler.xorq_rr(dest, dest);
2249         else
2250             m_assembler.movq_i64r(imm.m_value, dest);
2251     }
2252 
2253     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2254     {
<span class="line-removed">2255         ASSERT(isSSE2Present());</span>
<span class="line-removed">2256 </span>
2257         if (cond &amp; DoubleConditionBitInvert)
2258             m_assembler.ucomisd_rr(left, right);
2259         else
2260             m_assembler.ucomisd_rr(right, left);
2261         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2262     }
2263 
2264     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2265     {
<span class="line-removed">2266         ASSERT(isSSE2Present());</span>
<span class="line-removed">2267 </span>
2268         if (thenCase != dest &amp;&amp; elseCase != dest) {
2269             move(elseCase, dest);
2270             elseCase = dest;
2271         }
2272 
2273         RegisterID src;
2274         if (elseCase == dest)
2275             src = thenCase;
2276         else {
2277             cond = invert(cond);
2278             src = elseCase;
2279         }
2280 
2281         if (cond &amp; DoubleConditionBitInvert)
2282             m_assembler.ucomisd_rr(left, right);
2283         else
2284             m_assembler.ucomisd_rr(right, left);
2285         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2286     }
2287 
2288     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2289     {
<span class="line-removed">2290         ASSERT(isSSE2Present());</span>
<span class="line-removed">2291 </span>
2292         if (cond &amp; DoubleConditionBitInvert)
2293             m_assembler.ucomiss_rr(left, right);
2294         else
2295             m_assembler.ucomiss_rr(right, left);
2296         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2297     }
2298 
2299     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2300     {
<span class="line-removed">2301         ASSERT(isSSE2Present());</span>
<span class="line-removed">2302 </span>
2303         if (thenCase != dest &amp;&amp; elseCase != dest) {
2304             move(elseCase, dest);
2305             elseCase = dest;
2306         }
2307 
2308         RegisterID src;
2309         if (elseCase == dest)
2310             src = thenCase;
2311         else {
2312             cond = invert(cond);
2313             src = elseCase;
2314         }
2315 
2316         if (cond &amp; DoubleConditionBitInvert)
2317             m_assembler.ucomiss_rr(left, right);
2318         else
2319             m_assembler.ucomiss_rr(right, left);
2320         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2321     }
2322 
</pre>
<hr />
<pre>
2367         if (src != dest)
2368             m_assembler.movl_rr(src, dest);
2369     }
2370 
2371     void move(TrustedImmPtr imm, RegisterID dest)
2372     {
2373         if (!imm.m_value)
2374             m_assembler.xorl_rr(dest, dest);
2375         else
2376             m_assembler.movl_i32r(imm.asIntptr(), dest);
2377     }
2378 
2379     // Only here for templates!
2380     void move(TrustedImm64, RegisterID)
2381     {
2382         UNREACHABLE_FOR_PLATFORM();
2383     }
2384 
2385     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2386     {
<span class="line-removed">2387         ASSERT(isSSE2Present());</span>
<span class="line-removed">2388 </span>
2389         if (cond &amp; DoubleConditionBitInvert)
2390             m_assembler.ucomisd_rr(left, right);
2391         else
2392             m_assembler.ucomisd_rr(right, left);
2393 
2394         if (cond == DoubleEqual) {
2395             if (left == right) {
2396                 m_assembler.cmovnpl_rr(src, dest);
2397                 return;
2398             }
2399 
2400             Jump isUnordered(m_assembler.jp());
2401             m_assembler.cmovel_rr(src, dest);
2402             isUnordered.link(this);
2403             return;
2404         }
2405 
2406         if (cond == DoubleNotEqualOrUnordered) {
2407             if (left == right) {
2408                 m_assembler.cmovpl_rr(src, dest);
</pre>
<hr />
<pre>
2694         return Jump(m_assembler.jCC(x86Condition(cond)));
2695     }
2696 
2697     Jump branch32(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2698     {
2699         m_assembler.cmpl_im(right.m_value, left.offset, left.base, left.index, left.scale);
2700         return Jump(m_assembler.jCC(x86Condition(cond)));
2701     }
2702 
2703     Jump branch32WithUnalignedHalfWords(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2704     {
2705         return branch32(cond, left, right);
2706     }
2707 
2708     Jump branchTest32(ResultCondition cond, RegisterID reg, RegisterID mask)
2709     {
2710         m_assembler.testl_rr(reg, mask);
2711         return Jump(m_assembler.jCC(x86Condition(cond)));
2712     }
2713 






























2714     void test32(RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2715     {
2716         if (mask.m_value == -1)
2717             m_assembler.testl_rr(reg, reg);
2718         else if (!(mask.m_value &amp; ~0xff) &amp;&amp; reg &lt; X86Registers::esp) { // Using esp and greater as a byte register yields the upper half of the 16 bit registers ax, cx, dx and bx, e.g. esp, register 4, is actually ah.
2719             if (mask.m_value == 0xff)
2720                 m_assembler.testb_rr(reg, reg);
2721             else
2722                 m_assembler.testb_i8r(mask.m_value, reg);
2723         } else
2724             m_assembler.testl_i32r(mask.m_value, reg);
2725     }
2726 
2727     Jump branch(ResultCondition cond)
2728     {
2729         return Jump(m_assembler.jCC(x86Condition(cond)));
2730     }
2731 
2732     Jump branchTest32(ResultCondition cond, RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2733     {
</pre>
<hr />
<pre>
2765         TrustedImm32 mask8(static_cast&lt;int8_t&gt;(mask.m_value));
2766         if (mask8.m_value == -1)
2767             m_assembler.cmpb_im(0, address.offset, address.base, address.index, address.scale);
2768         else
2769             m_assembler.testb_im(mask8.m_value, address.offset, address.base, address.index, address.scale);
2770         return Jump(m_assembler.jCC(x86Condition(cond)));
2771     }
2772 
2773     Jump branch8(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2774     {
2775         TrustedImm32 right8(static_cast&lt;int8_t&gt;(right.m_value));
2776         m_assembler.cmpb_im(right8.m_value, left.offset, left.base, left.index, left.scale);
2777         return Jump(m_assembler.jCC(x86Condition(cond)));
2778     }
2779 
2780     Jump jump()
2781     {
2782         return Jump(m_assembler.jmp());
2783     }
2784 
<span class="line-modified">2785     void jump(RegisterID target, PtrTag)</span>
2786     {
2787         m_assembler.jmp_r(target);
2788     }
2789 
2790     // Address is a memory location containing the address to jump to
<span class="line-modified">2791     void jump(Address address, PtrTag)</span>
2792     {
2793         m_assembler.jmp_m(address.offset, address.base);
2794     }
2795 
2796     // Address is a memory location containing the address to jump to
<span class="line-modified">2797     void jump(BaseIndex address, PtrTag)</span>
2798     {
2799         m_assembler.jmp_m(address.offset, address.base, address.index, address.scale);
2800     }
2801 
<span class="line-modified">2802     ALWAYS_INLINE void jump(RegisterID target, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(target, NoPtrTag); }</span>
<span class="line-modified">2803     ALWAYS_INLINE void jump(Address address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(address, NoPtrTag); }</span>
<span class="line-modified">2804     ALWAYS_INLINE void jump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(address, NoPtrTag); }</span>
2805 
2806     // Arithmetic control flow operations:
2807     //
2808     // This set of conditional branch operations branch based
2809     // on the result of an arithmetic operation.  The operation
2810     // is performed as normal, storing the result.
2811     //
2812     // * jz operations branch if the result is zero.
2813     // * jo operations branch if the (signed) arithmetic
2814     //   operation caused an overflow to occur.
2815 
2816     Jump branchAdd32(ResultCondition cond, RegisterID src, RegisterID dest)
2817     {
2818         add32(src, dest);
2819         return Jump(m_assembler.jCC(x86Condition(cond)));
2820     }
2821 
2822     Jump branchAdd32(ResultCondition cond, TrustedImm32 imm, RegisterID dest)
2823     {
2824         add32(imm, dest);
</pre>
<hr />
<pre>
4245             Jump isUnordered(m_assembler.jp());
4246             m_assembler.cmoveq_rr(src, dest);
4247             isUnordered.link(this);
4248             return;
4249         }
4250 
4251         if (cond == DoubleNotEqualOrUnordered) {
4252             if (left == right) {
4253                 m_assembler.cmovpq_rr(src, dest);
4254                 return;
4255             }
4256 
4257             m_assembler.cmovpq_rr(src, dest);
4258             m_assembler.cmovneq_rr(src, dest);
4259             return;
4260         }
4261 
4262         ASSERT(!(cond &amp; DoubleConditionBitSpecial));
4263         cmov(static_cast&lt;X86Assembler::Condition&gt;(cond &amp; ~DoubleConditionBits), src, dest);
4264     }
<span class="line-removed">4265 #endif</span>
<span class="line-removed">4266 #if !defined(NDEBUG) // CPU(X86)</span>
<span class="line-removed">4267 </span>
<span class="line-removed">4268     // On x86-64 we should never be checking for SSE2 in a non-debug build,</span>
<span class="line-removed">4269     // but non debug add this method to keep the asserts above happy.</span>
<span class="line-removed">4270     static bool isSSE2Present()</span>
<span class="line-removed">4271     {</span>
<span class="line-removed">4272         return true;</span>
<span class="line-removed">4273     }</span>
<span class="line-removed">4274 </span>
4275 #endif
4276 
4277     using CPUID = std::array&lt;unsigned, 4&gt;;
4278     static CPUID getCPUID(unsigned level);
4279     static CPUID getCPUIDEx(unsigned level, unsigned count);
4280     JS_EXPORT_PRIVATE static void collectCPUFeatures();
4281 
4282     JS_EXPORT_PRIVATE static CPUIDCheckState s_sse4_1CheckState;
4283     JS_EXPORT_PRIVATE static CPUIDCheckState s_sse4_2CheckState;
4284     JS_EXPORT_PRIVATE static CPUIDCheckState s_avxCheckState;
4285     JS_EXPORT_PRIVATE static CPUIDCheckState s_lzcntCheckState;
4286     JS_EXPORT_PRIVATE static CPUIDCheckState s_bmi1CheckState;
4287     JS_EXPORT_PRIVATE static CPUIDCheckState s_popcntCheckState;
4288 };
4289 
4290 } // namespace JSC
4291 
4292 #endif // ENABLE(ASSEMBLER)
</pre>
</td>
<td>
<hr />
<pre>
1434         m_assembler.movw_rm(src, address.offset, address.base, address.index, address.scale);
1435     }
1436 
1437     void store16(RegisterID src, Address address)
1438     {
1439         m_assembler.movw_rm(src, address.offset, address.base);
1440     }
1441 
1442     void store16(TrustedImm32 imm, BaseIndex address)
1443     {
1444         m_assembler.movw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
1445     }
1446 
1447     void store16(TrustedImm32 imm, ImplicitAddress address)
1448     {
1449         m_assembler.movw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base);
1450     }
1451 
1452     // Floating-point operation:
1453     //


1454     void moveDouble(FPRegisterID src, FPRegisterID dest)
1455     {

1456         if (src != dest)
1457             m_assembler.movaps_rr(src, dest);
1458     }
1459 
1460     void loadDouble(TrustedImmPtr address, FPRegisterID dest)
1461     {
1462 #if CPU(X86)

1463         m_assembler.movsd_mr(address.asPtr(), dest);
1464 #else
1465         move(address, scratchRegister());
1466         loadDouble(scratchRegister(), dest);
1467 #endif
1468     }
1469 
1470     void loadDouble(ImplicitAddress address, FPRegisterID dest)
1471     {

1472         m_assembler.movsd_mr(address.offset, address.base, dest);
1473     }
1474 
1475     void loadDouble(BaseIndex address, FPRegisterID dest)
1476     {

1477         m_assembler.movsd_mr(address.offset, address.base, address.index, address.scale, dest);
1478     }
1479 
1480     void loadFloat(TrustedImmPtr address, FPRegisterID dest)
1481     {
1482 #if CPU(X86)

1483         m_assembler.movss_mr(address.asPtr(), dest);
1484 #else
1485         move(address, scratchRegister());
1486         loadFloat(scratchRegister(), dest);
1487 #endif
1488     }
1489 
1490     void loadFloat(ImplicitAddress address, FPRegisterID dest)
1491     {

1492         m_assembler.movss_mr(address.offset, address.base, dest);
1493     }
1494 
1495     void loadFloat(BaseIndex address, FPRegisterID dest)
1496     {

1497         m_assembler.movss_mr(address.offset, address.base, address.index, address.scale, dest);
1498     }
1499 
1500     void storeDouble(FPRegisterID src, ImplicitAddress address)
1501     {

1502         m_assembler.movsd_rm(src, address.offset, address.base);
1503     }
1504 
1505     void storeDouble(FPRegisterID src, BaseIndex address)
1506     {

1507         m_assembler.movsd_rm(src, address.offset, address.base, address.index, address.scale);
1508     }
1509 
1510     void storeFloat(FPRegisterID src, ImplicitAddress address)
1511     {

1512         m_assembler.movss_rm(src, address.offset, address.base);
1513     }
1514 
1515     void storeFloat(FPRegisterID src, BaseIndex address)
1516     {

1517         m_assembler.movss_rm(src, address.offset, address.base, address.index, address.scale);
1518     }
1519 
1520     void convertDoubleToFloat(FPRegisterID src, FPRegisterID dst)
1521     {

1522         m_assembler.cvtsd2ss_rr(src, dst);
1523     }
1524 
1525     void convertDoubleToFloat(Address address, FPRegisterID dst)
1526     {

1527         m_assembler.cvtsd2ss_mr(address.offset, address.base, dst);
1528     }
1529 
1530     void convertFloatToDouble(FPRegisterID src, FPRegisterID dst)
1531     {

1532         m_assembler.cvtss2sd_rr(src, dst);
1533     }
1534 
1535     void convertFloatToDouble(Address address, FPRegisterID dst)
1536     {

1537         m_assembler.cvtss2sd_mr(address.offset, address.base, dst);
1538     }
1539 
1540     void addDouble(FPRegisterID src, FPRegisterID dest)
1541     {
1542         addDouble(src, dest, dest);
1543     }
1544 
1545     void addDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1546     {
1547         if (supportsAVX())
1548             m_assembler.vaddsd_rr(op1, op2, dest);
1549         else {

1550             if (op1 == dest)
1551                 m_assembler.addsd_rr(op2, dest);
1552             else {
1553                 moveDouble(op2, dest);
1554                 m_assembler.addsd_rr(op1, dest);
1555             }
1556         }
1557     }
1558 
1559     void addDouble(Address src, FPRegisterID dest)
1560     {
1561         addDouble(src, dest, dest);
1562     }
1563 
1564     void addDouble(Address op1, FPRegisterID op2, FPRegisterID dest)
1565     {
1566         if (supportsAVX())
1567             m_assembler.vaddsd_mr(op1.offset, op1.base, op2, dest);
1568         else {

1569             if (op2 == dest) {
1570                 m_assembler.addsd_mr(op1.offset, op1.base, dest);
1571                 return;
1572             }
1573 
1574             loadDouble(op1, dest);
1575             addDouble(op2, dest);
1576         }
1577     }
1578 
1579     void addDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1580     {
1581         addDouble(op2, op1, dest);
1582     }
1583 
1584     void addDouble(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1585     {
1586         if (supportsAVX())
1587             m_assembler.vaddsd_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1588         else {

1589             if (op2 == dest) {
1590                 m_assembler.addsd_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1591                 return;
1592             }
1593             loadDouble(op1, dest);
1594             addDouble(op2, dest);
1595         }
1596     }
1597 
1598     void addFloat(FPRegisterID src, FPRegisterID dest)
1599     {
1600         addFloat(src, dest, dest);
1601     }
1602 
1603     void addFloat(Address src, FPRegisterID dest)
1604     {
1605         addFloat(src, dest, dest);
1606     }
1607 
1608     void addFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1609     {
1610         if (supportsAVX())
1611             m_assembler.vaddss_rr(op1, op2, dest);
1612         else {

1613             if (op1 == dest)
1614                 m_assembler.addss_rr(op2, dest);
1615             else {
1616                 moveDouble(op2, dest);
1617                 m_assembler.addss_rr(op1, dest);
1618             }
1619         }
1620     }
1621 
1622     void addFloat(Address op1, FPRegisterID op2, FPRegisterID dest)
1623     {
1624         if (supportsAVX())
1625             m_assembler.vaddss_mr(op1.offset, op1.base, op2, dest);
1626         else {

1627             if (op2 == dest) {
1628                 m_assembler.addss_mr(op1.offset, op1.base, dest);
1629                 return;
1630             }
1631 
1632             loadFloat(op1, dest);
1633             addFloat(op2, dest);
1634         }
1635     }
1636 
1637     void addFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1638     {
1639         addFloat(op2, op1, dest);
1640     }
1641 
1642     void addFloat(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1643     {
1644         if (supportsAVX())
1645             m_assembler.vaddss_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1646         else {

1647             if (op2 == dest) {
1648                 m_assembler.addss_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1649                 return;
1650             }
1651             loadFloat(op1, dest);
1652             addFloat(op2, dest);
1653         }
1654     }
1655 
1656     void divDouble(FPRegisterID src, FPRegisterID dest)
1657     {

1658         m_assembler.divsd_rr(src, dest);
1659     }
1660 
1661     void divDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1662     {
1663         // B := A / B is invalid.
1664         ASSERT(op1 == dest || op2 != dest);
1665 
1666         moveDouble(op1, dest);
1667         divDouble(op2, dest);
1668     }
1669 
1670     void divDouble(Address src, FPRegisterID dest)
1671     {

1672         m_assembler.divsd_mr(src.offset, src.base, dest);
1673     }
1674 
1675     void divFloat(FPRegisterID src, FPRegisterID dest)
1676     {

1677         m_assembler.divss_rr(src, dest);
1678     }
1679 
1680     void divFloat(Address src, FPRegisterID dest)
1681     {

1682         m_assembler.divss_mr(src.offset, src.base, dest);
1683     }
1684 
1685     void subDouble(FPRegisterID src, FPRegisterID dest)
1686     {
1687         subDouble(dest, src, dest);
1688     }
1689 
1690     void subDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1691     {
1692         if (supportsAVX())
1693             m_assembler.vsubsd_rr(op1, op2, dest);
1694         else {


1695             // B := A - B is invalid.
1696             ASSERT(op1 == dest || op2 != dest);
1697             moveDouble(op1, dest);
1698             m_assembler.subsd_rr(op2, dest);
1699         }
1700     }
1701 
1702     void subDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1703     {
1704         if (supportsAVX())
1705             m_assembler.vsubsd_mr(op1, op2.offset, op2.base, dest);
1706         else {
1707             moveDouble(op1, dest);
1708             m_assembler.subsd_mr(op2.offset, op2.base, dest);
1709         }
1710     }
1711 
1712     void subDouble(FPRegisterID op1, BaseIndex op2, FPRegisterID dest)
1713     {
1714         if (supportsAVX())
</pre>
<hr />
<pre>
1717             moveDouble(op1, dest);
1718             m_assembler.subsd_mr(op2.offset, op2.base, op2.index, op2.scale, dest);
1719         }
1720     }
1721 
1722     void subDouble(Address src, FPRegisterID dest)
1723     {
1724         subDouble(dest, src, dest);
1725     }
1726 
1727     void subFloat(FPRegisterID src, FPRegisterID dest)
1728     {
1729         subFloat(dest, src, dest);
1730     }
1731 
1732     void subFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1733     {
1734         if (supportsAVX())
1735             m_assembler.vsubss_rr(op1, op2, dest);
1736         else {

1737             // B := A - B is invalid.
1738             ASSERT(op1 == dest || op2 != dest);
1739             moveDouble(op1, dest);
1740             m_assembler.subss_rr(op2, dest);
1741         }
1742     }
1743 
1744     void subFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1745     {
1746         if (supportsAVX())
1747             m_assembler.vsubss_mr(op1, op2.offset, op2.base, dest);
1748         else {
1749             moveDouble(op1, dest);
1750             m_assembler.subss_mr(op2.offset, op2.base, dest);
1751         }
1752     }
1753 
1754     void subFloat(FPRegisterID op1, BaseIndex op2, FPRegisterID dest)
1755     {
1756         if (supportsAVX())
</pre>
<hr />
<pre>
1759             moveDouble(op1, dest);
1760             m_assembler.subss_mr(op2.offset, op2.base, op2.index, op2.scale, dest);
1761         }
1762     }
1763 
1764     void subFloat(Address src, FPRegisterID dest)
1765     {
1766         subFloat(dest, src, dest);
1767     }
1768 
1769     void mulDouble(FPRegisterID src, FPRegisterID dest)
1770     {
1771         mulDouble(src, dest, dest);
1772     }
1773 
1774     void mulDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1775     {
1776         if (supportsAVX())
1777             m_assembler.vmulsd_rr(op1, op2, dest);
1778         else {

1779             if (op1 == dest)
1780                 m_assembler.mulsd_rr(op2, dest);
1781             else {
1782                 moveDouble(op2, dest);
1783                 m_assembler.mulsd_rr(op1, dest);
1784             }
1785         }
1786     }
1787 
1788     void mulDouble(Address src, FPRegisterID dest)
1789     {
1790         mulDouble(src, dest, dest);
1791     }
1792 
1793     void mulDouble(Address op1, FPRegisterID op2, FPRegisterID dest)
1794     {
1795         if (supportsAVX())
1796             m_assembler.vmulsd_mr(op1.offset, op1.base, op2, dest);
1797         else {

1798             if (op2 == dest) {
1799                 m_assembler.mulsd_mr(op1.offset, op1.base, dest);
1800                 return;
1801             }
1802             loadDouble(op1, dest);
1803             mulDouble(op2, dest);
1804         }
1805     }
1806 
1807     void mulDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1808     {
1809         return mulDouble(op2, op1, dest);
1810     }
1811 
1812     void mulDouble(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1813     {
1814         if (supportsAVX())
1815             m_assembler.vmulsd_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1816         else {

1817             if (op2 == dest) {
1818                 m_assembler.mulsd_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1819                 return;
1820             }
1821             loadDouble(op1, dest);
1822             mulDouble(op2, dest);
1823         }
1824     }
1825 
1826     void mulFloat(FPRegisterID src, FPRegisterID dest)
1827     {
1828         mulFloat(src, dest, dest);
1829     }
1830 
1831     void mulFloat(Address src, FPRegisterID dest)
1832     {
1833         mulFloat(src, dest, dest);
1834     }
1835 
1836     void mulFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1837     {
1838         if (supportsAVX())
1839             m_assembler.vmulss_rr(op1, op2, dest);
1840         else {

1841             if (op1 == dest)
1842                 m_assembler.mulss_rr(op2, dest);
1843             else {
1844                 moveDouble(op2, dest);
1845                 m_assembler.mulss_rr(op1, dest);
1846             }
1847         }
1848     }
1849 
1850     void mulFloat(Address op1, FPRegisterID op2, FPRegisterID dest)
1851     {
1852         if (supportsAVX())
1853             m_assembler.vmulss_mr(op1.offset, op1.base, op2, dest);
1854         else {

1855             if (op2 == dest) {
1856                 m_assembler.mulss_mr(op1.offset, op1.base, dest);
1857                 return;
1858             }
1859             loadFloat(op1, dest);
1860             mulFloat(op2, dest);
1861         }
1862     }
1863 
1864     void mulFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1865     {
1866         mulFloat(op2, op1, dest);
1867     }
1868 
1869     void mulFloat(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1870     {
1871         if (supportsAVX())
1872             m_assembler.vmulss_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1873         else {

1874             if (op2 == dest) {
1875                 m_assembler.mulss_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1876                 return;
1877             }
1878             loadFloat(op1, dest);
1879             mulFloat(op2, dest);
1880         }
1881     }
1882 
1883     void andDouble(FPRegisterID src, FPRegisterID dst)
1884     {
1885         // ANDPS is defined on 128bits and is shorter than ANDPD.
1886         m_assembler.andps_rr(src, dst);
1887     }
1888 
1889     void andDouble(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
1890     {
1891         if (src1 == dst)
1892             andDouble(src2, dst);
1893         else {
</pre>
<hr />
<pre>
1956         }
1957     }
1958 
1959     void xorFloat(FPRegisterID src, FPRegisterID dst)
1960     {
1961         m_assembler.xorps_rr(src, dst);
1962     }
1963 
1964     void xorFloat(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
1965     {
1966         if (src1 == dst)
1967             xorFloat(src2, dst);
1968         else {
1969             moveDouble(src2, dst);
1970             xorFloat(src1, dst);
1971         }
1972     }
1973 
1974     void convertInt32ToDouble(RegisterID src, FPRegisterID dest)
1975     {

1976         m_assembler.cvtsi2sd_rr(src, dest);
1977     }
1978 
1979     void convertInt32ToDouble(Address src, FPRegisterID dest)
1980     {

1981         m_assembler.cvtsi2sd_mr(src.offset, src.base, dest);
1982     }
1983 
1984     void convertInt32ToFloat(RegisterID src, FPRegisterID dest)
1985     {

1986         m_assembler.cvtsi2ss_rr(src, dest);
1987     }
1988 
1989     void convertInt32ToFloat(Address src, FPRegisterID dest)
1990     {

1991         m_assembler.cvtsi2ss_mr(src.offset, src.base, dest);
1992     }
1993 
1994     Jump branchDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
1995     {


1996         if (cond &amp; DoubleConditionBitInvert)
1997             m_assembler.ucomisd_rr(left, right);
1998         else
1999             m_assembler.ucomisd_rr(right, left);
2000         return jumpAfterFloatingPointCompare(cond, left, right);
2001     }
2002 
2003     Jump branchFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
2004     {


2005         if (cond &amp; DoubleConditionBitInvert)
2006             m_assembler.ucomiss_rr(left, right);
2007         else
2008             m_assembler.ucomiss_rr(right, left);
2009         return jumpAfterFloatingPointCompare(cond, left, right);
2010     }
2011 
2012     void compareDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
2013     {

2014         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
2015             m_assembler.ucomisd_rr(arg1, arg2);
2016         });
2017     }
2018 
2019     void compareFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
2020     {

2021         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
2022             m_assembler.ucomiss_rr(arg1, arg2);
2023         });
2024     }
2025 
2026     // Truncates &#39;src&#39; to an integer, and places the resulting &#39;dest&#39;.
2027     // If the result is not representable as a 32 bit value, branch.
2028     // May also branch for some values that are representable in 32 bits
2029     // (specifically, in this case, INT_MIN).
2030     enum BranchTruncateType { BranchIfTruncateFailed, BranchIfTruncateSuccessful };
2031     Jump branchTruncateDoubleToInt32(FPRegisterID src, RegisterID dest, BranchTruncateType branchType = BranchIfTruncateFailed)
2032     {

2033         m_assembler.cvttsd2si_rr(src, dest);
2034         return branch32(branchType ? NotEqual : Equal, dest, TrustedImm32(0x80000000));
2035     }
2036 
2037     void truncateDoubleToInt32(FPRegisterID src, RegisterID dest)
2038     {

2039         m_assembler.cvttsd2si_rr(src, dest);
2040     }
2041 
2042     void truncateFloatToInt32(FPRegisterID src, RegisterID dest)
2043     {

2044         m_assembler.cvttss2si_rr(src, dest);
2045     }
2046 
2047     // Convert &#39;src&#39; to an integer, and places the resulting &#39;dest&#39;.
2048     // If the result is not representable as a 32 bit value, branch.
2049     // May also branch for some values that are representable in 32 bits
2050     // (specifically, in this case, 0).
2051     void branchConvertDoubleToInt32(FPRegisterID src, RegisterID dest, JumpList&amp; failureCases, FPRegisterID fpTemp, bool negZeroCheck = true)
2052     {

2053         m_assembler.cvttsd2si_rr(src, dest);
2054 
2055         // If the result is zero, it might have been -0.0, and the double comparison won&#39;t catch this!
2056 #if CPU(X86_64)
2057         if (negZeroCheck) {
2058             Jump valueIsNonZero = branchTest32(NonZero, dest);
2059             m_assembler.movmskpd_rr(src, scratchRegister());
2060             failureCases.append(branchTest32(NonZero, scratchRegister(), TrustedImm32(1)));
2061             valueIsNonZero.link(this);
2062         }
2063 #else
2064         if (negZeroCheck)
2065             failureCases.append(branchTest32(Zero, dest));
2066 #endif
2067 
2068         // Convert the integer result back to float &amp; compare to the original value - if not equal or unordered (NaN) then jump.
2069         convertInt32ToDouble(dest, fpTemp);
2070         m_assembler.ucomisd_rr(fpTemp, src);
2071         failureCases.append(m_assembler.jp());
2072         failureCases.append(m_assembler.jne());
2073     }
2074 
2075     void moveZeroToDouble(FPRegisterID reg)
2076     {
2077         m_assembler.xorps_rr(reg, reg);
2078     }
2079 
2080     Jump branchDoubleNonZero(FPRegisterID reg, FPRegisterID scratch)
2081     {

2082         m_assembler.xorpd_rr(scratch, scratch);
2083         return branchDouble(DoubleNotEqual, reg, scratch);
2084     }
2085 
2086     Jump branchDoubleZeroOrNaN(FPRegisterID reg, FPRegisterID scratch)
2087     {

2088         m_assembler.xorpd_rr(scratch, scratch);
2089         return branchDouble(DoubleEqualOrUnordered, reg, scratch);
2090     }
2091 
2092     void lshiftPacked(TrustedImm32 imm, XMMRegisterID reg)
2093     {

2094         m_assembler.psllq_i8r(imm.m_value, reg);
2095     }
2096 
2097     void rshiftPacked(TrustedImm32 imm, XMMRegisterID reg)
2098     {

2099         m_assembler.psrlq_i8r(imm.m_value, reg);
2100     }
2101 
2102     void orPacked(XMMRegisterID src, XMMRegisterID dst)
2103     {

2104         m_assembler.por_rr(src, dst);
2105     }
2106 
2107     void move32ToFloat(RegisterID src, XMMRegisterID dst)
2108     {

2109         m_assembler.movd_rr(src, dst);
2110     }
2111 
2112     void moveFloatTo32(XMMRegisterID src, RegisterID dst)
2113     {

2114         m_assembler.movd_rr(src, dst);
2115     }
2116 
2117     // Stack manipulation operations:
2118     //
2119     // The ABI is assumed to provide a stack abstraction to memory,
2120     // containing machine word sized units of data.  Push and pop
2121     // operations add and remove a single register sized unit of data
2122     // to or from the stack.  Peek and poke operations read or write
2123     // values on the stack, without moving the current stack position.
2124 
2125     void pop(RegisterID dest)
2126     {
2127         m_assembler.pop_r(dest);
2128     }
2129 
2130     void push(RegisterID src)
2131     {
2132         m_assembler.push_r(src);
2133     }
</pre>
<hr />
<pre>
2178     }
2179 
2180     void move(TrustedImmPtr imm, RegisterID dest)
2181     {
2182         if (!imm.m_value)
2183             m_assembler.xorq_rr(dest, dest);
2184         else
2185             m_assembler.movq_i64r(imm.asIntptr(), dest);
2186     }
2187 
2188     void move(TrustedImm64 imm, RegisterID dest)
2189     {
2190         if (!imm.m_value)
2191             m_assembler.xorq_rr(dest, dest);
2192         else
2193             m_assembler.movq_i64r(imm.m_value, dest);
2194     }
2195 
2196     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2197     {


2198         if (cond &amp; DoubleConditionBitInvert)
2199             m_assembler.ucomisd_rr(left, right);
2200         else
2201             m_assembler.ucomisd_rr(right, left);
2202         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2203     }
2204 
2205     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2206     {


2207         if (thenCase != dest &amp;&amp; elseCase != dest) {
2208             move(elseCase, dest);
2209             elseCase = dest;
2210         }
2211 
2212         RegisterID src;
2213         if (elseCase == dest)
2214             src = thenCase;
2215         else {
2216             cond = invert(cond);
2217             src = elseCase;
2218         }
2219 
2220         if (cond &amp; DoubleConditionBitInvert)
2221             m_assembler.ucomisd_rr(left, right);
2222         else
2223             m_assembler.ucomisd_rr(right, left);
2224         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2225     }
2226 
2227     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2228     {


2229         if (cond &amp; DoubleConditionBitInvert)
2230             m_assembler.ucomiss_rr(left, right);
2231         else
2232             m_assembler.ucomiss_rr(right, left);
2233         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2234     }
2235 
2236     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2237     {


2238         if (thenCase != dest &amp;&amp; elseCase != dest) {
2239             move(elseCase, dest);
2240             elseCase = dest;
2241         }
2242 
2243         RegisterID src;
2244         if (elseCase == dest)
2245             src = thenCase;
2246         else {
2247             cond = invert(cond);
2248             src = elseCase;
2249         }
2250 
2251         if (cond &amp; DoubleConditionBitInvert)
2252             m_assembler.ucomiss_rr(left, right);
2253         else
2254             m_assembler.ucomiss_rr(right, left);
2255         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2256     }
2257 
</pre>
<hr />
<pre>
2302         if (src != dest)
2303             m_assembler.movl_rr(src, dest);
2304     }
2305 
2306     void move(TrustedImmPtr imm, RegisterID dest)
2307     {
2308         if (!imm.m_value)
2309             m_assembler.xorl_rr(dest, dest);
2310         else
2311             m_assembler.movl_i32r(imm.asIntptr(), dest);
2312     }
2313 
2314     // Only here for templates!
2315     void move(TrustedImm64, RegisterID)
2316     {
2317         UNREACHABLE_FOR_PLATFORM();
2318     }
2319 
2320     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2321     {


2322         if (cond &amp; DoubleConditionBitInvert)
2323             m_assembler.ucomisd_rr(left, right);
2324         else
2325             m_assembler.ucomisd_rr(right, left);
2326 
2327         if (cond == DoubleEqual) {
2328             if (left == right) {
2329                 m_assembler.cmovnpl_rr(src, dest);
2330                 return;
2331             }
2332 
2333             Jump isUnordered(m_assembler.jp());
2334             m_assembler.cmovel_rr(src, dest);
2335             isUnordered.link(this);
2336             return;
2337         }
2338 
2339         if (cond == DoubleNotEqualOrUnordered) {
2340             if (left == right) {
2341                 m_assembler.cmovpl_rr(src, dest);
</pre>
<hr />
<pre>
2627         return Jump(m_assembler.jCC(x86Condition(cond)));
2628     }
2629 
2630     Jump branch32(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2631     {
2632         m_assembler.cmpl_im(right.m_value, left.offset, left.base, left.index, left.scale);
2633         return Jump(m_assembler.jCC(x86Condition(cond)));
2634     }
2635 
2636     Jump branch32WithUnalignedHalfWords(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2637     {
2638         return branch32(cond, left, right);
2639     }
2640 
2641     Jump branchTest32(ResultCondition cond, RegisterID reg, RegisterID mask)
2642     {
2643         m_assembler.testl_rr(reg, mask);
2644         return Jump(m_assembler.jCC(x86Condition(cond)));
2645     }
2646 
<span class="line-added">2647     Jump branchTestBit32(ResultCondition cond, RegisterID reg, TrustedImm32 bit)</span>
<span class="line-added">2648     {</span>
<span class="line-added">2649         m_assembler.bt_ir(static_cast&lt;unsigned&gt;(bit.m_value) % 32, reg);</span>
<span class="line-added">2650         if (cond == NonZero)</span>
<span class="line-added">2651             return Jump(m_assembler.jb());</span>
<span class="line-added">2652         if (cond == Zero)</span>
<span class="line-added">2653             return Jump(m_assembler.jae());</span>
<span class="line-added">2654         RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">2655     }</span>
<span class="line-added">2656 </span>
<span class="line-added">2657     Jump branchTestBit32(ResultCondition cond, Address testValue, TrustedImm32 bit)</span>
<span class="line-added">2658     {</span>
<span class="line-added">2659         m_assembler.bt_im(static_cast&lt;unsigned&gt;(bit.m_value) % 32, testValue.offset, testValue.base);</span>
<span class="line-added">2660         if (cond == NonZero)</span>
<span class="line-added">2661             return Jump(m_assembler.jb());</span>
<span class="line-added">2662         if (cond == Zero)</span>
<span class="line-added">2663             return Jump(m_assembler.jae());</span>
<span class="line-added">2664         RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">2665     }</span>
<span class="line-added">2666 </span>
<span class="line-added">2667     Jump branchTestBit32(ResultCondition cond, RegisterID reg, RegisterID bit)</span>
<span class="line-added">2668     {</span>
<span class="line-added">2669         m_assembler.bt_ir(bit, reg);</span>
<span class="line-added">2670         if (cond == NonZero)</span>
<span class="line-added">2671             return Jump(m_assembler.jb());</span>
<span class="line-added">2672         if (cond == Zero)</span>
<span class="line-added">2673             return Jump(m_assembler.jae());</span>
<span class="line-added">2674         RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">2675     }</span>
<span class="line-added">2676 </span>
2677     void test32(RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2678     {
2679         if (mask.m_value == -1)
2680             m_assembler.testl_rr(reg, reg);
2681         else if (!(mask.m_value &amp; ~0xff) &amp;&amp; reg &lt; X86Registers::esp) { // Using esp and greater as a byte register yields the upper half of the 16 bit registers ax, cx, dx and bx, e.g. esp, register 4, is actually ah.
2682             if (mask.m_value == 0xff)
2683                 m_assembler.testb_rr(reg, reg);
2684             else
2685                 m_assembler.testb_i8r(mask.m_value, reg);
2686         } else
2687             m_assembler.testl_i32r(mask.m_value, reg);
2688     }
2689 
2690     Jump branch(ResultCondition cond)
2691     {
2692         return Jump(m_assembler.jCC(x86Condition(cond)));
2693     }
2694 
2695     Jump branchTest32(ResultCondition cond, RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2696     {
</pre>
<hr />
<pre>
2728         TrustedImm32 mask8(static_cast&lt;int8_t&gt;(mask.m_value));
2729         if (mask8.m_value == -1)
2730             m_assembler.cmpb_im(0, address.offset, address.base, address.index, address.scale);
2731         else
2732             m_assembler.testb_im(mask8.m_value, address.offset, address.base, address.index, address.scale);
2733         return Jump(m_assembler.jCC(x86Condition(cond)));
2734     }
2735 
2736     Jump branch8(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2737     {
2738         TrustedImm32 right8(static_cast&lt;int8_t&gt;(right.m_value));
2739         m_assembler.cmpb_im(right8.m_value, left.offset, left.base, left.index, left.scale);
2740         return Jump(m_assembler.jCC(x86Condition(cond)));
2741     }
2742 
2743     Jump jump()
2744     {
2745         return Jump(m_assembler.jmp());
2746     }
2747 
<span class="line-modified">2748     void farJump(RegisterID target, PtrTag)</span>
2749     {
2750         m_assembler.jmp_r(target);
2751     }
2752 
2753     // Address is a memory location containing the address to jump to
<span class="line-modified">2754     void farJump(Address address, PtrTag)</span>
2755     {
2756         m_assembler.jmp_m(address.offset, address.base);
2757     }
2758 
2759     // Address is a memory location containing the address to jump to
<span class="line-modified">2760     void farJump(BaseIndex address, PtrTag)</span>
2761     {
2762         m_assembler.jmp_m(address.offset, address.base, address.index, address.scale);
2763     }
2764 
<span class="line-modified">2765     ALWAYS_INLINE void farJump(RegisterID target, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(target, NoPtrTag); }</span>
<span class="line-modified">2766     ALWAYS_INLINE void farJump(Address address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }</span>
<span class="line-modified">2767     ALWAYS_INLINE void farJump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }</span>
2768 
2769     // Arithmetic control flow operations:
2770     //
2771     // This set of conditional branch operations branch based
2772     // on the result of an arithmetic operation.  The operation
2773     // is performed as normal, storing the result.
2774     //
2775     // * jz operations branch if the result is zero.
2776     // * jo operations branch if the (signed) arithmetic
2777     //   operation caused an overflow to occur.
2778 
2779     Jump branchAdd32(ResultCondition cond, RegisterID src, RegisterID dest)
2780     {
2781         add32(src, dest);
2782         return Jump(m_assembler.jCC(x86Condition(cond)));
2783     }
2784 
2785     Jump branchAdd32(ResultCondition cond, TrustedImm32 imm, RegisterID dest)
2786     {
2787         add32(imm, dest);
</pre>
<hr />
<pre>
4208             Jump isUnordered(m_assembler.jp());
4209             m_assembler.cmoveq_rr(src, dest);
4210             isUnordered.link(this);
4211             return;
4212         }
4213 
4214         if (cond == DoubleNotEqualOrUnordered) {
4215             if (left == right) {
4216                 m_assembler.cmovpq_rr(src, dest);
4217                 return;
4218             }
4219 
4220             m_assembler.cmovpq_rr(src, dest);
4221             m_assembler.cmovneq_rr(src, dest);
4222             return;
4223         }
4224 
4225         ASSERT(!(cond &amp; DoubleConditionBitSpecial));
4226         cmov(static_cast&lt;X86Assembler::Condition&gt;(cond &amp; ~DoubleConditionBits), src, dest);
4227     }










4228 #endif
4229 
4230     using CPUID = std::array&lt;unsigned, 4&gt;;
4231     static CPUID getCPUID(unsigned level);
4232     static CPUID getCPUIDEx(unsigned level, unsigned count);
4233     JS_EXPORT_PRIVATE static void collectCPUFeatures();
4234 
4235     JS_EXPORT_PRIVATE static CPUIDCheckState s_sse4_1CheckState;
4236     JS_EXPORT_PRIVATE static CPUIDCheckState s_sse4_2CheckState;
4237     JS_EXPORT_PRIVATE static CPUIDCheckState s_avxCheckState;
4238     JS_EXPORT_PRIVATE static CPUIDCheckState s_lzcntCheckState;
4239     JS_EXPORT_PRIVATE static CPUIDCheckState s_bmi1CheckState;
4240     JS_EXPORT_PRIVATE static CPUIDCheckState s_popcntCheckState;
4241 };
4242 
4243 } // namespace JSC
4244 
4245 #endif // ENABLE(ASSEMBLER)
</pre>
</td>
</tr>
</table>
<center><a href="MacroAssemblerX86.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="MacroAssemblerX86_64.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>