<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="LowLevelInterpreter.asm.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter32_64.asm.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
232     t1 = t1Result;
233 }
234 
235 } // namespace LLint
236 
237 //============================================================================
238 // The llint C++ interpreter loop:
239 //
240 
241 JSValue CLoop::execute(OpcodeID entryOpcodeID, void* executableAddress, VM* vm, ProtoCallFrame* protoCallFrame, bool isInitializationPass)
242 {
243 #define CAST bitwise_cast
244 
245     // One-time initialization of our address tables. We have to put this code
246     // here because our labels are only in scope inside this function. The
247     // caller (or one of its ancestors) is responsible for ensuring that this
248     // is only called once during the initialization of the VM before threads
249     // are at play.
250     if (UNLIKELY(isInitializationPass)) {
251         Opcode* opcodeMap = LLInt::opcodeMap();
<span class="line-modified">252         Opcode* opcodeMapWide = LLInt::opcodeMapWide();</span>

253 
254 #if ENABLE(COMPUTED_GOTO_OPCODES)
255         #define OPCODE_ENTRY(__opcode, length) \
256             opcodeMap[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode); \
<span class="line-modified">257             opcodeMapWide[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode##_wide);</span>

258 
259         #define LLINT_OPCODE_ENTRY(__opcode, length) \
260             opcodeMap[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode);
261 #else
262         // FIXME: this mapping is unnecessarily expensive in the absence of COMPUTED_GOTO
263         //   narrow opcodes don&#39;t need any mapping and wide opcodes just need to add numOpcodeIDs
264         #define OPCODE_ENTRY(__opcode, length) \
265             opcodeMap[__opcode] = __opcode; \
<span class="line-modified">266             opcodeMapWide[__opcode] = static_cast&lt;OpcodeID&gt;(__opcode##_wide);</span>

267 
268         #define LLINT_OPCODE_ENTRY(__opcode, length) \
269             opcodeMap[__opcode] = __opcode;
270 #endif
271         FOR_EACH_BYTECODE_ID(OPCODE_ENTRY)
272         FOR_EACH_CLOOP_BYTECODE_HELPER_ID(LLINT_OPCODE_ENTRY)
273         FOR_EACH_LLINT_NATIVE_HELPER(LLINT_OPCODE_ENTRY)
274         #undef OPCODE_ENTRY
275         #undef LLINT_OPCODE_ENTRY
276 
277         // Note: we can only set the exceptionInstructions after we have
278         // initialized the opcodeMap above. This is because getCodePtr()
279         // can depend on the opcodeMap.
280         uint8_t* exceptionInstructions = reinterpret_cast&lt;uint8_t*&gt;(LLInt::exceptionInstructions());
281         for (int i = 0; i &lt; maxOpcodeLength + 1; ++i)
282             exceptionInstructions[i] = llint_throw_from_slow_path_trampoline;
283 
284         return JSValue();
285     }
286 
287     // Define the pseudo registers used by the LLINT C Loop backend:
<span class="line-modified">288     ASSERT(sizeof(CLoopRegister) == sizeof(intptr_t));</span>
289 
290     // The CLoop llint backend is initially based on the ARMv7 backend, and
291     // then further enhanced with a few instructions from the x86 backend to
292     // support building for X64 targets. Hence, the shape of the generated
293     // code and the usage convention of registers will look a lot like the
294     // ARMv7 backend&#39;s.
295     //
296     // For example, on a 32-bit build:
297     // 1. Outgoing args will be set up as follows:
298     //    arg1 in t0 (r0 on ARM)
299     //    arg2 in t1 (r1 on ARM)
300     // 2. 32 bit return values will be in t0 (r0 on ARM).
301     // 3. 64 bit return values (e.g. doubles) will be in t0,t1 (r0,r1 on ARM).
302     //
303     // But instead of naming these simulator registers based on their ARM
304     // counterparts, we&#39;ll name them based on their original llint asm names.
305     // This will make it easier to correlate the generated code with the
306     // original llint asm code.
307     //
308     // On a 64-bit build, it more like x64 in that the registers are 64 bit.
</pre>
</td>
<td>
<hr />
<pre>
232     t1 = t1Result;
233 }
234 
235 } // namespace LLint
236 
237 //============================================================================
238 // The llint C++ interpreter loop:
239 //
240 
241 JSValue CLoop::execute(OpcodeID entryOpcodeID, void* executableAddress, VM* vm, ProtoCallFrame* protoCallFrame, bool isInitializationPass)
242 {
243 #define CAST bitwise_cast
244 
245     // One-time initialization of our address tables. We have to put this code
246     // here because our labels are only in scope inside this function. The
247     // caller (or one of its ancestors) is responsible for ensuring that this
248     // is only called once during the initialization of the VM before threads
249     // are at play.
250     if (UNLIKELY(isInitializationPass)) {
251         Opcode* opcodeMap = LLInt::opcodeMap();
<span class="line-modified">252         Opcode* opcodeMapWide16 = LLInt::opcodeMapWide16();</span>
<span class="line-added">253         Opcode* opcodeMapWide32 = LLInt::opcodeMapWide32();</span>
254 
255 #if ENABLE(COMPUTED_GOTO_OPCODES)
256         #define OPCODE_ENTRY(__opcode, length) \
257             opcodeMap[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode); \
<span class="line-modified">258             opcodeMapWide16[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode##_wide16); \</span>
<span class="line-added">259             opcodeMapWide32[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode##_wide32);</span>
260 
261         #define LLINT_OPCODE_ENTRY(__opcode, length) \
262             opcodeMap[__opcode] = bitwise_cast&lt;void*&gt;(&amp;&amp;__opcode);
263 #else
264         // FIXME: this mapping is unnecessarily expensive in the absence of COMPUTED_GOTO
265         //   narrow opcodes don&#39;t need any mapping and wide opcodes just need to add numOpcodeIDs
266         #define OPCODE_ENTRY(__opcode, length) \
267             opcodeMap[__opcode] = __opcode; \
<span class="line-modified">268             opcodeMapWide16[__opcode] = static_cast&lt;OpcodeID&gt;(__opcode##_wide16); \</span>
<span class="line-added">269             opcodeMapWide32[__opcode] = static_cast&lt;OpcodeID&gt;(__opcode##_wide32);</span>
270 
271         #define LLINT_OPCODE_ENTRY(__opcode, length) \
272             opcodeMap[__opcode] = __opcode;
273 #endif
274         FOR_EACH_BYTECODE_ID(OPCODE_ENTRY)
275         FOR_EACH_CLOOP_BYTECODE_HELPER_ID(LLINT_OPCODE_ENTRY)
276         FOR_EACH_LLINT_NATIVE_HELPER(LLINT_OPCODE_ENTRY)
277         #undef OPCODE_ENTRY
278         #undef LLINT_OPCODE_ENTRY
279 
280         // Note: we can only set the exceptionInstructions after we have
281         // initialized the opcodeMap above. This is because getCodePtr()
282         // can depend on the opcodeMap.
283         uint8_t* exceptionInstructions = reinterpret_cast&lt;uint8_t*&gt;(LLInt::exceptionInstructions());
284         for (int i = 0; i &lt; maxOpcodeLength + 1; ++i)
285             exceptionInstructions[i] = llint_throw_from_slow_path_trampoline;
286 
287         return JSValue();
288     }
289 
290     // Define the pseudo registers used by the LLINT C Loop backend:
<span class="line-modified">291     static_assert(sizeof(CLoopRegister) == sizeof(intptr_t));</span>
292 
293     // The CLoop llint backend is initially based on the ARMv7 backend, and
294     // then further enhanced with a few instructions from the x86 backend to
295     // support building for X64 targets. Hence, the shape of the generated
296     // code and the usage convention of registers will look a lot like the
297     // ARMv7 backend&#39;s.
298     //
299     // For example, on a 32-bit build:
300     // 1. Outgoing args will be set up as follows:
301     //    arg1 in t0 (r0 on ARM)
302     //    arg2 in t1 (r1 on ARM)
303     // 2. 32 bit return values will be in t0 (r0 on ARM).
304     // 3. 64 bit return values (e.g. doubles) will be in t0,t1 (r0,r1 on ARM).
305     //
306     // But instead of naming these simulator registers based on their ARM
307     // counterparts, we&#39;ll name them based on their original llint asm names.
308     // This will make it easier to correlate the generated code with the
309     // original llint asm code.
310     //
311     // On a 64-bit build, it more like x64 in that the registers are 64 bit.
</pre>
</td>
</tr>
</table>
<center><a href="LowLevelInterpreter.asm.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter32_64.asm.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>