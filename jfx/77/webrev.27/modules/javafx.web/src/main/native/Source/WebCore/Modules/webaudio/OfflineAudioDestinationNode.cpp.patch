diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/OfflineAudioDestinationNode.cpp b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/OfflineAudioDestinationNode.cpp
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/OfflineAudioDestinationNode.cpp
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/OfflineAudioDestinationNode.cpp
@@ -30,14 +30,17 @@
 
 #include "AudioBus.h"
 #include "AudioContext.h"
 #include "HRTFDatabaseLoader.h"
 #include <algorithm>
+#include <wtf/IsoMallocInlines.h>
 #include <wtf/MainThread.h>
 
 namespace WebCore {
 
+WTF_MAKE_ISO_ALLOCATED_IMPL(OfflineAudioDestinationNode);
+
 const size_t renderQuantumSize = 128;
 
 OfflineAudioDestinationNode::OfflineAudioDestinationNode(AudioContext& context, AudioBuffer* renderTarget)
     : AudioDestinationNode(context, renderTarget->sampleRate())
     , m_renderTarget(renderTarget)
@@ -72,45 +75,55 @@
     AudioNode::uninitialize();
 }
 
 void OfflineAudioDestinationNode::startRendering()
 {
+    ALWAYS_LOG(LOGIDENTIFIER);
+
     ASSERT(isMainThread());
     ASSERT(m_renderTarget.get());
     if (!m_renderTarget.get())
         return;
 
-    if (!m_startedRendering) {
-        m_startedRendering = true;
-        ref(); // See corresponding deref() call in notifyCompleteDispatch().
-        m_renderThread = Thread::create("offline renderer", [this] {
-            offlineRender();
+    if (m_startedRendering)
+        return;
+
+    m_startedRendering = true;
+    ref();
+    // FIXME: Should we call lazyInitialize here?
+    // FIXME: We should probably limit the number of threads we create for offline audio.
+    m_renderThread = Thread::create("offline renderer", [this] {
+        bool didRender = offlineRender();
+        callOnMainThread([this, didRender] {
+            context().finishedRendering(didRender);
+            deref();
         });
-    }
+    });
 }
 
-void OfflineAudioDestinationNode::offlineRender()
+bool OfflineAudioDestinationNode::offlineRender()
 {
     ASSERT(!isMainThread());
     ASSERT(m_renderBus.get());
     if (!m_renderBus.get())
-        return;
+        return false;
 
     bool isAudioContextInitialized = context().isInitialized();
-    ASSERT(isAudioContextInitialized);
+    // FIXME: We used to assert that isAudioContextInitialized is true here.
+    // But it's trivially false in imported/w3c/web-platform-tests/webaudio/the-audio-api/the-offlineaudiocontext-interface/current-time-block-size.html
     if (!isAudioContextInitialized)
-        return;
+        return false;
 
     bool channelsMatch = m_renderBus->numberOfChannels() == m_renderTarget->numberOfChannels();
     ASSERT(channelsMatch);
     if (!channelsMatch)
-        return;
+        return false;
 
     bool isRenderBusAllocated = m_renderBus->length() >= renderQuantumSize;
     ASSERT(isRenderBusAllocated);
     if (!isRenderBusAllocated)
-        return;
+        return false;
 
     // Break up the render target into smaller "render quantize" sized pieces.
     // Render until we're finished.
     size_t framesToProcess = m_renderTarget->length();
     unsigned numberOfChannels = m_renderTarget->numberOfChannels();
@@ -130,20 +143,11 @@
 
         n += framesAvailableToCopy;
         framesToProcess -= framesAvailableToCopy;
     }
 
-    // Our work is done. Let the AudioContext know.
-    callOnMainThread([this] {
-        notifyComplete();
-        deref();
-    });
-}
-
-void OfflineAudioDestinationNode::notifyComplete()
-{
-    context().fireCompletionEvent();
+    return true;
 }
 
 } // namespace WebCore
 
 #endif // ENABLE(WEB_AUDIO)
