<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="../VideoTrackPrivateMediaStream.h.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../index.html" target="_top">index</a> <a href="GStreamerVideoDecoderFactory.h.udiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -52,10 +52,14 @@</span>
  
  class GStreamerVideoDecoder : public webrtc::VideoDecoder {
  public:
      GStreamerVideoDecoder()
          : m_pictureId(0)
<span class="udiff-line-added">+         , m_width(0)</span>
<span class="udiff-line-added">+         , m_height(0)</span>
<span class="udiff-line-added">+         , m_requireParse(false)</span>
<span class="udiff-line-added">+         , m_needsKeyframe(true)</span>
          , m_firstBufferPts(GST_CLOCK_TIME_NONE)
          , m_firstBufferDts(GST_CLOCK_TIME_NONE)
      {
      }
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -78,41 +82,79 @@</span>
          GUniquePtr&lt;char&gt; name(g_strdup_printf(&quot;%s_dec_%s_%p&quot;, Name(), factoryName, this));
  
          return gst_element_factory_make(factoryName, name.get());
      }
  
<span class="udiff-line-modified-removed">-     int32_t InitDecode(const webrtc::VideoCodec*, int32_t) override</span>
<span class="udiff-line-modified-added">+     int32_t InitDecode(const webrtc::VideoCodec* codecSettings, int32_t) override</span>
      {
          m_src = makeElement(&quot;appsrc&quot;);
  
<span class="udiff-line-added">+         GRefPtr&lt;GstCaps&gt; caps = nullptr;</span>
          auto capsfilter = CreateFilter();
          auto decoder = makeElement(&quot;decodebin&quot;);
  
<span class="udiff-line-added">+         if (codecSettings) {</span>
<span class="udiff-line-added">+             m_width = codecSettings-&gt;width;</span>
<span class="udiff-line-added">+             m_height = codecSettings-&gt;height;</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         m_pipeline = makeElement(&quot;pipeline&quot;);</span>
<span class="udiff-line-added">+         connectSimpleBusMessageCallback(m_pipeline.get());</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         auto sinkpad = adoptGRef(gst_element_get_static_pad(capsfilter, &quot;sink&quot;));</span>
<span class="udiff-line-added">+         g_signal_connect(decoder, &quot;pad-added&quot;, G_CALLBACK(decodebinPadAddedCb), sinkpad.get());</span>
          // Make the decoder output &quot;parsed&quot; frames only and let the main decodebin
          // do the real decoding. This allows us to have optimized decoding/rendering
          // happening in the main pipeline.
<span class="udiff-line-modified-removed">-         g_object_set(decoder, &quot;caps&quot;, adoptGRef(gst_caps_from_string(Caps())).get(), nullptr);</span>
<span class="udiff-line-modified-removed">-         auto sinkpad = gst_element_get_static_pad(capsfilter, &quot;sink&quot;);</span>
<span class="udiff-line-modified-removed">-         g_signal_connect(decoder, &quot;pad-added&quot;, G_CALLBACK(decodebinPadAddedCb), sinkpad);</span>
<span class="udiff-line-modified-added">+         if (m_requireParse) {</span>
<span class="udiff-line-modified-added">+             caps = gst_caps_new_simple(Caps(), &quot;parsed&quot;, G_TYPE_BOOLEAN, TRUE, nullptr);</span>
<span class="udiff-line-modified-added">+             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));</span>
  
<span class="udiff-line-modified-removed">-         m_pipeline = makeElement(&quot;pipeline&quot;);</span>
<span class="udiff-line-modified-removed">-         connectSimpleBusMessageCallback(m_pipeline.get());</span>
<span class="udiff-line-modified-added">+             gst_bus_enable_sync_message_emission(bus.get());</span>
<span class="udiff-line-modified-added">+             g_signal_connect(bus.get(), &quot;sync-message::warning&quot;,</span>
<span class="udiff-line-added">+                 G_CALLBACK(+[](GstBus*, GstMessage* message, GStreamerVideoDecoder* justThis) {</span>
<span class="udiff-line-added">+                 GUniqueOutPtr&lt;GError&gt; err;</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+                 switch (GST_MESSAGE_TYPE(message)) {</span>
<span class="udiff-line-added">+                 case GST_MESSAGE_WARNING: {</span>
<span class="udiff-line-added">+                     gst_message_parse_warning(message, &amp;err.outPtr(), nullptr);</span>
<span class="udiff-line-added">+                     FALLTHROUGH;</span>
<span class="udiff-line-added">+                 }</span>
<span class="udiff-line-added">+                 case GST_MESSAGE_ERROR: {</span>
<span class="udiff-line-added">+                     if (!err)</span>
<span class="udiff-line-added">+                         gst_message_parse_error(message, &amp;err.outPtr(), nullptr);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+                     if (g_error_matches(err.get(), GST_STREAM_ERROR, GST_STREAM_ERROR_DECODE)) {</span>
<span class="udiff-line-added">+                         GST_INFO_OBJECT(justThis-&gt;pipeline(), &quot;--&gt; needs keyframe (%s)&quot;,</span>
<span class="udiff-line-added">+                             err-&gt;message);</span>
<span class="udiff-line-added">+                         justThis-&gt;m_needsKeyframe = true;</span>
<span class="udiff-line-added">+                     }</span>
<span class="udiff-line-added">+                     break;</span>
<span class="udiff-line-added">+                 }</span>
<span class="udiff-line-added">+                 default:</span>
<span class="udiff-line-added">+                     break;</span>
<span class="udiff-line-added">+                 }</span>
<span class="udiff-line-added">+                 }), this);</span>
<span class="udiff-line-added">+         } else {</span>
<span class="udiff-line-added">+             /* FIXME - How could we handle missing keyframes case we do not plug parsers ? */</span>
<span class="udiff-line-added">+             caps = gst_caps_new_empty_simple(Caps());</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+         g_object_set(decoder, &quot;caps&quot;, caps.get(), nullptr);</span>
  
<span class="udiff-line-modified-removed">-         auto sink = makeElement(&quot;appsink&quot;);</span>
<span class="udiff-line-modified-removed">-         gst_app_sink_set_emit_signals(GST_APP_SINK(sink), true);</span>
<span class="udiff-line-modified-removed">-         g_signal_connect(sink, &quot;new-sample&quot;, G_CALLBACK(newSampleCallbackTramp), this);</span>
<span class="udiff-line-removed">-         // This is an encoder, everything should happen as fast as possible and not</span>
<span class="udiff-line-modified-added">+         m_sink = makeElement(&quot;appsink&quot;);</span>
<span class="udiff-line-modified-added">+         gst_app_sink_set_emit_signals(GST_APP_SINK(m_sink), true);</span>
<span class="udiff-line-modified-added">+         // This is an decoder, everything should happen as fast as possible and not</span>
          // be synced on the clock.
<span class="udiff-line-modified-removed">-         g_object_set(sink, &quot;sync&quot;, false, nullptr);</span>
<span class="udiff-line-modified-added">+         g_object_set(m_sink, &quot;sync&quot;, false, nullptr);</span>
  
<span class="udiff-line-modified-removed">-         gst_bin_add_many(GST_BIN(pipeline()), m_src, decoder, capsfilter, sink, nullptr);</span>
<span class="udiff-line-modified-added">+         gst_bin_add_many(GST_BIN(pipeline()), m_src, decoder, capsfilter, m_sink, nullptr);</span>
          if (!gst_element_link(m_src, decoder)) {
              GST_ERROR_OBJECT(pipeline(), &quot;Could not link src to decoder.&quot;);
              return WEBRTC_VIDEO_CODEC_ERROR;
          }
  
<span class="udiff-line-modified-removed">-         if (!gst_element_link(capsfilter, sink)) {</span>
<span class="udiff-line-modified-added">+         if (!gst_element_link(capsfilter, m_sink)) {</span>
              GST_ERROR_OBJECT(pipeline(), &quot;Could not link capsfilter to sink.&quot;);
              return WEBRTC_VIDEO_CODEC_ERROR;
          }
  
          if (gst_element_set_state(pipeline(), GST_STATE_PLAYING) == GST_STATE_CHANGE_FAILURE) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -141,10 +183,11 @@</span>
              GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
              gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
  
              gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
              m_src = nullptr;
<span class="udiff-line-added">+             m_sink = nullptr;</span>
              m_pipeline = nullptr;
          }
  
          return WEBRTC_VIDEO_CODEC_OK;
      }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -152,10 +195,24 @@</span>
      int32_t Decode(const webrtc::EncodedImage&amp; inputImage,
          bool,
          const webrtc::CodecSpecificInfo*,
          int64_t renderTimeMs) override
      {
<span class="udiff-line-added">+         if (m_needsKeyframe) {</span>
<span class="udiff-line-added">+             if (inputImage._frameType != webrtc::kVideoFrameKey) {</span>
<span class="udiff-line-added">+                 GST_ERROR(&quot;Waiting for keyframe but got a delta unit... asking for keyframe&quot;);</span>
<span class="udiff-line-added">+                 return WEBRTC_VIDEO_CODEC_ERROR;</span>
<span class="udiff-line-added">+             }</span>
<span class="udiff-line-added">+             if (inputImage._completeFrame)</span>
<span class="udiff-line-added">+                 m_needsKeyframe = false;</span>
<span class="udiff-line-added">+             else {</span>
<span class="udiff-line-added">+                 GST_ERROR(&quot;Waiting for keyframe but didn&#39;t get full frame, getting out&quot;);</span>
<span class="udiff-line-added">+                 return WEBRTC_VIDEO_CODEC_ERROR;</span>
<span class="udiff-line-added">+             }</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+ </span>
          if (!m_src) {
              GST_ERROR(&quot;No source set, can&#39;t decode.&quot;);
  
              return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
          }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -169,34 +226,59 @@</span>
          // FIXME- Use a GstBufferPool.
          auto buffer = adoptGRef(gst_buffer_new_wrapped(g_memdup(inputImage._buffer, inputImage._size),
              inputImage._size));
          GST_BUFFER_DTS(buffer.get()) = (static_cast&lt;guint64&gt;(inputImage.Timestamp()) * GST_MSECOND) - m_firstBufferDts;
          GST_BUFFER_PTS(buffer.get()) = (static_cast&lt;guint64&gt;(renderTimeMs) * GST_MSECOND) - m_firstBufferPts;
<span class="udiff-line-modified-removed">-         {</span>
<span class="udiff-line-modified-removed">-             auto locker = holdLock(m_bufferMapLock);</span>
<span class="udiff-line-removed">-             InputTimestamps timestamps = {inputImage.Timestamp(), renderTimeMs};</span>
<span class="udiff-line-removed">-             m_dtsPtsMap[GST_BUFFER_PTS(buffer.get())] = timestamps;</span>
<span class="udiff-line-removed">-         }</span>
<span class="udiff-line-modified-added">+         InputTimestamps timestamps = {inputImage.Timestamp(), renderTimeMs};</span>
<span class="udiff-line-modified-added">+         m_dtsPtsMap[GST_BUFFER_PTS(buffer.get())] = timestamps;</span>
  
<span class="udiff-line-modified-removed">-         GST_LOG_OBJECT(pipeline(), &quot;%ld Decoding: %&quot; GST_PTR_FORMAT, renderTimeMs, buffer.get());</span>
<span class="udiff-line-modified-added">+         GST_LOG_OBJECT(pipeline(), &quot;%&quot; G_GINT64_FORMAT &quot; Decoding: %&quot; GST_PTR_FORMAT, renderTimeMs, buffer.get());</span>
          auto sample = adoptGRef(gst_sample_new(buffer.get(), GetCapsForFrame(inputImage), nullptr, nullptr));
          switch (gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get())) {
          case GST_FLOW_OK:
<span class="udiff-line-modified-removed">-             return WEBRTC_VIDEO_CODEC_OK;</span>
<span class="udiff-line-modified-added">+             break;</span>
          case GST_FLOW_FLUSHING:
              return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
          default:
              return WEBRTC_VIDEO_CODEC_ERROR;
          }
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         return pullSample();</span>
<span class="udiff-line-added">+     }</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     int32_t pullSample()</span>
<span class="udiff-line-added">+     {</span>
<span class="udiff-line-added">+         auto sample = gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), GST_SECOND / 30);</span>
<span class="udiff-line-added">+         if (!sample) {</span>
<span class="udiff-line-added">+             GST_ERROR(&quot;Needs more data&quot;);</span>
<span class="udiff-line-added">+             return WEBRTC_VIDEO_CODEC_OK;</span>
<span class="udiff-line-added">+         }</span>
<span class="udiff-line-added">+         auto buffer = gst_sample_get_buffer(sample);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         // Make sure that the frame.timestamp == previsouly input_frame._timeStamp</span>
<span class="udiff-line-added">+         // as it is required by the VideoDecoder baseclass.</span>
<span class="udiff-line-added">+         auto timestamps = m_dtsPtsMap[GST_BUFFER_PTS(buffer)];</span>
<span class="udiff-line-added">+         m_dtsPtsMap.erase(GST_BUFFER_PTS(buffer));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         auto frame(LibWebRTCVideoFrameFromGStreamerSample(sample, webrtc::kVideoRotation_0,</span>
<span class="udiff-line-added">+             timestamps.timestamp, timestamps.renderTimeMs));</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         GST_BUFFER_DTS(buffer) = GST_CLOCK_TIME_NONE;</span>
<span class="udiff-line-added">+         GST_LOG_OBJECT(pipeline(), &quot;Output decoded frame! %d -&gt; %&quot; GST_PTR_FORMAT,</span>
<span class="udiff-line-added">+             frame-&gt;timestamp(), buffer);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         m_imageReadyCb-&gt;Decoded(*frame.get(), absl::optional&lt;int32_t&gt;(), absl::optional&lt;uint8_t&gt;());</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+         return WEBRTC_VIDEO_CODEC_OK;</span>
      }
  
      virtual GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image)
      {
          if (!m_caps) {
              m_caps = adoptGRef(gst_caps_new_simple(Caps(),
<span class="udiff-line-modified-removed">-                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth,</span>
<span class="udiff-line-modified-removed">-                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight,</span>
<span class="udiff-line-modified-added">+                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth ? image._encodedWidth : m_width,</span>
<span class="udiff-line-modified-added">+                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight ? image._encodedHeight : m_height,</span>
                  nullptr));
          }
  
          return m_caps.get();
      }
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -235,64 +317,39 @@</span>
      bool HasGstDecoder()
      {
          return GstDecoderFactory(Caps());
      }
  
<span class="udiff-line-removed">-     GstFlowReturn newSampleCallback(GstElement* sink)</span>
<span class="udiff-line-removed">-     {</span>
<span class="udiff-line-removed">-         auto sample = gst_app_sink_pull_sample(GST_APP_SINK(sink));</span>
<span class="udiff-line-removed">-         auto buffer = gst_sample_get_buffer(sample);</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-         m_bufferMapLock.lock();</span>
<span class="udiff-line-removed">-         // Make sure that the frame.timestamp == previsouly input_frame._timeStamp</span>
<span class="udiff-line-removed">-         // as it is required by the VideoDecoder baseclass.</span>
<span class="udiff-line-removed">-         auto timestamps = m_dtsPtsMap[GST_BUFFER_PTS(buffer)];</span>
<span class="udiff-line-removed">-         m_dtsPtsMap.erase(GST_BUFFER_PTS(buffer));</span>
<span class="udiff-line-removed">-         m_bufferMapLock.unlock();</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-         auto frame(LibWebRTCVideoFrameFromGStreamerSample(sample, webrtc::kVideoRotation_0,</span>
<span class="udiff-line-removed">-             timestamps.timestamp, timestamps.renderTimeMs));</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-         GST_BUFFER_DTS(buffer) = GST_CLOCK_TIME_NONE;</span>
<span class="udiff-line-removed">-         GST_LOG_OBJECT(pipeline(), &quot;Output decoded frame! %d -&gt; %&quot; GST_PTR_FORMAT,</span>
<span class="udiff-line-removed">-             frame-&gt;timestamp(), buffer);</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-         m_imageReadyCb-&gt;Decoded(*frame.get(), absl::optional&lt;int32_t&gt;(), absl::optional&lt;uint8_t&gt;());</span>
<span class="udiff-line-removed">- </span>
<span class="udiff-line-removed">-         return GST_FLOW_OK;</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">- </span>
      virtual const gchar* Caps() = 0;
      virtual webrtc::VideoCodecType CodecType() = 0;
      const char* ImplementationName() const { return &quot;GStreamer&quot;; }
      virtual const gchar* Name() = 0;
  
  protected:
      GRefPtr&lt;GstCaps&gt; m_caps;
      gint m_pictureId;
<span class="udiff-line-added">+     gint m_width;</span>
<span class="udiff-line-added">+     gint m_height;</span>
<span class="udiff-line-added">+     bool m_requireParse = false;</span>
<span class="udiff-line-added">+     bool m_needsKeyframe;</span>
  
  private:
<span class="udiff-line-removed">-     static GstFlowReturn newSampleCallbackTramp(GstElement* sink, GStreamerVideoDecoder* enc)</span>
<span class="udiff-line-removed">-     {</span>
<span class="udiff-line-removed">-         return enc-&gt;newSampleCallback(sink);</span>
<span class="udiff-line-removed">-     }</span>
<span class="udiff-line-removed">- </span>
      GRefPtr&lt;GstElement&gt; m_pipeline;
<span class="udiff-line-added">+     GstElement* m_sink;</span>
      GstElement* m_src;
  
      GstVideoInfo m_info;
      webrtc::DecodedImageCallback* m_imageReadyCb;
  
<span class="udiff-line-removed">-     Lock m_bufferMapLock;</span>
      StdMap&lt;GstClockTime, InputTimestamps&gt; m_dtsPtsMap;
      GstClockTime m_firstBufferPts;
      GstClockTime m_firstBufferDts;
  };
  
  class H264Decoder : public GStreamerVideoDecoder {
  public:
<span class="udiff-line-modified-removed">-     H264Decoder() { }</span>
<span class="udiff-line-modified-added">+     H264Decoder() { m_requireParse = true; }</span>
  
      int32_t InitDecode(const webrtc::VideoCodec* codecInfo, int32_t nCores) final
      {
          if (codecInfo &amp;&amp; codecInfo-&gt;codecType != webrtc::kVideoCodecH264)
              return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -325,14 +382,12 @@</span>
  
      GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image) final
      {
          if (!m_caps) {
              m_caps = adoptGRef(gst_caps_new_simple(Caps(),
<span class="udiff-line-modified-removed">-                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth,</span>
<span class="udiff-line-modified-removed">-                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight,</span>
<span class="udiff-line-removed">-                 &quot;profile&quot;, G_TYPE_STRING, m_profile ? m_profile : &quot;baseline&quot;,</span>
<span class="udiff-line-removed">-                 &quot;stream-format&quot;, G_TYPE_STRING, &quot;byte-stream&quot;,</span>
<span class="udiff-line-modified-added">+                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth ? image._encodedWidth : m_width,</span>
<span class="udiff-line-modified-added">+                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight ? image._encodedHeight : m_height,</span>
                  &quot;alignment&quot;, G_TYPE_STRING, &quot;au&quot;,
                  nullptr));
          }
  
          return m_caps.get();
</pre>
<center><a href="../VideoTrackPrivateMediaStream.h.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../index.html" target="_top">index</a> <a href="GStreamerVideoDecoderFactory.h.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>