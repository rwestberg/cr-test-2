<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioNode.h</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2010, Google Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1.  Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2.  Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 15  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 16  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 17  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 18  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 19  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 20  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 21  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 22  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 23  */
 24 
 25 #pragma once
 26 
 27 #include &quot;AudioBus.h&quot;
 28 #include &quot;EventTarget.h&quot;
 29 #include &quot;ExceptionOr.h&quot;
 30 #include &lt;wtf/Forward.h&gt;
<a name="1" id="anc1"></a>
 31 
 32 #define DEBUG_AUDIONODE_REFERENCES 0
 33 
 34 namespace WebCore {
 35 
 36 class AudioContext;
 37 class AudioNodeInput;
 38 class AudioNodeOutput;
 39 class AudioParam;
 40 
 41 // An AudioNode is the basic building block for handling audio within an AudioContext.
 42 // It may be an audio source, an intermediate processing module, or an audio destination.
 43 // Each AudioNode can have inputs and/or outputs. An AudioSourceNode has no inputs and a single output.
 44 // An AudioDestinationNode has one input and no outputs and represents the final destination to the audio hardware.
 45 // Most processing nodes such as filters will have one input and one output, although multiple inputs and outputs are possible.
 46 
<a name="2" id="anc2"></a><span class="line-modified"> 47 class AudioNode : public EventTargetWithInlineData {</span>





 48     WTF_MAKE_NONCOPYABLE(AudioNode);
<a name="3" id="anc3"></a><span class="line-modified"> 49     WTF_MAKE_FAST_ALLOCATED;</span>
 50 public:
 51     enum { ProcessingSizeInFrames = 128 };
 52 
 53     AudioNode(AudioContext&amp;, float sampleRate);
 54     virtual ~AudioNode();
 55 
 56     AudioContext&amp; context() { return m_context.get(); }
 57     const AudioContext&amp; context() const { return m_context.get(); }
 58 
 59     enum NodeType {
 60         NodeTypeUnknown,
 61         NodeTypeDestination,
 62         NodeTypeOscillator,
 63         NodeTypeAudioBufferSource,
 64         NodeTypeMediaElementAudioSource,
 65         NodeTypeMediaStreamAudioDestination,
 66         NodeTypeMediaStreamAudioSource,
 67         NodeTypeJavaScript,
 68         NodeTypeBiquadFilter,
 69         NodeTypePanner,
 70         NodeTypeConvolver,
 71         NodeTypeDelay,
 72         NodeTypeGain,
 73         NodeTypeChannelSplitter,
 74         NodeTypeChannelMerger,
 75         NodeTypeAnalyser,
 76         NodeTypeDynamicsCompressor,
 77         NodeTypeWaveShaper,
<a name="4" id="anc4"></a>
 78         NodeTypeEnd
 79     };
 80 
 81     enum ChannelCountMode {
 82         Max,
 83         ClampedMax,
 84         Explicit
 85     };
 86 
 87     NodeType nodeType() const { return m_nodeType; }
 88     void setNodeType(NodeType);
 89 
 90     // We handle our own ref-counting because of the threading issues and subtle nature of
 91     // how AudioNodes can continue processing (playing one-shot sound) after there are no more
 92     // JavaScript references to the object.
 93     enum RefType { RefTypeNormal, RefTypeConnection };
 94 
 95     // Can be called from main thread or context&#39;s audio thread.
 96     void ref(RefType refType = RefTypeNormal);
 97     void deref(RefType refType = RefTypeNormal);
 98 
 99     // Can be called from main thread or context&#39;s audio thread.  It must be called while the context&#39;s graph lock is held.
100     void finishDeref(RefType refType);
101 
102     // The AudioNodeInput(s) (if any) will already have their input data available when process() is called.
103     // Subclasses will take this input data and put the results in the AudioBus(s) of its AudioNodeOutput(s) (if any).
104     // Called from context&#39;s audio thread.
105     virtual void process(size_t framesToProcess) = 0;
106 
107     // Resets DSP processing state (clears delay lines, filter memory, etc.)
108     // Called from context&#39;s audio thread.
109     virtual void reset() = 0;
110 
111     // No significant resources should be allocated until initialize() is called.
112     // Processing may not occur until a node is initialized.
113     virtual void initialize();
114     virtual void uninitialize();
115 
116     bool isInitialized() const { return m_isInitialized; }
117     void lazyInitialize();
118 
119     unsigned numberOfInputs() const { return m_inputs.size(); }
120     unsigned numberOfOutputs() const { return m_outputs.size(); }
121 
122     AudioNodeInput* input(unsigned);
123     AudioNodeOutput* output(unsigned);
124 
125     // Called from main thread by corresponding JavaScript methods.
126     virtual ExceptionOr&lt;void&gt; connect(AudioNode&amp;, unsigned outputIndex, unsigned inputIndex);
127     ExceptionOr&lt;void&gt; connect(AudioParam&amp;, unsigned outputIndex);
128     virtual ExceptionOr&lt;void&gt; disconnect(unsigned outputIndex);
129 
130     virtual float sampleRate() const { return m_sampleRate; }
131 
132     // processIfNecessary() is called by our output(s) when the rendering graph needs this AudioNode to process.
133     // This method ensures that the AudioNode will only process once per rendering time quantum even if it&#39;s called repeatedly.
134     // This handles the case of &quot;fanout&quot; where an output is connected to multiple AudioNode inputs.
135     // Called from context&#39;s audio thread.
136     void processIfNecessary(size_t framesToProcess);
137 
138     // Called when a new connection has been made to one of our inputs or the connection number of channels has changed.
139     // This potentially gives us enough information to perform a lazy initialization or, if necessary, a re-initialization.
140     // Called from main thread.
141     virtual void checkNumberOfChannelsForInput(AudioNodeInput*);
142 
143 #if DEBUG_AUDIONODE_REFERENCES
144     static void printNodeCounts();
145 #endif
146 
147     bool isMarkedForDeletion() const { return m_isMarkedForDeletion; }
148 
149     // tailTime() is the length of time (not counting latency time) where non-zero output may occur after continuous silent input.
150     virtual double tailTime() const = 0;
151     // latencyTime() is the length of time it takes for non-zero output to appear after non-zero input is provided. This only applies to
152     // processing delay which is an artifact of the processing algorithm chosen and is *not* part of the intrinsic desired effect. For
153     // example, a &quot;delay&quot; effect is expected to delay the signal, and thus would not be considered latency.
154     virtual double latencyTime() const = 0;
155 
156     // propagatesSilence() should return true if the node will generate silent output when given silent input. By default, AudioNode
157     // will take tailTime() and latencyTime() into account when determining whether the node will propagate silence.
158     virtual bool propagatesSilence() const;
159     bool inputsAreSilent();
160     void silenceOutputs();
161 
162     void enableOutputsIfNecessary();
163     void disableOutputsIfNecessary();
164 
165     unsigned channelCount();
166     virtual ExceptionOr&lt;void&gt; setChannelCount(unsigned);
167 
168     String channelCountMode();
169     ExceptionOr&lt;void&gt; setChannelCountMode(const String&amp;);
170 
171     String channelInterpretation();
172     ExceptionOr&lt;void&gt; setChannelInterpretation(const String&amp;);
173 
174     ChannelCountMode internalChannelCountMode() const { return m_channelCountMode; }
175     AudioBus::ChannelInterpretation internalChannelInterpretation() const { return m_channelInterpretation; }
176 
<a name="5" id="anc5"></a><span class="line-removed">177     // EventTarget</span>
<span class="line-removed">178     EventTargetInterface eventTargetInterface() const override;</span>
<span class="line-removed">179     ScriptExecutionContext* scriptExecutionContext() const final;</span>
<span class="line-removed">180 </span>
181 protected:
182     // Inputs and outputs must be created before the AudioNode is initialized.
183     void addInput(std::unique_ptr&lt;AudioNodeInput&gt;);
184     void addOutput(std::unique_ptr&lt;AudioNodeOutput&gt;);
185 
186     // Called by processIfNecessary() to cause all parts of the rendering graph connected to us to process.
187     // Each rendering quantum, the audio data for each of the AudioNode&#39;s inputs will be available after this method is called.
188     // Called from context&#39;s audio thread.
189     virtual void pullInputs(size_t framesToProcess);
190 
191     // Force all inputs to take any channel interpretation changes into account.
192     void updateChannelsForInputs();
193 
<a name="6" id="anc6"></a>






194 private:
<a name="7" id="anc7"></a>



195     volatile bool m_isInitialized;
196     NodeType m_nodeType;
197     Ref&lt;AudioContext&gt; m_context;
198     float m_sampleRate;
199     Vector&lt;std::unique_ptr&lt;AudioNodeInput&gt;&gt; m_inputs;
200     Vector&lt;std::unique_ptr&lt;AudioNodeOutput&gt;&gt; m_outputs;
201 
202     double m_lastProcessingTime;
203     double m_lastNonSilentTime;
204 
205     // Ref-counting
206     std::atomic&lt;int&gt; m_normalRefCount;
207     std::atomic&lt;int&gt; m_connectionRefCount;
208 
209     bool m_isMarkedForDeletion;
210     bool m_isDisabled;
211 
212 #if DEBUG_AUDIONODE_REFERENCES
213     static bool s_isNodeCountInitialized;
214     static int s_nodeCount[NodeTypeEnd];
215 #endif
216 
217     void refEventTarget() override { ref(); }
218     void derefEventTarget() override { deref(); }
219 
<a name="8" id="anc8"></a>




220 protected:
221     unsigned m_channelCount;
222     ChannelCountMode m_channelCountMode;
223     AudioBus::ChannelInterpretation m_channelInterpretation;
224 };
225 
<a name="9" id="anc9"></a>

226 } // namespace WebCore
<a name="10" id="anc10"></a>







<a name="11" id="anc11"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="11" type="hidden" />
</body>
</html>