<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITPropertyAccess.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="JITOperations.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITPropertyAccess32_64.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JITPropertyAccess.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  27 
  28 #if ENABLE(JIT)
  29 #include &quot;JIT.h&quot;
  30 
  31 #include &quot;CodeBlock.h&quot;
  32 #include &quot;DirectArguments.h&quot;
  33 #include &quot;GCAwareJITStubRoutine.h&quot;
  34 #include &quot;GetterSetter.h&quot;
  35 #include &quot;InterpreterInlines.h&quot;
  36 #include &quot;JITInlines.h&quot;
  37 #include &quot;JSArray.h&quot;
  38 #include &quot;JSFunction.h&quot;
  39 #include &quot;JSLexicalEnvironment.h&quot;
  40 #include &quot;LinkBuffer.h&quot;
  41 #include &quot;OpcodeInlines.h&quot;
  42 #include &quot;ResultType.h&quot;
  43 #include &quot;ScopedArguments.h&quot;
  44 #include &quot;ScopedArgumentsTable.h&quot;
  45 #include &quot;SlowPathCall.h&quot;
  46 #include &quot;StructureStubInfo.h&quot;

  47 #include &lt;wtf/ScopedLambda.h&gt;
  48 #include &lt;wtf/StringPrintStream.h&gt;
  49 
  50 
  51 namespace JSC {
  52 #if USE(JSVALUE64)
  53 
  54 void JIT::emit_op_get_by_val(const Instruction* currentInstruction)
  55 {
  56     auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();
  57     auto&amp; metadata = bytecode.metadata(m_codeBlock);
  58     int dst = bytecode.m_dst.offset();
  59     int base = bytecode.m_base.offset();
  60     int property = bytecode.m_property.offset();
  61     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
  62     ByValInfo* byValInfo = m_codeBlock-&gt;addByValInfo();
  63 
  64     emitGetVirtualRegister(base, regT0);
  65     bool propertyNameIsIntegerConstant = isOperandConstantInt(property);
  66     if (propertyNameIsIntegerConstant)
</pre>
<hr />
<pre>
 565     Label coldPathBegin = label();
 566 
 567     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdDirectOptimize, resultVReg, gen.stubInfo(), regT0, ident-&gt;impl());
 568 
 569     gen.reportSlowPathCall(coldPathBegin, call);
 570 }
 571 
 572 void JIT::emit_op_get_by_id(const Instruction* currentInstruction)
 573 {
 574     auto bytecode = currentInstruction-&gt;as&lt;OpGetById&gt;();
 575     auto&amp; metadata = bytecode.metadata(m_codeBlock);
 576     int resultVReg = bytecode.m_dst.offset();
 577     int baseVReg = bytecode.m_base.offset();
 578     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 579 
 580     emitGetVirtualRegister(baseVReg, regT0);
 581 
 582     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 583 
 584     if (*ident == m_vm-&gt;propertyNames-&gt;length &amp;&amp; shouldEmitProfiling()) {
<span class="line-modified"> 585         Jump notArrayLengthMode = branch8(NotEqual, AbsoluteAddress(&amp;metadata.m_mode), TrustedImm32(static_cast&lt;uint8_t&gt;(GetByIdMode::ArrayLength)));</span>
 586         emitArrayProfilingSiteWithCell(regT0, regT1, &amp;metadata.m_modeMetadata.arrayLengthMode.arrayProfile);
 587         notArrayLengthMode.link(this);
 588     }
 589 
 590     JITGetByIdGenerator gen(
 591         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),
 592         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::Get);
 593     gen.generateFastPath(*this);
 594     addSlowCase(gen.slowPathJump());
 595     m_getByIds.append(gen);
 596 
 597     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 598     emitPutVirtualRegister(resultVReg);
 599 }
 600 
 601 void JIT::emit_op_get_by_id_with_this(const Instruction* currentInstruction)
 602 {
 603     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdWithThis&gt;();
 604     int resultVReg = bytecode.m_dst.offset();
 605     int baseVReg = bytecode.m_base.offset();
</pre>
<hr />
<pre>
1194     emitGetVirtualRegister(arguments, regT0);
1195     emitGetVirtualRegister(value, regT1);
1196     store64(regT1, Address(regT0, DirectArguments::storageOffset() + index * sizeof(WriteBarrier&lt;Unknown&gt;)));
1197 
1198     emitWriteBarrier(arguments, value, ShouldFilterValue);
1199 }
1200 
1201 void JIT::emitWriteBarrier(unsigned owner, unsigned value, WriteBarrierMode mode)
1202 {
1203     Jump valueNotCell;
1204     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue) {
1205         emitGetVirtualRegister(value, regT0);
1206         valueNotCell = branchIfNotCell(regT0);
1207     }
1208 
1209     emitGetVirtualRegister(owner, regT0);
1210     Jump ownerNotCell;
1211     if (mode == ShouldFilterBaseAndValue || mode == ShouldFilterBase)
1212         ownerNotCell = branchIfNotCell(regT0);
1213 
<span class="line-modified">1214     Jump ownerIsRememberedOrInEden = barrierBranch(*vm(), regT0, regT1);</span>
1215     callOperation(operationWriteBarrierSlowPath, regT0);
1216     ownerIsRememberedOrInEden.link(this);
1217 
1218     if (mode == ShouldFilterBaseAndValue || mode == ShouldFilterBase)
1219         ownerNotCell.link(this);
1220     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue)
1221         valueNotCell.link(this);
1222 }
1223 
1224 void JIT::emitWriteBarrier(JSCell* owner, unsigned value, WriteBarrierMode mode)
1225 {
1226     emitGetVirtualRegister(value, regT0);
1227     Jump valueNotCell;
1228     if (mode == ShouldFilterValue)
1229         valueNotCell = branchIfNotCell(regT0);
1230 
1231     emitWriteBarrier(owner);
1232 
1233     if (mode == ShouldFilterValue)
1234         valueNotCell.link(this);
1235 }
1236 
1237 #else // USE(JSVALUE64)
1238 
1239 void JIT::emitWriteBarrier(unsigned owner, unsigned value, WriteBarrierMode mode)
1240 {
1241     Jump valueNotCell;
1242     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue) {
1243         emitLoadTag(value, regT0);
1244         valueNotCell = branchIfNotCell(regT0);
1245     }
1246 
1247     emitLoad(owner, regT0, regT1);
1248     Jump ownerNotCell;
1249     if (mode == ShouldFilterBase || mode == ShouldFilterBaseAndValue)
1250         ownerNotCell = branchIfNotCell(regT0);
1251 
<span class="line-modified">1252     Jump ownerIsRememberedOrInEden = barrierBranch(*vm(), regT1, regT2);</span>
1253     callOperation(operationWriteBarrierSlowPath, regT1);
1254     ownerIsRememberedOrInEden.link(this);
1255 
1256     if (mode == ShouldFilterBase || mode == ShouldFilterBaseAndValue)
1257         ownerNotCell.link(this);
1258     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue)
1259         valueNotCell.link(this);
1260 }
1261 
1262 void JIT::emitWriteBarrier(JSCell* owner, unsigned value, WriteBarrierMode mode)
1263 {
1264     Jump valueNotCell;
1265     if (mode == ShouldFilterValue) {
1266         emitLoadTag(value, regT0);
1267         valueNotCell = branchIfNotCell(regT0);
1268     }
1269 
1270     emitWriteBarrier(owner);
1271 
1272     if (mode == ShouldFilterValue)
1273         valueNotCell.link(this);
1274 }
1275 
1276 #endif // USE(JSVALUE64)
1277 
1278 void JIT::emitWriteBarrier(JSCell* owner)
1279 {
<span class="line-modified">1280     Jump ownerIsRememberedOrInEden = barrierBranch(*vm(), owner, regT0);</span>
1281     callOperation(operationWriteBarrierSlowPath, owner);
1282     ownerIsRememberedOrInEden.link(this);
1283 }
1284 
1285 void JIT::emitByValIdentifierCheck(ByValInfo* byValInfo, RegisterID cell, RegisterID scratch, const Identifier&amp; propertyName, JumpList&amp; slowCases)
1286 {
1287     if (propertyName.isSymbol())
1288         slowCases.append(branchPtr(NotEqual, cell, TrustedImmPtr(byValInfo-&gt;cachedSymbol.get())));
1289     else {
1290         slowCases.append(branchIfNotString(cell));
1291         loadPtr(Address(cell, JSString::offsetOfValue()), scratch);
1292         slowCases.append(branchPtr(NotEqual, scratch, TrustedImmPtr(propertyName.impl())));
1293     }
1294 }
1295 
1296 void JIT::privateCompileGetByVal(const ConcurrentJSLocker&amp;, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)
1297 {
1298     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1299 
1300     PatchableJump badType;
</pre>
<hr />
<pre>
1422     patchBuffer.link(done, byValInfo-&gt;badTypeDoneTarget);
1423     if (needsLinkForWriteBarrier) {
1424         ASSERT(removeCodePtrTag(m_calls.last().callee.executableAddress()) == removeCodePtrTag(operationWriteBarrierSlowPath));
1425         patchBuffer.link(m_calls.last().from, m_calls.last().callee);
1426     }
1427 
1428     bool isDirect = currentInstruction-&gt;opcodeID() == op_put_by_val_direct;
1429     if (!isDirect) {
1430         byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1431             m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1432             &quot;Baseline put_by_val stub for %s, return point %p&quot;, toCString(*m_codeBlock).data(), returnAddress.value());
1433 
1434     } else {
1435         byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1436             m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1437             &quot;Baseline put_by_val_direct stub for %s, return point %p&quot;, toCString(*m_codeBlock).data(), returnAddress.value());
1438     }
1439     MacroAssembler::repatchJump(byValInfo-&gt;badTypeJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));
1440     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(isDirect ? operationDirectPutByValGeneric : operationPutByValGeneric));
1441 }




1442 
1443 template&lt;typename Op&gt;
1444 void JIT::privateCompilePutByValWithCachedId(ByValInfo* byValInfo, ReturnAddressPtr returnAddress, PutKind putKind, const Identifier&amp; propertyName)
1445 {
1446     ASSERT((putKind == Direct &amp;&amp; Op::opcodeID == op_put_by_val_direct) || (putKind == NotDirect &amp;&amp; Op::opcodeID == op_put_by_val));
1447     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1448     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
1449 
1450     JumpList doneCases;
1451     JumpList slowCases;
1452 
1453     JITPutByIdGenerator gen = emitPutByValWithCachedId(byValInfo, bytecode, putKind, propertyName, doneCases, slowCases);
1454 
1455     ConcurrentJSLocker locker(m_codeBlock-&gt;m_lock);
1456     LinkBuffer patchBuffer(*this, m_codeBlock);
1457     patchBuffer.link(slowCases, byValInfo-&gt;slowPathTarget);
1458     patchBuffer.link(doneCases, byValInfo-&gt;badTypeDoneTarget);
1459     if (!m_exceptionChecks.empty())
1460         patchBuffer.link(m_exceptionChecks, byValInfo-&gt;exceptionHandler);
1461 
1462     for (const auto&amp; callSite : m_calls) {
1463         if (callSite.callee)
1464             patchBuffer.link(callSite.from, callSite.callee);
1465     }
1466     gen.finalize(patchBuffer, patchBuffer);
1467 
1468     byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1469         m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1470         &quot;Baseline put_by_val%s with cached property name &#39;%s&#39; stub for %s, return point %p&quot;, (putKind == Direct) ? &quot;_direct&quot; : &quot;&quot;, propertyName.impl()-&gt;utf8().data(), toCString(*m_codeBlock).data(), returnAddress.value());
1471     byValInfo-&gt;stubInfo = gen.stubInfo();
1472 
1473     MacroAssembler::repatchJump(byValInfo-&gt;notIndexJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));
1474     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(putKind == Direct ? operationDirectPutByValGeneric : operationPutByValGeneric));
1475 }




1476 
1477 JIT::JumpList JIT::emitDoubleLoad(const Instruction*, PatchableJump&amp; badType)
1478 {
1479 #if USE(JSVALUE64)
1480     RegisterID base = regT0;
1481     RegisterID property = regT1;
1482     RegisterID indexing = regT2;
1483     RegisterID scratch = regT3;
1484 #else
1485     RegisterID base = regT0;
1486     RegisterID property = regT2;
1487     RegisterID indexing = regT1;
1488     RegisterID scratch = regT3;
1489 #endif
1490 
1491     JumpList slowCases;
1492 
1493     badType = patchableBranch32(NotEqual, indexing, TrustedImm32(DoubleShape));
1494     loadPtr(Address(base, JSObject::butterflyOffset()), scratch);
1495     slowCases.append(branch32(AboveOrEqual, property, Address(scratch, Butterfly::offsetOfPublicLength())));
</pre>
<hr />
<pre>
1643 
1644 #if USE(JSVALUE64)
1645     RegisterID base = regT0;
1646     RegisterID property = regT1;
1647     JSValueRegs result = JSValueRegs(regT0);
1648     RegisterID scratch = regT3;
1649     RegisterID scratch2 = regT4;
1650 #else
1651     RegisterID base = regT0;
1652     RegisterID property = regT2;
1653     JSValueRegs result = JSValueRegs(regT1, regT0);
1654     RegisterID scratch = regT3;
1655     RegisterID scratch2 = regT4;
1656 #endif
1657     RegisterID resultPayload = result.payloadGPR();
1658 
1659     JumpList slowCases;
1660 
1661     load8(Address(base, JSCell::typeInfoTypeOffset()), scratch);
1662     badType = patchableBranch32(NotEqual, scratch, TrustedImm32(typeForTypedArrayType(type)));
<span class="line-modified">1663     slowCases.append(branch32(AboveOrEqual, property, Address(base, JSArrayBufferView::offsetOfLength())));</span>

1664     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), scratch);
<span class="line-modified">1665     cageConditionally(Gigacage::Primitive, scratch, scratch2);</span>
1666 
1667     switch (elementSize(type)) {
1668     case 1:
1669         if (JSC::isSigned(type))
1670             load8SignedExtendTo32(BaseIndex(scratch, property, TimesOne), resultPayload);
1671         else
1672             load8(BaseIndex(scratch, property, TimesOne), resultPayload);
1673         break;
1674     case 2:
1675         if (JSC::isSigned(type))
1676             load16SignedExtendTo32(BaseIndex(scratch, property, TimesTwo), resultPayload);
1677         else
1678             load16(BaseIndex(scratch, property, TimesTwo), resultPayload);
1679         break;
1680     case 4:
1681         load32(BaseIndex(scratch, property, TimesFour), resultPayload);
1682         break;
1683     default:
1684         CRASH();
1685     }
</pre>
<hr />
<pre>
1706     ASSERT(isFloat(type));
1707 
1708 #if USE(JSVALUE64)
1709     RegisterID base = regT0;
1710     RegisterID property = regT1;
1711     JSValueRegs result = JSValueRegs(regT0);
1712     RegisterID scratch = regT3;
1713     RegisterID scratch2 = regT4;
1714 #else
1715     RegisterID base = regT0;
1716     RegisterID property = regT2;
1717     JSValueRegs result = JSValueRegs(regT1, regT0);
1718     RegisterID scratch = regT3;
1719     RegisterID scratch2 = regT4;
1720 #endif
1721 
1722     JumpList slowCases;
1723 
1724     load8(Address(base, JSCell::typeInfoTypeOffset()), scratch);
1725     badType = patchableBranch32(NotEqual, scratch, TrustedImm32(typeForTypedArrayType(type)));
<span class="line-modified">1726     slowCases.append(branch32(AboveOrEqual, property, Address(base, JSArrayBufferView::offsetOfLength())));</span>

1727     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), scratch);
<span class="line-modified">1728     cageConditionally(Gigacage::Primitive, scratch, scratch2);</span>
1729 
1730     switch (elementSize(type)) {
1731     case 4:
1732         loadFloat(BaseIndex(scratch, property, TimesFour), fpRegT0);
1733         convertFloatToDouble(fpRegT0, fpRegT0);
1734         break;
1735     case 8: {
1736         loadDouble(BaseIndex(scratch, property, TimesEight), fpRegT0);
1737         break;
1738     }
1739     default:
1740         CRASH();
1741     }
1742 
1743     purifyNaN(fpRegT0);
1744 
1745     boxDouble(fpRegT0, result);
1746     return slowCases;
1747 }
1748 
</pre>
<hr />
<pre>
1756     int value = bytecode.m_value.offset();
1757 
1758 #if USE(JSVALUE64)
1759     RegisterID base = regT0;
1760     RegisterID property = regT1;
1761     RegisterID earlyScratch = regT3;
1762     RegisterID lateScratch = regT2;
1763     RegisterID lateScratch2 = regT4;
1764 #else
1765     RegisterID base = regT0;
1766     RegisterID property = regT2;
1767     RegisterID earlyScratch = regT3;
1768     RegisterID lateScratch = regT1;
1769     RegisterID lateScratch2 = regT4;
1770 #endif
1771 
1772     JumpList slowCases;
1773 
1774     load8(Address(base, JSCell::typeInfoTypeOffset()), earlyScratch);
1775     badType = patchableBranch32(NotEqual, earlyScratch, TrustedImm32(typeForTypedArrayType(type)));
<span class="line-modified">1776     Jump inBounds = branch32(Below, property, Address(base, JSArrayBufferView::offsetOfLength()));</span>

1777     emitArrayProfileOutOfBoundsSpecialCase(profile);
1778     slowCases.append(jump());
1779     inBounds.link(this);
1780 
1781 #if USE(JSVALUE64)
1782     emitGetVirtualRegister(value, earlyScratch);
1783     slowCases.append(branchIfNotInt32(earlyScratch));
1784 #else
1785     emitLoad(value, lateScratch, earlyScratch);
1786     slowCases.append(branchIfNotInt32(lateScratch));
1787 #endif
1788 
1789     // We would be loading this into base as in get_by_val, except that the slow
1790     // path expects the base to be unclobbered.
1791     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), lateScratch);
<span class="line-modified">1792     cageConditionally(Gigacage::Primitive, lateScratch, lateScratch2);</span>
1793 
1794     if (isClamped(type)) {
1795         ASSERT(elementSize(type) == 1);
1796         ASSERT(!JSC::isSigned(type));
1797         Jump inBounds = branch32(BelowOrEqual, earlyScratch, TrustedImm32(0xff));
1798         Jump tooBig = branch32(GreaterThan, earlyScratch, TrustedImm32(0xff));
1799         xor32(earlyScratch, earlyScratch);
1800         Jump clamped = jump();
1801         tooBig.link(this);
1802         move(TrustedImm32(0xff), earlyScratch);
1803         clamped.link(this);
1804         inBounds.link(this);
1805     }
1806 
1807     switch (elementSize(type)) {
1808     case 1:
1809         store8(earlyScratch, BaseIndex(lateScratch, property, TimesOne));
1810         break;
1811     case 2:
1812         store16(earlyScratch, BaseIndex(lateScratch, property, TimesTwo));
</pre>
<hr />
<pre>
1831     int value = bytecode.m_value.offset();
1832 
1833 #if USE(JSVALUE64)
1834     RegisterID base = regT0;
1835     RegisterID property = regT1;
1836     RegisterID earlyScratch = regT3;
1837     RegisterID lateScratch = regT2;
1838     RegisterID lateScratch2 = regT4;
1839 #else
1840     RegisterID base = regT0;
1841     RegisterID property = regT2;
1842     RegisterID earlyScratch = regT3;
1843     RegisterID lateScratch = regT1;
1844     RegisterID lateScratch2 = regT4;
1845 #endif
1846 
1847     JumpList slowCases;
1848 
1849     load8(Address(base, JSCell::typeInfoTypeOffset()), earlyScratch);
1850     badType = patchableBranch32(NotEqual, earlyScratch, TrustedImm32(typeForTypedArrayType(type)));
<span class="line-modified">1851     Jump inBounds = branch32(Below, property, Address(base, JSArrayBufferView::offsetOfLength()));</span>

1852     emitArrayProfileOutOfBoundsSpecialCase(profile);
1853     slowCases.append(jump());
1854     inBounds.link(this);
1855 
1856 #if USE(JSVALUE64)
1857     emitGetVirtualRegister(value, earlyScratch);
1858     Jump doubleCase = branchIfNotInt32(earlyScratch);
1859     convertInt32ToDouble(earlyScratch, fpRegT0);
1860     Jump ready = jump();
1861     doubleCase.link(this);
1862     slowCases.append(branchIfNotNumber(earlyScratch));
1863     add64(tagTypeNumberRegister, earlyScratch);
1864     move64ToDouble(earlyScratch, fpRegT0);
1865     ready.link(this);
1866 #else
1867     emitLoad(value, lateScratch, earlyScratch);
1868     Jump doubleCase = branchIfNotInt32(lateScratch);
1869     convertInt32ToDouble(earlyScratch, fpRegT0);
1870     Jump ready = jump();
1871     doubleCase.link(this);
1872     slowCases.append(branch32(Above, lateScratch, TrustedImm32(JSValue::LowestTag)));
1873     moveIntsToDouble(earlyScratch, lateScratch, fpRegT0, fpRegT1);
1874     ready.link(this);
1875 #endif
1876 
1877     // We would be loading this into base as in get_by_val, except that the slow
1878     // path expects the base to be unclobbered.
1879     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), lateScratch);
<span class="line-modified">1880     cageConditionally(Gigacage::Primitive, lateScratch, lateScratch2);</span>
1881 
1882     switch (elementSize(type)) {
1883     case 4:
1884         convertDoubleToFloat(fpRegT0, fpRegT0);
1885         storeFloat(fpRegT0, BaseIndex(lateScratch, property, TimesFour));
1886         break;
1887     case 8:
1888         storeDouble(fpRegT0, BaseIndex(lateScratch, property, TimesEight));
1889         break;
1890     default:
1891         CRASH();
1892     }
1893 
1894     return slowCases;
1895 }
1896 
1897 template void JIT::emit_op_put_by_val&lt;OpPutByVal&gt;(const Instruction*);
1898 
1899 } // namespace JSC
1900 
</pre>
</td>
<td>
<hr />
<pre>
  27 
  28 #if ENABLE(JIT)
  29 #include &quot;JIT.h&quot;
  30 
  31 #include &quot;CodeBlock.h&quot;
  32 #include &quot;DirectArguments.h&quot;
  33 #include &quot;GCAwareJITStubRoutine.h&quot;
  34 #include &quot;GetterSetter.h&quot;
  35 #include &quot;InterpreterInlines.h&quot;
  36 #include &quot;JITInlines.h&quot;
  37 #include &quot;JSArray.h&quot;
  38 #include &quot;JSFunction.h&quot;
  39 #include &quot;JSLexicalEnvironment.h&quot;
  40 #include &quot;LinkBuffer.h&quot;
  41 #include &quot;OpcodeInlines.h&quot;
  42 #include &quot;ResultType.h&quot;
  43 #include &quot;ScopedArguments.h&quot;
  44 #include &quot;ScopedArgumentsTable.h&quot;
  45 #include &quot;SlowPathCall.h&quot;
  46 #include &quot;StructureStubInfo.h&quot;
<span class="line-added">  47 #include &quot;ThunkGenerators.h&quot;</span>
  48 #include &lt;wtf/ScopedLambda.h&gt;
  49 #include &lt;wtf/StringPrintStream.h&gt;
  50 
  51 
  52 namespace JSC {
  53 #if USE(JSVALUE64)
  54 
  55 void JIT::emit_op_get_by_val(const Instruction* currentInstruction)
  56 {
  57     auto bytecode = currentInstruction-&gt;as&lt;OpGetByVal&gt;();
  58     auto&amp; metadata = bytecode.metadata(m_codeBlock);
  59     int dst = bytecode.m_dst.offset();
  60     int base = bytecode.m_base.offset();
  61     int property = bytecode.m_property.offset();
  62     ArrayProfile* profile = &amp;metadata.m_arrayProfile;
  63     ByValInfo* byValInfo = m_codeBlock-&gt;addByValInfo();
  64 
  65     emitGetVirtualRegister(base, regT0);
  66     bool propertyNameIsIntegerConstant = isOperandConstantInt(property);
  67     if (propertyNameIsIntegerConstant)
</pre>
<hr />
<pre>
 566     Label coldPathBegin = label();
 567 
 568     Call call = callOperationWithProfile(bytecode.metadata(m_codeBlock), operationGetByIdDirectOptimize, resultVReg, gen.stubInfo(), regT0, ident-&gt;impl());
 569 
 570     gen.reportSlowPathCall(coldPathBegin, call);
 571 }
 572 
 573 void JIT::emit_op_get_by_id(const Instruction* currentInstruction)
 574 {
 575     auto bytecode = currentInstruction-&gt;as&lt;OpGetById&gt;();
 576     auto&amp; metadata = bytecode.metadata(m_codeBlock);
 577     int resultVReg = bytecode.m_dst.offset();
 578     int baseVReg = bytecode.m_base.offset();
 579     const Identifier* ident = &amp;(m_codeBlock-&gt;identifier(bytecode.m_property));
 580 
 581     emitGetVirtualRegister(baseVReg, regT0);
 582 
 583     emitJumpSlowCaseIfNotJSCell(regT0, baseVReg);
 584 
 585     if (*ident == m_vm-&gt;propertyNames-&gt;length &amp;&amp; shouldEmitProfiling()) {
<span class="line-modified"> 586         Jump notArrayLengthMode = branch8(NotEqual, AbsoluteAddress(&amp;metadata.m_modeMetadata.mode), TrustedImm32(static_cast&lt;uint8_t&gt;(GetByIdMode::ArrayLength)));</span>
 587         emitArrayProfilingSiteWithCell(regT0, regT1, &amp;metadata.m_modeMetadata.arrayLengthMode.arrayProfile);
 588         notArrayLengthMode.link(this);
 589     }
 590 
 591     JITGetByIdGenerator gen(
 592         m_codeBlock, CodeOrigin(m_bytecodeOffset), CallSiteIndex(m_bytecodeOffset), RegisterSet::stubUnavailableRegisters(),
 593         ident-&gt;impl(), JSValueRegs(regT0), JSValueRegs(regT0), AccessType::Get);
 594     gen.generateFastPath(*this);
 595     addSlowCase(gen.slowPathJump());
 596     m_getByIds.append(gen);
 597 
 598     emitValueProfilingSite(bytecode.metadata(m_codeBlock));
 599     emitPutVirtualRegister(resultVReg);
 600 }
 601 
 602 void JIT::emit_op_get_by_id_with_this(const Instruction* currentInstruction)
 603 {
 604     auto bytecode = currentInstruction-&gt;as&lt;OpGetByIdWithThis&gt;();
 605     int resultVReg = bytecode.m_dst.offset();
 606     int baseVReg = bytecode.m_base.offset();
</pre>
<hr />
<pre>
1195     emitGetVirtualRegister(arguments, regT0);
1196     emitGetVirtualRegister(value, regT1);
1197     store64(regT1, Address(regT0, DirectArguments::storageOffset() + index * sizeof(WriteBarrier&lt;Unknown&gt;)));
1198 
1199     emitWriteBarrier(arguments, value, ShouldFilterValue);
1200 }
1201 
1202 void JIT::emitWriteBarrier(unsigned owner, unsigned value, WriteBarrierMode mode)
1203 {
1204     Jump valueNotCell;
1205     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue) {
1206         emitGetVirtualRegister(value, regT0);
1207         valueNotCell = branchIfNotCell(regT0);
1208     }
1209 
1210     emitGetVirtualRegister(owner, regT0);
1211     Jump ownerNotCell;
1212     if (mode == ShouldFilterBaseAndValue || mode == ShouldFilterBase)
1213         ownerNotCell = branchIfNotCell(regT0);
1214 
<span class="line-modified">1215     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), regT0, regT1);</span>
1216     callOperation(operationWriteBarrierSlowPath, regT0);
1217     ownerIsRememberedOrInEden.link(this);
1218 
1219     if (mode == ShouldFilterBaseAndValue || mode == ShouldFilterBase)
1220         ownerNotCell.link(this);
1221     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue)
1222         valueNotCell.link(this);
1223 }
1224 
1225 void JIT::emitWriteBarrier(JSCell* owner, unsigned value, WriteBarrierMode mode)
1226 {
1227     emitGetVirtualRegister(value, regT0);
1228     Jump valueNotCell;
1229     if (mode == ShouldFilterValue)
1230         valueNotCell = branchIfNotCell(regT0);
1231 
1232     emitWriteBarrier(owner);
1233 
1234     if (mode == ShouldFilterValue)
1235         valueNotCell.link(this);
1236 }
1237 
1238 #else // USE(JSVALUE64)
1239 
1240 void JIT::emitWriteBarrier(unsigned owner, unsigned value, WriteBarrierMode mode)
1241 {
1242     Jump valueNotCell;
1243     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue) {
1244         emitLoadTag(value, regT0);
1245         valueNotCell = branchIfNotCell(regT0);
1246     }
1247 
1248     emitLoad(owner, regT0, regT1);
1249     Jump ownerNotCell;
1250     if (mode == ShouldFilterBase || mode == ShouldFilterBaseAndValue)
1251         ownerNotCell = branchIfNotCell(regT0);
1252 
<span class="line-modified">1253     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), regT1, regT2);</span>
1254     callOperation(operationWriteBarrierSlowPath, regT1);
1255     ownerIsRememberedOrInEden.link(this);
1256 
1257     if (mode == ShouldFilterBase || mode == ShouldFilterBaseAndValue)
1258         ownerNotCell.link(this);
1259     if (mode == ShouldFilterValue || mode == ShouldFilterBaseAndValue)
1260         valueNotCell.link(this);
1261 }
1262 
1263 void JIT::emitWriteBarrier(JSCell* owner, unsigned value, WriteBarrierMode mode)
1264 {
1265     Jump valueNotCell;
1266     if (mode == ShouldFilterValue) {
1267         emitLoadTag(value, regT0);
1268         valueNotCell = branchIfNotCell(regT0);
1269     }
1270 
1271     emitWriteBarrier(owner);
1272 
1273     if (mode == ShouldFilterValue)
1274         valueNotCell.link(this);
1275 }
1276 
1277 #endif // USE(JSVALUE64)
1278 
1279 void JIT::emitWriteBarrier(JSCell* owner)
1280 {
<span class="line-modified">1281     Jump ownerIsRememberedOrInEden = barrierBranch(vm(), owner, regT0);</span>
1282     callOperation(operationWriteBarrierSlowPath, owner);
1283     ownerIsRememberedOrInEden.link(this);
1284 }
1285 
1286 void JIT::emitByValIdentifierCheck(ByValInfo* byValInfo, RegisterID cell, RegisterID scratch, const Identifier&amp; propertyName, JumpList&amp; slowCases)
1287 {
1288     if (propertyName.isSymbol())
1289         slowCases.append(branchPtr(NotEqual, cell, TrustedImmPtr(byValInfo-&gt;cachedSymbol.get())));
1290     else {
1291         slowCases.append(branchIfNotString(cell));
1292         loadPtr(Address(cell, JSString::offsetOfValue()), scratch);
1293         slowCases.append(branchPtr(NotEqual, scratch, TrustedImmPtr(propertyName.impl())));
1294     }
1295 }
1296 
1297 void JIT::privateCompileGetByVal(const ConcurrentJSLocker&amp;, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)
1298 {
1299     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1300 
1301     PatchableJump badType;
</pre>
<hr />
<pre>
1423     patchBuffer.link(done, byValInfo-&gt;badTypeDoneTarget);
1424     if (needsLinkForWriteBarrier) {
1425         ASSERT(removeCodePtrTag(m_calls.last().callee.executableAddress()) == removeCodePtrTag(operationWriteBarrierSlowPath));
1426         patchBuffer.link(m_calls.last().from, m_calls.last().callee);
1427     }
1428 
1429     bool isDirect = currentInstruction-&gt;opcodeID() == op_put_by_val_direct;
1430     if (!isDirect) {
1431         byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1432             m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1433             &quot;Baseline put_by_val stub for %s, return point %p&quot;, toCString(*m_codeBlock).data(), returnAddress.value());
1434 
1435     } else {
1436         byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1437             m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1438             &quot;Baseline put_by_val_direct stub for %s, return point %p&quot;, toCString(*m_codeBlock).data(), returnAddress.value());
1439     }
1440     MacroAssembler::repatchJump(byValInfo-&gt;badTypeJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));
1441     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(isDirect ? operationDirectPutByValGeneric : operationPutByValGeneric));
1442 }
<span class="line-added">1443 // This function is only consumed from another translation unit (JITOperations.cpp),</span>
<span class="line-added">1444 // so we list off the two expected specializations in advance.</span>
<span class="line-added">1445 template void JIT::privateCompilePutByVal&lt;OpPutByVal&gt;(const ConcurrentJSLocker&amp;, ByValInfo*, ReturnAddressPtr, JITArrayMode);</span>
<span class="line-added">1446 template void JIT::privateCompilePutByVal&lt;OpPutByValDirect&gt;(const ConcurrentJSLocker&amp;, ByValInfo*, ReturnAddressPtr, JITArrayMode);</span>
1447 
1448 template&lt;typename Op&gt;
1449 void JIT::privateCompilePutByValWithCachedId(ByValInfo* byValInfo, ReturnAddressPtr returnAddress, PutKind putKind, const Identifier&amp; propertyName)
1450 {
1451     ASSERT((putKind == Direct &amp;&amp; Op::opcodeID == op_put_by_val_direct) || (putKind == NotDirect &amp;&amp; Op::opcodeID == op_put_by_val));
1452     const Instruction* currentInstruction = m_codeBlock-&gt;instructions().at(byValInfo-&gt;bytecodeIndex).ptr();
1453     auto bytecode = currentInstruction-&gt;as&lt;Op&gt;();
1454 
1455     JumpList doneCases;
1456     JumpList slowCases;
1457 
1458     JITPutByIdGenerator gen = emitPutByValWithCachedId(byValInfo, bytecode, putKind, propertyName, doneCases, slowCases);
1459 
1460     ConcurrentJSLocker locker(m_codeBlock-&gt;m_lock);
1461     LinkBuffer patchBuffer(*this, m_codeBlock);
1462     patchBuffer.link(slowCases, byValInfo-&gt;slowPathTarget);
1463     patchBuffer.link(doneCases, byValInfo-&gt;badTypeDoneTarget);
1464     if (!m_exceptionChecks.empty())
1465         patchBuffer.link(m_exceptionChecks, byValInfo-&gt;exceptionHandler);
1466 
1467     for (const auto&amp; callSite : m_calls) {
1468         if (callSite.callee)
1469             patchBuffer.link(callSite.from, callSite.callee);
1470     }
1471     gen.finalize(patchBuffer, patchBuffer);
1472 
1473     byValInfo-&gt;stubRoutine = FINALIZE_CODE_FOR_STUB(
1474         m_codeBlock, patchBuffer, JITStubRoutinePtrTag,
1475         &quot;Baseline put_by_val%s with cached property name &#39;%s&#39; stub for %s, return point %p&quot;, (putKind == Direct) ? &quot;_direct&quot; : &quot;&quot;, propertyName.impl()-&gt;utf8().data(), toCString(*m_codeBlock).data(), returnAddress.value());
1476     byValInfo-&gt;stubInfo = gen.stubInfo();
1477 
1478     MacroAssembler::repatchJump(byValInfo-&gt;notIndexJump, CodeLocationLabel&lt;JITStubRoutinePtrTag&gt;(byValInfo-&gt;stubRoutine-&gt;code().code()));
1479     MacroAssembler::repatchCall(CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)), FunctionPtr&lt;OperationPtrTag&gt;(putKind == Direct ? operationDirectPutByValGeneric : operationPutByValGeneric));
1480 }
<span class="line-added">1481 // This function is only consumed from another translation unit (JITOperations.cpp),</span>
<span class="line-added">1482 // so we list off the two expected specializations in advance.</span>
<span class="line-added">1483 template void JIT::privateCompilePutByValWithCachedId&lt;OpPutByVal&gt;(ByValInfo*, ReturnAddressPtr, PutKind, const Identifier&amp;);</span>
<span class="line-added">1484 template void JIT::privateCompilePutByValWithCachedId&lt;OpPutByValDirect&gt;(ByValInfo*, ReturnAddressPtr, PutKind, const Identifier&amp;);</span>
1485 
1486 JIT::JumpList JIT::emitDoubleLoad(const Instruction*, PatchableJump&amp; badType)
1487 {
1488 #if USE(JSVALUE64)
1489     RegisterID base = regT0;
1490     RegisterID property = regT1;
1491     RegisterID indexing = regT2;
1492     RegisterID scratch = regT3;
1493 #else
1494     RegisterID base = regT0;
1495     RegisterID property = regT2;
1496     RegisterID indexing = regT1;
1497     RegisterID scratch = regT3;
1498 #endif
1499 
1500     JumpList slowCases;
1501 
1502     badType = patchableBranch32(NotEqual, indexing, TrustedImm32(DoubleShape));
1503     loadPtr(Address(base, JSObject::butterflyOffset()), scratch);
1504     slowCases.append(branch32(AboveOrEqual, property, Address(scratch, Butterfly::offsetOfPublicLength())));
</pre>
<hr />
<pre>
1652 
1653 #if USE(JSVALUE64)
1654     RegisterID base = regT0;
1655     RegisterID property = regT1;
1656     JSValueRegs result = JSValueRegs(regT0);
1657     RegisterID scratch = regT3;
1658     RegisterID scratch2 = regT4;
1659 #else
1660     RegisterID base = regT0;
1661     RegisterID property = regT2;
1662     JSValueRegs result = JSValueRegs(regT1, regT0);
1663     RegisterID scratch = regT3;
1664     RegisterID scratch2 = regT4;
1665 #endif
1666     RegisterID resultPayload = result.payloadGPR();
1667 
1668     JumpList slowCases;
1669 
1670     load8(Address(base, JSCell::typeInfoTypeOffset()), scratch);
1671     badType = patchableBranch32(NotEqual, scratch, TrustedImm32(typeForTypedArrayType(type)));
<span class="line-modified">1672     load32(Address(base, JSArrayBufferView::offsetOfLength()), scratch2);</span>
<span class="line-added">1673     slowCases.append(branch32(AboveOrEqual, property, scratch2));</span>
1674     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), scratch);
<span class="line-modified">1675     cageConditionally(Gigacage::Primitive, scratch, scratch2, scratch2);</span>
1676 
1677     switch (elementSize(type)) {
1678     case 1:
1679         if (JSC::isSigned(type))
1680             load8SignedExtendTo32(BaseIndex(scratch, property, TimesOne), resultPayload);
1681         else
1682             load8(BaseIndex(scratch, property, TimesOne), resultPayload);
1683         break;
1684     case 2:
1685         if (JSC::isSigned(type))
1686             load16SignedExtendTo32(BaseIndex(scratch, property, TimesTwo), resultPayload);
1687         else
1688             load16(BaseIndex(scratch, property, TimesTwo), resultPayload);
1689         break;
1690     case 4:
1691         load32(BaseIndex(scratch, property, TimesFour), resultPayload);
1692         break;
1693     default:
1694         CRASH();
1695     }
</pre>
<hr />
<pre>
1716     ASSERT(isFloat(type));
1717 
1718 #if USE(JSVALUE64)
1719     RegisterID base = regT0;
1720     RegisterID property = regT1;
1721     JSValueRegs result = JSValueRegs(regT0);
1722     RegisterID scratch = regT3;
1723     RegisterID scratch2 = regT4;
1724 #else
1725     RegisterID base = regT0;
1726     RegisterID property = regT2;
1727     JSValueRegs result = JSValueRegs(regT1, regT0);
1728     RegisterID scratch = regT3;
1729     RegisterID scratch2 = regT4;
1730 #endif
1731 
1732     JumpList slowCases;
1733 
1734     load8(Address(base, JSCell::typeInfoTypeOffset()), scratch);
1735     badType = patchableBranch32(NotEqual, scratch, TrustedImm32(typeForTypedArrayType(type)));
<span class="line-modified">1736     load32(Address(base, JSArrayBufferView::offsetOfLength()), scratch2);</span>
<span class="line-added">1737     slowCases.append(branch32(AboveOrEqual, property, scratch2));</span>
1738     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), scratch);
<span class="line-modified">1739     cageConditionally(Gigacage::Primitive, scratch, scratch2, scratch2);</span>
1740 
1741     switch (elementSize(type)) {
1742     case 4:
1743         loadFloat(BaseIndex(scratch, property, TimesFour), fpRegT0);
1744         convertFloatToDouble(fpRegT0, fpRegT0);
1745         break;
1746     case 8: {
1747         loadDouble(BaseIndex(scratch, property, TimesEight), fpRegT0);
1748         break;
1749     }
1750     default:
1751         CRASH();
1752     }
1753 
1754     purifyNaN(fpRegT0);
1755 
1756     boxDouble(fpRegT0, result);
1757     return slowCases;
1758 }
1759 
</pre>
<hr />
<pre>
1767     int value = bytecode.m_value.offset();
1768 
1769 #if USE(JSVALUE64)
1770     RegisterID base = regT0;
1771     RegisterID property = regT1;
1772     RegisterID earlyScratch = regT3;
1773     RegisterID lateScratch = regT2;
1774     RegisterID lateScratch2 = regT4;
1775 #else
1776     RegisterID base = regT0;
1777     RegisterID property = regT2;
1778     RegisterID earlyScratch = regT3;
1779     RegisterID lateScratch = regT1;
1780     RegisterID lateScratch2 = regT4;
1781 #endif
1782 
1783     JumpList slowCases;
1784 
1785     load8(Address(base, JSCell::typeInfoTypeOffset()), earlyScratch);
1786     badType = patchableBranch32(NotEqual, earlyScratch, TrustedImm32(typeForTypedArrayType(type)));
<span class="line-modified">1787     load32(Address(base, JSArrayBufferView::offsetOfLength()), lateScratch2);</span>
<span class="line-added">1788     Jump inBounds = branch32(Below, property, lateScratch2);</span>
1789     emitArrayProfileOutOfBoundsSpecialCase(profile);
1790     slowCases.append(jump());
1791     inBounds.link(this);
1792 
1793 #if USE(JSVALUE64)
1794     emitGetVirtualRegister(value, earlyScratch);
1795     slowCases.append(branchIfNotInt32(earlyScratch));
1796 #else
1797     emitLoad(value, lateScratch, earlyScratch);
1798     slowCases.append(branchIfNotInt32(lateScratch));
1799 #endif
1800 
1801     // We would be loading this into base as in get_by_val, except that the slow
1802     // path expects the base to be unclobbered.
1803     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), lateScratch);
<span class="line-modified">1804     cageConditionally(Gigacage::Primitive, lateScratch, lateScratch2, lateScratch2);</span>
1805 
1806     if (isClamped(type)) {
1807         ASSERT(elementSize(type) == 1);
1808         ASSERT(!JSC::isSigned(type));
1809         Jump inBounds = branch32(BelowOrEqual, earlyScratch, TrustedImm32(0xff));
1810         Jump tooBig = branch32(GreaterThan, earlyScratch, TrustedImm32(0xff));
1811         xor32(earlyScratch, earlyScratch);
1812         Jump clamped = jump();
1813         tooBig.link(this);
1814         move(TrustedImm32(0xff), earlyScratch);
1815         clamped.link(this);
1816         inBounds.link(this);
1817     }
1818 
1819     switch (elementSize(type)) {
1820     case 1:
1821         store8(earlyScratch, BaseIndex(lateScratch, property, TimesOne));
1822         break;
1823     case 2:
1824         store16(earlyScratch, BaseIndex(lateScratch, property, TimesTwo));
</pre>
<hr />
<pre>
1843     int value = bytecode.m_value.offset();
1844 
1845 #if USE(JSVALUE64)
1846     RegisterID base = regT0;
1847     RegisterID property = regT1;
1848     RegisterID earlyScratch = regT3;
1849     RegisterID lateScratch = regT2;
1850     RegisterID lateScratch2 = regT4;
1851 #else
1852     RegisterID base = regT0;
1853     RegisterID property = regT2;
1854     RegisterID earlyScratch = regT3;
1855     RegisterID lateScratch = regT1;
1856     RegisterID lateScratch2 = regT4;
1857 #endif
1858 
1859     JumpList slowCases;
1860 
1861     load8(Address(base, JSCell::typeInfoTypeOffset()), earlyScratch);
1862     badType = patchableBranch32(NotEqual, earlyScratch, TrustedImm32(typeForTypedArrayType(type)));
<span class="line-modified">1863     load32(Address(base, JSArrayBufferView::offsetOfLength()), lateScratch2);</span>
<span class="line-added">1864     Jump inBounds = branch32(Below, property, lateScratch2);</span>
1865     emitArrayProfileOutOfBoundsSpecialCase(profile);
1866     slowCases.append(jump());
1867     inBounds.link(this);
1868 
1869 #if USE(JSVALUE64)
1870     emitGetVirtualRegister(value, earlyScratch);
1871     Jump doubleCase = branchIfNotInt32(earlyScratch);
1872     convertInt32ToDouble(earlyScratch, fpRegT0);
1873     Jump ready = jump();
1874     doubleCase.link(this);
1875     slowCases.append(branchIfNotNumber(earlyScratch));
1876     add64(tagTypeNumberRegister, earlyScratch);
1877     move64ToDouble(earlyScratch, fpRegT0);
1878     ready.link(this);
1879 #else
1880     emitLoad(value, lateScratch, earlyScratch);
1881     Jump doubleCase = branchIfNotInt32(lateScratch);
1882     convertInt32ToDouble(earlyScratch, fpRegT0);
1883     Jump ready = jump();
1884     doubleCase.link(this);
1885     slowCases.append(branch32(Above, lateScratch, TrustedImm32(JSValue::LowestTag)));
1886     moveIntsToDouble(earlyScratch, lateScratch, fpRegT0, fpRegT1);
1887     ready.link(this);
1888 #endif
1889 
1890     // We would be loading this into base as in get_by_val, except that the slow
1891     // path expects the base to be unclobbered.
1892     loadPtr(Address(base, JSArrayBufferView::offsetOfVector()), lateScratch);
<span class="line-modified">1893     cageConditionally(Gigacage::Primitive, lateScratch, lateScratch2, lateScratch2);</span>
1894 
1895     switch (elementSize(type)) {
1896     case 4:
1897         convertDoubleToFloat(fpRegT0, fpRegT0);
1898         storeFloat(fpRegT0, BaseIndex(lateScratch, property, TimesFour));
1899         break;
1900     case 8:
1901         storeDouble(fpRegT0, BaseIndex(lateScratch, property, TimesEight));
1902         break;
1903     default:
1904         CRASH();
1905     }
1906 
1907     return slowCases;
1908 }
1909 
1910 template void JIT::emit_op_put_by_val&lt;OpPutByVal&gt;(const Instruction*);
1911 
1912 } // namespace JSC
1913 
</pre>
</td>
</tr>
</table>
<center><a href="JITOperations.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITPropertyAccess32_64.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>