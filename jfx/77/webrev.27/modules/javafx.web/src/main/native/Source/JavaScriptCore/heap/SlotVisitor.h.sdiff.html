<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/SlotVisitor.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="SlotVisitor.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="SlotVisitorInlines.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/SlotVisitor.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (C) 2011-2018 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
 14  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 15  * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
 17  * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 18  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 19  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 20  * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 21  * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 22  * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 23  * THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;HandleTypes.h&quot;
 29 #include &quot;IterationStatus.h&quot;
 30 #include &quot;MarkStack.h&quot;
 31 #include &quot;VisitRaceKey.h&quot;
 32 #include &lt;wtf/Forward.h&gt;
 33 #include &lt;wtf/MonotonicTime.h&gt;
 34 #include &lt;wtf/SharedTask.h&gt;
 35 #include &lt;wtf/text/CString.h&gt;
 36 
 37 namespace JSC {
 38 
 39 class ConservativeRoots;
 40 class GCThreadSharedData;
 41 class Heap;
 42 class HeapCell;
<span class="line-modified"> 43 class HeapSnapshotBuilder;</span>
 44 class MarkedBlock;
 45 class MarkingConstraint;
 46 class MarkingConstraintSolver;
 47 template&lt;typename T&gt; class Weak;
 48 template&lt;typename T, typename Traits&gt; class WriteBarrierBase;
 49 
 50 typedef uint32_t HeapVersion;
 51 
 52 class SlotVisitor {
 53     WTF_MAKE_NONCOPYABLE(SlotVisitor);
 54     WTF_MAKE_FAST_ALLOCATED;
 55 
 56     friend class SetCurrentCellScope;
 57     friend class Heap;
 58 
 59 public:
 60     enum RootMarkReason {
 61         None,
 62         ConservativeScan,
 63         StrongReferences,
</pre>
<hr />
<pre>
102     //   friends).
103     //
104     // If you are not a root and you don&#39;t know what kind of barrier you have, then you
105     // shouldn&#39;t call these methods.
106     void appendUnbarriered(JSValue);
107     void appendUnbarriered(JSValue*, size_t);
108     void appendUnbarriered(JSCell*);
109 
110     template&lt;typename T&gt;
111     void append(const Weak&lt;T&gt;&amp; weak);
112 
113     void appendHiddenUnbarriered(JSValue);
114     void appendHiddenUnbarriered(JSCell*);
115 
116     bool addOpaqueRoot(void*); // Returns true if the root was new.
117 
118     bool containsOpaqueRoot(void*) const;
119 
120     bool isEmpty() { return m_collectorStack.isEmpty() &amp;&amp; m_mutatorStack.isEmpty(); }
121 


122     void didStartMarking();
123     void reset();
124     void clearMarkStacks();
125 
126     size_t bytesVisited() const { return m_bytesVisited; }
127     size_t visitCount() const { return m_visitCount; }
128 
129     void addToVisitCount(size_t value) { m_visitCount += value; }
130 
131     void donate();
132     void drain(MonotonicTime timeout = MonotonicTime::infinity());
133     void donateAndDrain(MonotonicTime timeout = MonotonicTime::infinity());
134 
135     enum SharedDrainMode { SlaveDrain, MasterDrain };
136     enum class SharedDrainResult { Done, TimedOut };
137     SharedDrainResult drainFromShared(SharedDrainMode, MonotonicTime timeout = MonotonicTime::infinity());
138 
139     SharedDrainResult drainInParallel(MonotonicTime timeout = MonotonicTime::infinity());
140     SharedDrainResult drainInParallelPassively(MonotonicTime timeout = MonotonicTime::infinity());
141 
142     SharedDrainResult waitForTermination(MonotonicTime timeout = MonotonicTime::infinity());
143 
144     // Attempts to perform an increment of draining that involves only walking `bytes` worth of data. This
145     // is likely to accidentally walk more or less than that. It will usually mark more than bytes. It may
146     // mark less than bytes if we&#39;re reaching termination or if the global worklist is empty (which may in
147     // rare cases happen temporarily even if we&#39;re not reaching termination).
148     size_t performIncrementOfDraining(size_t bytes);
149 
150     // This informs the GC about auxiliary of some size that we are keeping alive. If you don&#39;t do
151     // this then the space will be freed at end of GC.
152     void markAuxiliary(const void* base);
153 
154     void reportExtraMemoryVisited(size_t);
155 #if ENABLE(RESOURCE_USAGE)
156     void reportExternalMemoryVisited(size_t);
157 #endif
158 
159     void dump(PrintStream&amp;) const;
160 
<span class="line-modified">161     bool isBuildingHeapSnapshot() const { return !!m_heapSnapshotBuilder; }</span>
<span class="line-modified">162     HeapSnapshotBuilder* heapSnapshotBuilder() const { return m_heapSnapshotBuilder; }</span>
163 
164     RootMarkReason rootMarkReason() const { return m_rootMarkReason; }
165     void setRootMarkReason(RootMarkReason reason) { m_rootMarkReason = reason; }
166 
167     HeapVersion markingVersion() const { return m_markingVersion; }
168 
169     bool mutatorIsStopped() const { return m_mutatorIsStopped; }
170 
171     Lock&amp; rightToRun() { return m_rightToRun; }
172 
173     void updateMutatorIsStopped(const AbstractLocker&amp;);
174     void updateMutatorIsStopped();
175 
176     bool hasAcknowledgedThatTheMutatorIsResumed() const;
177     bool mutatorIsStoppedIsUpToDate() const;
178 
179     void optimizeForStoppedMutator();
180 
181     void didRace(const VisitRaceKey&amp;);
182     void didRace(JSCell* cell, const char* reason) { didRace(VisitRaceKey(cell, reason)); }
</pre>
<hr />
<pre>
194     JS_EXPORT_PRIVATE void addParallelConstraintTask(RefPtr&lt;SharedTask&lt;void(SlotVisitor&amp;)&gt;&gt;);
195 
196 private:
197     friend class ParallelModeEnabler;
198     friend class MarkingConstraintSolver;
199 
200     void appendJSCellOrAuxiliary(HeapCell*);
201 
202     JS_EXPORT_PRIVATE void appendSlow(JSCell*, Dependency);
203     JS_EXPORT_PRIVATE void appendHiddenSlow(JSCell*, Dependency);
204     void appendHiddenSlowImpl(JSCell*, Dependency);
205 
206     template&lt;typename ContainerType&gt;
207     void setMarkedAndAppendToMarkStack(ContainerType&amp;, JSCell*, Dependency);
208 
209     void appendToMarkStack(JSCell*);
210 
211     template&lt;typename ContainerType&gt;
212     void appendToMarkStack(ContainerType&amp;, JSCell*);
213 
<span class="line-removed">214     void appendToMutatorMarkStack(const JSCell*);</span>
<span class="line-removed">215 </span>
216     void noteLiveAuxiliaryCell(HeapCell*);
217 
218     void visitChildren(const JSCell*);
219 
220     void propagateExternalMemoryVisitedIfNecessary();
221 
222     void donateKnownParallel();
223     void donateKnownParallel(MarkStackArray&amp; from, MarkStackArray&amp; to);
224 
225     void donateAll(const AbstractLocker&amp;);
226 
227     bool hasWork(const AbstractLocker&amp;);
228     bool didReachTermination(const AbstractLocker&amp;);
229 




230     template&lt;typename Func&gt;
231     IterationStatus forEachMarkStack(const Func&amp;);
232 
233     MarkStackArray&amp; correspondingGlobalStack(MarkStackArray&amp;);
234 
235     MarkStackArray m_collectorStack;
236     MarkStackArray m_mutatorStack;
<span class="line-removed">237     bool m_ignoreNewOpaqueRoots { false }; // Useful as a debugging mode.</span>
238 
239     size_t m_bytesVisited;
240     size_t m_visitCount;
241     size_t m_nonCellVisitCount { 0 }; // Used for incremental draining, ignored otherwise.
242     Checked&lt;size_t, RecordOverflow&gt; m_extraMemorySize { 0 };
243     bool m_isInParallelMode;

244 
245     HeapVersion m_markingVersion;
246 
247     Heap&amp; m_heap;
248 
<span class="line-modified">249     HeapSnapshotBuilder* m_heapSnapshotBuilder { nullptr };</span>
250     JSCell* m_currentCell { nullptr };
251     RootMarkReason m_rootMarkReason { RootMarkReason::None };
252     bool m_isFirstVisit { false };
253     bool m_mutatorIsStopped { false };
254     bool m_canOptimizeForStoppedMutator { false };
255     Lock m_rightToRun;
256 
257     CString m_codeName;
258 
259     MarkingConstraint* m_currentConstraint { nullptr };
260     MarkingConstraintSolver* m_currentSolver { nullptr };
261 


262 public:
263 #if !ASSERT_DISABLED
264     bool m_isCheckingForDefaultMarkViolation;
265     bool m_isDraining;
266 #endif
267 };
268 
269 class ParallelModeEnabler {
270 public:
271     ParallelModeEnabler(SlotVisitor&amp; stack)
272         : m_stack(stack)
273     {
274         ASSERT(!m_stack.m_isInParallelMode);
275         m_stack.m_isInParallelMode = true;
276     }
277 
278     ~ParallelModeEnabler()
279     {
280         ASSERT(m_stack.m_isInParallelMode);
281         m_stack.m_isInParallelMode = false;
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
 14  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 15  * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
 17  * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 18  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 19  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 20  * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 21  * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 22  * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 23  * THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;HandleTypes.h&quot;
 29 #include &quot;IterationStatus.h&quot;
 30 #include &quot;MarkStack.h&quot;
 31 #include &quot;VisitRaceKey.h&quot;
 32 #include &lt;wtf/Forward.h&gt;
 33 #include &lt;wtf/MonotonicTime.h&gt;
 34 #include &lt;wtf/SharedTask.h&gt;
 35 #include &lt;wtf/text/CString.h&gt;
 36 
 37 namespace JSC {
 38 
 39 class ConservativeRoots;
 40 class GCThreadSharedData;
 41 class Heap;
 42 class HeapCell;
<span class="line-modified"> 43 class HeapAnalyzer;</span>
 44 class MarkedBlock;
 45 class MarkingConstraint;
 46 class MarkingConstraintSolver;
 47 template&lt;typename T&gt; class Weak;
 48 template&lt;typename T, typename Traits&gt; class WriteBarrierBase;
 49 
 50 typedef uint32_t HeapVersion;
 51 
 52 class SlotVisitor {
 53     WTF_MAKE_NONCOPYABLE(SlotVisitor);
 54     WTF_MAKE_FAST_ALLOCATED;
 55 
 56     friend class SetCurrentCellScope;
 57     friend class Heap;
 58 
 59 public:
 60     enum RootMarkReason {
 61         None,
 62         ConservativeScan,
 63         StrongReferences,
</pre>
<hr />
<pre>
102     //   friends).
103     //
104     // If you are not a root and you don&#39;t know what kind of barrier you have, then you
105     // shouldn&#39;t call these methods.
106     void appendUnbarriered(JSValue);
107     void appendUnbarriered(JSValue*, size_t);
108     void appendUnbarriered(JSCell*);
109 
110     template&lt;typename T&gt;
111     void append(const Weak&lt;T&gt;&amp; weak);
112 
113     void appendHiddenUnbarriered(JSValue);
114     void appendHiddenUnbarriered(JSCell*);
115 
116     bool addOpaqueRoot(void*); // Returns true if the root was new.
117 
118     bool containsOpaqueRoot(void*) const;
119 
120     bool isEmpty() { return m_collectorStack.isEmpty() &amp;&amp; m_mutatorStack.isEmpty(); }
121 
<span class="line-added">122     bool isFirstVisit() const { return m_isFirstVisit; }</span>
<span class="line-added">123 </span>
124     void didStartMarking();
125     void reset();
126     void clearMarkStacks();
127 
128     size_t bytesVisited() const { return m_bytesVisited; }
129     size_t visitCount() const { return m_visitCount; }
130 
131     void addToVisitCount(size_t value) { m_visitCount += value; }
132 
133     void donate();
134     void drain(MonotonicTime timeout = MonotonicTime::infinity());
135     void donateAndDrain(MonotonicTime timeout = MonotonicTime::infinity());
136 
137     enum SharedDrainMode { SlaveDrain, MasterDrain };
138     enum class SharedDrainResult { Done, TimedOut };
139     SharedDrainResult drainFromShared(SharedDrainMode, MonotonicTime timeout = MonotonicTime::infinity());
140 
141     SharedDrainResult drainInParallel(MonotonicTime timeout = MonotonicTime::infinity());
142     SharedDrainResult drainInParallelPassively(MonotonicTime timeout = MonotonicTime::infinity());
143 
144     SharedDrainResult waitForTermination(MonotonicTime timeout = MonotonicTime::infinity());
145 
146     // Attempts to perform an increment of draining that involves only walking `bytes` worth of data. This
147     // is likely to accidentally walk more or less than that. It will usually mark more than bytes. It may
148     // mark less than bytes if we&#39;re reaching termination or if the global worklist is empty (which may in
149     // rare cases happen temporarily even if we&#39;re not reaching termination).
150     size_t performIncrementOfDraining(size_t bytes);
151 
152     // This informs the GC about auxiliary of some size that we are keeping alive. If you don&#39;t do
153     // this then the space will be freed at end of GC.
154     void markAuxiliary(const void* base);
155 
156     void reportExtraMemoryVisited(size_t);
157 #if ENABLE(RESOURCE_USAGE)
158     void reportExternalMemoryVisited(size_t);
159 #endif
160 
161     void dump(PrintStream&amp;) const;
162 
<span class="line-modified">163     bool isAnalyzingHeap() const { return !!m_heapAnalyzer; }</span>
<span class="line-modified">164     HeapAnalyzer* heapAnalyzer() const { return m_heapAnalyzer; }</span>
165 
166     RootMarkReason rootMarkReason() const { return m_rootMarkReason; }
167     void setRootMarkReason(RootMarkReason reason) { m_rootMarkReason = reason; }
168 
169     HeapVersion markingVersion() const { return m_markingVersion; }
170 
171     bool mutatorIsStopped() const { return m_mutatorIsStopped; }
172 
173     Lock&amp; rightToRun() { return m_rightToRun; }
174 
175     void updateMutatorIsStopped(const AbstractLocker&amp;);
176     void updateMutatorIsStopped();
177 
178     bool hasAcknowledgedThatTheMutatorIsResumed() const;
179     bool mutatorIsStoppedIsUpToDate() const;
180 
181     void optimizeForStoppedMutator();
182 
183     void didRace(const VisitRaceKey&amp;);
184     void didRace(JSCell* cell, const char* reason) { didRace(VisitRaceKey(cell, reason)); }
</pre>
<hr />
<pre>
196     JS_EXPORT_PRIVATE void addParallelConstraintTask(RefPtr&lt;SharedTask&lt;void(SlotVisitor&amp;)&gt;&gt;);
197 
198 private:
199     friend class ParallelModeEnabler;
200     friend class MarkingConstraintSolver;
201 
202     void appendJSCellOrAuxiliary(HeapCell*);
203 
204     JS_EXPORT_PRIVATE void appendSlow(JSCell*, Dependency);
205     JS_EXPORT_PRIVATE void appendHiddenSlow(JSCell*, Dependency);
206     void appendHiddenSlowImpl(JSCell*, Dependency);
207 
208     template&lt;typename ContainerType&gt;
209     void setMarkedAndAppendToMarkStack(ContainerType&amp;, JSCell*, Dependency);
210 
211     void appendToMarkStack(JSCell*);
212 
213     template&lt;typename ContainerType&gt;
214     void appendToMarkStack(ContainerType&amp;, JSCell*);
215 


216     void noteLiveAuxiliaryCell(HeapCell*);
217 
218     void visitChildren(const JSCell*);
219 
220     void propagateExternalMemoryVisitedIfNecessary();
221 
222     void donateKnownParallel();
223     void donateKnownParallel(MarkStackArray&amp; from, MarkStackArray&amp; to);
224 
225     void donateAll(const AbstractLocker&amp;);
226 
227     bool hasWork(const AbstractLocker&amp;);
228     bool didReachTermination(const AbstractLocker&amp;);
229 
<span class="line-added">230 #if CPU(X86_64)</span>
<span class="line-added">231     NEVER_INLINE NO_RETURN_DUE_TO_CRASH NOT_TAIL_CALLED void reportZappedCellAndCrash(JSCell*);</span>
<span class="line-added">232 #endif</span>
<span class="line-added">233 </span>
234     template&lt;typename Func&gt;
235     IterationStatus forEachMarkStack(const Func&amp;);
236 
237     MarkStackArray&amp; correspondingGlobalStack(MarkStackArray&amp;);
238 
239     MarkStackArray m_collectorStack;
240     MarkStackArray m_mutatorStack;

241 
242     size_t m_bytesVisited;
243     size_t m_visitCount;
244     size_t m_nonCellVisitCount { 0 }; // Used for incremental draining, ignored otherwise.
245     Checked&lt;size_t, RecordOverflow&gt; m_extraMemorySize { 0 };
246     bool m_isInParallelMode;
<span class="line-added">247     bool m_ignoreNewOpaqueRoots { false }; // Useful as a debugging mode.</span>
248 
249     HeapVersion m_markingVersion;
250 
251     Heap&amp; m_heap;
252 
<span class="line-modified">253     HeapAnalyzer* m_heapAnalyzer { nullptr };</span>
254     JSCell* m_currentCell { nullptr };
255     RootMarkReason m_rootMarkReason { RootMarkReason::None };
256     bool m_isFirstVisit { false };
257     bool m_mutatorIsStopped { false };
258     bool m_canOptimizeForStoppedMutator { false };
259     Lock m_rightToRun;
260 
261     CString m_codeName;
262 
263     MarkingConstraint* m_currentConstraint { nullptr };
264     MarkingConstraintSolver* m_currentSolver { nullptr };
265 
<span class="line-added">266     // Put padding here to mitigate false sharing between multiple SlotVisitors.</span>
<span class="line-added">267     char padding[64];</span>
268 public:
269 #if !ASSERT_DISABLED
270     bool m_isCheckingForDefaultMarkViolation;
271     bool m_isDraining;
272 #endif
273 };
274 
275 class ParallelModeEnabler {
276 public:
277     ParallelModeEnabler(SlotVisitor&amp; stack)
278         : m_stack(stack)
279     {
280         ASSERT(!m_stack.m_isInParallelMode);
281         m_stack.m_isInParallelMode = true;
282     }
283 
284     ~ParallelModeEnabler()
285     {
286         ASSERT(m_stack.m_isInParallelMode);
287         m_stack.m_isInParallelMode = false;
</pre>
</td>
</tr>
</table>
<center><a href="SlotVisitor.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="SlotVisitorInlines.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>