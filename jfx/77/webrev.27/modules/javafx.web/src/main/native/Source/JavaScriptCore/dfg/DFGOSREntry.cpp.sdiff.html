<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGOSREntry.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="DFGOSRAvailabilityAnalysisPhase.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGOSREntrypointCreationPhase.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGOSREntry.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 79         printOperand(virtualRegisterForArgument(argumentIndex));
 80     }
 81     for (size_t localIndex = 0; localIndex &lt; m_expectedValues.numberOfLocals(); ++localIndex) {
 82         out.print(comma, &quot;loc&quot;, localIndex, &quot;:&quot;);
 83         printOperand(virtualRegisterForLocal(localIndex));
 84     }
 85 
 86     out.print(&quot;], machine stack used = &quot;, m_machineStackUsed);
 87 }
 88 
 89 void OSREntryData::dump(PrintStream&amp; out) const
 90 {
 91     dumpInContext(out, nullptr);
 92 }
 93 
 94 SUPPRESS_ASAN
 95 void* prepareOSREntry(ExecState* exec, CodeBlock* codeBlock, unsigned bytecodeIndex)
 96 {
 97     ASSERT(JITCode::isOptimizingJIT(codeBlock-&gt;jitType()));
 98     ASSERT(codeBlock-&gt;alternative());
<span class="line-modified"> 99     ASSERT(codeBlock-&gt;alternative()-&gt;jitType() == JITCode::BaselineJIT);</span>
100     ASSERT(!codeBlock-&gt;jitCodeMap());

101 
102     if (!Options::useOSREntryToDFG())
<span class="line-modified">103         return 0;</span>
104 
105     if (Options::verboseOSR()) {
106         dataLog(
107             &quot;DFG OSR in &quot;, *codeBlock-&gt;alternative(), &quot; -&gt; &quot;, *codeBlock,
108             &quot; from bc#&quot;, bytecodeIndex, &quot;\n&quot;);
109     }
110 
<span class="line-modified">111     VM* vm = &amp;exec-&gt;vm();</span>
112 
113     sanitizeStackForVM(vm);
114 
115     if (bytecodeIndex)
116         codeBlock-&gt;ownerExecutable()-&gt;setDidTryToEnterInLoop(true);
117 
<span class="line-modified">118     if (codeBlock-&gt;jitType() != JITCode::DFGJIT) {</span>
<span class="line-modified">119         RELEASE_ASSERT(codeBlock-&gt;jitType() == JITCode::FTLJIT);</span>
120 
121         // When will this happen? We could have:
122         //
123         // - An exit from the FTL JIT into the baseline JIT followed by an attempt
124         //   to reenter. We&#39;re fine with allowing this to fail. If it happens
125         //   enough we&#39;ll just reoptimize. It basically means that the OSR exit cost
126         //   us dearly and so reoptimizing is the right thing to do.
127         //
128         // - We have recursive code with hot loops. Consider that foo has a hot loop
129         //   that calls itself. We have two foo&#39;s on the stack, lets call them foo1
130         //   and foo2, with foo1 having called foo2 from foo&#39;s hot loop. foo2 gets
131         //   optimized all the way into the FTL. Then it returns into foo1, and then
132         //   foo1 wants to get optimized. It might reach this conclusion from its
133         //   hot loop and attempt to OSR enter. And we&#39;ll tell it that it can&#39;t. It
134         //   might be worth addressing this case, but I just think this case will
135         //   be super rare. For now, if it does happen, it&#39;ll cause some compilation
136         //   thrashing.
137 
138         if (Options::verboseOSR())
139             dataLog(&quot;    OSR failed because the target code block is not DFG.\n&quot;);
<span class="line-modified">140         return 0;</span>
141     }
142 
143     JITCode* jitCode = codeBlock-&gt;jitCode()-&gt;dfg();
144     OSREntryData* entry = jitCode-&gt;osrEntryDataForBytecodeIndex(bytecodeIndex);
145 
146     if (!entry) {
147         if (Options::verboseOSR())
148             dataLogF(&quot;    OSR failed because the entrypoint was optimized out.\n&quot;);
<span class="line-modified">149         return 0;</span>
150     }
151 
152     ASSERT(entry-&gt;m_bytecodeIndex == bytecodeIndex);
153 
154     // The code below checks if it is safe to perform OSR entry. It may find
155     // that it is unsafe to do so, for any number of reasons, which are documented
156     // below. If the code decides not to OSR then it returns 0, and it&#39;s the caller&#39;s
157     // responsibility to patch up the state in such a way as to ensure that it&#39;s
158     // both safe and efficient to continue executing baseline code for now. This
159     // should almost certainly include calling either codeBlock-&gt;optimizeAfterWarmUp()
160     // or codeBlock-&gt;dontOptimizeAnytimeSoon().
161 
162     // 1) Verify predictions. If the predictions are inconsistent with the actual
163     //    values, then OSR entry is not possible at this time. It&#39;s tempting to
164     //    assume that we could somehow avoid this case. We can certainly avoid it
165     //    for first-time loop OSR - that is, OSR into a CodeBlock that we have just
166     //    compiled. Then we are almost guaranteed that all of the predictions will
167     //    check out. It would be pretty easy to make that a hard guarantee. But
168     //    then there would still be the case where two call frames with the same
169     //    baseline CodeBlock are on the stack at the same time. The top one
170     //    triggers compilation and OSR. In that case, we may no longer have
171     //    accurate value profiles for the one deeper in the stack. Hence, when we
172     //    pop into the CodeBlock that is deeper on the stack, we might OSR and
173     //    realize that the predictions are wrong. Probably, in most cases, this is
174     //    just an anomaly in the sense that the older CodeBlock simply went off
175     //    into a less-likely path. So, the wisest course of action is to simply not
176     //    OSR at this time.
177 
178     for (size_t argument = 0; argument &lt; entry-&gt;m_expectedValues.numberOfArguments(); ++argument) {
<span class="line-removed">179         if (argument &gt;= exec-&gt;argumentCountIncludingThis()) {</span>
<span class="line-removed">180             if (Options::verboseOSR()) {</span>
<span class="line-removed">181                 dataLogF(&quot;    OSR failed because argument %zu was not passed, expected &quot;, argument);</span>
<span class="line-removed">182                 entry-&gt;m_expectedValues.argument(argument).dump(WTF::dataFile());</span>
<span class="line-removed">183                 dataLogF(&quot;.\n&quot;);</span>
<span class="line-removed">184             }</span>
<span class="line-removed">185             return 0;</span>
<span class="line-removed">186         }</span>
<span class="line-removed">187 </span>
188         JSValue value;
189         if (!argument)
190             value = exec-&gt;thisValue();
191         else
192             value = exec-&gt;argument(argument - 1);
193 
<span class="line-modified">194         if (!entry-&gt;m_expectedValues.argument(argument).validate(value)) {</span>
195             if (Options::verboseOSR()) {
196                 dataLog(
197                     &quot;    OSR failed because argument &quot;, argument, &quot; is &quot;, value,
198                     &quot;, expected &quot;, entry-&gt;m_expectedValues.argument(argument), &quot;.\n&quot;);
199             }
<span class="line-modified">200             return 0;</span>
201         }
202     }
203 
204     for (size_t local = 0; local &lt; entry-&gt;m_expectedValues.numberOfLocals(); ++local) {
205         int localOffset = virtualRegisterForLocal(local).offset();
<span class="line-modified">206         if (entry-&gt;m_localsForcedDouble.get(local)) {</span>
<span class="line-modified">207             if (!exec-&gt;registers()[localOffset].asanUnsafeJSValue().isNumber()) {</span>
<span class="line-modified">208                 if (Options::verboseOSR()) {</span>
<span class="line-removed">209                     dataLog(</span>
<span class="line-removed">210                         &quot;    OSR failed because variable &quot;, localOffset, &quot; is &quot;,</span>
<span class="line-removed">211                         exec-&gt;registers()[localOffset].asanUnsafeJSValue(), &quot;, expected number.\n&quot;);</span>
<span class="line-removed">212                 }</span>
<span class="line-removed">213                 return 0;</span>
<span class="line-removed">214             }</span>
<span class="line-removed">215             continue;</span>
<span class="line-removed">216         }</span>
217         if (entry-&gt;m_localsForcedAnyInt.get(local)) {
<span class="line-modified">218             if (!exec-&gt;registers()[localOffset].asanUnsafeJSValue().isAnyInt()) {</span>
<span class="line-modified">219                 if (Options::verboseOSR()) {</span>
<span class="line-modified">220                     dataLog(</span>
<span class="line-modified">221                         &quot;    OSR failed because variable &quot;, localOffset, &quot; is &quot;,</span>
<span class="line-modified">222                         exec-&gt;registers()[localOffset].asanUnsafeJSValue(), &quot;, expected &quot;,</span>
<span class="line-modified">223                         &quot;machine int.\n&quot;);</span>
<span class="line-removed">224                 }</span>
<span class="line-removed">225                 return 0;</span>
226             }
<span class="line-modified">227             continue;</span>

228         }
<span class="line-modified">229         if (!entry-&gt;m_expectedValues.local(local).validate(exec-&gt;registers()[localOffset].asanUnsafeJSValue())) {</span>
<span class="line-modified">230             if (Options::verboseOSR()) {</span>
<span class="line-modified">231                 dataLog(</span>
<span class="line-modified">232                     &quot;    OSR failed because variable &quot;, VirtualRegister(localOffset), &quot; is &quot;,</span>
<span class="line-modified">233                     exec-&gt;registers()[localOffset].asanUnsafeJSValue(), &quot;, expected &quot;,</span>
<span class="line-modified">234                     entry-&gt;m_expectedValues.local(local), &quot;.\n&quot;);</span>

235             }
<span class="line-modified">236             return 0;</span>









237         }
238     }
239 
240     // 2) Check the stack height. The DFG JIT may require a taller stack than the
241     //    baseline JIT, in some cases. If we can&#39;t grow the stack, then don&#39;t do
242     //    OSR right now. That&#39;s the only option we have unless we want basic block
243     //    boundaries to start throwing RangeErrors. Although that would be possible,
244     //    it seems silly: you&#39;d be diverting the program to error handling when it
245     //    would have otherwise just kept running albeit less quickly.
246 
247     unsigned frameSizeForCheck = jitCode-&gt;common.requiredRegisterCountForExecutionAndExit();
<span class="line-modified">248     if (UNLIKELY(!vm-&gt;ensureStackCapacityFor(&amp;exec-&gt;registers()[virtualRegisterForLocal(frameSizeForCheck - 1).offset()]))) {</span>
249         if (Options::verboseOSR())
250             dataLogF(&quot;    OSR failed because stack growth failed.\n&quot;);
<span class="line-modified">251         return 0;</span>
252     }
253 
254     if (Options::verboseOSR())
255         dataLogF(&quot;    OSR should succeed.\n&quot;);
256 
257     // At this point we&#39;re committed to entering. We will do some work to set things up,
258     // but we also rely on our caller recognizing that when we return a non-null pointer,
259     // that means that we&#39;re already past the point of no return and we must succeed at
260     // entering.
261 
262     // 3) Set up the data in the scratch buffer and perform data format conversions.
263 
264     unsigned frameSize = jitCode-&gt;common.frameRegisterCount;
265     unsigned baselineFrameSize = entry-&gt;m_expectedValues.numberOfLocals();
266     unsigned maxFrameSize = std::max(frameSize, baselineFrameSize);
267 
<span class="line-modified">268     Register* scratch = bitwise_cast&lt;Register*&gt;(vm-&gt;scratchBufferForSize(sizeof(Register) * (2 + CallFrame::headerSizeInRegisters + maxFrameSize))-&gt;dataBuffer());</span>
269 
270     *bitwise_cast&lt;size_t*&gt;(scratch + 0) = frameSize;
271 
272     void* targetPC = entry-&gt;m_machineCode.executableAddress();
273     RELEASE_ASSERT(codeBlock-&gt;jitCode()-&gt;contains(entry-&gt;m_machineCode.untaggedExecutableAddress()));
274     if (Options::verboseOSR())
275         dataLogF(&quot;    OSR using target PC %p.\n&quot;, targetPC);
276     RELEASE_ASSERT(targetPC);
277     *bitwise_cast&lt;void**&gt;(scratch + 1) = retagCodePtr(targetPC, OSREntryPtrTag, bitwise_cast&lt;PtrTag&gt;(exec));
278 
279     Register* pivot = scratch + 2 + CallFrame::headerSizeInRegisters;
280 
281     for (int index = -CallFrame::headerSizeInRegisters; index &lt; static_cast&lt;int&gt;(baselineFrameSize); ++index) {
282         VirtualRegister reg(-1 - index);
283 
284         if (reg.isLocal()) {
285             if (entry-&gt;m_localsForcedDouble.get(reg.toLocal())) {
286                 *bitwise_cast&lt;double*&gt;(pivot + index) = exec-&gt;registers()[reg.offset()].asanUnsafeJSValue().asNumber();
287                 continue;
288             }
</pre>
<hr />
<pre>
301     for (unsigned i = entry-&gt;m_reshufflings.size(); i--;)
302         temporaryLocals[i] = pivot[VirtualRegister(entry-&gt;m_reshufflings[i].fromOffset).toLocal()].asanUnsafeJSValue();
303     for (unsigned i = entry-&gt;m_reshufflings.size(); i--;)
304         pivot[VirtualRegister(entry-&gt;m_reshufflings[i].toOffset).toLocal()] = temporaryLocals[i];
305 
306     // 5) Clear those parts of the call frame that the DFG ain&#39;t using. This helps GC on
307     //    some programs by eliminating some stale pointer pathologies.
308     for (unsigned i = frameSize; i--;) {
309         if (entry-&gt;m_machineStackUsed.get(i))
310             continue;
311         pivot[i] = JSValue();
312     }
313 
314     // 6) Copy our callee saves to buffer.
315 #if NUMBER_OF_CALLEE_SAVES_REGISTERS &gt; 0
316     const RegisterAtOffsetList* registerSaveLocations = codeBlock-&gt;calleeSaveRegisters();
317     RegisterAtOffsetList* allCalleeSaves = RegisterSet::vmCalleeSaveRegisterOffsets();
318     RegisterSet dontSaveRegisters = RegisterSet(RegisterSet::stackRegisters(), RegisterSet::allFPRs());
319 
320     unsigned registerCount = registerSaveLocations-&gt;size();
<span class="line-modified">321     VMEntryRecord* record = vmEntryRecord(vm-&gt;topEntryFrame);</span>
322     for (unsigned i = 0; i &lt; registerCount; i++) {
323         RegisterAtOffset currentEntry = registerSaveLocations-&gt;at(i);
324         if (dontSaveRegisters.get(currentEntry.reg()))
325             continue;
326         RegisterAtOffset* calleeSavesEntry = allCalleeSaves-&gt;find(currentEntry.reg());
327 
328         *(bitwise_cast&lt;intptr_t*&gt;(pivot - 1) - currentEntry.offsetAsIndex()) = record-&gt;calleeSaveRegistersBuffer[calleeSavesEntry-&gt;offsetAsIndex()];
329     }
330 #endif
331 
332     // 7) Fix the call frame to have the right code block.
333 
334     *bitwise_cast&lt;CodeBlock**&gt;(pivot - 1 - CallFrameSlot::codeBlock) = codeBlock;
335 
336     if (Options::verboseOSR())
337         dataLogF(&quot;    OSR returning data buffer %p.\n&quot;, scratch);
338     return scratch;
339 }
340 
341 MacroAssemblerCodePtr&lt;ExceptionHandlerPtrTag&gt; prepareCatchOSREntry(ExecState* exec, CodeBlock* codeBlock, unsigned bytecodeIndex)
342 {
<span class="line-modified">343     ASSERT(codeBlock-&gt;jitType() == JITCode::DFGJIT || codeBlock-&gt;jitType() == JITCode::FTLJIT);</span>

344 
<span class="line-modified">345     if (!Options::useOSREntryToDFG() &amp;&amp; codeBlock-&gt;jitCode()-&gt;jitType() == JITCode::DFGJIT)</span>
346         return nullptr;
<span class="line-modified">347     if (!Options::useOSREntryToFTL() &amp;&amp; codeBlock-&gt;jitCode()-&gt;jitType() == JITCode::FTLJIT)</span>
348         return nullptr;
349 
350     VM&amp; vm = exec-&gt;vm();
351 
352     CommonData* dfgCommon = codeBlock-&gt;jitCode()-&gt;dfgCommon();
353     RELEASE_ASSERT(dfgCommon);
354     DFG::CatchEntrypointData* catchEntrypoint = dfgCommon-&gt;catchOSREntryDataForBytecodeIndex(bytecodeIndex);
355     if (!catchEntrypoint) {
356         // This can be null under some circumstances. The most common is that we didn&#39;t
357         // compile this op_catch as an entrypoint since it had never executed when starting
358         // the compilation.
359         return nullptr;
360     }
361 
362     // We&#39;re only allowed to OSR enter if we&#39;ve proven we have compatible argument types.
363     for (unsigned argument = 0; argument &lt; catchEntrypoint-&gt;argumentFormats.size(); ++argument) {
364         JSValue value = exec-&gt;uncheckedR(virtualRegisterForArgument(argument)).jsValue();
365         switch (catchEntrypoint-&gt;argumentFormats[argument]) {
366         case DFG::FlushedInt32:
367             if (!value.isInt32())
</pre>
</td>
<td>
<hr />
<pre>
 79         printOperand(virtualRegisterForArgument(argumentIndex));
 80     }
 81     for (size_t localIndex = 0; localIndex &lt; m_expectedValues.numberOfLocals(); ++localIndex) {
 82         out.print(comma, &quot;loc&quot;, localIndex, &quot;:&quot;);
 83         printOperand(virtualRegisterForLocal(localIndex));
 84     }
 85 
 86     out.print(&quot;], machine stack used = &quot;, m_machineStackUsed);
 87 }
 88 
 89 void OSREntryData::dump(PrintStream&amp; out) const
 90 {
 91     dumpInContext(out, nullptr);
 92 }
 93 
 94 SUPPRESS_ASAN
 95 void* prepareOSREntry(ExecState* exec, CodeBlock* codeBlock, unsigned bytecodeIndex)
 96 {
 97     ASSERT(JITCode::isOptimizingJIT(codeBlock-&gt;jitType()));
 98     ASSERT(codeBlock-&gt;alternative());
<span class="line-modified"> 99     ASSERT(codeBlock-&gt;alternative()-&gt;jitType() == JITType::BaselineJIT);</span>
100     ASSERT(!codeBlock-&gt;jitCodeMap());
<span class="line-added">101     ASSERT(codeBlock-&gt;jitCode()-&gt;dfgCommon()-&gt;isStillValid);</span>
102 
103     if (!Options::useOSREntryToDFG())
<span class="line-modified">104         return nullptr;</span>
105 
106     if (Options::verboseOSR()) {
107         dataLog(
108             &quot;DFG OSR in &quot;, *codeBlock-&gt;alternative(), &quot; -&gt; &quot;, *codeBlock,
109             &quot; from bc#&quot;, bytecodeIndex, &quot;\n&quot;);
110     }
111 
<span class="line-modified">112     VM&amp; vm = exec-&gt;vm();</span>
113 
114     sanitizeStackForVM(vm);
115 
116     if (bytecodeIndex)
117         codeBlock-&gt;ownerExecutable()-&gt;setDidTryToEnterInLoop(true);
118 
<span class="line-modified">119     if (codeBlock-&gt;jitType() != JITType::DFGJIT) {</span>
<span class="line-modified">120         RELEASE_ASSERT(codeBlock-&gt;jitType() == JITType::FTLJIT);</span>
121 
122         // When will this happen? We could have:
123         //
124         // - An exit from the FTL JIT into the baseline JIT followed by an attempt
125         //   to reenter. We&#39;re fine with allowing this to fail. If it happens
126         //   enough we&#39;ll just reoptimize. It basically means that the OSR exit cost
127         //   us dearly and so reoptimizing is the right thing to do.
128         //
129         // - We have recursive code with hot loops. Consider that foo has a hot loop
130         //   that calls itself. We have two foo&#39;s on the stack, lets call them foo1
131         //   and foo2, with foo1 having called foo2 from foo&#39;s hot loop. foo2 gets
132         //   optimized all the way into the FTL. Then it returns into foo1, and then
133         //   foo1 wants to get optimized. It might reach this conclusion from its
134         //   hot loop and attempt to OSR enter. And we&#39;ll tell it that it can&#39;t. It
135         //   might be worth addressing this case, but I just think this case will
136         //   be super rare. For now, if it does happen, it&#39;ll cause some compilation
137         //   thrashing.
138 
139         if (Options::verboseOSR())
140             dataLog(&quot;    OSR failed because the target code block is not DFG.\n&quot;);
<span class="line-modified">141         return nullptr;</span>
142     }
143 
144     JITCode* jitCode = codeBlock-&gt;jitCode()-&gt;dfg();
145     OSREntryData* entry = jitCode-&gt;osrEntryDataForBytecodeIndex(bytecodeIndex);
146 
147     if (!entry) {
148         if (Options::verboseOSR())
149             dataLogF(&quot;    OSR failed because the entrypoint was optimized out.\n&quot;);
<span class="line-modified">150         return nullptr;</span>
151     }
152 
153     ASSERT(entry-&gt;m_bytecodeIndex == bytecodeIndex);
154 
155     // The code below checks if it is safe to perform OSR entry. It may find
156     // that it is unsafe to do so, for any number of reasons, which are documented
157     // below. If the code decides not to OSR then it returns 0, and it&#39;s the caller&#39;s
158     // responsibility to patch up the state in such a way as to ensure that it&#39;s
159     // both safe and efficient to continue executing baseline code for now. This
160     // should almost certainly include calling either codeBlock-&gt;optimizeAfterWarmUp()
161     // or codeBlock-&gt;dontOptimizeAnytimeSoon().
162 
163     // 1) Verify predictions. If the predictions are inconsistent with the actual
164     //    values, then OSR entry is not possible at this time. It&#39;s tempting to
165     //    assume that we could somehow avoid this case. We can certainly avoid it
166     //    for first-time loop OSR - that is, OSR into a CodeBlock that we have just
167     //    compiled. Then we are almost guaranteed that all of the predictions will
168     //    check out. It would be pretty easy to make that a hard guarantee. But
169     //    then there would still be the case where two call frames with the same
170     //    baseline CodeBlock are on the stack at the same time. The top one
171     //    triggers compilation and OSR. In that case, we may no longer have
172     //    accurate value profiles for the one deeper in the stack. Hence, when we
173     //    pop into the CodeBlock that is deeper on the stack, we might OSR and
174     //    realize that the predictions are wrong. Probably, in most cases, this is
175     //    just an anomaly in the sense that the older CodeBlock simply went off
176     //    into a less-likely path. So, the wisest course of action is to simply not
177     //    OSR at this time.
178 
179     for (size_t argument = 0; argument &lt; entry-&gt;m_expectedValues.numberOfArguments(); ++argument) {









180         JSValue value;
181         if (!argument)
182             value = exec-&gt;thisValue();
183         else
184             value = exec-&gt;argument(argument - 1);
185 
<span class="line-modified">186         if (!entry-&gt;m_expectedValues.argument(argument).validateOSREntryValue(value, FlushedJSValue)) {</span>
187             if (Options::verboseOSR()) {
188                 dataLog(
189                     &quot;    OSR failed because argument &quot;, argument, &quot; is &quot;, value,
190                     &quot;, expected &quot;, entry-&gt;m_expectedValues.argument(argument), &quot;.\n&quot;);
191             }
<span class="line-modified">192             return nullptr;</span>
193         }
194     }
195 
196     for (size_t local = 0; local &lt; entry-&gt;m_expectedValues.numberOfLocals(); ++local) {
197         int localOffset = virtualRegisterForLocal(local).offset();
<span class="line-modified">198         JSValue value = exec-&gt;registers()[localOffset].asanUnsafeJSValue();</span>
<span class="line-modified">199         FlushFormat format = FlushedJSValue;</span>
<span class="line-modified">200 </span>








201         if (entry-&gt;m_localsForcedAnyInt.get(local)) {
<span class="line-modified">202             if (!value.isAnyInt()) {</span>
<span class="line-modified">203                 dataLogLnIf(Options::verboseOSR(),</span>
<span class="line-modified">204                     &quot;    OSR failed because variable &quot;, localOffset, &quot; is &quot;,</span>
<span class="line-modified">205                     value, &quot;, expected &quot;,</span>
<span class="line-modified">206                     &quot;machine int.&quot;);</span>
<span class="line-modified">207                 return nullptr;</span>


208             }
<span class="line-modified">209             value = jsDoubleNumber(value.asAnyInt());</span>
<span class="line-added">210             format = FlushedInt52;</span>
211         }
<span class="line-modified">212 </span>
<span class="line-modified">213         if (entry-&gt;m_localsForcedDouble.get(local)) {</span>
<span class="line-modified">214             if (!value.isNumber()) {</span>
<span class="line-modified">215                 dataLogLnIf(Options::verboseOSR(),</span>
<span class="line-modified">216                     &quot;    OSR failed because variable &quot;, localOffset, &quot; is &quot;,</span>
<span class="line-modified">217                     value, &quot;, expected number.&quot;);</span>
<span class="line-added">218                 return nullptr;</span>
219             }
<span class="line-modified">220             value = jsDoubleNumber(value.asNumber());</span>
<span class="line-added">221             format = FlushedDouble;</span>
<span class="line-added">222         }</span>
<span class="line-added">223 </span>
<span class="line-added">224         if (!entry-&gt;m_expectedValues.local(local).validateOSREntryValue(value, format)) {</span>
<span class="line-added">225             dataLogLnIf(Options::verboseOSR(),</span>
<span class="line-added">226                 &quot;    OSR failed because variable &quot;, VirtualRegister(localOffset), &quot; is &quot;,</span>
<span class="line-added">227                 value, &quot;, expected &quot;,</span>
<span class="line-added">228                 entry-&gt;m_expectedValues.local(local), &quot;.&quot;);</span>
<span class="line-added">229             return nullptr;</span>
230         }
231     }
232 
233     // 2) Check the stack height. The DFG JIT may require a taller stack than the
234     //    baseline JIT, in some cases. If we can&#39;t grow the stack, then don&#39;t do
235     //    OSR right now. That&#39;s the only option we have unless we want basic block
236     //    boundaries to start throwing RangeErrors. Although that would be possible,
237     //    it seems silly: you&#39;d be diverting the program to error handling when it
238     //    would have otherwise just kept running albeit less quickly.
239 
240     unsigned frameSizeForCheck = jitCode-&gt;common.requiredRegisterCountForExecutionAndExit();
<span class="line-modified">241     if (UNLIKELY(!vm.ensureStackCapacityFor(&amp;exec-&gt;registers()[virtualRegisterForLocal(frameSizeForCheck - 1).offset()]))) {</span>
242         if (Options::verboseOSR())
243             dataLogF(&quot;    OSR failed because stack growth failed.\n&quot;);
<span class="line-modified">244         return nullptr;</span>
245     }
246 
247     if (Options::verboseOSR())
248         dataLogF(&quot;    OSR should succeed.\n&quot;);
249 
250     // At this point we&#39;re committed to entering. We will do some work to set things up,
251     // but we also rely on our caller recognizing that when we return a non-null pointer,
252     // that means that we&#39;re already past the point of no return and we must succeed at
253     // entering.
254 
255     // 3) Set up the data in the scratch buffer and perform data format conversions.
256 
257     unsigned frameSize = jitCode-&gt;common.frameRegisterCount;
258     unsigned baselineFrameSize = entry-&gt;m_expectedValues.numberOfLocals();
259     unsigned maxFrameSize = std::max(frameSize, baselineFrameSize);
260 
<span class="line-modified">261     Register* scratch = bitwise_cast&lt;Register*&gt;(vm.scratchBufferForSize(sizeof(Register) * (2 + CallFrame::headerSizeInRegisters + maxFrameSize))-&gt;dataBuffer());</span>
262 
263     *bitwise_cast&lt;size_t*&gt;(scratch + 0) = frameSize;
264 
265     void* targetPC = entry-&gt;m_machineCode.executableAddress();
266     RELEASE_ASSERT(codeBlock-&gt;jitCode()-&gt;contains(entry-&gt;m_machineCode.untaggedExecutableAddress()));
267     if (Options::verboseOSR())
268         dataLogF(&quot;    OSR using target PC %p.\n&quot;, targetPC);
269     RELEASE_ASSERT(targetPC);
270     *bitwise_cast&lt;void**&gt;(scratch + 1) = retagCodePtr(targetPC, OSREntryPtrTag, bitwise_cast&lt;PtrTag&gt;(exec));
271 
272     Register* pivot = scratch + 2 + CallFrame::headerSizeInRegisters;
273 
274     for (int index = -CallFrame::headerSizeInRegisters; index &lt; static_cast&lt;int&gt;(baselineFrameSize); ++index) {
275         VirtualRegister reg(-1 - index);
276 
277         if (reg.isLocal()) {
278             if (entry-&gt;m_localsForcedDouble.get(reg.toLocal())) {
279                 *bitwise_cast&lt;double*&gt;(pivot + index) = exec-&gt;registers()[reg.offset()].asanUnsafeJSValue().asNumber();
280                 continue;
281             }
</pre>
<hr />
<pre>
294     for (unsigned i = entry-&gt;m_reshufflings.size(); i--;)
295         temporaryLocals[i] = pivot[VirtualRegister(entry-&gt;m_reshufflings[i].fromOffset).toLocal()].asanUnsafeJSValue();
296     for (unsigned i = entry-&gt;m_reshufflings.size(); i--;)
297         pivot[VirtualRegister(entry-&gt;m_reshufflings[i].toOffset).toLocal()] = temporaryLocals[i];
298 
299     // 5) Clear those parts of the call frame that the DFG ain&#39;t using. This helps GC on
300     //    some programs by eliminating some stale pointer pathologies.
301     for (unsigned i = frameSize; i--;) {
302         if (entry-&gt;m_machineStackUsed.get(i))
303             continue;
304         pivot[i] = JSValue();
305     }
306 
307     // 6) Copy our callee saves to buffer.
308 #if NUMBER_OF_CALLEE_SAVES_REGISTERS &gt; 0
309     const RegisterAtOffsetList* registerSaveLocations = codeBlock-&gt;calleeSaveRegisters();
310     RegisterAtOffsetList* allCalleeSaves = RegisterSet::vmCalleeSaveRegisterOffsets();
311     RegisterSet dontSaveRegisters = RegisterSet(RegisterSet::stackRegisters(), RegisterSet::allFPRs());
312 
313     unsigned registerCount = registerSaveLocations-&gt;size();
<span class="line-modified">314     VMEntryRecord* record = vmEntryRecord(vm.topEntryFrame);</span>
315     for (unsigned i = 0; i &lt; registerCount; i++) {
316         RegisterAtOffset currentEntry = registerSaveLocations-&gt;at(i);
317         if (dontSaveRegisters.get(currentEntry.reg()))
318             continue;
319         RegisterAtOffset* calleeSavesEntry = allCalleeSaves-&gt;find(currentEntry.reg());
320 
321         *(bitwise_cast&lt;intptr_t*&gt;(pivot - 1) - currentEntry.offsetAsIndex()) = record-&gt;calleeSaveRegistersBuffer[calleeSavesEntry-&gt;offsetAsIndex()];
322     }
323 #endif
324 
325     // 7) Fix the call frame to have the right code block.
326 
327     *bitwise_cast&lt;CodeBlock**&gt;(pivot - 1 - CallFrameSlot::codeBlock) = codeBlock;
328 
329     if (Options::verboseOSR())
330         dataLogF(&quot;    OSR returning data buffer %p.\n&quot;, scratch);
331     return scratch;
332 }
333 
334 MacroAssemblerCodePtr&lt;ExceptionHandlerPtrTag&gt; prepareCatchOSREntry(ExecState* exec, CodeBlock* codeBlock, unsigned bytecodeIndex)
335 {
<span class="line-modified">336     ASSERT(codeBlock-&gt;jitType() == JITType::DFGJIT || codeBlock-&gt;jitType() == JITType::FTLJIT);</span>
<span class="line-added">337     ASSERT(codeBlock-&gt;jitCode()-&gt;dfgCommon()-&gt;isStillValid);</span>
338 
<span class="line-modified">339     if (!Options::useOSREntryToDFG() &amp;&amp; codeBlock-&gt;jitCode()-&gt;jitType() == JITType::DFGJIT)</span>
340         return nullptr;
<span class="line-modified">341     if (!Options::useOSREntryToFTL() &amp;&amp; codeBlock-&gt;jitCode()-&gt;jitType() == JITType::FTLJIT)</span>
342         return nullptr;
343 
344     VM&amp; vm = exec-&gt;vm();
345 
346     CommonData* dfgCommon = codeBlock-&gt;jitCode()-&gt;dfgCommon();
347     RELEASE_ASSERT(dfgCommon);
348     DFG::CatchEntrypointData* catchEntrypoint = dfgCommon-&gt;catchOSREntryDataForBytecodeIndex(bytecodeIndex);
349     if (!catchEntrypoint) {
350         // This can be null under some circumstances. The most common is that we didn&#39;t
351         // compile this op_catch as an entrypoint since it had never executed when starting
352         // the compilation.
353         return nullptr;
354     }
355 
356     // We&#39;re only allowed to OSR enter if we&#39;ve proven we have compatible argument types.
357     for (unsigned argument = 0; argument &lt; catchEntrypoint-&gt;argumentFormats.size(); ++argument) {
358         JSValue value = exec-&gt;uncheckedR(virtualRegisterForArgument(argument)).jsValue();
359         switch (catchEntrypoint-&gt;argumentFormats[argument]) {
360         case DFG::FlushedInt32:
361             if (!value.isInt32())
</pre>
</td>
</tr>
</table>
<center><a href="DFGOSRAvailabilityAnalysisPhase.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="DFGOSREntrypointCreationPhase.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>