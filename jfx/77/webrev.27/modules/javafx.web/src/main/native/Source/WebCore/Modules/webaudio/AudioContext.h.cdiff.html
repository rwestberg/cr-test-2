<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="AudioContext.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioContext.idl.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,8 ***</span>
  /*
   * Copyright (C) 2010 Google Inc. All rights reserved.
<span class="line-modified">!  * Copyright (C) 2016 Apple Inc. All rights reserved.</span>
   *
   * Redistribution and use in source and binary forms, with or without
   * modification, are permitted provided that the following conditions
   * are met:
   * 1.  Redistributions of source code must retain the above copyright
<span class="line-new-header">--- 1,8 ---</span>
  /*
   * Copyright (C) 2010 Google Inc. All rights reserved.
<span class="line-modified">!  * Copyright (C) 2016-2019 Apple Inc. All rights reserved.</span>
   *
   * Redistribution and use in source and binary forms, with or without
   * modification, are permitted provided that the following conditions
   * are met:
   * 1.  Redistributions of source code must retain the above copyright
</pre>
<hr />
<pre>
<span class="line-old-header">*** 32,20 ***</span>
  #include &quot;EventTarget.h&quot;
  #include &quot;JSDOMPromiseDeferred.h&quot;
  #include &quot;MediaCanStartListener.h&quot;
  #include &quot;MediaProducer.h&quot;
  #include &quot;PlatformMediaSession.h&quot;
  #include &quot;VisibilityChangeClient.h&quot;
  #include &lt;JavaScriptCore/Float32Array.h&gt;
  #include &lt;atomic&gt;
  #include &lt;wtf/HashSet.h&gt;
  #include &lt;wtf/MainThread.h&gt;
  #include &lt;wtf/RefPtr.h&gt;
  #include &lt;wtf/ThreadSafeRefCounted.h&gt;
  #include &lt;wtf/Threading.h&gt;
  #include &lt;wtf/Vector.h&gt;
<span class="line-modified">! #include &lt;wtf/text/AtomicStringHash.h&gt;</span>
  
  namespace WebCore {
  
  class AnalyserNode;
  class AudioBuffer;
<span class="line-new-header">--- 32,23 ---</span>
  #include &quot;EventTarget.h&quot;
  #include &quot;JSDOMPromiseDeferred.h&quot;
  #include &quot;MediaCanStartListener.h&quot;
  #include &quot;MediaProducer.h&quot;
  #include &quot;PlatformMediaSession.h&quot;
<span class="line-added">+ #include &quot;ScriptExecutionContext.h&quot;</span>
  #include &quot;VisibilityChangeClient.h&quot;
<span class="line-added">+ #include &lt;JavaScriptCore/ConsoleTypes.h&gt;</span>
  #include &lt;JavaScriptCore/Float32Array.h&gt;
  #include &lt;atomic&gt;
  #include &lt;wtf/HashSet.h&gt;
<span class="line-added">+ #include &lt;wtf/LoggerHelper.h&gt;</span>
  #include &lt;wtf/MainThread.h&gt;
  #include &lt;wtf/RefPtr.h&gt;
  #include &lt;wtf/ThreadSafeRefCounted.h&gt;
  #include &lt;wtf/Threading.h&gt;
  #include &lt;wtf/Vector.h&gt;
<span class="line-modified">! #include &lt;wtf/text/AtomStringHash.h&gt;</span>
  
  namespace WebCore {
  
  class AnalyserNode;
  class AudioBuffer;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 69,16 ***</span>
  class MediaStreamAudioSourceNode;
  class OscillatorNode;
  class PannerNode;
  class PeriodicWave;
  class ScriptProcessorNode;
  class WaveShaperNode;
  
  // AudioContext is the cornerstone of the web audio API and all AudioNodes are created from it.
  // For thread safety between the audio thread and the main thread, it has a rendering graph locking mechanism.
  
<span class="line-modified">! class AudioContext : public ActiveDOMObject, public ThreadSafeRefCounted&lt;AudioContext&gt;, public EventTargetWithInlineData, public MediaCanStartListener, public MediaProducer, private PlatformMediaSessionClient, private VisibilityChangeClient {</span>
  public:
      // Create an AudioContext for rendering to the audio hardware.
      static RefPtr&lt;AudioContext&gt; create(Document&amp;);
  
      virtual ~AudioContext();
<span class="line-new-header">--- 72,29 ---</span>
  class MediaStreamAudioSourceNode;
  class OscillatorNode;
  class PannerNode;
  class PeriodicWave;
  class ScriptProcessorNode;
<span class="line-added">+ class SecurityOrigin;</span>
  class WaveShaperNode;
  
  // AudioContext is the cornerstone of the web audio API and all AudioNodes are created from it.
  // For thread safety between the audio thread and the main thread, it has a rendering graph locking mechanism.
  
<span class="line-modified">! class AudioContext</span>
<span class="line-added">+     : public ActiveDOMObject</span>
<span class="line-added">+     , public ThreadSafeRefCounted&lt;AudioContext&gt;</span>
<span class="line-added">+     , public EventTargetWithInlineData</span>
<span class="line-added">+     , public MediaCanStartListener</span>
<span class="line-added">+     , public MediaProducer</span>
<span class="line-added">+     , private PlatformMediaSessionClient</span>
<span class="line-added">+     , private VisibilityChangeClient</span>
<span class="line-added">+ #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">+     , private LoggerHelper</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+ {</span>
<span class="line-added">+     WTF_MAKE_ISO_ALLOCATED(AudioContext);</span>
  public:
      // Create an AudioContext for rendering to the audio hardware.
      static RefPtr&lt;AudioContext&gt; create(Document&amp;);
  
      virtual ~AudioContext();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 90,13 ***</span>
      Document* document() const; // ASSERTs if document no longer exists.
  
      Document* hostingDocument() const final;
  
      AudioDestinationNode* destination() { return m_destinationNode.get(); }
<span class="line-modified">!     size_t currentSampleFrame() const { return m_destinationNode-&gt;currentSampleFrame(); }</span>
<span class="line-modified">!     double currentTime() const { return m_destinationNode-&gt;currentTime(); }</span>
<span class="line-modified">!     float sampleRate() const { return m_destinationNode-&gt;sampleRate(); }</span>
      unsigned long activeSourceCount() const { return static_cast&lt;unsigned long&gt;(m_activeSourceCount); }
  
      void incrementActiveSourceCount();
      void decrementActiveSourceCount();
  
<span class="line-new-header">--- 106,13 ---</span>
      Document* document() const; // ASSERTs if document no longer exists.
  
      Document* hostingDocument() const final;
  
      AudioDestinationNode* destination() { return m_destinationNode.get(); }
<span class="line-modified">!     size_t currentSampleFrame() const { return m_destinationNode ? m_destinationNode-&gt;currentSampleFrame() : 0; }</span>
<span class="line-modified">!     double currentTime() const { return m_destinationNode ? m_destinationNode-&gt;currentTime() : 0.; }</span>
<span class="line-modified">!     float sampleRate() const { return m_destinationNode ? m_destinationNode-&gt;sampleRate() : 0.f; }</span>
      unsigned long activeSourceCount() const { return static_cast&lt;unsigned long&gt;(m_activeSourceCount); }
  
      void incrementActiveSourceCount();
      void decrementActiveSourceCount();
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 115,34 ***</span>
      void resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
      void close(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
  
      enum class State { Suspended, Running, Interrupted, Closed };
      State state() const;
  
      bool wouldTaintOrigin(const URL&amp;) const;
  
      // The AudioNode create methods are called on the main thread (from JavaScript).
<span class="line-modified">!     Ref&lt;AudioBufferSourceNode&gt; createBufferSource();</span>
  #if ENABLE(VIDEO)
      ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; createMediaElementSource(HTMLMediaElement&amp;);
  #endif
  #if ENABLE(MEDIA_STREAM)
      ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; createMediaStreamSource(MediaStream&amp;);
<span class="line-modified">!     Ref&lt;MediaStreamAudioDestinationNode&gt; createMediaStreamDestination();</span>
  #endif
<span class="line-modified">!     Ref&lt;GainNode&gt; createGain();</span>
<span class="line-modified">!     Ref&lt;BiquadFilterNode&gt; createBiquadFilter();</span>
<span class="line-modified">!     Ref&lt;WaveShaperNode&gt; createWaveShaper();</span>
      ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; createDelay(double maxDelayTime);
<span class="line-modified">!     Ref&lt;PannerNode&gt; createPanner();</span>
<span class="line-modified">!     Ref&lt;ConvolverNode&gt; createConvolver();</span>
<span class="line-modified">!     Ref&lt;DynamicsCompressorNode&gt; createDynamicsCompressor();</span>
<span class="line-modified">!     Ref&lt;AnalyserNode&gt; createAnalyser();</span>
      ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels);
      ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; createChannelSplitter(size_t numberOfOutputs);
      ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; createChannelMerger(size_t numberOfInputs);
<span class="line-modified">!     Ref&lt;OscillatorNode&gt; createOscillator();</span>
      ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary);
  
      // When a source node has no more processing to do (has finished playing), then it tells the context to dereference it.
      void notifyNodeFinishedProcessing(AudioNode*);
  
<span class="line-new-header">--- 131,35 ---</span>
      void resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
      void close(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
  
      enum class State { Suspended, Running, Interrupted, Closed };
      State state() const;
<span class="line-added">+     bool isClosed() const { return m_state == State::Closed; }</span>
  
      bool wouldTaintOrigin(const URL&amp;) const;
  
      // The AudioNode create methods are called on the main thread (from JavaScript).
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;AudioBufferSourceNode&gt;&gt; createBufferSource();</span>
  #if ENABLE(VIDEO)
      ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; createMediaElementSource(HTMLMediaElement&amp;);
  #endif
  #if ENABLE(MEDIA_STREAM)
      ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; createMediaStreamSource(MediaStream&amp;);
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;MediaStreamAudioDestinationNode&gt;&gt; createMediaStreamDestination();</span>
  #endif
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;GainNode&gt;&gt; createGain();</span>
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;BiquadFilterNode&gt;&gt; createBiquadFilter();</span>
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;WaveShaperNode&gt;&gt; createWaveShaper();</span>
      ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; createDelay(double maxDelayTime);
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;PannerNode&gt;&gt; createPanner();</span>
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;ConvolverNode&gt;&gt; createConvolver();</span>
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;DynamicsCompressorNode&gt;&gt; createDynamicsCompressor();</span>
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;AnalyserNode&gt;&gt; createAnalyser();</span>
      ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels);
      ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; createChannelSplitter(size_t numberOfOutputs);
      ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; createChannelMerger(size_t numberOfInputs);
<span class="line-modified">!     ExceptionOr&lt;Ref&lt;OscillatorNode&gt;&gt; createOscillator();</span>
      ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary);
  
      // When a source node has no more processing to do (has finished playing), then it tells the context to dereference it.
      void notifyNodeFinishedProcessing(AudioNode*);
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 234,18 ***</span>
      // Must be called on main thread.
      void removeMarkedSummingJunction(AudioSummingJunction*);
  
      // EventTarget
      EventTargetInterface eventTargetInterface() const final { return AudioContextEventTargetInterfaceType; }
<span class="line-removed">-     ScriptExecutionContext* scriptExecutionContext() const final;</span>
  
      // Reconcile ref/deref which are defined both in ThreadSafeRefCounted and EventTarget.
      using ThreadSafeRefCounted::ref;
      using ThreadSafeRefCounted::deref;
  
      void startRendering();
<span class="line-modified">!     void fireCompletionEvent();</span>
  
      static unsigned s_hardwareContextCount;
  
      // Restrictions to change default behaviors.
      enum BehaviorRestrictionFlags {
<span class="line-new-header">--- 251,17 ---</span>
      // Must be called on main thread.
      void removeMarkedSummingJunction(AudioSummingJunction*);
  
      // EventTarget
      EventTargetInterface eventTargetInterface() const final { return AudioContextEventTargetInterfaceType; }
  
      // Reconcile ref/deref which are defined both in ThreadSafeRefCounted and EventTarget.
      using ThreadSafeRefCounted::ref;
      using ThreadSafeRefCounted::deref;
  
      void startRendering();
<span class="line-modified">!     void finishedRendering(bool didRendering);</span>
  
      static unsigned s_hardwareContextCount;
  
      // Restrictions to change default behaviors.
      enum BehaviorRestrictionFlags {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 261,15 ***</span>
<span class="line-new-header">--- 277,30 ---</span>
  
      void isPlayingAudioDidChange();
  
      void nodeWillBeginPlayback();
  
<span class="line-added">+ #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">+     const Logger&amp; logger() const final { return m_logger.get(); }</span>
<span class="line-added">+     const void* logIdentifier() const final { return m_logIdentifier; }</span>
<span class="line-added">+     WTFLogChannel&amp; logChannel() const final;</span>
<span class="line-added">+     const void* nextAudioNodeLogIdentifier() { return childLogIdentifier(++m_nextAudioNodeIdentifier); }</span>
<span class="line-added">+     const void* nextAudioParameterLogIdentifier() { return childLogIdentifier(++m_nextAudioParameterIdentifier); }</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+ </span>
<span class="line-added">+     void postTask(WTF::Function&lt;void()&gt;&amp;&amp;);</span>
<span class="line-added">+     bool isStopped() const { return m_isStopScheduled; }</span>
<span class="line-added">+     const SecurityOrigin* origin() const;</span>
<span class="line-added">+     void addConsoleMessage(MessageSource, MessageLevel, const String&amp; message);</span>
<span class="line-added">+ </span>
  protected:
      explicit AudioContext(Document&amp;);
      AudioContext(Document&amp;, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
  
      static bool isSampleRateRangeGood(float sampleRate);
<span class="line-added">+     void clearPendingActivity();</span>
<span class="line-added">+     void makePendingActivity();</span>
  
  private:
      void constructCommon();
  
      void lazyInitialize();
</pre>
<hr />
<pre>
<span class="line-old-header">*** 287,10 ***</span>
<span class="line-new-header">--- 318,14 ---</span>
  
      void scheduleNodeDeletion();
  
      void mediaCanStart(Document&amp;) override;
  
<span class="line-added">+     // EventTarget</span>
<span class="line-added">+     ScriptExecutionContext* scriptExecutionContext() const final;</span>
<span class="line-added">+     void dispatchEvent(Event&amp;) final;</span>
<span class="line-added">+ </span>
      // MediaProducer
      MediaProducer::MediaStateFlags mediaState() const override;
      void pageMutedStateDidChange() override;
  
      // The context itself keeps a reference to all source nodes.  The source nodes, then reference all nodes they&#39;re connected to.
</pre>
<hr />
<pre>
<span class="line-old-header">*** 334,10 ***</span>
<span class="line-new-header">--- 369,19 ---</span>
      void handleDirtyAudioNodeOutputs();
  
      void addReaction(State, DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
      void updateAutomaticPullNodes();
  
<span class="line-added">+ #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">+     const char* logClassName() const final { return &quot;AudioContext&quot;; }</span>
<span class="line-added">+ </span>
<span class="line-added">+     Ref&lt;Logger&gt; m_logger;</span>
<span class="line-added">+     const void* m_logIdentifier;</span>
<span class="line-added">+     uint64_t m_nextAudioNodeIdentifier { 0 };</span>
<span class="line-added">+     uint64_t m_nextAudioParameterIdentifier { 0 };</span>
<span class="line-added">+ #endif</span>
<span class="line-added">+ </span>
      // Only accessed in the audio thread.
      Vector&lt;AudioNode*&gt; m_finishedNodes;
  
      // We don&#39;t use RefPtr&lt;AudioNode&gt; here because AudioNode has a more complex ref() / deref() implementation
      // with an optional argument for refType.  We need to use the special refType: RefTypeConnection
</pre>
<hr />
<pre>
<span class="line-old-header">*** 386,11 ***</span>
      // FIXME: Using volatile seems incorrect.
      // https://bugs.webkit.org/show_bug.cgi?id=180332
      Thread* volatile m_audioThread { nullptr };
      Thread* volatile m_graphOwnerThread { nullptr }; // if the lock is held then this is the thread which owns it, otherwise == nullptr.
  
<span class="line-modified">!     AsyncAudioDecoder m_audioDecoder;</span>
  
      // This is considering 32 is large enough for multiple channels audio.
      // It is somewhat arbitrary and could be increased if necessary.
      enum { MaxNumberOfChannels = 32 };
  
<span class="line-new-header">--- 430,11 ---</span>
      // FIXME: Using volatile seems incorrect.
      // https://bugs.webkit.org/show_bug.cgi?id=180332
      Thread* volatile m_audioThread { nullptr };
      Thread* volatile m_graphOwnerThread { nullptr }; // if the lock is held then this is the thread which owns it, otherwise == nullptr.
  
<span class="line-modified">!     std::unique_ptr&lt;AsyncAudioDecoder&gt; m_audioDecoder;</span>
  
      // This is considering 32 is large enough for multiple channels audio.
      // It is somewhat arbitrary and could be increased if necessary.
      enum { MaxNumberOfChannels = 32 };
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 398,10 ***</span>
<span class="line-new-header">--- 442,11 ---</span>
      std::atomic&lt;int&gt; m_activeSourceCount { 0 };
  
      BehaviorRestrictions m_restrictions { NoRestrictions };
  
      State m_state { State::Suspended };
<span class="line-added">+     RefPtr&lt;PendingActivity&lt;AudioContext&gt;&gt; m_pendingActivity;</span>
  };
  
  // FIXME: Find out why these ==/!= functions are needed and remove them if possible.
  
  inline bool operator==(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
</pre>
<center><a href="AudioContext.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="AudioContext.idl.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>