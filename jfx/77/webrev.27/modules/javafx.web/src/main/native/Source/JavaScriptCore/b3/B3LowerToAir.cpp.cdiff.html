<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/b3/B3LowerToAir.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="B3LowerMacrosAfterOptimizations.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="B3MemoryValue.cpp.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/b3/B3LowerToAir.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,7 ***</span>
  /*
<span class="line-modified">!  * Copyright (C) 2015-2017 Apple Inc. All rights reserved.</span>
   *
   * Redistribution and use in source and binary forms, with or without
   * modification, are permitted provided that the following conditions
   * are met:
   * 1. Redistributions of source code must retain the above copyright
<span class="line-new-header">--- 1,7 ---</span>
  /*
<span class="line-modified">!  * Copyright (C) 2015-2019 Apple Inc. All rights reserved.</span>
   *
   * Redistribution and use in source and binary forms, with or without
   * modification, are permitted provided that the following conditions
   * are met:
   * 1. Redistributions of source code must retain the above copyright
</pre>
<hr />
<pre>
<span class="line-old-header">*** 41,10 ***</span>
<span class="line-new-header">--- 41,11 ---</span>
  #include &quot;B3BlockWorklist.h&quot;
  #include &quot;B3CCallValue.h&quot;
  #include &quot;B3CheckSpecial.h&quot;
  #include &quot;B3Commutativity.h&quot;
  #include &quot;B3Dominators.h&quot;
<span class="line-added">+ #include &quot;B3ExtractValue.h&quot;</span>
  #include &quot;B3FenceValue.h&quot;
  #include &quot;B3MemoryValueInlines.h&quot;
  #include &quot;B3PatchpointSpecial.h&quot;
  #include &quot;B3PatchpointValue.h&quot;
  #include &quot;B3PhaseScope.h&quot;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 113,27 ***</span>
      {
          using namespace Air;
          for (B3::BasicBlock* block : m_procedure)
              m_blockToBlock[block] = m_code.addBlock(block-&gt;frequency());
  
          for (Value* value : m_procedure.values()) {
              switch (value-&gt;opcode()) {
              case Phi: {
                  m_phiToTmp[value] = m_code.newTmp(value-&gt;resultBank());
                  if (B3LowerToAirInternal::verbose)
                      dataLog(&quot;Phi tmp for &quot;, *value, &quot;: &quot;, m_phiToTmp[value], &quot;\n&quot;);
                  break;
              }
              default:
                  break;
              }
          }
  
          for (B3::StackSlot* stack : m_procedure.stackSlots())
              m_stackToStack.add(stack, m_code.addStackSlot(stack));
<span class="line-modified">!         for (Variable* variable : m_procedure.variables())</span>
<span class="line-modified">!             m_variableToTmp.add(variable, m_code.newTmp(variable-&gt;bank()));</span>
  
          // Figure out which blocks are not rare.
          m_fastWorklist.push(m_procedure[0]);
          while (B3::BasicBlock* block = m_fastWorklist.pop()) {
              for (B3::FrequentedBlock&amp; successor : block-&gt;successors()) {
<span class="line-new-header">--- 114,54 ---</span>
      {
          using namespace Air;
          for (B3::BasicBlock* block : m_procedure)
              m_blockToBlock[block] = m_code.addBlock(block-&gt;frequency());
  
<span class="line-added">+         auto ensureTupleTmps = [&amp;] (Value* tupleValue, auto&amp; hashTable) {</span>
<span class="line-added">+             hashTable.ensure(tupleValue, [&amp;] {</span>
<span class="line-added">+                 const auto tuple = m_procedure.tupleForType(tupleValue-&gt;type());</span>
<span class="line-added">+                 Vector&lt;Tmp&gt; tmps(tuple.size());</span>
<span class="line-added">+ </span>
<span class="line-added">+                 for (unsigned i = 0; i &lt; tuple.size(); ++i)</span>
<span class="line-added">+                     tmps[i] = tmpForType(tuple[i]);</span>
<span class="line-added">+                 return tmps;</span>
<span class="line-added">+             });</span>
<span class="line-added">+         };</span>
<span class="line-added">+ </span>
          for (Value* value : m_procedure.values()) {
              switch (value-&gt;opcode()) {
              case Phi: {
<span class="line-added">+                 if (value-&gt;type().isTuple()) {</span>
<span class="line-added">+                     ensureTupleTmps(value, m_tuplePhiToTmps);</span>
<span class="line-added">+                     ensureTupleTmps(value, m_tupleValueToTmps);</span>
<span class="line-added">+                     break;</span>
<span class="line-added">+                 }</span>
<span class="line-added">+ </span>
                  m_phiToTmp[value] = m_code.newTmp(value-&gt;resultBank());
                  if (B3LowerToAirInternal::verbose)
                      dataLog(&quot;Phi tmp for &quot;, *value, &quot;: &quot;, m_phiToTmp[value], &quot;\n&quot;);
                  break;
              }
<span class="line-added">+             case Get:</span>
<span class="line-added">+             case Patchpoint: {</span>
<span class="line-added">+                 if (value-&gt;type().isTuple())</span>
<span class="line-added">+                     ensureTupleTmps(value, m_tupleValueToTmps);</span>
<span class="line-added">+                 break;</span>
<span class="line-added">+             }</span>
              default:
                  break;
              }
          }
  
          for (B3::StackSlot* stack : m_procedure.stackSlots())
              m_stackToStack.add(stack, m_code.addStackSlot(stack));
<span class="line-modified">!         for (Variable* variable : m_procedure.variables()) {</span>
<span class="line-modified">!             auto addResult = m_variableToTmps.add(variable, Vector&lt;Tmp, 1&gt;(m_procedure.returnCount(variable-&gt;type())));</span>
<span class="line-added">+             ASSERT(addResult.isNewEntry);</span>
<span class="line-added">+             for (unsigned i = 0; i &lt; m_procedure.returnCount(variable-&gt;type()); ++i)</span>
<span class="line-added">+                 addResult.iterator-&gt;value[i] = tmpForType(variable-&gt;type().isNumeric() ? variable-&gt;type() : m_procedure.extractFromTuple(variable-&gt;type(), i));</span>
<span class="line-added">+         }</span>
  
          // Figure out which blocks are not rare.
          m_fastWorklist.push(m_procedure[0]);
          while (B3::BasicBlock* block = m_fastWorklist.pop()) {
              for (B3::FrequentedBlock&amp; successor : block-&gt;successors()) {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 395,10 ***</span>
<span class="line-new-header">--- 423,33 ---</span>
      ArgPromise tmpPromise(Value* value)
      {
          return ArgPromise::tmp(value);
      }
  
<span class="line-added">+     Tmp tmpForType(Type type)</span>
<span class="line-added">+     {</span>
<span class="line-added">+         return m_code.newTmp(bankForType(type));</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
<span class="line-added">+     const Vector&lt;Tmp&gt;&amp; tmpsForTuple(Value* tupleValue)</span>
<span class="line-added">+     {</span>
<span class="line-added">+         ASSERT(tupleValue-&gt;type().isTuple());</span>
<span class="line-added">+ </span>
<span class="line-added">+         switch (tupleValue-&gt;opcode()) {</span>
<span class="line-added">+         case Phi:</span>
<span class="line-added">+         case Patchpoint: {</span>
<span class="line-added">+             return m_tupleValueToTmps.find(tupleValue)-&gt;value;</span>
<span class="line-added">+         }</span>
<span class="line-added">+         case Get:</span>
<span class="line-added">+         case Set:</span>
<span class="line-added">+             return m_variableToTmps.find(tupleValue-&gt;as&lt;VariableValue&gt;()-&gt;variable())-&gt;value;</span>
<span class="line-added">+         default:</span>
<span class="line-added">+             break;</span>
<span class="line-added">+         }</span>
<span class="line-added">+         RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
      bool canBeInternal(Value* value)
      {
          // If one of the internal things has already been computed, then we don&#39;t want to cause
          // it to be recomputed again.
          if (m_valueToTmp[value])
</pre>
<hr />
<pre>
<span class="line-old-header">*** 655,16 ***</span>
          if (Arg result = imm(value))
              return result;
          return tmp(value);
      }
  
      // By convention, we use Oops to mean &quot;I don&#39;t know&quot;.
      Air::Opcode tryOpcodeForType(
          Air::Opcode opcode32, Air::Opcode opcode64, Air::Opcode opcodeDouble, Air::Opcode opcodeFloat, Type type)
      {
          Air::Opcode opcode;
<span class="line-modified">!         switch (type) {</span>
          case Int32:
              opcode = opcode32;
              break;
          case Int64:
              opcode = opcode64;
<span class="line-new-header">--- 706,31 ---</span>
          if (Arg result = imm(value))
              return result;
          return tmp(value);
      }
  
<span class="line-added">+     template&lt;typename Functor&gt;</span>
<span class="line-added">+     void forEachImmOrTmp(Value* value, const Functor&amp; func)</span>
<span class="line-added">+     {</span>
<span class="line-added">+         ASSERT(value-&gt;type() != Void);</span>
<span class="line-added">+         if (!value-&gt;type().isTuple()) {</span>
<span class="line-added">+             func(immOrTmp(value), value-&gt;type(), 0);</span>
<span class="line-added">+             return;</span>
<span class="line-added">+         }</span>
<span class="line-added">+ </span>
<span class="line-added">+         const Vector&lt;Type&gt;&amp; tuple = m_procedure.tupleForType(value-&gt;type());</span>
<span class="line-added">+         const auto&amp; tmps = tmpsForTuple(value);</span>
<span class="line-added">+         for (unsigned i = 0; i &lt; tuple.size(); ++i)</span>
<span class="line-added">+             func(tmps[i], tuple[i], i);</span>
<span class="line-added">+     }</span>
<span class="line-added">+ </span>
      // By convention, we use Oops to mean &quot;I don&#39;t know&quot;.
      Air::Opcode tryOpcodeForType(
          Air::Opcode opcode32, Air::Opcode opcode64, Air::Opcode opcodeDouble, Air::Opcode opcodeFloat, Type type)
      {
          Air::Opcode opcode;
<span class="line-modified">!         switch (type.kind()) {</span>
          case Int32:
              opcode = opcode32;
              break;
          case Int64:
              opcode = opcode64;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1108,31 ***</span>
      }
  
      Air::Opcode moveForType(Type type)
      {
          using namespace Air;
<span class="line-modified">!         switch (type) {</span>
          case Int32:
              return Move32;
          case Int64:
              RELEASE_ASSERT(is64Bit());
              return Move;
          case Float:
              return MoveFloat;
          case Double:
              return MoveDouble;
          case Void:
              break;
          }
          RELEASE_ASSERT_NOT_REACHED();
          return Air::Oops;
      }
  
      Air::Opcode relaxedMoveForType(Type type)
      {
          using namespace Air;
<span class="line-modified">!         switch (type) {</span>
          case Int32:
          case Int64:
              // For Int32, we could return Move or Move32. It&#39;s a trade-off.
              //
              // Move32: Using Move32 guarantees that we use the narrower move, but in cases where the
<span class="line-new-header">--- 1174,32 ---</span>
      }
  
      Air::Opcode moveForType(Type type)
      {
          using namespace Air;
<span class="line-modified">!         switch (type.kind()) {</span>
          case Int32:
              return Move32;
          case Int64:
              RELEASE_ASSERT(is64Bit());
              return Move;
          case Float:
              return MoveFloat;
          case Double:
              return MoveDouble;
          case Void:
<span class="line-added">+         case Tuple:</span>
              break;
          }
          RELEASE_ASSERT_NOT_REACHED();
          return Air::Oops;
      }
  
      Air::Opcode relaxedMoveForType(Type type)
      {
          using namespace Air;
<span class="line-modified">!         switch (type.kind()) {</span>
          case Int32:
          case Int64:
              // For Int32, we could return Move or Move32. It&#39;s a trade-off.
              //
              // Move32: Using Move32 guarantees that we use the narrower move, but in cases where the
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1153,10 ***</span>
<span class="line-new-header">--- 1220,11 ---</span>
              // should use MoveFloat when we know that the temporaries involved are 32-bit.
              return MoveFloat;
          case Double:
              return MoveDouble;
          case Void:
<span class="line-added">+         case Tuple:</span>
              break;
          }
          RELEASE_ASSERT_NOT_REACHED();
          return Air::Oops;
      }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1171,11 ***</span>
  
      template&lt;typename... Arguments&gt;
      void print(Value* origin, Arguments&amp;&amp;... arguments)
      {
          auto printList = Printer::makePrintRecordList(arguments...);
<span class="line-modified">!         auto printSpecial = static_cast&lt;Air::PrintSpecial*&gt;(m_code.addSpecial(std::make_unique&lt;Air::PrintSpecial&gt;(printList)));</span>
          Inst inst(Air::Patch, origin, Arg::special(printSpecial));
          Printer::appendAirArgs(inst, std::forward&lt;Arguments&gt;(arguments)...);
          append(WTFMove(inst));
      }
  #endif // ENABLE(MASM_PROBE)
<span class="line-new-header">--- 1239,11 ---</span>
  
      template&lt;typename... Arguments&gt;
      void print(Value* origin, Arguments&amp;&amp;... arguments)
      {
          auto printList = Printer::makePrintRecordList(arguments...);
<span class="line-modified">!         auto printSpecial = static_cast&lt;Air::PrintSpecial*&gt;(m_code.addSpecial(makeUnique&lt;Air::PrintSpecial&gt;(printList)));</span>
          Inst inst(Air::Patch, origin, Arg::special(printSpecial));
          Printer::appendAirArgs(inst, std::forward&lt;Arguments&gt;(arguments)...);
          append(WTFMove(inst));
      }
  #endif // ENABLE(MASM_PROBE)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1238,11 ***</span>
      template&lt;typename T, typename... Arguments&gt;
      T* ensureSpecial(T*&amp; field, Arguments&amp;&amp;... arguments)
      {
          if (!field) {
              field = static_cast&lt;T*&gt;(
<span class="line-modified">!                 m_code.addSpecial(std::make_unique&lt;T&gt;(std::forward&lt;Arguments&gt;(arguments)...)));</span>
          }
          return field;
      }
  
      template&lt;typename... Arguments&gt;
<span class="line-new-header">--- 1306,11 ---</span>
      template&lt;typename T, typename... Arguments&gt;
      T* ensureSpecial(T*&amp; field, Arguments&amp;&amp;... arguments)
      {
          if (!field) {
              field = static_cast&lt;T*&gt;(
<span class="line-modified">!                 m_code.addSpecial(makeUnique&lt;T&gt;(std::forward&lt;Arguments&gt;(arguments)...)));</span>
          }
          return field;
      }
  
      template&lt;typename... Arguments&gt;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1268,14 ***</span>
<span class="line-new-header">--- 1336,18 ---</span>
                  else if (value.value()-&gt;hasInt64())
                      arg = Arg::bigImm(value.value()-&gt;asInt64());
                  else if (value.value()-&gt;hasDouble() &amp;&amp; canBeInternal(value.value())) {
                      commitInternal(value.value());
                      arg = Arg::bigImm(bitwise_cast&lt;int64_t&gt;(value.value()-&gt;asDouble()));
<span class="line-added">+                 } else if (value.value()-&gt;hasFloat() &amp;&amp; canBeInternal(value.value())) {</span>
<span class="line-added">+                     commitInternal(value.value());</span>
<span class="line-added">+                     arg = Arg::bigImm(static_cast&lt;uint64_t&gt;(bitwise_cast&lt;uint32_t&gt;(value.value()-&gt;asFloat())));</span>
                  } else
                      arg = tmp(value.value());
                  break;
              case ValueRep::SomeRegister:
<span class="line-added">+             case ValueRep::SomeLateRegister:</span>
                  arg = tmp(value.value());
                  break;
              case ValueRep::SomeRegisterWithClobber: {
                  Tmp dstTmp = m_code.newTmp(value.value()-&gt;resultBank());
                  append(relaxedMoveForType(value.value()-&gt;type()), immOrTmp(value.value()), dstTmp);
</pre>
<hr />
<pre>
<span class="line-old-header">*** 1458,11 ***</span>
              Arg relCond = Arg::relCond(relationalCondition).inverted(inverted);
              Arg doubleCond = Arg::doubleCond(doubleCondition).inverted(inverted);
              Value* left = value-&gt;child(0);
              Value* right = value-&gt;child(1);
  
<span class="line-modified">!             if (isInt(value-&gt;child(0)-&gt;type())) {</span>
                  Arg rightImm = imm(right);
  
                  auto tryCompare = [&amp;] (
                      Width width, ArgPromise&amp;&amp; left, ArgPromise&amp;&amp; right) -&gt; Inst {
                      if (Inst result = compare(width, relCond, left, right))
<span class="line-new-header">--- 1530,11 ---</span>
              Arg relCond = Arg::relCond(relationalCondition).inverted(inverted);
              Arg doubleCond = Arg::doubleCond(doubleCondition).inverted(inverted);
              Value* left = value-&gt;child(0);
              Value* right = value-&gt;child(1);
  
<span class="line-modified">!             if (value-&gt;child(0)-&gt;type().isInt()) {</span>
                  Arg rightImm = imm(right);
  
                  auto tryCompare = [&amp;] (
                      Width width, ArgPromise&amp;&amp; left, ArgPromise&amp;&amp; right) -&gt; Inst {
                      if (Inst result = compare(width, relCond, left, right))
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2122,11 ***</span>
      void appendX86Div(B3::Opcode op)
      {
          using namespace Air;
          Air::Opcode convertToDoubleWord;
          Air::Opcode div;
<span class="line-modified">!         switch (m_value-&gt;type()) {</span>
          case Int32:
              convertToDoubleWord = X86ConvertToDoubleWord32;
              div = X86Div32;
              break;
          case Int64:
<span class="line-new-header">--- 2194,11 ---</span>
      void appendX86Div(B3::Opcode op)
      {
          using namespace Air;
          Air::Opcode convertToDoubleWord;
          Air::Opcode div;
<span class="line-modified">!         switch (m_value-&gt;type().kind()) {</span>
          case Int32:
              convertToDoubleWord = X86ConvertToDoubleWord32;
              div = X86Div32;
              break;
          case Int64:
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2446,11 ***</span>
              Air::Kind kind = moveForType(memory-&gt;type());
              if (memory-&gt;hasFence()) {
                  if (isX86())
                      kind.effects = true;
                  else {
<span class="line-modified">!                     switch (memory-&gt;type()) {</span>
                      case Int32:
                          kind = LoadAcq32;
                          break;
                      case Int64:
                          kind = LoadAcq64;
<span class="line-new-header">--- 2518,11 ---</span>
              Air::Kind kind = moveForType(memory-&gt;type());
              if (memory-&gt;hasFence()) {
                  if (isX86())
                      kind.effects = true;
                  else {
<span class="line-modified">!                     switch (memory-&gt;type().kind()) {</span>
                      case Int32:
                          kind = LoadAcq32;
                          break;
                      case Int64:
                          kind = LoadAcq64;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2599,35 ***</span>
              appendUnOp&lt;Neg32, Neg64, NegateDouble, NegateFloat&gt;(m_value-&gt;child(0));
              return;
          }
  
          case Mul: {
              appendBinOp&lt;Mul32, Mul64, MulDouble, MulFloat, Commutative&gt;(
                  m_value-&gt;child(0), m_value-&gt;child(1));
              return;
          }
  
          case Div: {
              if (m_value-&gt;isChill())
                  RELEASE_ASSERT(isARM64());
<span class="line-modified">!             if (isInt(m_value-&gt;type()) &amp;&amp; isX86()) {</span>
                  appendX86Div(Div);
                  return;
              }
<span class="line-modified">!             ASSERT(!isX86() || isFloat(m_value-&gt;type()));</span>
  
              appendBinOp&lt;Div32, Div64, DivDouble, DivFloat&gt;(m_value-&gt;child(0), m_value-&gt;child(1));
              return;
          }
  
          case UDiv: {
<span class="line-modified">!             if (isInt(m_value-&gt;type()) &amp;&amp; isX86()) {</span>
                  appendX86UDiv(UDiv);
                  return;
              }
  
<span class="line-modified">!             ASSERT(!isX86() &amp;&amp; !isFloat(m_value-&gt;type()));</span>
  
              appendBinOp&lt;UDiv32, UDiv64, Air::Oops, Air::Oops&gt;(m_value-&gt;child(0), m_value-&gt;child(1));
              return;
  
          }
<span class="line-new-header">--- 2671,56 ---</span>
              appendUnOp&lt;Neg32, Neg64, NegateDouble, NegateFloat&gt;(m_value-&gt;child(0));
              return;
          }
  
          case Mul: {
<span class="line-added">+             if (m_value-&gt;type() == Int64</span>
<span class="line-added">+                 &amp;&amp; isValidForm(MultiplySignExtend32, Arg::Tmp, Arg::Tmp, Arg::Tmp)</span>
<span class="line-added">+                 &amp;&amp; m_value-&gt;child(0)-&gt;opcode() == SExt32</span>
<span class="line-added">+                 &amp;&amp; !m_locked.contains(m_value-&gt;child(0))) {</span>
<span class="line-added">+                 Value* opLeft = m_value-&gt;child(0);</span>
<span class="line-added">+                 Value* left = opLeft-&gt;child(0);</span>
<span class="line-added">+                 Value* opRight = m_value-&gt;child(1);</span>
<span class="line-added">+                 Value* right = nullptr;</span>
<span class="line-added">+ </span>
<span class="line-added">+                 if (opRight-&gt;opcode() == SExt32 &amp;&amp; !m_locked.contains(opRight-&gt;child(0))) {</span>
<span class="line-added">+                     right = opRight-&gt;child(0);</span>
<span class="line-added">+                 } else if (m_value-&gt;child(1)-&gt;isRepresentableAs&lt;int32_t&gt;() &amp;&amp; !m_locked.contains(m_value-&gt;child(1))) {</span>
<span class="line-added">+                     // We just use the 64-bit const int as a 32 bit const int directly</span>
<span class="line-added">+                     right = opRight;</span>
<span class="line-added">+                 }</span>
<span class="line-added">+ </span>
<span class="line-added">+                 if (right) {</span>
<span class="line-added">+                     append(MultiplySignExtend32, tmp(left), tmp(right), tmp(m_value));</span>
<span class="line-added">+                     return;</span>
<span class="line-added">+                 }</span>
<span class="line-added">+             }</span>
              appendBinOp&lt;Mul32, Mul64, MulDouble, MulFloat, Commutative&gt;(
                  m_value-&gt;child(0), m_value-&gt;child(1));
              return;
          }
  
          case Div: {
              if (m_value-&gt;isChill())
                  RELEASE_ASSERT(isARM64());
<span class="line-modified">!             if (m_value-&gt;type().isInt() &amp;&amp; isX86()) {</span>
                  appendX86Div(Div);
                  return;
              }
<span class="line-modified">!             ASSERT(!isX86() || m_value-&gt;type().isFloat());</span>
  
              appendBinOp&lt;Div32, Div64, DivDouble, DivFloat&gt;(m_value-&gt;child(0), m_value-&gt;child(1));
              return;
          }
  
          case UDiv: {
<span class="line-modified">!             if (m_value-&gt;type().isInt() &amp;&amp; isX86()) {</span>
                  appendX86UDiv(UDiv);
                  return;
              }
  
<span class="line-modified">!             ASSERT(!isX86() &amp;&amp; !m_value-&gt;type().isFloat());</span>
  
              appendBinOp&lt;UDiv32, UDiv64, Air::Oops, Air::Oops&gt;(m_value-&gt;child(0), m_value-&gt;child(1));
              return;
  
          }
</pre>
<hr />
<pre>
<span class="line-old-header">*** 2986,11 ***</span>
              return;
          }
  
          case Select: {
              MoveConditionallyConfig config;
<span class="line-modified">!             if (isInt(m_value-&gt;type())) {</span>
                  config.moveConditionally32 = MoveConditionally32;
                  config.moveConditionally64 = MoveConditionally64;
                  config.moveConditionallyTest32 = MoveConditionallyTest32;
                  config.moveConditionallyTest64 = MoveConditionallyTest64;
                  config.moveConditionallyDouble = MoveConditionallyDouble;
<span class="line-new-header">--- 3079,11 ---</span>
              return;
          }
  
          case Select: {
              MoveConditionallyConfig config;
<span class="line-modified">!             if (m_value-&gt;type().isInt()) {</span>
                  config.moveConditionally32 = MoveConditionally32;
                  config.moveConditionally64 = MoveConditionally64;
                  config.moveConditionallyTest32 = MoveConditionallyTest32;
                  config.moveConditionallyTest64 = MoveConditionallyTest64;
                  config.moveConditionallyDouble = MoveConditionallyDouble;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3051,43 ***</span>
              ensureSpecial(m_patchpointSpecial);
  
              Inst inst(Patch, patchpointValue, Arg::special(m_patchpointSpecial));
  
              Vector&lt;Inst&gt; after;
<span class="line-modified">!             if (patchpointValue-&gt;type() != Void) {</span>
<span class="line-modified">!                 switch (patchpointValue-&gt;resultConstraint.kind()) {</span>
                  case ValueRep::WarmAny:
                  case ValueRep::ColdAny:
                  case ValueRep::LateColdAny:
                  case ValueRep::SomeRegister:
                  case ValueRep::SomeEarlyRegister:
<span class="line-modified">!                     inst.args.append(tmp(patchpointValue));</span>
<span class="line-modified">!                     break;</span>
                  case ValueRep::Register: {
<span class="line-modified">!                     Tmp reg = Tmp(patchpointValue-&gt;resultConstraint.reg());</span>
                      inst.args.append(reg);
<span class="line-modified">!                     after.append(Inst(</span>
<span class="line-modified">!                         relaxedMoveForType(patchpointValue-&gt;type()), m_value, reg, tmp(patchpointValue)));</span>
<span class="line-removed">-                     break;</span>
                  }
                  case ValueRep::StackArgument: {
<span class="line-modified">!                     Arg arg = Arg::callArg(patchpointValue-&gt;resultConstraint.offsetFromSP());</span>
                      inst.args.append(arg);
<span class="line-modified">!                     after.append(Inst(</span>
<span class="line-modified">!                         moveForType(patchpointValue-&gt;type()), m_value, arg, tmp(patchpointValue)));</span>
<span class="line-removed">-                     break;</span>
                  }
                  default:
                      RELEASE_ASSERT_NOT_REACHED();
<span class="line-modified">!                     break;</span>
                  }
              }
  
              fillStackmap(inst, patchpointValue, 0);
<span class="line-modified">! </span>
<span class="line-modified">!             if (patchpointValue-&gt;resultConstraint.isReg())</span>
<span class="line-modified">!                 patchpointValue-&gt;lateClobbered().clear(patchpointValue-&gt;resultConstraint.reg());</span>
  
              for (unsigned i = patchpointValue-&gt;numGPScratchRegisters; i--;)
                  inst.args.append(m_code.newTmp(GP));
              for (unsigned i = patchpointValue-&gt;numFPScratchRegisters; i--;)
                  inst.args.append(m_code.newTmp(FP));
<span class="line-new-header">--- 3144,49 ---</span>
              ensureSpecial(m_patchpointSpecial);
  
              Inst inst(Patch, patchpointValue, Arg::special(m_patchpointSpecial));
  
              Vector&lt;Inst&gt; after;
<span class="line-modified">!             auto generateResultOperand = [&amp;] (Type type, ValueRep rep, Tmp tmp) {</span>
<span class="line-modified">!                 switch (rep.kind()) {</span>
                  case ValueRep::WarmAny:
                  case ValueRep::ColdAny:
                  case ValueRep::LateColdAny:
                  case ValueRep::SomeRegister:
                  case ValueRep::SomeEarlyRegister:
<span class="line-modified">!                 case ValueRep::SomeLateRegister:</span>
<span class="line-modified">!                     inst.args.append(tmp);</span>
<span class="line-added">+                     return;</span>
                  case ValueRep::Register: {
<span class="line-modified">!                     Tmp reg = Tmp(rep.reg());</span>
                      inst.args.append(reg);
<span class="line-modified">!                     after.append(Inst(relaxedMoveForType(type), m_value, reg, tmp));</span>
<span class="line-modified">!                     return;</span>
                  }
                  case ValueRep::StackArgument: {
<span class="line-modified">!                     Arg arg = Arg::callArg(rep.offsetFromSP());</span>
                      inst.args.append(arg);
<span class="line-modified">!                     after.append(Inst(moveForType(type), m_value, arg, tmp));</span>
<span class="line-modified">!                     return;</span>
                  }
                  default:
                      RELEASE_ASSERT_NOT_REACHED();
<span class="line-modified">!                     return;</span>
                  }
<span class="line-added">+             };</span>
<span class="line-added">+ </span>
<span class="line-added">+             if (patchpointValue-&gt;type() != Void) {</span>
<span class="line-added">+                 forEachImmOrTmp(patchpointValue, [&amp;] (Arg arg, Type type, unsigned index) {</span>
<span class="line-added">+                     generateResultOperand(type, patchpointValue-&gt;resultConstraints[index], arg.tmp());</span>
<span class="line-added">+                 });</span>
              }
  
              fillStackmap(inst, patchpointValue, 0);
<span class="line-modified">!             for (auto&amp; constraint : patchpointValue-&gt;resultConstraints) {</span>
<span class="line-modified">!                 if (constraint.isReg())</span>
<span class="line-modified">!                     patchpointValue-&gt;lateClobbered().clear(constraint.reg());</span>
<span class="line-added">+             }</span>
  
              for (unsigned i = patchpointValue-&gt;numGPScratchRegisters; i--;)
                  inst.args.append(m_code.newTmp(GP));
              for (unsigned i = patchpointValue-&gt;numFPScratchRegisters; i--;)
                  inst.args.append(m_code.newTmp(FP));
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3095,10 ***</span>
<span class="line-new-header">--- 3194,19 ---</span>
              m_insts.last().append(WTFMove(inst));
              m_insts.last().appendVector(after);
              return;
          }
  
<span class="line-added">+         case Extract: {</span>
<span class="line-added">+             Value* tupleValue = m_value-&gt;child(0);</span>
<span class="line-added">+             unsigned index = m_value-&gt;as&lt;ExtractValue&gt;()-&gt;index();</span>
<span class="line-added">+ </span>
<span class="line-added">+             const auto&amp; tmps = tmpsForTuple(tupleValue);</span>
<span class="line-added">+             append(relaxedMoveForType(m_value-&gt;type()), tmps[index], tmp(m_value));</span>
<span class="line-added">+             return;</span>
<span class="line-added">+         }</span>
<span class="line-added">+ </span>
          case CheckAdd:
          case CheckSub:
          case CheckMul: {
              CheckValue* checkValue = m_value-&gt;as&lt;CheckValue&gt;();
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3267,45 ***</span>
              return;
          }
  
          case Upsilon: {
              Value* value = m_value-&gt;child(0);
<span class="line-modified">!             append(</span>
<span class="line-modified">!                 relaxedMoveForType(value-&gt;type()), immOrTmp(value),</span>
<span class="line-modified">!                 m_phiToTmp[m_value-&gt;as&lt;UpsilonValue&gt;()-&gt;phi()]);</span>
              return;
          }
  
          case Phi: {
              // Snapshot the value of the Phi. It may change under us because you could do:
              // a = Phi()
              // Upsilon(@x, ^a)
              // @a =&gt; this should get the value of the Phi before the Upsilon, i.e. not @x.
  
<span class="line-modified">!             append(relaxedMoveForType(m_value-&gt;type()), m_phiToTmp[m_value], tmp(m_value));</span>
              return;
          }
  
          case Set: {
              Value* value = m_value-&gt;child(0);
<span class="line-modified">!             append(</span>
<span class="line-modified">!                 relaxedMoveForType(value-&gt;type()), immOrTmp(value),</span>
<span class="line-modified">!                 m_variableToTmp.get(m_value-&gt;as&lt;VariableValue&gt;()-&gt;variable()));</span>
              return;
          }
  
          case Get: {
<span class="line-modified">!             append(</span>
<span class="line-modified">!                 relaxedMoveForType(m_value-&gt;type()),</span>
<span class="line-modified">!                 m_variableToTmp.get(m_value-&gt;as&lt;VariableValue&gt;()-&gt;variable()), tmp(m_value));</span>
              return;
          }
  
          case Branch: {
              if (canBeInternal(m_value-&gt;child(0))) {
                  Value* branchChild = m_value-&gt;child(0);
                  switch (branchChild-&gt;opcode()) {
                  case AtomicWeakCAS:
                      commitInternal(branchChild);
                      appendCAS(branchChild, false);
                      return;
  
<span class="line-new-header">--- 3375,148 ---</span>
              return;
          }
  
          case Upsilon: {
              Value* value = m_value-&gt;child(0);
<span class="line-modified">!             Value* phi = m_value-&gt;as&lt;UpsilonValue&gt;()-&gt;phi();</span>
<span class="line-modified">!             if (value-&gt;type().isNumeric()) {</span>
<span class="line-modified">!                 append(relaxedMoveForType(value-&gt;type()), immOrTmp(value), m_phiToTmp[phi]);</span>
<span class="line-added">+                 return;</span>
<span class="line-added">+             }</span>
<span class="line-added">+ </span>
<span class="line-added">+             const Vector&lt;Type&gt;&amp; tuple = m_procedure.tupleForType(value-&gt;type());</span>
<span class="line-added">+             const auto&amp; valueTmps = tmpsForTuple(value);</span>
<span class="line-added">+             const auto&amp; phiTmps = m_tuplePhiToTmps.find(phi)-&gt;value;</span>
<span class="line-added">+             ASSERT(valueTmps.size() == phiTmps.size());</span>
<span class="line-added">+             for (unsigned i = 0; i &lt; valueTmps.size(); ++i)</span>
<span class="line-added">+                 append(relaxedMoveForType(tuple[i]), valueTmps[i], phiTmps[i]);</span>
              return;
          }
  
          case Phi: {
              // Snapshot the value of the Phi. It may change under us because you could do:
              // a = Phi()
              // Upsilon(@x, ^a)
              // @a =&gt; this should get the value of the Phi before the Upsilon, i.e. not @x.
  
<span class="line-modified">!             if (m_value-&gt;type().isNumeric()) {</span>
<span class="line-added">+                 append(relaxedMoveForType(m_value-&gt;type()), m_phiToTmp[m_value], tmp(m_value));</span>
<span class="line-added">+                 return;</span>
<span class="line-added">+             }</span>
<span class="line-added">+ </span>
<span class="line-added">+             const Vector&lt;Type&gt;&amp; tuple = m_procedure.tupleForType(m_value-&gt;type());</span>
<span class="line-added">+             const auto&amp; valueTmps = tmpsForTuple(m_value);</span>
<span class="line-added">+             const auto&amp; phiTmps = m_tuplePhiToTmps.find(m_value)-&gt;value;</span>
<span class="line-added">+             ASSERT(valueTmps.size() == phiTmps.size());</span>
<span class="line-added">+             for (unsigned i = 0; i &lt; valueTmps.size(); ++i)</span>
<span class="line-added">+                 append(relaxedMoveForType(tuple[i]), phiTmps[i], valueTmps[i]);</span>
              return;
          }
  
          case Set: {
              Value* value = m_value-&gt;child(0);
<span class="line-modified">!             const Vector&lt;Tmp&gt;&amp; variableTmps = m_variableToTmps.get(m_value-&gt;as&lt;VariableValue&gt;()-&gt;variable());</span>
<span class="line-modified">!             forEachImmOrTmp(value, [&amp;] (Arg immOrTmp, Type type, unsigned index) {</span>
<span class="line-modified">!                 append(relaxedMoveForType(type), immOrTmp, variableTmps[index]);</span>
<span class="line-added">+             });</span>
              return;
          }
  
          case Get: {
<span class="line-modified">!             // Snapshot the value of the Get. It may change under us because you could do:</span>
<span class="line-modified">!             // a = Get(var)</span>
<span class="line-modified">!             // Set(@x, var)</span>
<span class="line-added">+             // @a =&gt; this should get the value of the Get before the Set, i.e. not @x.</span>
<span class="line-added">+ </span>
<span class="line-added">+             const Vector&lt;Tmp&gt;&amp; variableTmps = m_variableToTmps.get(m_value-&gt;as&lt;VariableValue&gt;()-&gt;variable());</span>
<span class="line-added">+             forEachImmOrTmp(m_value, [&amp;] (Arg tmp, Type type, unsigned index) {</span>
<span class="line-added">+                 append(relaxedMoveForType(type), variableTmps[index], tmp.tmp());</span>
<span class="line-added">+             });</span>
              return;
          }
  
          case Branch: {
              if (canBeInternal(m_value-&gt;child(0))) {
                  Value* branchChild = m_value-&gt;child(0);
<span class="line-added">+ </span>
                  switch (branchChild-&gt;opcode()) {
<span class="line-added">+                 case BitAnd: {</span>
<span class="line-added">+                     Value* andValue = branchChild-&gt;child(0);</span>
<span class="line-added">+                     Value* andMask = branchChild-&gt;child(1);</span>
<span class="line-added">+                     Air::Opcode opcode = opcodeForType(BranchTestBit32, BranchTestBit64, andValue-&gt;type());</span>
<span class="line-added">+ </span>
<span class="line-added">+                     Value* testValue = nullptr;</span>
<span class="line-added">+                     Value* bitOffset = nullptr;</span>
<span class="line-added">+                     Value* internalNode = nullptr;</span>
<span class="line-added">+                     Value* negationNode = nullptr;</span>
<span class="line-added">+                     bool inverted = false;</span>
<span class="line-added">+ </span>
<span class="line-added">+                     // if (~(val &gt;&gt; x)&amp;1)</span>
<span class="line-added">+                     if (andMask-&gt;isInt(1)</span>
<span class="line-added">+                         &amp;&amp; andValue-&gt;opcode() == BitXor &amp;&amp; (andValue-&gt;child(1)-&gt;isInt32(-1) || andValue-&gt;child(1)-&gt;isInt64(-1l))</span>
<span class="line-added">+                         &amp;&amp; (andValue-&gt;child(0)-&gt;opcode() == SShr || andValue-&gt;child(0)-&gt;opcode() == ZShr)) {</span>
<span class="line-added">+ </span>
<span class="line-added">+                         negationNode = andValue;</span>
<span class="line-added">+                         testValue = andValue-&gt;child(0)-&gt;child(0);</span>
<span class="line-added">+                         bitOffset = andValue-&gt;child(0)-&gt;child(1);</span>
<span class="line-added">+                         internalNode = andValue-&gt;child(0);</span>
<span class="line-added">+                         inverted = !inverted;</span>
<span class="line-added">+                     }</span>
<span class="line-added">+ </span>
<span class="line-added">+                     // Turn if ((val &gt;&gt; x)&amp;1) -&gt; Bt val x</span>
<span class="line-added">+                     if (andMask-&gt;isInt(1) &amp;&amp; (andValue-&gt;opcode() == SShr || andValue-&gt;opcode() == ZShr)) {</span>
<span class="line-added">+                         testValue = andValue-&gt;child(0);</span>
<span class="line-added">+                         bitOffset = andValue-&gt;child(1);</span>
<span class="line-added">+                         internalNode = andValue;</span>
<span class="line-added">+                     }</span>
<span class="line-added">+ </span>
<span class="line-added">+                     // Turn if (val &amp; (1&lt;&lt;x)) -&gt; Bt val x</span>
<span class="line-added">+                     if ((andMask-&gt;opcode() == Shl) &amp;&amp; andMask-&gt;child(0)-&gt;isInt(1)) {</span>
<span class="line-added">+                         testValue = andValue;</span>
<span class="line-added">+                         bitOffset = andMask-&gt;child(1);</span>
<span class="line-added">+                         internalNode = andMask;</span>
<span class="line-added">+                     }</span>
<span class="line-added">+ </span>
<span class="line-added">+                     // if (~val &amp; (1&lt;&lt;x)) or if ((~val &gt;&gt; x)&amp;1)</span>
<span class="line-added">+                     if (!negationNode &amp;&amp; testValue &amp;&amp; testValue-&gt;opcode() == BitXor &amp;&amp; (testValue-&gt;child(1)-&gt;isInt32(-1) || testValue-&gt;child(1)-&gt;isInt64(-1l))) {</span>
<span class="line-added">+                         negationNode = testValue;</span>
<span class="line-added">+                         testValue = testValue-&gt;child(0);</span>
<span class="line-added">+                         inverted = !inverted;</span>
<span class="line-added">+                     }</span>
<span class="line-added">+ </span>
<span class="line-added">+                     if (testValue &amp;&amp; bitOffset) {</span>
<span class="line-added">+                         for (auto&amp; basePromise : Vector&lt;ArgPromise&gt;::from(loadPromise(testValue), tmpPromise(testValue))) {</span>
<span class="line-added">+                             bool hasLoad = basePromise.kind() != Arg::Tmp;</span>
<span class="line-added">+                             bool canMakeInternal = (hasLoad ? canBeInternal(testValue) : !m_locked.contains(testValue))</span>
<span class="line-added">+                                 &amp;&amp; (!negationNode || canBeInternal(negationNode))</span>
<span class="line-added">+                                 &amp;&amp; (!internalNode || canBeInternal(internalNode));</span>
<span class="line-added">+ </span>
<span class="line-added">+                             if (basePromise &amp;&amp; canMakeInternal) {</span>
<span class="line-added">+                                 if (bitOffset-&gt;hasInt() &amp;&amp; isValidForm(opcode, Arg::ResCond, basePromise.kind(), Arg::Imm)) {</span>
<span class="line-added">+                                     commitInternal(branchChild);</span>
<span class="line-added">+                                     commitInternal(internalNode);</span>
<span class="line-added">+                                     if (hasLoad)</span>
<span class="line-added">+                                         commitInternal(testValue);</span>
<span class="line-added">+                                     commitInternal(negationNode);</span>
<span class="line-added">+                                     append(basePromise.inst(opcode, m_value, Arg::resCond(MacroAssembler::NonZero).inverted(inverted), basePromise.consume(*this), Arg::imm(bitOffset-&gt;asInt())));</span>
<span class="line-added">+                                     return;</span>
<span class="line-added">+                                 }</span>
<span class="line-added">+ </span>
<span class="line-added">+                                 if (!m_locked.contains(bitOffset) &amp;&amp; isValidForm(opcode, Arg::ResCond, basePromise.kind(), Arg::Tmp)) {</span>
<span class="line-added">+                                     commitInternal(branchChild);</span>
<span class="line-added">+                                     commitInternal(internalNode);</span>
<span class="line-added">+                                     if (hasLoad)</span>
<span class="line-added">+                                         commitInternal(testValue);</span>
<span class="line-added">+                                     commitInternal(negationNode);</span>
<span class="line-added">+                                     append(basePromise.inst(opcode, m_value, Arg::resCond(MacroAssembler::NonZero).inverted(inverted), basePromise.consume(*this), tmp(bitOffset)));</span>
<span class="line-added">+                                     return;</span>
<span class="line-added">+                                 }</span>
<span class="line-added">+                             }</span>
<span class="line-added">+                         }</span>
<span class="line-added">+                     }</span>
<span class="line-added">+                     break;</span>
<span class="line-added">+                 }</span>
                  case AtomicWeakCAS:
                      commitInternal(branchChild);
                      appendCAS(branchChild, false);
                      return;
  
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3362,12 ***</span>
                  return;
              }
              Value* value = m_value-&gt;child(0);
              Tmp returnValueGPR = Tmp(GPRInfo::returnValueGPR);
              Tmp returnValueFPR = Tmp(FPRInfo::returnValueFPR);
<span class="line-modified">!             switch (value-&gt;type()) {</span>
              case Void:
                  // It&#39;s impossible for a void value to be used as a child. We use RetVoid
                  // for void returns.
                  RELEASE_ASSERT_NOT_REACHED();
                  break;
              case Int32:
<span class="line-new-header">--- 3573,13 ---</span>
                  return;
              }
              Value* value = m_value-&gt;child(0);
              Tmp returnValueGPR = Tmp(GPRInfo::returnValueGPR);
              Tmp returnValueFPR = Tmp(FPRInfo::returnValueFPR);
<span class="line-modified">!             switch (value-&gt;type().kind()) {</span>
              case Void:
<span class="line-added">+             case Tuple:</span>
                  // It&#39;s impossible for a void value to be used as a child. We use RetVoid
                  // for void returns.
                  RELEASE_ASSERT_NOT_REACHED();
                  break;
              case Int32:
</pre>
<hr />
<pre>
<span class="line-old-header">*** 3483,13 ***</span>
      }
  
      IndexSet&lt;Value*&gt; m_locked; // These are values that will have no Tmp in Air.
      IndexMap&lt;Value*, Tmp&gt; m_valueToTmp; // These are values that must have a Tmp in Air. We say that a Value* with a non-null Tmp is &quot;pinned&quot;.
      IndexMap&lt;Value*, Tmp&gt; m_phiToTmp; // Each Phi gets its own Tmp.
      IndexMap&lt;B3::BasicBlock*, Air::BasicBlock*&gt; m_blockToBlock;
      HashMap&lt;B3::StackSlot*, Air::StackSlot*&gt; m_stackToStack;
<span class="line-modified">!     HashMap&lt;Variable*, Tmp&gt; m_variableToTmp;</span>
  
      UseCounts m_useCounts;
      PhiChildren m_phiChildren;
      BlockWorklist m_fastWorklist;
      Dominators&amp; m_dominators;
<span class="line-new-header">--- 3695,15 ---</span>
      }
  
      IndexSet&lt;Value*&gt; m_locked; // These are values that will have no Tmp in Air.
      IndexMap&lt;Value*, Tmp&gt; m_valueToTmp; // These are values that must have a Tmp in Air. We say that a Value* with a non-null Tmp is &quot;pinned&quot;.
      IndexMap&lt;Value*, Tmp&gt; m_phiToTmp; // Each Phi gets its own Tmp.
<span class="line-added">+     HashMap&lt;Value*, Vector&lt;Tmp&gt;&gt; m_tupleValueToTmps; // This is the same as m_valueToTmp for Values that are Tuples.</span>
<span class="line-added">+     HashMap&lt;Value*, Vector&lt;Tmp&gt;&gt; m_tuplePhiToTmps; // This is the same as m_phiToTmp for Phis that are Tuples.</span>
      IndexMap&lt;B3::BasicBlock*, Air::BasicBlock*&gt; m_blockToBlock;
      HashMap&lt;B3::StackSlot*, Air::StackSlot*&gt; m_stackToStack;
<span class="line-modified">!     HashMap&lt;Variable*, Vector&lt;Tmp&gt;&gt; m_variableToTmps;</span>
  
      UseCounts m_useCounts;
      PhiChildren m_phiChildren;
      BlockWorklist m_fastWorklist;
      Dominators&amp; m_dominators;
</pre>
<center><a href="B3LowerMacrosAfterOptimizations.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="B3MemoryValue.cpp.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>