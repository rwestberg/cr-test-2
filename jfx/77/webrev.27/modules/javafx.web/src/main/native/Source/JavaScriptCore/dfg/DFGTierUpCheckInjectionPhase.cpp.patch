diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGTierUpCheckInjectionPhase.cpp b/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGTierUpCheckInjectionPhase.cpp
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGTierUpCheckInjectionPhase.cpp
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGTierUpCheckInjectionPhase.cpp
@@ -67,11 +67,11 @@
             return false;
 
         if (m_graph.m_profiledBlock->m_didFailFTLCompilation)
             return false;
 
-        if (!Options::bytecodeRangeToFTLCompile().isInRange(m_graph.m_profiledBlock->instructionCount()))
+        if (!Options::bytecodeRangeToFTLCompile().isInRange(m_graph.m_profiledBlock->instructionsSize()))
             return false;
 
         if (!ensureGlobalFTLWhitelist().contains(m_graph.m_profiledBlock))
             return false;
 
@@ -106,11 +106,11 @@
                 NodeType tierUpType = CheckTierUpAndOSREnter;
                 if (!canOSREnter)
                     tierUpType = CheckTierUpInLoop;
                 insertionSet.insertNode(nodeIndex + 1, SpecNone, tierUpType, origin);
 
-                unsigned bytecodeIndex = origin.semantic.bytecodeIndex;
+                unsigned bytecodeIndex = origin.semantic.bytecodeIndex();
                 if (canOSREnter)
                     m_graph.m_plan.tierUpAndOSREnterBytecodes().append(bytecodeIndex);
 
                 if (const NaturalLoop* loop = naturalLoops.innerMostLoopOf(block)) {
                     LoopHintDescriptor descriptor;
@@ -168,11 +168,11 @@
     {
         Node* node = block->at(nodeIndex);
         ASSERT(node->op() == LoopHint);
 
         NodeOrigin origin = node->origin;
-        if (level != FTL::CanCompileAndOSREnter || origin.semantic.inlineCallFrame)
+        if (level != FTL::CanCompileAndOSREnter || origin.semantic.inlineCallFrame())
             return false;
 
         // We only put OSR checks for the first LoopHint in the block. Note that
         // more than one LoopHint could happen in cases where we did a lot of CFG
         // simplification in the bytecode parser, but it should be very rare.
@@ -192,11 +192,11 @@
                 Node* node = block->at(nodeIndex);
                 if (node->op() != LoopHint)
                     continue;
 
                 if (const NaturalLoop* loop = naturalLoops.innerMostLoopOf(block)) {
-                    unsigned bytecodeIndex = node->origin.semantic.bytecodeIndex;
+                    unsigned bytecodeIndex = node->origin.semantic.bytecodeIndex();
                     naturalLoopsToLoopHint.add(loop, bytecodeIndex);
                 }
                 break;
             }
         }
