diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioNode.h b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioNode.h
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioNode.h
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioNode.h
@@ -26,10 +26,11 @@
 
 #include "AudioBus.h"
 #include "EventTarget.h"
 #include "ExceptionOr.h"
 #include <wtf/Forward.h>
+#include <wtf/LoggerHelper.h>
 
 #define DEBUG_AUDIONODE_REFERENCES 0
 
 namespace WebCore {
 
@@ -42,13 +43,18 @@
 // It may be an audio source, an intermediate processing module, or an audio destination.
 // Each AudioNode can have inputs and/or outputs. An AudioSourceNode has no inputs and a single output.
 // An AudioDestinationNode has one input and no outputs and represents the final destination to the audio hardware.
 // Most processing nodes such as filters will have one input and one output, although multiple inputs and outputs are possible.
 
-class AudioNode : public EventTargetWithInlineData {
+class AudioNode
+    : public EventTargetWithInlineData
+#if !RELEASE_LOG_DISABLED
+    , private LoggerHelper
+#endif
+{
     WTF_MAKE_NONCOPYABLE(AudioNode);
-    WTF_MAKE_FAST_ALLOCATED;
+    WTF_MAKE_ISO_ALLOCATED(AudioNode);
 public:
     enum { ProcessingSizeInFrames = 128 };
 
     AudioNode(AudioContext&, float sampleRate);
     virtual ~AudioNode();
@@ -73,10 +79,11 @@
         NodeTypeChannelSplitter,
         NodeTypeChannelMerger,
         NodeTypeAnalyser,
         NodeTypeDynamicsCompressor,
         NodeTypeWaveShaper,
+        NodeTypeBasicInspector,
         NodeTypeEnd
     };
 
     enum ChannelCountMode {
         Max,
@@ -172,14 +179,10 @@
     ExceptionOr<void> setChannelInterpretation(const String&);
 
     ChannelCountMode internalChannelCountMode() const { return m_channelCountMode; }
     AudioBus::ChannelInterpretation internalChannelInterpretation() const { return m_channelInterpretation; }
 
-    // EventTarget
-    EventTargetInterface eventTargetInterface() const override;
-    ScriptExecutionContext* scriptExecutionContext() const final;
-
 protected:
     // Inputs and outputs must be created before the AudioNode is initialized.
     void addInput(std::unique_ptr<AudioNodeInput>);
     void addOutput(std::unique_ptr<AudioNodeOutput>);
 
@@ -189,11 +192,22 @@
     virtual void pullInputs(size_t framesToProcess);
 
     // Force all inputs to take any channel interpretation changes into account.
     void updateChannelsForInputs();
 
+#if !RELEASE_LOG_DISABLED
+    const Logger& logger() const final { return m_logger.get(); }
+    const void* logIdentifier() const final { return m_logIdentifier; }
+    const char* logClassName() const final { return "AudioNode"; }
+    WTFLogChannel& logChannel() const final;
+#endif
+
 private:
+    // EventTarget
+    EventTargetInterface eventTargetInterface() const override;
+    ScriptExecutionContext* scriptExecutionContext() const final;
+
     volatile bool m_isInitialized;
     NodeType m_nodeType;
     Ref<AudioContext> m_context;
     float m_sampleRate;
     Vector<std::unique_ptr<AudioNodeInput>> m_inputs;
@@ -215,12 +229,27 @@
 #endif
 
     void refEventTarget() override { ref(); }
     void derefEventTarget() override { deref(); }
 
+#if !RELEASE_LOG_DISABLED
+    mutable Ref<const Logger> m_logger;
+    const void* m_logIdentifier;
+#endif
+
 protected:
     unsigned m_channelCount;
     ChannelCountMode m_channelCountMode;
     AudioBus::ChannelInterpretation m_channelInterpretation;
 };
 
+String convertEnumerationToString(AudioNode::NodeType);
+
 } // namespace WebCore
+
+namespace WTF {
+
+template<> struct LogArgument<WebCore::AudioNode::NodeType> {
+    static String toString(WebCore::AudioNode::NodeType type) { return convertEnumerationToString(type); }
+};
+
+} // namespace WTF
