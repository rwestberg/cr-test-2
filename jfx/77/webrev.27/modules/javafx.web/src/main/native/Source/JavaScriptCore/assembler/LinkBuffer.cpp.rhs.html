<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/LinkBuffer.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2012-2019 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #include &quot;config.h&quot;
 27 #include &quot;LinkBuffer.h&quot;
 28 
 29 #if ENABLE(ASSEMBLER)
 30 
 31 #include &quot;CodeBlock.h&quot;
 32 #include &quot;Disassembler.h&quot;
 33 #include &quot;JITCode.h&quot;
 34 #include &quot;JSCInlines.h&quot;
 35 #include &quot;Options.h&quot;
 36 #include &lt;wtf/CompilationThread.h&gt;
 37 
 38 #if OS(LINUX)
 39 #include &quot;PerfLog.h&quot;
 40 #endif
 41 
 42 namespace JSC {
 43 
 44 bool shouldDumpDisassemblyFor(CodeBlock* codeBlock)
 45 {
 46     if (codeBlock &amp;&amp; JITCode::isOptimizingJIT(codeBlock-&gt;jitType()) &amp;&amp; Options::dumpDFGDisassembly())
 47         return true;
 48     return Options::dumpDisassembly();
 49 }
 50 
 51 LinkBuffer::CodeRef&lt;LinkBufferPtrTag&gt; LinkBuffer::finalizeCodeWithoutDisassemblyImpl()
 52 {
 53     performFinalization();
 54 
 55     ASSERT(m_didAllocate);
 56     if (m_executableMemory)
 57         return CodeRef&lt;LinkBufferPtrTag&gt;(*m_executableMemory);
 58 
 59     return CodeRef&lt;LinkBufferPtrTag&gt;::createSelfManagedCodeRef(m_code);
 60 }
 61 
 62 LinkBuffer::CodeRef&lt;LinkBufferPtrTag&gt; LinkBuffer::finalizeCodeWithDisassemblyImpl(bool dumpDisassembly, const char* format, ...)
 63 {
 64     CodeRef&lt;LinkBufferPtrTag&gt; result = finalizeCodeWithoutDisassemblyImpl();
 65 
 66 #if OS(LINUX)
 67     if (Options::logJITCodeForPerf()) {
 68         StringPrintStream out;
 69         va_list argList;
 70         va_start(argList, format);
 71         va_start(argList, format);
 72         out.vprintf(format, argList);
 73         va_end(argList);
 74         PerfLog::log(out.toCString(), result.code().untaggedExecutableAddress&lt;const uint8_t*&gt;(), result.size());
 75     }
 76 #endif
 77 
 78     if (!dumpDisassembly || m_alreadyDisassembled)
 79         return result;
 80 
 81     StringPrintStream out;
 82     out.printf(&quot;Generated JIT code for &quot;);
 83     va_list argList;
 84     va_start(argList, format);
 85     out.vprintf(format, argList);
 86     va_end(argList);
 87     out.printf(&quot;:\n&quot;);
 88 
 89     uint8_t* executableAddress = result.code().untaggedExecutableAddress&lt;uint8_t*&gt;();
 90     out.printf(&quot;    Code at [%p, %p):\n&quot;, executableAddress, executableAddress + result.size());
 91 
 92     CString header = out.toCString();
 93 
 94     if (Options::asyncDisassembly()) {
 95         CodeRef&lt;DisassemblyPtrTag&gt; codeRefForDisassembly = result.retagged&lt;DisassemblyPtrTag&gt;();
 96         disassembleAsynchronously(header, WTFMove(codeRefForDisassembly), m_size, &quot;    &quot;);
 97         return result;
 98     }
 99 
100     dataLog(header);
101     disassemble(result.retaggedCode&lt;DisassemblyPtrTag&gt;(), m_size, &quot;    &quot;, WTF::dataFile());
102 
103     return result;
104 }
105 
106 #if ENABLE(BRANCH_COMPACTION)
107 static ALWAYS_INLINE void recordLinkOffsets(AssemblerData&amp; assemblerData, int32_t regionStart, int32_t regionEnd, int32_t offset)
108 {
109     int32_t ptr = regionStart / sizeof(int32_t);
110     const int32_t end = regionEnd / sizeof(int32_t);
111     int32_t* offsets = reinterpret_cast_ptr&lt;int32_t*&gt;(assemblerData.buffer());
112     while (ptr &lt; end)
113         offsets[ptr++] = offset;
114 }
115 
116 template &lt;typename InstructionType&gt;
117 void LinkBuffer::copyCompactAndLinkCode(MacroAssembler&amp; macroAssembler, void* ownerUID, JITCompilationEffort effort)
118 {
119     allocate(macroAssembler, ownerUID, effort);
120     const size_t initialSize = macroAssembler.m_assembler.codeSize();
121     if (didFailToAllocate())
122         return;
123 
124     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt;&amp; jumpsToLink = macroAssembler.jumpsToLink();
125     m_assemblerStorage = macroAssembler.m_assembler.buffer().releaseAssemblerData();
126     uint8_t* inData = reinterpret_cast&lt;uint8_t*&gt;(m_assemblerStorage.buffer());
127 
128     uint8_t* codeOutData = m_code.dataLocation&lt;uint8_t*&gt;();
129 #if CPU(ARM64E) &amp;&amp; ENABLE(FAST_JIT_PERMISSIONS)
130     const uint32_t expectedFinalHash = macroAssembler.m_assembler.buffer().hash().finalHash();
131     ARM64EHash verifyUncompactedHash;
132     uint8_t* outData = codeOutData;
133 #else
134     AssemblerData outBuffer(m_size);
135     uint8_t* outData = reinterpret_cast&lt;uint8_t*&gt;(outBuffer.buffer());
136 #endif
137 #if CPU(ARM64)
138     RELEASE_ASSERT(roundUpToMultipleOf&lt;sizeof(unsigned)&gt;(outData) == outData);
139     RELEASE_ASSERT(roundUpToMultipleOf&lt;sizeof(unsigned)&gt;(codeOutData) == codeOutData);
140 #endif
141 
142     int readPtr = 0;
143     int writePtr = 0;
144     unsigned jumpCount = jumpsToLink.size();
145 
146 #if CPU(ARM64E) &amp;&amp; ENABLE(FAST_JIT_PERMISSIONS)
147     os_thread_self_restrict_rwx_to_rw();
148 #endif
149 
150     if (m_shouldPerformBranchCompaction) {
151         for (unsigned i = 0; i &lt; jumpCount; ++i) {
152             int offset = readPtr - writePtr;
153             ASSERT(!(offset &amp; 1));
154 
155             // Copy the instructions from the last jump to the current one.
156             size_t regionSize = jumpsToLink[i].from() - readPtr;
157             InstructionType* copySource = reinterpret_cast_ptr&lt;InstructionType*&gt;(inData + readPtr);
158             InstructionType* copyEnd = reinterpret_cast_ptr&lt;InstructionType*&gt;(inData + readPtr + regionSize);
159             InstructionType* copyDst = reinterpret_cast_ptr&lt;InstructionType*&gt;(outData + writePtr);
160             ASSERT(!(regionSize % 2));
161             ASSERT(!(readPtr % 2));
162             ASSERT(!(writePtr % 2));
163             while (copySource != copyEnd) {
164                 InstructionType insn = *copySource++;
165 #if CPU(ARM64E) &amp;&amp; ENABLE(FAST_JIT_PERMISSIONS)
166                 static_assert(sizeof(InstructionType) == 4, &quot;&quot;);
167                 verifyUncompactedHash.update(insn);
168 #endif
169                 *copyDst++ = insn;
170             }
171             recordLinkOffsets(m_assemblerStorage, readPtr, jumpsToLink[i].from(), offset);
172             readPtr += regionSize;
173             writePtr += regionSize;
174 
175             // Calculate absolute address of the jump target, in the case of backwards
176             // branches we need to be precise, forward branches we are pessimistic
177             const uint8_t* target;
178             if (jumpsToLink[i].to() &gt;= jumpsToLink[i].from())
179                 target = codeOutData + jumpsToLink[i].to() - offset; // Compensate for what we have collapsed so far
180             else
181                 target = codeOutData + jumpsToLink[i].to() - executableOffsetFor(jumpsToLink[i].to());
182 
183             JumpLinkType jumpLinkType = MacroAssembler::computeJumpType(jumpsToLink[i], codeOutData + writePtr, target);
184             // Compact branch if we can...
185             if (MacroAssembler::canCompact(jumpsToLink[i].type())) {
186                 // Step back in the write stream
187                 int32_t delta = MacroAssembler::jumpSizeDelta(jumpsToLink[i].type(), jumpLinkType);
188                 if (delta) {
189                     writePtr -= delta;
190                     recordLinkOffsets(m_assemblerStorage, jumpsToLink[i].from() - delta, readPtr, readPtr - writePtr);
191                 }
192             }
193             jumpsToLink[i].setFrom(writePtr);
194         }
195     } else {
196         if (!ASSERT_DISABLED) {
197             for (unsigned i = 0; i &lt; jumpCount; ++i)
198                 ASSERT(!MacroAssembler::canCompact(jumpsToLink[i].type()));
199         }
200     }
201 
202     // Copy everything after the last jump
203     {
204         InstructionType* dst = bitwise_cast&lt;InstructionType*&gt;(outData + writePtr);
205         InstructionType* src = bitwise_cast&lt;InstructionType*&gt;(inData + readPtr);
206         size_t bytes = initialSize - readPtr;
207 
208         RELEASE_ASSERT(bitwise_cast&lt;uintptr_t&gt;(dst) % sizeof(InstructionType) == 0);
209         RELEASE_ASSERT(bitwise_cast&lt;uintptr_t&gt;(src) % sizeof(InstructionType) == 0);
210         RELEASE_ASSERT(bytes % sizeof(InstructionType) == 0);
211 
212         for (size_t i = 0; i &lt; bytes; i += sizeof(InstructionType)) {
213             InstructionType insn = *src++;
214 #if CPU(ARM64E) &amp;&amp; ENABLE(FAST_JIT_PERMISSIONS)
215             verifyUncompactedHash.update(insn);
216 #endif
217             *dst++ = insn;
218         }
219     }
220 
221 #if CPU(ARM64E) &amp;&amp; ENABLE(FAST_JIT_PERMISSIONS)
222     if (verifyUncompactedHash.finalHash() != expectedFinalHash) {
223         dataLogLn(&quot;Hashes don&#39;t match: &quot;, RawPointer(bitwise_cast&lt;void*&gt;(static_cast&lt;uintptr_t&gt;(verifyUncompactedHash.finalHash()))), &quot; &quot;, RawPointer(bitwise_cast&lt;void*&gt;(static_cast&lt;uintptr_t&gt;(expectedFinalHash))));
224         dataLogLn(&quot;Crashing!&quot;);
225         CRASH();
226     }
227 #endif
228 
229     recordLinkOffsets(m_assemblerStorage, readPtr, initialSize, readPtr - writePtr);
230 
<a name="1" id="anc1"></a>
231 #if CPU(ARM64E) &amp;&amp; ENABLE(FAST_JIT_PERMISSIONS)
<a name="2" id="anc2"></a><span class="line-modified">232     auto memcpyFunction = tagCFunctionPtr&lt;CopyFunctionPtrTag&gt;(memcpy);</span>
233 #else
<a name="3" id="anc3"></a><span class="line-modified">234     auto memcpyFunction = tagCFunctionPtr&lt;CopyFunctionPtrTag&gt;(performJITMemcpy);</span>
235 #endif
<a name="4" id="anc4"></a><span class="line-modified">236     for (unsigned i = 0; i &lt; jumpCount; ++i) {</span>
237         uint8_t* location = codeOutData + jumpsToLink[i].from();
238         uint8_t* target = codeOutData + jumpsToLink[i].to() - executableOffsetFor(jumpsToLink[i].to());
239         MacroAssembler::link(jumpsToLink[i], outData + jumpsToLink[i].from(), location, target, memcpyFunction);
240     }
241 
242     size_t compactSize = writePtr + initialSize - readPtr;
243     if (!m_executableMemory) {
244         size_t nopSizeInBytes = initialSize - compactSize;
245         MacroAssembler::AssemblerType_T::fillNops(outData + compactSize, nopSizeInBytes, memcpy);
246     }
247 
248 #if CPU(ARM64E) &amp;&amp; ENABLE(FAST_JIT_PERMISSIONS)
249     os_thread_self_restrict_rwx_to_rx();
250 #endif
251 
252     if (m_executableMemory) {
253         m_size = compactSize;
254         m_executableMemory-&gt;shrink(m_size);
255     }
256 
257 #if !CPU(ARM64E) || !ENABLE(FAST_JIT_PERMISSIONS)
258     ASSERT(codeOutData != outData);
259     performJITMemcpy(codeOutData, outData, m_size);
260 #else
261     ASSERT(codeOutData == outData);
<a name="5" id="anc5"></a><span class="line-added">262     if (UNLIKELY(Options::dumpJITMemoryPath()))</span>
<span class="line-added">263         dumpJITMemory(outData, outData, m_size);</span>
264 #endif
265 
266     jumpsToLink.clear();
267 
268 #if DUMP_LINK_STATISTICS
269     dumpLinkStatistics(codeOutData, initialSize, m_size);
270 #endif
271 #if DUMP_CODE
272     dumpCode(codeOutData, m_size);
273 #endif
274 }
275 #endif // ENABLE(BRANCH_COMPACTION)
276 
277 
278 void LinkBuffer::linkCode(MacroAssembler&amp; macroAssembler, void* ownerUID, JITCompilationEffort effort)
279 {
280     // Ensure that the end of the last invalidation point does not extend beyond the end of the buffer.
281     macroAssembler.label();
282 
283 #if !ENABLE(BRANCH_COMPACTION)
284 #if defined(ASSEMBLER_HAS_CONSTANT_POOL) &amp;&amp; ASSEMBLER_HAS_CONSTANT_POOL
285     macroAssembler.m_assembler.buffer().flushConstantPool(false);
286 #endif
287     allocate(macroAssembler, ownerUID, effort);
288     if (!m_didAllocate)
289         return;
290     ASSERT(m_code);
291     AssemblerBuffer&amp; buffer = macroAssembler.m_assembler.buffer();
292     void* code = m_code.dataLocation();
293 #if CPU(ARM64)
294     RELEASE_ASSERT(roundUpToMultipleOf&lt;Assembler::instructionSize&gt;(code) == code);
295 #endif
296     performJITMemcpy(code, buffer.data(), buffer.codeSize());
297 #if CPU(MIPS)
298     macroAssembler.m_assembler.relocateJumps(buffer.data(), code);
299 #endif
300 #elif CPU(ARM_THUMB2)
301     copyCompactAndLinkCode&lt;uint16_t&gt;(macroAssembler, ownerUID, effort);
302 #elif CPU(ARM64)
303     copyCompactAndLinkCode&lt;uint32_t&gt;(macroAssembler, ownerUID, effort);
304 #endif // !ENABLE(BRANCH_COMPACTION)
305 
306     m_linkTasks = WTFMove(macroAssembler.m_linkTasks);
307 }
308 
309 void LinkBuffer::allocate(MacroAssembler&amp; macroAssembler, void* ownerUID, JITCompilationEffort effort)
310 {
311     size_t initialSize = macroAssembler.m_assembler.codeSize();
312     if (m_code) {
313         if (initialSize &gt; m_size)
314             return;
315 
316         size_t nopsToFillInBytes = m_size - initialSize;
317         macroAssembler.emitNops(nopsToFillInBytes);
318         m_didAllocate = true;
319         return;
320     }
321 
322     while (initialSize % jitAllocationGranule) {
323         macroAssembler.breakpoint();
324         initialSize = macroAssembler.m_assembler.codeSize();
325     }
326 
327     m_executableMemory = ExecutableAllocator::singleton().allocate(initialSize, ownerUID, effort);
328     if (!m_executableMemory)
329         return;
330     m_code = MacroAssemblerCodePtr&lt;LinkBufferPtrTag&gt;(m_executableMemory-&gt;start().retaggedPtr&lt;LinkBufferPtrTag&gt;());
331     m_size = initialSize;
332     m_didAllocate = true;
333 }
334 
335 void LinkBuffer::performFinalization()
336 {
337     for (auto&amp; task : m_linkTasks)
338         task-&gt;run(*this);
339 
340 #ifndef NDEBUG
341     ASSERT(!isCompilationThread());
342     ASSERT(!m_completed);
343     ASSERT(isValid());
344     m_completed = true;
345 #endif
346 
347     MacroAssembler::cacheFlush(code(), m_size);
348 }
349 
350 #if DUMP_LINK_STATISTICS
351 void LinkBuffer::dumpLinkStatistics(void* code, size_t initializeSize, size_t finalSize)
352 {
353     static unsigned linkCount = 0;
354     static unsigned totalInitialSize = 0;
355     static unsigned totalFinalSize = 0;
356     linkCount++;
357     totalInitialSize += initialSize;
358     totalFinalSize += finalSize;
359     dataLogF(&quot;link %p: orig %u, compact %u (delta %u, %.2f%%)\n&quot;,
360             code, static_cast&lt;unsigned&gt;(initialSize), static_cast&lt;unsigned&gt;(finalSize),
361             static_cast&lt;unsigned&gt;(initialSize - finalSize),
362             100.0 * (initialSize - finalSize) / initialSize);
363     dataLogF(&quot;\ttotal %u: orig %u, compact %u (delta %u, %.2f%%)\n&quot;,
364             linkCount, totalInitialSize, totalFinalSize, totalInitialSize - totalFinalSize,
365             100.0 * (totalInitialSize - totalFinalSize) / totalInitialSize);
366 }
367 #endif
368 
369 #if DUMP_CODE
370 void LinkBuffer::dumpCode(void* code, size_t size)
371 {
372 #if CPU(ARM_THUMB2)
373     // Dump the generated code in an asm file format that can be assembled and then disassembled
374     // for debugging purposes. For example, save this output as jit.s:
375     //   gcc -arch armv7 -c jit.s
376     //   otool -tv jit.o
377     static unsigned codeCount = 0;
378     unsigned short* tcode = static_cast&lt;unsigned short*&gt;(code);
379     size_t tsize = size / sizeof(short);
380     char nameBuf[128];
381     snprintf(nameBuf, sizeof(nameBuf), &quot;_jsc_jit%u&quot;, codeCount++);
382     dataLogF(&quot;\t.syntax unified\n&quot;
383             &quot;\t.section\t__TEXT,__text,regular,pure_instructions\n&quot;
384             &quot;\t.globl\t%s\n&quot;
385             &quot;\t.align 2\n&quot;
386             &quot;\t.code 16\n&quot;
387             &quot;\t.thumb_func\t%s\n&quot;
388             &quot;# %p\n&quot;
389             &quot;%s:\n&quot;, nameBuf, nameBuf, code, nameBuf);
390 
391     for (unsigned i = 0; i &lt; tsize; i++)
392         dataLogF(&quot;\t.short\t0x%x\n&quot;, tcode[i]);
393 #endif
394 }
395 #endif
396 
397 } // namespace JSC
398 
399 #endif // ENABLE(ASSEMBLER)
<a name="6" id="anc6"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="6" type="hidden" />
</body>
</html>