<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JIT.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (C) 2008-2019 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #if ENABLE(JIT)
 29 
 30 // We&#39;ve run into some problems where changing the size of the class JIT leads to
 31 // performance fluctuations. Try forcing alignment in an attempt to stabilize this.
 32 #if COMPILER(GCC_COMPATIBLE)
 33 #define JIT_CLASS_ALIGNMENT alignas(32)
 34 #else
 35 #define JIT_CLASS_ALIGNMENT
 36 #endif
 37 
 38 #define ASSERT_JIT_OFFSET(actual, expected) ASSERT_WITH_MESSAGE(actual == expected, &quot;JIT Offset \&quot;%s\&quot; should be %d, not %d.\n&quot;, #expected, static_cast&lt;int&gt;(expected), static_cast&lt;int&gt;(actual));
 39 
 40 #include &quot;CodeBlock.h&quot;
 41 #include &quot;CommonSlowPaths.h&quot;
 42 #include &quot;JITDisassembler.h&quot;
 43 #include &quot;JITInlineCacheGenerator.h&quot;
 44 #include &quot;JITMathIC.h&quot;
 45 #include &quot;JITRightShiftGenerator.h&quot;
 46 #include &quot;JSInterfaceJIT.h&quot;
 47 #include &quot;PCToCodeOriginMap.h&quot;
 48 #include &quot;UnusedPointer.h&quot;
 49 
 50 namespace JSC {
 51 
 52     enum OpcodeID : unsigned;
 53 
 54     class ArrayAllocationProfile;
 55     class CallLinkInfo;
 56     class CodeBlock;
 57     class FunctionExecutable;
 58     class JIT;
 59     class Identifier;
 60     class Interpreter;
 61     class BlockDirectory;
 62     class Register;
 63     class StructureChain;
 64     class StructureStubInfo;
 65 
 66     struct Instruction;
 67     struct OperandTypes;
 68     struct SimpleJumpTable;
 69     struct StringJumpTable;
 70 
 71     struct CallRecord {
 72         MacroAssembler::Call from;
 73         unsigned bytecodeOffset;
 74         FunctionPtr&lt;OperationPtrTag&gt; callee;
 75 
 76         CallRecord()
 77         {
 78         }
 79 
 80         CallRecord(MacroAssembler::Call from, unsigned bytecodeOffset, FunctionPtr&lt;OperationPtrTag&gt; callee)
 81             : from(from)
 82             , bytecodeOffset(bytecodeOffset)
 83             , callee(callee)
 84         {
 85         }
 86     };
 87 
 88     struct JumpTable {
 89         MacroAssembler::Jump from;
 90         unsigned toBytecodeOffset;
 91 
 92         JumpTable(MacroAssembler::Jump f, unsigned t)
 93             : from(f)
 94             , toBytecodeOffset(t)
 95         {
 96         }
 97     };
 98 
 99     struct SlowCaseEntry {
100         MacroAssembler::Jump from;
101         unsigned to;
102 
103         SlowCaseEntry(MacroAssembler::Jump f, unsigned t)
104             : from(f)
105             , to(t)
106         {
107         }
108     };
109 
110     struct SwitchRecord {
111         enum Type {
112             Immediate,
113             Character,
114             String
115         };
116 
117         Type type;
118 
119         union {
120             SimpleJumpTable* simpleJumpTable;
121             StringJumpTable* stringJumpTable;
122         } jumpTable;
123 
124         unsigned bytecodeOffset;
125         unsigned defaultOffset;
126 
127         SwitchRecord(SimpleJumpTable* jumpTable, unsigned bytecodeOffset, unsigned defaultOffset, Type type)
128             : type(type)
129             , bytecodeOffset(bytecodeOffset)
130             , defaultOffset(defaultOffset)
131         {
132             this-&gt;jumpTable.simpleJumpTable = jumpTable;
133         }
134 
135         SwitchRecord(StringJumpTable* jumpTable, unsigned bytecodeOffset, unsigned defaultOffset)
136             : type(String)
137             , bytecodeOffset(bytecodeOffset)
138             , defaultOffset(defaultOffset)
139         {
140             this-&gt;jumpTable.stringJumpTable = jumpTable;
141         }
142     };
143 
144     struct ByValCompilationInfo {
145         ByValCompilationInfo() { }
146 
147         ByValCompilationInfo(ByValInfo* byValInfo, unsigned bytecodeIndex, MacroAssembler::PatchableJump notIndexJump, MacroAssembler::PatchableJump badTypeJump, JITArrayMode arrayMode, ArrayProfile* arrayProfile, MacroAssembler::Label doneTarget, MacroAssembler::Label nextHotPathTarget)
148             : byValInfo(byValInfo)
149             , bytecodeIndex(bytecodeIndex)
150             , notIndexJump(notIndexJump)
151             , badTypeJump(badTypeJump)
152             , arrayMode(arrayMode)
153             , arrayProfile(arrayProfile)
154             , doneTarget(doneTarget)
155             , nextHotPathTarget(nextHotPathTarget)
156         {
157         }
158 
159         ByValInfo* byValInfo;
160         unsigned bytecodeIndex;
161         MacroAssembler::PatchableJump notIndexJump;
162         MacroAssembler::PatchableJump badTypeJump;
163         JITArrayMode arrayMode;
164         ArrayProfile* arrayProfile;
165         MacroAssembler::Label doneTarget;
166         MacroAssembler::Label nextHotPathTarget;
167         MacroAssembler::Label slowPathTarget;
168         MacroAssembler::Call returnAddress;
169     };
170 
171     struct CallCompilationInfo {
172         MacroAssembler::DataLabelPtr hotPathBegin;
173         MacroAssembler::Call hotPathOther;
174         MacroAssembler::Call callReturnLocation;
175         CallLinkInfo* callLinkInfo;
176     };
177 
178     void ctiPatchCallByReturnAddress(ReturnAddressPtr, FunctionPtr&lt;CFunctionPtrTag&gt; newCalleeFunction);
179 
180     class JIT_CLASS_ALIGNMENT JIT : private JSInterfaceJIT {
181         friend class JITSlowPathCall;
182         friend class JITStubCall;
183 
184         using MacroAssembler::Jump;
185         using MacroAssembler::JumpList;
186         using MacroAssembler::Label;
187 
188         static const uintptr_t patchGetByIdDefaultStructure = unusedPointer;
189         static const int patchGetByIdDefaultOffset = 0;
190         // Magic number - initial offset cannot be representable as a signed 8bit value, or the X86Assembler
191         // will compress the displacement, and we may not be able to fit a patched offset.
192         static const int patchPutByIdDefaultOffset = 256;
193 
194     public:
<a name="2" id="anc2"></a><span class="line-modified">195         JIT(VM&amp;, CodeBlock* = 0, unsigned loopOSREntryBytecodeOffset = 0);</span>
196         ~JIT();
197 
<a name="3" id="anc3"></a><span class="line-added">198         VM&amp; vm() { return *JSInterfaceJIT::vm(); }</span>
<span class="line-added">199 </span>
200         void compileWithoutLinking(JITCompilationEffort);
201         CompilationResult link();
202 
203         void doMainThreadPreparationBeforeCompile();
204 
<a name="4" id="anc4"></a><span class="line-modified">205         static CompilationResult compile(VM&amp; vm, CodeBlock* codeBlock, JITCompilationEffort effort, unsigned bytecodeOffset = 0)</span>
206         {
207             return JIT(vm, codeBlock, bytecodeOffset).privateCompile(effort);
208         }
209 
<a name="5" id="anc5"></a><span class="line-modified">210         static void compileGetByVal(const ConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
211         {
212             JIT jit(vm, codeBlock);
213             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
214             jit.privateCompileGetByVal(locker, byValInfo, returnAddress, arrayMode);
215         }
216 
<a name="6" id="anc6"></a><span class="line-modified">217         static void compileGetByValWithCachedId(VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, const Identifier&amp; propertyName)</span>
218         {
219             JIT jit(vm, codeBlock);
220             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
221             jit.privateCompileGetByValWithCachedId(byValInfo, returnAddress, propertyName);
222         }
223 
<a name="7" id="anc7"></a><span class="line-modified">224         static void compilePutByVal(const ConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
225         {
226             JIT jit(vm, codeBlock);
227             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
228             jit.privateCompilePutByVal&lt;OpPutByVal&gt;(locker, byValInfo, returnAddress, arrayMode);
229         }
230 
<a name="8" id="anc8"></a><span class="line-modified">231         static void compileDirectPutByVal(const ConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
232         {
233             JIT jit(vm, codeBlock);
234             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
235             jit.privateCompilePutByVal&lt;OpPutByValDirect&gt;(locker, byValInfo, returnAddress, arrayMode);
236         }
237 
238         template&lt;typename Op&gt;
<a name="9" id="anc9"></a><span class="line-modified">239         static void compilePutByValWithCachedId(VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, PutKind putKind, const Identifier&amp; propertyName)</span>
240         {
241             JIT jit(vm, codeBlock);
242             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
243             jit.privateCompilePutByValWithCachedId&lt;Op&gt;(byValInfo, returnAddress, putKind, propertyName);
244         }
245 
<a name="10" id="anc10"></a><span class="line-modified">246         static void compileHasIndexedProperty(VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
247         {
248             JIT jit(vm, codeBlock);
249             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
250             jit.privateCompileHasIndexedProperty(byValInfo, returnAddress, arrayMode);
251         }
252 
253         static unsigned frameRegisterCountFor(CodeBlock*);
254         static int stackPointerOffsetFor(CodeBlock*);
255 
256         JS_EXPORT_PRIVATE static HashMap&lt;CString, Seconds&gt; compileTimeStats();
257         JS_EXPORT_PRIVATE static Seconds totalCompileTime();
258 
259     private:
260         void privateCompileMainPass();
261         void privateCompileLinkPass();
262         void privateCompileSlowCases();
263         CompilationResult privateCompile(JITCompilationEffort);
264 
265         void privateCompileGetByVal(const ConcurrentJSLocker&amp;, ByValInfo*, ReturnAddressPtr, JITArrayMode);
266         void privateCompileGetByValWithCachedId(ByValInfo*, ReturnAddressPtr, const Identifier&amp;);
267         template&lt;typename Op&gt;
268         void privateCompilePutByVal(const ConcurrentJSLocker&amp;, ByValInfo*, ReturnAddressPtr, JITArrayMode);
269         template&lt;typename Op&gt;
270         void privateCompilePutByValWithCachedId(ByValInfo*, ReturnAddressPtr, PutKind, const Identifier&amp;);
271 
272         void privateCompileHasIndexedProperty(ByValInfo*, ReturnAddressPtr, JITArrayMode);
273 
274         void privateCompilePatchGetArrayLength(ReturnAddressPtr returnAddress);
275 
276         // Add a call out from JIT code, without an exception check.
277         Call appendCall(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
278         {
279             Call functionCall = call(OperationPtrTag);
280             m_calls.append(CallRecord(functionCall, m_bytecodeOffset, function.retagged&lt;OperationPtrTag&gt;()));
281             return functionCall;
282         }
283 
284 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
285         Call appendCallWithSlowPathReturnType(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
286         {
287             Call functionCall = callWithSlowPathReturnType(OperationPtrTag);
288             m_calls.append(CallRecord(functionCall, m_bytecodeOffset, function.retagged&lt;OperationPtrTag&gt;()));
289             return functionCall;
290         }
291 #endif
292 
293         void exceptionCheck(Jump jumpToHandler)
294         {
295             m_exceptionChecks.append(jumpToHandler);
296         }
297 
298         void exceptionCheck()
299         {
<a name="11" id="anc11"></a><span class="line-modified">300             m_exceptionChecks.append(emitExceptionCheck(vm()));</span>
301         }
302 
303         void exceptionCheckWithCallFrameRollback()
304         {
<a name="12" id="anc12"></a><span class="line-modified">305             m_exceptionChecksWithCallFrameRollback.append(emitExceptionCheck(vm()));</span>
306         }
307 
308         void privateCompileExceptionHandlers();
309 
310         void addSlowCase(Jump);
311         void addSlowCase(const JumpList&amp;);
312         void addSlowCase();
313         void addJump(Jump, int);
314         void addJump(const JumpList&amp;, int);
315         void emitJumpSlowToHot(Jump, int);
316 
317         template&lt;typename Op&gt;
318         void compileOpCall(const Instruction*, unsigned callLinkInfoIndex);
319         template&lt;typename Op&gt;
320         void compileOpCallSlowCase(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, unsigned callLinkInfoIndex);
321         template&lt;typename Op&gt;
322         std::enable_if_t&lt;
323             Op::opcodeID != op_call_varargs &amp;&amp; Op::opcodeID != op_construct_varargs
324             &amp;&amp; Op::opcodeID != op_tail_call_varargs &amp;&amp; Op::opcodeID != op_tail_call_forward_arguments
325         , void&gt; compileSetupFrame(const Op&amp;, CallLinkInfo*);
326 
327         template&lt;typename Op&gt;
328         std::enable_if_t&lt;
329             Op::opcodeID == op_call_varargs || Op::opcodeID == op_construct_varargs
330             || Op::opcodeID == op_tail_call_varargs || Op::opcodeID == op_tail_call_forward_arguments
331         , void&gt; compileSetupFrame(const Op&amp;, CallLinkInfo*);
332 
333         template&lt;typename Op&gt;
334         bool compileTailCall(const Op&amp;, CallLinkInfo*, unsigned callLinkInfoIndex);
335         template&lt;typename Op&gt;
336         bool compileCallEval(const Op&amp;);
337         void compileCallEvalSlowCase(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
338         template&lt;typename Op&gt;
339         void emitPutCallResult(const Op&amp;);
340 
341         enum class CompileOpStrictEqType { StrictEq, NStrictEq };
342         template&lt;typename Op&gt;
343         void compileOpStrictEq(const Instruction*, CompileOpStrictEqType);
344         template&lt;typename Op&gt;
345         void compileOpStrictEqJump(const Instruction*, CompileOpStrictEqType);
346         enum class CompileOpEqType { Eq, NEq };
347         void compileOpEqJumpSlow(Vector&lt;SlowCaseEntry&gt;::iterator&amp;, CompileOpEqType, int jumpTarget);
348         bool isOperandConstantDouble(int src);
349 
350         void emitLoadDouble(int index, FPRegisterID value);
351         void emitLoadInt32ToDouble(int index, FPRegisterID value);
352 
353         enum WriteBarrierMode { UnconditionalWriteBarrier, ShouldFilterBase, ShouldFilterValue, ShouldFilterBaseAndValue };
354         // value register in write barrier is used before any scratch registers
355         // so may safely be the same as either of the scratch registers.
356         void emitWriteBarrier(unsigned owner, unsigned value, WriteBarrierMode);
357         void emitWriteBarrier(JSCell* owner, unsigned value, WriteBarrierMode);
358         void emitWriteBarrier(JSCell* owner);
359 
360         // This assumes that the value to profile is in regT0 and that regT3 is available for
361         // scratch.
362         void emitValueProfilingSite(ValueProfile&amp;);
363         template&lt;typename Metadata&gt; void emitValueProfilingSite(Metadata&amp;);
364         void emitValueProfilingSiteIfProfiledOpcode(...);
365         template&lt;typename Op&gt;
366         std::enable_if_t&lt;std::is_same&lt;decltype(Op::Metadata::m_profile), ValueProfile&gt;::value, void&gt;
367         emitValueProfilingSiteIfProfiledOpcode(Op bytecode);
368 
369         void emitArrayProfilingSiteWithCell(RegisterID cell, RegisterID indexingType, ArrayProfile*);
370         void emitArrayProfileStoreToHoleSpecialCase(ArrayProfile*);
371         void emitArrayProfileOutOfBoundsSpecialCase(ArrayProfile*);
372 
373         JITArrayMode chooseArrayMode(ArrayProfile*);
374 
375         // Property is in regT1, base is in regT0. regT2 contains indexing type.
376         // Property is int-checked and zero extended. Base is cell checked.
377         // Structure is already profiled. Returns the slow cases. Fall-through
378         // case contains result in regT0, and it is not yet profiled.
379         JumpList emitInt32Load(const Instruction* instruction, PatchableJump&amp; badType) { return emitContiguousLoad(instruction, badType, Int32Shape); }
380         JumpList emitDoubleLoad(const Instruction*, PatchableJump&amp; badType);
381         JumpList emitContiguousLoad(const Instruction*, PatchableJump&amp; badType, IndexingType expectedShape = ContiguousShape);
382         JumpList emitArrayStorageLoad(const Instruction*, PatchableJump&amp; badType);
383         JumpList emitLoadForArrayMode(const Instruction*, JITArrayMode, PatchableJump&amp; badType);
384 
385         JumpList emitInt32GetByVal(const Instruction* instruction, PatchableJump&amp; badType) { return emitContiguousGetByVal(instruction, badType, Int32Shape); }
386         JumpList emitDoubleGetByVal(const Instruction*, PatchableJump&amp; badType);
387         JumpList emitContiguousGetByVal(const Instruction*, PatchableJump&amp; badType, IndexingType expectedShape = ContiguousShape);
388         JumpList emitArrayStorageGetByVal(const Instruction*, PatchableJump&amp; badType);
389         JumpList emitDirectArgumentsGetByVal(const Instruction*, PatchableJump&amp; badType);
390         JumpList emitScopedArgumentsGetByVal(const Instruction*, PatchableJump&amp; badType);
391         JumpList emitIntTypedArrayGetByVal(const Instruction*, PatchableJump&amp; badType, TypedArrayType);
392         JumpList emitFloatTypedArrayGetByVal(const Instruction*, PatchableJump&amp; badType, TypedArrayType);
393 
394         // Property is in regT1, base is in regT0. regT2 contains indecing type.
395         // The value to store is not yet loaded. Property is int-checked and
396         // zero-extended. Base is cell checked. Structure is already profiled.
397         // returns the slow cases.
398         template&lt;typename Op&gt;
399         JumpList emitInt32PutByVal(Op bytecode, PatchableJump&amp; badType)
400         {
401             return emitGenericContiguousPutByVal(bytecode, badType, Int32Shape);
402         }
403         template&lt;typename Op&gt;
404         JumpList emitDoublePutByVal(Op bytecode, PatchableJump&amp; badType)
405         {
406             return emitGenericContiguousPutByVal(bytecode, badType, DoubleShape);
407         }
408         template&lt;typename Op&gt;
409         JumpList emitContiguousPutByVal(Op bytecode, PatchableJump&amp; badType)
410         {
411             return emitGenericContiguousPutByVal(bytecode, badType);
412         }
413         template&lt;typename Op&gt;
414         JumpList emitGenericContiguousPutByVal(Op, PatchableJump&amp; badType, IndexingType indexingShape = ContiguousShape);
415         template&lt;typename Op&gt;
416         JumpList emitArrayStoragePutByVal(Op, PatchableJump&amp; badType);
417         template&lt;typename Op&gt;
418         JumpList emitIntTypedArrayPutByVal(Op, PatchableJump&amp; badType, TypedArrayType);
419         template&lt;typename Op&gt;
420         JumpList emitFloatTypedArrayPutByVal(Op, PatchableJump&amp; badType, TypedArrayType);
421 
422         // Identifier check helper for GetByVal and PutByVal.
423         void emitByValIdentifierCheck(ByValInfo*, RegisterID cell, RegisterID scratch, const Identifier&amp;, JumpList&amp; slowCases);
424 
425         JITGetByIdGenerator emitGetByValWithCachedId(ByValInfo*, OpGetByVal, const Identifier&amp;, Jump&amp; fastDoneCase, Jump&amp; slowDoneCase, JumpList&amp; slowCases);
426         template&lt;typename Op&gt;
427         JITPutByIdGenerator emitPutByValWithCachedId(ByValInfo*, Op, PutKind, const Identifier&amp;, JumpList&amp; doneCases, JumpList&amp; slowCases);
428 
429         enum FinalObjectMode { MayBeFinal, KnownNotFinal };
430 
431         void emitGetVirtualRegister(int src, JSValueRegs dst);
432         void emitPutVirtualRegister(int dst, JSValueRegs src);
433 
434         int32_t getOperandConstantInt(int src);
435         double getOperandConstantDouble(int src);
436 
437 #if USE(JSVALUE32_64)
438         bool getOperandConstantInt(int op1, int op2, int&amp; op, int32_t&amp; constant);
439 
440         void emitLoadTag(int index, RegisterID tag);
441         void emitLoadPayload(int index, RegisterID payload);
442 
443         void emitLoad(const JSValue&amp; v, RegisterID tag, RegisterID payload);
444         void emitLoad(int index, RegisterID tag, RegisterID payload, RegisterID base = callFrameRegister);
445         void emitLoad2(int index1, RegisterID tag1, RegisterID payload1, int index2, RegisterID tag2, RegisterID payload2);
446 
447         void emitStore(int index, RegisterID tag, RegisterID payload, RegisterID base = callFrameRegister);
448         void emitStore(int index, const JSValue constant, RegisterID base = callFrameRegister);
449         void emitStoreInt32(int index, RegisterID payload, bool indexIsInt32 = false);
450         void emitStoreInt32(int index, TrustedImm32 payload, bool indexIsInt32 = false);
451         void emitStoreCell(int index, RegisterID payload, bool indexIsCell = false);
452         void emitStoreBool(int index, RegisterID payload, bool indexIsBool = false);
453         void emitStoreDouble(int index, FPRegisterID value);
454 
455         void emitJumpSlowCaseIfNotJSCell(int virtualRegisterIndex);
456         void emitJumpSlowCaseIfNotJSCell(int virtualRegisterIndex, RegisterID tag);
457 
458         void compileGetByIdHotPath(const Identifier*);
459 
460         // Arithmetic opcode helpers
461         template &lt;typename Op&gt;
462         void emitBinaryDoubleOp(const Instruction *, OperandTypes, JumpList&amp; notInt32Op1, JumpList&amp; notInt32Op2, bool op1IsInRegisters = true, bool op2IsInRegisters = true);
463 
464 #else // USE(JSVALUE32_64)
465         void emitGetVirtualRegister(int src, RegisterID dst);
466         void emitGetVirtualRegister(VirtualRegister src, RegisterID dst);
467         void emitGetVirtualRegisters(int src1, RegisterID dst1, int src2, RegisterID dst2);
468         void emitGetVirtualRegisters(VirtualRegister src1, RegisterID dst1, VirtualRegister src2, RegisterID dst2);
469         void emitPutVirtualRegister(int dst, RegisterID from = regT0);
470         void emitPutVirtualRegister(VirtualRegister dst, RegisterID from = regT0);
471         void emitStoreCell(int dst, RegisterID payload, bool /* only used in JSValue32_64 */ = false)
472         {
473             emitPutVirtualRegister(dst, payload);
474         }
475         void emitStoreCell(VirtualRegister dst, RegisterID payload)
476         {
477             emitPutVirtualRegister(dst, payload);
478         }
479 
480         Jump emitJumpIfBothJSCells(RegisterID, RegisterID, RegisterID);
481         void emitJumpSlowCaseIfJSCell(RegisterID);
482         void emitJumpSlowCaseIfNotJSCell(RegisterID);
483         void emitJumpSlowCaseIfNotJSCell(RegisterID, int VReg);
484         Jump emitJumpIfNotInt(RegisterID, RegisterID, RegisterID scratch);
485         PatchableJump emitPatchableJumpIfNotInt(RegisterID);
486         void emitJumpSlowCaseIfNotInt(RegisterID);
487         void emitJumpSlowCaseIfNotNumber(RegisterID);
488         void emitJumpSlowCaseIfNotInt(RegisterID, RegisterID, RegisterID scratch);
489 
490         void compileGetByIdHotPath(int baseVReg, const Identifier*);
491 
492 #endif // USE(JSVALUE32_64)
493 
494         template&lt;typename Op&gt;
495         void emit_compareAndJump(const Instruction*, RelationalCondition);
496         template&lt;typename Op&gt;
497         void emit_compareUnsigned(const Instruction*, RelationalCondition);
498         template&lt;typename Op&gt;
499         void emit_compareUnsignedAndJump(const Instruction*, RelationalCondition);
500         template&lt;typename Op&gt;
501         void emit_compareAndJumpSlow(const Instruction*, DoubleCondition, size_t (JIT_OPERATION *operation)(ExecState*, EncodedJSValue, EncodedJSValue), bool invert, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
502 
503         void assertStackPointerOffset();
504 
505         void emit_op_add(const Instruction*);
506         void emit_op_bitand(const Instruction*);
507         void emit_op_bitor(const Instruction*);
508         void emit_op_bitxor(const Instruction*);
509         void emit_op_bitnot(const Instruction*);
510         void emit_op_call(const Instruction*);
511         void emit_op_tail_call(const Instruction*);
512         void emit_op_call_eval(const Instruction*);
513         void emit_op_call_varargs(const Instruction*);
514         void emit_op_tail_call_varargs(const Instruction*);
515         void emit_op_tail_call_forward_arguments(const Instruction*);
516         void emit_op_construct_varargs(const Instruction*);
517         void emit_op_catch(const Instruction*);
518         void emit_op_construct(const Instruction*);
519         void emit_op_create_this(const Instruction*);
520         void emit_op_to_this(const Instruction*);
521         void emit_op_get_argument(const Instruction*);
522         void emit_op_argument_count(const Instruction*);
523         void emit_op_get_rest_length(const Instruction*);
524         void emit_op_check_tdz(const Instruction*);
525         void emit_op_identity_with_profile(const Instruction*);
526         void emit_op_debug(const Instruction*);
527         void emit_op_del_by_id(const Instruction*);
528         void emit_op_del_by_val(const Instruction*);
529         void emit_op_div(const Instruction*);
530         void emit_op_end(const Instruction*);
531         void emit_op_enter(const Instruction*);
532         void emit_op_get_scope(const Instruction*);
533         void emit_op_eq(const Instruction*);
534         void emit_op_eq_null(const Instruction*);
535         void emit_op_below(const Instruction*);
536         void emit_op_beloweq(const Instruction*);
537         void emit_op_try_get_by_id(const Instruction*);
538         void emit_op_get_by_id(const Instruction*);
539         void emit_op_get_by_id_with_this(const Instruction*);
540         void emit_op_get_by_id_direct(const Instruction*);
541         void emit_op_get_by_val(const Instruction*);
542         void emit_op_get_argument_by_val(const Instruction*);
543         void emit_op_in_by_id(const Instruction*);
544         void emit_op_init_lazy_reg(const Instruction*);
545         void emit_op_overrides_has_instance(const Instruction*);
546         void emit_op_instanceof(const Instruction*);
547         void emit_op_instanceof_custom(const Instruction*);
548         void emit_op_is_empty(const Instruction*);
549         void emit_op_is_undefined(const Instruction*);
550         void emit_op_is_undefined_or_null(const Instruction*);
551         void emit_op_is_boolean(const Instruction*);
552         void emit_op_is_number(const Instruction*);
553         void emit_op_is_object(const Instruction*);
554         void emit_op_is_cell_with_type(const Instruction*);
555         void emit_op_jeq_null(const Instruction*);
556         void emit_op_jfalse(const Instruction*);
557         void emit_op_jmp(const Instruction*);
558         void emit_op_jneq_null(const Instruction*);
<a name="13" id="anc13"></a><span class="line-added">559         void emit_op_jundefined_or_null(const Instruction*);</span>
<span class="line-added">560         void emit_op_jnundefined_or_null(const Instruction*);</span>
561         void emit_op_jneq_ptr(const Instruction*);
562         void emit_op_jless(const Instruction*);
563         void emit_op_jlesseq(const Instruction*);
564         void emit_op_jgreater(const Instruction*);
565         void emit_op_jgreatereq(const Instruction*);
566         void emit_op_jnless(const Instruction*);
567         void emit_op_jnlesseq(const Instruction*);
568         void emit_op_jngreater(const Instruction*);
569         void emit_op_jngreatereq(const Instruction*);
570         void emit_op_jeq(const Instruction*);
571         void emit_op_jneq(const Instruction*);
572         void emit_op_jstricteq(const Instruction*);
573         void emit_op_jnstricteq(const Instruction*);
574         void emit_op_jbelow(const Instruction*);
575         void emit_op_jbeloweq(const Instruction*);
576         void emit_op_jtrue(const Instruction*);
577         void emit_op_loop_hint(const Instruction*);
<a name="14" id="anc14"></a>
578         void emit_op_nop(const Instruction*);
579         void emit_op_super_sampler_begin(const Instruction*);
580         void emit_op_super_sampler_end(const Instruction*);
581         void emit_op_lshift(const Instruction*);
582         void emit_op_mod(const Instruction*);
583         void emit_op_mov(const Instruction*);
584         void emit_op_mul(const Instruction*);
585         void emit_op_negate(const Instruction*);
586         void emit_op_neq(const Instruction*);
587         void emit_op_neq_null(const Instruction*);
588         void emit_op_new_array(const Instruction*);
589         void emit_op_new_array_with_size(const Instruction*);
590         void emit_op_new_func(const Instruction*);
591         void emit_op_new_func_exp(const Instruction*);
592         void emit_op_new_generator_func(const Instruction*);
593         void emit_op_new_generator_func_exp(const Instruction*);
594         void emit_op_new_async_func(const Instruction*);
595         void emit_op_new_async_func_exp(const Instruction*);
596         void emit_op_new_async_generator_func(const Instruction*);
597         void emit_op_new_async_generator_func_exp(const Instruction*);
598         void emit_op_new_object(const Instruction*);
599         void emit_op_new_regexp(const Instruction*);
600         void emit_op_not(const Instruction*);
601         void emit_op_nstricteq(const Instruction*);
602         void emit_op_dec(const Instruction*);
603         void emit_op_inc(const Instruction*);
604         void emit_op_profile_type(const Instruction*);
605         void emit_op_profile_control_flow(const Instruction*);
606         void emit_op_get_parent_scope(const Instruction*);
607         void emit_op_put_by_id(const Instruction*);
608         template&lt;typename Op = OpPutByVal&gt;
609         void emit_op_put_by_val(const Instruction*);
610         void emit_op_put_by_val_direct(const Instruction*);
611         void emit_op_put_getter_by_id(const Instruction*);
612         void emit_op_put_setter_by_id(const Instruction*);
613         void emit_op_put_getter_setter_by_id(const Instruction*);
614         void emit_op_put_getter_by_val(const Instruction*);
615         void emit_op_put_setter_by_val(const Instruction*);
616         void emit_op_ret(const Instruction*);
617         void emit_op_rshift(const Instruction*);
618         void emit_op_set_function_name(const Instruction*);
619         void emit_op_stricteq(const Instruction*);
620         void emit_op_sub(const Instruction*);
621         void emit_op_switch_char(const Instruction*);
622         void emit_op_switch_imm(const Instruction*);
623         void emit_op_switch_string(const Instruction*);
624         void emit_op_tear_off_arguments(const Instruction*);
625         void emit_op_throw(const Instruction*);
626         void emit_op_to_number(const Instruction*);
627         void emit_op_to_string(const Instruction*);
628         void emit_op_to_object(const Instruction*);
629         void emit_op_to_primitive(const Instruction*);
630         void emit_op_unexpected_load(const Instruction*);
631         void emit_op_unsigned(const Instruction*);
632         void emit_op_urshift(const Instruction*);
633         void emit_op_has_structure_property(const Instruction*);
634         void emit_op_has_indexed_property(const Instruction*);
635         void emit_op_get_direct_pname(const Instruction*);
636         void emit_op_enumerator_structure_pname(const Instruction*);
637         void emit_op_enumerator_generic_pname(const Instruction*);
638         void emit_op_log_shadow_chicken_prologue(const Instruction*);
639         void emit_op_log_shadow_chicken_tail(const Instruction*);
640 
641         void emitSlow_op_add(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
642         void emitSlow_op_call(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
643         void emitSlow_op_tail_call(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
644         void emitSlow_op_call_eval(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
645         void emitSlow_op_call_varargs(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
646         void emitSlow_op_tail_call_varargs(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
647         void emitSlow_op_tail_call_forward_arguments(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
648         void emitSlow_op_construct_varargs(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
649         void emitSlow_op_construct(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
650         void emitSlow_op_eq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
651         void emitSlow_op_get_callee(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
652         void emitSlow_op_try_get_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
653         void emitSlow_op_get_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
654         void emitSlow_op_get_by_id_with_this(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
655         void emitSlow_op_get_by_id_direct(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
656         void emitSlow_op_get_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
657         void emitSlow_op_get_argument_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
658         void emitSlow_op_in_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
659         void emitSlow_op_instanceof(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
660         void emitSlow_op_instanceof_custom(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
661         void emitSlow_op_jless(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
662         void emitSlow_op_jlesseq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
663         void emitSlow_op_jgreater(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
664         void emitSlow_op_jgreatereq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
665         void emitSlow_op_jnless(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
666         void emitSlow_op_jnlesseq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
667         void emitSlow_op_jngreater(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
668         void emitSlow_op_jngreatereq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
669         void emitSlow_op_jeq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
670         void emitSlow_op_jneq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
671         void emitSlow_op_jstricteq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
672         void emitSlow_op_jnstricteq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
673         void emitSlow_op_jtrue(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
674         void emitSlow_op_loop_hint(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
<a name="15" id="anc15"></a><span class="line-modified">675         void emitSlow_op_enter(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);</span>
676         void emitSlow_op_mod(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
677         void emitSlow_op_mul(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
678         void emitSlow_op_negate(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
679         void emitSlow_op_neq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
680         void emitSlow_op_new_object(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
681         void emitSlow_op_put_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
682         void emitSlow_op_put_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
683         void emitSlow_op_sub(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
684         void emitSlow_op_has_indexed_property(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
685 
686         void emit_op_resolve_scope(const Instruction*);
687         void emit_op_get_from_scope(const Instruction*);
688         void emit_op_put_to_scope(const Instruction*);
689         void emit_op_get_from_arguments(const Instruction*);
690         void emit_op_put_to_arguments(const Instruction*);
691         void emitSlow_op_get_from_scope(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
692         void emitSlow_op_put_to_scope(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
693 
694         void emitSlowCaseCall(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, SlowPathFunction);
695 
696         void emitRightShift(const Instruction*, bool isUnsigned);
697         void emitRightShiftSlowCase(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, bool isUnsigned);
698 
699         template&lt;typename Op&gt;
700         void emitNewFuncCommon(const Instruction*);
701         template&lt;typename Op&gt;
702         void emitNewFuncExprCommon(const Instruction*);
703         void emitVarInjectionCheck(bool needsVarInjectionChecks);
704         void emitResolveClosure(int dst, int scope, bool needsVarInjectionChecks, unsigned depth);
705         void emitLoadWithStructureCheck(int scope, Structure** structureSlot);
706 #if USE(JSVALUE64)
707         void emitGetVarFromPointer(JSValue* operand, GPRReg);
708         void emitGetVarFromIndirectPointer(JSValue** operand, GPRReg);
709 #else
710         void emitGetVarFromIndirectPointer(JSValue** operand, GPRReg tag, GPRReg payload);
711         void emitGetVarFromPointer(JSValue* operand, GPRReg tag, GPRReg payload);
712 #endif
713         void emitGetClosureVar(int scope, uintptr_t operand);
714         void emitNotifyWrite(WatchpointSet*);
715         void emitNotifyWrite(GPRReg pointerToSet);
716         void emitPutGlobalVariable(JSValue* operand, int value, WatchpointSet*);
717         void emitPutGlobalVariableIndirect(JSValue** addressOfOperand, int value, WatchpointSet**);
718         void emitPutClosureVar(int scope, uintptr_t operand, int value, WatchpointSet*);
719 
720         void emitInitRegister(int dst);
721 
722         void emitPutIntToCallFrameHeader(RegisterID from, int entry);
723 
724         JSValue getConstantOperand(int src);
725         bool isOperandConstantInt(int src);
726         bool isOperandConstantChar(int src);
727 
728         template &lt;typename Op, typename Generator, typename ProfiledFunction, typename NonProfiledFunction&gt;
729         void emitMathICFast(JITUnaryMathIC&lt;Generator&gt;*, const Instruction*, ProfiledFunction, NonProfiledFunction);
730         template &lt;typename Op, typename Generator, typename ProfiledFunction, typename NonProfiledFunction&gt;
731         void emitMathICFast(JITBinaryMathIC&lt;Generator&gt;*, const Instruction*, ProfiledFunction, NonProfiledFunction);
732 
733         template &lt;typename Op, typename Generator, typename ProfiledRepatchFunction, typename ProfiledFunction, typename RepatchFunction&gt;
734         void emitMathICSlow(JITBinaryMathIC&lt;Generator&gt;*, const Instruction*, ProfiledRepatchFunction, ProfiledFunction, RepatchFunction);
735         template &lt;typename Op, typename Generator, typename ProfiledRepatchFunction, typename ProfiledFunction, typename RepatchFunction&gt;
736         void emitMathICSlow(JITUnaryMathIC&lt;Generator&gt;*, const Instruction*, ProfiledRepatchFunction, ProfiledFunction, RepatchFunction);
737 
738         Jump getSlowCase(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
739         {
740             return iter++-&gt;from;
741         }
742         void linkSlowCase(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
743         {
744             if (iter-&gt;from.isSet())
745                 iter-&gt;from.link(this);
746             ++iter;
747         }
748         void linkDummySlowCase(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
749         {
750             ASSERT(!iter-&gt;from.isSet());
751             ++iter;
752         }
753         void linkSlowCaseIfNotJSCell(Vector&lt;SlowCaseEntry&gt;::iterator&amp;, int virtualRegisterIndex);
754         void linkAllSlowCasesForBytecodeOffset(Vector&lt;SlowCaseEntry&gt;&amp; slowCases,
755             Vector&lt;SlowCaseEntry&gt;::iterator&amp;, unsigned bytecodeOffset);
756 
757         void linkAllSlowCases(Vector&lt;SlowCaseEntry&gt;::iterator&amp; iter)
758         {
759             linkAllSlowCasesForBytecodeOffset(m_slowCases, iter, m_bytecodeOffset);
760         }
761 
762         MacroAssembler::Call appendCallWithExceptionCheck(const FunctionPtr&lt;CFunctionPtrTag&gt;);
763 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
764         MacroAssembler::Call appendCallWithExceptionCheckAndSlowPathReturnType(const FunctionPtr&lt;CFunctionPtrTag&gt;);
765 #endif
766         MacroAssembler::Call appendCallWithCallFrameRollbackOnException(const FunctionPtr&lt;CFunctionPtrTag&gt;);
767         MacroAssembler::Call appendCallWithExceptionCheckSetJSValueResult(const FunctionPtr&lt;CFunctionPtrTag&gt;, int);
768         template&lt;typename Metadata&gt;
769         MacroAssembler::Call appendCallWithExceptionCheckSetJSValueResultWithProfile(Metadata&amp;, const FunctionPtr&lt;CFunctionPtrTag&gt;, int);
770 
771         template&lt;typename OperationType, typename... Args&gt;
772         std::enable_if_t&lt;FunctionTraits&lt;OperationType&gt;::hasResult, MacroAssembler::Call&gt;
773         callOperation(OperationType operation, int result, Args... args)
774         {
775             setupArguments&lt;OperationType&gt;(args...);
776             return appendCallWithExceptionCheckSetJSValueResult(operation, result);
777         }
778 
779 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
780         template&lt;typename OperationType, typename... Args&gt;
781         std::enable_if_t&lt;std::is_same&lt;typename FunctionTraits&lt;OperationType&gt;::ResultType, SlowPathReturnType&gt;::value, MacroAssembler::Call&gt;
782         callOperation(OperationType operation, Args... args)
783         {
784             setupArguments&lt;OperationType&gt;(args...);
785             return appendCallWithExceptionCheckAndSlowPathReturnType(operation);
786         }
787 
788         template&lt;typename Type&gt;
789         struct is64BitType {
790             static constexpr bool value = sizeof(Type) &lt;= 8;
791         };
792 
793         template&lt;&gt;
794         struct is64BitType&lt;void&gt; {
795             static constexpr bool value = true;
796         };
797 
798         template&lt;typename OperationType, typename... Args&gt;
799         std::enable_if_t&lt;!std::is_same&lt;typename FunctionTraits&lt;OperationType&gt;::ResultType, SlowPathReturnType&gt;::value, MacroAssembler::Call&gt;
800         callOperation(OperationType operation, Args... args)
801         {
802             static_assert(is64BitType&lt;typename FunctionTraits&lt;OperationType&gt;::ResultType&gt;::value, &quot;Win64 cannot use standard call when return type is larger than 64 bits.&quot;);
803             setupArguments&lt;OperationType&gt;(args...);
804             return appendCallWithExceptionCheck(operation);
805         }
806 #else // OS(WINDOWS) &amp;&amp; CPU(X86_64)
807         template&lt;typename OperationType, typename... Args&gt;
808         MacroAssembler::Call callOperation(OperationType operation, Args... args)
809         {
810             setupArguments&lt;OperationType&gt;(args...);
811             return appendCallWithExceptionCheck(operation);
812         }
813 #endif // OS(WINDOWS) &amp;&amp; CPU(X86_64)
814 
815         template&lt;typename Metadata, typename OperationType, typename... Args&gt;
816         std::enable_if_t&lt;FunctionTraits&lt;OperationType&gt;::hasResult, MacroAssembler::Call&gt;
817         callOperationWithProfile(Metadata&amp; metadata, OperationType operation, int result, Args... args)
818         {
819             setupArguments&lt;OperationType&gt;(args...);
820             return appendCallWithExceptionCheckSetJSValueResultWithProfile(metadata, operation, result);
821         }
822 
823         template&lt;typename OperationType, typename... Args&gt;
824         MacroAssembler::Call callOperationWithResult(OperationType operation, JSValueRegs resultRegs, Args... args)
825         {
826             setupArguments&lt;OperationType&gt;(args...);
827             auto result = appendCallWithExceptionCheck(operation);
828             setupResults(resultRegs);
829             return result;
830         }
831 
832         template&lt;typename OperationType, typename... Args&gt;
833         MacroAssembler::Call callOperationNoExceptionCheck(OperationType operation, Args... args)
834         {
835             setupArguments&lt;OperationType&gt;(args...);
836             updateTopCallFrame();
837             return appendCall(operation);
838         }
839 
840         template&lt;typename OperationType, typename... Args&gt;
841         MacroAssembler::Call callOperationWithCallFrameRollbackOnException(OperationType operation, Args... args)
842         {
843             setupArguments&lt;OperationType&gt;(args...);
844             return appendCallWithCallFrameRollbackOnException(operation);
845         }
846 
847         enum class ProfilingPolicy {
848             ShouldEmitProfiling,
849             NoProfiling
850         };
851 
852         template&lt;typename Op, typename SnippetGenerator&gt;
853         void emitBitBinaryOpFastPath(const Instruction* currentInstruction, ProfilingPolicy shouldEmitProfiling = ProfilingPolicy::NoProfiling);
854 
855         void emitRightShiftFastPath(const Instruction* currentInstruction, OpcodeID);
856 
857         template&lt;typename Op&gt;
858         void emitRightShiftFastPath(const Instruction* currentInstruction, JITRightShiftGenerator::ShiftType);
859 
860         void updateTopCallFrame();
861 
862         Call emitNakedCall(CodePtr&lt;NoPtrTag&gt; function = CodePtr&lt;NoPtrTag&gt;());
863         Call emitNakedTailCall(CodePtr&lt;NoPtrTag&gt; function = CodePtr&lt;NoPtrTag&gt;());
864 
865         // Loads the character value of a single character string into dst.
866         void emitLoadCharacterString(RegisterID src, RegisterID dst, JumpList&amp; failures);
867 
868         int jumpTarget(const Instruction*, int target);
869 
<a name="16" id="anc16"></a>





870 #ifndef NDEBUG
871         void printBytecodeOperandTypes(int src1, int src2);
872 #endif
873 
874 #if ENABLE(SAMPLING_FLAGS)
875         void setSamplingFlag(int32_t);
876         void clearSamplingFlag(int32_t);
877 #endif
878 
879 #if ENABLE(SAMPLING_COUNTERS)
880         void emitCount(AbstractSamplingCounter&amp;, int32_t = 1);
881 #endif
882 
883 #if ENABLE(OPCODE_SAMPLING)
884         void sampleInstruction(const Instruction*, bool = false);
885 #endif
886 
887 #if ENABLE(CODEBLOCK_SAMPLING)
888         void sampleCodeBlock(CodeBlock*);
889 #else
890         void sampleCodeBlock(CodeBlock*) {}
891 #endif
892 
893 #if ENABLE(DFG_JIT)
894         bool canBeOptimized() { return m_canBeOptimized; }
895         bool canBeOptimizedOrInlined() { return m_canBeOptimizedOrInlined; }
896         bool shouldEmitProfiling() { return m_shouldEmitProfiling; }
897 #else
898         bool canBeOptimized() { return false; }
899         bool canBeOptimizedOrInlined() { return false; }
900         // Enables use of value profiler with tiered compilation turned off,
901         // in which case all code gets profiled.
902         bool shouldEmitProfiling() { return false; }
903 #endif
904 
905         static bool reportCompileTimes();
906         static bool computeCompileTimes();
907 
908         // If you need to check a value from the metadata table and you need it to
909         // be consistent across the fast and slow path, then you want to use this.
910         // It will give the slow path the same value read by the fast path.
911         GetPutInfo copiedGetPutInfo(OpPutToScope);
912         template&lt;typename BinaryOp&gt;
913         ArithProfile copiedArithProfile(BinaryOp);
914 
915         Interpreter* m_interpreter;
916 
917         Vector&lt;CallRecord&gt; m_calls;
918         Vector&lt;Label&gt; m_labels;
919         Vector&lt;JITGetByIdGenerator&gt; m_getByIds;
920         Vector&lt;JITGetByIdWithThisGenerator&gt; m_getByIdsWithThis;
921         Vector&lt;JITPutByIdGenerator&gt; m_putByIds;
922         Vector&lt;JITInByIdGenerator&gt; m_inByIds;
923         Vector&lt;JITInstanceOfGenerator&gt; m_instanceOfs;
924         Vector&lt;ByValCompilationInfo&gt; m_byValCompilationInfo;
925         Vector&lt;CallCompilationInfo&gt; m_callCompilationInfo;
926         Vector&lt;JumpTable&gt; m_jmpTable;
927 
928         unsigned m_bytecodeOffset;
929         Vector&lt;SlowCaseEntry&gt; m_slowCases;
930         Vector&lt;SwitchRecord&gt; m_switches;
931 
932         HashMap&lt;unsigned, unsigned&gt; m_copiedGetPutInfos;
933         HashMap&lt;uint64_t, ArithProfile&gt; m_copiedArithProfiles;
934 
935         JumpList m_exceptionChecks;
936         JumpList m_exceptionChecksWithCallFrameRollback;
937         Label m_exceptionHandler;
938 
939         unsigned m_getByIdIndex { UINT_MAX };
940         unsigned m_getByIdWithThisIndex { UINT_MAX };
941         unsigned m_putByIdIndex { UINT_MAX };
942         unsigned m_inByIdIndex { UINT_MAX };
943         unsigned m_instanceOfIndex { UINT_MAX };
944         unsigned m_byValInstructionIndex { UINT_MAX };
945         unsigned m_callLinkInfoIndex { UINT_MAX };
946 
947         Label m_arityCheck;
948         std::unique_ptr&lt;LinkBuffer&gt; m_linkBuffer;
949 
950         std::unique_ptr&lt;JITDisassembler&gt; m_disassembler;
951         RefPtr&lt;Profiler::Compilation&gt; m_compilation;
952 
953         PCToCodeOriginMapBuilder m_pcToCodeOriginMapBuilder;
954 
955         HashMap&lt;const Instruction*, void*&gt; m_instructionToMathIC;
956         HashMap&lt;const Instruction*, MathICGenerationState&gt; m_instructionToMathICGenerationState;
957 
958         bool m_canBeOptimized;
959         bool m_canBeOptimizedOrInlined;
960         bool m_shouldEmitProfiling;
961         bool m_shouldUseIndexMasking;
962         unsigned m_loopOSREntryBytecodeOffset { 0 };
963     };
964 
965 } // namespace JSC
966 
967 
968 #endif // ENABLE(JIT)
<a name="17" id="anc17"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="17" type="hidden" />
</body>
</html>