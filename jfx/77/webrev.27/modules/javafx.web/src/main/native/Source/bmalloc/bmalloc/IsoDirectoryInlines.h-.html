<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/IsoDirectoryInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2017-2018 Apple Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;IsoDirectory.h&quot;
 29 
 30 namespace bmalloc {
 31 
 32 template&lt;typename Config&gt;
 33 IsoDirectoryBase&lt;Config&gt;::IsoDirectoryBase(IsoHeapImpl&lt;Config&gt;&amp; heap)
 34     : m_heap(heap)
 35 {
 36 }
 37 
 38 template&lt;typename Config, unsigned passedNumPages&gt;
 39 IsoDirectory&lt;Config, passedNumPages&gt;::IsoDirectory(IsoHeapImpl&lt;Config&gt;&amp; heap)
 40     : IsoDirectoryBase&lt;Config&gt;(heap)
 41 {
 42     for (unsigned i = numPages; i--;)
 43         m_pages[i] = nullptr;
 44 }
 45 
 46 template&lt;typename Config, unsigned passedNumPages&gt;
 47 EligibilityResult&lt;Config&gt; IsoDirectory&lt;Config, passedNumPages&gt;::takeFirstEligible()
 48 {
 49     unsigned pageIndex = (m_eligible | ~m_committed).findBit(m_firstEligible, true);
 50     m_firstEligible = pageIndex;
 51     if (pageIndex &gt;= numPages)
 52         return EligibilityKind::Full;
 53 
 54     m_highWatermark = std::max(pageIndex, m_highWatermark);
 55 
 56     Scavenger&amp; scavenger = *PerProcess&lt;Scavenger&gt;::get();
 57     scavenger.didStartGrowing();
 58 
 59     IsoPage&lt;Config&gt;* page = m_pages[pageIndex];
 60 
 61     if (!m_committed[pageIndex]) {
 62         scavenger.scheduleIfUnderMemoryPressure(IsoPageBase::pageSize);
 63 
 64         // It could be that we haven&#39;t even allocated a page yet. Do that now!
 65         if (!page) {
 66             page = IsoPage&lt;Config&gt;::tryCreate(*this, pageIndex);
 67             if (!page)
 68                 return EligibilityKind::OutOfMemory;
 69             m_pages[pageIndex] = page;
 70         } else {
 71             // This means that we have a page that we previously allocated and that page just needs to be
 72             // committed.
 73             vmAllocatePhysicalPages(page, IsoPageBase::pageSize);
 74             new (page) IsoPage&lt;Config&gt;(*this, pageIndex);
 75         }
 76 
 77         m_committed[pageIndex] = true;
 78         this-&gt;m_heap.didCommit(page, IsoPageBase::pageSize);
 79     } else {
 80         if (m_empty[pageIndex])
 81             this-&gt;m_heap.isNoLongerFreeable(page, IsoPageBase::pageSize);
 82     }
 83 
 84     RELEASE_BASSERT(page);
 85 
 86     // Make the page non-empty and non-eligible.
 87     m_eligible[pageIndex] = false;
 88     m_empty[pageIndex] = false;
 89     return page;
 90 }
 91 
 92 template&lt;typename Config, unsigned passedNumPages&gt;
 93 void IsoDirectory&lt;Config, passedNumPages&gt;::didBecome(IsoPage&lt;Config&gt;* page, IsoPageTrigger trigger)
 94 {
 95     static constexpr bool verbose = false;
 96     unsigned pageIndex = page-&gt;index();
 97     switch (trigger) {
 98     case IsoPageTrigger::Eligible:
 99         if (verbose)
100             fprintf(stderr, &quot;%p: %p did become eligible.\n&quot;, this, page);
101         m_eligible[pageIndex] = true;
102         m_firstEligible = std::min(m_firstEligible, pageIndex);
103         this-&gt;m_heap.didBecomeEligible(this);
104         return;
105     case IsoPageTrigger::Empty:
106         if (verbose)
107             fprintf(stderr, &quot;%p: %p did become empty.\n&quot;, this, page);
108         BASSERT(!!m_committed[pageIndex]);
109         this-&gt;m_heap.isNowFreeable(page, IsoPageBase::pageSize);
110         m_empty[pageIndex] = true;
111         PerProcess&lt;Scavenger&gt;::get()-&gt;schedule(IsoPageBase::pageSize);
112         return;
113     }
114     BCRASH();
115 }
116 
117 template&lt;typename Config, unsigned passedNumPages&gt;
118 void IsoDirectory&lt;Config, passedNumPages&gt;::didDecommit(unsigned index)
119 {
120     // FIXME: We could do this without grabbing the lock. I just doubt that it matters. This is not going
121     // to be a frequently executed path, in the sense that decommitting perf will be dominated by the
122     // syscall itself (which has to do many hard things).
123     std::lock_guard&lt;Mutex&gt; locker(this-&gt;m_heap.lock);
124     BASSERT(!!m_committed[index]);
125     this-&gt;m_heap.isNoLongerFreeable(m_pages[index], IsoPageBase::pageSize);
126     m_committed[index] = false;
127     this-&gt;m_heap.didDecommit(m_pages[index], IsoPageBase::pageSize);
128 }
129 
130 template&lt;typename Config, unsigned passedNumPages&gt;
131 void IsoDirectory&lt;Config, passedNumPages&gt;::scavengePage(size_t index, Vector&lt;DeferredDecommit&gt;&amp; decommits)
132 {
133     // Make sure that this page is now off limits.
134     m_empty[index] = false;
135     m_eligible[index] = false;
136     decommits.push(DeferredDecommit(this, m_pages[index], index));
137 }
138 
139 template&lt;typename Config, unsigned passedNumPages&gt;
140 void IsoDirectory&lt;Config, passedNumPages&gt;::scavenge(Vector&lt;DeferredDecommit&gt;&amp; decommits)
141 {
142     (m_empty &amp; m_committed).forEachSetBit(
143         [&amp;] (size_t index) {
144             scavengePage(index, decommits);
145         });
146     m_highWatermark = 0;
147 }
148 
149 template&lt;typename Config, unsigned passedNumPages&gt;
150 void IsoDirectory&lt;Config, passedNumPages&gt;::scavengeToHighWatermark(Vector&lt;DeferredDecommit&gt;&amp; decommits)
151 {
152     (m_empty &amp; m_committed).forEachSetBit(
153         [&amp;] (size_t index) {
154             if (index &gt; m_highWatermark)
155                 scavengePage(index, decommits);
156         });
157     m_highWatermark = 0;
158 }
159 
160 template&lt;typename Config, unsigned passedNumPages&gt;
161 template&lt;typename Func&gt;
162 void IsoDirectory&lt;Config, passedNumPages&gt;::forEachCommittedPage(const Func&amp; func)
163 {
164     m_committed.forEachSetBit(
165         [&amp;] (size_t index) {
166             func(*m_pages[index]);
167         });
168 }
169 
170 } // namespace bmalloc
171 
    </pre>
  </body>
</html>