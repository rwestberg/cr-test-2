<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JIT.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="JIT.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITArithmetic.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JIT.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (C) 2008-2018 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
</pre>
<hr />
<pre>
175         CallLinkInfo* callLinkInfo;
176     };
177 
178     void ctiPatchCallByReturnAddress(ReturnAddressPtr, FunctionPtr&lt;CFunctionPtrTag&gt; newCalleeFunction);
179 
180     class JIT_CLASS_ALIGNMENT JIT : private JSInterfaceJIT {
181         friend class JITSlowPathCall;
182         friend class JITStubCall;
183 
184         using MacroAssembler::Jump;
185         using MacroAssembler::JumpList;
186         using MacroAssembler::Label;
187 
188         static const uintptr_t patchGetByIdDefaultStructure = unusedPointer;
189         static const int patchGetByIdDefaultOffset = 0;
190         // Magic number - initial offset cannot be representable as a signed 8bit value, or the X86Assembler
191         // will compress the displacement, and we may not be able to fit a patched offset.
192         static const int patchPutByIdDefaultOffset = 256;
193 
194     public:
<span class="line-modified">195         JIT(VM*, CodeBlock* = 0, unsigned loopOSREntryBytecodeOffset = 0);</span>
196         ~JIT();
197 


198         void compileWithoutLinking(JITCompilationEffort);
199         CompilationResult link();
200 
201         void doMainThreadPreparationBeforeCompile();
202 
<span class="line-modified">203         static CompilationResult compile(VM* vm, CodeBlock* codeBlock, JITCompilationEffort effort, unsigned bytecodeOffset = 0)</span>
204         {
205             return JIT(vm, codeBlock, bytecodeOffset).privateCompile(effort);
206         }
207 
<span class="line-modified">208         static void compileGetByVal(const ConcurrentJSLocker&amp; locker, VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
209         {
210             JIT jit(vm, codeBlock);
211             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
212             jit.privateCompileGetByVal(locker, byValInfo, returnAddress, arrayMode);
213         }
214 
<span class="line-modified">215         static void compileGetByValWithCachedId(VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, const Identifier&amp; propertyName)</span>
216         {
217             JIT jit(vm, codeBlock);
218             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
219             jit.privateCompileGetByValWithCachedId(byValInfo, returnAddress, propertyName);
220         }
221 
<span class="line-modified">222         static void compilePutByVal(const ConcurrentJSLocker&amp; locker, VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
223         {
224             JIT jit(vm, codeBlock);
225             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
226             jit.privateCompilePutByVal&lt;OpPutByVal&gt;(locker, byValInfo, returnAddress, arrayMode);
227         }
228 
<span class="line-modified">229         static void compileDirectPutByVal(const ConcurrentJSLocker&amp; locker, VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
230         {
231             JIT jit(vm, codeBlock);
232             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
233             jit.privateCompilePutByVal&lt;OpPutByValDirect&gt;(locker, byValInfo, returnAddress, arrayMode);
234         }
235 
236         template&lt;typename Op&gt;
<span class="line-modified">237         static void compilePutByValWithCachedId(VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, PutKind putKind, const Identifier&amp; propertyName)</span>
238         {
239             JIT jit(vm, codeBlock);
240             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
241             jit.privateCompilePutByValWithCachedId&lt;Op&gt;(byValInfo, returnAddress, putKind, propertyName);
242         }
243 
<span class="line-modified">244         static void compileHasIndexedProperty(VM* vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
245         {
246             JIT jit(vm, codeBlock);
247             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
248             jit.privateCompileHasIndexedProperty(byValInfo, returnAddress, arrayMode);
249         }
250 
251         static unsigned frameRegisterCountFor(CodeBlock*);
252         static int stackPointerOffsetFor(CodeBlock*);
253 
254         JS_EXPORT_PRIVATE static HashMap&lt;CString, Seconds&gt; compileTimeStats();
255         JS_EXPORT_PRIVATE static Seconds totalCompileTime();
256 
257     private:
258         void privateCompileMainPass();
259         void privateCompileLinkPass();
260         void privateCompileSlowCases();
261         CompilationResult privateCompile(JITCompilationEffort);
262 
263         void privateCompileGetByVal(const ConcurrentJSLocker&amp;, ByValInfo*, ReturnAddressPtr, JITArrayMode);
264         void privateCompileGetByValWithCachedId(ByValInfo*, ReturnAddressPtr, const Identifier&amp;);
</pre>
<hr />
<pre>
278             m_calls.append(CallRecord(functionCall, m_bytecodeOffset, function.retagged&lt;OperationPtrTag&gt;()));
279             return functionCall;
280         }
281 
282 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
283         Call appendCallWithSlowPathReturnType(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
284         {
285             Call functionCall = callWithSlowPathReturnType(OperationPtrTag);
286             m_calls.append(CallRecord(functionCall, m_bytecodeOffset, function.retagged&lt;OperationPtrTag&gt;()));
287             return functionCall;
288         }
289 #endif
290 
291         void exceptionCheck(Jump jumpToHandler)
292         {
293             m_exceptionChecks.append(jumpToHandler);
294         }
295 
296         void exceptionCheck()
297         {
<span class="line-modified">298             m_exceptionChecks.append(emitExceptionCheck(*vm()));</span>
299         }
300 
301         void exceptionCheckWithCallFrameRollback()
302         {
<span class="line-modified">303             m_exceptionChecksWithCallFrameRollback.append(emitExceptionCheck(*vm()));</span>
304         }
305 
306         void privateCompileExceptionHandlers();
307 
308         void addSlowCase(Jump);
309         void addSlowCase(const JumpList&amp;);
310         void addSlowCase();
311         void addJump(Jump, int);
312         void addJump(const JumpList&amp;, int);
313         void emitJumpSlowToHot(Jump, int);
314 
315         template&lt;typename Op&gt;
316         void compileOpCall(const Instruction*, unsigned callLinkInfoIndex);
317         template&lt;typename Op&gt;
318         void compileOpCallSlowCase(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, unsigned callLinkInfoIndex);
319         template&lt;typename Op&gt;
320         std::enable_if_t&lt;
321             Op::opcodeID != op_call_varargs &amp;&amp; Op::opcodeID != op_construct_varargs
322             &amp;&amp; Op::opcodeID != op_tail_call_varargs &amp;&amp; Op::opcodeID != op_tail_call_forward_arguments
323         , void&gt; compileSetupFrame(const Op&amp;, CallLinkInfo*);
</pre>
<hr />
<pre>
537         void emit_op_get_by_id_with_this(const Instruction*);
538         void emit_op_get_by_id_direct(const Instruction*);
539         void emit_op_get_by_val(const Instruction*);
540         void emit_op_get_argument_by_val(const Instruction*);
541         void emit_op_in_by_id(const Instruction*);
542         void emit_op_init_lazy_reg(const Instruction*);
543         void emit_op_overrides_has_instance(const Instruction*);
544         void emit_op_instanceof(const Instruction*);
545         void emit_op_instanceof_custom(const Instruction*);
546         void emit_op_is_empty(const Instruction*);
547         void emit_op_is_undefined(const Instruction*);
548         void emit_op_is_undefined_or_null(const Instruction*);
549         void emit_op_is_boolean(const Instruction*);
550         void emit_op_is_number(const Instruction*);
551         void emit_op_is_object(const Instruction*);
552         void emit_op_is_cell_with_type(const Instruction*);
553         void emit_op_jeq_null(const Instruction*);
554         void emit_op_jfalse(const Instruction*);
555         void emit_op_jmp(const Instruction*);
556         void emit_op_jneq_null(const Instruction*);


557         void emit_op_jneq_ptr(const Instruction*);
558         void emit_op_jless(const Instruction*);
559         void emit_op_jlesseq(const Instruction*);
560         void emit_op_jgreater(const Instruction*);
561         void emit_op_jgreatereq(const Instruction*);
562         void emit_op_jnless(const Instruction*);
563         void emit_op_jnlesseq(const Instruction*);
564         void emit_op_jngreater(const Instruction*);
565         void emit_op_jngreatereq(const Instruction*);
566         void emit_op_jeq(const Instruction*);
567         void emit_op_jneq(const Instruction*);
568         void emit_op_jstricteq(const Instruction*);
569         void emit_op_jnstricteq(const Instruction*);
570         void emit_op_jbelow(const Instruction*);
571         void emit_op_jbeloweq(const Instruction*);
572         void emit_op_jtrue(const Instruction*);
573         void emit_op_loop_hint(const Instruction*);
<span class="line-removed">574         void emit_op_check_traps(const Instruction*);</span>
575         void emit_op_nop(const Instruction*);
576         void emit_op_super_sampler_begin(const Instruction*);
577         void emit_op_super_sampler_end(const Instruction*);
578         void emit_op_lshift(const Instruction*);
579         void emit_op_mod(const Instruction*);
580         void emit_op_mov(const Instruction*);
581         void emit_op_mul(const Instruction*);
582         void emit_op_negate(const Instruction*);
583         void emit_op_neq(const Instruction*);
584         void emit_op_neq_null(const Instruction*);
585         void emit_op_new_array(const Instruction*);
586         void emit_op_new_array_with_size(const Instruction*);
587         void emit_op_new_func(const Instruction*);
588         void emit_op_new_func_exp(const Instruction*);
589         void emit_op_new_generator_func(const Instruction*);
590         void emit_op_new_generator_func_exp(const Instruction*);
591         void emit_op_new_async_func(const Instruction*);
592         void emit_op_new_async_func_exp(const Instruction*);
593         void emit_op_new_async_generator_func(const Instruction*);
594         void emit_op_new_async_generator_func_exp(const Instruction*);
</pre>
<hr />
<pre>
652         void emitSlow_op_get_by_id_direct(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
653         void emitSlow_op_get_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
654         void emitSlow_op_get_argument_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
655         void emitSlow_op_in_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
656         void emitSlow_op_instanceof(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
657         void emitSlow_op_instanceof_custom(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
658         void emitSlow_op_jless(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
659         void emitSlow_op_jlesseq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
660         void emitSlow_op_jgreater(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
661         void emitSlow_op_jgreatereq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
662         void emitSlow_op_jnless(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
663         void emitSlow_op_jnlesseq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
664         void emitSlow_op_jngreater(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
665         void emitSlow_op_jngreatereq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
666         void emitSlow_op_jeq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
667         void emitSlow_op_jneq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
668         void emitSlow_op_jstricteq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
669         void emitSlow_op_jnstricteq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
670         void emitSlow_op_jtrue(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
671         void emitSlow_op_loop_hint(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
<span class="line-modified">672         void emitSlow_op_check_traps(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);</span>
673         void emitSlow_op_mod(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
674         void emitSlow_op_mul(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
675         void emitSlow_op_negate(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
676         void emitSlow_op_neq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
677         void emitSlow_op_new_object(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
678         void emitSlow_op_put_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
679         void emitSlow_op_put_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
680         void emitSlow_op_sub(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
681         void emitSlow_op_has_indexed_property(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
682 
683         void emit_op_resolve_scope(const Instruction*);
684         void emit_op_get_from_scope(const Instruction*);
685         void emit_op_put_to_scope(const Instruction*);
686         void emit_op_get_from_arguments(const Instruction*);
687         void emit_op_put_to_arguments(const Instruction*);
688         void emitSlow_op_get_from_scope(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
689         void emitSlow_op_put_to_scope(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
690 
691         void emitSlowCaseCall(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, SlowPathFunction);
692 
</pre>
<hr />
<pre>
847         };
848 
849         template&lt;typename Op, typename SnippetGenerator&gt;
850         void emitBitBinaryOpFastPath(const Instruction* currentInstruction, ProfilingPolicy shouldEmitProfiling = ProfilingPolicy::NoProfiling);
851 
852         void emitRightShiftFastPath(const Instruction* currentInstruction, OpcodeID);
853 
854         template&lt;typename Op&gt;
855         void emitRightShiftFastPath(const Instruction* currentInstruction, JITRightShiftGenerator::ShiftType);
856 
857         void updateTopCallFrame();
858 
859         Call emitNakedCall(CodePtr&lt;NoPtrTag&gt; function = CodePtr&lt;NoPtrTag&gt;());
860         Call emitNakedTailCall(CodePtr&lt;NoPtrTag&gt; function = CodePtr&lt;NoPtrTag&gt;());
861 
862         // Loads the character value of a single character string into dst.
863         void emitLoadCharacterString(RegisterID src, RegisterID dst, JumpList&amp; failures);
864 
865         int jumpTarget(const Instruction*, int target);
866 
<span class="line-removed">867 #if ENABLE(DFG_JIT)</span>
<span class="line-removed">868         void emitEnterOptimizationCheck();</span>
<span class="line-removed">869 #else</span>
<span class="line-removed">870         void emitEnterOptimizationCheck() { }</span>
<span class="line-removed">871 #endif</span>
<span class="line-removed">872 </span>
873 #ifndef NDEBUG
874         void printBytecodeOperandTypes(int src1, int src2);
875 #endif
876 
877 #if ENABLE(SAMPLING_FLAGS)
878         void setSamplingFlag(int32_t);
879         void clearSamplingFlag(int32_t);
880 #endif
881 
882 #if ENABLE(SAMPLING_COUNTERS)
883         void emitCount(AbstractSamplingCounter&amp;, int32_t = 1);
884 #endif
885 
886 #if ENABLE(OPCODE_SAMPLING)
887         void sampleInstruction(const Instruction*, bool = false);
888 #endif
889 
890 #if ENABLE(CODEBLOCK_SAMPLING)
891         void sampleCodeBlock(CodeBlock*);
892 #else
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (C) 2008-2019 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
 17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
</pre>
<hr />
<pre>
175         CallLinkInfo* callLinkInfo;
176     };
177 
178     void ctiPatchCallByReturnAddress(ReturnAddressPtr, FunctionPtr&lt;CFunctionPtrTag&gt; newCalleeFunction);
179 
180     class JIT_CLASS_ALIGNMENT JIT : private JSInterfaceJIT {
181         friend class JITSlowPathCall;
182         friend class JITStubCall;
183 
184         using MacroAssembler::Jump;
185         using MacroAssembler::JumpList;
186         using MacroAssembler::Label;
187 
188         static const uintptr_t patchGetByIdDefaultStructure = unusedPointer;
189         static const int patchGetByIdDefaultOffset = 0;
190         // Magic number - initial offset cannot be representable as a signed 8bit value, or the X86Assembler
191         // will compress the displacement, and we may not be able to fit a patched offset.
192         static const int patchPutByIdDefaultOffset = 256;
193 
194     public:
<span class="line-modified">195         JIT(VM&amp;, CodeBlock* = 0, unsigned loopOSREntryBytecodeOffset = 0);</span>
196         ~JIT();
197 
<span class="line-added">198         VM&amp; vm() { return *JSInterfaceJIT::vm(); }</span>
<span class="line-added">199 </span>
200         void compileWithoutLinking(JITCompilationEffort);
201         CompilationResult link();
202 
203         void doMainThreadPreparationBeforeCompile();
204 
<span class="line-modified">205         static CompilationResult compile(VM&amp; vm, CodeBlock* codeBlock, JITCompilationEffort effort, unsigned bytecodeOffset = 0)</span>
206         {
207             return JIT(vm, codeBlock, bytecodeOffset).privateCompile(effort);
208         }
209 
<span class="line-modified">210         static void compileGetByVal(const ConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
211         {
212             JIT jit(vm, codeBlock);
213             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
214             jit.privateCompileGetByVal(locker, byValInfo, returnAddress, arrayMode);
215         }
216 
<span class="line-modified">217         static void compileGetByValWithCachedId(VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, const Identifier&amp; propertyName)</span>
218         {
219             JIT jit(vm, codeBlock);
220             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
221             jit.privateCompileGetByValWithCachedId(byValInfo, returnAddress, propertyName);
222         }
223 
<span class="line-modified">224         static void compilePutByVal(const ConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
225         {
226             JIT jit(vm, codeBlock);
227             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
228             jit.privateCompilePutByVal&lt;OpPutByVal&gt;(locker, byValInfo, returnAddress, arrayMode);
229         }
230 
<span class="line-modified">231         static void compileDirectPutByVal(const ConcurrentJSLocker&amp; locker, VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
232         {
233             JIT jit(vm, codeBlock);
234             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
235             jit.privateCompilePutByVal&lt;OpPutByValDirect&gt;(locker, byValInfo, returnAddress, arrayMode);
236         }
237 
238         template&lt;typename Op&gt;
<span class="line-modified">239         static void compilePutByValWithCachedId(VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, PutKind putKind, const Identifier&amp; propertyName)</span>
240         {
241             JIT jit(vm, codeBlock);
242             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
243             jit.privateCompilePutByValWithCachedId&lt;Op&gt;(byValInfo, returnAddress, putKind, propertyName);
244         }
245 
<span class="line-modified">246         static void compileHasIndexedProperty(VM&amp; vm, CodeBlock* codeBlock, ByValInfo* byValInfo, ReturnAddressPtr returnAddress, JITArrayMode arrayMode)</span>
247         {
248             JIT jit(vm, codeBlock);
249             jit.m_bytecodeOffset = byValInfo-&gt;bytecodeIndex;
250             jit.privateCompileHasIndexedProperty(byValInfo, returnAddress, arrayMode);
251         }
252 
253         static unsigned frameRegisterCountFor(CodeBlock*);
254         static int stackPointerOffsetFor(CodeBlock*);
255 
256         JS_EXPORT_PRIVATE static HashMap&lt;CString, Seconds&gt; compileTimeStats();
257         JS_EXPORT_PRIVATE static Seconds totalCompileTime();
258 
259     private:
260         void privateCompileMainPass();
261         void privateCompileLinkPass();
262         void privateCompileSlowCases();
263         CompilationResult privateCompile(JITCompilationEffort);
264 
265         void privateCompileGetByVal(const ConcurrentJSLocker&amp;, ByValInfo*, ReturnAddressPtr, JITArrayMode);
266         void privateCompileGetByValWithCachedId(ByValInfo*, ReturnAddressPtr, const Identifier&amp;);
</pre>
<hr />
<pre>
280             m_calls.append(CallRecord(functionCall, m_bytecodeOffset, function.retagged&lt;OperationPtrTag&gt;()));
281             return functionCall;
282         }
283 
284 #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
285         Call appendCallWithSlowPathReturnType(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
286         {
287             Call functionCall = callWithSlowPathReturnType(OperationPtrTag);
288             m_calls.append(CallRecord(functionCall, m_bytecodeOffset, function.retagged&lt;OperationPtrTag&gt;()));
289             return functionCall;
290         }
291 #endif
292 
293         void exceptionCheck(Jump jumpToHandler)
294         {
295             m_exceptionChecks.append(jumpToHandler);
296         }
297 
298         void exceptionCheck()
299         {
<span class="line-modified">300             m_exceptionChecks.append(emitExceptionCheck(vm()));</span>
301         }
302 
303         void exceptionCheckWithCallFrameRollback()
304         {
<span class="line-modified">305             m_exceptionChecksWithCallFrameRollback.append(emitExceptionCheck(vm()));</span>
306         }
307 
308         void privateCompileExceptionHandlers();
309 
310         void addSlowCase(Jump);
311         void addSlowCase(const JumpList&amp;);
312         void addSlowCase();
313         void addJump(Jump, int);
314         void addJump(const JumpList&amp;, int);
315         void emitJumpSlowToHot(Jump, int);
316 
317         template&lt;typename Op&gt;
318         void compileOpCall(const Instruction*, unsigned callLinkInfoIndex);
319         template&lt;typename Op&gt;
320         void compileOpCallSlowCase(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, unsigned callLinkInfoIndex);
321         template&lt;typename Op&gt;
322         std::enable_if_t&lt;
323             Op::opcodeID != op_call_varargs &amp;&amp; Op::opcodeID != op_construct_varargs
324             &amp;&amp; Op::opcodeID != op_tail_call_varargs &amp;&amp; Op::opcodeID != op_tail_call_forward_arguments
325         , void&gt; compileSetupFrame(const Op&amp;, CallLinkInfo*);
</pre>
<hr />
<pre>
539         void emit_op_get_by_id_with_this(const Instruction*);
540         void emit_op_get_by_id_direct(const Instruction*);
541         void emit_op_get_by_val(const Instruction*);
542         void emit_op_get_argument_by_val(const Instruction*);
543         void emit_op_in_by_id(const Instruction*);
544         void emit_op_init_lazy_reg(const Instruction*);
545         void emit_op_overrides_has_instance(const Instruction*);
546         void emit_op_instanceof(const Instruction*);
547         void emit_op_instanceof_custom(const Instruction*);
548         void emit_op_is_empty(const Instruction*);
549         void emit_op_is_undefined(const Instruction*);
550         void emit_op_is_undefined_or_null(const Instruction*);
551         void emit_op_is_boolean(const Instruction*);
552         void emit_op_is_number(const Instruction*);
553         void emit_op_is_object(const Instruction*);
554         void emit_op_is_cell_with_type(const Instruction*);
555         void emit_op_jeq_null(const Instruction*);
556         void emit_op_jfalse(const Instruction*);
557         void emit_op_jmp(const Instruction*);
558         void emit_op_jneq_null(const Instruction*);
<span class="line-added">559         void emit_op_jundefined_or_null(const Instruction*);</span>
<span class="line-added">560         void emit_op_jnundefined_or_null(const Instruction*);</span>
561         void emit_op_jneq_ptr(const Instruction*);
562         void emit_op_jless(const Instruction*);
563         void emit_op_jlesseq(const Instruction*);
564         void emit_op_jgreater(const Instruction*);
565         void emit_op_jgreatereq(const Instruction*);
566         void emit_op_jnless(const Instruction*);
567         void emit_op_jnlesseq(const Instruction*);
568         void emit_op_jngreater(const Instruction*);
569         void emit_op_jngreatereq(const Instruction*);
570         void emit_op_jeq(const Instruction*);
571         void emit_op_jneq(const Instruction*);
572         void emit_op_jstricteq(const Instruction*);
573         void emit_op_jnstricteq(const Instruction*);
574         void emit_op_jbelow(const Instruction*);
575         void emit_op_jbeloweq(const Instruction*);
576         void emit_op_jtrue(const Instruction*);
577         void emit_op_loop_hint(const Instruction*);

578         void emit_op_nop(const Instruction*);
579         void emit_op_super_sampler_begin(const Instruction*);
580         void emit_op_super_sampler_end(const Instruction*);
581         void emit_op_lshift(const Instruction*);
582         void emit_op_mod(const Instruction*);
583         void emit_op_mov(const Instruction*);
584         void emit_op_mul(const Instruction*);
585         void emit_op_negate(const Instruction*);
586         void emit_op_neq(const Instruction*);
587         void emit_op_neq_null(const Instruction*);
588         void emit_op_new_array(const Instruction*);
589         void emit_op_new_array_with_size(const Instruction*);
590         void emit_op_new_func(const Instruction*);
591         void emit_op_new_func_exp(const Instruction*);
592         void emit_op_new_generator_func(const Instruction*);
593         void emit_op_new_generator_func_exp(const Instruction*);
594         void emit_op_new_async_func(const Instruction*);
595         void emit_op_new_async_func_exp(const Instruction*);
596         void emit_op_new_async_generator_func(const Instruction*);
597         void emit_op_new_async_generator_func_exp(const Instruction*);
</pre>
<hr />
<pre>
655         void emitSlow_op_get_by_id_direct(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
656         void emitSlow_op_get_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
657         void emitSlow_op_get_argument_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
658         void emitSlow_op_in_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
659         void emitSlow_op_instanceof(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
660         void emitSlow_op_instanceof_custom(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
661         void emitSlow_op_jless(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
662         void emitSlow_op_jlesseq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
663         void emitSlow_op_jgreater(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
664         void emitSlow_op_jgreatereq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
665         void emitSlow_op_jnless(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
666         void emitSlow_op_jnlesseq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
667         void emitSlow_op_jngreater(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
668         void emitSlow_op_jngreatereq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
669         void emitSlow_op_jeq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
670         void emitSlow_op_jneq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
671         void emitSlow_op_jstricteq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
672         void emitSlow_op_jnstricteq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
673         void emitSlow_op_jtrue(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
674         void emitSlow_op_loop_hint(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
<span class="line-modified">675         void emitSlow_op_enter(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);</span>
676         void emitSlow_op_mod(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
677         void emitSlow_op_mul(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
678         void emitSlow_op_negate(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
679         void emitSlow_op_neq(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
680         void emitSlow_op_new_object(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
681         void emitSlow_op_put_by_id(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
682         void emitSlow_op_put_by_val(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
683         void emitSlow_op_sub(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
684         void emitSlow_op_has_indexed_property(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
685 
686         void emit_op_resolve_scope(const Instruction*);
687         void emit_op_get_from_scope(const Instruction*);
688         void emit_op_put_to_scope(const Instruction*);
689         void emit_op_get_from_arguments(const Instruction*);
690         void emit_op_put_to_arguments(const Instruction*);
691         void emitSlow_op_get_from_scope(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
692         void emitSlow_op_put_to_scope(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;);
693 
694         void emitSlowCaseCall(const Instruction*, Vector&lt;SlowCaseEntry&gt;::iterator&amp;, SlowPathFunction);
695 
</pre>
<hr />
<pre>
850         };
851 
852         template&lt;typename Op, typename SnippetGenerator&gt;
853         void emitBitBinaryOpFastPath(const Instruction* currentInstruction, ProfilingPolicy shouldEmitProfiling = ProfilingPolicy::NoProfiling);
854 
855         void emitRightShiftFastPath(const Instruction* currentInstruction, OpcodeID);
856 
857         template&lt;typename Op&gt;
858         void emitRightShiftFastPath(const Instruction* currentInstruction, JITRightShiftGenerator::ShiftType);
859 
860         void updateTopCallFrame();
861 
862         Call emitNakedCall(CodePtr&lt;NoPtrTag&gt; function = CodePtr&lt;NoPtrTag&gt;());
863         Call emitNakedTailCall(CodePtr&lt;NoPtrTag&gt; function = CodePtr&lt;NoPtrTag&gt;());
864 
865         // Loads the character value of a single character string into dst.
866         void emitLoadCharacterString(RegisterID src, RegisterID dst, JumpList&amp; failures);
867 
868         int jumpTarget(const Instruction*, int target);
869 






870 #ifndef NDEBUG
871         void printBytecodeOperandTypes(int src1, int src2);
872 #endif
873 
874 #if ENABLE(SAMPLING_FLAGS)
875         void setSamplingFlag(int32_t);
876         void clearSamplingFlag(int32_t);
877 #endif
878 
879 #if ENABLE(SAMPLING_COUNTERS)
880         void emitCount(AbstractSamplingCounter&amp;, int32_t = 1);
881 #endif
882 
883 #if ENABLE(OPCODE_SAMPLING)
884         void sampleInstruction(const Instruction*, bool = false);
885 #endif
886 
887 #if ENABLE(CODEBLOCK_SAMPLING)
888         void sampleCodeBlock(CodeBlock*);
889 #else
</pre>
</td>
</tr>
</table>
<center><a href="JIT.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JITArithmetic.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>