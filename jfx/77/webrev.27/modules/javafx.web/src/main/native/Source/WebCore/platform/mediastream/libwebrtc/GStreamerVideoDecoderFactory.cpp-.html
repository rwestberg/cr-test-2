<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoDecoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (C) 2018 Metrological Group B.V.
  3  * Copyright (C) 2018 Igalia S.L. All rights reserved.
  4  *
  5  * This library is free software; you can redistribute it and/or
  6  * modify it under the terms of the GNU Library General Public
  7  * License as published by the Free Software Foundation; either
  8  * version 2 of the License, or (at your option) any later version.
  9  *
 10  * This library is distributed in the hope that it will be useful,
 11  * but WITHOUT ANY WARRANTY; without even the implied warranty of
 12  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 13  * Library General Public License for more details.
 14  *
 15  * You should have received a copy of the GNU Library General Public License
 16  * aint with this library; see the file COPYING.LIB.  If not, write to
 17  * the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
 18  * Boston, MA 02110-1301, USA.
 19  */
 20 
 21 #include &quot;config.h&quot;
 22 
 23 #if ENABLE(VIDEO) &amp;&amp; ENABLE(MEDIA_STREAM) &amp;&amp; USE(LIBWEBRTC) &amp;&amp; USE(GSTREAMER)
 24 #include &quot;GStreamerVideoDecoderFactory.h&quot;
 25 
 26 #include &quot;GStreamerVideoFrameLibWebRTC.h&quot;
 27 #include &quot;webrtc/common_video/h264/h264_common.h&quot;
 28 #include &quot;webrtc/common_video/h264/profile_level_id.h&quot;
 29 #include &quot;webrtc/media/base/codec.h&quot;
 30 #include &quot;webrtc/modules/video_coding/codecs/h264/include/h264.h&quot;
 31 #include &quot;webrtc/modules/video_coding/codecs/vp8/include/vp8.h&quot;
 32 #include &quot;webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_decoder.h&quot;
 33 #include &quot;webrtc/modules/video_coding/include/video_codec_interface.h&quot;
 34 #include &lt;gst/app/gstappsink.h&gt;
 35 #include &lt;gst/app/gstappsrc.h&gt;
 36 #include &lt;gst/video/video.h&gt;
 37 #include &lt;mutex&gt;
 38 #include &lt;wtf/Lock.h&gt;
 39 #include &lt;wtf/StdMap.h&gt;
 40 #include &lt;wtf/glib/RunLoopSourcePriority.h&gt;
 41 #include &lt;wtf/text/WTFString.h&gt;
 42 
 43 GST_DEBUG_CATEGORY(webkit_webrtcdec_debug);
 44 #define GST_CAT_DEFAULT webkit_webrtcdec_debug
 45 
 46 namespace WebCore {
 47 
 48 typedef struct {
 49     uint64_t timestamp;
 50     int64_t renderTimeMs;
 51 } InputTimestamps;
 52 
 53 class GStreamerVideoDecoder : public webrtc::VideoDecoder {
 54 public:
 55     GStreamerVideoDecoder()
 56         : m_pictureId(0)
 57         , m_firstBufferPts(GST_CLOCK_TIME_NONE)
 58         , m_firstBufferDts(GST_CLOCK_TIME_NONE)
 59     {
 60     }
 61 
 62     static void decodebinPadAddedCb(GstElement*,
 63         GstPad* srcpad,
 64         GstPad* sinkpad)
 65     {
 66         GST_INFO_OBJECT(srcpad, &quot;connecting pad with %&quot; GST_PTR_FORMAT, sinkpad);
 67         if (gst_pad_link(srcpad, sinkpad) != GST_PAD_LINK_OK)
 68             ASSERT_NOT_REACHED();
 69     }
 70 
 71     GstElement* pipeline()
 72     {
 73         return m_pipeline.get();
 74     }
 75 
 76     GstElement* makeElement(const gchar* factoryName)
 77     {
 78         GUniquePtr&lt;char&gt; name(g_strdup_printf(&quot;%s_dec_%s_%p&quot;, Name(), factoryName, this));
 79 
 80         return gst_element_factory_make(factoryName, name.get());
 81     }
 82 
 83     int32_t InitDecode(const webrtc::VideoCodec*, int32_t) override
 84     {
 85         m_src = makeElement(&quot;appsrc&quot;);
 86 
 87         auto capsfilter = CreateFilter();
 88         auto decoder = makeElement(&quot;decodebin&quot;);
 89 
 90         // Make the decoder output &quot;parsed&quot; frames only and let the main decodebin
 91         // do the real decoding. This allows us to have optimized decoding/rendering
 92         // happening in the main pipeline.
 93         g_object_set(decoder, &quot;caps&quot;, adoptGRef(gst_caps_from_string(Caps())).get(), nullptr);
 94         auto sinkpad = gst_element_get_static_pad(capsfilter, &quot;sink&quot;);
 95         g_signal_connect(decoder, &quot;pad-added&quot;, G_CALLBACK(decodebinPadAddedCb), sinkpad);
 96 
 97         m_pipeline = makeElement(&quot;pipeline&quot;);
 98         connectSimpleBusMessageCallback(m_pipeline.get());
 99 
100         auto sink = makeElement(&quot;appsink&quot;);
101         gst_app_sink_set_emit_signals(GST_APP_SINK(sink), true);
102         g_signal_connect(sink, &quot;new-sample&quot;, G_CALLBACK(newSampleCallbackTramp), this);
103         // This is an encoder, everything should happen as fast as possible and not
104         // be synced on the clock.
105         g_object_set(sink, &quot;sync&quot;, false, nullptr);
106 
107         gst_bin_add_many(GST_BIN(pipeline()), m_src, decoder, capsfilter, sink, nullptr);
108         if (!gst_element_link(m_src, decoder)) {
109             GST_ERROR_OBJECT(pipeline(), &quot;Could not link src to decoder.&quot;);
110             return WEBRTC_VIDEO_CODEC_ERROR;
111         }
112 
113         if (!gst_element_link(capsfilter, sink)) {
114             GST_ERROR_OBJECT(pipeline(), &quot;Could not link capsfilter to sink.&quot;);
115             return WEBRTC_VIDEO_CODEC_ERROR;
116         }
117 
118         if (gst_element_set_state(pipeline(), GST_STATE_PLAYING) == GST_STATE_CHANGE_FAILURE) {
119             GST_ERROR_OBJECT(pipeline(), &quot;Could not set state to PLAYING.&quot;);
120             return WEBRTC_VIDEO_CODEC_ERROR;
121         }
122 
123         return WEBRTC_VIDEO_CODEC_OK;
124     }
125 
126     int32_t RegisterDecodeCompleteCallback(webrtc::DecodedImageCallback* callback)
127     {
128         m_imageReadyCb = callback;
129 
130         return WEBRTC_VIDEO_CODEC_OK;
131     }
132 
133     virtual GstElement* CreateFilter()
134     {
135         return makeElement(&quot;identity&quot;);
136     }
137 
138     int32_t Release() final
139     {
140         if (m_pipeline.get()) {
141             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
142             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
143 
144             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
145             m_src = nullptr;
146             m_pipeline = nullptr;
147         }
148 
149         return WEBRTC_VIDEO_CODEC_OK;
150     }
151 
152     int32_t Decode(const webrtc::EncodedImage&amp; inputImage,
153         bool,
154         const webrtc::CodecSpecificInfo*,
155         int64_t renderTimeMs) override
156     {
157         if (!m_src) {
158             GST_ERROR(&quot;No source set, can&#39;t decode.&quot;);
159 
160             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
161         }
162 
163         if (!GST_CLOCK_TIME_IS_VALID(m_firstBufferPts)) {
164             GRefPtr&lt;GstPad&gt; srcpad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
165             m_firstBufferPts = (static_cast&lt;guint64&gt;(renderTimeMs)) * GST_MSECOND;
166             m_firstBufferDts = (static_cast&lt;guint64&gt;(inputImage.Timestamp())) * GST_MSECOND;
167         }
168 
169         // FIXME- Use a GstBufferPool.
170         auto buffer = adoptGRef(gst_buffer_new_wrapped(g_memdup(inputImage._buffer, inputImage._size),
171             inputImage._size));
172         GST_BUFFER_DTS(buffer.get()) = (static_cast&lt;guint64&gt;(inputImage.Timestamp()) * GST_MSECOND) - m_firstBufferDts;
173         GST_BUFFER_PTS(buffer.get()) = (static_cast&lt;guint64&gt;(renderTimeMs) * GST_MSECOND) - m_firstBufferPts;
174         {
175             auto locker = holdLock(m_bufferMapLock);
176             InputTimestamps timestamps = {inputImage.Timestamp(), renderTimeMs};
177             m_dtsPtsMap[GST_BUFFER_PTS(buffer.get())] = timestamps;
178         }
179 
180         GST_LOG_OBJECT(pipeline(), &quot;%ld Decoding: %&quot; GST_PTR_FORMAT, renderTimeMs, buffer.get());
181         auto sample = adoptGRef(gst_sample_new(buffer.get(), GetCapsForFrame(inputImage), nullptr, nullptr));
182         switch (gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get())) {
183         case GST_FLOW_OK:
184             return WEBRTC_VIDEO_CODEC_OK;
185         case GST_FLOW_FLUSHING:
186             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
187         default:
188             return WEBRTC_VIDEO_CODEC_ERROR;
189         }
190     }
191 
192     virtual GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image)
193     {
194         if (!m_caps) {
195             m_caps = adoptGRef(gst_caps_new_simple(Caps(),
196                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth,
197                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight,
198                 nullptr));
199         }
200 
201         return m_caps.get();
202     }
203 
204     void AddDecoderIfSupported(std::vector&lt;webrtc::SdpVideoFormat&gt; codecList)
205     {
206         if (HasGstDecoder()) {
207             webrtc::SdpVideoFormat format = ConfigureSupportedDecoder();
208 
209             codecList.push_back(format);
210         }
211     }
212 
213     virtual webrtc::SdpVideoFormat ConfigureSupportedDecoder()
214     {
215         return webrtc::SdpVideoFormat(Name());
216     }
217 
218     static GRefPtr&lt;GstElementFactory&gt; GstDecoderFactory(const char *capsStr)
219     {
220         auto all_decoders = gst_element_factory_list_get_elements(GST_ELEMENT_FACTORY_TYPE_DECODER,
221             GST_RANK_MARGINAL);
222         auto caps = adoptGRef(gst_caps_from_string(capsStr));
223         auto decoders = gst_element_factory_list_filter(all_decoders,
224             caps.get(), GST_PAD_SINK, FALSE);
225 
226         gst_plugin_feature_list_free(all_decoders);
227         GRefPtr&lt;GstElementFactory&gt; res;
228         if (decoders)
229             res = GST_ELEMENT_FACTORY(decoders-&gt;data);
230         gst_plugin_feature_list_free(decoders);
231 
232         return res;
233     }
234 
235     bool HasGstDecoder()
236     {
237         return GstDecoderFactory(Caps());
238     }
239 
240     GstFlowReturn newSampleCallback(GstElement* sink)
241     {
242         auto sample = gst_app_sink_pull_sample(GST_APP_SINK(sink));
243         auto buffer = gst_sample_get_buffer(sample);
244 
245         m_bufferMapLock.lock();
246         // Make sure that the frame.timestamp == previsouly input_frame._timeStamp
247         // as it is required by the VideoDecoder baseclass.
248         auto timestamps = m_dtsPtsMap[GST_BUFFER_PTS(buffer)];
249         m_dtsPtsMap.erase(GST_BUFFER_PTS(buffer));
250         m_bufferMapLock.unlock();
251 
252         auto frame(LibWebRTCVideoFrameFromGStreamerSample(sample, webrtc::kVideoRotation_0,
253             timestamps.timestamp, timestamps.renderTimeMs));
254 
255         GST_BUFFER_DTS(buffer) = GST_CLOCK_TIME_NONE;
256         GST_LOG_OBJECT(pipeline(), &quot;Output decoded frame! %d -&gt; %&quot; GST_PTR_FORMAT,
257             frame-&gt;timestamp(), buffer);
258 
259         m_imageReadyCb-&gt;Decoded(*frame.get(), absl::optional&lt;int32_t&gt;(), absl::optional&lt;uint8_t&gt;());
260 
261         return GST_FLOW_OK;
262     }
263 
264     virtual const gchar* Caps() = 0;
265     virtual webrtc::VideoCodecType CodecType() = 0;
266     const char* ImplementationName() const { return &quot;GStreamer&quot;; }
267     virtual const gchar* Name() = 0;
268 
269 protected:
270     GRefPtr&lt;GstCaps&gt; m_caps;
271     gint m_pictureId;
272 
273 private:
274     static GstFlowReturn newSampleCallbackTramp(GstElement* sink, GStreamerVideoDecoder* enc)
275     {
276         return enc-&gt;newSampleCallback(sink);
277     }
278 
279     GRefPtr&lt;GstElement&gt; m_pipeline;
280     GstElement* m_src;
281 
282     GstVideoInfo m_info;
283     webrtc::DecodedImageCallback* m_imageReadyCb;
284 
285     Lock m_bufferMapLock;
286     StdMap&lt;GstClockTime, InputTimestamps&gt; m_dtsPtsMap;
287     GstClockTime m_firstBufferPts;
288     GstClockTime m_firstBufferDts;
289 };
290 
291 class H264Decoder : public GStreamerVideoDecoder {
292 public:
293     H264Decoder() { }
294 
295     int32_t InitDecode(const webrtc::VideoCodec* codecInfo, int32_t nCores) final
296     {
297         if (codecInfo &amp;&amp; codecInfo-&gt;codecType != webrtc::kVideoCodecH264)
298             return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
299 
300         m_profile = nullptr;
301         if (codecInfo) {
302             auto h264Info = codecInfo-&gt;H264();
303 
304             switch (h264Info.profile) {
305             case webrtc::H264::kProfileConstrainedBaseline:
306                 m_profile = &quot;constrained-baseline&quot;;
307                 break;
308             case webrtc::H264::kProfileBaseline:
309                 m_profile = &quot;baseline&quot;;
310                 break;
311             case webrtc::H264::kProfileMain:
312                 m_profile = &quot;main&quot;;
313                 break;
314             case webrtc::H264::kProfileConstrainedHigh:
315                 m_profile = &quot;constrained-high&quot;;
316                 break;
317             case webrtc::H264::kProfileHigh:
318                 m_profile = &quot;high&quot;;
319                 break;
320             }
321         }
322 
323         return GStreamerVideoDecoder::InitDecode(codecInfo, nCores);
324     }
325 
326     GstCaps* GetCapsForFrame(const webrtc::EncodedImage&amp; image) final
327     {
328         if (!m_caps) {
329             m_caps = adoptGRef(gst_caps_new_simple(Caps(),
330                 &quot;width&quot;, G_TYPE_INT, image._encodedWidth,
331                 &quot;height&quot;, G_TYPE_INT, image._encodedHeight,
332                 &quot;profile&quot;, G_TYPE_STRING, m_profile ? m_profile : &quot;baseline&quot;,
333                 &quot;stream-format&quot;, G_TYPE_STRING, &quot;byte-stream&quot;,
334                 &quot;alignment&quot;, G_TYPE_STRING, &quot;au&quot;,
335                 nullptr));
336         }
337 
338         return m_caps.get();
339     }
340     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
341     const gchar* Name() final { return cricket::kH264CodecName; }
342     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
343 
344 private:
345     const gchar* m_profile;
346 };
347 
348 class VP8Decoder : public GStreamerVideoDecoder {
349 public:
350     VP8Decoder() { }
351     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
352     const gchar* Name() final { return cricket::kVp8CodecName; }
353     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
354     static std::unique_ptr&lt;webrtc::VideoDecoder&gt; Create()
355     {
356         auto factory = GstDecoderFactory(&quot;video/x-vp8&quot;);
357 
358         if (factory &amp;&amp; !g_strcmp0(GST_OBJECT_NAME(GST_OBJECT(factory.get())), &quot;vp8dec&quot;)) {
359             GST_INFO(&quot;Our best GStreamer VP8 decoder is vp8dec, better use the one from LibWebRTC&quot;);
360 
361             return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(new webrtc::LibvpxVp8Decoder());
362         }
363 
364         return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(new VP8Decoder());
365     }
366 };
367 
368 std::unique_ptr&lt;webrtc::VideoDecoder&gt; GStreamerVideoDecoderFactory::CreateVideoDecoder(const webrtc::SdpVideoFormat&amp; format)
369 {
370     webrtc::VideoDecoder* dec;
371 
372     if (format.name == cricket::kH264CodecName)
373         dec = new H264Decoder();
374     else if (format.name == cricket::kVp8CodecName)
375         return VP8Decoder::Create();
376     else {
377         GST_ERROR(&quot;Could not create decoder for %s&quot;, format.name.c_str());
378 
379         return nullptr;
380     }
381 
382     return std::unique_ptr&lt;webrtc::VideoDecoder&gt;(dec);
383 }
384 
385 GStreamerVideoDecoderFactory::GStreamerVideoDecoderFactory()
386 {
387     static std::once_flag debugRegisteredFlag;
388 
389     std::call_once(debugRegisteredFlag, [] {
390         GST_DEBUG_CATEGORY_INIT(webkit_webrtcdec_debug, &quot;webkitlibwebrtcvideodecoder&quot;, 0, &quot;WebKit WebRTC video decoder&quot;);
391     });
392 }
393 std::vector&lt;webrtc::SdpVideoFormat&gt; GStreamerVideoDecoderFactory::GetSupportedFormats() const
394 {
395     std::vector&lt;webrtc::SdpVideoFormat&gt; formats;
396 
397     VP8Decoder().AddDecoderIfSupported(formats);
398     H264Decoder().AddDecoderIfSupported(formats);
399 
400     return formats;
401 }
402 }
403 #endif
    </pre>
  </body>
</html>