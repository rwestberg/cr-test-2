<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/AudioContext.h</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2010 Google Inc. All rights reserved.
<a name="1" id="anc1"></a><span class="line-modified">  3  * Copyright (C) 2016-2019 Apple Inc. All rights reserved.</span>
  4  *
  5  * Redistribution and use in source and binary forms, with or without
  6  * modification, are permitted provided that the following conditions
  7  * are met:
  8  * 1.  Redistributions of source code must retain the above copyright
  9  *    notice, this list of conditions and the following disclaimer.
 10  * 2.  Redistributions in binary form must reproduce the above copyright
 11  *    notice, this list of conditions and the following disclaimer in the
 12  *    documentation and/or other materials provided with the distribution.
 13  *
 14  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 15  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 16  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 17  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 18  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 19  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 20  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 21  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 23  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;ActiveDOMObject.h&quot;
 29 #include &quot;AsyncAudioDecoder.h&quot;
 30 #include &quot;AudioBus.h&quot;
 31 #include &quot;AudioDestinationNode.h&quot;
 32 #include &quot;EventTarget.h&quot;
 33 #include &quot;JSDOMPromiseDeferred.h&quot;
 34 #include &quot;MediaCanStartListener.h&quot;
 35 #include &quot;MediaProducer.h&quot;
 36 #include &quot;PlatformMediaSession.h&quot;
<a name="2" id="anc2"></a><span class="line-added"> 37 #include &quot;ScriptExecutionContext.h&quot;</span>
 38 #include &quot;VisibilityChangeClient.h&quot;
<a name="3" id="anc3"></a><span class="line-added"> 39 #include &lt;JavaScriptCore/ConsoleTypes.h&gt;</span>
 40 #include &lt;JavaScriptCore/Float32Array.h&gt;
 41 #include &lt;atomic&gt;
 42 #include &lt;wtf/HashSet.h&gt;
<a name="4" id="anc4"></a><span class="line-added"> 43 #include &lt;wtf/LoggerHelper.h&gt;</span>
 44 #include &lt;wtf/MainThread.h&gt;
 45 #include &lt;wtf/RefPtr.h&gt;
 46 #include &lt;wtf/ThreadSafeRefCounted.h&gt;
 47 #include &lt;wtf/Threading.h&gt;
 48 #include &lt;wtf/Vector.h&gt;
<a name="5" id="anc5"></a><span class="line-modified"> 49 #include &lt;wtf/text/AtomStringHash.h&gt;</span>
 50 
 51 namespace WebCore {
 52 
 53 class AnalyserNode;
 54 class AudioBuffer;
 55 class AudioBufferCallback;
 56 class AudioBufferSourceNode;
 57 class AudioListener;
 58 class AudioSummingJunction;
 59 class BiquadFilterNode;
 60 class ChannelMergerNode;
 61 class ChannelSplitterNode;
 62 class ConvolverNode;
 63 class DelayNode;
 64 class Document;
 65 class DynamicsCompressorNode;
 66 class GainNode;
 67 class GenericEventQueue;
 68 class HTMLMediaElement;
 69 class MediaElementAudioSourceNode;
 70 class MediaStream;
 71 class MediaStreamAudioDestinationNode;
 72 class MediaStreamAudioSourceNode;
 73 class OscillatorNode;
 74 class PannerNode;
 75 class PeriodicWave;
 76 class ScriptProcessorNode;
<a name="6" id="anc6"></a><span class="line-added"> 77 class SecurityOrigin;</span>
 78 class WaveShaperNode;
 79 
 80 // AudioContext is the cornerstone of the web audio API and all AudioNodes are created from it.
 81 // For thread safety between the audio thread and the main thread, it has a rendering graph locking mechanism.
 82 
<a name="7" id="anc7"></a><span class="line-modified"> 83 class AudioContext</span>
<span class="line-added"> 84     : public ActiveDOMObject</span>
<span class="line-added"> 85     , public ThreadSafeRefCounted&lt;AudioContext&gt;</span>
<span class="line-added"> 86     , public EventTargetWithInlineData</span>
<span class="line-added"> 87     , public MediaCanStartListener</span>
<span class="line-added"> 88     , public MediaProducer</span>
<span class="line-added"> 89     , private PlatformMediaSessionClient</span>
<span class="line-added"> 90     , private VisibilityChangeClient</span>
<span class="line-added"> 91 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added"> 92     , private LoggerHelper</span>
<span class="line-added"> 93 #endif</span>
<span class="line-added"> 94 {</span>
<span class="line-added"> 95     WTF_MAKE_ISO_ALLOCATED(AudioContext);</span>
 96 public:
 97     // Create an AudioContext for rendering to the audio hardware.
 98     static RefPtr&lt;AudioContext&gt; create(Document&amp;);
 99 
100     virtual ~AudioContext();
101 
102     bool isInitialized() const;
103 
104     bool isOfflineContext() const { return m_isOfflineContext; }
105 
106     Document* document() const; // ASSERTs if document no longer exists.
107 
108     Document* hostingDocument() const final;
109 
110     AudioDestinationNode* destination() { return m_destinationNode.get(); }
<a name="8" id="anc8"></a><span class="line-modified">111     size_t currentSampleFrame() const { return m_destinationNode ? m_destinationNode-&gt;currentSampleFrame() : 0; }</span>
<span class="line-modified">112     double currentTime() const { return m_destinationNode ? m_destinationNode-&gt;currentTime() : 0.; }</span>
<span class="line-modified">113     float sampleRate() const { return m_destinationNode ? m_destinationNode-&gt;sampleRate() : 0.f; }</span>
114     unsigned long activeSourceCount() const { return static_cast&lt;unsigned long&gt;(m_activeSourceCount); }
115 
116     void incrementActiveSourceCount();
117     void decrementActiveSourceCount();
118 
119     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
120     ExceptionOr&lt;Ref&lt;AudioBuffer&gt;&gt; createBuffer(ArrayBuffer&amp;, bool mixToMono);
121 
122     // Asynchronous audio file data decoding.
123     void decodeAudioData(Ref&lt;ArrayBuffer&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;, RefPtr&lt;AudioBufferCallback&gt;&amp;&amp;);
124 
125     AudioListener* listener() { return m_listener.get(); }
126 
127     using ActiveDOMObject::suspend;
128     using ActiveDOMObject::resume;
129 
130     void suspend(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
131     void resume(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
132     void close(DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
133 
134     enum class State { Suspended, Running, Interrupted, Closed };
135     State state() const;
<a name="9" id="anc9"></a><span class="line-added">136     bool isClosed() const { return m_state == State::Closed; }</span>
137 
138     bool wouldTaintOrigin(const URL&amp;) const;
139 
140     // The AudioNode create methods are called on the main thread (from JavaScript).
<a name="10" id="anc10"></a><span class="line-modified">141     ExceptionOr&lt;Ref&lt;AudioBufferSourceNode&gt;&gt; createBufferSource();</span>
142 #if ENABLE(VIDEO)
143     ExceptionOr&lt;Ref&lt;MediaElementAudioSourceNode&gt;&gt; createMediaElementSource(HTMLMediaElement&amp;);
144 #endif
145 #if ENABLE(MEDIA_STREAM)
146     ExceptionOr&lt;Ref&lt;MediaStreamAudioSourceNode&gt;&gt; createMediaStreamSource(MediaStream&amp;);
<a name="11" id="anc11"></a><span class="line-modified">147     ExceptionOr&lt;Ref&lt;MediaStreamAudioDestinationNode&gt;&gt; createMediaStreamDestination();</span>
148 #endif
<a name="12" id="anc12"></a><span class="line-modified">149     ExceptionOr&lt;Ref&lt;GainNode&gt;&gt; createGain();</span>
<span class="line-modified">150     ExceptionOr&lt;Ref&lt;BiquadFilterNode&gt;&gt; createBiquadFilter();</span>
<span class="line-modified">151     ExceptionOr&lt;Ref&lt;WaveShaperNode&gt;&gt; createWaveShaper();</span>
152     ExceptionOr&lt;Ref&lt;DelayNode&gt;&gt; createDelay(double maxDelayTime);
<a name="13" id="anc13"></a><span class="line-modified">153     ExceptionOr&lt;Ref&lt;PannerNode&gt;&gt; createPanner();</span>
<span class="line-modified">154     ExceptionOr&lt;Ref&lt;ConvolverNode&gt;&gt; createConvolver();</span>
<span class="line-modified">155     ExceptionOr&lt;Ref&lt;DynamicsCompressorNode&gt;&gt; createDynamicsCompressor();</span>
<span class="line-modified">156     ExceptionOr&lt;Ref&lt;AnalyserNode&gt;&gt; createAnalyser();</span>
157     ExceptionOr&lt;Ref&lt;ScriptProcessorNode&gt;&gt; createScriptProcessor(size_t bufferSize, size_t numberOfInputChannels, size_t numberOfOutputChannels);
158     ExceptionOr&lt;Ref&lt;ChannelSplitterNode&gt;&gt; createChannelSplitter(size_t numberOfOutputs);
159     ExceptionOr&lt;Ref&lt;ChannelMergerNode&gt;&gt; createChannelMerger(size_t numberOfInputs);
<a name="14" id="anc14"></a><span class="line-modified">160     ExceptionOr&lt;Ref&lt;OscillatorNode&gt;&gt; createOscillator();</span>
161     ExceptionOr&lt;Ref&lt;PeriodicWave&gt;&gt; createPeriodicWave(Float32Array&amp; real, Float32Array&amp; imaginary);
162 
163     // When a source node has no more processing to do (has finished playing), then it tells the context to dereference it.
164     void notifyNodeFinishedProcessing(AudioNode*);
165 
166     // Called at the start of each render quantum.
167     void handlePreRenderTasks();
168 
169     // Called at the end of each render quantum.
170     void handlePostRenderTasks();
171 
172     // Called periodically at the end of each render quantum to dereference finished source nodes.
173     void derefFinishedSourceNodes();
174 
175     // We schedule deletion of all marked nodes at the end of each realtime render quantum.
176     void markForDeletion(AudioNode&amp;);
177     void deleteMarkedNodes();
178 
179     // AudioContext can pull node(s) at the end of each render quantum even when they are not connected to any downstream nodes.
180     // These two methods are called by the nodes who want to add/remove themselves into/from the automatic pull lists.
181     void addAutomaticPullNode(AudioNode&amp;);
182     void removeAutomaticPullNode(AudioNode&amp;);
183 
184     // Called right before handlePostRenderTasks() to handle nodes which need to be pulled even when they are not connected to anything.
185     void processAutomaticPullNodes(size_t framesToProcess);
186 
187     // Keeps track of the number of connections made.
188     void incrementConnectionCount()
189     {
190         ASSERT(isMainThread());
191         m_connectionCount++;
192     }
193 
194     unsigned connectionCount() const { return m_connectionCount; }
195 
196     //
197     // Thread Safety and Graph Locking:
198     //
199 
200     void setAudioThread(Thread&amp; thread) { m_audioThread = &amp;thread; } // FIXME: check either not initialized or the same
201     Thread* audioThread() const { return m_audioThread; }
202     bool isAudioThread() const;
203 
204     // Returns true only after the audio thread has been started and then shutdown.
205     bool isAudioThreadFinished() { return m_isAudioThreadFinished; }
206 
207     // mustReleaseLock is set to true if we acquired the lock in this method call and caller must unlock(), false if it was previously acquired.
208     void lock(bool&amp; mustReleaseLock);
209 
210     // Returns true if we own the lock.
211     // mustReleaseLock is set to true if we acquired the lock in this method call and caller must unlock(), false if it was previously acquired.
212     bool tryLock(bool&amp; mustReleaseLock);
213 
214     void unlock();
215 
216     // Returns true if this thread owns the context&#39;s lock.
217     bool isGraphOwner() const;
218 
219     // Returns the maximum number of channels we can support.
220     static unsigned maxNumberOfChannels() { return MaxNumberOfChannels; }
221 
222     class AutoLocker {
223     public:
224         explicit AutoLocker(AudioContext&amp; context)
225             : m_context(context)
226         {
227             m_context.lock(m_mustReleaseLock);
228         }
229 
230         ~AutoLocker()
231         {
232             if (m_mustReleaseLock)
233                 m_context.unlock();
234         }
235 
236     private:
237         AudioContext&amp; m_context;
238         bool m_mustReleaseLock;
239     };
240 
241     // In AudioNode::deref() a tryLock() is used for calling finishDeref(), but if it fails keep track here.
242     void addDeferredFinishDeref(AudioNode*);
243 
244     // In the audio thread at the start of each render cycle, we&#39;ll call handleDeferredFinishDerefs().
245     void handleDeferredFinishDerefs();
246 
247     // Only accessed when the graph lock is held.
248     void markSummingJunctionDirty(AudioSummingJunction*);
249     void markAudioNodeOutputDirty(AudioNodeOutput*);
250 
251     // Must be called on main thread.
252     void removeMarkedSummingJunction(AudioSummingJunction*);
253 
254     // EventTarget
255     EventTargetInterface eventTargetInterface() const final { return AudioContextEventTargetInterfaceType; }
<a name="15" id="anc15"></a>
256 
257     // Reconcile ref/deref which are defined both in ThreadSafeRefCounted and EventTarget.
258     using ThreadSafeRefCounted::ref;
259     using ThreadSafeRefCounted::deref;
260 
261     void startRendering();
<a name="16" id="anc16"></a><span class="line-modified">262     void finishedRendering(bool didRendering);</span>
263 
264     static unsigned s_hardwareContextCount;
265 
266     // Restrictions to change default behaviors.
267     enum BehaviorRestrictionFlags {
268         NoRestrictions = 0,
269         RequireUserGestureForAudioStartRestriction = 1 &lt;&lt; 0,
270         RequirePageConsentForAudioStartRestriction = 1 &lt;&lt; 1,
271     };
272     typedef unsigned BehaviorRestrictions;
273 
274     BehaviorRestrictions behaviorRestrictions() const { return m_restrictions; }
275     void addBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions |= restriction; }
276     void removeBehaviorRestriction(BehaviorRestrictions restriction) { m_restrictions &amp;= ~restriction; }
277 
278     void isPlayingAudioDidChange();
279 
280     void nodeWillBeginPlayback();
281 
<a name="17" id="anc17"></a><span class="line-added">282 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">283     const Logger&amp; logger() const final { return m_logger.get(); }</span>
<span class="line-added">284     const void* logIdentifier() const final { return m_logIdentifier; }</span>
<span class="line-added">285     WTFLogChannel&amp; logChannel() const final;</span>
<span class="line-added">286     const void* nextAudioNodeLogIdentifier() { return childLogIdentifier(++m_nextAudioNodeIdentifier); }</span>
<span class="line-added">287     const void* nextAudioParameterLogIdentifier() { return childLogIdentifier(++m_nextAudioParameterIdentifier); }</span>
<span class="line-added">288 #endif</span>
<span class="line-added">289 </span>
<span class="line-added">290     void postTask(WTF::Function&lt;void()&gt;&amp;&amp;);</span>
<span class="line-added">291     bool isStopped() const { return m_isStopScheduled; }</span>
<span class="line-added">292     const SecurityOrigin* origin() const;</span>
<span class="line-added">293     void addConsoleMessage(MessageSource, MessageLevel, const String&amp; message);</span>
<span class="line-added">294 </span>
295 protected:
296     explicit AudioContext(Document&amp;);
297     AudioContext(Document&amp;, unsigned numberOfChannels, size_t numberOfFrames, float sampleRate);
298 
299     static bool isSampleRateRangeGood(float sampleRate);
<a name="18" id="anc18"></a><span class="line-added">300     void clearPendingActivity();</span>
<span class="line-added">301     void makePendingActivity();</span>
302 
303 private:
304     void constructCommon();
305 
306     void lazyInitialize();
307     void uninitialize();
308 
309     bool willBeginPlayback();
310     bool willPausePlayback();
311 
312     bool userGestureRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequireUserGestureForAudioStartRestriction; }
313     bool pageConsentRequiredForAudioStart() const { return !isOfflineContext() &amp;&amp; m_restrictions &amp; RequirePageConsentForAudioStartRestriction; }
314 
315     void setState(State);
316 
317     void clear();
318 
319     void scheduleNodeDeletion();
320 
321     void mediaCanStart(Document&amp;) override;
322 
<a name="19" id="anc19"></a><span class="line-added">323     // EventTarget</span>
<span class="line-added">324     ScriptExecutionContext* scriptExecutionContext() const final;</span>
<span class="line-added">325     void dispatchEvent(Event&amp;) final;</span>
<span class="line-added">326 </span>
327     // MediaProducer
328     MediaProducer::MediaStateFlags mediaState() const override;
329     void pageMutedStateDidChange() override;
330 
331     // The context itself keeps a reference to all source nodes.  The source nodes, then reference all nodes they&#39;re connected to.
332     // In turn, these nodes reference all nodes they&#39;re connected to.  All nodes are ultimately connected to the AudioDestinationNode.
333     // When the context dereferences a source node, it will be deactivated from the rendering graph along with all other nodes it is
334     // uniquely connected to.  See the AudioNode::ref() and AudioNode::deref() methods for more details.
335     void refNode(AudioNode&amp;);
336     void derefNode(AudioNode&amp;);
337 
338     // ActiveDOMObject API.
339     void stop() override;
340     bool canSuspendForDocumentSuspension() const override;
341     const char* activeDOMObjectName() const override;
342 
343     // When the context goes away, there might still be some sources which haven&#39;t finished playing.
344     // Make sure to dereference them here.
345     void derefUnfinishedSourceNodes();
346 
347     // PlatformMediaSessionClient
348     PlatformMediaSession::MediaType mediaType() const override { return PlatformMediaSession::WebAudio; }
349     PlatformMediaSession::MediaType presentationType() const override { return PlatformMediaSession::WebAudio; }
350     PlatformMediaSession::CharacteristicsFlags characteristics() const override { return m_state == State::Running ? PlatformMediaSession::HasAudio : PlatformMediaSession::HasNothing; }
351     void mayResumePlayback(bool shouldResume) override;
352     void suspendPlayback() override;
353     bool canReceiveRemoteControlCommands() const override { return false; }
354     void didReceiveRemoteControlCommand(PlatformMediaSession::RemoteControlCommandType, const PlatformMediaSession::RemoteCommandArgument*) override { }
355     bool supportsSeeking() const override { return false; }
356     bool shouldOverrideBackgroundPlaybackRestriction(PlatformMediaSession::InterruptionType) const override { return false; }
357     String sourceApplicationIdentifier() const override;
358     bool canProduceAudio() const final { return true; }
359     bool isSuspended() const final;
360     bool processingUserGestureForMedia() const final;
361 
362     void visibilityStateChanged() final;
363 
364     // EventTarget
365     void refEventTarget() override { ref(); }
366     void derefEventTarget() override { deref(); }
367 
368     void handleDirtyAudioSummingJunctions();
369     void handleDirtyAudioNodeOutputs();
370 
371     void addReaction(State, DOMPromiseDeferred&lt;void&gt;&amp;&amp;);
372     void updateAutomaticPullNodes();
373 
<a name="20" id="anc20"></a><span class="line-added">374 #if !RELEASE_LOG_DISABLED</span>
<span class="line-added">375     const char* logClassName() const final { return &quot;AudioContext&quot;; }</span>
<span class="line-added">376 </span>
<span class="line-added">377     Ref&lt;Logger&gt; m_logger;</span>
<span class="line-added">378     const void* m_logIdentifier;</span>
<span class="line-added">379     uint64_t m_nextAudioNodeIdentifier { 0 };</span>
<span class="line-added">380     uint64_t m_nextAudioParameterIdentifier { 0 };</span>
<span class="line-added">381 #endif</span>
<span class="line-added">382 </span>
383     // Only accessed in the audio thread.
384     Vector&lt;AudioNode*&gt; m_finishedNodes;
385 
386     // We don&#39;t use RefPtr&lt;AudioNode&gt; here because AudioNode has a more complex ref() / deref() implementation
387     // with an optional argument for refType.  We need to use the special refType: RefTypeConnection
388     // Either accessed when the graph lock is held, or on the main thread when the audio thread has finished.
389     Vector&lt;AudioNode*&gt; m_referencedNodes;
390 
391     // Accumulate nodes which need to be deleted here.
392     // This is copied to m_nodesToDelete at the end of a render cycle in handlePostRenderTasks(), where we&#39;re assured of a stable graph
393     // state which will have no references to any of the nodes in m_nodesToDelete once the context lock is released
394     // (when handlePostRenderTasks() has completed).
395     Vector&lt;AudioNode*&gt; m_nodesMarkedForDeletion;
396 
397     // They will be scheduled for deletion (on the main thread) at the end of a render cycle (in realtime thread).
398     Vector&lt;AudioNode*&gt; m_nodesToDelete;
399 
400     bool m_isDeletionScheduled { false };
401     bool m_isStopScheduled { false };
402     bool m_isInitialized { false };
403     bool m_isAudioThreadFinished { false };
404     bool m_automaticPullNodesNeedUpdating { false };
405     bool m_isOfflineContext { false };
406 
407     // Only accessed when the graph lock is held.
408     HashSet&lt;AudioSummingJunction*&gt; m_dirtySummingJunctions;
409     HashSet&lt;AudioNodeOutput*&gt; m_dirtyAudioNodeOutputs;
410 
411     // For the sake of thread safety, we maintain a seperate Vector of automatic pull nodes for rendering in m_renderingAutomaticPullNodes.
412     // It will be copied from m_automaticPullNodes by updateAutomaticPullNodes() at the very start or end of the rendering quantum.
413     HashSet&lt;AudioNode*&gt; m_automaticPullNodes;
414     Vector&lt;AudioNode*&gt; m_renderingAutomaticPullNodes;
415     // Only accessed in the audio thread.
416     Vector&lt;AudioNode*&gt; m_deferredFinishDerefList;
417     Vector&lt;Vector&lt;DOMPromiseDeferred&lt;void&gt;&gt;&gt; m_stateReactions;
418 
419     std::unique_ptr&lt;PlatformMediaSession&gt; m_mediaSession;
420     std::unique_ptr&lt;GenericEventQueue&gt; m_eventQueue;
421 
422     RefPtr&lt;AudioBuffer&gt; m_renderTarget;
423     RefPtr&lt;AudioDestinationNode&gt; m_destinationNode;
424     RefPtr&lt;AudioListener&gt; m_listener;
425 
426     unsigned m_connectionCount { 0 };
427 
428     // Graph locking.
429     Lock m_contextGraphMutex;
430     // FIXME: Using volatile seems incorrect.
431     // https://bugs.webkit.org/show_bug.cgi?id=180332
432     Thread* volatile m_audioThread { nullptr };
433     Thread* volatile m_graphOwnerThread { nullptr }; // if the lock is held then this is the thread which owns it, otherwise == nullptr.
434 
<a name="21" id="anc21"></a><span class="line-modified">435     std::unique_ptr&lt;AsyncAudioDecoder&gt; m_audioDecoder;</span>
436 
437     // This is considering 32 is large enough for multiple channels audio.
438     // It is somewhat arbitrary and could be increased if necessary.
439     enum { MaxNumberOfChannels = 32 };
440 
441     // Number of AudioBufferSourceNodes that are active (playing).
442     std::atomic&lt;int&gt; m_activeSourceCount { 0 };
443 
444     BehaviorRestrictions m_restrictions { NoRestrictions };
445 
446     State m_state { State::Suspended };
<a name="22" id="anc22"></a><span class="line-added">447     RefPtr&lt;PendingActivity&lt;AudioContext&gt;&gt; m_pendingActivity;</span>
448 };
449 
450 // FIXME: Find out why these ==/!= functions are needed and remove them if possible.
451 
452 inline bool operator==(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
453 {
454     return &amp;lhs == &amp;rhs;
455 }
456 
457 inline bool operator!=(const AudioContext&amp; lhs, const AudioContext&amp; rhs)
458 {
459     return &amp;lhs != &amp;rhs;
460 }
461 
462 inline AudioContext::State AudioContext::state() const
463 {
464     return m_state;
465 }
466 
467 } // WebCore
<a name="23" id="anc23"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="23" type="hidden" />
</body>
</html>