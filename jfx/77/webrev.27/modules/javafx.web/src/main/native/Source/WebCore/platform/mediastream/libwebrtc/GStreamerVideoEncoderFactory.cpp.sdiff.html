<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoEncoderFactory.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="GStreamerVideoEncoder.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../index.html" target="_top">index</a> <a href="GStreamerVideoEncoderFactory.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/platform/mediastream/libwebrtc/GStreamerVideoEncoderFactory.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
 24 #include &quot;GStreamerVideoEncoderFactory.h&quot;
 25 
 26 #include &quot;GStreamerVideoEncoder.h&quot;
 27 #include &quot;GStreamerVideoFrameLibWebRTC.h&quot;
 28 #include &quot;webrtc/common_video/h264/h264_common.h&quot;
 29 #include &quot;webrtc/common_video/h264/profile_level_id.h&quot;
 30 #include &quot;webrtc/media/base/codec.h&quot;
 31 #include &quot;webrtc/modules/video_coding/codecs/h264/include/h264.h&quot;
 32 #include &quot;webrtc/modules/video_coding/codecs/vp8/include/vp8.h&quot;
 33 #include &quot;webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_encoder.h&quot;
 34 #include &quot;webrtc/modules/video_coding/include/video_codec_interface.h&quot;
 35 #include &quot;webrtc/modules/video_coding/utility/simulcast_utility.h&quot;
 36 
 37 #include &lt;gst/app/gstappsink.h&gt;
 38 #include &lt;gst/app/gstappsrc.h&gt;
 39 #define GST_USE_UNSTABLE_API 1
 40 #include &lt;gst/codecparsers/gsth264parser.h&gt;
 41 #undef GST_USE_UNSTABLE_API
 42 #include &lt;gst/pbutils/encoding-profile.h&gt;
 43 #include &lt;gst/video/video.h&gt;

 44 #include &lt;wtf/HashMap.h&gt;
<span class="line-removed"> 45 #include &lt;wtf/HexNumber.h&gt;</span>
 46 #include &lt;wtf/Lock.h&gt;
 47 #include &lt;wtf/StdMap.h&gt;

 48 
 49 // Required for unified builds
 50 #ifdef GST_CAT_DEFAULT
 51 #undef GST_CAT_DEFAULT
 52 #endif
 53 
 54 GST_DEBUG_CATEGORY(webkit_webrtcenc_debug);
 55 #define GST_CAT_DEFAULT webkit_webrtcenc_debug
 56 
 57 #define KBIT_TO_BIT 1024
 58 
 59 namespace WebCore {
 60 
<span class="line-removed"> 61 typedef struct {</span>
<span class="line-removed"> 62     uint64_t rtpTimestamp;</span>
<span class="line-removed"> 63     int64_t captureTimeMs;</span>
<span class="line-removed"> 64     webrtc::CodecSpecificInfo codecInfo;</span>
<span class="line-removed"> 65 } FrameData;</span>
<span class="line-removed"> 66 </span>
 67 class GStreamerVideoEncoder : public webrtc::VideoEncoder {

 68 public:
 69     GStreamerVideoEncoder(const webrtc::SdpVideoFormat&amp;)
 70         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 71         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
<span class="line-removed"> 72         , m_adapter(adoptGRef(gst_adapter_new()))</span>
 73     {
 74     }
 75     GStreamerVideoEncoder()
 76         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 77         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))
<span class="line-removed"> 78         , m_adapter(adoptGRef(gst_adapter_new()))</span>
 79     {
 80     }
 81 
 82     int SetRates(uint32_t newBitrate, uint32_t frameRate) override
 83     {
 84         GST_INFO_OBJECT(m_pipeline.get(), &quot;New bitrate: %d - framerate is %d&quot;,
 85             newBitrate, frameRate);
 86 
 87         auto caps = adoptGRef(gst_caps_copy(m_restrictionCaps.get()));
 88 
 89         SetRestrictionCaps(WTFMove(caps));
 90 
 91         if (m_encoder)
 92             g_object_set(m_encoder, &quot;bitrate&quot;, newBitrate, nullptr);
 93 
 94         return WEBRTC_VIDEO_CODEC_OK;
 95     }
 96 
 97     GstElement* pipeline()
 98     {
 99         return m_pipeline.get();
100     }
101 
102     GstElement* makeElement(const gchar* factoryName)
103     {
<span class="line-modified">104         auto name = makeString(Name(), &quot;_enc_&quot;, factoryName, &quot;_0x&quot;, hex(reinterpret_cast&lt;uintptr_t&gt;(this)));</span>

105         auto elem = gst_element_factory_make(factoryName, name.utf8().data());
106 
107         return elem;
108     }
109 
110     int32_t InitEncode(const webrtc::VideoCodec* codecSettings, int32_t, size_t)
111     {
112         g_return_val_if_fail(codecSettings, WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
113         g_return_val_if_fail(codecSettings-&gt;codecType == CodecType(), WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
114 
115         if (webrtc::SimulcastUtility::NumberOfSimulcastStreams(*codecSettings) &gt; 1) {
116             GST_ERROR(&quot;Simulcast not supported.&quot;);
117 
118             return WEBRTC_VIDEO_CODEC_ERR_SIMULCAST_PARAMETERS_NOT_SUPPORTED;
119         }
120 
121         m_encodedFrame._size = codecSettings-&gt;width * codecSettings-&gt;height * 3;
122         m_encodedFrame._buffer = new uint8_t[m_encodedFrame._size];
123         m_encodedImageBuffer.reset(m_encodedFrame._buffer);
124         m_encodedFrame._completeFrame = true;
125         m_encodedFrame._encodedWidth = 0;
126         m_encodedFrame._encodedHeight = 0;
127         m_encodedFrame._length = 0;
128 
129         m_pipeline = makeElement(&quot;pipeline&quot;);
130 
131         connectSimpleBusMessageCallback(m_pipeline.get());
132         auto encoder = createEncoder();
133         ASSERT(encoder);
134         m_encoder = encoder.get();
135 
136         g_object_set(m_encoder, &quot;keyframe-interval&quot;, KeyframeInterval(codecSettings), nullptr);
137 
138         m_src = makeElement(&quot;appsrc&quot;);
139         g_object_set(m_src, &quot;is-live&quot;, true, &quot;format&quot;, GST_FORMAT_TIME, nullptr);
140 
141         auto videoconvert = makeElement(&quot;videoconvert&quot;);
<span class="line-modified">142         auto sink = makeElement(&quot;appsink&quot;);</span>
<span class="line-modified">143         gst_app_sink_set_emit_signals(GST_APP_SINK(sink), TRUE);</span>
<span class="line-removed">144         g_signal_connect(sink, &quot;new-sample&quot;, G_CALLBACK(newSampleCallbackTramp), this);</span>
145 
<span class="line-modified">146         auto name = makeString(Name(), &quot;_enc_rawcapsfilter_0x&quot;, hex(reinterpret_cast&lt;uintptr_t&gt;(this)));</span>
<span class="line-removed">147         m_capsFilter = gst_element_factory_make(&quot;capsfilter&quot;, name.utf8().data());</span>
148         if (m_restrictionCaps)
149             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
150 
<span class="line-modified">151         gst_bin_add_many(GST_BIN(m_pipeline.get()), m_src, videoconvert, m_capsFilter, encoder.leakRef(), sink, nullptr);</span>
<span class="line-modified">152         if (!gst_element_link_many(m_src, videoconvert, m_capsFilter, m_encoder, sink, nullptr))</span>


153             ASSERT_NOT_REACHED();

154 
155         gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
156 
157         return WEBRTC_VIDEO_CODEC_OK;
158     }
159 
160     bool SupportsNativeHandle() const final
161     {
162         return true;
163     }
164 
165     int32_t RegisterEncodeCompleteCallback(webrtc::EncodedImageCallback* callback) final
166     {
167         m_imageReadyCb = callback;
168 
169         return WEBRTC_VIDEO_CODEC_OK;
170     }
171 
172     int32_t Release() final
173     {
174         m_encodedFrame._buffer = nullptr;
175         m_encodedImageBuffer.reset();
176         if (m_pipeline) {
177             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
178             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
179 
180             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
181             m_src = nullptr;
182             m_encoder = nullptr;
183             m_capsFilter = nullptr;

184             m_pipeline = nullptr;
185         }
186 
187         return WEBRTC_VIDEO_CODEC_OK;
188     }
189 












190     int32_t Encode(const webrtc::VideoFrame&amp; frame,
<span class="line-modified">191         const webrtc::CodecSpecificInfo* codecInfo,</span>
192         const std::vector&lt;webrtc::FrameType&gt;* frameTypes) final
193     {


194         if (!m_imageReadyCb) {
195             GST_INFO_OBJECT(m_pipeline.get(), &quot;No encoded callback set yet!&quot;);
196 
197             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
198         }
199 
200         if (!m_src) {
201             GST_INFO_OBJECT(m_pipeline.get(), &quot;No source set yet!&quot;);
202 
203             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
204         }
205 
206         auto sample = GStreamerSampleFromLibWebRTCVideoFrame(frame);
207         auto buffer = gst_sample_get_buffer(sample.get());
208 
209         if (!GST_CLOCK_TIME_IS_VALID(m_firstFramePts)) {
210             m_firstFramePts = GST_BUFFER_PTS(buffer);
211             auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
212             gst_pad_set_offset(pad.get(), -m_firstFramePts);
213         }
214 
<span class="line-removed">215         webrtc::CodecSpecificInfo localCodecInfo;</span>
<span class="line-removed">216         FrameData frameData = { frame.timestamp(), frame.render_time_ms(), codecInfo ? *codecInfo : localCodecInfo };</span>
<span class="line-removed">217         {</span>
<span class="line-removed">218             auto locker = holdLock(m_bufferMapLock);</span>
<span class="line-removed">219             m_framesData.append(frameData);</span>
<span class="line-removed">220         }</span>
<span class="line-removed">221 </span>
222         for (auto frame_type : *frameTypes) {
223             if (frame_type == webrtc::kVideoFrameKey) {
224                 auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
225                 auto forceKeyUnit = gst_video_event_new_downstream_force_key_unit(GST_CLOCK_TIME_NONE,
226                     GST_CLOCK_TIME_NONE, GST_CLOCK_TIME_NONE, FALSE, 1);
227                 GST_INFO_OBJECT(m_pipeline.get(), &quot;Requesting KEYFRAME!&quot;);
228 
229                 if (!gst_pad_push_event(pad.get(), forceKeyUnit))
230                     GST_WARNING_OBJECT(pipeline(), &quot;Could not send ForceKeyUnit event&quot;);
231 
232                 break;
233             }
234         }
235 
<span class="line-modified">236         switch (gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get())) {</span>
<span class="line-modified">237         case GST_FLOW_OK:</span>
<span class="line-modified">238             return WEBRTC_VIDEO_CODEC_OK;</span>
<span class="line-modified">239         case GST_FLOW_FLUSHING:</span>
<span class="line-modified">240             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;</span>
<span class="line-modified">241         default:</span>

242             return WEBRTC_VIDEO_CODEC_ERROR;
243         }
<span class="line-removed">244     }</span>
<span class="line-removed">245 </span>
<span class="line-removed">246     GstFlowReturn newSampleCallback(GstElement* sink)</span>
<span class="line-removed">247     {</span>
<span class="line-removed">248         auto sample = adoptGRef(gst_app_sink_pull_sample(GST_APP_SINK(sink)));</span>
<span class="line-removed">249         auto buffer = gst_sample_get_buffer(sample.get());</span>
<span class="line-removed">250         auto caps = gst_sample_get_caps(sample.get());</span>
<span class="line-removed">251 </span>
<span class="line-removed">252         webrtc::CodecSpecificInfo localCodecInfo;</span>
<span class="line-removed">253         FrameData frameData = { 0, 0, localCodecInfo};</span>
<span class="line-removed">254         {</span>
<span class="line-removed">255             auto locker = holdLock(m_bufferMapLock);</span>
<span class="line-removed">256             if (!m_framesData.size()) {</span>
<span class="line-removed">257                 gst_adapter_push(m_adapter.get(), gst_buffer_ref(buffer));</span>
<span class="line-removed">258 </span>
<span class="line-removed">259                 return GST_FLOW_OK;</span>
<span class="line-removed">260             }</span>
<span class="line-removed">261 </span>
<span class="line-removed">262             if (gst_adapter_available(m_adapter.get()) &gt; 0) {</span>
<span class="line-removed">263                 uint flags = GST_BUFFER_FLAGS(buffer);</span>
<span class="line-removed">264 </span>
<span class="line-removed">265                 GST_INFO_OBJECT(m_pipeline.get(), &quot;Got more buffer than pushed frame, trying to deal with it.&quot;);</span>
<span class="line-removed">266                 gst_adapter_push(m_adapter.get(), gst_buffer_ref(buffer));</span>
267 
<span class="line-modified">268                 buffer = gst_adapter_take_buffer(m_adapter.get(), gst_adapter_available(m_adapter.get()));</span>
<span class="line-modified">269                 GST_BUFFER_FLAGS(buffer) = flags;</span>
<span class="line-removed">270             }</span>
<span class="line-removed">271             frameData = m_framesData[0];</span>
<span class="line-removed">272             m_framesData.remove(static_cast&lt;size_t&gt;(0));</span>
<span class="line-removed">273         }</span>
274 
275         webrtc::RTPFragmentationHeader fragmentationInfo;
<span class="line-modified">276         Fragmentize(&amp;m_encodedFrame, &amp;m_encodedImageBuffer, &amp;m_encodedImageBufferSize, buffer, &amp;fragmentationInfo);</span>

277         if (!m_encodedFrame._size)
<span class="line-modified">278             return GST_FLOW_OK;</span>
279 
<span class="line-modified">280         gst_structure_get(gst_caps_get_structure(caps, 0),</span>
281             &quot;width&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedWidth,
282             &quot;height&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedHeight,
283             nullptr);
284 
<span class="line-modified">285         m_encodedFrame._frameType = GST_BUFFER_FLAG_IS_SET(buffer, GST_BUFFER_FLAG_DELTA_UNIT) ? webrtc::kVideoFrameDelta : webrtc::kVideoFrameKey;</span>
<span class="line-modified">286         m_encodedFrame._completeFrame = false;</span>
<span class="line-modified">287         m_encodedFrame.capture_time_ms_ = frameData.captureTimeMs;</span>
<span class="line-modified">288         m_encodedFrame.SetTimestamp(frameData.rtpTimestamp);</span>
289 
<span class="line-modified">290         GST_LOG_OBJECT(m_pipeline.get(), &quot;Got buffer capture_time_ms: %ld _timestamp: %u&quot;,</span>
291             m_encodedFrame.capture_time_ms_, m_encodedFrame.Timestamp());
292 
<span class="line-modified">293         PopulateCodecSpecific(&amp;frameData.codecInfo, buffer);</span>
<span class="line-modified">294 </span>
<span class="line-modified">295         webrtc::EncodedImageCallback::Result result = m_imageReadyCb-&gt;OnEncodedImage(m_encodedFrame, &amp;frameData.codecInfo, &amp;fragmentationInfo);</span>
296         if (result.error != webrtc::EncodedImageCallback::Result::OK)
297             GST_ERROR_OBJECT(m_pipeline.get(), &quot;Encode callback failed: %d&quot;, result.error);
298 
<span class="line-modified">299         return GST_FLOW_OK;</span>
300     }
301 
302     GRefPtr&lt;GstElement&gt; createEncoder(void)
303     {
304         GRefPtr&lt;GstElement&gt; encoder = nullptr;
305         GstElement* webrtcencoder = GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL)));
306 
307         g_object_set(webrtcencoder, &quot;format&quot;, adoptGRef(gst_caps_from_string(Caps())).get(), NULL);
308         g_object_get(webrtcencoder, &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
309 
310         if (!encoder) {
311             GST_INFO(&quot;No encoder found for %s&quot;, Caps());
312 
313             return nullptr;
314         }
315 
316         return webrtcencoder;
317     }
318 
319     void AddCodecIfSupported(std::vector&lt;webrtc::SdpVideoFormat&gt;* supportedFormats)
</pre>
<hr />
<pre>
368         GRefPtr&lt;GstElement&gt; encoderImplementation;
369         g_return_val_if_fail(m_encoder, nullptr);
370 
371         g_object_get(m_encoder, &quot;encoder&quot;, &amp;encoderImplementation.outPtr(), nullptr);
372 
373         return GST_OBJECT_NAME(gst_element_get_factory(encoderImplementation.get()));
374     }
375 
376     virtual const gchar* Name() = 0;
377     virtual int KeyframeInterval(const webrtc::VideoCodec* codecSettings) = 0;
378 
379     void SetRestrictionCaps(GRefPtr&lt;GstCaps&gt; caps)
380     {
381         if (m_restrictionCaps)
382             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
383 
384         m_restrictionCaps = caps;
385     }
386 
387 private:
<span class="line-removed">388     static GstFlowReturn newSampleCallbackTramp(GstElement* sink, GStreamerVideoEncoder* enc)</span>
<span class="line-removed">389     {</span>
<span class="line-removed">390         return enc-&gt;newSampleCallback(sink);</span>
<span class="line-removed">391     }</span>
<span class="line-removed">392 </span>
393     GRefPtr&lt;GstElement&gt; m_pipeline;
394     GstElement* m_src;
395     GstElement* m_encoder;
396     GstElement* m_capsFilter;
397 
398     webrtc::EncodedImageCallback* m_imageReadyCb;
399     GstClockTime m_firstFramePts;
400     GRefPtr&lt;GstCaps&gt; m_restrictionCaps;
401     webrtc::EncodedImage m_encodedFrame;
402     std::unique_ptr&lt;uint8_t[]&gt; m_encodedImageBuffer;
403     size_t m_encodedImageBufferSize;
404 
405     Lock m_bufferMapLock;
<span class="line-modified">406     GRefPtr&lt;GstAdapter&gt; m_adapter;</span>
<span class="line-removed">407     Vector&lt;FrameData&gt; m_framesData;</span>
408 };
409 
410 class GStreamerH264Encoder : public GStreamerVideoEncoder {
411 public:
412     GStreamerH264Encoder() { }
413 
414     GStreamerH264Encoder(const webrtc::SdpVideoFormat&amp; format)
415         : m_parser(gst_h264_nal_parser_new())
416         , packetizationMode(webrtc::H264PacketizationMode::NonInterleaved)
417     {
418         auto it = format.parameters.find(cricket::kH264FmtpPacketizationMode);
419 
420         if (it != format.parameters.end() &amp;&amp; it-&gt;second == &quot;1&quot;)
421             packetizationMode = webrtc::H264PacketizationMode::NonInterleaved;
422     }
423 
424     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
425     {
426         return codecSettings-&gt;H264().keyFrameInterval;
427     }
</pre>
<hr />
<pre>
477             memcpy(encodedImage-&gt;_buffer + encodedImage-&gt;_length, &amp;map-&gt;data()[nal-&gt;sc_offset],
478                 sizeof(startCode) + nal-&gt;size);
479             encodedImage-&gt;_length += nal-&gt;size + sizeof(startCode);
480         }
481     }
482 
483     webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*) final
484     {
485         // TODO- Create from encoder src pad caps template
486         return webrtc::SdpVideoFormat(cricket::kH264CodecName,
487             { { cricket::kH264FmtpProfileLevelId, cricket::kH264ProfileLevelConstrainedBaseline },
488                 { cricket::kH264FmtpLevelAsymmetryAllowed, &quot;1&quot; },
489                 { cricket::kH264FmtpPacketizationMode, &quot;1&quot; } });
490     }
491 
492     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
493     const gchar* Name() final { return cricket::kH264CodecName; }
494     GstH264NalParser* m_parser;
495     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
496 
<span class="line-modified">497     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecifiInfos, GstBuffer*) final</span>
498     {
<span class="line-modified">499         codecSpecifiInfos-&gt;codecType = CodecType();</span>
<span class="line-modified">500         codecSpecifiInfos-&gt;codec_name = ImplementationName();</span>
<span class="line-modified">501         webrtc::CodecSpecificInfoH264* h264Info = &amp;(codecSpecifiInfos-&gt;codecSpecific.H264);</span>
502         h264Info-&gt;packetization_mode = packetizationMode;
503     }
504 
505     webrtc::H264PacketizationMode packetizationMode;
506 };
507 
508 class GStreamerVP8Encoder : public GStreamerVideoEncoder {
509 public:
510     GStreamerVP8Encoder() { }
511     GStreamerVP8Encoder(const webrtc::SdpVideoFormat&amp;) { }
512     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
513     const gchar* Name() final { return cricket::kVp8CodecName; }
514     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
515 
516     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
517     {
518         return codecSettings-&gt;VP8().keyFrameInterval;
519     }
520 
<span class="line-modified">521     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecifiInfos, GstBuffer* buffer) final</span>
522     {
<span class="line-modified">523         codecSpecifiInfos-&gt;codecType = webrtc::kVideoCodecVP8;</span>
<span class="line-modified">524         codecSpecifiInfos-&gt;codec_name = ImplementationName();</span>
<span class="line-modified">525         webrtc::CodecSpecificInfoVP8* vp8Info = &amp;(codecSpecifiInfos-&gt;codecSpecific.VP8);</span>
526         vp8Info-&gt;temporalIdx = 0;
527 
528         vp8Info-&gt;keyIdx = webrtc::kNoKeyIdx;
529         vp8Info-&gt;nonReference = GST_BUFFER_FLAG_IS_SET(buffer, GST_BUFFER_FLAG_DELTA_UNIT);
530     }
531 };
532 
533 std::unique_ptr&lt;webrtc::VideoEncoder&gt; GStreamerVideoEncoderFactory::CreateVideoEncoder(const webrtc::SdpVideoFormat&amp; format)
534 {
535     if (format.name == cricket::kVp8CodecName) {
536         GRefPtr&lt;GstElement&gt; webrtcencoder = adoptGRef(GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL))));
537         GRefPtr&lt;GstElement&gt; encoder = nullptr;
538 
539         g_object_set(webrtcencoder.get(), &quot;format&quot;, adoptGRef(gst_caps_from_string(&quot;video/x-vp8&quot;)).get(), NULL);
540         g_object_get(webrtcencoder.get(), &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
541 
542         if (encoder)
<span class="line-modified">543             return std::make_unique&lt;GStreamerVP8Encoder&gt;(format);</span>
544 
545         GST_INFO(&quot;Using VP8 Encoder from LibWebRTC.&quot;);
<span class="line-modified">546         return std::make_unique&lt;webrtc::LibvpxVp8Encoder&gt;();</span>
547     }
548 
549     if (format.name == cricket::kH264CodecName)
<span class="line-modified">550         return std::make_unique&lt;GStreamerH264Encoder&gt;(format);</span>
551 
552     return nullptr;
553 }
554 
555 GStreamerVideoEncoderFactory::GStreamerVideoEncoderFactory()
556 {
557     static std::once_flag debugRegisteredFlag;
558 
559     std::call_once(debugRegisteredFlag, [] {
560         GST_DEBUG_CATEGORY_INIT(webkit_webrtcenc_debug, &quot;webkitlibwebrtcvideoencoder&quot;, 0, &quot;WebKit WebRTC video encoder&quot;);
561         gst_element_register(nullptr, &quot;webrtcvideoencoder&quot;, GST_RANK_PRIMARY, GST_TYPE_WEBRTC_VIDEO_ENCODER);
562     });
563 }
564 
565 std::vector&lt;webrtc::SdpVideoFormat&gt; GStreamerVideoEncoderFactory::GetSupportedFormats() const
566 {
567     std::vector&lt;webrtc::SdpVideoFormat&gt; supportedCodecs;
568 
569     supportedCodecs.push_back(webrtc::SdpVideoFormat(cricket::kVp8CodecName));
570     GStreamerH264Encoder().AddCodecIfSupported(&amp;supportedCodecs);
</pre>
</td>
<td>
<hr />
<pre>
 24 #include &quot;GStreamerVideoEncoderFactory.h&quot;
 25 
 26 #include &quot;GStreamerVideoEncoder.h&quot;
 27 #include &quot;GStreamerVideoFrameLibWebRTC.h&quot;
 28 #include &quot;webrtc/common_video/h264/h264_common.h&quot;
 29 #include &quot;webrtc/common_video/h264/profile_level_id.h&quot;
 30 #include &quot;webrtc/media/base/codec.h&quot;
 31 #include &quot;webrtc/modules/video_coding/codecs/h264/include/h264.h&quot;
 32 #include &quot;webrtc/modules/video_coding/codecs/vp8/include/vp8.h&quot;
 33 #include &quot;webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_encoder.h&quot;
 34 #include &quot;webrtc/modules/video_coding/include/video_codec_interface.h&quot;
 35 #include &quot;webrtc/modules/video_coding/utility/simulcast_utility.h&quot;
 36 
 37 #include &lt;gst/app/gstappsink.h&gt;
 38 #include &lt;gst/app/gstappsrc.h&gt;
 39 #define GST_USE_UNSTABLE_API 1
 40 #include &lt;gst/codecparsers/gsth264parser.h&gt;
 41 #undef GST_USE_UNSTABLE_API
 42 #include &lt;gst/pbutils/encoding-profile.h&gt;
 43 #include &lt;gst/video/video.h&gt;
<span class="line-added"> 44 #include &lt;wtf/Atomics.h&gt;</span>
 45 #include &lt;wtf/HashMap.h&gt;

 46 #include &lt;wtf/Lock.h&gt;
 47 #include &lt;wtf/StdMap.h&gt;
<span class="line-added"> 48 #include &lt;wtf/text/StringConcatenateNumbers.h&gt;</span>
 49 
 50 // Required for unified builds
 51 #ifdef GST_CAT_DEFAULT
 52 #undef GST_CAT_DEFAULT
 53 #endif
 54 
 55 GST_DEBUG_CATEGORY(webkit_webrtcenc_debug);
 56 #define GST_CAT_DEFAULT webkit_webrtcenc_debug
 57 
 58 #define KBIT_TO_BIT 1024
 59 
 60 namespace WebCore {
 61 






 62 class GStreamerVideoEncoder : public webrtc::VideoEncoder {
<span class="line-added"> 63     WTF_MAKE_FAST_ALLOCATED;</span>
 64 public:
 65     GStreamerVideoEncoder(const webrtc::SdpVideoFormat&amp;)
 66         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 67         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))

 68     {
 69     }
 70     GStreamerVideoEncoder()
 71         : m_firstFramePts(GST_CLOCK_TIME_NONE)
 72         , m_restrictionCaps(adoptGRef(gst_caps_new_empty_simple(&quot;video/x-raw&quot;)))

 73     {
 74     }
 75 
 76     int SetRates(uint32_t newBitrate, uint32_t frameRate) override
 77     {
 78         GST_INFO_OBJECT(m_pipeline.get(), &quot;New bitrate: %d - framerate is %d&quot;,
 79             newBitrate, frameRate);
 80 
 81         auto caps = adoptGRef(gst_caps_copy(m_restrictionCaps.get()));
 82 
 83         SetRestrictionCaps(WTFMove(caps));
 84 
 85         if (m_encoder)
 86             g_object_set(m_encoder, &quot;bitrate&quot;, newBitrate, nullptr);
 87 
 88         return WEBRTC_VIDEO_CODEC_OK;
 89     }
 90 
 91     GstElement* pipeline()
 92     {
 93         return m_pipeline.get();
 94     }
 95 
 96     GstElement* makeElement(const gchar* factoryName)
 97     {
<span class="line-modified"> 98         static Atomic&lt;uint32_t&gt; elementId;</span>
<span class="line-added"> 99         auto name = makeString(Name(), &quot;-enc-&quot;, factoryName, &quot;-&quot;, elementId.exchangeAdd(1));</span>
100         auto elem = gst_element_factory_make(factoryName, name.utf8().data());
101 
102         return elem;
103     }
104 
105     int32_t InitEncode(const webrtc::VideoCodec* codecSettings, int32_t, size_t)
106     {
107         g_return_val_if_fail(codecSettings, WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
108         g_return_val_if_fail(codecSettings-&gt;codecType == CodecType(), WEBRTC_VIDEO_CODEC_ERR_PARAMETER);
109 
110         if (webrtc::SimulcastUtility::NumberOfSimulcastStreams(*codecSettings) &gt; 1) {
111             GST_ERROR(&quot;Simulcast not supported.&quot;);
112 
113             return WEBRTC_VIDEO_CODEC_ERR_SIMULCAST_PARAMETERS_NOT_SUPPORTED;
114         }
115 
116         m_encodedFrame._size = codecSettings-&gt;width * codecSettings-&gt;height * 3;
117         m_encodedFrame._buffer = new uint8_t[m_encodedFrame._size];
118         m_encodedImageBuffer.reset(m_encodedFrame._buffer);
119         m_encodedFrame._completeFrame = true;
120         m_encodedFrame._encodedWidth = 0;
121         m_encodedFrame._encodedHeight = 0;
122         m_encodedFrame._length = 0;
123 
124         m_pipeline = makeElement(&quot;pipeline&quot;);
125 
126         connectSimpleBusMessageCallback(m_pipeline.get());
127         auto encoder = createEncoder();
128         ASSERT(encoder);
129         m_encoder = encoder.get();
130 
131         g_object_set(m_encoder, &quot;keyframe-interval&quot;, KeyframeInterval(codecSettings), nullptr);
132 
133         m_src = makeElement(&quot;appsrc&quot;);
134         g_object_set(m_src, &quot;is-live&quot;, true, &quot;format&quot;, GST_FORMAT_TIME, nullptr);
135 
136         auto videoconvert = makeElement(&quot;videoconvert&quot;);
<span class="line-modified">137         m_sink = makeElement(&quot;appsink&quot;);</span>
<span class="line-modified">138         g_object_set(m_sink, &quot;sync&quot;, FALSE, nullptr);</span>

139 
<span class="line-modified">140         m_capsFilter = makeElement(&quot;capsfilter&quot;);</span>

141         if (m_restrictionCaps)
142             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
143 
<span class="line-modified">144         gst_bin_add_many(GST_BIN(m_pipeline.get()), m_src, videoconvert, m_capsFilter, encoder.leakRef(), m_sink, nullptr);</span>
<span class="line-modified">145         if (!gst_element_link_many(m_src, videoconvert, m_capsFilter, m_encoder, m_sink, nullptr)) {</span>
<span class="line-added">146             GST_DEBUG_BIN_TO_DOT_FILE_WITH_TS(GST_BIN(m_pipeline.get()), GST_DEBUG_GRAPH_SHOW_VERBOSE, &quot;webkit-webrtc-encoder.error&quot;);</span>
<span class="line-added">147 </span>
148             ASSERT_NOT_REACHED();
<span class="line-added">149         }</span>
150 
151         gst_element_set_state(m_pipeline.get(), GST_STATE_PLAYING);
152 
153         return WEBRTC_VIDEO_CODEC_OK;
154     }
155 
156     bool SupportsNativeHandle() const final
157     {
158         return true;
159     }
160 
161     int32_t RegisterEncodeCompleteCallback(webrtc::EncodedImageCallback* callback) final
162     {
163         m_imageReadyCb = callback;
164 
165         return WEBRTC_VIDEO_CODEC_OK;
166     }
167 
168     int32_t Release() final
169     {
170         m_encodedFrame._buffer = nullptr;
171         m_encodedImageBuffer.reset();
172         if (m_pipeline) {
173             GRefPtr&lt;GstBus&gt; bus = adoptGRef(gst_pipeline_get_bus(GST_PIPELINE(m_pipeline.get())));
174             gst_bus_set_sync_handler(bus.get(), nullptr, nullptr, nullptr);
175 
176             gst_element_set_state(m_pipeline.get(), GST_STATE_NULL);
177             m_src = nullptr;
178             m_encoder = nullptr;
179             m_capsFilter = nullptr;
<span class="line-added">180             m_sink = nullptr;</span>
181             m_pipeline = nullptr;
182         }
183 
184         return WEBRTC_VIDEO_CODEC_OK;
185     }
186 
<span class="line-added">187     int32_t returnFromFlowReturn(GstFlowReturn flow)</span>
<span class="line-added">188     {</span>
<span class="line-added">189         switch (flow) {</span>
<span class="line-added">190         case GST_FLOW_OK:</span>
<span class="line-added">191             return WEBRTC_VIDEO_CODEC_OK;</span>
<span class="line-added">192         case GST_FLOW_FLUSHING:</span>
<span class="line-added">193             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;</span>
<span class="line-added">194         default:</span>
<span class="line-added">195             return WEBRTC_VIDEO_CODEC_ERROR;</span>
<span class="line-added">196         }</span>
<span class="line-added">197     }</span>
<span class="line-added">198 </span>
199     int32_t Encode(const webrtc::VideoFrame&amp; frame,
<span class="line-modified">200         const webrtc::CodecSpecificInfo*,</span>
201         const std::vector&lt;webrtc::FrameType&gt;* frameTypes) final
202     {
<span class="line-added">203         int32_t res;</span>
<span class="line-added">204 </span>
205         if (!m_imageReadyCb) {
206             GST_INFO_OBJECT(m_pipeline.get(), &quot;No encoded callback set yet!&quot;);
207 
208             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
209         }
210 
211         if (!m_src) {
212             GST_INFO_OBJECT(m_pipeline.get(), &quot;No source set yet!&quot;);
213 
214             return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
215         }
216 
217         auto sample = GStreamerSampleFromLibWebRTCVideoFrame(frame);
218         auto buffer = gst_sample_get_buffer(sample.get());
219 
220         if (!GST_CLOCK_TIME_IS_VALID(m_firstFramePts)) {
221             m_firstFramePts = GST_BUFFER_PTS(buffer);
222             auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
223             gst_pad_set_offset(pad.get(), -m_firstFramePts);
224         }
225 







226         for (auto frame_type : *frameTypes) {
227             if (frame_type == webrtc::kVideoFrameKey) {
228                 auto pad = adoptGRef(gst_element_get_static_pad(m_src, &quot;src&quot;));
229                 auto forceKeyUnit = gst_video_event_new_downstream_force_key_unit(GST_CLOCK_TIME_NONE,
230                     GST_CLOCK_TIME_NONE, GST_CLOCK_TIME_NONE, FALSE, 1);
231                 GST_INFO_OBJECT(m_pipeline.get(), &quot;Requesting KEYFRAME!&quot;);
232 
233                 if (!gst_pad_push_event(pad.get(), forceKeyUnit))
234                     GST_WARNING_OBJECT(pipeline(), &quot;Could not send ForceKeyUnit event&quot;);
235 
236                 break;
237             }
238         }
239 
<span class="line-modified">240         res = returnFromFlowReturn(gst_app_src_push_sample(GST_APP_SRC(m_src), sample.get()));</span>
<span class="line-modified">241         if (res != WEBRTC_VIDEO_CODEC_OK)</span>
<span class="line-modified">242             return res;</span>
<span class="line-modified">243 </span>
<span class="line-modified">244         auto encodedSample = adoptGRef(gst_app_sink_try_pull_sample(GST_APP_SINK(m_sink), 5 * GST_SECOND));</span>
<span class="line-modified">245         if (!encodedSample) {</span>
<span class="line-added">246             GST_ERROR(&quot;Didn&#39;t get any encodedSample&quot;);</span>
247             return WEBRTC_VIDEO_CODEC_ERROR;
248         }























249 
<span class="line-modified">250         auto encodedBuffer = gst_sample_get_buffer(encodedSample.get());</span>
<span class="line-modified">251         auto encodedCaps = gst_sample_get_caps(encodedSample.get());</span>




252 
253         webrtc::RTPFragmentationHeader fragmentationInfo;
<span class="line-modified">254 </span>
<span class="line-added">255         Fragmentize(&amp;m_encodedFrame, &amp;m_encodedImageBuffer, &amp;m_encodedImageBufferSize, encodedBuffer, &amp;fragmentationInfo);</span>
256         if (!m_encodedFrame._size)
<span class="line-modified">257             return WEBRTC_VIDEO_CODEC_OK;</span>
258 
<span class="line-modified">259         gst_structure_get(gst_caps_get_structure(encodedCaps, 0),</span>
260             &quot;width&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedWidth,
261             &quot;height&quot;, G_TYPE_INT, &amp;m_encodedFrame._encodedHeight,
262             nullptr);
263 
<span class="line-modified">264         m_encodedFrame._frameType = GST_BUFFER_FLAG_IS_SET(encodedBuffer, GST_BUFFER_FLAG_DELTA_UNIT) ? webrtc::kVideoFrameDelta : webrtc::kVideoFrameKey;</span>
<span class="line-modified">265         m_encodedFrame._completeFrame = true;</span>
<span class="line-modified">266         m_encodedFrame.capture_time_ms_ = frame.render_time_ms();</span>
<span class="line-modified">267         m_encodedFrame.SetTimestamp(frame.timestamp());</span>
268 
<span class="line-modified">269         GST_LOG_OBJECT(m_pipeline.get(), &quot;Got buffer capture_time_ms: %&quot; G_GINT64_FORMAT  &quot; _timestamp: %u&quot;,</span>
270             m_encodedFrame.capture_time_ms_, m_encodedFrame.Timestamp());
271 
<span class="line-modified">272         webrtc::CodecSpecificInfo codecInfo;</span>
<span class="line-modified">273         PopulateCodecSpecific(&amp;codecInfo, encodedBuffer);</span>
<span class="line-modified">274         webrtc::EncodedImageCallback::Result result = m_imageReadyCb-&gt;OnEncodedImage(m_encodedFrame, &amp;codecInfo, &amp;fragmentationInfo);</span>
275         if (result.error != webrtc::EncodedImageCallback::Result::OK)
276             GST_ERROR_OBJECT(m_pipeline.get(), &quot;Encode callback failed: %d&quot;, result.error);
277 
<span class="line-modified">278         return WEBRTC_VIDEO_CODEC_OK;</span>
279     }
280 
281     GRefPtr&lt;GstElement&gt; createEncoder(void)
282     {
283         GRefPtr&lt;GstElement&gt; encoder = nullptr;
284         GstElement* webrtcencoder = GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL)));
285 
286         g_object_set(webrtcencoder, &quot;format&quot;, adoptGRef(gst_caps_from_string(Caps())).get(), NULL);
287         g_object_get(webrtcencoder, &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
288 
289         if (!encoder) {
290             GST_INFO(&quot;No encoder found for %s&quot;, Caps());
291 
292             return nullptr;
293         }
294 
295         return webrtcencoder;
296     }
297 
298     void AddCodecIfSupported(std::vector&lt;webrtc::SdpVideoFormat&gt;* supportedFormats)
</pre>
<hr />
<pre>
347         GRefPtr&lt;GstElement&gt; encoderImplementation;
348         g_return_val_if_fail(m_encoder, nullptr);
349 
350         g_object_get(m_encoder, &quot;encoder&quot;, &amp;encoderImplementation.outPtr(), nullptr);
351 
352         return GST_OBJECT_NAME(gst_element_get_factory(encoderImplementation.get()));
353     }
354 
355     virtual const gchar* Name() = 0;
356     virtual int KeyframeInterval(const webrtc::VideoCodec* codecSettings) = 0;
357 
358     void SetRestrictionCaps(GRefPtr&lt;GstCaps&gt; caps)
359     {
360         if (m_restrictionCaps)
361             g_object_set(m_capsFilter, &quot;caps&quot;, m_restrictionCaps.get(), nullptr);
362 
363         m_restrictionCaps = caps;
364     }
365 
366 private:





367     GRefPtr&lt;GstElement&gt; m_pipeline;
368     GstElement* m_src;
369     GstElement* m_encoder;
370     GstElement* m_capsFilter;
371 
372     webrtc::EncodedImageCallback* m_imageReadyCb;
373     GstClockTime m_firstFramePts;
374     GRefPtr&lt;GstCaps&gt; m_restrictionCaps;
375     webrtc::EncodedImage m_encodedFrame;
376     std::unique_ptr&lt;uint8_t[]&gt; m_encodedImageBuffer;
377     size_t m_encodedImageBufferSize;
378 
379     Lock m_bufferMapLock;
<span class="line-modified">380     GstElement* m_sink;</span>

381 };
382 
383 class GStreamerH264Encoder : public GStreamerVideoEncoder {
384 public:
385     GStreamerH264Encoder() { }
386 
387     GStreamerH264Encoder(const webrtc::SdpVideoFormat&amp; format)
388         : m_parser(gst_h264_nal_parser_new())
389         , packetizationMode(webrtc::H264PacketizationMode::NonInterleaved)
390     {
391         auto it = format.parameters.find(cricket::kH264FmtpPacketizationMode);
392 
393         if (it != format.parameters.end() &amp;&amp; it-&gt;second == &quot;1&quot;)
394             packetizationMode = webrtc::H264PacketizationMode::NonInterleaved;
395     }
396 
397     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
398     {
399         return codecSettings-&gt;H264().keyFrameInterval;
400     }
</pre>
<hr />
<pre>
450             memcpy(encodedImage-&gt;_buffer + encodedImage-&gt;_length, &amp;map-&gt;data()[nal-&gt;sc_offset],
451                 sizeof(startCode) + nal-&gt;size);
452             encodedImage-&gt;_length += nal-&gt;size + sizeof(startCode);
453         }
454     }
455 
456     webrtc::SdpVideoFormat ConfigureSupportedCodec(GstElement*) final
457     {
458         // TODO- Create from encoder src pad caps template
459         return webrtc::SdpVideoFormat(cricket::kH264CodecName,
460             { { cricket::kH264FmtpProfileLevelId, cricket::kH264ProfileLevelConstrainedBaseline },
461                 { cricket::kH264FmtpLevelAsymmetryAllowed, &quot;1&quot; },
462                 { cricket::kH264FmtpPacketizationMode, &quot;1&quot; } });
463     }
464 
465     const gchar* Caps() final { return &quot;video/x-h264&quot;; }
466     const gchar* Name() final { return cricket::kH264CodecName; }
467     GstH264NalParser* m_parser;
468     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecH264; }
469 
<span class="line-modified">470     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer*) final</span>
471     {
<span class="line-modified">472         codecSpecificInfos-&gt;codecType = CodecType();</span>
<span class="line-modified">473         codecSpecificInfos-&gt;codec_name = ImplementationName();</span>
<span class="line-modified">474         webrtc::CodecSpecificInfoH264* h264Info = &amp;(codecSpecificInfos-&gt;codecSpecific.H264);</span>
475         h264Info-&gt;packetization_mode = packetizationMode;
476     }
477 
478     webrtc::H264PacketizationMode packetizationMode;
479 };
480 
481 class GStreamerVP8Encoder : public GStreamerVideoEncoder {
482 public:
483     GStreamerVP8Encoder() { }
484     GStreamerVP8Encoder(const webrtc::SdpVideoFormat&amp;) { }
485     const gchar* Caps() final { return &quot;video/x-vp8&quot;; }
486     const gchar* Name() final { return cricket::kVp8CodecName; }
487     webrtc::VideoCodecType CodecType() final { return webrtc::kVideoCodecVP8; }
488 
489     int KeyframeInterval(const webrtc::VideoCodec* codecSettings) final
490     {
491         return codecSettings-&gt;VP8().keyFrameInterval;
492     }
493 
<span class="line-modified">494     void PopulateCodecSpecific(webrtc::CodecSpecificInfo* codecSpecificInfos, GstBuffer* buffer) final</span>
495     {
<span class="line-modified">496         codecSpecificInfos-&gt;codecType = webrtc::kVideoCodecVP8;</span>
<span class="line-modified">497         codecSpecificInfos-&gt;codec_name = ImplementationName();</span>
<span class="line-modified">498         webrtc::CodecSpecificInfoVP8* vp8Info = &amp;(codecSpecificInfos-&gt;codecSpecific.VP8);</span>
499         vp8Info-&gt;temporalIdx = 0;
500 
501         vp8Info-&gt;keyIdx = webrtc::kNoKeyIdx;
502         vp8Info-&gt;nonReference = GST_BUFFER_FLAG_IS_SET(buffer, GST_BUFFER_FLAG_DELTA_UNIT);
503     }
504 };
505 
506 std::unique_ptr&lt;webrtc::VideoEncoder&gt; GStreamerVideoEncoderFactory::CreateVideoEncoder(const webrtc::SdpVideoFormat&amp; format)
507 {
508     if (format.name == cricket::kVp8CodecName) {
509         GRefPtr&lt;GstElement&gt; webrtcencoder = adoptGRef(GST_ELEMENT(g_object_ref_sink(gst_element_factory_make(&quot;webrtcvideoencoder&quot;, NULL))));
510         GRefPtr&lt;GstElement&gt; encoder = nullptr;
511 
512         g_object_set(webrtcencoder.get(), &quot;format&quot;, adoptGRef(gst_caps_from_string(&quot;video/x-vp8&quot;)).get(), NULL);
513         g_object_get(webrtcencoder.get(), &quot;encoder&quot;, &amp;encoder.outPtr(), NULL);
514 
515         if (encoder)
<span class="line-modified">516             return makeUnique&lt;GStreamerVP8Encoder&gt;(format);</span>
517 
518         GST_INFO(&quot;Using VP8 Encoder from LibWebRTC.&quot;);
<span class="line-modified">519         return makeUniqueWithoutFastMallocCheck&lt;webrtc::LibvpxVp8Encoder&gt;();</span>
520     }
521 
522     if (format.name == cricket::kH264CodecName)
<span class="line-modified">523         return makeUnique&lt;GStreamerH264Encoder&gt;(format);</span>
524 
525     return nullptr;
526 }
527 
528 GStreamerVideoEncoderFactory::GStreamerVideoEncoderFactory()
529 {
530     static std::once_flag debugRegisteredFlag;
531 
532     std::call_once(debugRegisteredFlag, [] {
533         GST_DEBUG_CATEGORY_INIT(webkit_webrtcenc_debug, &quot;webkitlibwebrtcvideoencoder&quot;, 0, &quot;WebKit WebRTC video encoder&quot;);
534         gst_element_register(nullptr, &quot;webrtcvideoencoder&quot;, GST_RANK_PRIMARY, GST_TYPE_WEBRTC_VIDEO_ENCODER);
535     });
536 }
537 
538 std::vector&lt;webrtc::SdpVideoFormat&gt; GStreamerVideoEncoderFactory::GetSupportedFormats() const
539 {
540     std::vector&lt;webrtc::SdpVideoFormat&gt; supportedCodecs;
541 
542     supportedCodecs.push_back(webrtc::SdpVideoFormat(cricket::kVp8CodecName));
543     GStreamerH264Encoder().AddCodecIfSupported(&amp;supportedCodecs);
</pre>
</td>
</tr>
</table>
<center><a href="GStreamerVideoEncoder.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../../index.html" target="_top">index</a> <a href="GStreamerVideoEncoderFactory.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>