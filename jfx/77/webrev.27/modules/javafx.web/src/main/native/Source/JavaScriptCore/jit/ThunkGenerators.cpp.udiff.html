<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Udiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/ThunkGenerators.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="ThunkGenerator.h.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="ThunkGenerators.h.udiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/ThunkGenerators.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-new-header">@@ -51,42 +51,42 @@</span>
          return;
      CCallHelpers::Jump isNonZero = jit.branchTestPtr(CCallHelpers::NonZero, pointerGPR);
      jit.abortWithReason(TGInvalidPointer);
      isNonZero.link(&amp;jit);
      jit.pushToSave(pointerGPR);
<span class="udiff-line-modified-removed">-     jit.untagPtr(pointerGPR, tag);</span>
<span class="udiff-line-modified-added">+     jit.untagPtr(tag, pointerGPR);</span>
      jit.load8(pointerGPR, pointerGPR);
      jit.popToRestore(pointerGPR);
  }
  
  // We will jump here if the JIT code tries to make a call, but the
  // linking helper (C++ code) decides to throw an exception instead.
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; throwExceptionFromCallSlowPathGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; throwExceptionFromCallSlowPathGenerator(VM&amp; vm)</span>
  {
      CCallHelpers jit;
  
      // The call pushed a return address, so we need to pop it back off to re-align the stack,
      // even though we won&#39;t use it.
      jit.preserveReturnAddressAfterCall(GPRInfo::nonPreservedNonReturnGPR);
  
<span class="udiff-line-modified-removed">-     jit.copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm-&gt;topEntryFrame);</span>
<span class="udiff-line-modified-added">+     jit.copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm.topEntryFrame);</span>
  
<span class="udiff-line-modified-removed">-     jit.setupArguments&lt;decltype(lookupExceptionHandler)&gt;(CCallHelpers::TrustedImmPtr(vm), GPRInfo::callFrameRegister);</span>
<span class="udiff-line-modified-added">+     jit.setupArguments&lt;decltype(lookupExceptionHandler)&gt;(CCallHelpers::TrustedImmPtr(&amp;vm), GPRInfo::callFrameRegister);</span>
      jit.move(CCallHelpers::TrustedImmPtr(tagCFunctionPtr&lt;OperationPtrTag&gt;(lookupExceptionHandler)), GPRInfo::nonArgGPR0);
      emitPointerValidation(jit, GPRInfo::nonArgGPR0, OperationPtrTag);
      jit.call(GPRInfo::nonArgGPR0, OperationPtrTag);
<span class="udiff-line-modified-removed">-     jit.jumpToExceptionHandler(*vm);</span>
<span class="udiff-line-modified-added">+     jit.jumpToExceptionHandler(vm);</span>
  
      LinkBuffer patchBuffer(jit, GLOBAL_THUNK_ID);
      return FINALIZE_CODE(patchBuffer, JITThunkPtrTag, &quot;Throw exception from call slow path thunk&quot;);
  }
  
<span class="udiff-line-modified-removed">- static void slowPathFor(CCallHelpers&amp; jit, VM* vm, Sprt_JITOperation_ECli slowPathFunction)</span>
<span class="udiff-line-modified-added">+ static void slowPathFor(CCallHelpers&amp; jit, VM&amp; vm, Sprt_JITOperation_ECli slowPathFunction)</span>
  {
<span class="udiff-line-modified-removed">-     jit.sanitizeStackInline(*vm, GPRInfo::nonArgGPR0);</span>
<span class="udiff-line-modified-added">+     jit.sanitizeStackInline(vm, GPRInfo::nonArgGPR0);</span>
      jit.emitFunctionPrologue();
<span class="udiff-line-modified-removed">-     jit.storePtr(GPRInfo::callFrameRegister, &amp;vm-&gt;topCallFrame);</span>
<span class="udiff-line-modified-added">+     jit.storePtr(GPRInfo::callFrameRegister, &amp;vm.topCallFrame);</span>
  #if OS(WINDOWS) &amp;&amp; CPU(X86_64)
      // Windows X86_64 needs some space pointed to by arg0 for return types larger than 64 bits.
      // Other argument values are shift by 1. Use space on the stack for our two return values.
      // Moving the stack down maxFrameExtentForSlowPathCall bytes gives us room for our 3 arguments
      // and space for the 16 byte return area.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -126,14 +126,14 @@</span>
  
      jit.preserveReturnAddressAfterCall(GPRInfo::nonPreservedNonReturnGPR);
      jit.prepareForTailCallSlow(GPRInfo::returnValueGPR);
  
      doNotTrash.link(&amp;jit);
<span class="udiff-line-modified-removed">-     jit.jump(GPRInfo::returnValueGPR, JSEntryPtrTag);</span>
<span class="udiff-line-modified-added">+     jit.farJump(GPRInfo::returnValueGPR, JSEntryPtrTag);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; linkCallThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; linkCallThunkGenerator(VM&amp; vm)</span>
  {
      // The return address is on the stack or in the link register. We will hence
      // save the return address to the call frame while we make a C++ function call
      // to perform linking and lazy compilation if necessary. We expect the callee
      // to be in regT0/regT1 (payload/tag), the CallFrame to have already
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -146,11 +146,11 @@</span>
      return FINALIZE_CODE(patchBuffer, JITThunkPtrTag, &quot;Link call slow path thunk&quot;);
  }
  
  // For closure optimizations, we only include calls, since if you&#39;re using closures for
  // object construction then you&#39;re going to lose big time anyway.
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; linkPolymorphicCallThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; linkPolymorphicCallThunkGenerator(VM&amp; vm)</span>
  {
      CCallHelpers jit;
  
      slowPathFor(jit, vm, operationLinkPolymorphicCall);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -160,11 +160,11 @@</span>
  
  // FIXME: We should distinguish between a megamorphic virtual call vs. a slow
  // path virtual call so that we can enable fast tail calls for megamorphic
  // virtual calls by using the shuffler.
  // https://bugs.webkit.org/show_bug.cgi?id=148831
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunkFor(VM* vm, CallLinkInfo&amp; callLinkInfo)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITStubRoutinePtrTag&gt; virtualThunkFor(VM&amp; vm, CallLinkInfo&amp; callLinkInfo)</span>
  {
      // The callee is in regT0 (for JSVALUE32_64, the tag is in regT1).
      // The return address is on the stack, or in the link register. We will hence
      // jump to the callee, or save the return address to the call frame while we
      // make a C++ function call to the appropriate JIT operation.
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -181,24 +181,21 @@</span>
  
      // FIXME: we should have a story for eliminating these checks. In many cases,
      // the DFG knows that the value is definitely a cell, or definitely a function.
  
  #if USE(JSVALUE64)
<span class="udiff-line-removed">-     GPRReg tagMaskRegister = GPRInfo::tagMaskRegister;</span>
      if (callLinkInfo.isTailCall()) {
          // Tail calls could have clobbered the GPRInfo::tagMaskRegister because they
          // restore callee saved registers before getthing here. So, let&#39;s materialize
          // the TagMask in a temp register and use the temp instead.
<span class="udiff-line-modified-removed">-         tagMaskRegister = GPRInfo::regT4;</span>
<span class="udiff-line-modified-removed">-         jit.move(CCallHelpers::TrustedImm64(TagMask), tagMaskRegister);</span>
<span class="udiff-line-modified-removed">-     }</span>
<span class="udiff-line-removed">-     slowCase.append(</span>
<span class="udiff-line-removed">-         jit.branchTest64(CCallHelpers::NonZero, GPRInfo::regT0, tagMaskRegister));</span>
<span class="udiff-line-modified-added">+         slowCase.append(jit.branchIfNotCell(GPRInfo::regT0, DoNotHaveTagRegisters));</span>
<span class="udiff-line-modified-added">+     } else</span>
<span class="udiff-line-modified-added">+         slowCase.append(jit.branchIfNotCell(GPRInfo::regT0));</span>
  #else
      slowCase.append(jit.branchIfNotCell(GPRInfo::regT1));
  #endif
<span class="udiff-line-modified-removed">-     auto notJSFunction = jit.branchIfNotType(GPRInfo::regT0, JSFunctionType);</span>
<span class="udiff-line-modified-added">+     auto notJSFunction = jit.branchIfNotFunction(GPRInfo::regT0);</span>
  
      // Now we know we have a JSFunction.
  
      jit.loadPtr(
          CCallHelpers::Address(GPRInfo::regT0, JSFunction::offsetOfExecutable()),
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -218,15 +215,15 @@</span>
      emitPointerValidation(jit, GPRInfo::regT4, JSEntryPtrTag);
      if (callLinkInfo.isTailCall()) {
          jit.preserveReturnAddressAfterCall(GPRInfo::regT0);
          jit.prepareForTailCallSlow(GPRInfo::regT4);
      }
<span class="udiff-line-modified-removed">-     jit.jump(GPRInfo::regT4, JSEntryPtrTag);</span>
<span class="udiff-line-modified-added">+     jit.farJump(GPRInfo::regT4, JSEntryPtrTag);</span>
  
      notJSFunction.link(&amp;jit);
      slowCase.append(jit.branchIfNotType(GPRInfo::regT0, InternalFunctionType));
<span class="udiff-line-modified-removed">-     void* executableAddress = vm-&gt;getCTIInternalFunctionTrampolineFor(callLinkInfo.specializationKind()).executableAddress();</span>
<span class="udiff-line-modified-added">+     void* executableAddress = vm.getCTIInternalFunctionTrampolineFor(callLinkInfo.specializationKind()).executableAddress();</span>
      jit.move(CCallHelpers::TrustedImmPtr(executableAddress), GPRInfo::regT4);
      jit.jump().linkTo(callCode, &amp;jit);
  
      slowCase.link(&amp;jit);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -241,18 +238,18 @@</span>
  }
  
  enum ThunkEntryType { EnterViaCall, EnterViaJumpWithSavedTags, EnterViaJumpWithoutSavedTags };
  enum class ThunkFunctionType { JSFunction, InternalFunction };
  
<span class="udiff-line-modified-removed">- static MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeForGenerator(VM* vm, ThunkFunctionType thunkFunctionType, CodeSpecializationKind kind, ThunkEntryType entryType = EnterViaCall)</span>
<span class="udiff-line-modified-added">+ static MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeForGenerator(VM&amp; vm, ThunkFunctionType thunkFunctionType, CodeSpecializationKind kind, ThunkEntryType entryType = EnterViaCall)</span>
  {
      // FIXME: This should be able to log ShadowChicken prologue packets.
      // https://bugs.webkit.org/show_bug.cgi?id=155689
  
      int executableOffsetToFunction = NativeExecutable::offsetOfNativeFunctionFor(kind);
  
<span class="udiff-line-modified-removed">-     JSInterfaceJIT jit(vm);</span>
<span class="udiff-line-modified-added">+     JSInterfaceJIT jit(&amp;vm);</span>
  
      switch (entryType) {
      case EnterViaCall:
          jit.emitFunctionPrologue();
          break;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -267,11 +264,11 @@</span>
          jit.move(JSInterfaceJIT::framePointerRegister, JSInterfaceJIT::stackPointerRegister);
          break;
      }
  
      jit.emitPutToCallFrameHeader(0, CallFrameSlot::codeBlock);
<span class="udiff-line-modified-removed">-     jit.storePtr(JSInterfaceJIT::callFrameRegister, &amp;vm-&gt;topCallFrame);</span>
<span class="udiff-line-modified-added">+     jit.storePtr(JSInterfaceJIT::callFrameRegister, &amp;vm.topCallFrame);</span>
  
  #if CPU(X86)
      // Calling convention:      f(ecx, edx, ...);
      // Host function signature: f(ExecState*);
      jit.move(JSInterfaceJIT::callFrameRegister, X86Registers::ecx);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -364,28 +361,28 @@</span>
      abortWithReason(TGNotSupported);
  #endif
  
      // Check for an exception
  #if USE(JSVALUE64)
<span class="udiff-line-modified-removed">-     jit.load64(vm-&gt;addressOfException(), JSInterfaceJIT::regT2);</span>
<span class="udiff-line-modified-added">+     jit.load64(vm.addressOfException(), JSInterfaceJIT::regT2);</span>
      JSInterfaceJIT::Jump exceptionHandler = jit.branchTest64(JSInterfaceJIT::NonZero, JSInterfaceJIT::regT2);
  #else
      JSInterfaceJIT::Jump exceptionHandler = jit.branch32(
          JSInterfaceJIT::NotEqual,
<span class="udiff-line-modified-removed">-         JSInterfaceJIT::AbsoluteAddress(vm-&gt;addressOfException()),</span>
<span class="udiff-line-modified-added">+         JSInterfaceJIT::AbsoluteAddress(vm.addressOfException()),</span>
          JSInterfaceJIT::TrustedImm32(0));
  #endif
  
      jit.emitFunctionEpilogue();
      // Return.
      jit.ret();
  
      // Handle an exception
      exceptionHandler.link(&amp;jit);
  
<span class="udiff-line-modified-removed">-     jit.copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm-&gt;topEntryFrame);</span>
<span class="udiff-line-modified-removed">-     jit.storePtr(JSInterfaceJIT::callFrameRegister, &amp;vm-&gt;topCallFrame);</span>
<span class="udiff-line-modified-added">+     jit.copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm.topEntryFrame);</span>
<span class="udiff-line-modified-added">+     jit.storePtr(JSInterfaceJIT::callFrameRegister, &amp;vm.topCallFrame);</span>
  
  #if CPU(X86) &amp;&amp; USE(JSVALUE32_64)
      jit.subPtr(JSInterfaceJIT::TrustedImm32(4), JSInterfaceJIT::stackPointerRegister);
      jit.move(JSInterfaceJIT::callFrameRegister, JSInterfaceJIT::regT0);
      jit.push(JSInterfaceJIT::regT0);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -402,49 +399,49 @@</span>
      jit.addPtr(JSInterfaceJIT::TrustedImm32(8), JSInterfaceJIT::stackPointerRegister);
  #elif OS(WINDOWS)
      jit.addPtr(JSInterfaceJIT::TrustedImm32(4 * sizeof(int64_t)), JSInterfaceJIT::stackPointerRegister);
  #endif
  
<span class="udiff-line-modified-removed">-     jit.jumpToExceptionHandler(*vm);</span>
<span class="udiff-line-modified-added">+     jit.jumpToExceptionHandler(vm);</span>
  
      LinkBuffer patchBuffer(jit, GLOBAL_THUNK_ID);
      return FINALIZE_CODE(patchBuffer, JITThunkPtrTag, &quot;%s %s%s trampoline&quot;, thunkFunctionType == ThunkFunctionType::JSFunction ? &quot;native&quot; : &quot;internal&quot;, entryType == EnterViaJumpWithSavedTags ? &quot;Tail With Saved Tags &quot; : entryType == EnterViaJumpWithoutSavedTags ? &quot;Tail Without Saved Tags &quot; : &quot;&quot;, toCString(kind).data());
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeCallGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeCallGenerator(VM&amp; vm)</span>
  {
      return nativeForGenerator(vm, ThunkFunctionType::JSFunction, CodeForCall);
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeTailCallGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeTailCallGenerator(VM&amp; vm)</span>
  {
      return nativeForGenerator(vm, ThunkFunctionType::JSFunction, CodeForCall, EnterViaJumpWithSavedTags);
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeTailCallWithoutSavedTagsGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeTailCallWithoutSavedTagsGenerator(VM&amp; vm)</span>
  {
      return nativeForGenerator(vm, ThunkFunctionType::JSFunction, CodeForCall, EnterViaJumpWithoutSavedTags);
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeConstructGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; nativeConstructGenerator(VM&amp; vm)</span>
  {
      return nativeForGenerator(vm, ThunkFunctionType::JSFunction, CodeForConstruct);
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; internalFunctionCallGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; internalFunctionCallGenerator(VM&amp; vm)</span>
  {
      return nativeForGenerator(vm, ThunkFunctionType::InternalFunction, CodeForCall);
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; internalFunctionConstructGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; internalFunctionConstructGenerator(VM&amp; vm)</span>
  {
      return nativeForGenerator(vm, ThunkFunctionType::InternalFunction, CodeForConstruct);
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; arityFixupGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; arityFixupGenerator(VM&amp; vm)</span>
  {
<span class="udiff-line-modified-removed">-     JSInterfaceJIT jit(vm);</span>
<span class="udiff-line-modified-added">+     JSInterfaceJIT jit(&amp;vm);</span>
  
      // We enter with fixup count in argumentGPR0
      // We have the guarantee that a0, a1, a2, t3, t4 and t5 (or t0 for Windows) are all distinct :-)
  #if USE(JSVALUE64)
  #if OS(WINDOWS)
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -454,17 +451,17 @@</span>
  #endif
  #  if CPU(X86_64)
      jit.pop(JSInterfaceJIT::regT4);
  #  endif
      jit.tagReturnAddress();
<span class="udiff-line-modified-removed">- #if CPU(ARM64) &amp;&amp; USE(POINTER_PROFILING)</span>
<span class="udiff-line-modified-added">+ #if CPU(ARM64E)</span>
      jit.loadPtr(JSInterfaceJIT::Address(GPRInfo::callFrameRegister, CallFrame::returnPCOffset()), GPRInfo::regT3);
      jit.addPtr(JSInterfaceJIT::TrustedImm32(sizeof(CallerFrameAndPC)), GPRInfo::callFrameRegister, extraTemp);
<span class="udiff-line-modified-removed">-     jit.untagPtr(GPRInfo::regT3, extraTemp);</span>
<span class="udiff-line-modified-added">+     jit.untagPtr(extraTemp, GPRInfo::regT3);</span>
      PtrTag tempReturnPCTag = static_cast&lt;PtrTag&gt;(random());
      jit.move(JSInterfaceJIT::TrustedImmPtr(tempReturnPCTag), extraTemp);
<span class="udiff-line-modified-removed">-     jit.tagPtr(GPRInfo::regT3, extraTemp);</span>
<span class="udiff-line-modified-added">+     jit.tagPtr(extraTemp, GPRInfo::regT3);</span>
      jit.storePtr(GPRInfo::regT3, JSInterfaceJIT::Address(GPRInfo::callFrameRegister, CallFrame::returnPCOffset()));
  #endif
      jit.move(JSInterfaceJIT::callFrameRegister, JSInterfaceJIT::regT3);
      jit.load32(JSInterfaceJIT::addressFor(CallFrameSlot::argumentCount), JSInterfaceJIT::argumentGPR2);
      jit.add32(JSInterfaceJIT::TrustedImm32(CallFrame::headerSizeInRegisters), JSInterfaceJIT::argumentGPR2);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -510,16 +507,16 @@</span>
      jit.addPtr(JSInterfaceJIT::TrustedImm32(8), JSInterfaceJIT::regT3);
      jit.branchAdd32(MacroAssembler::NonZero, JSInterfaceJIT::TrustedImm32(1), JSInterfaceJIT::argumentGPR2).linkTo(fillUndefinedLoop, &amp;jit);
  
      done.link(&amp;jit);
  
<span class="udiff-line-modified-removed">- #if CPU(ARM64) &amp;&amp; USE(POINTER_PROFILING)</span>
<span class="udiff-line-modified-added">+ #if CPU(ARM64E)</span>
      jit.loadPtr(JSInterfaceJIT::Address(GPRInfo::callFrameRegister, CallFrame::returnPCOffset()), GPRInfo::regT3);
      jit.move(JSInterfaceJIT::TrustedImmPtr(tempReturnPCTag), extraTemp);
<span class="udiff-line-modified-removed">-     jit.untagPtr(GPRInfo::regT3, extraTemp);</span>
<span class="udiff-line-modified-added">+     jit.untagPtr(extraTemp, GPRInfo::regT3);</span>
      jit.addPtr(JSInterfaceJIT::TrustedImm32(sizeof(CallerFrameAndPC)), GPRInfo::callFrameRegister, extraTemp);
<span class="udiff-line-modified-removed">-     jit.tagPtr(GPRInfo::regT3, extraTemp);</span>
<span class="udiff-line-modified-added">+     jit.tagPtr(extraTemp, GPRInfo::regT3);</span>
      jit.storePtr(GPRInfo::regT3, JSInterfaceJIT::Address(GPRInfo::callFrameRegister, CallFrame::returnPCOffset()));
  #endif
  
  #  if CPU(X86_64)
      jit.push(JSInterfaceJIT::regT4);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -591,21 +588,21 @@</span>
  
      LinkBuffer patchBuffer(jit, GLOBAL_THUNK_ID);
      return FINALIZE_CODE(patchBuffer, JITThunkPtrTag, &quot;fixup arity&quot;);
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; unreachableGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; unreachableGenerator(VM&amp; vm)</span>
  {
<span class="udiff-line-modified-removed">-     JSInterfaceJIT jit(vm);</span>
<span class="udiff-line-modified-added">+     JSInterfaceJIT jit(&amp;vm);</span>
  
      jit.breakpoint();
  
      LinkBuffer patchBuffer(jit, GLOBAL_THUNK_ID);
      return FINALIZE_CODE(patchBuffer, JITThunkPtrTag, &quot;unreachable thunk&quot;);
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; stringGetByValGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; stringGetByValGenerator(VM&amp; vm)</span>
  {
      // regT0 is JSString*, and regT1 (64bit) or regT2 (32bit) is int index.
      // Return regT0 = result JSString* if succeeds. Otherwise, return regT0 = 0.
  #if USE(JSVALUE64)
      GPRReg stringGPR = GPRInfo::regT0;
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -615,11 +612,11 @@</span>
      GPRReg stringGPR = GPRInfo::regT0;
      GPRReg indexGPR = GPRInfo::regT2;
      GPRReg scratchGPR = GPRInfo::regT1;
  #endif
  
<span class="udiff-line-modified-removed">-     JSInterfaceJIT jit(vm);</span>
<span class="udiff-line-modified-added">+     JSInterfaceJIT jit(&amp;vm);</span>
      JSInterfaceJIT::JumpList failures;
      jit.tagReturnAddress();
  
      // Load string length to regT2, and start the process of loading the data pointer into regT0
      jit.loadPtr(JSInterfaceJIT::Address(stringGPR, JSString::offsetOfValue()), stringGPR);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -641,11 +638,11 @@</span>
      is16Bit.link(&amp;jit);
      jit.load16(JSInterfaceJIT::BaseIndex(stringGPR, indexGPR, JSInterfaceJIT::TimesTwo, 0), stringGPR);
      cont8Bit.link(&amp;jit);
  
      failures.append(jit.branch32(JSInterfaceJIT::Above, stringGPR, JSInterfaceJIT::TrustedImm32(maxSingleCharacterString)));
<span class="udiff-line-modified-removed">-     jit.move(JSInterfaceJIT::TrustedImmPtr(vm-&gt;smallStrings.singleCharacterStrings()), indexGPR);</span>
<span class="udiff-line-modified-added">+     jit.move(JSInterfaceJIT::TrustedImmPtr(vm.smallStrings.singleCharacterStrings()), indexGPR);</span>
      jit.loadPtr(JSInterfaceJIT::BaseIndex(indexGPR, stringGPR, JSInterfaceJIT::ScalePtr, 0), stringGPR);
      jit.ret();
  
      failures.link(&amp;jit);
      jit.move(JSInterfaceJIT::TrustedImm32(0), stringGPR);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -683,46 +680,46 @@</span>
      is16Bit.link(&amp;jit);
      jit.load16(MacroAssembler::BaseIndex(SpecializedThunkJIT::regT0, SpecializedThunkJIT::regT1, MacroAssembler::TimesTwo, 0), SpecializedThunkJIT::regT0);
      cont8Bit.link(&amp;jit);
  }
  
<span class="udiff-line-modified-removed">- static void charToString(SpecializedThunkJIT&amp; jit, VM* vm, MacroAssembler::RegisterID src, MacroAssembler::RegisterID dst, MacroAssembler::RegisterID scratch)</span>
<span class="udiff-line-modified-added">+ static void charToString(SpecializedThunkJIT&amp; jit, VM&amp; vm, MacroAssembler::RegisterID src, MacroAssembler::RegisterID dst, MacroAssembler::RegisterID scratch)</span>
  {
      jit.appendFailure(jit.branch32(MacroAssembler::Above, src, MacroAssembler::TrustedImm32(maxSingleCharacterString)));
<span class="udiff-line-modified-removed">-     jit.move(MacroAssembler::TrustedImmPtr(vm-&gt;smallStrings.singleCharacterStrings()), scratch);</span>
<span class="udiff-line-modified-added">+     jit.move(MacroAssembler::TrustedImmPtr(vm.smallStrings.singleCharacterStrings()), scratch);</span>
      jit.loadPtr(MacroAssembler::BaseIndex(scratch, src, MacroAssembler::ScalePtr, 0), dst);
      jit.appendFailure(jit.branchTestPtr(MacroAssembler::Zero, dst));
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; charCodeAtThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; charCodeAtThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      stringCharLoad(jit);
      jit.returnInt32(SpecializedThunkJIT::regT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;charCodeAt&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;charCodeAt&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; charAtThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; charAtThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      stringCharLoad(jit);
      charToString(jit, vm, SpecializedThunkJIT::regT0, SpecializedThunkJIT::regT0, SpecializedThunkJIT::regT1);
      jit.returnJSCell(SpecializedThunkJIT::regT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;charAt&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;charAt&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; fromCharCodeThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; fromCharCodeThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      // load char code
      jit.loadInt32Argument(0, SpecializedThunkJIT::regT0);
      charToString(jit, vm, SpecializedThunkJIT::regT0, SpecializedThunkJIT::regT0, SpecializedThunkJIT::regT1);
      jit.returnJSCell(SpecializedThunkJIT::regT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;fromCharCode&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;fromCharCode&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; clz32ThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; clz32ThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      MacroAssembler::Jump nonIntArgJump;
      jit.loadInt32Argument(0, SpecializedThunkJIT::regT0, nonIntArgJump);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -736,23 +733,23 @@</span>
          jit.branchTruncateDoubleToInt32(SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0, SpecializedThunkJIT::BranchIfTruncateSuccessful).linkTo(convertedArgumentReentry, &amp;jit);
          jit.appendFailure(jit.jump());
      } else
          jit.appendFailure(nonIntArgJump);
  
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;clz32&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;clz32&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; sqrtThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; sqrtThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      if (!jit.supportsFloatingPointSqrt())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
  
      jit.loadDoubleArgument(0, SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0);
      jit.sqrtDouble(SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::fpRegT0);
      jit.returnDouble(SpecializedThunkJIT::fpRegT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;sqrt&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;sqrt&quot;);</span>
  }
  
  
  #define UnaryDoubleOpWrapper(function) function##Wrapper
  enum MathThunkCallingConvention { };
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -899,16 +896,16 @@</span>
  defineUnaryDoubleOpWrapper(ceil);
  defineUnaryDoubleOpWrapper(trunc);
  
  static const double halfConstant = 0.5;
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; floorThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; floorThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      MacroAssembler::Jump nonIntJump;
      if (!UnaryDoubleOpWrapper(floor) || !jit.supportsFloatingPoint())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
      jit.loadInt32Argument(0, SpecializedThunkJIT::regT0, nonIntJump);
      jit.returnInt32(SpecializedThunkJIT::regT0);
      nonIntJump.link(&amp;jit);
      jit.loadDoubleArgument(0, SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -917,11 +914,11 @@</span>
          jit.floorDouble(SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::fpRegT0);
          jit.branchConvertDoubleToInt32(SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0, doubleResult, SpecializedThunkJIT::fpRegT1);
          jit.returnInt32(SpecializedThunkJIT::regT0);
          doubleResult.link(&amp;jit);
          jit.returnDouble(SpecializedThunkJIT::fpRegT0);
<span class="udiff-line-modified-removed">-         return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;floor&quot;);</span>
<span class="udiff-line-modified-added">+         return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;floor&quot;);</span>
      }
  
      SpecializedThunkJIT::Jump intResult;
      SpecializedThunkJIT::JumpList doubleResult;
      if (jit.supportsFloatingPointTruncate()) {
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -939,18 +936,18 @@</span>
      if (jit.supportsFloatingPointTruncate())
          intResult.link(&amp;jit);
      jit.returnInt32(SpecializedThunkJIT::regT0);
      doubleResult.link(&amp;jit);
      jit.returnDouble(SpecializedThunkJIT::fpRegT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;floor&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;floor&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; ceilThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; ceilThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      if (!UnaryDoubleOpWrapper(ceil) || !jit.supportsFloatingPoint())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
      MacroAssembler::Jump nonIntJump;
      jit.loadInt32Argument(0, SpecializedThunkJIT::regT0, nonIntJump);
      jit.returnInt32(SpecializedThunkJIT::regT0);
      nonIntJump.link(&amp;jit);
      jit.loadDoubleArgument(0, SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -962,18 +959,18 @@</span>
      SpecializedThunkJIT::JumpList doubleResult;
      jit.branchConvertDoubleToInt32(SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0, doubleResult, SpecializedThunkJIT::fpRegT1);
      jit.returnInt32(SpecializedThunkJIT::regT0);
      doubleResult.link(&amp;jit);
      jit.returnDouble(SpecializedThunkJIT::fpRegT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;ceil&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;ceil&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; truncThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; truncThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      if (!UnaryDoubleOpWrapper(trunc) || !jit.supportsFloatingPoint())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
      MacroAssembler::Jump nonIntJump;
      jit.loadInt32Argument(0, SpecializedThunkJIT::regT0, nonIntJump);
      jit.returnInt32(SpecializedThunkJIT::regT0);
      nonIntJump.link(&amp;jit);
      jit.loadDoubleArgument(0, SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -985,18 +982,18 @@</span>
      SpecializedThunkJIT::JumpList doubleResult;
      jit.branchConvertDoubleToInt32(SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0, doubleResult, SpecializedThunkJIT::fpRegT1);
      jit.returnInt32(SpecializedThunkJIT::regT0);
      doubleResult.link(&amp;jit);
      jit.returnDouble(SpecializedThunkJIT::fpRegT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;trunc&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;trunc&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; roundThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; roundThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      if (!UnaryDoubleOpWrapper(jsRound) || !jit.supportsFloatingPoint())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
      MacroAssembler::Jump nonIntJump;
      jit.loadInt32Argument(0, SpecializedThunkJIT::regT0, nonIntJump);
      jit.returnInt32(SpecializedThunkJIT::regT0);
      nonIntJump.link(&amp;jit);
      jit.loadDoubleArgument(0, SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1019,44 +1016,44 @@</span>
      if (jit.supportsFloatingPointTruncate())
          intResult.link(&amp;jit);
      jit.returnInt32(SpecializedThunkJIT::regT0);
      doubleResult.link(&amp;jit);
      jit.returnDouble(SpecializedThunkJIT::fpRegT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;round&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;round&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; expThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; expThunkGenerator(VM&amp; vm)</span>
  {
      if (!UnaryDoubleOpWrapper(exp))
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
      SpecializedThunkJIT jit(vm, 1);
      if (!jit.supportsFloatingPoint())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
      jit.loadDoubleArgument(0, SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0);
      jit.callDoubleToDoublePreservingReturn(UnaryDoubleOpWrapper(exp));
      jit.returnDouble(SpecializedThunkJIT::fpRegT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;exp&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;exp&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; logThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; logThunkGenerator(VM&amp; vm)</span>
  {
      if (!UnaryDoubleOpWrapper(log))
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
      SpecializedThunkJIT jit(vm, 1);
      if (!jit.supportsFloatingPoint())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
      jit.loadDoubleArgument(0, SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0);
      jit.callDoubleToDoublePreservingReturn(UnaryDoubleOpWrapper(log));
      jit.returnDouble(SpecializedThunkJIT::fpRegT0);
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;log&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;log&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; absThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; absThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 1);
      if (!jit.supportsFloatingPointAbs())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
  
  #if USE(JSVALUE64)
      unsigned virtualRegisterIndex = CallFrame::argumentOffset(0);
      jit.load64(AssemblyHelpers::addressFor(virtualRegisterIndex), GPRInfo::regT0);
      auto notInteger = jit.branchIfNotInt32(GPRInfo::regT0);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1102,14 +1099,14 @@</span>
      // Shame about the double int conversion here.
      jit.loadDoubleArgument(0, SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT0);
      jit.absDouble(SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::fpRegT1);
      jit.returnDouble(SpecializedThunkJIT::fpRegT1);
  #endif
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;abs&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;abs&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; imulThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; imulThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 2);
      MacroAssembler::Jump nonIntArg0Jump;
      jit.loadInt32Argument(0, SpecializedThunkJIT::regT0, nonIntArg0Jump);
      SpecializedThunkJIT::Label doneLoadingArg0(&amp;jit);
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1133,30 +1130,30 @@</span>
          jit.branchTruncateDoubleToInt32(SpecializedThunkJIT::fpRegT0, SpecializedThunkJIT::regT1, SpecializedThunkJIT::BranchIfTruncateSuccessful).linkTo(doneLoadingArg1, &amp;jit);
          jit.appendFailure(jit.jump());
      } else
          jit.appendFailure(nonIntArg1Jump);
  
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;imul&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;imul&quot;);</span>
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; randomThunkGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; randomThunkGenerator(VM&amp; vm)</span>
  {
      SpecializedThunkJIT jit(vm, 0);
      if (!jit.supportsFloatingPoint())
<span class="udiff-line-modified-removed">-         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+         return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
  
  #if USE(JSVALUE64)
<span class="udiff-line-modified-removed">-     jit.emitRandomThunk(*vm, SpecializedThunkJIT::regT0, SpecializedThunkJIT::regT1, SpecializedThunkJIT::regT2, SpecializedThunkJIT::regT3, SpecializedThunkJIT::fpRegT0);</span>
<span class="udiff-line-modified-added">+     jit.emitRandomThunk(vm, SpecializedThunkJIT::regT0, SpecializedThunkJIT::regT1, SpecializedThunkJIT::regT2, SpecializedThunkJIT::regT3, SpecializedThunkJIT::fpRegT0);</span>
      jit.returnDouble(SpecializedThunkJIT::fpRegT0);
  
<span class="udiff-line-modified-removed">-     return jit.finalize(vm-&gt;jitStubs-&gt;ctiNativeTailCall(vm), &quot;random&quot;);</span>
<span class="udiff-line-modified-added">+     return jit.finalize(vm.jitStubs-&gt;ctiNativeTailCall(vm), &quot;random&quot;);</span>
  #else
<span class="udiff-line-modified-removed">-     return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm-&gt;jitStubs-&gt;ctiNativeCall(vm));</span>
<span class="udiff-line-modified-added">+     return MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt;::createSelfManagedCodeRef(vm.jitStubs-&gt;ctiNativeCall(vm));</span>
  #endif
  }
  
<span class="udiff-line-modified-removed">- MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; boundThisNoArgsFunctionCallGenerator(VM* vm)</span>
<span class="udiff-line-modified-added">+ MacroAssemblerCodeRef&lt;JITThunkPtrTag&gt; boundThisNoArgsFunctionCallGenerator(VM&amp; vm)</span>
  {
      CCallHelpers jit;
  
      jit.emitFunctionPrologue();
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1190,14 +1187,27 @@</span>
      jit.and32(CCallHelpers::TrustedImm32(-stackAlignmentBytes()), GPRInfo::regT2);
  
      if (extraStackNeeded)
          jit.add32(CCallHelpers::TrustedImm32(extraStackNeeded), GPRInfo::regT2);
  
<span class="udiff-line-modified-removed">-     // At this point regT1 has the actual argument count and regT2 has the amount of stack we will</span>
<span class="udiff-line-modified-removed">-     // need.</span>
<span class="udiff-line-modified-added">+     // At this point regT1 has the actual argument count and regT2 has the amount of stack we will need.</span>
<span class="udiff-line-modified-added">+     // Check to see if we have enough stack space.</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     jit.negPtr(GPRInfo::regT2);</span>
<span class="udiff-line-added">+     jit.addPtr(CCallHelpers::stackPointerRegister, GPRInfo::regT2);</span>
<span class="udiff-line-added">+     CCallHelpers::Jump haveStackSpace = jit.branchPtr(CCallHelpers::BelowOrEqual, CCallHelpers::AbsoluteAddress(vm.addressOfSoftStackLimit()), GPRInfo::regT2);</span>
<span class="udiff-line-added">+ </span>
<span class="udiff-line-added">+     // Throw Stack Overflow exception</span>
<span class="udiff-line-added">+     jit.copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm.topEntryFrame);</span>
<span class="udiff-line-added">+     jit.setupArguments&lt;decltype(throwStackOverflowErrorFromThunk)&gt;(CCallHelpers::TrustedImmPtr(&amp;vm), GPRInfo::callFrameRegister);</span>
<span class="udiff-line-added">+     jit.move(CCallHelpers::TrustedImmPtr(tagCFunctionPtr&lt;OperationPtrTag&gt;(throwStackOverflowErrorFromThunk)), GPRInfo::nonArgGPR0);</span>
<span class="udiff-line-added">+     emitPointerValidation(jit, GPRInfo::nonArgGPR0, OperationPtrTag);</span>
<span class="udiff-line-added">+     jit.call(GPRInfo::nonArgGPR0, OperationPtrTag);</span>
<span class="udiff-line-added">+     jit.jumpToExceptionHandler(vm);</span>
  
<span class="udiff-line-modified-removed">-     jit.subPtr(GPRInfo::regT2, CCallHelpers::stackPointerRegister);</span>
<span class="udiff-line-modified-added">+     haveStackSpace.link(&amp;jit);</span>
<span class="udiff-line-added">+     jit.move(GPRInfo::regT2, CCallHelpers::stackPointerRegister);</span>
  
      // Do basic callee frame setup, including &#39;this&#39;.
  
      jit.loadCell(CCallHelpers::addressFor(CallFrameSlot::callee), GPRInfo::regT3);
  
</pre>
<hr />
<pre>
<span class="line-new-header">@@ -1238,11 +1248,11 @@</span>
  
      jit.emitFunctionEpilogue();
      jit.ret();
  
      LinkBuffer linkBuffer(jit, GLOBAL_THUNK_ID);
<span class="udiff-line-modified-removed">-     linkBuffer.link(noCode, CodeLocationLabel&lt;JITThunkPtrTag&gt;(vm-&gt;jitStubs-&gt;ctiNativeTailCallWithoutSavedTags(vm)));</span>
<span class="udiff-line-modified-added">+     linkBuffer.link(noCode, CodeLocationLabel&lt;JITThunkPtrTag&gt;(vm.jitStubs-&gt;ctiNativeTailCallWithoutSavedTags(vm)));</span>
      return FINALIZE_CODE(
          linkBuffer, JITThunkPtrTag, &quot;Specialized thunk for bound function calls with no arguments&quot;);
  }
  
  } // namespace JSC
</pre>
<center><a href="ThunkGenerator.h.udiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="ThunkGenerators.h.udiff.html" target="_top">next &gt;</a></center>  </body>
</html>