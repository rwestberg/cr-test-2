<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>New modules/javafx.web/src/main/native/Source/JavaScriptCore/offlineasm/arm64.rb</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
  <body>
    <pre>
   1 # Copyright (C) 2011-2019 Apple Inc. All rights reserved.
   2 # Copyright (C) 2014 University of Szeged. All rights reserved.
   3 #
   4 # Redistribution and use in source and binary forms, with or without
   5 # modification, are permitted provided that the following conditions
   6 # are met:
   7 # 1. Redistributions of source code must retain the above copyright
   8 #    notice, this list of conditions and the following disclaimer.
   9 # 2. Redistributions in binary form must reproduce the above copyright
  10 #    notice, this list of conditions and the following disclaimer in the
  11 #    documentation and/or other materials provided with the distribution.
  12 #
  13 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  14 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  15 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  17 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  18 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  19 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  20 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  21 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  22 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  23 # THE POSSIBILITY OF SUCH DAMAGE.
  24 
  25 require &quot;ast&quot;
  26 require &quot;opt&quot;
  27 require &quot;risc&quot;
  28 
  29 # Naming conventions:
  30 #
  31 # x&lt;number&gt;  =&gt; GPR. This is both the generic name of the register, and the name used
  32 #               to indicate that the register is used in 64-bit mode.
  33 # w&lt;number&gt;  =&gt; GPR in 32-bit mode. This is the low 32-bits of the GPR. If it is
  34 #               mutated then the high 32-bit part of the register is zero filled.
  35 # q&lt;number&gt;  =&gt; FPR. This is the generic name of the register.
  36 # d&lt;number&gt;  =&gt; FPR used as an IEEE 64-bit binary floating point number (i.e. double).
  37 #
  38 # GPR conventions, to match the baseline JIT:
  39 #
  40 #  x0  =&gt; t0, a0, r0
  41 #  x1  =&gt; t1, a1, r1
  42 #  x2  =&gt; t2, a2
  43 #  x3  =&gt; t3, a3
  44 #  x4  =&gt; t4
  45 #  x5  =&gt; t5
  46 # x13  =&gt;                  (scratch)
  47 # x16  =&gt;                  (scratch)
  48 # x17  =&gt;                  (scratch)
  49 # x26  =&gt;             csr0 (PB)
  50 # x27  =&gt;             csr1 (tagTypeNumber)
  51 # x28  =&gt;             csr2 (tagMask)
  52 # x29  =&gt; cfr
  53 #  sp  =&gt; sp
  54 #  lr  =&gt; lr
  55 #
  56 # FPR conventions, to match the baseline JIT:
  57 #
  58 #  q0  =&gt; ft0, fa0, fr
  59 #  q1  =&gt; ft1, fa1
  60 #  q2  =&gt; ft2, fa2
  61 #  q3  =&gt; ft3, fa3
  62 #  q4  =&gt; ft4          (unused in baseline)
  63 #  q5  =&gt; ft5          (unused in baseline)
  64 #  q8  =&gt; csfr0        (Only the lower 64 bits)
  65 #  q9  =&gt; csfr1        (Only the lower 64 bits)
  66 # q10  =&gt; csfr2        (Only the lower 64 bits)
  67 # q11  =&gt; csfr3        (Only the lower 64 bits)
  68 # q12  =&gt; csfr4        (Only the lower 64 bits)
  69 # q13  =&gt; csfr5        (Only the lower 64 bits)
  70 # q14  =&gt; csfr6        (Only the lower 64 bits)
  71 # q15  =&gt; csfr7        (Only the lower 64 bits)
  72 # q31  =&gt; scratch
  73 
  74 def arm64GPRName(name, kind)
  75     raise &quot;bad GPR name #{name}&quot; unless name =~ /^x/
  76     number = name[1..-1]
  77     case kind
  78     when :word
  79         &quot;w&quot; + number
  80     when :ptr
  81         prefix = $currentSettings[&quot;ADDRESS64&quot;] ? &quot;x&quot; : &quot;w&quot;
  82         prefix + number
  83     when :quad
  84         &quot;x&quot; + number
  85     else
  86         raise &quot;Wrong kind: #{kind}&quot;
  87     end
  88 end
  89 
  90 def arm64FPRName(name, kind)
  91     raise &quot;bad FPR kind #{kind}&quot; unless kind == :double
  92     raise &quot;bad FPR name #{name}&quot; unless name =~ /^q/
  93     &quot;d&quot; + name[1..-1]
  94 end
  95 
  96 class SpecialRegister
  97     def arm64Operand(kind)
  98         case @name
  99         when /^x/
 100             arm64GPRName(@name, kind)
 101         when /^q/
 102             arm64FPRName(@name, kind)
 103         else
 104             raise &quot;Bad name: #{@name}&quot;
 105         end
 106     end
 107 end
 108 
 109 ARM64_EXTRA_GPRS = [SpecialRegister.new(&quot;x16&quot;), SpecialRegister.new(&quot;x17&quot;), SpecialRegister.new(&quot;x13&quot;)]
 110 ARM64_EXTRA_FPRS = [SpecialRegister.new(&quot;q31&quot;)]
 111 
 112 class RegisterID
 113     def arm64Operand(kind)
 114         case @name
 115         when &#39;t0&#39;, &#39;a0&#39;, &#39;r0&#39;
 116             arm64GPRName(&#39;x0&#39;, kind)
 117         when &#39;t1&#39;, &#39;a1&#39;, &#39;r1&#39;
 118             arm64GPRName(&#39;x1&#39;, kind)
 119         when &#39;t2&#39;, &#39;a2&#39;
 120             arm64GPRName(&#39;x2&#39;, kind)
 121         when &#39;t3&#39;, &#39;a3&#39;
 122             arm64GPRName(&#39;x3&#39;, kind)
 123         when &#39;t4&#39;
 124             arm64GPRName(&#39;x4&#39;, kind)
 125         when &#39;t5&#39;
 126           arm64GPRName(&#39;x5&#39;, kind)
 127         when &#39;t6&#39;
 128           arm64GPRName(&#39;x6&#39;, kind)
 129         when &#39;t7&#39;
 130           arm64GPRName(&#39;x7&#39;, kind)
 131         when &#39;cfr&#39;
 132             arm64GPRName(&#39;x29&#39;, kind)
 133         when &#39;csr0&#39;
 134             arm64GPRName(&#39;x19&#39;, kind)
 135         when &#39;csr1&#39;
 136             arm64GPRName(&#39;x20&#39;, kind)
 137         when &#39;csr2&#39;
 138             arm64GPRName(&#39;x21&#39;, kind)
 139         when &#39;csr3&#39;
 140             arm64GPRName(&#39;x22&#39;, kind)
 141         when &#39;csr4&#39;
 142             arm64GPRName(&#39;x23&#39;, kind)
 143         when &#39;csr5&#39;
 144             arm64GPRName(&#39;x24&#39;, kind)
 145         when &#39;csr6&#39;
 146             arm64GPRName(&#39;x25&#39;, kind)
 147         when &#39;csr7&#39;
 148             arm64GPRName(&#39;x26&#39;, kind)
 149         when &#39;csr8&#39;
 150             arm64GPRName(&#39;x27&#39;, kind)
 151         when &#39;csr9&#39;
 152             arm64GPRName(&#39;x28&#39;, kind)
 153         when &#39;sp&#39;
 154             &#39;sp&#39;
 155         when &#39;lr&#39;
 156             &#39;x30&#39;
 157         else
 158             raise &quot;Bad register name #{@name} at #{codeOriginString}&quot;
 159         end
 160     end
 161 end
 162 
 163 class FPRegisterID
 164     def arm64Operand(kind)
 165         case @name
 166         when &#39;ft0&#39;, &#39;fr&#39;, &#39;fa0&#39;
 167             arm64FPRName(&#39;q0&#39;, kind)
 168         when &#39;ft1&#39;, &#39;fa1&#39;
 169             arm64FPRName(&#39;q1&#39;, kind)
 170         when &#39;ft2&#39;, &#39;fa2&#39;
 171             arm64FPRName(&#39;q2&#39;, kind)
 172         when &#39;ft3&#39;, &#39;fa3&#39;
 173             arm64FPRName(&#39;q3&#39;, kind)
 174         when &#39;ft4&#39;
 175             arm64FPRName(&#39;q4&#39;, kind)
 176         when &#39;ft5&#39;
 177             arm64FPRName(&#39;q5&#39;, kind)
 178         when &#39;csfr0&#39;
 179             arm64FPRName(&#39;q8&#39;, kind)
 180         when &#39;csfr1&#39;
 181             arm64FPRName(&#39;q9&#39;, kind)
 182         when &#39;csfr2&#39;
 183             arm64FPRName(&#39;q10&#39;, kind)
 184         when &#39;csfr3&#39;
 185             arm64FPRName(&#39;q11&#39;, kind)
 186         when &#39;csfr4&#39;
 187             arm64FPRName(&#39;q12&#39;, kind)
 188         when &#39;csfr5&#39;
 189             arm64FPRName(&#39;q13&#39;, kind)
 190         when &#39;csfr6&#39;
 191             arm64FPRName(&#39;q14&#39;, kind)
 192         when &#39;csfr7&#39;
 193             arm64FPRName(&#39;q15&#39;, kind)
 194         else &quot;Bad register name #{@name} at #{codeOriginString}&quot;
 195         end
 196     end
 197 end
 198 
 199 class Immediate
 200     def arm64Operand(kind)
 201         raise &quot;Invalid immediate #{value} at #{codeOriginString}&quot; if value &lt; 0 or value &gt; 4095
 202         &quot;\##{value}&quot;
 203     end
 204 end
 205 
 206 class Address
 207     def arm64Operand(kind)
 208         raise &quot;Invalid offset #{offset.value} at #{codeOriginString}&quot; if offset.value &lt; -255 or offset.value &gt; 4095
 209         &quot;[#{base.arm64Operand(:quad)}, \##{offset.value}]&quot;
 210     end
 211     
 212     def arm64EmitLea(destination, kind)
 213         $asm.puts &quot;add #{destination.arm64Operand(kind)}, #{base.arm64Operand(kind)}, \##{offset.value}&quot;
 214     end
 215 end
 216 
 217 class BaseIndex
 218     def arm64Operand(kind)
 219         raise &quot;Invalid offset #{offset.value} at #{codeOriginString}&quot; if offset.value != 0
 220         &quot;[#{base.arm64Operand(:quad)}, #{index.arm64Operand(:quad)}, lsl \##{scaleShift}]&quot;
 221     end
 222 
 223     def arm64EmitLea(destination, kind)
 224         $asm.puts &quot;add #{destination.arm64Operand(kind)}, #{base.arm64Operand(kind)}, #{index.arm64Operand(kind)}, lsl \##{scaleShift}&quot;
 225     end
 226 end
 227 
 228 class AbsoluteAddress
 229     def arm64Operand(kind)
 230         raise &quot;Unconverted absolute address #{address.value} at #{codeOriginString}&quot;
 231     end
 232 end
 233 
 234 # FIXME: We could support AbsoluteAddress for lea, but we don&#39;t.
 235 
 236 #
 237 # Actual lowering code follows.
 238 #
 239 
 240 def arm64LowerMalformedLoadStoreAddresses(list)
 241     newList = []
 242 
 243     def isAddressMalformed(opcode, operand)
 244         malformed = false
 245         if operand.is_a? Address
 246             malformed ||= (not (-255..4095).include? operand.offset.value)
 247             if opcode =~ /q$/ and $currentSettings[&quot;ADDRESS64&quot;]
 248                 malformed ||= operand.offset.value % 8
 249             end
 250         end
 251         malformed
 252     end
 253 
 254     list.each {
 255         | node |
 256         if node.is_a? Instruction
 257             if node.opcode =~ /^store/ and isAddressMalformed(node.opcode, node.operands[1])
 258                 address = node.operands[1]
 259                 tmp = Tmp.new(codeOrigin, :gpr)
 260                 newList &lt;&lt; Instruction.new(node.codeOrigin, &quot;move&quot;, [address.offset, tmp])
 261                 newList &lt;&lt; Instruction.new(node.codeOrigin, node.opcode, [node.operands[0], BaseIndex.new(node.codeOrigin, address.base, tmp, Immediate.new(codeOrigin, 1), Immediate.new(codeOrigin, 0))], node.annotation)
 262             elsif node.opcode =~ /^load/ and isAddressMalformed(node.opcode, node.operands[0])
 263                 address = node.operands[0]
 264                 tmp = Tmp.new(codeOrigin, :gpr)
 265                 newList &lt;&lt; Instruction.new(node.codeOrigin, &quot;move&quot;, [address.offset, tmp])
 266                 newList &lt;&lt; Instruction.new(node.codeOrigin, node.opcode, [BaseIndex.new(node.codeOrigin, address.base, tmp, Immediate.new(codeOrigin, 1), Immediate.new(codeOrigin, 0)), node.operands[1]], node.annotation)
 267             else
 268                 newList &lt;&lt; node
 269             end
 270         else
 271             newList &lt;&lt; node
 272         end
 273     }
 274     newList
 275 end
 276 
 277 def arm64LowerLabelReferences(list)
 278     newList = []
 279     list.each {
 280         | node |
 281         if node.is_a? Instruction
 282             case node.opcode
 283             when &quot;loadi&quot;, &quot;loadis&quot;, &quot;loadp&quot;, &quot;loadq&quot;, &quot;loadb&quot;, &quot;loadbsi&quot;, &quot;loadbsq&quot;, &quot;loadh&quot;, &quot;loadhsi&quot;, &quot;loadhsq&quot;, &quot;leap&quot;
 284                 labelRef = node.operands[0]
 285                 if labelRef.is_a? LabelReference
 286                     tmp = Tmp.new(node.codeOrigin, :gpr)
 287                     newList &lt;&lt; Instruction.new(codeOrigin, &quot;globaladdr&quot;, [LabelReference.new(node.codeOrigin, labelRef.label), tmp])
 288                     newList &lt;&lt; Instruction.new(codeOrigin, node.opcode, [Address.new(node.codeOrigin, tmp, Immediate.new(node.codeOrigin, labelRef.offset)), node.operands[1]])
 289                 else
 290                     newList &lt;&lt; node
 291                 end
 292             else
 293                 newList &lt;&lt; node
 294             end
 295         else
 296             newList &lt;&lt; node
 297         end
 298     }
 299     newList
 300 end
 301 
 302 def arm64FixSpecialRegisterArithmeticMode(list)
 303     newList = []
 304     def usesSpecialRegister(node)
 305         node.children.any? {
 306             |operand|
 307             if operand.is_a? RegisterID and operand.name =~ /sp/
 308                 true
 309             elsif operand.is_a? Address or operand.is_a? BaseIndex
 310                 usesSpecialRegister(operand)
 311             else
 312                 false
 313             end
 314         }
 315     end
 316 
 317 
 318     list.each {
 319         | node |
 320         if node.is_a? Instruction
 321             case node.opcode
 322             when &quot;addp&quot;, &quot;subp&quot;, &quot;mulp&quot;, &quot;divp&quot;, &quot;leap&quot;
 323                 if not $currentSettings[&quot;ADDRESS64&quot;] and usesSpecialRegister(node)
 324                     newOpcode = node.opcode.sub(/(.*)p/, &#39;\1q&#39;)
 325                     node = Instruction.new(node.codeOrigin, newOpcode, node.operands, node.annotation)
 326                 end
 327             when /^bp/
 328                 if not $currentSettings[&quot;ADDRESS64&quot;] and usesSpecialRegister(node)
 329                     newOpcode = node.opcode.sub(/^bp(.*)/, &#39;bq\1&#39;)
 330                     node = Instruction.new(node.codeOrigin, newOpcode, node.operands, node.annotation)
 331                 end
 332             end
 333         end
 334         newList &lt;&lt; node
 335     }
 336     newList
 337 end
 338 
 339 # Workaround for Cortex-A53 erratum (835769)
 340 def arm64CortexA53Fix835769(list)
 341     newList = []
 342     lastOpcodeUnsafe = false
 343 
 344     list.each {
 345         | node |
 346         if node.is_a? Instruction
 347             case node.opcode
 348             when /^store/, /^load/
 349                 # List all macro instructions that can be lowered to a load, store or prefetch ARM64 assembly instruction
 350                 lastOpcodeUnsafe = true
 351             when  &quot;muli&quot;, &quot;mulp&quot;, &quot;mulq&quot;, &quot;smulli&quot;
 352                 # List all macro instructions that can be lowered to a 64-bit multiply-accumulate ARM64 assembly instruction
 353                 # (defined as one of MADD, MSUB, SMADDL, SMSUBL, UMADDL or UMSUBL).
 354                 if lastOpcodeUnsafe
 355                     newList &lt;&lt; Instruction.new(node.codeOrigin, &quot;nopCortexA53Fix835769&quot;, [])
 356                 end
 357                 lastOpcodeUnsafe = false
 358             else
 359                 lastOpcodeUnsafe = false
 360             end
 361         end
 362         newList &lt;&lt; node
 363     }
 364     newList
 365 end
 366 
 367 class Sequence
 368     def getModifiedListARM64(result = @list)
 369         result = riscLowerNot(result)
 370         result = riscLowerSimpleBranchOps(result)
 371 
 372         result = $currentSettings[&quot;ADDRESS64&quot;] ? riscLowerHardBranchOps64(result) : riscLowerHardBranchOps(result)
 373         result = riscLowerShiftOps(result)
 374         result = arm64LowerMalformedLoadStoreAddresses(result)
 375         result = arm64LowerLabelReferences(result)
 376         result = riscLowerMalformedAddresses(result) {
 377             | node, address |
 378             case node.opcode
 379             when &quot;loadb&quot;, &quot;loadbsi&quot;, &quot;loadbsq&quot;, &quot;storeb&quot;, /^bb/, /^btb/, /^cb/, /^tb/
 380                 size = 1
 381             when &quot;loadh&quot;, &quot;loadhsi&quot;, &quot;loadhsq&quot;
 382                 size = 2
 383             when &quot;loadi&quot;, &quot;loadis&quot;, &quot;storei&quot;, &quot;addi&quot;, &quot;andi&quot;, &quot;lshifti&quot;, &quot;muli&quot;, &quot;negi&quot;,
 384                 &quot;noti&quot;, &quot;ori&quot;, &quot;rshifti&quot;, &quot;urshifti&quot;, &quot;subi&quot;, &quot;xori&quot;, /^bi/, /^bti/,
 385                 /^ci/, /^ti/, &quot;addis&quot;, &quot;subis&quot;, &quot;mulis&quot;, &quot;smulli&quot;, &quot;leai&quot;
 386                 size = 4
 387             when &quot;loadp&quot;, &quot;storep&quot;, &quot;loadq&quot;, &quot;storeq&quot;, &quot;loadd&quot;, &quot;stored&quot;, &quot;lshiftp&quot;, &quot;lshiftq&quot;, &quot;negp&quot;, &quot;negq&quot;, &quot;rshiftp&quot;, &quot;rshiftq&quot;,
 388                 &quot;urshiftp&quot;, &quot;urshiftq&quot;, &quot;addp&quot;, &quot;addq&quot;, &quot;mulp&quot;, &quot;mulq&quot;, &quot;andp&quot;, &quot;andq&quot;, &quot;orp&quot;, &quot;orq&quot;, &quot;subp&quot;, &quot;subq&quot;, &quot;xorp&quot;, &quot;xorq&quot;, &quot;addd&quot;,
 389                 &quot;divd&quot;, &quot;subd&quot;, &quot;muld&quot;, &quot;sqrtd&quot;, /^bp/, /^bq/, /^btp/, /^btq/, /^cp/, /^cq/, /^tp/, /^tq/, /^bd/,
 390                 &quot;jmp&quot;, &quot;call&quot;, &quot;leap&quot;, &quot;leaq&quot;
 391                 size = $currentSettings[&quot;ADDRESS64&quot;] ? 8 : 4
 392             else
 393                 raise &quot;Bad instruction #{node.opcode} for heap access at #{node.codeOriginString}: #{node.dump}&quot;
 394             end
 395             
 396             if address.is_a? BaseIndex
 397                 address.offset.value == 0 and
 398                     (node.opcode =~ /^lea/ or address.scale == 1 or address.scale == size)
 399             elsif address.is_a? Address
 400                 (-255..4095).include? address.offset.value
 401             else
 402                 false
 403             end
 404         }
 405         result = riscLowerMisplacedImmediates(result, [&quot;storeb&quot;, &quot;storei&quot;, &quot;storep&quot;, &quot;storeq&quot;])
 406         result = riscLowerMalformedImmediates(result, 0..4095)
 407         result = riscLowerMisplacedAddresses(result)
 408         result = riscLowerMalformedAddresses(result) {
 409             | node, address |
 410             case node.opcode
 411             when /^load/
 412                 true
 413             when /^store/
 414                 not (address.is_a? Address and address.offset.value &lt; 0)
 415             when /^lea/
 416                 true
 417             else
 418                 raise &quot;Bad instruction #{node.opcode} for heap access at #{node.codeOriginString}&quot;
 419             end
 420         }
 421         result = riscLowerTest(result)
 422         result = arm64FixSpecialRegisterArithmeticMode(result)
 423         result = assignRegistersToTemporaries(result, :gpr, ARM64_EXTRA_GPRS)
 424         result = assignRegistersToTemporaries(result, :fpr, ARM64_EXTRA_FPRS)
 425         result = arm64CortexA53Fix835769(result)
 426         return result
 427     end
 428 end
 429 
 430 def arm64Operands(operands, kinds)
 431     if kinds.is_a? Array
 432         raise &quot;Mismatched operand lists: #{operands.inspect} and #{kinds.inspect}&quot; if operands.size != kinds.size
 433     else
 434         kinds = operands.map{ kinds }
 435     end
 436     (0...operands.size).map {
 437         | index |
 438         operands[index].arm64Operand(kinds[index])
 439     }.join(&#39;, &#39;)
 440 end
 441 
 442 def arm64FlippedOperands(operands, kinds)
 443     if kinds.is_a? Array
 444         kinds = [kinds[-1]] + kinds[0..-2]
 445     end
 446     arm64Operands([operands[-1]] + operands[0..-2], kinds)
 447 end
 448 
 449 # TAC = three address code.
 450 def arm64TACOperands(operands, kind)
 451     if operands.size == 3
 452         return arm64FlippedOperands(operands, kind)
 453     end
 454     
 455     raise unless operands.size == 2
 456     
 457     return operands[1].arm64Operand(kind) + &quot;, &quot; + arm64FlippedOperands(operands, kind)
 458 end
 459 
 460 def emitARM64Add(opcode, operands, kind)
 461     if operands.size == 3
 462         raise unless operands[1].register?
 463         raise unless operands[2].register?
 464         
 465         if operands[0].immediate?
 466             if operands[0].value == 0 and opcode !~ /s$/
 467                 if operands[1] != operands[2]
 468                     $asm.puts &quot;mov #{arm64FlippedOperands(operands[1..2], kind)}&quot;
 469                 end
 470             else
 471                 $asm.puts &quot;#{opcode} #{arm64Operands(operands.reverse, kind)}&quot;
 472             end
 473             return
 474         end
 475         
 476         raise unless operands[0].register?
 477         $asm.puts &quot;#{opcode} #{arm64FlippedOperands(operands, kind)}&quot;
 478         return
 479     end
 480     
 481     raise unless operands.size == 2
 482     
 483     if operands[0].immediate? and operands[0].value == 0 and opcode !~ /s$/
 484         return
 485     end
 486     
 487     $asm.puts &quot;#{opcode} #{arm64TACOperands(operands, kind)}&quot;
 488 end
 489 
 490 def emitARM64Mul(opcode, operands, kind)
 491     if operands.size == 2 and operands[0].is_a? Immediate
 492         imm = operands[0].value
 493         if imm &gt; 0 and isPowerOfTwo(imm)
 494             emitARM64LShift([Immediate.new(nil, Math.log2(imm).to_i), operands[1]], kind)
 495             return
 496         end
 497     end
 498 
 499     $asm.puts &quot;madd #{arm64TACOperands(operands, kind)}, #{arm64GPRName(&#39;xzr&#39;, kind)}&quot;
 500 end
 501 
 502 def emitARM64Sub(opcode, operands, kind)
 503     if operands.size == 3
 504         raise unless operands[0].register?
 505         raise unless operands[2].register?
 506 
 507         if operands[1].immediate?
 508             if operands[1].value == 0 and opcode !~ /s$/
 509                 if operands[0] != operands[2]
 510                     $asm.puts &quot;mov #{arm64FlippedOperands([operands[0], operands[2]], kind)}&quot;
 511                 end
 512                 return
 513             end
 514         end
 515     end
 516 
 517     if operands.size == 2
 518         if operands[0].immediate? and operands[0].value == 0 and opcode !~ /s$/
 519             return
 520         end
 521     end
 522 
 523     emitARM64TAC(opcode, operands, kind)
 524 end
 525 
 526 def emitARM64Unflipped(opcode, operands, kind)
 527     $asm.puts &quot;#{opcode} #{arm64Operands(operands, kind)}&quot;
 528 end
 529 
 530 def emitARM64TAC(opcode, operands, kind)
 531     $asm.puts &quot;#{opcode} #{arm64TACOperands(operands, kind)}&quot;
 532 end
 533 
 534 def emitARM64(opcode, operands, kind)
 535     $asm.puts &quot;#{opcode} #{arm64FlippedOperands(operands, kind)}&quot;
 536 end
 537 
 538 def emitARM64Access(opcode, opcodeNegativeOffset, register, memory, kind)
 539     if memory.is_a? Address and memory.offset.value &lt; 0
 540         raise unless -256 &lt;= memory.offset.value
 541         $asm.puts &quot;#{opcodeNegativeOffset} #{register.arm64Operand(kind)}, #{memory.arm64Operand(kind)}&quot;
 542         return
 543     end
 544 
 545     $asm.puts &quot;#{opcode} #{register.arm64Operand(kind)}, #{memory.arm64Operand(kind)}&quot;
 546 end
 547 
 548 def emitARM64Shift(opcodeRegs, opcodeImmediate, operands, kind)
 549     if operands.size == 3 and operands[1].immediate?
 550         magicNumbers = yield operands[1].value
 551         $asm.puts &quot;#{opcodeImmediate} #{operands[2].arm64Operand(kind)}, #{operands[0].arm64Operand(kind)}, \##{magicNumbers[0]}, \##{magicNumbers[1]}&quot;
 552         return
 553     end
 554     
 555     if operands.size == 2 and operands[0].immediate?
 556         magicNumbers = yield operands[0].value
 557         $asm.puts &quot;#{opcodeImmediate} #{operands[1].arm64Operand(kind)}, #{operands[1].arm64Operand(kind)}, \##{magicNumbers[0]}, \##{magicNumbers[1]}&quot;
 558         return
 559     end
 560     
 561     emitARM64TAC(opcodeRegs, operands, kind)
 562 end
 563 
 564 def emitARM64LShift(operands, kind)
 565     emitARM64Shift(&quot;lslv&quot;, &quot;ubfm&quot;, operands, kind) {
 566         | value |
 567         case kind
 568         when :word
 569             [32 - value, 31 - value]
 570         when :ptr
 571             bitSize = $currentSettings[&quot;ADDRESS64&quot;] ? 64 : 32
 572             [bitSize - value, bitSize - 1 - value]
 573         when :quad
 574             [64 - value, 63 - value]
 575         end
 576     }
 577 end
 578 
 579 def emitARM64Branch(opcode, operands, kind, branchOpcode)
 580     emitARM64Unflipped(opcode, operands[0..-2], kind)
 581     $asm.puts &quot;#{branchOpcode} #{operands[-1].asmLabel}&quot;
 582 end
 583 
 584 def emitARM64Compare(operands, kind, compareCode)
 585     emitARM64Unflipped(&quot;subs #{arm64GPRName(&#39;xzr&#39;, kind)}, &quot;, operands[0..-2], kind)
 586     $asm.puts &quot;csinc #{operands[-1].arm64Operand(:word)}, wzr, wzr, #{compareCode}&quot;
 587 end
 588 
 589 def emitARM64MoveImmediate(value, target)
 590     first = true
 591     isNegative = value &lt; 0
 592     [48, 32, 16, 0].each {
 593         | shift |
 594         currentValue = (value &gt;&gt; shift) &amp; 0xffff
 595         next if currentValue == (isNegative ? 0xffff : 0) and (shift != 0 or !first)
 596         if first
 597             if isNegative
 598                 $asm.puts &quot;movn #{target.arm64Operand(:quad)}, \##{(~currentValue) &amp; 0xffff}, lsl \##{shift}&quot;
 599             else
 600                 $asm.puts &quot;movz #{target.arm64Operand(:quad)}, \##{currentValue}, lsl \##{shift}&quot;
 601             end
 602             first = false
 603         else
 604             $asm.puts &quot;movk #{target.arm64Operand(:quad)}, \##{currentValue}, lsl \##{shift}&quot;
 605         end
 606     }
 607 end
 608 
 609 class Instruction
 610     def lowerARM64
 611         case opcode
 612         when &#39;addi&#39;
 613             emitARM64Add(&quot;add&quot;, operands, :word)
 614         when &#39;addis&#39;
 615             emitARM64Add(&quot;adds&quot;, operands, :word)
 616         when &#39;addp&#39;
 617             emitARM64Add(&quot;add&quot;, operands, :ptr)
 618         when &#39;addps&#39;
 619             emitARM64Add(&quot;adds&quot;, operands, :ptr)
 620         when &#39;addq&#39;
 621             emitARM64Add(&quot;add&quot;, operands, :quad)
 622         when &quot;andi&quot;
 623             emitARM64TAC(&quot;and&quot;, operands, :word)
 624         when &quot;andp&quot;
 625             emitARM64TAC(&quot;and&quot;, operands, :ptr)
 626         when &quot;andq&quot;
 627             emitARM64TAC(&quot;and&quot;, operands, :quad)
 628         when &quot;ori&quot;
 629             emitARM64TAC(&quot;orr&quot;, operands, :word)
 630         when &quot;orp&quot;
 631             emitARM64TAC(&quot;orr&quot;, operands, :ptr)
 632         when &quot;orq&quot;
 633             emitARM64TAC(&quot;orr&quot;, operands, :quad)
 634         when &quot;xori&quot;
 635             emitARM64TAC(&quot;eor&quot;, operands, :word)
 636         when &quot;xorp&quot;
 637             emitARM64TAC(&quot;eor&quot;, operands, :ptr)
 638         when &quot;xorq&quot;
 639             emitARM64TAC(&quot;eor&quot;, operands, :quad)
 640         when &quot;lshifti&quot;
 641             emitARM64LShift(operands, :word)
 642         when &quot;lshiftp&quot;
 643             emitARM64LShift(operands, :ptr)
 644         when &quot;lshiftq&quot;
 645             emitARM64LShift(operands, :quad)
 646         when &quot;rshifti&quot;
 647             emitARM64Shift(&quot;asrv&quot;, &quot;sbfm&quot;, operands, :word) {
 648                 | value |
 649                 [value, 31]
 650             }
 651         when &quot;rshiftp&quot;
 652             emitARM64Shift(&quot;asrv&quot;, &quot;sbfm&quot;, operands, :ptr) {
 653                 | value |
 654                 bitSize = $currentSettings[&quot;ADDRESS64&quot;] ? 64 : 32
 655                 [value, bitSize - 1]
 656             }
 657         when &quot;rshiftq&quot;
 658             emitARM64Shift(&quot;asrv&quot;, &quot;sbfm&quot;, operands, :quad) {
 659                 | value |
 660                 [value, 63]
 661             }
 662         when &quot;urshifti&quot;
 663             emitARM64Shift(&quot;lsrv&quot;, &quot;ubfm&quot;, operands, :word) {
 664                 | value |
 665                 [value, 31]
 666             }
 667         when &quot;urshiftp&quot;
 668             emitARM64Shift(&quot;lsrv&quot;, &quot;ubfm&quot;, operands, :ptr) {
 669                 | value |
 670                 bitSize = $currentSettings[&quot;ADDRESS64&quot;] ? 64 : 32
 671                 [value, bitSize - 1]
 672             }
 673         when &quot;urshiftq&quot;
 674             emitARM64Shift(&quot;lsrv&quot;, &quot;ubfm&quot;, operands, :quad) {
 675                 | value |
 676                 [value, 63]
 677             }
 678         when &quot;muli&quot;
 679             emitARM64Mul(&#39;mul&#39;, operands, :word)
 680         when &quot;mulp&quot;
 681             emitARM64Mul(&#39;mul&#39;, operands, :ptr)
 682         when &quot;mulq&quot;
 683             emitARM64Mul(&#39;mul&#39;, operands, :quad)
 684         when &quot;subi&quot;
 685             emitARM64Sub(&quot;sub&quot;, operands, :word)
 686         when &quot;subp&quot;
 687             emitARM64Sub(&quot;sub&quot;, operands, :ptr)
 688         when &quot;subq&quot;
 689             emitARM64Sub(&quot;sub&quot;, operands, :quad)
 690         when &quot;subis&quot;
 691             emitARM64Sub(&quot;subs&quot;, operands, :word)
 692         when &quot;negi&quot;
 693             $asm.puts &quot;sub #{operands[0].arm64Operand(:word)}, wzr, #{operands[0].arm64Operand(:word)}&quot;
 694         when &quot;negp&quot;
 695             $asm.puts &quot;sub #{operands[0].arm64Operand(:ptr)}, #{arm64GPRName(&#39;xzr&#39;, :ptr)}, #{operands[0].arm64Operand(:ptr)}&quot;
 696         when &quot;negq&quot;
 697             $asm.puts &quot;sub #{operands[0].arm64Operand(:quad)}, xzr, #{operands[0].arm64Operand(:quad)}&quot;
 698         when &quot;loadi&quot;
 699             emitARM64Access(&quot;ldr&quot;, &quot;ldur&quot;, operands[1], operands[0], :word)
 700         when &quot;loadis&quot;
 701             emitARM64Access(&quot;ldrsw&quot;, &quot;ldursw&quot;, operands[1], operands[0], :quad)
 702         when &quot;loadp&quot;
 703             emitARM64Access(&quot;ldr&quot;, &quot;ldur&quot;, operands[1], operands[0], :ptr)
 704         when &quot;loadq&quot;
 705             emitARM64Access(&quot;ldr&quot;, &quot;ldur&quot;, operands[1], operands[0], :quad)
 706         when &quot;storei&quot;
 707             emitARM64Unflipped(&quot;str&quot;, operands, :word)
 708         when &quot;storep&quot;
 709             emitARM64Unflipped(&quot;str&quot;, operands, :ptr)
 710         when &quot;storeq&quot;
 711             emitARM64Unflipped(&quot;str&quot;, operands, :quad)
 712         when &quot;loadb&quot;
 713             emitARM64Access(&quot;ldrb&quot;, &quot;ldurb&quot;, operands[1], operands[0], :word)
 714         when &quot;loadbsi&quot;
 715             emitARM64Access(&quot;ldrsb&quot;, &quot;ldursb&quot;, operands[1], operands[0], :word)
 716         when &quot;loadbsq&quot;
 717             emitARM64Access(&quot;ldrsb&quot;, &quot;ldursb&quot;, operands[1], operands[0], :quad)
 718         when &quot;storeb&quot;
 719             emitARM64Unflipped(&quot;strb&quot;, operands, :word)
 720         when &quot;loadh&quot;
 721             emitARM64Access(&quot;ldrh&quot;, &quot;ldurh&quot;, operands[1], operands[0], :word)
 722         when &quot;loadhsi&quot;
 723             emitARM64Access(&quot;ldrsh&quot;, &quot;ldursh&quot;, operands[1], operands[0], :word)
 724         when &quot;loadhsq&quot;
 725             emitARM64Access(&quot;ldrsh&quot;, &quot;ldursh&quot;, operands[1], operands[0], :quad)
 726         when &quot;storeh&quot;
 727             emitARM64Unflipped(&quot;strh&quot;, operands, :word)
 728         when &quot;loadd&quot;
 729             emitARM64Access(&quot;ldr&quot;, &quot;ldur&quot;, operands[1], operands[0], :double)
 730         when &quot;stored&quot;
 731             emitARM64Unflipped(&quot;str&quot;, operands, :double)
 732         when &quot;addd&quot;
 733             emitARM64TAC(&quot;fadd&quot;, operands, :double)
 734         when &quot;divd&quot;
 735             emitARM64TAC(&quot;fdiv&quot;, operands, :double)
 736         when &quot;subd&quot;
 737             emitARM64TAC(&quot;fsub&quot;, operands, :double)
 738         when &quot;muld&quot;
 739             emitARM64TAC(&quot;fmul&quot;, operands, :double)
 740         when &quot;sqrtd&quot;
 741             emitARM64(&quot;fsqrt&quot;, operands, :double)
 742         when &quot;ci2d&quot;
 743             emitARM64(&quot;scvtf&quot;, operands, [:word, :double])
 744         when &quot;bdeq&quot;
 745             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.eq&quot;)
 746         when &quot;bdneq&quot;
 747             emitARM64Unflipped(&quot;fcmp&quot;, operands[0..1], :double)
 748             isUnordered = LocalLabel.unique(&quot;bdneq&quot;)
 749             $asm.puts &quot;b.vs #{LocalLabelReference.new(codeOrigin, isUnordered).asmLabel}&quot;
 750             $asm.puts &quot;b.ne #{operands[2].asmLabel}&quot;
 751             isUnordered.lower(&quot;ARM64&quot;)
 752         when &quot;bdgt&quot;
 753             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.gt&quot;)
 754         when &quot;bdgteq&quot;
 755             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.ge&quot;)
 756         when &quot;bdlt&quot;
 757             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.mi&quot;)
 758         when &quot;bdlteq&quot;
 759             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.ls&quot;)
 760         when &quot;bdequn&quot;
 761             emitARM64Unflipped(&quot;fcmp&quot;, operands[0..1], :double)
 762             $asm.puts &quot;b.vs #{operands[2].asmLabel}&quot;
 763             $asm.puts &quot;b.eq #{operands[2].asmLabel}&quot;
 764         when &quot;bdnequn&quot;
 765             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.ne&quot;)
 766         when &quot;bdgtun&quot;
 767             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.hi&quot;)
 768         when &quot;bdgtequn&quot;
 769             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.pl&quot;)
 770         when &quot;bdltun&quot;
 771             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.lt&quot;)
 772         when &quot;bdltequn&quot;
 773             emitARM64Branch(&quot;fcmp&quot;, operands, :double, &quot;b.le&quot;)
 774         when &quot;btd2i&quot;
 775             # FIXME: May be a good idea to just get rid of this instruction, since the interpreter
 776             # currently does not use it.
 777             raise &quot;ARM64 does not support this opcode yet, #{codeOriginString}&quot;
 778         when &quot;td2i&quot;
 779             emitARM64(&quot;fcvtzs&quot;, operands, [:double, :word])
 780         when &quot;bcd2i&quot;
 781             # FIXME: Remove this instruction, or use it and implement it. Currently it&#39;s not
 782             # used.
 783             raise &quot;ARM64 does not support this opcode yet, #{codeOriginString}&quot;
 784         when &quot;movdz&quot;
 785             # FIXME: Remove it or support it.
 786             raise &quot;ARM64 does not support this opcode yet, #{codeOriginString}&quot;
 787         when &quot;pop&quot;
 788             operands.each_slice(2) {
 789                 | ops |
 790                 # Note that the operands are in the reverse order of the case for push.
 791                 # This is due to the fact that order matters for pushing and popping, and 
 792                 # on platforms that only push/pop one slot at a time they pop their 
 793                 # arguments in the reverse order that they were pushed. In order to remain 
 794                 # compatible with those platforms we assume here that that&#39;s what has been done.
 795 
 796                 # So for example, if we did push(A, B, C, D), we would then pop(D, C, B, A).
 797                 # But since the ordering of arguments doesn&#39;t change on arm64 between the stp and ldp 
 798                 # instructions we need to flip flop the argument positions that were passed to us.
 799                 $asm.puts &quot;ldp #{ops[1].arm64Operand(:quad)}, #{ops[0].arm64Operand(:quad)}, [sp], #16&quot;
 800             }
 801         when &quot;push&quot;
 802             operands.each_slice(2) {
 803                 | ops |
 804                 $asm.puts &quot;stp #{ops[0].arm64Operand(:quad)}, #{ops[1].arm64Operand(:quad)}, [sp, #-16]!&quot;
 805             }
 806         when &quot;move&quot;
 807             if operands[0].immediate?
 808                 emitARM64MoveImmediate(operands[0].value, operands[1])
 809             else
 810                 emitARM64(&quot;mov&quot;, operands, :quad)
 811             end
 812         when &quot;sxi2p&quot;
 813             emitARM64(&quot;sxtw&quot;, operands, [:word, :ptr])
 814         when &quot;sxi2q&quot;
 815             emitARM64(&quot;sxtw&quot;, operands, [:word, :quad])
 816         when &quot;zxi2p&quot;
 817             emitARM64(&quot;uxtw&quot;, operands, [:word, :ptr])
 818         when &quot;zxi2q&quot;
 819             emitARM64(&quot;uxtw&quot;, operands, [:word, :quad])
 820         when &quot;nop&quot;
 821             $asm.puts &quot;nop&quot;
 822         when &quot;bieq&quot;, &quot;bbeq&quot;
 823             if operands[0].immediate? and operands[0].value == 0
 824                 $asm.puts &quot;cbz #{operands[1].arm64Operand(:word)}, #{operands[2].asmLabel}&quot;
 825             elsif operands[1].immediate? and operands[1].value == 0
 826                 $asm.puts &quot;cbz #{operands[0].arm64Operand(:word)}, #{operands[2].asmLabel}&quot;
 827             else
 828                 emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.eq&quot;)
 829             end
 830         when &quot;bpeq&quot;
 831             if operands[0].immediate? and operands[0].value == 0
 832                 $asm.puts &quot;cbz #{operands[1].arm64Operand(:ptr)}, #{operands[2].asmLabel}&quot;
 833             elsif operands[1].immediate? and operands[1].value == 0
 834                 $asm.puts &quot;cbz #{operands[0].arm64Operand(:ptr)}, #{operands[2].asmLabel}&quot;
 835             else
 836                 emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.eq&quot;)
 837             end
 838         when &quot;bqeq&quot;
 839             if operands[0].immediate? and operands[0].value == 0
 840                 $asm.puts &quot;cbz #{operands[1].arm64Operand(:quad)}, #{operands[2].asmLabel}&quot;
 841             elsif operands[1].immediate? and operands[1].value == 0
 842                 $asm.puts &quot;cbz #{operands[0].arm64Operand(:quad)}, #{operands[2].asmLabel}&quot;
 843             else
 844                 emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.eq&quot;)
 845             end
 846         when &quot;bineq&quot;, &quot;bbneq&quot;
 847             if operands[0].immediate? and operands[0].value == 0
 848                 $asm.puts &quot;cbnz #{operands[1].arm64Operand(:word)}, #{operands[2].asmLabel}&quot;
 849             elsif operands[1].immediate? and operands[1].value == 0
 850                 $asm.puts &quot;cbnz #{operands[0].arm64Operand(:word)}, #{operands[2].asmLabel}&quot;
 851             else
 852                 emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.ne&quot;)
 853             end
 854         when &quot;bpneq&quot;
 855             if operands[0].immediate? and operands[0].value == 0
 856                 $asm.puts &quot;cbnz #{operands[1].arm64Operand(:ptr)}, #{operands[2].asmLabel}&quot;
 857             elsif operands[1].immediate? and operands[1].value == 0
 858                 $asm.puts &quot;cbnz #{operands[0].arm64Operand(:ptr)}, #{operands[2].asmLabel}&quot;
 859             else
 860                 emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.ne&quot;)
 861             end
 862         when &quot;bqneq&quot;
 863             if operands[0].immediate? and operands[0].value == 0
 864                 $asm.puts &quot;cbnz #{operands[1].arm64Operand(:quad)}, #{operands[2].asmLabel}&quot;
 865             elsif operands[1].immediate? and operands[1].value == 0
 866                 $asm.puts &quot;cbnz #{operands[0].arm64Operand(:quad)}, #{operands[2].asmLabel}&quot;
 867             else
 868                 emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.ne&quot;)
 869             end
 870         when &quot;bia&quot;, &quot;bba&quot;
 871             emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.hi&quot;)
 872         when &quot;bpa&quot;
 873             emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.hi&quot;)
 874         when &quot;bqa&quot;
 875             emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.hi&quot;)
 876         when &quot;biaeq&quot;, &quot;bbaeq&quot;
 877             emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.hs&quot;)
 878         when &quot;bpaeq&quot;
 879             emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.hs&quot;)
 880         when &quot;bqaeq&quot;
 881             emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.hs&quot;)
 882         when &quot;bib&quot;, &quot;bbb&quot;
 883             emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.lo&quot;)
 884         when &quot;bpb&quot;
 885             emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.lo&quot;)
 886         when &quot;bqb&quot;
 887             emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.lo&quot;)
 888         when &quot;bibeq&quot;, &quot;bbbeq&quot;
 889             emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.ls&quot;)
 890         when &quot;bpbeq&quot;
 891             emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.ls&quot;)
 892         when &quot;bqbeq&quot;
 893             emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.ls&quot;)
 894         when &quot;bigt&quot;, &quot;bbgt&quot;
 895             emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.gt&quot;)
 896         when &quot;bpgt&quot;
 897             emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.gt&quot;)
 898         when &quot;bqgt&quot;
 899             emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.gt&quot;)
 900         when &quot;bigteq&quot;, &quot;bbgteq&quot;
 901             emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.ge&quot;)
 902         when &quot;bpgteq&quot;
 903             emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.ge&quot;)
 904         when &quot;bqgteq&quot;
 905             emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.ge&quot;)
 906         when &quot;bilt&quot;, &quot;bblt&quot;
 907             emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.lt&quot;)
 908         when &quot;bplt&quot;
 909             emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.lt&quot;)
 910         when &quot;bqlt&quot;
 911             emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.lt&quot;)
 912         when &quot;bilteq&quot;, &quot;bblteq&quot;
 913             emitARM64Branch(&quot;subs wzr, &quot;, operands, :word, &quot;b.le&quot;)
 914         when &quot;bplteq&quot;
 915             emitARM64Branch(&quot;subs #{arm64GPRName(&#39;xzr&#39;, :ptr)}, &quot;, operands, :ptr, &quot;b.le&quot;)
 916         when &quot;bqlteq&quot;
 917             emitARM64Branch(&quot;subs xzr, &quot;, operands, :quad, &quot;b.le&quot;)
 918         when &quot;jmp&quot;
 919             if operands[0].label?
 920                 $asm.puts &quot;b #{operands[0].asmLabel}&quot;
 921             else
 922                 emitARM64Unflipped(&quot;br&quot;, operands, :quad)
 923             end
 924         when &quot;call&quot;
 925             if operands[0].label?
 926                 $asm.puts &quot;bl #{operands[0].asmLabel}&quot;
 927             else
 928                 emitARM64Unflipped(&quot;blr&quot;, operands, :quad)
 929             end
 930         when &quot;break&quot;
 931             $asm.puts &quot;brk \#0&quot;
 932         when &quot;ret&quot;
 933             $asm.puts &quot;ret&quot;
 934         when &quot;cieq&quot;, &quot;cbeq&quot;
 935             emitARM64Compare(operands, :word, &quot;ne&quot;)
 936         when &quot;cpeq&quot;
 937             emitARM64Compare(operands, :ptr, &quot;ne&quot;)
 938         when &quot;cqeq&quot;
 939             emitARM64Compare(operands, :quad, &quot;ne&quot;)
 940         when &quot;cineq&quot;, &quot;cbneq&quot;
 941             emitARM64Compare(operands, :word, &quot;eq&quot;)
 942         when &quot;cpneq&quot;
 943             emitARM64Compare(operands, :ptr, &quot;eq&quot;)
 944         when &quot;cqneq&quot;
 945             emitARM64Compare(operands, :quad, &quot;eq&quot;)
 946         when &quot;cia&quot;, &quot;cba&quot;
 947             emitARM64Compare(operands, :word, &quot;ls&quot;)
 948         when &quot;cpa&quot;
 949             emitARM64Compare(operands, :ptr, &quot;ls&quot;)
 950         when &quot;cqa&quot;
 951             emitARM64Compare(operands, :quad, &quot;ls&quot;)
 952         when &quot;ciaeq&quot;, &quot;cbaeq&quot;
 953             emitARM64Compare(operands, :word, &quot;lo&quot;)
 954         when &quot;cpaeq&quot;
 955             emitARM64Compare(operands, :ptr, &quot;lo&quot;)
 956         when &quot;cqaeq&quot;
 957             emitARM64Compare(operands, :quad, &quot;lo&quot;)
 958         when &quot;cib&quot;, &quot;cbb&quot;
 959             emitARM64Compare(operands, :word, &quot;hs&quot;)
 960         when &quot;cpb&quot;
 961             emitARM64Compare(operands, :ptr, &quot;hs&quot;)
 962         when &quot;cqb&quot;
 963             emitARM64Compare(operands, :quad, &quot;hs&quot;)
 964         when &quot;cibeq&quot;, &quot;cbbeq&quot;
 965             emitARM64Compare(operands, :word, &quot;hi&quot;)
 966         when &quot;cpbeq&quot;
 967             emitARM64Compare(operands, :ptr, &quot;hi&quot;)
 968         when &quot;cqbeq&quot;
 969             emitARM64Compare(operands, :quad, &quot;hi&quot;)
 970         when &quot;cilt&quot;, &quot;cblt&quot;
 971             emitARM64Compare(operands, :word, &quot;ge&quot;)
 972         when &quot;cplt&quot;
 973             emitARM64Compare(operands, :ptr, &quot;ge&quot;)
 974         when &quot;cqlt&quot;
 975             emitARM64Compare(operands, :quad, &quot;ge&quot;)
 976         when &quot;cilteq&quot;, &quot;cblteq&quot;
 977             emitARM64Compare(operands, :word, &quot;gt&quot;)
 978         when &quot;cplteq&quot;
 979             emitARM64Compare(operands, :ptr, &quot;gt&quot;)
 980         when &quot;cqlteq&quot;
 981             emitARM64Compare(operands, :quad, &quot;gt&quot;)
 982         when &quot;cigt&quot;, &quot;cbgt&quot;
 983             emitARM64Compare(operands, :word, &quot;le&quot;)
 984         when &quot;cpgt&quot;
 985             emitARM64Compare(operands, :ptr, &quot;le&quot;)
 986         when &quot;cqgt&quot;
 987             emitARM64Compare(operands, :quad, &quot;le&quot;)
 988         when &quot;cigteq&quot;, &quot;cbgteq&quot;
 989             emitARM64Compare(operands, :word, &quot;lt&quot;)
 990         when &quot;cpgteq&quot;
 991             emitARM64Compare(operands, :ptr, &quot;lt&quot;)
 992         when &quot;cqgteq&quot;
 993             emitARM64Compare(operands, :quad, &quot;lt&quot;)
 994         when &quot;peek&quot;
 995             $asm.puts &quot;ldr #{operands[1].arm64Operand(:quad)}, [sp, \##{operands[0].value * 8}]&quot;
 996         when &quot;poke&quot;
 997             $asm.puts &quot;str #{operands[1].arm64Operand(:quad)}, [sp, \##{operands[0].value * 8}]&quot;
 998         when &quot;fp2d&quot;
 999             emitARM64(&quot;fmov&quot;, operands, [:ptr, :double])
1000         when &quot;fq2d&quot;
1001             emitARM64(&quot;fmov&quot;, operands, [:quad, :double])
1002         when &quot;fd2p&quot;
1003             emitARM64(&quot;fmov&quot;, operands, [:double, :ptr])
1004         when &quot;fd2q&quot;
1005             emitARM64(&quot;fmov&quot;, operands, [:double, :quad])
1006         when &quot;bo&quot;
1007             $asm.puts &quot;b.vs #{operands[0].asmLabel}&quot;
1008         when &quot;bs&quot;
1009             $asm.puts &quot;b.mi #{operands[0].asmLabel}&quot;
1010         when &quot;bz&quot;
1011             $asm.puts &quot;b.eq #{operands[0].asmLabel}&quot;
1012         when &quot;bnz&quot;
1013             $asm.puts &quot;b.ne #{operands[0].asmLabel}&quot;
1014         when &quot;leai&quot;
1015             operands[0].arm64EmitLea(operands[1], :word)
1016         when &quot;leap&quot;
1017             operands[0].arm64EmitLea(operands[1], :ptr)
1018         when &quot;leaq&quot;
1019             operands[0].arm64EmitLea(operands[1], :quad)
1020         when &quot;smulli&quot;
1021             $asm.puts &quot;smaddl #{operands[2].arm64Operand(:quad)}, #{operands[0].arm64Operand(:word)}, #{operands[1].arm64Operand(:word)}, xzr&quot;
1022         when &quot;memfence&quot;
1023             $asm.puts &quot;dmb sy&quot;
1024         when &quot;bfiq&quot;
1025             $asm.puts &quot;bfi #{operands[3].arm64Operand(:quad)}, #{operands[0].arm64Operand(:quad)}, #{operands[1].value}, #{operands[2].value}&quot;
1026         when &quot;pcrtoaddr&quot;
1027             $asm.puts &quot;adr #{operands[1].arm64Operand(:quad)}, #{operands[0].value}&quot;
1028         when &quot;nopCortexA53Fix835769&quot;
1029             $asm.putStr(&quot;#if CPU(ARM64_CORTEXA53)&quot;)
1030             $asm.puts &quot;nop&quot;
1031             $asm.putStr(&quot;#endif&quot;)
1032         when &quot;globaladdr&quot;
1033             uid = $asm.newUID
1034 
1035             # On Darwin, use Macho-O GOT relocation specifiers, along with
1036             # the labels required for the .loh directive.
1037             $asm.putStr(&quot;#if OS(DARWIN)&quot;)
1038             $asm.puts &quot;L_offlineasm_loh_adrp_#{uid}:&quot;
1039             $asm.puts &quot;adrp #{operands[1].arm64Operand(:quad)}, #{operands[0].asmLabel}@GOTPAGE&quot;
1040             $asm.puts &quot;L_offlineasm_loh_ldr_#{uid}:&quot;
1041             $asm.puts &quot;ldr #{operands[1].arm64Operand(:quad)}, [#{operands[1].arm64Operand(:quad)}, #{operands[0].asmLabel}@GOTPAGEOFF]&quot;
1042 
1043             # On Linux, use ELF GOT relocation specifiers.
1044             $asm.putStr(&quot;#elif OS(LINUX)&quot;)
1045             $asm.puts &quot;adrp #{operands[1].arm64Operand(:quad)}, :got:#{operands[0].asmLabel}&quot;
1046             $asm.puts &quot;ldr #{operands[1].arm64Operand(:quad)}, [#{operands[1].arm64Operand(:quad)}, :got_lo12:#{operands[0].asmLabel}]&quot;
1047 
1048             # Throw a compiler error everywhere else.
1049             $asm.putStr(&quot;#else&quot;)
1050             $asm.putStr(&quot;#error Missing globaladdr implementation&quot;)
1051             $asm.putStr(&quot;#endif&quot;)
1052 
1053             $asm.deferAction {
1054                 # On Darwin, also include the .loh directive using the generated labels.
1055                 $asm.putStr(&quot;#if OS(DARWIN)&quot;)
1056                 $asm.puts &quot;.loh AdrpLdrGot L_offlineasm_loh_adrp_#{uid}, L_offlineasm_loh_ldr_#{uid}&quot;
1057                 $asm.putStr(&quot;#endif&quot;)
1058             }
1059         else
1060             lowerDefault
1061         end
1062     end
1063 end
1064 
    </pre>
  </body>
</html>