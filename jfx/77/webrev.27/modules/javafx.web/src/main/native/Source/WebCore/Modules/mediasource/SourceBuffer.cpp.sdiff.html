<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
  </head>
<body>
<center><a href="MediaSourceRegistry.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="SourceBuffer.h.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  39 #include &quot;Event.h&quot;
  40 #include &quot;EventNames.h&quot;
  41 #include &quot;GenericEventQueue.h&quot;
  42 #include &quot;HTMLMediaElement.h&quot;
  43 #include &quot;InbandTextTrack.h&quot;
  44 #include &quot;Logging.h&quot;
  45 #include &quot;MediaDescription.h&quot;
  46 #include &quot;MediaSample.h&quot;
  47 #include &quot;MediaSource.h&quot;
  48 #include &quot;SampleMap.h&quot;
  49 #include &quot;SourceBufferList.h&quot;
  50 #include &quot;SourceBufferPrivate.h&quot;
  51 #include &quot;TextTrackList.h&quot;
  52 #include &quot;TimeRanges.h&quot;
  53 #include &quot;VideoTrackList.h&quot;
  54 #include &lt;JavaScriptCore/JSCInlines.h&gt;
  55 #include &lt;JavaScriptCore/JSLock.h&gt;
  56 #include &lt;JavaScriptCore/VM.h&gt;
  57 #include &lt;limits&gt;
  58 #include &lt;wtf/CheckedArithmetic.h&gt;

  59 
  60 namespace WebCore {
  61 


  62 static const double ExponentialMovingAverageCoefficient = 0.1;
  63 
  64 struct SourceBuffer::TrackBuffer {
  65     MediaTime lastDecodeTimestamp;
  66     MediaTime greatestDecodeDuration;
  67     MediaTime lastFrameDuration;
  68     MediaTime highestPresentationTimestamp;
  69     MediaTime lastEnqueuedPresentationTime;

  70     DecodeOrderSampleMap::KeyType lastEnqueuedDecodeKey;
  71     MediaTime lastEnqueuedDecodeDuration;
  72     MediaTime roundedTimestampOffset;
  73     uint32_t lastFrameTimescale { 0 };
  74     bool needRandomAccessFlag { true };
  75     bool enabled { false };
  76     bool needsReenqueueing { false };

  77     SampleMap samples;
  78     DecodeOrderSampleMap::MapType decodeQueue;
  79     RefPtr&lt;MediaDescription&gt; description;
  80     PlatformTimeRanges buffered;
  81 
  82     TrackBuffer()
  83         : lastDecodeTimestamp(MediaTime::invalidTime())
  84         , greatestDecodeDuration(MediaTime::invalidTime())
  85         , lastFrameDuration(MediaTime::invalidTime())
  86         , highestPresentationTimestamp(MediaTime::invalidTime())
  87         , lastEnqueuedPresentationTime(MediaTime::invalidTime())
  88         , lastEnqueuedDecodeKey({MediaTime::invalidTime(), MediaTime::invalidTime()})
  89         , lastEnqueuedDecodeDuration(MediaTime::invalidTime())
  90     {
  91     }
  92 };
  93 
  94 Ref&lt;SourceBuffer&gt; SourceBuffer::create(Ref&lt;SourceBufferPrivate&gt;&amp;&amp; sourceBufferPrivate, MediaSource* source)
  95 {
  96     auto sourceBuffer = adoptRef(*new SourceBuffer(WTFMove(sourceBufferPrivate), source));
</pre>
<hr />
<pre>
 461     if (isRemoved())
 462         return;
 463 
 464     abortIfUpdating();
 465 
 466     for (auto&amp; trackBufferPair : m_trackBufferMap.values()) {
 467         trackBufferPair.samples.clear();
 468         trackBufferPair.decodeQueue.clear();
 469     }
 470 
 471     m_private-&gt;removedFromMediaSource();
 472     m_source = nullptr;
 473 }
 474 
 475 void SourceBuffer::seekToTime(const MediaTime&amp; time)
 476 {
 477     ALWAYS_LOG(LOGIDENTIFIER, time);
 478 
 479     for (auto&amp; trackBufferPair : m_trackBufferMap) {
 480         TrackBuffer&amp; trackBuffer = trackBufferPair.value;
<span class="line-modified"> 481         const AtomicString&amp; trackID = trackBufferPair.key;</span>
 482 
 483         trackBuffer.needsReenqueueing = true;
 484         reenqueueMediaForTime(trackBuffer, trackID, time);
 485     }
 486 }
 487 
 488 MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(const MediaTime&amp; targetTime, const MediaTime&amp; negativeThreshold, const MediaTime&amp; positiveThreshold)
 489 {
 490     MediaTime seekTime = targetTime;
 491     MediaTime lowerBoundTime = targetTime - negativeThreshold;
 492     MediaTime upperBoundTime = targetTime + positiveThreshold;
 493 
 494     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
 495         // Find the sample which contains the target time time.
 496         auto futureSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(targetTime, positiveThreshold);
 497         auto pastSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSamplePriorToPresentationTime(targetTime, negativeThreshold);
 498         auto upperBound = trackBuffer.samples.decodeOrder().end();
 499         auto lowerBound = trackBuffer.samples.decodeOrder().rend();
 500 
 501         if (futureSyncSampleIterator == upperBound &amp;&amp; pastSyncSampleIterator == lowerBound)
</pre>
<hr />
<pre>
 550     m_asyncEventQueue.close();
 551     m_appendBufferTimer.stop();
 552     m_removeTimer.stop();
 553 }
 554 
 555 bool SourceBuffer::canSuspendForDocumentSuspension() const
 556 {
 557     return !hasPendingActivity();
 558 }
 559 
 560 const char* SourceBuffer::activeDOMObjectName() const
 561 {
 562     return &quot;SourceBuffer&quot;;
 563 }
 564 
 565 bool SourceBuffer::isRemoved() const
 566 {
 567     return !m_source;
 568 }
 569 
<span class="line-modified"> 570 void SourceBuffer::scheduleEvent(const AtomicString&amp; eventName)</span>
 571 {
 572     auto event = Event::create(eventName, Event::CanBubble::No, Event::IsCancelable::No);
 573     event-&gt;setTarget(this);
 574 
 575     m_asyncEventQueue.enqueueEvent(WTFMove(event));
 576 }
 577 
 578 ExceptionOr&lt;void&gt; SourceBuffer::appendBufferInternal(const unsigned char* data, unsigned size)
 579 {
 580     // Section 3.2 appendBuffer()
 581     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-appendBuffer-void-ArrayBufferView-data
 582 
 583     // Step 1 is enforced by the caller.
 584     // 2. Run the prepare append algorithm.
 585     // Section 3.5.4 Prepare AppendAlgorithm
 586 
 587     // 1. If the SourceBuffer has been removed from the sourceBuffers attribute of the parent media source
 588     // then throw an InvalidStateError exception and abort these steps.
 589     // 2. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 590     if (isRemoved() || m_updating)
</pre>
<hr />
<pre>
 683     // NOTE: return to Section 3.5.5
 684     // 2.If the segment parser loop algorithm in the previous step was aborted, then abort this algorithm.
 685     if (result != AppendSucceeded)
 686         return;
 687 
 688     // 3. Set the updating attribute to false.
 689     m_updating = false;
 690 
 691     // 4. Queue a task to fire a simple event named update at this SourceBuffer object.
 692     scheduleEvent(eventNames().updateEvent);
 693 
 694     // 5. Queue a task to fire a simple event named updateend at this SourceBuffer object.
 695     scheduleEvent(eventNames().updateendEvent);
 696 
 697     if (m_source)
 698         m_source-&gt;monitorSourceBuffers();
 699 
 700     MediaTime currentMediaTime = m_source-&gt;currentTime();
 701     for (auto&amp; trackBufferPair : m_trackBufferMap) {
 702         TrackBuffer&amp; trackBuffer = trackBufferPair.value;
<span class="line-modified"> 703         const AtomicString&amp; trackID = trackBufferPair.key;</span>
 704 
 705         if (trackBuffer.needsReenqueueing) {
 706             DEBUG_LOG(LOGIDENTIFIER, &quot;reenqueuing at time &quot;, currentMediaTime);
 707             reenqueueMediaForTime(trackBuffer, trackID, currentMediaTime);
 708         } else
 709             provideMediaData(trackBuffer, trackID);
 710     }
 711 
 712     reportExtraMemoryAllocated();
 713     if (extraMemoryCost() &gt; this-&gt;maximumBufferSize())
 714         m_bufferFull = true;
 715 
 716     DEBUG_LOG(LOGIDENTIFIER);
 717 }
 718 
 719 void SourceBuffer::sourceBufferPrivateDidReceiveRenderingError(int error)
 720 {
 721 #if RELEASE_LOG_DISABLED
 722     UNUSED_PARAM(error);
 723 #endif
 724 
 725     ERROR_LOG(LOGIDENTIFIER, error);
 726 
 727     if (!isRemoved())
 728         m_source-&gt;streamEndedWithError(MediaSource::EndOfStreamError::Decode);
 729 }
 730 
 731 static bool decodeTimeComparator(const PresentationOrderSampleMap::MapType::value_type&amp; a, const PresentationOrderSampleMap::MapType::value_type&amp; b)
 732 {
 733     return a.second-&gt;decodeTime() &lt; b.second-&gt;decodeTime();
 734 }
 735 
 736 static PlatformTimeRanges removeSamplesFromTrackBuffer(const DecodeOrderSampleMap::MapType&amp; samples, SourceBuffer::TrackBuffer&amp; trackBuffer, const SourceBuffer* buffer, const char* logPrefix)
 737 {
 738 #if !RELEASE_LOG_DISABLED
 739     MediaTime earliestSample = MediaTime::positiveInfiniteTime();
 740     MediaTime latestSample = MediaTime::zeroTime();
 741     size_t bytesRemoved = 0;
 742     auto logIdentifier = WTF::Logger::LogSiteIdentifier(buffer-&gt;logClassName(), logPrefix, buffer-&gt;logIdentifier());
 743     auto&amp; logger = buffer-&gt;logger();
<span class="line-modified"> 744     auto willLog = logger.willLog(buffer-&gt;logChannel(), WTFLogLevelDebug);</span>
 745 #else
 746     UNUSED_PARAM(logPrefix);
 747     UNUSED_PARAM(buffer);
 748 #endif
 749 
 750     PlatformTimeRanges erasedRanges;
 751     for (const auto&amp; sampleIt : samples) {
 752         const DecodeOrderSampleMap::KeyType&amp; decodeKey = sampleIt.first;
 753 #if !RELEASE_LOG_DISABLED
 754         size_t startBufferSize = trackBuffer.samples.sizeInBytes();
 755 #endif
 756 
 757         const RefPtr&lt;MediaSample&gt;&amp; sample = sampleIt.second;
 758 
 759 #if !RELEASE_LOG_DISABLED
 760         if (willLog)
 761             logger.debug(buffer-&gt;logChannel(), logIdentifier, &quot;removing sample &quot;, *sampleIt.second);
 762 #endif
 763 
 764         // Remove the erased samples from the TrackBuffer sample map.
</pre>
<hr />
<pre>
 812     if (bytesRemoved &amp;&amp; willLog)
 813         logger.debug(buffer-&gt;logChannel(), logIdentifier, &quot;removed &quot;, bytesRemoved, &quot;, start = &quot;, earliestSample, &quot;, end = &quot;, latestSample);
 814 #endif
 815 
 816     return erasedRanges;
 817 }
 818 
 819 void SourceBuffer::removeCodedFrames(const MediaTime&amp; start, const MediaTime&amp; end)
 820 {
 821     DEBUG_LOG(LOGIDENTIFIER, &quot;start = &quot;, start, &quot;, end = &quot;, end);
 822 
 823     // 3.5.9 Coded Frame Removal Algorithm
 824     // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-coded-frame-removal
 825 
 826     // 1. Let start be the starting presentation timestamp for the removal range.
 827     MediaTime durationMediaTime = m_source-&gt;duration();
 828     MediaTime currentMediaTime = m_source-&gt;currentTime();
 829 
 830     // 2. Let end be the end presentation timestamp for the removal range.
 831     // 3. For each track buffer in this source buffer, run the following steps:
<span class="line-modified"> 832     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {</span>



 833         // 3.1. Let remove end timestamp be the current value of duration
 834         // 3.2 If this track buffer has a random access point timestamp that is greater than or equal to end, then update
 835         // remove end timestamp to that random access point timestamp.
 836         // NOTE: Step 3.2 will be incorrect for any random access point timestamp whose decode time is later than the sample at end,
 837         // but whose presentation time is less than the sample at end. Skip this step until step 3.3 below.
 838 
 839         // NOTE: To handle MediaSamples which may be an amalgamation of multiple shorter samples, find samples whose presentation
 840         // interval straddles the start and end times, and divide them if possible:
 841         auto divideSampleIfPossibleAtPresentationTime = [&amp;] (const MediaTime&amp; time) {
 842             auto sampleIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
 843             if (sampleIterator == trackBuffer.samples.presentationOrder().end())
 844                 return;
 845             RefPtr&lt;MediaSample&gt; sample = sampleIterator-&gt;second;
 846             if (!sample-&gt;isDivisable())
 847                 return;
 848             std::pair&lt;RefPtr&lt;MediaSample&gt;, RefPtr&lt;MediaSample&gt;&gt; replacementSamples = sample-&gt;divide(time);
 849             if (!replacementSamples.first || !replacementSamples.second)
 850                 return;
 851             DEBUG_LOG(LOGIDENTIFIER, &quot;splitting sample &quot;, *sample, &quot; into &quot;, *replacementSamples.first, &quot; and &quot;, *replacementSamples.second);
 852             trackBuffer.samples.removeSample(sample.get());
</pre>
<hr />
<pre>
 864         // 3.3 Remove all media data, from this track buffer, that contain starting timestamps greater than or equal to
 865         // start and less than the remove end timestamp.
 866         // NOTE: frames must be removed in decode order, so that all dependant frames between the frame to be removed
 867         // and the next sync sample frame are removed. But we must start from the first sample in decode order, not
 868         // presentation order.
 869         auto minmaxDecodeTimeIterPair = std::minmax_element(removePresentationStart, removePresentationEnd, decodeTimeComparator);
 870         auto&amp; firstSample = *minmaxDecodeTimeIterPair.first-&gt;second;
 871         auto&amp; lastSample = *minmaxDecodeTimeIterPair.second-&gt;second;
 872         auto removeDecodeStart = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({firstSample.decodeTime(), firstSample.presentationTime()});
 873         auto removeDecodeLast = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({lastSample.decodeTime(), lastSample.presentationTime()});
 874         auto removeDecodeEnd = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(removeDecodeLast);
 875 
 876         DecodeOrderSampleMap::MapType erasedSamples(removeDecodeStart, removeDecodeEnd);
 877         PlatformTimeRanges erasedRanges = removeSamplesFromTrackBuffer(erasedSamples, trackBuffer, this, &quot;removeCodedFrames&quot;);
 878 
 879         // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
 880         // not yet displayed samples.
 881         if (trackBuffer.lastEnqueuedPresentationTime.isValid() &amp;&amp; currentMediaTime &lt; trackBuffer.lastEnqueuedPresentationTime) {
 882             PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.lastEnqueuedPresentationTime);
 883             possiblyEnqueuedRanges.intersectWith(erasedRanges);
<span class="line-modified"> 884             if (possiblyEnqueuedRanges.length())</span>
 885                 trackBuffer.needsReenqueueing = true;



 886         }
 887 
 888         erasedRanges.invert();
 889         trackBuffer.buffered.intersectWith(erasedRanges);
 890         setBufferedDirty(true);
 891 
 892         // 3.4 If this object is in activeSourceBuffers, the current playback position is greater than or equal to start
 893         // and less than the remove end timestamp, and HTMLMediaElement.readyState is greater than HAVE_METADATA, then set
 894         // the HTMLMediaElement.readyState attribute to HAVE_METADATA and stall playback.
 895         if (m_active &amp;&amp; currentMediaTime &gt;= start &amp;&amp; currentMediaTime &lt; end &amp;&amp; m_private-&gt;readyState() &gt; MediaPlayer::HaveMetadata)
 896             m_private-&gt;setReadyState(MediaPlayer::HaveMetadata);
 897     }
 898 
 899     updateBufferedFromTrackBuffers();
 900 
 901     // 4. If buffer full flag equals true and this object is ready to accept more bytes, then set the buffer full flag to false.
 902     // No-op
 903 
 904     LOG(Media, &quot;SourceBuffer::removeCodedFrames(%p) - buffered = %s&quot;, this, toString(m_buffered-&gt;ranges()).utf8().data());
 905 }
</pre>
<hr />
<pre>
 971             m_bufferFull = false;
 972             break;
 973         }
 974 
 975         rangeStart += thirtySeconds;
 976         rangeEnd += thirtySeconds;
 977     }
 978 
 979 #if !RELEASE_LOG_DISABLED
 980     if (!m_bufferFull) {
 981         DEBUG_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost());
 982         return;
 983     }
 984 #endif
 985 
 986     // If there still isn&#39;t enough free space and there buffers in time ranges after the current range (ie. there is a gap after
 987     // the current buffered range), delete 30 seconds at a time from duration back to the current time range or 30 seconds after
 988     // currenTime whichever we hit first.
 989     auto buffered = m_buffered-&gt;ranges();
 990     size_t currentTimeRange = buffered.find(currentTime);
<span class="line-modified"> 991     if (currentTimeRange == notFound || currentTimeRange == buffered.length() - 1) {</span>
 992 #if !RELEASE_LOG_DISABLED
<span class="line-modified"> 993         ERROR_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost(), &quot; bytes but FAILED to free enough&quot;);</span>
 994 #endif
 995         return;
 996     }
 997 
 998     MediaTime minimumRangeStart = currentTime + thirtySeconds;
 999 
1000     rangeEnd = m_source-&gt;duration();
1001     rangeStart = rangeEnd - thirtySeconds;
1002     while (rangeStart &gt; minimumRangeStart) {
1003 
1004         // Do not evict data from the time range that contains currentTime.
1005         size_t startTimeRange = buffered.find(rangeStart);
<span class="line-modified">1006         if (startTimeRange == currentTimeRange) {</span>
1007             size_t endTimeRange = buffered.find(rangeEnd);
<span class="line-modified">1008             if (endTimeRange == currentTimeRange)</span>
1009                 break;
1010 
1011             rangeEnd = buffered.start(endTimeRange);
1012         }
1013 
1014         // 4. For each range in removal ranges, run the coded frame removal algorithm with start and
1015         // end equal to the removal range start and end timestamp respectively.
1016         removeCodedFrames(std::max(minimumRangeStart, rangeStart), rangeEnd);
1017         if (extraMemoryCost() + newDataSize &lt; maximumBufferSize) {
1018             m_bufferFull = false;
1019             break;
1020         }
1021 
1022         rangeStart -= thirtySeconds;
1023         rangeEnd -= thirtySeconds;
1024     }
1025 
1026 #if !RELEASE_LOG_DISABLED
1027     if (m_bufferFull)
<span class="line-modified">1028         ERROR_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost(), &quot; but FAILED to free enough&quot;);</span>
1029     else
1030         DEBUG_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost());
1031 #endif
1032 }
1033 
1034 size_t SourceBuffer::maximumBufferSize() const
1035 {
1036     if (isRemoved())
1037         return 0;
1038 
1039     auto* element = m_source-&gt;mediaElement();
1040     if (!element)
1041         return 0;
1042 
1043     return element-&gt;maximumSourceBufferSize(*this);
1044 }
1045 
1046 VideoTrackList&amp; SourceBuffer::videoTracks()
1047 {
1048     if (!m_videoTracks)
</pre>
<hr />
<pre>
1488             m_timestampOffset = m_groupStartTimestamp;
1489 
1490             for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
1491                 trackBuffer.lastFrameTimescale = 0;
1492                 trackBuffer.roundedTimestampOffset = MediaTime::invalidTime();
1493             }
1494 
1495             // 1.3.2 Set group end timestamp equal to group start timestamp.
1496             m_groupEndTimestamp = m_groupStartTimestamp;
1497 
1498             // 1.3.3 Set the need random access point flag on all track buffers to true.
1499             for (auto&amp; trackBuffer : m_trackBufferMap.values())
1500                 trackBuffer.needRandomAccessFlag = true;
1501 
1502             // 1.3.4 Unset group start timestamp.
1503             m_groupStartTimestamp = MediaTime::invalidTime();
1504         }
1505 
1506         // NOTE: this is out-of-order, but we need TrackBuffer to be able to cache the results of timestamp offset rounding
1507         // 1.5 Let track buffer equal the track buffer that the coded frame will be added to.
<span class="line-modified">1508         AtomicString trackID = sample.trackID();</span>
1509         auto it = m_trackBufferMap.find(trackID);
1510         if (it == m_trackBufferMap.end()) {
1511             // The client managed to append a sample with a trackID not present in the initialization
1512             // segment. This would be a good place to post an message to the developer console.
1513             didDropSample();
1514             return;
1515         }
1516         TrackBuffer&amp; trackBuffer = it-&gt;value;
1517 
1518         MediaTime microsecond(1, 1000000);
1519 
1520         auto roundTowardsTimeScaleWithRoundingMargin = [] (const MediaTime&amp; time, uint32_t timeScale, const MediaTime&amp; roundingMargin) {
1521             while (true) {
1522                 MediaTime roundedTime = time.toTimeScale(timeScale);
1523                 if (abs(roundedTime - time) &lt; roundingMargin || timeScale &gt;= MediaTime::MaximumTimeScale)
1524                     return roundedTime;
1525 
1526                 if (!WTF::safeMultiply(timeScale, 2, timeScale) || timeScale &gt; MediaTime::MaximumTimeScale)
1527                     timeScale = MediaTime::MaximumTimeScale;
1528             }
</pre>
<hr />
<pre>
1762 
1763         // 1.17 If spliced audio frame is set:
1764         // Add spliced audio frame to the track buffer.
1765         // If spliced timed text frame is set:
1766         // Add spliced timed text frame to the track buffer.
1767         // FIXME: Add support for sample splicing.
1768 
1769         // Otherwise:
1770         // Add the coded frame with the presentation timestamp, decode timestamp, and frame duration to the track buffer.
1771         trackBuffer.samples.addSample(sample);
1772 
1773         // Note: The terminology here is confusing: &quot;enqueuing&quot; means providing a frame to the inner media framework.
1774         // First, frames are inserted in the decode queue; later, at the end of the append all the frames in the decode
1775         // queue are &quot;enqueued&quot; (sent to the inner media framework) in `provideMediaData()`.
1776         //
1777         // In order to check whether a frame should be added to the decode queue we check whether it starts after the
1778         // lastEnqueuedDecodeKey.
1779         DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());
1780         if (trackBuffer.lastEnqueuedDecodeKey.first.isInvalid() || decodeKey &gt; trackBuffer.lastEnqueuedDecodeKey) {
1781             trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, &amp;sample));



1782         }
1783 
1784         // NOTE: the spec considers &quot;Coded Frame Duration&quot; to be the presentation duration, but this is not necessarily equal
1785         // to the decoded duration. When comparing deltas between decode timestamps, the decode duration, not the presentation.
1786         if (trackBuffer.lastDecodeTimestamp.isValid()) {
1787             MediaTime lastDecodeDuration = decodeTimestamp - trackBuffer.lastDecodeTimestamp;
1788             if (!trackBuffer.greatestDecodeDuration.isValid() || lastDecodeDuration &gt; trackBuffer.greatestDecodeDuration)
1789                 trackBuffer.greatestDecodeDuration = lastDecodeDuration;
1790         }
1791 
1792         // 1.18 Set last decode timestamp for track buffer to decode timestamp.
1793         trackBuffer.lastDecodeTimestamp = decodeTimestamp;
1794 
1795         // 1.19 Set last frame duration for track buffer to frame duration.
1796         trackBuffer.lastFrameDuration = frameDuration;
1797 
1798         // 1.20 If highest presentation timestamp for track buffer is unset or frame end timestamp is greater
1799         // than highest presentation timestamp, then set highest presentation timestamp for track buffer
1800         // to frame end timestamp.
1801         if (trackBuffer.highestPresentationTimestamp.isInvalid() || frameEndTimestamp &gt; trackBuffer.highestPresentationTimestamp)
</pre>
<hr />
<pre>
1956 }
1957 
1958 void SourceBuffer::textTrackRemoveCue(TextTrack&amp; track, TextTrackCue&amp; cue)
1959 {
1960     if (!isRemoved())
1961         m_source-&gt;mediaElement()-&gt;textTrackRemoveCue(track, cue);
1962 }
1963 
1964 void SourceBuffer::textTrackRemoveCues(TextTrack&amp; track, const TextTrackCueList&amp; cueList)
1965 {
1966     if (!isRemoved())
1967         m_source-&gt;mediaElement()-&gt;textTrackRemoveCues(track, cueList);
1968 }
1969 
1970 void SourceBuffer::textTrackKindChanged(TextTrack&amp; track)
1971 {
1972     if (!isRemoved())
1973         m_source-&gt;mediaElement()-&gt;textTrackKindChanged(track);
1974 }
1975 
<span class="line-modified">1976 void SourceBuffer::sourceBufferPrivateReenqueSamples(const AtomicString&amp; trackID)</span>
1977 {
1978     if (isRemoved())
1979         return;
1980 
1981     DEBUG_LOG(LOGIDENTIFIER);
1982     auto it = m_trackBufferMap.find(trackID);
1983     if (it == m_trackBufferMap.end())
1984         return;
1985 
1986     auto&amp; trackBuffer = it-&gt;value;
1987     trackBuffer.needsReenqueueing = true;
1988     reenqueueMediaForTime(trackBuffer, trackID, m_source-&gt;currentTime());
1989 }
1990 
<span class="line-modified">1991 void SourceBuffer::sourceBufferPrivateDidBecomeReadyForMoreSamples(const AtomicString&amp; trackID)</span>
1992 {
1993     if (isRemoved())
1994         return;
1995 
1996     DEBUG_LOG(LOGIDENTIFIER);
1997     auto it = m_trackBufferMap.find(trackID);
1998     if (it == m_trackBufferMap.end())
1999         return;
2000 
2001     auto&amp; trackBuffer = it-&gt;value;
2002     if (!trackBuffer.needsReenqueueing &amp;&amp; !m_source-&gt;isSeeking())
2003         provideMediaData(trackBuffer, trackID);
2004 }
2005 
<span class="line-modified">2006 void SourceBuffer::provideMediaData(TrackBuffer&amp; trackBuffer, const AtomicString&amp; trackID)</span>
2007 {
2008     if (m_source-&gt;isSeeking())
2009         return;
2010 
2011 #if !RELEASE_LOG_DISABLED
2012     unsigned enqueuedSamples = 0;
2013 #endif
2014 



2015     while (!trackBuffer.decodeQueue.empty()) {
2016         if (!m_private-&gt;isReadyForMoreSamples(trackID)) {

2017             m_private-&gt;notifyClientWhenReadyForMoreSamples(trackID);
2018             break;
2019         }
2020 
2021         // FIXME(rdar://problem/20635969): Remove this re-entrancy protection when the aforementioned radar is resolved; protecting
2022         // against re-entrancy introduces a small inefficency when removing appended samples from the decode queue one at a time
2023         // rather than when all samples have been enqueued.
2024         auto sample = trackBuffer.decodeQueue.begin()-&gt;second;
2025 
2026         // Do not enqueue samples spanning a significant unbuffered gap.
2027         // NOTE: one second is somewhat arbitrary. MediaSource::monitorSourceBuffers() is run
2028         // on the playbackTimer, which is effectively every 350ms. Allowing &gt; 350ms gap between
2029         // enqueued samples allows for situations where we overrun the end of a buffered range
2030         // but don&#39;t notice for 350s of playback time, and the client can enqueue data for the
2031         // new current time without triggering this early return.
2032         // FIXME(135867): Make this gap detection logic less arbitrary.
2033         MediaTime oneSecond(1, 1);
2034         if (trackBuffer.lastEnqueuedDecodeKey.first.isValid()
2035             &amp;&amp; trackBuffer.lastEnqueuedDecodeDuration.isValid()
<span class="line-modified">2036             &amp;&amp; sample-&gt;decodeTime() - trackBuffer.lastEnqueuedDecodeKey.first &gt; oneSecond + trackBuffer.lastEnqueuedDecodeDuration)</span>


2037             break;

2038 
2039         // Remove the sample from the decode queue now.
2040         trackBuffer.decodeQueue.erase(trackBuffer.decodeQueue.begin());
2041 
2042         trackBuffer.lastEnqueuedPresentationTime = sample-&gt;presentationTime();
2043         trackBuffer.lastEnqueuedDecodeKey = {sample-&gt;decodeTime(), sample-&gt;presentationTime()};
2044         trackBuffer.lastEnqueuedDecodeDuration = sample-&gt;duration();
2045         m_private-&gt;enqueueSample(sample.releaseNonNull(), trackID);
2046 #if !RELEASE_LOG_DISABLED
2047         ++enqueuedSamples;
2048 #endif
2049     }
2050 


2051 #if !RELEASE_LOG_DISABLED
<span class="line-modified">2052     DEBUG_LOG(LOGIDENTIFIER, &quot;Enqueued &quot;, enqueuedSamples, &quot; samples, &quot;, static_cast&lt;size_t&gt;(trackBuffer.decodeQueue.size()), &quot; remaining&quot;);</span>
2053 #endif
2054 
2055     trySignalAllSamplesInTrackEnqueued(trackID);
2056 }
2057 
<span class="line-modified">2058 void SourceBuffer::trySignalAllSamplesInTrackEnqueued(const AtomicString&amp; trackID)</span>



































2059 {
2060     if (m_source-&gt;isEnded() &amp;&amp; m_trackBufferMap.get(trackID).decodeQueue.empty()) {
<span class="line-modified">2061         DEBUG_LOG(LOGIDENTIFIER, &quot;All samples in track &quot;, trackID, &quot; enqueued&quot;);</span>
2062         m_private-&gt;allSamplesInTrackEnqueued(trackID);
2063     }
2064 }
2065 
2066 void SourceBuffer::trySignalAllSamplesEnqueued()
2067 {
<span class="line-modified">2068     for (const AtomicString&amp; trackID : m_trackBufferMap.keys())</span>
2069         trySignalAllSamplesInTrackEnqueued(trackID);
2070 }
2071 
<span class="line-modified">2072 void SourceBuffer::reenqueueMediaForTime(TrackBuffer&amp; trackBuffer, const AtomicString&amp; trackID, const MediaTime&amp; time)</span>
2073 {
2074     m_private-&gt;flush(trackID);
2075     trackBuffer.decodeQueue.clear();
2076 
2077     // Find the sample which contains the current presentation time.
2078     auto currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
2079 
2080     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end())
2081         currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleStartingOnOrAfterPresentationTime(time);
2082 
2083     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end()
2084         || (currentSamplePTSIterator-&gt;first - time) &gt; MediaSource::currentTimeFudgeFactor())
2085         return;
2086 
2087     // Seach backward for the previous sync sample.
2088     DecodeOrderSampleMap::KeyType decodeKey(currentSamplePTSIterator-&gt;second-&gt;decodeTime(), currentSamplePTSIterator-&gt;second-&gt;presentationTime());
2089     auto currentSampleDTSIterator = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
2090     ASSERT(currentSampleDTSIterator != trackBuffer.samples.decodeOrder().end());
2091 
2092     auto reverseCurrentSampleIter = --DecodeOrderSampleMap::reverse_iterator(currentSampleDTSIterator);
</pre>
<hr />
<pre>
2222         extraMemoryCost += trackBuffer.samples.sizeInBytes();
2223 
2224     return extraMemoryCost;
2225 }
2226 
2227 void SourceBuffer::reportExtraMemoryAllocated()
2228 {
2229     size_t extraMemoryCost = this-&gt;extraMemoryCost();
2230     if (extraMemoryCost &lt;= m_reportedExtraMemoryCost)
2231         return;
2232 
2233     size_t extraMemoryCostDelta = extraMemoryCost - m_reportedExtraMemoryCost;
2234     m_reportedExtraMemoryCost = extraMemoryCost;
2235 
2236     JSC::JSLockHolder lock(scriptExecutionContext()-&gt;vm());
2237     // FIXME: Adopt reportExtraMemoryVisited, and switch to reportExtraMemoryAllocated.
2238     // https://bugs.webkit.org/show_bug.cgi?id=142595
2239     scriptExecutionContext()-&gt;vm().heap.deprecatedReportExtraMemory(extraMemoryCostDelta);
2240 }
2241 
<span class="line-modified">2242 Vector&lt;String&gt; SourceBuffer::bufferedSamplesForTrackID(const AtomicString&amp; trackID)</span>
2243 {
2244     auto it = m_trackBufferMap.find(trackID);
2245     if (it == m_trackBufferMap.end())
2246         return Vector&lt;String&gt;();
2247 
2248     TrackBuffer&amp; trackBuffer = it-&gt;value;
2249     Vector&lt;String&gt; sampleDescriptions;
2250     for (auto&amp; pair : trackBuffer.samples.decodeOrder())
2251         sampleDescriptions.append(toString(*pair.second));
2252 
2253     return sampleDescriptions;
2254 }
2255 
<span class="line-modified">2256 Vector&lt;String&gt; SourceBuffer::enqueuedSamplesForTrackID(const AtomicString&amp; trackID)</span>
2257 {
2258     return m_private-&gt;enqueuedSamplesForTrackID(trackID);
2259 }
2260 










2261 Document&amp; SourceBuffer::document() const
2262 {
2263     ASSERT(scriptExecutionContext());
2264     return downcast&lt;Document&gt;(*scriptExecutionContext());
2265 }
2266 
2267 ExceptionOr&lt;void&gt; SourceBuffer::setMode(AppendMode newMode)
2268 {
2269     // 3.1 Attributes - mode
2270     // http://www.w3.org/TR/media-source/#widl-SourceBuffer-mode
2271 
2272     // On setting, run the following steps:
2273 
2274     // 1. Let new mode equal the new value being assigned to this attribute.
2275     // 2. If generate timestamps flag equals true and new mode equals &quot;segments&quot;, then throw an InvalidAccessError exception and abort these steps.
2276     if (m_shouldGenerateTimestamps &amp;&amp; newMode == AppendMode::Segments)
2277         return Exception { InvalidAccessError };
2278 
2279     // 3. If this object has been removed from the sourceBuffers attribute of the parent media source, then throw an InvalidStateError exception and abort these steps.
2280     // 4. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
</pre>
</td>
<td>
<hr />
<pre>
  39 #include &quot;Event.h&quot;
  40 #include &quot;EventNames.h&quot;
  41 #include &quot;GenericEventQueue.h&quot;
  42 #include &quot;HTMLMediaElement.h&quot;
  43 #include &quot;InbandTextTrack.h&quot;
  44 #include &quot;Logging.h&quot;
  45 #include &quot;MediaDescription.h&quot;
  46 #include &quot;MediaSample.h&quot;
  47 #include &quot;MediaSource.h&quot;
  48 #include &quot;SampleMap.h&quot;
  49 #include &quot;SourceBufferList.h&quot;
  50 #include &quot;SourceBufferPrivate.h&quot;
  51 #include &quot;TextTrackList.h&quot;
  52 #include &quot;TimeRanges.h&quot;
  53 #include &quot;VideoTrackList.h&quot;
  54 #include &lt;JavaScriptCore/JSCInlines.h&gt;
  55 #include &lt;JavaScriptCore/JSLock.h&gt;
  56 #include &lt;JavaScriptCore/VM.h&gt;
  57 #include &lt;limits&gt;
  58 #include &lt;wtf/CheckedArithmetic.h&gt;
<span class="line-added">  59 #include &lt;wtf/IsoMallocInlines.h&gt;</span>
  60 
  61 namespace WebCore {
  62 
<span class="line-added">  63 WTF_MAKE_ISO_ALLOCATED_IMPL(SourceBuffer);</span>
<span class="line-added">  64 </span>
  65 static const double ExponentialMovingAverageCoefficient = 0.1;
  66 
  67 struct SourceBuffer::TrackBuffer {
  68     MediaTime lastDecodeTimestamp;
  69     MediaTime greatestDecodeDuration;
  70     MediaTime lastFrameDuration;
  71     MediaTime highestPresentationTimestamp;
  72     MediaTime lastEnqueuedPresentationTime;
<span class="line-added">  73     MediaTime minimumEnqueuedPresentationTime;</span>
  74     DecodeOrderSampleMap::KeyType lastEnqueuedDecodeKey;
  75     MediaTime lastEnqueuedDecodeDuration;
  76     MediaTime roundedTimestampOffset;
  77     uint32_t lastFrameTimescale { 0 };
  78     bool needRandomAccessFlag { true };
  79     bool enabled { false };
  80     bool needsReenqueueing { false };
<span class="line-added">  81     bool needsMinimumUpcomingPresentationTimeUpdating { false };</span>
  82     SampleMap samples;
  83     DecodeOrderSampleMap::MapType decodeQueue;
  84     RefPtr&lt;MediaDescription&gt; description;
  85     PlatformTimeRanges buffered;
  86 
  87     TrackBuffer()
  88         : lastDecodeTimestamp(MediaTime::invalidTime())
  89         , greatestDecodeDuration(MediaTime::invalidTime())
  90         , lastFrameDuration(MediaTime::invalidTime())
  91         , highestPresentationTimestamp(MediaTime::invalidTime())
  92         , lastEnqueuedPresentationTime(MediaTime::invalidTime())
  93         , lastEnqueuedDecodeKey({MediaTime::invalidTime(), MediaTime::invalidTime()})
  94         , lastEnqueuedDecodeDuration(MediaTime::invalidTime())
  95     {
  96     }
  97 };
  98 
  99 Ref&lt;SourceBuffer&gt; SourceBuffer::create(Ref&lt;SourceBufferPrivate&gt;&amp;&amp; sourceBufferPrivate, MediaSource* source)
 100 {
 101     auto sourceBuffer = adoptRef(*new SourceBuffer(WTFMove(sourceBufferPrivate), source));
</pre>
<hr />
<pre>
 466     if (isRemoved())
 467         return;
 468 
 469     abortIfUpdating();
 470 
 471     for (auto&amp; trackBufferPair : m_trackBufferMap.values()) {
 472         trackBufferPair.samples.clear();
 473         trackBufferPair.decodeQueue.clear();
 474     }
 475 
 476     m_private-&gt;removedFromMediaSource();
 477     m_source = nullptr;
 478 }
 479 
 480 void SourceBuffer::seekToTime(const MediaTime&amp; time)
 481 {
 482     ALWAYS_LOG(LOGIDENTIFIER, time);
 483 
 484     for (auto&amp; trackBufferPair : m_trackBufferMap) {
 485         TrackBuffer&amp; trackBuffer = trackBufferPair.value;
<span class="line-modified"> 486         const AtomString&amp; trackID = trackBufferPair.key;</span>
 487 
 488         trackBuffer.needsReenqueueing = true;
 489         reenqueueMediaForTime(trackBuffer, trackID, time);
 490     }
 491 }
 492 
 493 MediaTime SourceBuffer::sourceBufferPrivateFastSeekTimeForMediaTime(const MediaTime&amp; targetTime, const MediaTime&amp; negativeThreshold, const MediaTime&amp; positiveThreshold)
 494 {
 495     MediaTime seekTime = targetTime;
 496     MediaTime lowerBoundTime = targetTime - negativeThreshold;
 497     MediaTime upperBoundTime = targetTime + positiveThreshold;
 498 
 499     for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
 500         // Find the sample which contains the target time time.
 501         auto futureSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSampleAfterPresentationTime(targetTime, positiveThreshold);
 502         auto pastSyncSampleIterator = trackBuffer.samples.decodeOrder().findSyncSamplePriorToPresentationTime(targetTime, negativeThreshold);
 503         auto upperBound = trackBuffer.samples.decodeOrder().end();
 504         auto lowerBound = trackBuffer.samples.decodeOrder().rend();
 505 
 506         if (futureSyncSampleIterator == upperBound &amp;&amp; pastSyncSampleIterator == lowerBound)
</pre>
<hr />
<pre>
 555     m_asyncEventQueue.close();
 556     m_appendBufferTimer.stop();
 557     m_removeTimer.stop();
 558 }
 559 
 560 bool SourceBuffer::canSuspendForDocumentSuspension() const
 561 {
 562     return !hasPendingActivity();
 563 }
 564 
 565 const char* SourceBuffer::activeDOMObjectName() const
 566 {
 567     return &quot;SourceBuffer&quot;;
 568 }
 569 
 570 bool SourceBuffer::isRemoved() const
 571 {
 572     return !m_source;
 573 }
 574 
<span class="line-modified"> 575 void SourceBuffer::scheduleEvent(const AtomString&amp; eventName)</span>
 576 {
 577     auto event = Event::create(eventName, Event::CanBubble::No, Event::IsCancelable::No);
 578     event-&gt;setTarget(this);
 579 
 580     m_asyncEventQueue.enqueueEvent(WTFMove(event));
 581 }
 582 
 583 ExceptionOr&lt;void&gt; SourceBuffer::appendBufferInternal(const unsigned char* data, unsigned size)
 584 {
 585     // Section 3.2 appendBuffer()
 586     // https://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html#widl-SourceBuffer-appendBuffer-void-ArrayBufferView-data
 587 
 588     // Step 1 is enforced by the caller.
 589     // 2. Run the prepare append algorithm.
 590     // Section 3.5.4 Prepare AppendAlgorithm
 591 
 592     // 1. If the SourceBuffer has been removed from the sourceBuffers attribute of the parent media source
 593     // then throw an InvalidStateError exception and abort these steps.
 594     // 2. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
 595     if (isRemoved() || m_updating)
</pre>
<hr />
<pre>
 688     // NOTE: return to Section 3.5.5
 689     // 2.If the segment parser loop algorithm in the previous step was aborted, then abort this algorithm.
 690     if (result != AppendSucceeded)
 691         return;
 692 
 693     // 3. Set the updating attribute to false.
 694     m_updating = false;
 695 
 696     // 4. Queue a task to fire a simple event named update at this SourceBuffer object.
 697     scheduleEvent(eventNames().updateEvent);
 698 
 699     // 5. Queue a task to fire a simple event named updateend at this SourceBuffer object.
 700     scheduleEvent(eventNames().updateendEvent);
 701 
 702     if (m_source)
 703         m_source-&gt;monitorSourceBuffers();
 704 
 705     MediaTime currentMediaTime = m_source-&gt;currentTime();
 706     for (auto&amp; trackBufferPair : m_trackBufferMap) {
 707         TrackBuffer&amp; trackBuffer = trackBufferPair.value;
<span class="line-modified"> 708         const AtomString&amp; trackID = trackBufferPair.key;</span>
 709 
 710         if (trackBuffer.needsReenqueueing) {
 711             DEBUG_LOG(LOGIDENTIFIER, &quot;reenqueuing at time &quot;, currentMediaTime);
 712             reenqueueMediaForTime(trackBuffer, trackID, currentMediaTime);
 713         } else
 714             provideMediaData(trackBuffer, trackID);
 715     }
 716 
 717     reportExtraMemoryAllocated();
 718     if (extraMemoryCost() &gt; this-&gt;maximumBufferSize())
 719         m_bufferFull = true;
 720 
 721     DEBUG_LOG(LOGIDENTIFIER);
 722 }
 723 
 724 void SourceBuffer::sourceBufferPrivateDidReceiveRenderingError(int error)
 725 {
 726 #if RELEASE_LOG_DISABLED
 727     UNUSED_PARAM(error);
 728 #endif
 729 
 730     ERROR_LOG(LOGIDENTIFIER, error);
 731 
 732     if (!isRemoved())
 733         m_source-&gt;streamEndedWithError(MediaSource::EndOfStreamError::Decode);
 734 }
 735 
 736 static bool decodeTimeComparator(const PresentationOrderSampleMap::MapType::value_type&amp; a, const PresentationOrderSampleMap::MapType::value_type&amp; b)
 737 {
 738     return a.second-&gt;decodeTime() &lt; b.second-&gt;decodeTime();
 739 }
 740 
 741 static PlatformTimeRanges removeSamplesFromTrackBuffer(const DecodeOrderSampleMap::MapType&amp; samples, SourceBuffer::TrackBuffer&amp; trackBuffer, const SourceBuffer* buffer, const char* logPrefix)
 742 {
 743 #if !RELEASE_LOG_DISABLED
 744     MediaTime earliestSample = MediaTime::positiveInfiniteTime();
 745     MediaTime latestSample = MediaTime::zeroTime();
 746     size_t bytesRemoved = 0;
 747     auto logIdentifier = WTF::Logger::LogSiteIdentifier(buffer-&gt;logClassName(), logPrefix, buffer-&gt;logIdentifier());
 748     auto&amp; logger = buffer-&gt;logger();
<span class="line-modified"> 749     auto willLog = logger.willLog(buffer-&gt;logChannel(), WTFLogLevel::Debug);</span>
 750 #else
 751     UNUSED_PARAM(logPrefix);
 752     UNUSED_PARAM(buffer);
 753 #endif
 754 
 755     PlatformTimeRanges erasedRanges;
 756     for (const auto&amp; sampleIt : samples) {
 757         const DecodeOrderSampleMap::KeyType&amp; decodeKey = sampleIt.first;
 758 #if !RELEASE_LOG_DISABLED
 759         size_t startBufferSize = trackBuffer.samples.sizeInBytes();
 760 #endif
 761 
 762         const RefPtr&lt;MediaSample&gt;&amp; sample = sampleIt.second;
 763 
 764 #if !RELEASE_LOG_DISABLED
 765         if (willLog)
 766             logger.debug(buffer-&gt;logChannel(), logIdentifier, &quot;removing sample &quot;, *sampleIt.second);
 767 #endif
 768 
 769         // Remove the erased samples from the TrackBuffer sample map.
</pre>
<hr />
<pre>
 817     if (bytesRemoved &amp;&amp; willLog)
 818         logger.debug(buffer-&gt;logChannel(), logIdentifier, &quot;removed &quot;, bytesRemoved, &quot;, start = &quot;, earliestSample, &quot;, end = &quot;, latestSample);
 819 #endif
 820 
 821     return erasedRanges;
 822 }
 823 
 824 void SourceBuffer::removeCodedFrames(const MediaTime&amp; start, const MediaTime&amp; end)
 825 {
 826     DEBUG_LOG(LOGIDENTIFIER, &quot;start = &quot;, start, &quot;, end = &quot;, end);
 827 
 828     // 3.5.9 Coded Frame Removal Algorithm
 829     // https://dvcs.w3.org/hg/html-media/raw-file/tip/media-source/media-source.html#sourcebuffer-coded-frame-removal
 830 
 831     // 1. Let start be the starting presentation timestamp for the removal range.
 832     MediaTime durationMediaTime = m_source-&gt;duration();
 833     MediaTime currentMediaTime = m_source-&gt;currentTime();
 834 
 835     // 2. Let end be the end presentation timestamp for the removal range.
 836     // 3. For each track buffer in this source buffer, run the following steps:
<span class="line-modified"> 837     for (auto&amp; trackBufferKeyValue : m_trackBufferMap) {</span>
<span class="line-added"> 838         TrackBuffer&amp; trackBuffer = trackBufferKeyValue.value;</span>
<span class="line-added"> 839         AtomString trackID = trackBufferKeyValue.key;</span>
<span class="line-added"> 840 </span>
 841         // 3.1. Let remove end timestamp be the current value of duration
 842         // 3.2 If this track buffer has a random access point timestamp that is greater than or equal to end, then update
 843         // remove end timestamp to that random access point timestamp.
 844         // NOTE: Step 3.2 will be incorrect for any random access point timestamp whose decode time is later than the sample at end,
 845         // but whose presentation time is less than the sample at end. Skip this step until step 3.3 below.
 846 
 847         // NOTE: To handle MediaSamples which may be an amalgamation of multiple shorter samples, find samples whose presentation
 848         // interval straddles the start and end times, and divide them if possible:
 849         auto divideSampleIfPossibleAtPresentationTime = [&amp;] (const MediaTime&amp; time) {
 850             auto sampleIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
 851             if (sampleIterator == trackBuffer.samples.presentationOrder().end())
 852                 return;
 853             RefPtr&lt;MediaSample&gt; sample = sampleIterator-&gt;second;
 854             if (!sample-&gt;isDivisable())
 855                 return;
 856             std::pair&lt;RefPtr&lt;MediaSample&gt;, RefPtr&lt;MediaSample&gt;&gt; replacementSamples = sample-&gt;divide(time);
 857             if (!replacementSamples.first || !replacementSamples.second)
 858                 return;
 859             DEBUG_LOG(LOGIDENTIFIER, &quot;splitting sample &quot;, *sample, &quot; into &quot;, *replacementSamples.first, &quot; and &quot;, *replacementSamples.second);
 860             trackBuffer.samples.removeSample(sample.get());
</pre>
<hr />
<pre>
 872         // 3.3 Remove all media data, from this track buffer, that contain starting timestamps greater than or equal to
 873         // start and less than the remove end timestamp.
 874         // NOTE: frames must be removed in decode order, so that all dependant frames between the frame to be removed
 875         // and the next sync sample frame are removed. But we must start from the first sample in decode order, not
 876         // presentation order.
 877         auto minmaxDecodeTimeIterPair = std::minmax_element(removePresentationStart, removePresentationEnd, decodeTimeComparator);
 878         auto&amp; firstSample = *minmaxDecodeTimeIterPair.first-&gt;second;
 879         auto&amp; lastSample = *minmaxDecodeTimeIterPair.second-&gt;second;
 880         auto removeDecodeStart = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({firstSample.decodeTime(), firstSample.presentationTime()});
 881         auto removeDecodeLast = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey({lastSample.decodeTime(), lastSample.presentationTime()});
 882         auto removeDecodeEnd = trackBuffer.samples.decodeOrder().findSyncSampleAfterDecodeIterator(removeDecodeLast);
 883 
 884         DecodeOrderSampleMap::MapType erasedSamples(removeDecodeStart, removeDecodeEnd);
 885         PlatformTimeRanges erasedRanges = removeSamplesFromTrackBuffer(erasedSamples, trackBuffer, this, &quot;removeCodedFrames&quot;);
 886 
 887         // Only force the TrackBuffer to re-enqueue if the removed ranges overlap with enqueued and possibly
 888         // not yet displayed samples.
 889         if (trackBuffer.lastEnqueuedPresentationTime.isValid() &amp;&amp; currentMediaTime &lt; trackBuffer.lastEnqueuedPresentationTime) {
 890             PlatformTimeRanges possiblyEnqueuedRanges(currentMediaTime, trackBuffer.lastEnqueuedPresentationTime);
 891             possiblyEnqueuedRanges.intersectWith(erasedRanges);
<span class="line-modified"> 892             if (possiblyEnqueuedRanges.length()) {</span>
 893                 trackBuffer.needsReenqueueing = true;
<span class="line-added"> 894                 DEBUG_LOG(LOGIDENTIFIER, &quot;the range in removeCodedFrames() includes already enqueued samples, reenqueueing from &quot;, currentMediaTime);</span>
<span class="line-added"> 895                 reenqueueMediaForTime(trackBuffer, trackID, currentMediaTime);</span>
<span class="line-added"> 896             }</span>
 897         }
 898 
 899         erasedRanges.invert();
 900         trackBuffer.buffered.intersectWith(erasedRanges);
 901         setBufferedDirty(true);
 902 
 903         // 3.4 If this object is in activeSourceBuffers, the current playback position is greater than or equal to start
 904         // and less than the remove end timestamp, and HTMLMediaElement.readyState is greater than HAVE_METADATA, then set
 905         // the HTMLMediaElement.readyState attribute to HAVE_METADATA and stall playback.
 906         if (m_active &amp;&amp; currentMediaTime &gt;= start &amp;&amp; currentMediaTime &lt; end &amp;&amp; m_private-&gt;readyState() &gt; MediaPlayer::HaveMetadata)
 907             m_private-&gt;setReadyState(MediaPlayer::HaveMetadata);
 908     }
 909 
 910     updateBufferedFromTrackBuffers();
 911 
 912     // 4. If buffer full flag equals true and this object is ready to accept more bytes, then set the buffer full flag to false.
 913     // No-op
 914 
 915     LOG(Media, &quot;SourceBuffer::removeCodedFrames(%p) - buffered = %s&quot;, this, toString(m_buffered-&gt;ranges()).utf8().data());
 916 }
</pre>
<hr />
<pre>
 982             m_bufferFull = false;
 983             break;
 984         }
 985 
 986         rangeStart += thirtySeconds;
 987         rangeEnd += thirtySeconds;
 988     }
 989 
 990 #if !RELEASE_LOG_DISABLED
 991     if (!m_bufferFull) {
 992         DEBUG_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost());
 993         return;
 994     }
 995 #endif
 996 
 997     // If there still isn&#39;t enough free space and there buffers in time ranges after the current range (ie. there is a gap after
 998     // the current buffered range), delete 30 seconds at a time from duration back to the current time range or 30 seconds after
 999     // currenTime whichever we hit first.
1000     auto buffered = m_buffered-&gt;ranges();
1001     size_t currentTimeRange = buffered.find(currentTime);
<span class="line-modified">1002     if (currentTimeRange == buffered.length() - 1) {</span>
1003 #if !RELEASE_LOG_DISABLED
<span class="line-modified">1004         ERROR_LOG(LOGIDENTIFIER, &quot;FAILED to free enough after evicting &quot;, initialBufferedSize - extraMemoryCost());</span>
1005 #endif
1006         return;
1007     }
1008 
1009     MediaTime minimumRangeStart = currentTime + thirtySeconds;
1010 
1011     rangeEnd = m_source-&gt;duration();
1012     rangeStart = rangeEnd - thirtySeconds;
1013     while (rangeStart &gt; minimumRangeStart) {
1014 
1015         // Do not evict data from the time range that contains currentTime.
1016         size_t startTimeRange = buffered.find(rangeStart);
<span class="line-modified">1017         if (currentTimeRange != notFound &amp;&amp; startTimeRange == currentTimeRange) {</span>
1018             size_t endTimeRange = buffered.find(rangeEnd);
<span class="line-modified">1019             if (currentTimeRange != notFound &amp;&amp; endTimeRange == currentTimeRange)</span>
1020                 break;
1021 
1022             rangeEnd = buffered.start(endTimeRange);
1023         }
1024 
1025         // 4. For each range in removal ranges, run the coded frame removal algorithm with start and
1026         // end equal to the removal range start and end timestamp respectively.
1027         removeCodedFrames(std::max(minimumRangeStart, rangeStart), rangeEnd);
1028         if (extraMemoryCost() + newDataSize &lt; maximumBufferSize) {
1029             m_bufferFull = false;
1030             break;
1031         }
1032 
1033         rangeStart -= thirtySeconds;
1034         rangeEnd -= thirtySeconds;
1035     }
1036 
1037 #if !RELEASE_LOG_DISABLED
1038     if (m_bufferFull)
<span class="line-modified">1039         ERROR_LOG(LOGIDENTIFIER, &quot;FAILED to free enough after evicting &quot;, initialBufferedSize - extraMemoryCost());</span>
1040     else
1041         DEBUG_LOG(LOGIDENTIFIER, &quot;evicted &quot;, initialBufferedSize - extraMemoryCost());
1042 #endif
1043 }
1044 
1045 size_t SourceBuffer::maximumBufferSize() const
1046 {
1047     if (isRemoved())
1048         return 0;
1049 
1050     auto* element = m_source-&gt;mediaElement();
1051     if (!element)
1052         return 0;
1053 
1054     return element-&gt;maximumSourceBufferSize(*this);
1055 }
1056 
1057 VideoTrackList&amp; SourceBuffer::videoTracks()
1058 {
1059     if (!m_videoTracks)
</pre>
<hr />
<pre>
1499             m_timestampOffset = m_groupStartTimestamp;
1500 
1501             for (auto&amp; trackBuffer : m_trackBufferMap.values()) {
1502                 trackBuffer.lastFrameTimescale = 0;
1503                 trackBuffer.roundedTimestampOffset = MediaTime::invalidTime();
1504             }
1505 
1506             // 1.3.2 Set group end timestamp equal to group start timestamp.
1507             m_groupEndTimestamp = m_groupStartTimestamp;
1508 
1509             // 1.3.3 Set the need random access point flag on all track buffers to true.
1510             for (auto&amp; trackBuffer : m_trackBufferMap.values())
1511                 trackBuffer.needRandomAccessFlag = true;
1512 
1513             // 1.3.4 Unset group start timestamp.
1514             m_groupStartTimestamp = MediaTime::invalidTime();
1515         }
1516 
1517         // NOTE: this is out-of-order, but we need TrackBuffer to be able to cache the results of timestamp offset rounding
1518         // 1.5 Let track buffer equal the track buffer that the coded frame will be added to.
<span class="line-modified">1519         AtomString trackID = sample.trackID();</span>
1520         auto it = m_trackBufferMap.find(trackID);
1521         if (it == m_trackBufferMap.end()) {
1522             // The client managed to append a sample with a trackID not present in the initialization
1523             // segment. This would be a good place to post an message to the developer console.
1524             didDropSample();
1525             return;
1526         }
1527         TrackBuffer&amp; trackBuffer = it-&gt;value;
1528 
1529         MediaTime microsecond(1, 1000000);
1530 
1531         auto roundTowardsTimeScaleWithRoundingMargin = [] (const MediaTime&amp; time, uint32_t timeScale, const MediaTime&amp; roundingMargin) {
1532             while (true) {
1533                 MediaTime roundedTime = time.toTimeScale(timeScale);
1534                 if (abs(roundedTime - time) &lt; roundingMargin || timeScale &gt;= MediaTime::MaximumTimeScale)
1535                     return roundedTime;
1536 
1537                 if (!WTF::safeMultiply(timeScale, 2, timeScale) || timeScale &gt; MediaTime::MaximumTimeScale)
1538                     timeScale = MediaTime::MaximumTimeScale;
1539             }
</pre>
<hr />
<pre>
1773 
1774         // 1.17 If spliced audio frame is set:
1775         // Add spliced audio frame to the track buffer.
1776         // If spliced timed text frame is set:
1777         // Add spliced timed text frame to the track buffer.
1778         // FIXME: Add support for sample splicing.
1779 
1780         // Otherwise:
1781         // Add the coded frame with the presentation timestamp, decode timestamp, and frame duration to the track buffer.
1782         trackBuffer.samples.addSample(sample);
1783 
1784         // Note: The terminology here is confusing: &quot;enqueuing&quot; means providing a frame to the inner media framework.
1785         // First, frames are inserted in the decode queue; later, at the end of the append all the frames in the decode
1786         // queue are &quot;enqueued&quot; (sent to the inner media framework) in `provideMediaData()`.
1787         //
1788         // In order to check whether a frame should be added to the decode queue we check whether it starts after the
1789         // lastEnqueuedDecodeKey.
1790         DecodeOrderSampleMap::KeyType decodeKey(sample.decodeTime(), sample.presentationTime());
1791         if (trackBuffer.lastEnqueuedDecodeKey.first.isInvalid() || decodeKey &gt; trackBuffer.lastEnqueuedDecodeKey) {
1792             trackBuffer.decodeQueue.insert(DecodeOrderSampleMap::MapType::value_type(decodeKey, &amp;sample));
<span class="line-added">1793 </span>
<span class="line-added">1794             if (trackBuffer.minimumEnqueuedPresentationTime.isValid() &amp;&amp; sample.presentationTime() &lt; trackBuffer.minimumEnqueuedPresentationTime)</span>
<span class="line-added">1795                 trackBuffer.needsMinimumUpcomingPresentationTimeUpdating = true;</span>
1796         }
1797 
1798         // NOTE: the spec considers &quot;Coded Frame Duration&quot; to be the presentation duration, but this is not necessarily equal
1799         // to the decoded duration. When comparing deltas between decode timestamps, the decode duration, not the presentation.
1800         if (trackBuffer.lastDecodeTimestamp.isValid()) {
1801             MediaTime lastDecodeDuration = decodeTimestamp - trackBuffer.lastDecodeTimestamp;
1802             if (!trackBuffer.greatestDecodeDuration.isValid() || lastDecodeDuration &gt; trackBuffer.greatestDecodeDuration)
1803                 trackBuffer.greatestDecodeDuration = lastDecodeDuration;
1804         }
1805 
1806         // 1.18 Set last decode timestamp for track buffer to decode timestamp.
1807         trackBuffer.lastDecodeTimestamp = decodeTimestamp;
1808 
1809         // 1.19 Set last frame duration for track buffer to frame duration.
1810         trackBuffer.lastFrameDuration = frameDuration;
1811 
1812         // 1.20 If highest presentation timestamp for track buffer is unset or frame end timestamp is greater
1813         // than highest presentation timestamp, then set highest presentation timestamp for track buffer
1814         // to frame end timestamp.
1815         if (trackBuffer.highestPresentationTimestamp.isInvalid() || frameEndTimestamp &gt; trackBuffer.highestPresentationTimestamp)
</pre>
<hr />
<pre>
1970 }
1971 
1972 void SourceBuffer::textTrackRemoveCue(TextTrack&amp; track, TextTrackCue&amp; cue)
1973 {
1974     if (!isRemoved())
1975         m_source-&gt;mediaElement()-&gt;textTrackRemoveCue(track, cue);
1976 }
1977 
1978 void SourceBuffer::textTrackRemoveCues(TextTrack&amp; track, const TextTrackCueList&amp; cueList)
1979 {
1980     if (!isRemoved())
1981         m_source-&gt;mediaElement()-&gt;textTrackRemoveCues(track, cueList);
1982 }
1983 
1984 void SourceBuffer::textTrackKindChanged(TextTrack&amp; track)
1985 {
1986     if (!isRemoved())
1987         m_source-&gt;mediaElement()-&gt;textTrackKindChanged(track);
1988 }
1989 
<span class="line-modified">1990 void SourceBuffer::sourceBufferPrivateReenqueSamples(const AtomString&amp; trackID)</span>
1991 {
1992     if (isRemoved())
1993         return;
1994 
1995     DEBUG_LOG(LOGIDENTIFIER);
1996     auto it = m_trackBufferMap.find(trackID);
1997     if (it == m_trackBufferMap.end())
1998         return;
1999 
2000     auto&amp; trackBuffer = it-&gt;value;
2001     trackBuffer.needsReenqueueing = true;
2002     reenqueueMediaForTime(trackBuffer, trackID, m_source-&gt;currentTime());
2003 }
2004 
<span class="line-modified">2005 void SourceBuffer::sourceBufferPrivateDidBecomeReadyForMoreSamples(const AtomString&amp; trackID)</span>
2006 {
2007     if (isRemoved())
2008         return;
2009 
2010     DEBUG_LOG(LOGIDENTIFIER);
2011     auto it = m_trackBufferMap.find(trackID);
2012     if (it == m_trackBufferMap.end())
2013         return;
2014 
2015     auto&amp; trackBuffer = it-&gt;value;
2016     if (!trackBuffer.needsReenqueueing &amp;&amp; !m_source-&gt;isSeeking())
2017         provideMediaData(trackBuffer, trackID);
2018 }
2019 
<span class="line-modified">2020 void SourceBuffer::provideMediaData(TrackBuffer&amp; trackBuffer, const AtomString&amp; trackID)</span>
2021 {
2022     if (m_source-&gt;isSeeking())
2023         return;
2024 
2025 #if !RELEASE_LOG_DISABLED
2026     unsigned enqueuedSamples = 0;
2027 #endif
2028 
<span class="line-added">2029     if (trackBuffer.needsMinimumUpcomingPresentationTimeUpdating)</span>
<span class="line-added">2030         resetMinimumUpcomingPresentationTime(trackBuffer, trackID);</span>
<span class="line-added">2031 </span>
2032     while (!trackBuffer.decodeQueue.empty()) {
2033         if (!m_private-&gt;isReadyForMoreSamples(trackID)) {
<span class="line-added">2034             DEBUG_LOG(LOGIDENTIFIER, &quot;bailing early, track id &quot;, trackID, &quot; is not ready for more data&quot;);</span>
2035             m_private-&gt;notifyClientWhenReadyForMoreSamples(trackID);
2036             break;
2037         }
2038 
2039         // FIXME(rdar://problem/20635969): Remove this re-entrancy protection when the aforementioned radar is resolved; protecting
2040         // against re-entrancy introduces a small inefficency when removing appended samples from the decode queue one at a time
2041         // rather than when all samples have been enqueued.
2042         auto sample = trackBuffer.decodeQueue.begin()-&gt;second;
2043 
2044         // Do not enqueue samples spanning a significant unbuffered gap.
2045         // NOTE: one second is somewhat arbitrary. MediaSource::monitorSourceBuffers() is run
2046         // on the playbackTimer, which is effectively every 350ms. Allowing &gt; 350ms gap between
2047         // enqueued samples allows for situations where we overrun the end of a buffered range
2048         // but don&#39;t notice for 350s of playback time, and the client can enqueue data for the
2049         // new current time without triggering this early return.
2050         // FIXME(135867): Make this gap detection logic less arbitrary.
2051         MediaTime oneSecond(1, 1);
2052         if (trackBuffer.lastEnqueuedDecodeKey.first.isValid()
2053             &amp;&amp; trackBuffer.lastEnqueuedDecodeDuration.isValid()
<span class="line-modified">2054             &amp;&amp; sample-&gt;decodeTime() - trackBuffer.lastEnqueuedDecodeKey.first &gt; oneSecond + trackBuffer.lastEnqueuedDecodeDuration) {</span>
<span class="line-added">2055 </span>
<span class="line-added">2056         DEBUG_LOG(LOGIDENTIFIER, &quot;bailing early because of unbuffered gap, new sample: &quot;, sample-&gt;decodeTime(), &quot;, last enqueued sample ends: &quot;, trackBuffer.lastEnqueuedDecodeKey.first + trackBuffer.lastEnqueuedDecodeDuration);</span>
2057             break;
<span class="line-added">2058         }</span>
2059 
2060         // Remove the sample from the decode queue now.
2061         trackBuffer.decodeQueue.erase(trackBuffer.decodeQueue.begin());
2062 
2063         trackBuffer.lastEnqueuedPresentationTime = sample-&gt;presentationTime();
2064         trackBuffer.lastEnqueuedDecodeKey = {sample-&gt;decodeTime(), sample-&gt;presentationTime()};
2065         trackBuffer.lastEnqueuedDecodeDuration = sample-&gt;duration();
2066         m_private-&gt;enqueueSample(sample.releaseNonNull(), trackID);
2067 #if !RELEASE_LOG_DISABLED
2068         ++enqueuedSamples;
2069 #endif
2070     }
2071 
<span class="line-added">2072     updateMinimumUpcomingPresentationTime(trackBuffer, trackID);</span>
<span class="line-added">2073 </span>
2074 #if !RELEASE_LOG_DISABLED
<span class="line-modified">2075     DEBUG_LOG(LOGIDENTIFIER, &quot;enqueued &quot;, enqueuedSamples, &quot; samples, &quot;, static_cast&lt;size_t&gt;(trackBuffer.decodeQueue.size()), &quot; remaining&quot;);</span>
2076 #endif
2077 
2078     trySignalAllSamplesInTrackEnqueued(trackID);
2079 }
2080 
<span class="line-modified">2081 void SourceBuffer::updateMinimumUpcomingPresentationTime(TrackBuffer&amp; trackBuffer, const AtomString&amp; trackID)</span>
<span class="line-added">2082 {</span>
<span class="line-added">2083     if (!m_private-&gt;canSetMinimumUpcomingPresentationTime(trackID))</span>
<span class="line-added">2084         return;</span>
<span class="line-added">2085 </span>
<span class="line-added">2086     if (trackBuffer.decodeQueue.empty()) {</span>
<span class="line-added">2087         trackBuffer.minimumEnqueuedPresentationTime = MediaTime::invalidTime();</span>
<span class="line-added">2088         m_private-&gt;clearMinimumUpcomingPresentationTime(trackID);</span>
<span class="line-added">2089         return;</span>
<span class="line-added">2090     }</span>
<span class="line-added">2091 </span>
<span class="line-added">2092     auto minPts = std::min_element(trackBuffer.decodeQueue.begin(), trackBuffer.decodeQueue.end(), [](auto&amp; left, auto&amp; right) -&gt; bool {</span>
<span class="line-added">2093         return left.second-&gt;outputPresentationTime() &lt; right.second-&gt;outputPresentationTime();</span>
<span class="line-added">2094     });</span>
<span class="line-added">2095 </span>
<span class="line-added">2096     if (minPts == trackBuffer.decodeQueue.end()) {</span>
<span class="line-added">2097         trackBuffer.minimumEnqueuedPresentationTime = MediaTime::invalidTime();</span>
<span class="line-added">2098         m_private-&gt;clearMinimumUpcomingPresentationTime(trackID);</span>
<span class="line-added">2099         return;</span>
<span class="line-added">2100     }</span>
<span class="line-added">2101 </span>
<span class="line-added">2102     trackBuffer.minimumEnqueuedPresentationTime = minPts-&gt;second-&gt;outputPresentationTime();</span>
<span class="line-added">2103     m_private-&gt;setMinimumUpcomingPresentationTime(trackID, trackBuffer.minimumEnqueuedPresentationTime);</span>
<span class="line-added">2104 }</span>
<span class="line-added">2105 </span>
<span class="line-added">2106 </span>
<span class="line-added">2107 void SourceBuffer::resetMinimumUpcomingPresentationTime(TrackBuffer&amp; trackBuffer, const AtomString&amp; trackID)</span>
<span class="line-added">2108 {</span>
<span class="line-added">2109     if (!m_private-&gt;canSetMinimumUpcomingPresentationTime(trackID))</span>
<span class="line-added">2110         return;</span>
<span class="line-added">2111 </span>
<span class="line-added">2112     trackBuffer.minimumEnqueuedPresentationTime = MediaTime::invalidTime();</span>
<span class="line-added">2113     m_private-&gt;clearMinimumUpcomingPresentationTime(trackID);</span>
<span class="line-added">2114 }</span>
<span class="line-added">2115 </span>
<span class="line-added">2116 void SourceBuffer::trySignalAllSamplesInTrackEnqueued(const AtomString&amp; trackID)</span>
2117 {
2118     if (m_source-&gt;isEnded() &amp;&amp; m_trackBufferMap.get(trackID).decodeQueue.empty()) {
<span class="line-modified">2119         DEBUG_LOG(LOGIDENTIFIER, &quot;enqueued all samples from track &quot;, trackID);</span>
2120         m_private-&gt;allSamplesInTrackEnqueued(trackID);
2121     }
2122 }
2123 
2124 void SourceBuffer::trySignalAllSamplesEnqueued()
2125 {
<span class="line-modified">2126     for (const AtomString&amp; trackID : m_trackBufferMap.keys())</span>
2127         trySignalAllSamplesInTrackEnqueued(trackID);
2128 }
2129 
<span class="line-modified">2130 void SourceBuffer::reenqueueMediaForTime(TrackBuffer&amp; trackBuffer, const AtomString&amp; trackID, const MediaTime&amp; time)</span>
2131 {
2132     m_private-&gt;flush(trackID);
2133     trackBuffer.decodeQueue.clear();
2134 
2135     // Find the sample which contains the current presentation time.
2136     auto currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleContainingPresentationTime(time);
2137 
2138     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end())
2139         currentSamplePTSIterator = trackBuffer.samples.presentationOrder().findSampleStartingOnOrAfterPresentationTime(time);
2140 
2141     if (currentSamplePTSIterator == trackBuffer.samples.presentationOrder().end()
2142         || (currentSamplePTSIterator-&gt;first - time) &gt; MediaSource::currentTimeFudgeFactor())
2143         return;
2144 
2145     // Seach backward for the previous sync sample.
2146     DecodeOrderSampleMap::KeyType decodeKey(currentSamplePTSIterator-&gt;second-&gt;decodeTime(), currentSamplePTSIterator-&gt;second-&gt;presentationTime());
2147     auto currentSampleDTSIterator = trackBuffer.samples.decodeOrder().findSampleWithDecodeKey(decodeKey);
2148     ASSERT(currentSampleDTSIterator != trackBuffer.samples.decodeOrder().end());
2149 
2150     auto reverseCurrentSampleIter = --DecodeOrderSampleMap::reverse_iterator(currentSampleDTSIterator);
</pre>
<hr />
<pre>
2280         extraMemoryCost += trackBuffer.samples.sizeInBytes();
2281 
2282     return extraMemoryCost;
2283 }
2284 
2285 void SourceBuffer::reportExtraMemoryAllocated()
2286 {
2287     size_t extraMemoryCost = this-&gt;extraMemoryCost();
2288     if (extraMemoryCost &lt;= m_reportedExtraMemoryCost)
2289         return;
2290 
2291     size_t extraMemoryCostDelta = extraMemoryCost - m_reportedExtraMemoryCost;
2292     m_reportedExtraMemoryCost = extraMemoryCost;
2293 
2294     JSC::JSLockHolder lock(scriptExecutionContext()-&gt;vm());
2295     // FIXME: Adopt reportExtraMemoryVisited, and switch to reportExtraMemoryAllocated.
2296     // https://bugs.webkit.org/show_bug.cgi?id=142595
2297     scriptExecutionContext()-&gt;vm().heap.deprecatedReportExtraMemory(extraMemoryCostDelta);
2298 }
2299 
<span class="line-modified">2300 Vector&lt;String&gt; SourceBuffer::bufferedSamplesForTrackID(const AtomString&amp; trackID)</span>
2301 {
2302     auto it = m_trackBufferMap.find(trackID);
2303     if (it == m_trackBufferMap.end())
2304         return Vector&lt;String&gt;();
2305 
2306     TrackBuffer&amp; trackBuffer = it-&gt;value;
2307     Vector&lt;String&gt; sampleDescriptions;
2308     for (auto&amp; pair : trackBuffer.samples.decodeOrder())
2309         sampleDescriptions.append(toString(*pair.second));
2310 
2311     return sampleDescriptions;
2312 }
2313 
<span class="line-modified">2314 Vector&lt;String&gt; SourceBuffer::enqueuedSamplesForTrackID(const AtomString&amp; trackID)</span>
2315 {
2316     return m_private-&gt;enqueuedSamplesForTrackID(trackID);
2317 }
2318 
<span class="line-added">2319 MediaTime SourceBuffer::minimumUpcomingPresentationTimeForTrackID(const AtomString&amp; trackID)</span>
<span class="line-added">2320 {</span>
<span class="line-added">2321     return m_private-&gt;minimumUpcomingPresentationTimeForTrackID(trackID);</span>
<span class="line-added">2322 }</span>
<span class="line-added">2323 </span>
<span class="line-added">2324 void SourceBuffer::setMaximumQueueDepthForTrackID(const AtomString&amp; trackID, size_t maxQueueDepth)</span>
<span class="line-added">2325 {</span>
<span class="line-added">2326     m_private-&gt;setMaximumQueueDepthForTrackID(trackID, maxQueueDepth);</span>
<span class="line-added">2327 }</span>
<span class="line-added">2328 </span>
2329 Document&amp; SourceBuffer::document() const
2330 {
2331     ASSERT(scriptExecutionContext());
2332     return downcast&lt;Document&gt;(*scriptExecutionContext());
2333 }
2334 
2335 ExceptionOr&lt;void&gt; SourceBuffer::setMode(AppendMode newMode)
2336 {
2337     // 3.1 Attributes - mode
2338     // http://www.w3.org/TR/media-source/#widl-SourceBuffer-mode
2339 
2340     // On setting, run the following steps:
2341 
2342     // 1. Let new mode equal the new value being assigned to this attribute.
2343     // 2. If generate timestamps flag equals true and new mode equals &quot;segments&quot;, then throw an InvalidAccessError exception and abort these steps.
2344     if (m_shouldGenerateTimestamps &amp;&amp; newMode == AppendMode::Segments)
2345         return Exception { InvalidAccessError };
2346 
2347     // 3. If this object has been removed from the sourceBuffers attribute of the parent media source, then throw an InvalidStateError exception and abort these steps.
2348     // 4. If the updating attribute equals true, then throw an InvalidStateError exception and abort these steps.
</pre>
</td>
</tr>
</table>
<center><a href="MediaSourceRegistry.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../../index.html" target="_top">index</a> <a href="SourceBuffer.h.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>