<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/WebCore/Modules/webaudio/PannerNode.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (C) 2010, Google Inc. All rights reserved.
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1.  Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2.  Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39; AND ANY
 14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 15  * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 16  * DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS BE LIABLE FOR ANY
 17  * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 18  * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 19  * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 20  * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 21  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 22  * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 23  */
 24 
 25 #include &quot;config.h&quot;
 26 #include &quot;PannerNode.h&quot;
 27 
 28 #if ENABLE(WEB_AUDIO)
 29 
 30 #include &quot;AudioBufferSourceNode.h&quot;
 31 #include &quot;AudioBus.h&quot;
 32 #include &quot;AudioContext.h&quot;
 33 #include &quot;AudioNodeInput.h&quot;
 34 #include &quot;AudioNodeOutput.h&quot;
 35 #include &quot;HRTFPanner.h&quot;
 36 #include &quot;ScriptExecutionContext.h&quot;
<a name="1" id="anc1"></a>
 37 #include &lt;wtf/MathExtras.h&gt;
 38 
 39 namespace WebCore {
 40 
<a name="2" id="anc2"></a>

 41 static void fixNANs(double &amp;x)
 42 {
 43     if (std::isnan(x) || std::isinf(x))
 44         x = 0.0;
 45 }
 46 
 47 PannerNode::PannerNode(AudioContext&amp; context, float sampleRate)
 48     : AudioNode(context, sampleRate)
 49     , m_panningModel(PanningModelType::HRTF)
 50     , m_lastGain(-1.0)
 51     , m_connectionCount(0)
 52 {
<a name="3" id="anc3"></a>

 53     // Load the HRTF database asynchronously so we don&#39;t block the Javascript thread while creating the HRTF database.
 54     m_hrtfDatabaseLoader = HRTFDatabaseLoader::createAndLoadAsynchronouslyIfNecessary(context.sampleRate());
 55 
<a name="4" id="anc4"></a><span class="line-modified"> 56     addInput(std::make_unique&lt;AudioNodeInput&gt;(this));</span>
<span class="line-modified"> 57     addOutput(std::make_unique&lt;AudioNodeOutput&gt;(this, 2));</span>
 58 
 59     // Node-specific default mixing rules.
 60     m_channelCount = 2;
 61     m_channelCountMode = ClampedMax;
 62     m_channelInterpretation = AudioBus::Speakers;
 63 
 64     m_distanceGain = AudioParam::create(context, &quot;distanceGain&quot;, 1.0, 0.0, 1.0);
 65     m_coneGain = AudioParam::create(context, &quot;coneGain&quot;, 1.0, 0.0, 1.0);
 66 
 67     m_position = FloatPoint3D(0, 0, 0);
 68     m_orientation = FloatPoint3D(1, 0, 0);
 69     m_velocity = FloatPoint3D(0, 0, 0);
 70 
<a name="5" id="anc5"></a><span class="line-removed"> 71     setNodeType(NodeTypePanner);</span>
<span class="line-removed"> 72 </span>
 73     initialize();
 74 }
 75 
 76 PannerNode::~PannerNode()
 77 {
 78     uninitialize();
 79 }
 80 
 81 void PannerNode::pullInputs(size_t framesToProcess)
 82 {
 83     // We override pullInputs(), so we can detect new AudioSourceNodes which have connected to us when new connections are made.
 84     // These AudioSourceNodes need to be made aware of our existence in order to handle doppler shift pitch changes.
 85     if (m_connectionCount != context().connectionCount()) {
 86         m_connectionCount = context().connectionCount();
 87 
 88         // Recursively go through all nodes connected to us.
 89         HashSet&lt;AudioNode*&gt; visitedNodes;
 90         notifyAudioSourcesConnectedToNode(this, visitedNodes);
 91     }
 92 
 93     AudioNode::pullInputs(framesToProcess);
 94 }
 95 
 96 void PannerNode::process(size_t framesToProcess)
 97 {
 98     AudioBus* destination = output(0)-&gt;bus();
 99 
100     if (!isInitialized() || !input(0)-&gt;isConnected() || !m_panner.get()) {
101         destination-&gt;zero();
102         return;
103     }
104 
105     AudioBus* source = input(0)-&gt;bus();
106     if (!source) {
107         destination-&gt;zero();
108         return;
109     }
110 
111     // HRTFDatabase should be loaded before proceeding for offline audio context when panningModel() is &quot;HRTF&quot;.
112     if (panningModel() == PanningModelType::HRTF &amp;&amp; !m_hrtfDatabaseLoader-&gt;isLoaded()) {
113         if (context().isOfflineContext())
114             m_hrtfDatabaseLoader-&gt;waitForLoaderThreadCompletion();
115         else {
116             destination-&gt;zero();
117             return;
118         }
119     }
120 
121     // The audio thread can&#39;t block on this lock, so we use std::try_to_lock instead.
122     std::unique_lock&lt;Lock&gt; lock(m_pannerMutex, std::try_to_lock);
123     if (!lock.owns_lock()) {
124         // Too bad - The try_lock() failed. We must be in the middle of changing the panner.
125         destination-&gt;zero();
126         return;
127     }
128 
129     // Apply the panning effect.
130     double azimuth;
131     double elevation;
132     getAzimuthElevation(&amp;azimuth, &amp;elevation);
133     m_panner-&gt;pan(azimuth, elevation, source, destination, framesToProcess);
134 
135     // Get the distance and cone gain.
136     double totalGain = distanceConeGain();
137 
138     // Snap to desired gain at the beginning.
139     if (m_lastGain == -1.0)
140         m_lastGain = totalGain;
141 
142     // Apply gain in-place with de-zippering.
143     destination-&gt;copyWithGainFrom(*destination, &amp;m_lastGain, totalGain);
144 }
145 
146 void PannerNode::reset()
147 {
148     m_lastGain = -1.0; // force to snap to initial gain
149     if (m_panner.get())
150         m_panner-&gt;reset();
151 }
152 
153 void PannerNode::initialize()
154 {
155     if (isInitialized())
156         return;
157 
158     m_panner = Panner::create(m_panningModel, sampleRate(), m_hrtfDatabaseLoader.get());
159 
160     AudioNode::initialize();
161 }
162 
163 void PannerNode::uninitialize()
164 {
165     if (!isInitialized())
166         return;
167 
168     m_panner = nullptr;
169     AudioNode::uninitialize();
170 }
171 
172 AudioListener* PannerNode::listener()
173 {
174     return context().listener();
175 }
176 
177 void PannerNode::setPanningModel(PanningModelType model)
178 {
179     if (!m_panner.get() || model != m_panningModel) {
180         // This synchronizes with process().
181         std::lock_guard&lt;Lock&gt; lock(m_pannerMutex);
182 
183         m_panner = Panner::create(model, sampleRate(), m_hrtfDatabaseLoader.get());
184         m_panningModel = model;
185     }
186 }
187 
188 DistanceModelType PannerNode::distanceModel() const
189 {
190     return const_cast&lt;PannerNode*&gt;(this)-&gt;m_distanceEffect.model();
191 }
192 
193 void PannerNode::setDistanceModel(DistanceModelType model)
194 {
195     m_distanceEffect.setModel(model, true);
196 }
197 
198 void PannerNode::getAzimuthElevation(double* outAzimuth, double* outElevation)
199 {
200     // FIXME: we should cache azimuth and elevation (if possible), so we only re-calculate if a change has been made.
201 
202     double azimuth = 0.0;
203 
204     // Calculate the source-listener vector
205     FloatPoint3D listenerPosition = listener()-&gt;position();
206     FloatPoint3D sourceListener = m_position - listenerPosition;
207 
208     if (sourceListener.isZero()) {
209         // degenerate case if source and listener are at the same point
210         *outAzimuth = 0.0;
211         *outElevation = 0.0;
212         return;
213     }
214 
215     sourceListener.normalize();
216 
217     // Align axes
218     FloatPoint3D listenerFront = listener()-&gt;orientation();
219     FloatPoint3D listenerUp = listener()-&gt;upVector();
220     FloatPoint3D listenerRight = listenerFront.cross(listenerUp);
221     listenerRight.normalize();
222 
223     FloatPoint3D listenerFrontNorm = listenerFront;
224     listenerFrontNorm.normalize();
225 
226     FloatPoint3D up = listenerRight.cross(listenerFrontNorm);
227 
228     float upProjection = sourceListener.dot(up);
229 
230     FloatPoint3D projectedSource = sourceListener - upProjection * up;
231     projectedSource.normalize();
232 
233     azimuth = 180.0 * acos(projectedSource.dot(listenerRight)) / piDouble;
234     fixNANs(azimuth); // avoid illegal values
235 
236     // Source  in front or behind the listener
237     double frontBack = projectedSource.dot(listenerFrontNorm);
238     if (frontBack &lt; 0.0)
239         azimuth = 360.0 - azimuth;
240 
241     // Make azimuth relative to &quot;front&quot; and not &quot;right&quot; listener vector
242     if ((azimuth &gt;= 0.0) &amp;&amp; (azimuth &lt;= 270.0))
243         azimuth = 90.0 - azimuth;
244     else
245         azimuth = 450.0 - azimuth;
246 
247     // Elevation
248     double elevation = 90.0 - 180.0 * acos(sourceListener.dot(up)) / piDouble;
249     fixNANs(elevation); // avoid illegal values
250 
251     if (elevation &gt; 90.0)
252         elevation = 180.0 - elevation;
253     else if (elevation &lt; -90.0)
254         elevation = -180.0 - elevation;
255 
256     if (outAzimuth)
257         *outAzimuth = azimuth;
258     if (outElevation)
259         *outElevation = elevation;
260 }
261 
262 float PannerNode::dopplerRate()
263 {
264     double dopplerShift = 1.0;
265 
266     // FIXME: optimize for case when neither source nor listener has changed...
267     double dopplerFactor = listener()-&gt;dopplerFactor();
268 
269     if (dopplerFactor &gt; 0.0) {
270         double speedOfSound = listener()-&gt;speedOfSound();
271 
272         const FloatPoint3D &amp;sourceVelocity = m_velocity;
273         const FloatPoint3D &amp;listenerVelocity = listener()-&gt;velocity();
274 
275         // Don&#39;t bother if both source and listener have no velocity
276         bool sourceHasVelocity = !sourceVelocity.isZero();
277         bool listenerHasVelocity = !listenerVelocity.isZero();
278 
279         if (sourceHasVelocity || listenerHasVelocity) {
280             // Calculate the source to listener vector
281             FloatPoint3D listenerPosition = listener()-&gt;position();
282             FloatPoint3D sourceToListener = m_position - listenerPosition;
283 
284             double sourceListenerMagnitude = sourceToListener.length();
285 
286             double listenerProjection = sourceToListener.dot(listenerVelocity) / sourceListenerMagnitude;
287             double sourceProjection = sourceToListener.dot(sourceVelocity) / sourceListenerMagnitude;
288 
289             listenerProjection = -listenerProjection;
290             sourceProjection = -sourceProjection;
291 
292             double scaledSpeedOfSound = speedOfSound / dopplerFactor;
293             listenerProjection = std::min(listenerProjection, scaledSpeedOfSound);
294             sourceProjection = std::min(sourceProjection, scaledSpeedOfSound);
295 
296             dopplerShift = ((speedOfSound - dopplerFactor * listenerProjection) / (speedOfSound - dopplerFactor * sourceProjection));
297             fixNANs(dopplerShift); // avoid illegal values
298 
299             // Limit the pitch shifting to 4 octaves up and 3 octaves down.
300             if (dopplerShift &gt; 16.0)
301                 dopplerShift = 16.0;
302             else if (dopplerShift &lt; 0.125)
303                 dopplerShift = 0.125;
304         }
305     }
306 
307     return static_cast&lt;float&gt;(dopplerShift);
308 }
309 
310 float PannerNode::distanceConeGain()
311 {
312     FloatPoint3D listenerPosition = listener()-&gt;position();
313 
314     double listenerDistance = m_position.distanceTo(listenerPosition);
315     double distanceGain = m_distanceEffect.gain(listenerDistance);
316 
317     m_distanceGain-&gt;setValue(static_cast&lt;float&gt;(distanceGain));
318 
319     // FIXME: could optimize by caching coneGain
320     double coneGain = m_coneEffect.gain(m_position, m_orientation, listenerPosition);
321 
322     m_coneGain-&gt;setValue(static_cast&lt;float&gt;(coneGain));
323 
324     return float(distanceGain * coneGain);
325 }
326 
327 void PannerNode::notifyAudioSourcesConnectedToNode(AudioNode* node, HashSet&lt;AudioNode*&gt;&amp; visitedNodes)
328 {
329     ASSERT(node);
330     if (!node)
331         return;
332 
333     // First check if this node is an AudioBufferSourceNode. If so, let it know about us so that doppler shift pitch can be taken into account.
334     if (node-&gt;nodeType() == NodeTypeAudioBufferSource) {
335         AudioBufferSourceNode* bufferSourceNode = reinterpret_cast&lt;AudioBufferSourceNode*&gt;(node);
336         bufferSourceNode-&gt;setPannerNode(this);
337     } else {
338         // Go through all inputs to this node.
339         for (unsigned i = 0; i &lt; node-&gt;numberOfInputs(); ++i) {
340             AudioNodeInput* input = node-&gt;input(i);
341 
342             // For each input, go through all of its connections, looking for AudioBufferSourceNodes.
343             for (unsigned j = 0; j &lt; input-&gt;numberOfRenderingConnections(); ++j) {
344                 AudioNodeOutput* connectedOutput = input-&gt;renderingOutput(j);
345                 AudioNode* connectedNode = connectedOutput-&gt;node();
346                 if (visitedNodes.contains(connectedNode))
347                     continue;
348 
349                 visitedNodes.add(connectedNode);
350                 notifyAudioSourcesConnectedToNode(connectedNode, visitedNodes);
351             }
352         }
353     }
354 }
355 
356 } // namespace WebCore
357 
358 #endif // ENABLE(WEB_AUDIO)
<a name="6" id="anc6"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="6" type="hidden" />
</body>
</html>