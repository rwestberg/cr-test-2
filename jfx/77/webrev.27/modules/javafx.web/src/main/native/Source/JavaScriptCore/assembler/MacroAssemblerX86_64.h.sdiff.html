<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86_64.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="MacroAssemblerX86Common.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="ProbeStack.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86_64.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  37 
  38 class MacroAssemblerX86_64 : public MacroAssemblerX86Common {
  39 public:
  40     static const unsigned numGPRs = 16;
  41     static const unsigned numFPRs = 16;
  42 
  43     static const Scale ScalePtr = TimesEight;
  44 
  45     using MacroAssemblerX86Common::add32;
  46     using MacroAssemblerX86Common::and32;
  47     using MacroAssemblerX86Common::branch32;
  48     using MacroAssemblerX86Common::branchAdd32;
  49     using MacroAssemblerX86Common::or32;
  50     using MacroAssemblerX86Common::sub32;
  51     using MacroAssemblerX86Common::load8;
  52     using MacroAssemblerX86Common::load32;
  53     using MacroAssemblerX86Common::store32;
  54     using MacroAssemblerX86Common::store8;
  55     using MacroAssemblerX86Common::call;
  56     using MacroAssemblerX86Common::jump;

  57     using MacroAssemblerX86Common::addDouble;
  58     using MacroAssemblerX86Common::loadDouble;
  59     using MacroAssemblerX86Common::convertInt32ToDouble;
  60 
  61     void add32(TrustedImm32 imm, AbsoluteAddress address)
  62     {
  63         move(TrustedImmPtr(address.m_ptr), scratchRegister());
  64         add32(imm, Address(scratchRegister()));
  65     }
  66 
  67     void and32(TrustedImm32 imm, AbsoluteAddress address)
  68     {
  69         move(TrustedImmPtr(address.m_ptr), scratchRegister());
  70         and32(imm, Address(scratchRegister()));
  71     }
  72 
  73     void add32(AbsoluteAddress address, RegisterID dest)
  74     {
  75         move(TrustedImmPtr(address.m_ptr), scratchRegister());
  76         add32(Address(scratchRegister()), dest);
</pre>
<hr />
<pre>
 226         load64(Address(X86Registers::esp, 5 * sizeof(int64_t)), scratchRegister());
 227         store64(scratchRegister(), Address(X86Registers::esp, -3 * static_cast&lt;int32_t&gt;(sizeof(int64_t))));
 228 
 229         // We also need to allocate the shadow space on the stack for the 4 parameter registers.
 230         // Also, we should allocate 16 bytes for the frame pointer, and return address (not populated).
 231         // In addition, we need to allocate 16 bytes for two more parameters, since the call can have up to 6 parameters.
 232         sub64(TrustedImm32(8 * sizeof(int64_t)), X86Registers::esp);
 233 #endif
 234         DataLabelPtr label = moveWithPatch(TrustedImmPtr(nullptr), scratchRegister());
 235         Call result = Call(m_assembler.call(scratchRegister()), Call::Linkable);
 236 #if OS(WINDOWS)
 237         add64(TrustedImm32(8 * sizeof(int64_t)), X86Registers::esp);
 238 #endif
 239         ASSERT_UNUSED(label, differenceBetween(label, result) == REPATCH_OFFSET_CALL_R11);
 240         return result;
 241     }
 242 
 243     ALWAYS_INLINE Call call(RegisterID callTag) { return UNUSED_PARAM(callTag), call(NoPtrTag); }
 244 
 245     // Address is a memory location containing the address to jump to
<span class="line-modified"> 246     void jump(AbsoluteAddress address, PtrTag tag)</span>
 247     {
 248         move(TrustedImmPtr(address.m_ptr), scratchRegister());
<span class="line-modified"> 249         jump(Address(scratchRegister()), tag);</span>
 250     }
 251 
<span class="line-modified"> 252     ALWAYS_INLINE void jump(AbsoluteAddress address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(address, NoPtrTag); }</span>
<span class="line-removed"> 253 </span>
<span class="line-removed"> 254     Call tailRecursiveCall()</span>
<span class="line-removed"> 255     {</span>
<span class="line-removed"> 256         DataLabelPtr label = moveWithPatch(TrustedImmPtr(nullptr), scratchRegister());</span>
<span class="line-removed"> 257         Jump newJump = Jump(m_assembler.jmp_r(scratchRegister()));</span>
<span class="line-removed"> 258         ASSERT_UNUSED(label, differenceBetween(label, newJump) == REPATCH_OFFSET_CALL_R11);</span>
<span class="line-removed"> 259         return Call::fromTailJump(newJump);</span>
<span class="line-removed"> 260     }</span>
<span class="line-removed"> 261 </span>
<span class="line-removed"> 262     Call makeTailRecursiveCall(Jump oldJump)</span>
<span class="line-removed"> 263     {</span>
<span class="line-removed"> 264         oldJump.link(this);</span>
<span class="line-removed"> 265         DataLabelPtr label = moveWithPatch(TrustedImmPtr(nullptr), scratchRegister());</span>
<span class="line-removed"> 266         Jump newJump = Jump(m_assembler.jmp_r(scratchRegister()));</span>
<span class="line-removed"> 267         ASSERT_UNUSED(label, differenceBetween(label, newJump) == REPATCH_OFFSET_CALL_R11);</span>
<span class="line-removed"> 268         return Call::fromTailJump(newJump);</span>
<span class="line-removed"> 269     }</span>
 270 
 271     Call threadSafePatchableNearCall()
 272     {
 273         const size_t nearCallOpcodeSize = 1;
 274         const size_t nearCallRelativeLocationSize = sizeof(int32_t);
 275         // We want to make sure the 32-bit near call immediate is 32-bit aligned.
 276         size_t codeSize = m_assembler.codeSize();
 277         size_t alignedSize = WTF::roundUpToMultipleOf&lt;nearCallRelativeLocationSize&gt;(codeSize + nearCallOpcodeSize);
 278         emitNops(alignedSize - (codeSize + nearCallOpcodeSize));
 279         DataLabelPtr label = DataLabelPtr(this);
 280         Call result = nearCall();
 281         ASSERT_UNUSED(label, differenceBetween(label, result) == (nearCallOpcodeSize + nearCallRelativeLocationSize));
 282         return result;
 283     }
 284 
 285     Jump branchAdd32(ResultCondition cond, TrustedImm32 src, AbsoluteAddress dest)
 286     {
 287         move(TrustedImmPtr(dest.m_ptr), scratchRegister());
 288         add32(src, Address(scratchRegister()));
 289         return Jump(m_assembler.jCC(x86Condition(cond)));
</pre>
<hr />
<pre>
1086     }
1087 
1088     Jump branchTest64(ResultCondition cond, RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
1089     {
1090         // if we are only interested in the low seven bits, this can be tested with a testb
1091         if (mask.m_value == -1)
1092             m_assembler.testq_rr(reg, reg);
1093         else if ((mask.m_value &amp; ~0x7f) == 0)
1094             m_assembler.testb_i8r(mask.m_value, reg);
1095         else
1096             m_assembler.testq_i32r(mask.m_value, reg);
1097         return Jump(m_assembler.jCC(x86Condition(cond)));
1098     }
1099 
1100     Jump branchTest64(ResultCondition cond, RegisterID reg, TrustedImm64 mask)
1101     {
1102         move(mask, scratchRegister());
1103         return branchTest64(cond, reg, scratchRegister());
1104     }
1105 






























1106     void test64(ResultCondition cond, RegisterID reg, TrustedImm32 mask, RegisterID dest)
1107     {
1108         if (mask.m_value == -1)
1109             m_assembler.testq_rr(reg, reg);
1110         else if ((mask.m_value &amp; ~0x7f) == 0)
1111             m_assembler.testb_i8r(mask.m_value, reg);
1112         else
1113             m_assembler.testq_i32r(mask.m_value, reg);
1114         set32(x86Condition(cond), dest);
1115     }
1116 
1117     void test64(ResultCondition cond, RegisterID reg, RegisterID mask, RegisterID dest)
1118     {
1119         m_assembler.testq_rr(reg, mask);
1120         set32(x86Condition(cond), dest);
1121     }
1122 
1123     Jump branchTest64(ResultCondition cond, AbsoluteAddress address, TrustedImm32 mask = TrustedImm32(-1))
1124     {
1125         load64(address.m_ptr, scratchRegister());
</pre>
</td>
<td>
<hr />
<pre>
  37 
  38 class MacroAssemblerX86_64 : public MacroAssemblerX86Common {
  39 public:
  40     static const unsigned numGPRs = 16;
  41     static const unsigned numFPRs = 16;
  42 
  43     static const Scale ScalePtr = TimesEight;
  44 
  45     using MacroAssemblerX86Common::add32;
  46     using MacroAssemblerX86Common::and32;
  47     using MacroAssemblerX86Common::branch32;
  48     using MacroAssemblerX86Common::branchAdd32;
  49     using MacroAssemblerX86Common::or32;
  50     using MacroAssemblerX86Common::sub32;
  51     using MacroAssemblerX86Common::load8;
  52     using MacroAssemblerX86Common::load32;
  53     using MacroAssemblerX86Common::store32;
  54     using MacroAssemblerX86Common::store8;
  55     using MacroAssemblerX86Common::call;
  56     using MacroAssemblerX86Common::jump;
<span class="line-added">  57     using MacroAssemblerX86Common::farJump;</span>
  58     using MacroAssemblerX86Common::addDouble;
  59     using MacroAssemblerX86Common::loadDouble;
  60     using MacroAssemblerX86Common::convertInt32ToDouble;
  61 
  62     void add32(TrustedImm32 imm, AbsoluteAddress address)
  63     {
  64         move(TrustedImmPtr(address.m_ptr), scratchRegister());
  65         add32(imm, Address(scratchRegister()));
  66     }
  67 
  68     void and32(TrustedImm32 imm, AbsoluteAddress address)
  69     {
  70         move(TrustedImmPtr(address.m_ptr), scratchRegister());
  71         and32(imm, Address(scratchRegister()));
  72     }
  73 
  74     void add32(AbsoluteAddress address, RegisterID dest)
  75     {
  76         move(TrustedImmPtr(address.m_ptr), scratchRegister());
  77         add32(Address(scratchRegister()), dest);
</pre>
<hr />
<pre>
 227         load64(Address(X86Registers::esp, 5 * sizeof(int64_t)), scratchRegister());
 228         store64(scratchRegister(), Address(X86Registers::esp, -3 * static_cast&lt;int32_t&gt;(sizeof(int64_t))));
 229 
 230         // We also need to allocate the shadow space on the stack for the 4 parameter registers.
 231         // Also, we should allocate 16 bytes for the frame pointer, and return address (not populated).
 232         // In addition, we need to allocate 16 bytes for two more parameters, since the call can have up to 6 parameters.
 233         sub64(TrustedImm32(8 * sizeof(int64_t)), X86Registers::esp);
 234 #endif
 235         DataLabelPtr label = moveWithPatch(TrustedImmPtr(nullptr), scratchRegister());
 236         Call result = Call(m_assembler.call(scratchRegister()), Call::Linkable);
 237 #if OS(WINDOWS)
 238         add64(TrustedImm32(8 * sizeof(int64_t)), X86Registers::esp);
 239 #endif
 240         ASSERT_UNUSED(label, differenceBetween(label, result) == REPATCH_OFFSET_CALL_R11);
 241         return result;
 242     }
 243 
 244     ALWAYS_INLINE Call call(RegisterID callTag) { return UNUSED_PARAM(callTag), call(NoPtrTag); }
 245 
 246     // Address is a memory location containing the address to jump to
<span class="line-modified"> 247     void farJump(AbsoluteAddress address, PtrTag tag)</span>
 248     {
 249         move(TrustedImmPtr(address.m_ptr), scratchRegister());
<span class="line-modified"> 250         farJump(Address(scratchRegister()), tag);</span>
 251     }
 252 
<span class="line-modified"> 253     ALWAYS_INLINE void farJump(AbsoluteAddress address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), farJump(address, NoPtrTag); }</span>

















 254 
 255     Call threadSafePatchableNearCall()
 256     {
 257         const size_t nearCallOpcodeSize = 1;
 258         const size_t nearCallRelativeLocationSize = sizeof(int32_t);
 259         // We want to make sure the 32-bit near call immediate is 32-bit aligned.
 260         size_t codeSize = m_assembler.codeSize();
 261         size_t alignedSize = WTF::roundUpToMultipleOf&lt;nearCallRelativeLocationSize&gt;(codeSize + nearCallOpcodeSize);
 262         emitNops(alignedSize - (codeSize + nearCallOpcodeSize));
 263         DataLabelPtr label = DataLabelPtr(this);
 264         Call result = nearCall();
 265         ASSERT_UNUSED(label, differenceBetween(label, result) == (nearCallOpcodeSize + nearCallRelativeLocationSize));
 266         return result;
 267     }
 268 
 269     Jump branchAdd32(ResultCondition cond, TrustedImm32 src, AbsoluteAddress dest)
 270     {
 271         move(TrustedImmPtr(dest.m_ptr), scratchRegister());
 272         add32(src, Address(scratchRegister()));
 273         return Jump(m_assembler.jCC(x86Condition(cond)));
</pre>
<hr />
<pre>
1070     }
1071 
1072     Jump branchTest64(ResultCondition cond, RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
1073     {
1074         // if we are only interested in the low seven bits, this can be tested with a testb
1075         if (mask.m_value == -1)
1076             m_assembler.testq_rr(reg, reg);
1077         else if ((mask.m_value &amp; ~0x7f) == 0)
1078             m_assembler.testb_i8r(mask.m_value, reg);
1079         else
1080             m_assembler.testq_i32r(mask.m_value, reg);
1081         return Jump(m_assembler.jCC(x86Condition(cond)));
1082     }
1083 
1084     Jump branchTest64(ResultCondition cond, RegisterID reg, TrustedImm64 mask)
1085     {
1086         move(mask, scratchRegister());
1087         return branchTest64(cond, reg, scratchRegister());
1088     }
1089 
<span class="line-added">1090     Jump branchTestBit64(ResultCondition cond, RegisterID testValue, TrustedImm32 bit)</span>
<span class="line-added">1091     {</span>
<span class="line-added">1092         m_assembler.btw_ir(static_cast&lt;unsigned&gt;(bit.m_value) % 64, testValue);</span>
<span class="line-added">1093         if (cond == NonZero)</span>
<span class="line-added">1094             return Jump(m_assembler.jb());</span>
<span class="line-added">1095         if (cond == Zero)</span>
<span class="line-added">1096             return Jump(m_assembler.jae());</span>
<span class="line-added">1097         RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">1098     }</span>
<span class="line-added">1099 </span>
<span class="line-added">1100     Jump branchTestBit64(ResultCondition cond, Address testValue, TrustedImm32 bit)</span>
<span class="line-added">1101     {</span>
<span class="line-added">1102         m_assembler.btw_im(static_cast&lt;unsigned&gt;(bit.m_value) % 64, testValue.offset, testValue.base);</span>
<span class="line-added">1103         if (cond == NonZero)</span>
<span class="line-added">1104             return Jump(m_assembler.jb());</span>
<span class="line-added">1105         if (cond == Zero)</span>
<span class="line-added">1106             return Jump(m_assembler.jae());</span>
<span class="line-added">1107         RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">1108     }</span>
<span class="line-added">1109 </span>
<span class="line-added">1110     Jump branchTestBit64(ResultCondition cond, RegisterID reg, RegisterID bit)</span>
<span class="line-added">1111     {</span>
<span class="line-added">1112         m_assembler.btw_ir(bit, reg);</span>
<span class="line-added">1113         if (cond == NonZero)</span>
<span class="line-added">1114             return Jump(m_assembler.jb());</span>
<span class="line-added">1115         if (cond == Zero)</span>
<span class="line-added">1116             return Jump(m_assembler.jae());</span>
<span class="line-added">1117         RELEASE_ASSERT_NOT_REACHED();</span>
<span class="line-added">1118     }</span>
<span class="line-added">1119 </span>
1120     void test64(ResultCondition cond, RegisterID reg, TrustedImm32 mask, RegisterID dest)
1121     {
1122         if (mask.m_value == -1)
1123             m_assembler.testq_rr(reg, reg);
1124         else if ((mask.m_value &amp; ~0x7f) == 0)
1125             m_assembler.testb_i8r(mask.m_value, reg);
1126         else
1127             m_assembler.testq_i32r(mask.m_value, reg);
1128         set32(x86Condition(cond), dest);
1129     }
1130 
1131     void test64(ResultCondition cond, RegisterID reg, RegisterID mask, RegisterID dest)
1132     {
1133         m_assembler.testq_rr(reg, mask);
1134         set32(x86Condition(cond), dest);
1135     }
1136 
1137     Jump branchTest64(ResultCondition cond, AbsoluteAddress address, TrustedImm32 mask = TrustedImm32(-1))
1138     {
1139         load64(address.m_ptr, scratchRegister());
</pre>
</td>
</tr>
</table>
<center><a href="MacroAssemblerX86Common.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="ProbeStack.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>