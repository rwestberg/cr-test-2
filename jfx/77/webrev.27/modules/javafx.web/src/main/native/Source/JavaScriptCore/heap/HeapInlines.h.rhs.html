<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/HeapInlines.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
<a name="1" id="anc1"></a><span class="line-modified">  2  * Copyright (C) 2014-2019 Apple Inc. All rights reserved.</span>
  3  *
  4  * Redistribution and use in source and binary forms, with or without
  5  * modification, are permitted provided that the following conditions
  6  * are met:
  7  * 1. Redistributions of source code must retain the above copyright
  8  *    notice, this list of conditions and the following disclaimer.
  9  * 2. Redistributions in binary form must reproduce the above copyright
 10  *    notice, this list of conditions and the following disclaimer in the
 11  *    documentation and/or other materials provided with the distribution.
 12  *
 13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
 14  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 15  * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 16  * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
 17  * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 18  * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 19  * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 20  * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 21  * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 22  * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
 23  * THE POSSIBILITY OF SUCH DAMAGE.
 24  */
 25 
 26 #pragma once
 27 
 28 #include &quot;GCDeferralContext.h&quot;
 29 #include &quot;Heap.h&quot;
 30 #include &quot;HeapCellInlines.h&quot;
 31 #include &quot;IndexingHeader.h&quot;
<a name="2" id="anc2"></a>
 32 #include &quot;JSCast.h&quot;
 33 #include &quot;Structure.h&quot;
 34 #include &lt;type_traits&gt;
 35 #include &lt;wtf/Assertions.h&gt;
 36 #include &lt;wtf/MainThread.h&gt;
 37 #include &lt;wtf/RandomNumber.h&gt;
 38 
 39 namespace JSC {
 40 
<a name="3" id="anc3"></a><span class="line-modified"> 41 ALWAYS_INLINE VM&amp; Heap::vm() const</span>
 42 {
<a name="4" id="anc4"></a><span class="line-modified"> 43     return *bitwise_cast&lt;VM*&gt;(bitwise_cast&lt;uintptr_t&gt;(this) - OBJECT_OFFSETOF(VM, heap));</span>
 44 }
 45 
 46 ALWAYS_INLINE Heap* Heap::heap(const HeapCell* cell)
 47 {
 48     if (!cell)
 49         return nullptr;
 50     return cell-&gt;heap();
 51 }
 52 
 53 inline Heap* Heap::heap(const JSValue v)
 54 {
 55     if (!v.isCell())
 56         return nullptr;
 57     return heap(v.asCell());
 58 }
 59 
 60 inline bool Heap::hasHeapAccess() const
 61 {
 62     return m_worldState.load() &amp; hasAccessBit;
 63 }
 64 
 65 inline bool Heap::worldIsStopped() const
 66 {
 67     return m_worldIsStopped;
 68 }
 69 
<a name="5" id="anc5"></a>

 70 ALWAYS_INLINE bool Heap::isMarked(const void* rawCell)
 71 {
 72     HeapCell* cell = bitwise_cast&lt;HeapCell*&gt;(rawCell);
 73     if (cell-&gt;isLargeAllocation())
 74         return cell-&gt;largeAllocation().isMarked();
 75     MarkedBlock&amp; block = cell-&gt;markedBlock();
<a name="6" id="anc6"></a><span class="line-modified"> 76     return block.isMarked(m_objectSpace.markingVersion(), cell);</span>
 77 }
 78 
 79 ALWAYS_INLINE bool Heap::testAndSetMarked(HeapVersion markingVersion, const void* rawCell)
 80 {
 81     HeapCell* cell = bitwise_cast&lt;HeapCell*&gt;(rawCell);
 82     if (cell-&gt;isLargeAllocation())
 83         return cell-&gt;largeAllocation().testAndSetMarked();
 84     MarkedBlock&amp; block = cell-&gt;markedBlock();
 85     Dependency dependency = block.aboutToMark(markingVersion);
 86     return block.testAndSetMarked(cell, dependency);
 87 }
 88 
 89 ALWAYS_INLINE size_t Heap::cellSize(const void* rawCell)
 90 {
 91     return bitwise_cast&lt;HeapCell*&gt;(rawCell)-&gt;cellSize();
 92 }
 93 
 94 inline void Heap::writeBarrier(const JSCell* from, JSValue to)
 95 {
 96 #if ENABLE(WRITE_BARRIER_PROFILING)
 97     WriteBarrierCounters::countWriteBarrier();
 98 #endif
 99     if (!to.isCell())
100         return;
101     writeBarrier(from, to.asCell());
102 }
103 
104 inline void Heap::writeBarrier(const JSCell* from, JSCell* to)
105 {
106 #if ENABLE(WRITE_BARRIER_PROFILING)
107     WriteBarrierCounters::countWriteBarrier();
108 #endif
109     if (!from)
110         return;
111     if (!isWithinThreshold(from-&gt;cellState(), barrierThreshold()))
112         return;
113     if (LIKELY(!to))
114         return;
115     writeBarrierSlowPath(from);
116 }
117 
118 inline void Heap::writeBarrier(const JSCell* from)
119 {
120     ASSERT_GC_OBJECT_LOOKS_VALID(const_cast&lt;JSCell*&gt;(from));
121     if (!from)
122         return;
123     if (UNLIKELY(isWithinThreshold(from-&gt;cellState(), barrierThreshold())))
124         writeBarrierSlowPath(from);
125 }
126 
127 inline void Heap::writeBarrierWithoutFence(const JSCell* from)
128 {
129     ASSERT_GC_OBJECT_LOOKS_VALID(const_cast&lt;JSCell*&gt;(from));
130     if (!from)
131         return;
132     if (UNLIKELY(isWithinThreshold(from-&gt;cellState(), blackThreshold)))
133         addToRememberedSet(from);
134 }
135 
136 inline void Heap::mutatorFence()
137 {
138     if (isX86() || UNLIKELY(mutatorShouldBeFenced()))
139         WTF::storeStoreFence();
140 }
141 
142 template&lt;typename Functor&gt; inline void Heap::forEachCodeBlock(const Functor&amp; func)
143 {
144     forEachCodeBlockImpl(scopedLambdaRef&lt;void(CodeBlock*)&gt;(func));
145 }
146 
147 template&lt;typename Functor&gt; inline void Heap::forEachCodeBlockIgnoringJITPlans(const AbstractLocker&amp; codeBlockSetLocker, const Functor&amp; func)
148 {
149     forEachCodeBlockIgnoringJITPlansImpl(codeBlockSetLocker, scopedLambdaRef&lt;void(CodeBlock*)&gt;(func));
150 }
151 
152 template&lt;typename Functor&gt; inline void Heap::forEachProtectedCell(const Functor&amp; functor)
153 {
154     for (auto&amp; pair : m_protectedValues)
155         functor(pair.key);
156     m_handleSet.forEachStrongHandle(functor, m_protectedValues);
157 }
158 
159 #if USE(FOUNDATION)
160 template &lt;typename T&gt;
161 inline void Heap::releaseSoon(RetainPtr&lt;T&gt;&amp;&amp; object)
162 {
163     m_delayedReleaseObjects.append(WTFMove(object));
164 }
165 #endif
166 
<a name="7" id="anc7"></a><span class="line-modified">167 #ifdef JSC_GLIB_API_ENABLED</span>
168 inline void Heap::releaseSoon(std::unique_ptr&lt;JSCGLibWrapperObject&gt;&amp;&amp; object)
169 {
170     m_delayedReleaseObjects.append(WTFMove(object));
171 }
172 #endif
173 
174 inline void Heap::incrementDeferralDepth()
175 {
<a name="8" id="anc8"></a><span class="line-modified">176     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);</span>
177     m_deferralDepth++;
178 }
179 
180 inline void Heap::decrementDeferralDepth()
181 {
<a name="9" id="anc9"></a><span class="line-modified">182     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);</span>
183     m_deferralDepth--;
184 }
185 
186 inline void Heap::decrementDeferralDepthAndGCIfNeeded()
187 {
<a name="10" id="anc10"></a><span class="line-modified">188     ASSERT(!Thread::mayBeGCThread() || m_worldIsStopped);</span>
189     m_deferralDepth--;
190 
191     if (UNLIKELY(m_didDeferGCWork)) {
192         decrementDeferralDepthAndGCIfNeededSlow();
193 
194         // Here are the possible relationships between m_deferralDepth and m_didDeferGCWork.
195         // Note that prior to the call to decrementDeferralDepthAndGCIfNeededSlow,
196         // m_didDeferGCWork had to have been true. Now it can be either false or true. There is
197         // nothing we can reliably assert.
198         //
199         // Possible arrangements of m_didDeferGCWork and !!m_deferralDepth:
200         //
201         // Both false: We popped out of all DeferGCs and we did whatever work was deferred.
202         //
203         // Only m_didDeferGCWork is true: We stopped for GC and the GC did DeferGC. This is
204         // possible because of how we handle the baseline JIT&#39;s worklist. It&#39;s also perfectly
205         // safe because it only protects reportExtraMemory. We can just ignore this.
206         //
207         // Only !!m_deferralDepth is true: m_didDeferGCWork had been set spuriously. It is only
208         // cleared by decrementDeferralDepthAndGCIfNeededSlow(). So, if we had deferred work but
209         // then decrementDeferralDepth()&#39;d, then we might have the bit set even if we GC&#39;d since
210         // then.
211         //
212         // Both true: We&#39;re in a recursive ~DeferGC. We wanted to do something about the
213         // deferred work, but were unable to.
214     }
215 }
216 
217 inline HashSet&lt;MarkedArgumentBuffer*&gt;&amp; Heap::markListSet()
218 {
219     if (!m_markListSet)
<a name="11" id="anc11"></a><span class="line-modified">220         m_markListSet = makeUnique&lt;HashSet&lt;MarkedArgumentBuffer*&gt;&gt;();</span>
221     return *m_markListSet;
222 }
223 
224 inline void Heap::reportExtraMemoryAllocated(size_t size)
225 {
226     if (size &gt; minExtraMemory)
227         reportExtraMemoryAllocatedSlowCase(size);
228 }
229 
230 inline void Heap::deprecatedReportExtraMemory(size_t size)
231 {
232     if (size &gt; minExtraMemory)
233         deprecatedReportExtraMemorySlowCase(size);
234 }
235 
236 inline void Heap::acquireAccess()
237 {
238     if (validateDFGDoesGC)
239         RELEASE_ASSERT(expectDoesGC());
240 
241     if (m_worldState.compareExchangeWeak(0, hasAccessBit))
242         return;
243     acquireAccessSlow();
244 }
245 
246 inline bool Heap::hasAccess() const
247 {
248     return m_worldState.loadRelaxed() &amp; hasAccessBit;
249 }
250 
251 inline void Heap::releaseAccess()
252 {
253     if (m_worldState.compareExchangeWeak(hasAccessBit, 0))
254         return;
255     releaseAccessSlow();
256 }
257 
258 inline bool Heap::mayNeedToStop()
259 {
260     return m_worldState.loadRelaxed() != hasAccessBit;
261 }
262 
263 inline void Heap::stopIfNecessary()
264 {
265     if (validateDFGDoesGC)
266         RELEASE_ASSERT(expectDoesGC());
267 
268     if (mayNeedToStop())
269         stopIfNecessarySlow();
270 }
271 
272 template&lt;typename Func&gt;
273 void Heap::forEachSlotVisitor(const Func&amp; func)
274 {
<a name="12" id="anc12"></a>
275     func(*m_collectorSlotVisitor);
276     func(*m_mutatorSlotVisitor);
277     for (auto&amp; slotVisitor : m_parallelSlotVisitors)
278         func(*slotVisitor);
279 }
280 
<a name="13" id="anc13"></a>





281 } // namespace JSC
<a name="14" id="anc14"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="14" type="hidden" />
</body>
</html>