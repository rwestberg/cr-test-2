<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Cdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JIT.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="IntrinsicEmitter.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JIT.h.cdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/jit/JIT.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<hr />
<pre>
<span class="line-old-header">*** 1,7 ***</span>
  /*
<span class="line-modified">!  * Copyright (C) 2008-2018 Apple Inc. All rights reserved.</span>
   *
   * Redistribution and use in source and binary forms, with or without
   * modification, are permitted provided that the following conditions
   * are met:
   * 1. Redistributions of source code must retain the above copyright
<span class="line-new-header">--- 1,7 ---</span>
  /*
<span class="line-modified">!  * Copyright (C) 2008-2019 Apple Inc. All rights reserved.</span>
   *
   * Redistribution and use in source and binary forms, with or without
   * modification, are permitted provided that the following conditions
   * are met:
   * 1. Redistributions of source code must retain the above copyright
</pre>
<hr />
<pre>
<span class="line-old-header">*** 72,16 ***</span>
      MacroAssembler::repatchCall(
          CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)),
          newCalleeFunction.retagged&lt;OperationPtrTag&gt;());
  }
  
<span class="line-modified">! JIT::JIT(VM* vm, CodeBlock* codeBlock, unsigned loopOSREntryBytecodeOffset)</span>
<span class="line-modified">!     : JSInterfaceJIT(vm, codeBlock)</span>
<span class="line-modified">!     , m_interpreter(vm-&gt;interpreter)</span>
      , m_labels(codeBlock ? codeBlock-&gt;instructions().size() : 0)
      , m_bytecodeOffset(std::numeric_limits&lt;unsigned&gt;::max())
<span class="line-modified">!     , m_pcToCodeOriginMapBuilder(*vm)</span>
      , m_canBeOptimized(false)
      , m_shouldEmitProfiling(false)
      , m_shouldUseIndexMasking(Options::enableSpectreMitigations())
      , m_loopOSREntryBytecodeOffset(loopOSREntryBytecodeOffset)
  {
<span class="line-new-header">--- 72,16 ---</span>
      MacroAssembler::repatchCall(
          CodeLocationCall&lt;NoPtrTag&gt;(MacroAssemblerCodePtr&lt;NoPtrTag&gt;(returnAddress)),
          newCalleeFunction.retagged&lt;OperationPtrTag&gt;());
  }
  
<span class="line-modified">! JIT::JIT(VM&amp; vm, CodeBlock* codeBlock, unsigned loopOSREntryBytecodeOffset)</span>
<span class="line-modified">!     : JSInterfaceJIT(&amp;vm, codeBlock)</span>
<span class="line-modified">!     , m_interpreter(vm.interpreter)</span>
      , m_labels(codeBlock ? codeBlock-&gt;instructions().size() : 0)
      , m_bytecodeOffset(std::numeric_limits&lt;unsigned&gt;::max())
<span class="line-modified">!     , m_pcToCodeOriginMapBuilder(vm)</span>
      , m_canBeOptimized(false)
      , m_shouldEmitProfiling(false)
      , m_shouldUseIndexMasking(Options::enableSpectreMitigations())
      , m_loopOSREntryBytecodeOffset(loopOSREntryBytecodeOffset)
  {
</pre>
<hr />
<pre>
<span class="line-old-header">*** 89,30 ***</span>
  
  JIT::~JIT()
  {
  }
  
<span class="line-removed">- #if ENABLE(DFG_JIT)</span>
<span class="line-removed">- void JIT::emitEnterOptimizationCheck()</span>
<span class="line-removed">- {</span>
<span class="line-removed">-     if (!canBeOptimized())</span>
<span class="line-removed">-         return;</span>
<span class="line-removed">- </span>
<span class="line-removed">-     JumpList skipOptimize;</span>
<span class="line-removed">- </span>
<span class="line-removed">-     skipOptimize.append(branchAdd32(Signed, TrustedImm32(Options::executionCounterIncrementForEntry()), AbsoluteAddress(m_codeBlock-&gt;addressOfJITExecuteCounter())));</span>
<span class="line-removed">-     ASSERT(!m_bytecodeOffset);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     copyCalleeSavesFromFrameOrRegisterToEntryFrameCalleeSavesBuffer(vm()-&gt;topEntryFrame);</span>
<span class="line-removed">- </span>
<span class="line-removed">-     callOperation(operationOptimize, m_bytecodeOffset);</span>
<span class="line-removed">-     skipOptimize.append(branchTestPtr(Zero, returnValueGPR));</span>
<span class="line-removed">-     jump(returnValueGPR, GPRInfo::callFrameRegister);</span>
<span class="line-removed">-     skipOptimize.link(this);</span>
<span class="line-removed">- }</span>
<span class="line-removed">- #endif</span>
<span class="line-removed">- </span>
  void JIT::emitNotifyWrite(WatchpointSet* set)
  {
      if (!set || set-&gt;state() == IsInvalidated) {
          addSlowCase(Jump());
          return;
<span class="line-new-header">--- 89,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 189,11 ***</span>
      auto&amp; instructions = m_codeBlock-&gt;instructions();
      unsigned instructionCount = m_codeBlock-&gt;instructions().size();
  
      m_callLinkInfoIndex = 0;
  
<span class="line-modified">!     VM&amp; vm = *m_codeBlock-&gt;vm();</span>
      unsigned startBytecodeOffset = 0;
      if (m_loopOSREntryBytecodeOffset &amp;&amp; (m_codeBlock-&gt;inherits&lt;ProgramCodeBlock&gt;(vm) || m_codeBlock-&gt;inherits&lt;ModuleProgramCodeBlock&gt;(vm))) {
          // We can only do this optimization because we execute ProgramCodeBlock&#39;s exactly once.
          // This optimization would be invalid otherwise. When the LLInt determines it wants to
          // do OSR entry into the baseline JIT in a loop, it will pass in the bytecode offset it
<span class="line-new-header">--- 169,11 ---</span>
      auto&amp; instructions = m_codeBlock-&gt;instructions();
      unsigned instructionCount = m_codeBlock-&gt;instructions().size();
  
      m_callLinkInfoIndex = 0;
  
<span class="line-modified">!     VM&amp; vm = m_codeBlock-&gt;vm();</span>
      unsigned startBytecodeOffset = 0;
      if (m_loopOSREntryBytecodeOffset &amp;&amp; (m_codeBlock-&gt;inherits&lt;ProgramCodeBlock&gt;(vm) || m_codeBlock-&gt;inherits&lt;ModuleProgramCodeBlock&gt;(vm))) {
          // We can only do this optimization because we execute ProgramCodeBlock&#39;s exactly once.
          // This optimization would be invalid otherwise. When the LLInt determines it wants to
          // do OSR entry into the baseline JIT in a loop, it will pass in the bytecode offset it
</pre>
<hr />
<pre>
<span class="line-old-header">*** 362,10 ***</span>
<span class="line-new-header">--- 342,12 ---</span>
          DEFINE_OP(op_is_cell_with_type)
          DEFINE_OP(op_jeq_null)
          DEFINE_OP(op_jfalse)
          DEFINE_OP(op_jmp)
          DEFINE_OP(op_jneq_null)
<span class="line-added">+         DEFINE_OP(op_jundefined_or_null)</span>
<span class="line-added">+         DEFINE_OP(op_jnundefined_or_null)</span>
          DEFINE_OP(op_jneq_ptr)
          DEFINE_OP(op_jless)
          DEFINE_OP(op_jlesseq)
          DEFINE_OP(op_jgreater)
          DEFINE_OP(op_jgreatereq)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 379,11 ***</span>
          DEFINE_OP(op_jnstricteq)
          DEFINE_OP(op_jbelow)
          DEFINE_OP(op_jbeloweq)
          DEFINE_OP(op_jtrue)
          DEFINE_OP(op_loop_hint)
<span class="line-removed">-         DEFINE_OP(op_check_traps)</span>
          DEFINE_OP(op_nop)
          DEFINE_OP(op_super_sampler_begin)
          DEFINE_OP(op_super_sampler_end)
          DEFINE_OP(op_lshift)
          DEFINE_OP(op_mod)
<span class="line-new-header">--- 361,10 ---</span>
</pre>
<hr />
<pre>
<span class="line-old-header">*** 544,11 ***</span>
          DEFINE_SLOWCASE_OP(op_jeq)
          DEFINE_SLOWCASE_OP(op_jneq)
          DEFINE_SLOWCASE_OP(op_jstricteq)
          DEFINE_SLOWCASE_OP(op_jnstricteq)
          DEFINE_SLOWCASE_OP(op_loop_hint)
<span class="line-modified">!         DEFINE_SLOWCASE_OP(op_check_traps)</span>
          DEFINE_SLOWCASE_OP(op_mod)
          DEFINE_SLOWCASE_OP(op_mul)
          DEFINE_SLOWCASE_OP(op_negate)
          DEFINE_SLOWCASE_OP(op_neq)
          DEFINE_SLOWCASE_OP(op_new_object)
<span class="line-new-header">--- 525,11 ---</span>
          DEFINE_SLOWCASE_OP(op_jeq)
          DEFINE_SLOWCASE_OP(op_jneq)
          DEFINE_SLOWCASE_OP(op_jstricteq)
          DEFINE_SLOWCASE_OP(op_jnstricteq)
          DEFINE_SLOWCASE_OP(op_loop_hint)
<span class="line-modified">!         DEFINE_SLOWCASE_OP(op_enter)</span>
          DEFINE_SLOWCASE_OP(op_mod)
          DEFINE_SLOWCASE_OP(op_mul)
          DEFINE_SLOWCASE_OP(op_negate)
          DEFINE_SLOWCASE_OP(op_neq)
          DEFINE_SLOWCASE_OP(op_new_object)
</pre>
<hr />
<pre>
<span class="line-old-header">*** 650,11 ***</span>
          m_codeBlock-&gt;m_shouldAlwaysBeInlined &amp;= canInline(level) &amp;&amp; DFG::mightInlineFunction(m_codeBlock);
          break;
      }
  
      if (UNLIKELY(Options::dumpDisassembly() || (m_vm-&gt;m_perBytecodeProfiler &amp;&amp; Options::disassembleBaselineForProfiler())))
<span class="line-modified">!         m_disassembler = std::make_unique&lt;JITDisassembler&gt;(m_codeBlock);</span>
      if (UNLIKELY(m_vm-&gt;m_perBytecodeProfiler)) {
          m_compilation = adoptRef(
              new Profiler::Compilation(
                  m_vm-&gt;m_perBytecodeProfiler-&gt;ensureBytecodesFor(m_codeBlock),
                  Profiler::Baseline));
<span class="line-new-header">--- 631,11 ---</span>
          m_codeBlock-&gt;m_shouldAlwaysBeInlined &amp;= canInline(level) &amp;&amp; DFG::mightInlineFunction(m_codeBlock);
          break;
      }
  
      if (UNLIKELY(Options::dumpDisassembly() || (m_vm-&gt;m_perBytecodeProfiler &amp;&amp; Options::disassembleBaselineForProfiler())))
<span class="line-modified">!         m_disassembler = makeUnique&lt;JITDisassembler&gt;(m_codeBlock);</span>
      if (UNLIKELY(m_vm-&gt;m_perBytecodeProfiler)) {
          m_compilation = adoptRef(
              new Profiler::Compilation(
                  m_vm-&gt;m_perBytecodeProfiler-&gt;ensureBytecodesFor(m_codeBlock),
                  Profiler::Baseline));
</pre>
<hr />
<pre>
<span class="line-old-header">*** 897,23 ***</span>
              m_disassembler-&gt;reportToProfiler(m_compilation.get(), patchBuffer);
          m_vm-&gt;m_perBytecodeProfiler-&gt;addCompilation(m_codeBlock, *m_compilation);
      }
  
      if (m_pcToCodeOriginMapBuilder.didBuildMapping())
<span class="line-modified">!         m_codeBlock-&gt;setPCToCodeOriginMap(std::make_unique&lt;PCToCodeOriginMap&gt;(WTFMove(m_pcToCodeOriginMapBuilder), patchBuffer));</span>
  
      CodeRef&lt;JSEntryPtrTag&gt; result = FINALIZE_CODE(
          patchBuffer, JSEntryPtrTag,
<span class="line-modified">!         &quot;Baseline JIT code for %s&quot;, toCString(CodeBlockWithJITType(m_codeBlock, JITCode::BaselineJIT)).data());</span>
  
      m_vm-&gt;machineCodeBytesPerBytecodeWordForBaselineJIT-&gt;add(
          static_cast&lt;double&gt;(result.size()) /
<span class="line-modified">!         static_cast&lt;double&gt;(m_codeBlock-&gt;instructionCount()));</span>
  
      m_codeBlock-&gt;shrinkToFit(CodeBlock::LateShrink);
      m_codeBlock-&gt;setJITCode(
<span class="line-modified">!         adoptRef(*new DirectJITCode(result, withArityCheck, JITCode::BaselineJIT)));</span>
  
      if (JITInternal::verbose)
          dataLogF(&quot;JIT generated code for %p at [%p, %p).\n&quot;, m_codeBlock, result.executableMemory()-&gt;start().untaggedPtr(), result.executableMemory()-&gt;end().untaggedPtr());
  
      return CompilationSuccessful;
<span class="line-new-header">--- 878,23 ---</span>
              m_disassembler-&gt;reportToProfiler(m_compilation.get(), patchBuffer);
          m_vm-&gt;m_perBytecodeProfiler-&gt;addCompilation(m_codeBlock, *m_compilation);
      }
  
      if (m_pcToCodeOriginMapBuilder.didBuildMapping())
<span class="line-modified">!         m_codeBlock-&gt;setPCToCodeOriginMap(makeUnique&lt;PCToCodeOriginMap&gt;(WTFMove(m_pcToCodeOriginMapBuilder), patchBuffer));</span>
  
      CodeRef&lt;JSEntryPtrTag&gt; result = FINALIZE_CODE(
          patchBuffer, JSEntryPtrTag,
<span class="line-modified">!         &quot;Baseline JIT code for %s&quot;, toCString(CodeBlockWithJITType(m_codeBlock, JITType::BaselineJIT)).data());</span>
  
      m_vm-&gt;machineCodeBytesPerBytecodeWordForBaselineJIT-&gt;add(
          static_cast&lt;double&gt;(result.size()) /
<span class="line-modified">!         static_cast&lt;double&gt;(m_codeBlock-&gt;instructionsSize()));</span>
  
      m_codeBlock-&gt;shrinkToFit(CodeBlock::LateShrink);
      m_codeBlock-&gt;setJITCode(
<span class="line-modified">!         adoptRef(*new DirectJITCode(result, withArityCheck, JITType::BaselineJIT)));</span>
  
      if (JITInternal::verbose)
          dataLogF(&quot;JIT generated code for %p at [%p, %p).\n&quot;, m_codeBlock, result.executableMemory()-&gt;start().untaggedPtr(), result.executableMemory()-&gt;end().untaggedPtr());
  
      return CompilationSuccessful;
</pre>
<hr />
<pre>
<span class="line-old-header">*** 929,43 ***</span>
  void JIT::privateCompileExceptionHandlers()
  {
      if (!m_exceptionChecksWithCallFrameRollback.empty()) {
          m_exceptionChecksWithCallFrameRollback.link(this);
  
<span class="line-modified">!         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm()-&gt;topEntryFrame);</span>
  
          // lookupExceptionHandlerFromCallerFrame is passed two arguments, the VM and the exec (the CallFrame*).
  
<span class="line-modified">!         move(TrustedImmPtr(vm()), GPRInfo::argumentGPR0);</span>
          move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR1);
  
  #if CPU(X86)
          // FIXME: should use the call abstraction, but this is currently in the SpeculativeJIT layer!
          poke(GPRInfo::argumentGPR0);
          poke(GPRInfo::argumentGPR1, 1);
  #endif
          m_calls.append(CallRecord(call(OperationPtrTag), std::numeric_limits&lt;unsigned&gt;::max(), FunctionPtr&lt;OperationPtrTag&gt;(lookupExceptionHandlerFromCallerFrame)));
<span class="line-modified">!         jumpToExceptionHandler(*vm());</span>
      }
  
      if (!m_exceptionChecks.empty() || m_byValCompilationInfo.size()) {
          m_exceptionHandler = label();
          m_exceptionChecks.link(this);
  
<span class="line-modified">!         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm()-&gt;topEntryFrame);</span>
  
          // lookupExceptionHandler is passed two arguments, the VM and the exec (the CallFrame*).
<span class="line-modified">!         move(TrustedImmPtr(vm()), GPRInfo::argumentGPR0);</span>
          move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR1);
  
  #if CPU(X86)
          // FIXME: should use the call abstraction, but this is currently in the SpeculativeJIT layer!
          poke(GPRInfo::argumentGPR0);
          poke(GPRInfo::argumentGPR1, 1);
  #endif
          m_calls.append(CallRecord(call(OperationPtrTag), std::numeric_limits&lt;unsigned&gt;::max(), FunctionPtr&lt;OperationPtrTag&gt;(lookupExceptionHandler)));
<span class="line-modified">!         jumpToExceptionHandler(*vm());</span>
      }
  }
  
  void JIT::doMainThreadPreparationBeforeCompile()
  {
<span class="line-new-header">--- 910,43 ---</span>
  void JIT::privateCompileExceptionHandlers()
  {
      if (!m_exceptionChecksWithCallFrameRollback.empty()) {
          m_exceptionChecksWithCallFrameRollback.link(this);
  
<span class="line-modified">!         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);</span>
  
          // lookupExceptionHandlerFromCallerFrame is passed two arguments, the VM and the exec (the CallFrame*).
  
<span class="line-modified">!         move(TrustedImmPtr(&amp;vm()), GPRInfo::argumentGPR0);</span>
          move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR1);
  
  #if CPU(X86)
          // FIXME: should use the call abstraction, but this is currently in the SpeculativeJIT layer!
          poke(GPRInfo::argumentGPR0);
          poke(GPRInfo::argumentGPR1, 1);
  #endif
          m_calls.append(CallRecord(call(OperationPtrTag), std::numeric_limits&lt;unsigned&gt;::max(), FunctionPtr&lt;OperationPtrTag&gt;(lookupExceptionHandlerFromCallerFrame)));
<span class="line-modified">!         jumpToExceptionHandler(vm());</span>
      }
  
      if (!m_exceptionChecks.empty() || m_byValCompilationInfo.size()) {
          m_exceptionHandler = label();
          m_exceptionChecks.link(this);
  
<span class="line-modified">!         copyCalleeSavesToEntryFrameCalleeSavesBuffer(vm().topEntryFrame);</span>
  
          // lookupExceptionHandler is passed two arguments, the VM and the exec (the CallFrame*).
<span class="line-modified">!         move(TrustedImmPtr(&amp;vm()), GPRInfo::argumentGPR0);</span>
          move(GPRInfo::callFrameRegister, GPRInfo::argumentGPR1);
  
  #if CPU(X86)
          // FIXME: should use the call abstraction, but this is currently in the SpeculativeJIT layer!
          poke(GPRInfo::argumentGPR0);
          poke(GPRInfo::argumentGPR1, 1);
  #endif
          m_calls.append(CallRecord(call(OperationPtrTag), std::numeric_limits&lt;unsigned&gt;::max(), FunctionPtr&lt;OperationPtrTag&gt;(lookupExceptionHandler)));
<span class="line-modified">!         jumpToExceptionHandler(vm());</span>
      }
  }
  
  void JIT::doMainThreadPreparationBeforeCompile()
  {
</pre>
<center><a href="IntrinsicEmitter.cpp.cdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="JIT.h.cdiff.html" target="_top">next &gt;</a></center>  </body>
</html>