<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/b3/air/AirOpcode.opcodes</title>
    <link rel="stylesheet" href="../../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 # Copyright (C) 2015-2017 Apple Inc. All rights reserved.
   2 #
   3 # Redistribution and use in source and binary forms, with or without
   4 # modification, are permitted provided that the following conditions
   5 # are met:
   6 # 1. Redistributions of source code must retain the above copyright
   7 #    notice, this list of conditions and the following disclaimer.
   8 # 2. Redistributions in binary form must reproduce the above copyright
   9 #    notice, this list of conditions and the following disclaimer in the
  10 #    documentation and/or other materials provided with the distribution.
  11 #
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 # Syllabus:
  25 #
  26 # Examples of some roles, types, and widths:
  27 # U:G:32 =&gt; use of the low 32 bits of a general-purpose register or value
  28 # D:G:32 =&gt; def of the low 32 bits of a general-purpose register or value
  29 # UD:G:32 =&gt; use and def of the low 32 bits of a general-purpose register or value
  30 # U:G:64 =&gt; use of the low 64 bits of a general-purpose register or value
  31 # ZD:G:32 =&gt; def of all bits of a general-purpose register, where all but the low 32 bits are guaranteed to be zeroed.
  32 # UA:G:Ptr =&gt; UseAddr (see comment in Arg.h)
  33 # U:F:32 =&gt; use of a float register or value
  34 # U:F:64 =&gt; use of a double register or value
  35 # D:F:32 =&gt; def of a float register or value
  36 # UD:F:32 =&gt; use and def of a float register or value
  37 # S:F:32 =&gt; scratch float register.
  38 #
  39 # Argument kinds:
  40 # Tmp =&gt; temporary or register
  41 # Imm =&gt; 32-bit immediate int
  42 # BigImm =&gt; TrustedImm64
  43 # Addr =&gt; address as temporary/register+offset
  44 # Index =&gt; BaseIndex address
  45 # Abs =&gt; AbsoluteAddress
  46 #
  47 # The parser views these things as keywords, and understands that they fall into two distinct classes
  48 # of things. So, although this file uses a particular indentation style, none of the whitespace or
  49 # even newlines are meaningful to the parser. For example, you could write:
  50 #
  51 # Foo42 U:G:32, UD:F:32 Imm, Tmp Addr, Tmp
  52 #
  53 # And the parser would know that this is the same as:
  54 #
  55 # Foo42 U:G:32, UD:F:32
  56 #     Imm, Tmp
  57 #     Addr, Tmp
  58 #
  59 # I.e. a two-form instruction that uses a GPR or an int immediate and uses+defs a float register.
  60 #
  61 # Any opcode or opcode form can be preceded with an architecture list, which restricts the opcode to the
  62 # union of those architectures. For example, if this is the only overload of the opcode, then it makes the
  63 # opcode only available on x86_64:
  64 #
  65 # x86_64: Fuzz UD:G:64, D:G:64
  66 #     Tmp, Tmp
  67 #     Tmp, Addr
  68 #
  69 # But this only restricts the two-operand form, the other form is allowed on all architectures:
  70 #
  71 # x86_64: Fuzz UD:G:64, D:G:64
  72 #     Tmp, Tmp
  73 #     Tmp, Addr
  74 # Fuzz UD:G:Ptr, D:G:Ptr, U:F:Ptr
  75 #     Tmp, Tmp, Tmp
  76 #     Tmp, Addr, Tmp
  77 #
  78 # And you can also restrict individual forms:
  79 #
  80 # Thingy UD:G:32, D:G:32
  81 #     Tmp, Tmp
  82 #     arm64: Tmp, Addr
  83 #
  84 # Additionally, you can have an intersection between the architectures of the opcode overload and the
  85 # form. In this example, the version that takes an address is only available on armv7 while the other
  86 # versions are available on armv7 or x86_64:
  87 #
  88 # x86_64 armv7: Buzz U:G:32, UD:F:32
  89 #     Tmp, Tmp
  90 #     Imm, Tmp
  91 #     armv7: Addr, Tmp
  92 #
  93 # Finally, you can specify architectures using helpful architecture groups. Here are all of the
  94 # architecture keywords that we support:
  95 #
  96 # x86: means x86-32 or x86-64.
  97 # x86_32: means just x86-32.
  98 # x86_64: means just x86-64.
  99 # arm: means armv7 or arm64.
 100 # armv7: means just armv7.
 101 # arm64: means just arm64.
 102 # 32: means x86-32 or armv7.
 103 # 64: means x86-64 or arm64.
 104 
 105 # Note that the opcodes here have a leading capital (Add32) but must correspond to MacroAssembler
 106 # API that has a leading lower-case (add32).
 107 
 108 Nop
 109 
 110 Add32 U:G:32, U:G:32, ZD:G:32
 111     Imm, Tmp, Tmp
 112     Tmp, Tmp, Tmp
 113 
 114 Add32 U:G:32, UZD:G:32
 115     Tmp, Tmp
 116     x86: Imm, Addr
 117     x86: Imm, Index
 118     Imm, Tmp
 119     x86: Addr, Tmp
 120     x86: Index, Tmp
 121     x86: Tmp, Addr
 122     x86: Tmp, Index
 123 
 124 x86: Add8 U:G:8, UD:G:8
 125     Imm, Addr
 126     Imm, Index
 127     Tmp, Addr
 128     Tmp, Index
 129 
 130 x86: Add16 U:G:16, UD:G:16
 131     Imm, Addr
 132     Imm, Index
 133     Tmp, Addr
 134     Tmp, Index
 135 
 136 64: Add64 U:G:64, UD:G:64
 137     Tmp, Tmp
 138     x86: Imm, Addr
 139     x86: Imm, Index
 140     Imm, Tmp
 141     x86: Addr, Tmp
 142     x86: Index, Tmp
 143     x86: Tmp, Addr
 144     x86: Tmp, Index
 145 
 146 64: Add64 U:G:64, U:G:64, D:G:64
 147     Imm, Tmp, Tmp
 148     Tmp, Tmp, Tmp
 149 
 150 AddDouble U:F:64, U:F:64, D:F:64
 151     Tmp, Tmp, Tmp
 152     x86: Addr, Tmp, Tmp
 153     x86: Tmp, Addr, Tmp
 154     x86: Index, Tmp, Tmp
 155 
 156 x86: AddDouble U:F:64, UD:F:64
 157     Tmp, Tmp
 158     Addr, Tmp
 159 
 160 AddFloat U:F:32, U:F:32, D:F:32
 161     Tmp, Tmp, Tmp
 162     x86: Addr, Tmp, Tmp
 163     x86: Tmp, Addr, Tmp
 164     x86: Index, Tmp, Tmp
 165 
 166 x86: AddFloat U:F:32, UD:F:32
 167     Tmp, Tmp
 168     Addr, Tmp
 169 
 170 Sub32 U:G:32, UZD:G:32
 171     Tmp, Tmp
 172     x86: Imm, Addr
 173     x86: Imm, Index
 174     Imm, Tmp
 175     x86: Addr, Tmp
 176     x86: Index, Tmp
 177     x86: Tmp, Addr
 178     x86: Tmp, Index
 179 
 180 arm64: Sub32 U:G:32, U:G:32, D:G:32
 181     Tmp, Tmp, Tmp
 182 
 183 64: Sub64 U:G:64, UD:G:64
 184     Tmp, Tmp
 185     x86: Imm, Addr
 186     x86: Imm, Index
 187     Imm, Tmp
 188     x86: Addr, Tmp
 189     x86: Index, Tmp
 190     x86: Tmp, Addr
 191     x86: Tmp, Index
 192 
 193 arm64: Sub64 U:G:64, U:G:64, D:G:64
 194     Tmp, Tmp, Tmp
 195 
 196 SubDouble U:F:64, U:F:64, D:F:64
 197     arm64: Tmp, Tmp, Tmp
 198     x86: Tmp, Addr, Tmp
 199     x86: Tmp, Index, Tmp
 200 
 201 x86: SubDouble U:F:64, UD:F:64
 202     Tmp, Tmp
 203     Addr, Tmp
 204 
 205 SubFloat U:F:32, U:F:32, D:F:32
 206     arm64: Tmp, Tmp, Tmp
 207     x86: Tmp, Addr, Tmp
 208     x86: Tmp, Index, Tmp
 209 
 210 x86: SubFloat U:F:32, UD:F:32
 211     Tmp, Tmp
 212     Addr, Tmp
 213 
 214 Neg32 UZD:G:32
 215     Tmp
 216     x86: Addr
 217     x86: Index
 218 
 219 64: Neg64 UD:G:64
 220     Tmp
 221     x86: Addr
 222     x86: Index
 223 
 224 arm64: NegateDouble U:F:64, D:F:64
 225     Tmp, Tmp
 226 
 227 arm64: NegateFloat U:F:32, D:F:32
 228     Tmp, Tmp
 229 
 230 Mul32 U:G:32, UZD:G:32
 231     Tmp, Tmp
 232     x86: Addr, Tmp
 233 
 234 Mul32 U:G:32, U:G:32, ZD:G:32
 235     Tmp, Tmp, Tmp
 236     x86: Addr, Tmp, Tmp
 237     x86: Tmp, Addr, Tmp
 238     x86: Imm, Tmp, Tmp
 239 
 240 64: Mul64 U:G:64, UD:G:64
 241     Tmp, Tmp
 242 
 243 Mul64 U:G:64, U:G:64, D:G:64
 244     Tmp, Tmp, Tmp
 245 
 246 arm64: MultiplyAdd32 U:G:32, U:G:32, U:G:32, ZD:G:32
 247     Tmp, Tmp, Tmp, Tmp
 248 
 249 arm64: MultiplyAdd64 U:G:64, U:G:64, U:G:64, D:G:64
 250     Tmp, Tmp, Tmp, Tmp
 251 
 252 arm64: MultiplySub32 U:G:32, U:G:32, U:G:32, ZD:G:32
 253     Tmp, Tmp, Tmp, Tmp
 254 
 255 arm64: MultiplySub64 U:G:64, U:G:64, U:G:64, D:G:64
 256     Tmp, Tmp, Tmp, Tmp
 257 
 258 arm64: MultiplyNeg32 U:G:32, U:G:32, ZD:G:32
 259     Tmp, Tmp, Tmp
 260 
 261 arm64: MultiplyNeg64 U:G:64, U:G:64, ZD:G:64
 262     Tmp, Tmp, Tmp
 263 
<a name="1" id="anc1"></a><span class="line-added"> 264 arm64: MultiplySignExtend32 U:G:32, U:G:32, ZD:G:64</span>
<span class="line-added"> 265     Tmp, Tmp, Tmp</span>
<span class="line-added"> 266 </span>
 267 arm64: Div32 U:G:32, U:G:32, ZD:G:32
 268     Tmp, Tmp, Tmp
 269 
 270 arm64: UDiv32 U:G:32, U:G:32, ZD:G:32
 271     Tmp, Tmp, Tmp
 272 
 273 arm64: Div64 U:G:64, U:G:64, D:G:64
 274     Tmp, Tmp, Tmp
 275 
 276 arm64: UDiv64 U:G:64, U:G:64, D:G:64
 277     Tmp, Tmp, Tmp
 278 
 279 MulDouble U:F:64, U:F:64, D:F:64
 280     Tmp, Tmp, Tmp
 281     x86: Addr, Tmp, Tmp
 282     x86: Tmp, Addr, Tmp
 283     x86: Index, Tmp, Tmp
 284 
 285 x86: MulDouble U:F:64, UD:F:64
 286     Tmp, Tmp
 287     Addr, Tmp
 288 
 289 MulFloat U:F:32, U:F:32, D:F:32
 290     Tmp, Tmp, Tmp
 291     x86: Addr, Tmp, Tmp
 292     x86: Tmp, Addr, Tmp
 293     x86: Index, Tmp, Tmp
 294 
 295 x86: MulFloat U:F:32, UD:F:32
 296     Tmp, Tmp
 297     Addr, Tmp
 298 
 299 arm64: DivDouble U:F:64, U:F:32, D:F:64
 300     Tmp, Tmp, Tmp
 301 
 302 x86: DivDouble U:F:64, UD:F:64
 303     Tmp, Tmp
 304     Addr, Tmp
 305 
 306 arm64: DivFloat U:F:32, U:F:32, D:F:32
 307     Tmp, Tmp, Tmp
 308 
 309 x86: DivFloat U:F:32, UD:F:32
 310     Tmp, Tmp
 311     Addr, Tmp
 312 
 313 x86: X86ConvertToDoubleWord32 U:G:32, ZD:G:32
 314     Tmp*, Tmp*
 315 
 316 x86_64: X86ConvertToQuadWord64 U:G:64, D:G:64
 317     Tmp*, Tmp*
 318 
 319 x86: X86Div32 UZD:G:32, UZD:G:32, U:G:32
 320     Tmp*, Tmp*, Tmp
 321 
 322 x86: X86UDiv32 UZD:G:32, UZD:G:32, U:G:32
 323     Tmp*, Tmp*, Tmp
 324 
 325 x86_64: X86Div64 UZD:G:64, UZD:G:64, U:G:64
 326     Tmp*, Tmp*, Tmp
 327 
 328 x86_64: X86UDiv64 UZD:G:64, UZD:G:64, U:G:64
 329     Tmp*, Tmp*, Tmp
 330 
 331 # If we add other things like Lea that are UA, we may need to lower
 332 # them on arm64 similarly to how we do for Lea. In lowerStackArgs,
 333 # we lower Lea to add on arm64.
 334 Lea32 UA:G:32, D:G:32
 335     Addr, Tmp
 336     x86: Index, Tmp as x86Lea32
 337 
 338 Lea64 UA:G:64, D:G:64
 339     Addr, Tmp
 340     x86: Index, Tmp as x86Lea64
 341 
 342 And32 U:G:32, U:G:32, ZD:G:32
 343     Tmp, Tmp, Tmp
 344     arm64: BitImm, Tmp, Tmp
 345     x86: Tmp, Addr, Tmp
 346     x86: Addr, Tmp, Tmp
 347 
 348 And32 U:G:32, UZD:G:32
 349     Tmp, Tmp
 350     x86: Imm, Tmp
 351     x86: Tmp, Addr
 352     x86: Tmp, Index
 353     x86: Addr, Tmp
 354     x86: Index, Tmp
 355     x86: Imm, Addr
 356     x86: Imm, Index
 357 
 358 64: And64 U:G:64, U:G:64, D:G:64
 359     Tmp, Tmp, Tmp
 360     arm64: BitImm64, Tmp, Tmp
 361 
 362 x86_64: And64 U:G:64, UD:G:64
 363     Tmp, Tmp
 364     Imm, Tmp
 365     Imm, Addr
 366     Imm, Index
 367     Tmp, Addr
 368     Tmp, Index
 369     Addr, Tmp
 370     Index, Tmp
 371 
 372 AndDouble U:F:64, U:F:64, D:F:64
 373     Tmp, Tmp, Tmp
 374 
 375 x86: AndDouble U:F:64, UD:F:64
 376     Tmp, Tmp
 377 
 378 AndFloat U:F:32, U:F:32, D:F:32
 379     Tmp, Tmp, Tmp
 380 
 381 x86: AndFloat U:F:32, UD:F:32
 382     Tmp, Tmp
 383 
 384 OrDouble U:F:64, U:F:64, D:F:64
 385     Tmp, Tmp, Tmp
 386 
 387 x86: OrDouble U:F:64, UD:F:64
 388     Tmp, Tmp
 389 
 390 OrFloat U:F:32, U:F:32, D:F:32
 391     Tmp, Tmp, Tmp
 392 
 393 x86: OrFloat U:F:32, UD:F:32
 394     Tmp, Tmp
 395 
 396 x86: XorDouble U:F:64, U:F:64, D:F:64
 397     Tmp, Tmp, Tmp
 398 
 399 x86: XorDouble U:F:64, UD:F:64
 400     Tmp, Tmp
 401 
 402 x86: XorFloat U:F:32, U:F:32, D:F:32
 403     Tmp, Tmp, Tmp
 404 
 405 x86: XorFloat U:F:32, UD:F:32
 406     Tmp, Tmp
 407 
 408 arm64: Lshift32 U:G:32, U:G:32, ZD:G:32
 409     Tmp, Tmp, Tmp
 410     Tmp, Imm, Tmp
 411 
 412 x86:Lshift32 U:G:32, UZD:G:32
 413     Tmp*, Tmp
 414     Imm, Tmp
 415 
 416 arm64: Lshift64 U:G:64, U:G:64, D:G:64
 417     Tmp, Tmp, Tmp
 418     Tmp, Imm, Tmp
 419 
 420 x86_64: Lshift64 U:G:64, UD:G:64
 421     Tmp*, Tmp
 422     Imm, Tmp
 423 
 424 arm64: Rshift32 U:G:32, U:G:32, ZD:G:32
 425     Tmp, Tmp, Tmp
 426     Tmp, Imm, Tmp
 427 
 428 x86: Rshift32 U:G:32, UZD:G:32
 429     Tmp*, Tmp
 430     Imm, Tmp
 431 
 432 arm64: Rshift64 U:G:64, U:G:64, D:G:64
 433     Tmp, Tmp, Tmp
 434     Tmp, Imm, Tmp
 435 
 436 x86_64: Rshift64 U:G:64, UD:G:64
 437     Tmp*, Tmp
 438     Imm, Tmp
 439 
 440 arm64: Urshift32 U:G:32, U:G:32, ZD:G:32
 441     Tmp, Tmp, Tmp
 442     Tmp, Imm, Tmp
 443 
 444 x86: Urshift32 U:G:32, UZD:G:32
 445     Tmp*, Tmp
 446     Imm, Tmp
 447 
 448 arm64: Urshift64 U:G:64, U:G:64, D:G:64
 449     Tmp, Tmp, Tmp
 450     Tmp, Imm, Tmp
 451 
 452 x86_64: Urshift64 U:G:64, UD:G:64
 453     Tmp*, Tmp
 454     Imm, Tmp
 455 
 456 x86_64: RotateRight32 U:G:32, UZD:G:32
 457     Tmp*, Tmp
 458     Imm, Tmp
 459 
 460 arm64: RotateRight32 U:G:32, U:G:32, ZD:G:32
 461     Tmp, Tmp, Tmp
 462     Tmp, Imm, Tmp
 463 
 464 x86_64: RotateRight64 U:G:64, UD:G:64
 465     Tmp*, Tmp
 466     Imm, Tmp
 467 
 468 arm64: RotateRight64 U:G:64, U:G:64, D:G:64
 469     Tmp, Tmp, Tmp
 470     Tmp, Imm, Tmp
 471 
 472 x86_64: RotateLeft32 U:G:32, UZD:G:32
 473     Tmp*, Tmp
 474     Imm, Tmp
 475 
 476 x86_64: RotateLeft64 U:G:64, UD:G:64
 477     Tmp*, Tmp
 478     Imm, Tmp
 479 
 480 Or32 U:G:32, U:G:32, ZD:G:32
 481     Tmp, Tmp, Tmp
 482     arm64: BitImm, Tmp, Tmp
 483     x86: Tmp, Addr, Tmp
 484     x86: Addr, Tmp, Tmp
 485 
 486 Or32 U:G:32, UZD:G:32
 487     Tmp, Tmp
 488     x86: Imm, Tmp
 489     x86: Tmp, Addr
 490     x86: Tmp, Index
 491     x86: Addr, Tmp
 492     x86: Index, Tmp
 493     x86: Imm, Addr
 494     x86: Imm, Index
 495 
 496 64: Or64 U:G:64, U:G:64, D:G:64
 497     Tmp, Tmp, Tmp
 498     arm64: BitImm64, Tmp, Tmp
 499 
 500 64: Or64 U:G:64, UD:G:64
 501     Tmp, Tmp
 502     x86: Imm, Tmp
 503     x86: Imm, Addr
 504     x86: Imm, Index
 505     x86: Tmp, Addr
 506     x86: Tmp, Index
 507     x86: Addr, Tmp
 508     x86: Index, Tmp
 509 
 510 Xor32 U:G:32, U:G:32, ZD:G:32
 511     Tmp, Tmp, Tmp
 512     arm64: BitImm, Tmp, Tmp
 513     x86: Tmp, Addr, Tmp
 514     x86: Addr, Tmp, Tmp
 515 
 516 Xor32 U:G:32, UZD:G:32
 517     Tmp, Tmp
 518     x86: Imm, Tmp
 519     x86: Tmp, Addr
 520     x86: Tmp, Index
 521     x86: Addr, Tmp
 522     x86: Index, Tmp
 523     x86: Imm, Addr
 524     x86: Imm, Index
 525 
 526 64: Xor64 U:G:64, U:G:64, D:G:64
 527     Tmp, Tmp, Tmp
 528     arm64: BitImm64, Tmp, Tmp
 529 
 530 64: Xor64 U:G:64, UD:G:64
 531     Tmp, Tmp
 532     x86: Tmp, Addr
 533     x86: Tmp, Index
 534     x86: Addr, Tmp
 535     x86: Index, Tmp
 536     x86: Imm, Addr
 537     x86: Imm, Index
 538     x86: Imm, Tmp
 539 
 540 arm64: Not32 U:G:32, ZD:G:32
 541     Tmp, Tmp
 542 
 543 x86: Not32 UZD:G:32
 544     Tmp
 545     Addr
 546     Index
 547 
 548 arm64: Not64 U:G:64, D:G:64
 549     Tmp, Tmp
 550 
 551 x86_64: Not64 UD:G:64
 552     Tmp
 553     Addr
 554     Index
 555 
 556 arm64: AbsDouble U:F:64, D:F:64
 557     Tmp, Tmp
 558 
 559 arm64: AbsFloat U:F:32, D:F:32
 560     Tmp, Tmp
 561 
 562 CeilDouble U:F:64, D:F:64
 563     Tmp, Tmp
 564     x86: Addr, Tmp
 565 
 566 CeilFloat U:F:32, D:F:32
 567     Tmp, Tmp
 568     x86: Addr, Tmp
 569 
 570 FloorDouble U:F:64, D:F:64
 571     Tmp, Tmp
 572     x86: Addr, Tmp
 573 
 574 FloorFloat U:F:32, D:F:32
 575     Tmp, Tmp
 576     x86: Addr, Tmp
 577 
 578 SqrtDouble U:F:64, D:F:64
 579     Tmp, Tmp
 580     x86: Addr, Tmp
 581 
 582 SqrtFloat U:F:32, D:F:32
 583     Tmp, Tmp
 584     x86: Addr, Tmp
 585 
 586 ConvertInt32ToDouble U:G:32, D:F:64
 587     Tmp, Tmp
 588     x86: Addr, Tmp
 589 
 590 64: ConvertInt64ToDouble U:G:64, D:F:64
 591     Tmp, Tmp
 592     x86_64: Addr, Tmp
 593 
 594 ConvertInt32ToFloat U:G:32, D:F:32
 595     Tmp, Tmp
 596     x86: Addr, Tmp
 597 
 598 64: ConvertInt64ToFloat U:G:64, D:F:32
 599     Tmp, Tmp
 600     x86_64: Addr, Tmp
 601 
 602 CountLeadingZeros32 U:G:32, ZD:G:32
 603     Tmp, Tmp
 604     x86: Addr, Tmp
 605 
 606 64: CountLeadingZeros64 U:G:64, D:G:64
 607     Tmp, Tmp
 608     x86: Addr, Tmp
 609 
 610 ConvertDoubleToFloat U:F:64, D:F:32
 611     Tmp, Tmp
 612     x86: Addr, Tmp
 613 
 614 ConvertFloatToDouble U:F:32, D:F:64
 615     Tmp, Tmp
 616     x86: Addr, Tmp
 617 
 618 # Note that Move operates over the full register size, which is either 32-bit or 64-bit depending on
 619 # the platform. I&#39;m not entirely sure that this is a good thing; it might be better to just have a
 620 # Move64 instruction. OTOH, our MacroAssemblers already have this notion of &quot;move()&quot; that basically
 621 # means movePtr.
 622 Move U:G:Ptr, D:G:Ptr
 623     Tmp, Tmp
 624     Imm, Tmp as signExtend32ToPtr
 625     BigImm, Tmp
 626     Addr, Tmp as loadPtr # This means that &quot;Move Addr, Tmp&quot; is code-generated as &quot;load&quot; not &quot;move&quot;.
 627     Index, Tmp as loadPtr
 628     Tmp, Addr as storePtr
 629     Tmp, Index as storePtr
 630     x86: Imm, Addr as storePtr
 631 
 632 # This is for moving between spill slots.
 633 Move U:G:Ptr, D:G:Ptr, S:G:Ptr
 634     Addr, Addr, Tmp
 635 
 636 x86: Swap32 UD:G:32, UD:G:32
 637     Tmp, Tmp
 638     Tmp, Addr
 639 
 640 x86_64: Swap64 UD:G:64, UD:G:64
 641     Tmp, Tmp
 642     Tmp, Addr
 643 
 644 Move32 U:G:32, ZD:G:32
 645     Tmp, Tmp as zeroExtend32ToPtr
 646     Addr, Tmp as load32
 647     Index, Tmp as load32
 648     Tmp, Addr as store32
 649     Tmp, Index as store32
 650     x86: Imm, Tmp as zeroExtend32ToPtr
 651     x86: Imm, Addr as store32
 652     x86: Imm, Index as store32
 653 
 654 # This is for moving between spill slots.
 655 Move32 U:G:32, ZD:G:32, S:G:32
 656     Addr, Addr, Tmp
 657 
 658 # FIXME: StoreZero32 and StoreZero64 are hacks on ARM64, we can do better: https://bugs.webkit.org/show_bug.cgi?id=174821
 659 StoreZero32 D:G:32
 660     Addr
 661     Index
 662 
 663 64: StoreZero64 D:G:64
 664     Addr
 665     Index
 666 
 667 SignExtend32ToPtr U:G:32, D:G:Ptr
 668     Tmp, Tmp
 669 
 670 ZeroExtend8To32 U:G:8, ZD:G:32
 671     Tmp, Tmp
 672     x86: Addr, Tmp as load8
 673     x86: Index, Tmp as load8
 674 
 675 SignExtend8To32 U:G:8, ZD:G:32
 676     Tmp, Tmp
 677     x86: Addr, Tmp as load8SignedExtendTo32
 678     x86: Index, Tmp as load8SignedExtendTo32
 679 
 680 ZeroExtend16To32 U:G:16, ZD:G:32
 681     Tmp, Tmp
 682     x86: Addr, Tmp as load16
 683     x86: Index, Tmp as load16
 684 
 685 SignExtend16To32 U:G:16, ZD:G:32
 686     Tmp, Tmp
 687     x86: Addr, Tmp as load16SignedExtendTo32
 688     x86: Index, Tmp as load16SignedExtendTo32
 689 
 690 MoveFloat U:F:32, D:F:32
 691     Tmp, Tmp as moveDouble
 692     Addr, Tmp as loadFloat
 693     Index, Tmp as loadFloat
 694     Tmp, Addr as storeFloat
 695     Tmp, Index as storeFloat
 696 
 697 MoveFloat U:F:32, D:F:32, S:F:32
 698     Addr, Addr, Tmp
 699 
 700 MoveDouble U:F:64, D:F:64
 701     Tmp, Tmp
 702     Addr, Tmp as loadDouble
 703     Index, Tmp as loadDouble
 704     Tmp, Addr as storeDouble
 705     Tmp, Index as storeDouble
 706 
 707 MoveDouble U:F:64, D:F:64, S:F:64
 708     Addr, Addr, Tmp
 709 
 710 MoveZeroToDouble D:F:64
 711     Tmp
 712 
 713 64: Move64ToDouble U:G:64, D:F:64
 714     Tmp, Tmp
 715     x86: Addr, Tmp as loadDouble
 716     Index, Tmp as loadDouble
 717 
 718 Move32ToFloat U:G:32, D:F:32
 719     Tmp, Tmp
 720     x86: Addr, Tmp as loadFloat
 721     Index, Tmp as loadFloat
 722 
 723 64: MoveDoubleTo64 U:F:64, D:G:64
 724     Tmp, Tmp
 725     Addr, Tmp as load64
 726     Index, Tmp as load64
 727 
 728 MoveFloatTo32 U:F:32, D:G:32
 729     Tmp, Tmp
 730     Addr, Tmp as load32
 731     Index, Tmp as load32
 732 
 733 Load8 U:G:8, ZD:G:32
 734     Addr, Tmp
 735     Index, Tmp
 736 
 737 arm: LoadAcq8 U:G:8, ZD:G:32 /effects
 738     SimpleAddr, Tmp
 739 
 740 Store8 U:G:8, D:G:8
 741     Tmp, Index
 742     Tmp, Addr
 743     x86: Imm, Index
 744     x86: Imm, Addr
 745 
 746 arm: StoreRel8 U:G:8, D:G:8 /effects
 747     Tmp, SimpleAddr
 748 
 749 Load8SignedExtendTo32 U:G:8, ZD:G:32
 750     Addr, Tmp
 751     Index, Tmp
 752 
 753 arm: LoadAcq8SignedExtendTo32 U:G:8, ZD:G:32 /effects
 754     SimpleAddr, Tmp
 755 
 756 Load16 U:G:16, ZD:G:32
 757     Addr, Tmp
 758     Index, Tmp
 759 
 760 arm: LoadAcq16 U:G:16, ZD:G:32 /effects
 761     SimpleAddr, Tmp
 762 
 763 Load16SignedExtendTo32 U:G:16, ZD:G:32
 764     Addr, Tmp
 765     Index, Tmp
 766 
 767 arm: LoadAcq16SignedExtendTo32 U:G:16, ZD:G:32 /effects
 768     SimpleAddr, Tmp
 769 
 770 Store16 U:G:16, D:G:16
 771     Tmp, Index
 772     Tmp, Addr
 773     x86: Imm, Index
 774     x86: Imm, Addr
 775 
 776 arm: StoreRel16 U:G:16, D:G:16 /effects
 777     Tmp, SimpleAddr
 778 
 779 arm: LoadAcq32 U:G:32, ZD:G:32 /effects
 780     SimpleAddr, Tmp
 781 
 782 arm: StoreRel32 U:G:32, ZD:G:32 /effects
 783     Tmp, SimpleAddr
 784 
 785 arm64: LoadAcq64 U:G:64, ZD:G:64 /effects
 786     SimpleAddr, Tmp
 787 
 788 arm64: StoreRel64 U:G:64, ZD:G:64 /effects
 789     Tmp, SimpleAddr
 790 
 791 x86: Xchg8 UD:G:8, UD:G:8 /effects
 792     Tmp, Addr
 793     Tmp, Index
 794 
 795 x86: Xchg16 UD:G:16, UD:G:16 /effects
 796     Tmp, Addr
 797     Tmp, Index
 798 
 799 x86: Xchg32 UD:G:32, UD:G:32 /effects
 800     Tmp, Addr
 801     Tmp, Index
 802 
 803 x86_64: Xchg64 UD:G:64, UD:G:64 /effects
 804     Tmp, Addr
 805     Tmp, Index
 806 
 807 # The first operand is rax.
 808 # FIXME: This formulation means that the boolean result cannot be put in eax, even though all users
 809 # of this would be OK with that.
 810 # https://bugs.webkit.org/show_bug.cgi?id=169254
 811 x86: AtomicStrongCAS8 U:G:32, UD:G:8, U:G:8, UD:G:8, ZD:G:8 /effects
 812     StatusCond, Tmp*, Tmp, Addr, Tmp
 813     StatusCond, Tmp*, Tmp, Index, Tmp
 814 
 815 x86: AtomicStrongCAS16 U:G:32, UD:G:16, U:G:32, UD:G:16, ZD:G:8 /effects
 816     StatusCond, Tmp*, Tmp, Addr, Tmp
 817     StatusCond, Tmp*, Tmp, Index, Tmp
 818 
 819 x86: AtomicStrongCAS32 U:G:32, UD:G:32, U:G:32, UD:G:32, ZD:G:8 /effects
 820     StatusCond, Tmp*, Tmp, Addr, Tmp
 821     StatusCond, Tmp*, Tmp, Index, Tmp
 822 
 823 x86_64: AtomicStrongCAS64 U:G:32, UD:G:64, U:G:64, UD:G:64, ZD:G:8 /effects
 824     StatusCond, Tmp*, Tmp, Addr, Tmp
 825     StatusCond, Tmp*, Tmp, Index, Tmp
 826 
 827 x86: AtomicStrongCAS8 UD:G:8, U:G:8, UD:G:8 /effects
 828     Tmp*, Tmp, Addr
 829     Tmp*, Tmp, Index
 830 
 831 x86: AtomicStrongCAS16 UD:G:16, U:G:32, UD:G:16 /effects
 832     Tmp*, Tmp, Addr
 833     Tmp*, Tmp, Index
 834 
 835 x86: AtomicStrongCAS32 UD:G:32, U:G:32, UD:G:32 /effects
 836     Tmp*, Tmp, Addr
 837     Tmp*, Tmp, Index
 838 
 839 x86_64: AtomicStrongCAS64 UD:G:64, U:G:64, UD:G:64 /effects
 840     Tmp*, Tmp, Addr
 841     Tmp*, Tmp, Index
 842 
 843 x86: BranchAtomicStrongCAS8 U:G:32, UD:G:8, U:G:8, UD:G:8 /branch /effects
 844     StatusCond, Tmp*, Tmp, Addr
 845     StatusCond, Tmp*, Tmp, Index
 846 
 847 x86: BranchAtomicStrongCAS16 U:G:32, UD:G:16, U:G:32, UD:G:16 /branch /effects
 848     StatusCond, Tmp*, Tmp, Addr
 849     StatusCond, Tmp*, Tmp, Index
 850 
 851 x86: BranchAtomicStrongCAS32 U:G:32, UD:G:32, U:G:32, UD:G:32 /branch /effects
 852     StatusCond, Tmp*, Tmp, Addr
 853     StatusCond, Tmp*, Tmp, Index
 854 
 855 x86_64: BranchAtomicStrongCAS64 U:G:32, UD:G:64, U:G:64, UD:G:64 /branch /effects
 856     StatusCond, Tmp*, Tmp, Addr
 857     StatusCond, Tmp*, Tmp, Index
 858 
 859 x86: AtomicAdd8 U:G:8, UD:G:8 /effects
 860     Imm, Addr
 861     Imm, Index
 862     Tmp, Addr
 863     Tmp, Index
 864 
 865 x86: AtomicAdd16 U:G:16, UD:G:16 /effects
 866     Imm, Addr
 867     Imm, Index
 868     Tmp, Addr
 869     Tmp, Index
 870 
 871 x86: AtomicAdd32 U:G:32, UD:G:32 /effects
 872     Imm, Addr
 873     Imm, Index
 874     Tmp, Addr
 875     Tmp, Index
 876 
 877 x86_64: AtomicAdd64 U:G:64, UD:G:64 /effects
 878     Imm, Addr
 879     Imm, Index
 880     Tmp, Addr
 881     Tmp, Index
 882 
 883 x86: AtomicSub8 U:G:8, UD:G:8 /effects
 884     Imm, Addr
 885     Imm, Index
 886     Tmp, Addr
 887     Tmp, Index
 888 
 889 x86: AtomicSub16 U:G:16, UD:G:16 /effects
 890     Imm, Addr
 891     Imm, Index
 892     Tmp, Addr
 893     Tmp, Index
 894 
 895 x86: AtomicSub32 U:G:32, UD:G:32 /effects
 896     Imm, Addr
 897     Imm, Index
 898     Tmp, Addr
 899     Tmp, Index
 900 
 901 x86_64: AtomicSub64 U:G:64, UD:G:64 /effects
 902     Imm, Addr
 903     Imm, Index
 904     Tmp, Addr
 905     Tmp, Index
 906 
 907 x86: AtomicAnd8 U:G:8, UD:G:8 /effects
 908     Imm, Addr
 909     Imm, Index
 910     Tmp, Addr
 911     Tmp, Index
 912 
 913 x86: AtomicAnd16 U:G:16, UD:G:16 /effects
 914     Imm, Addr
 915     Imm, Index
 916     Tmp, Addr
 917     Tmp, Index
 918 
 919 x86: AtomicAnd32 U:G:32, UD:G:32 /effects
 920     Imm, Addr
 921     Imm, Index
 922     Tmp, Addr
 923     Tmp, Index
 924 
 925 x86_64: AtomicAnd64 U:G:64, UD:G:64 /effects
 926     Imm, Addr
 927     Imm, Index
 928     Tmp, Addr
 929     Tmp, Index
 930 
 931 x86: AtomicOr8 U:G:8, UD:G:8 /effects
 932     Imm, Addr
 933     Imm, Index
 934     Tmp, Addr
 935     Tmp, Index
 936 
 937 x86: AtomicOr16 U:G:16, UD:G:16 /effects
 938     Imm, Addr
 939     Imm, Index
 940     Tmp, Addr
 941     Tmp, Index
 942 
 943 x86: AtomicOr32 U:G:32, UD:G:32 /effects
 944     Imm, Addr
 945     Imm, Index
 946     Tmp, Addr
 947     Tmp, Index
 948 
 949 x86_64: AtomicOr64 U:G:64, UD:G:64 /effects
 950     Imm, Addr
 951     Imm, Index
 952     Tmp, Addr
 953     Tmp, Index
 954 
 955 x86: AtomicXor8 U:G:8, UD:G:8 /effects
 956     Imm, Addr
 957     Imm, Index
 958     Tmp, Addr
 959     Tmp, Index
 960 
 961 x86: AtomicXor16 U:G:16, UD:G:16 /effects
 962     Imm, Addr
 963     Imm, Index
 964     Tmp, Addr
 965     Tmp, Index
 966 
 967 x86: AtomicXor32 U:G:32, UD:G:32 /effects
 968     Imm, Addr
 969     Imm, Index
 970     Tmp, Addr
 971     Tmp, Index
 972 
 973 x86_64: AtomicXor64 U:G:64, UD:G:64 /effects
 974     Imm, Addr
 975     Imm, Index
 976     Tmp, Addr
 977     Tmp, Index
 978 
 979 x86: AtomicNeg8 UD:G:8 /effects
 980     Addr
 981     Index
 982 
 983 x86: AtomicNeg16 UD:G:16 /effects
 984     Addr
 985     Index
 986 
 987 x86: AtomicNeg32 UD:G:32 /effects
 988     Addr
 989     Index
 990 
 991 x86_64: AtomicNeg64 UD:G:64 /effects
 992     Addr
 993     Index
 994 
 995 x86: AtomicNot8 UD:G:8 /effects
 996     Addr
 997     Index
 998 
 999 x86: AtomicNot16 UD:G:16 /effects
1000     Addr
1001     Index
1002 
1003 x86: AtomicNot32 UD:G:32 /effects
1004     Addr
1005     Index
1006 
1007 x86_64: AtomicNot64 UD:G:64 /effects
1008     Addr
1009     Index
1010 
1011 x86: AtomicXchgAdd8 UD:G:8, UD:G:8 /effects
1012     Tmp, Addr
1013     Tmp, Index
1014 
1015 x86: AtomicXchgAdd16 UD:G:16, UD:G:16 /effects
1016     Tmp, Addr
1017     Tmp, Index
1018 
1019 x86: AtomicXchgAdd32 UD:G:32, UD:G:32 /effects
1020     Tmp, Addr
1021     Tmp, Index
1022 
1023 x86_64: AtomicXchgAdd64 UD:G:64, UD:G:64 /effects
1024     Tmp, Addr
1025     Tmp, Index
1026 
1027 x86: AtomicXchg8 UD:G:8, UD:G:8 /effects
1028     Tmp, Addr
1029     Tmp, Index
1030 
1031 x86: AtomicXchg16 UD:G:16, UD:G:16 /effects
1032     Tmp, Addr
1033     Tmp, Index
1034 
1035 x86: AtomicXchg32 UD:G:32, UD:G:32 /effects
1036     Tmp, Addr
1037     Tmp, Index
1038 
1039 x86_64: AtomicXchg64 UD:G:64, UD:G:64 /effects
1040     Tmp, Addr
1041     Tmp, Index
1042 
1043 arm64: LoadLink8 U:G:8, ZD:G:8 /effects
1044     SimpleAddr, Tmp
1045 
1046 arm64: LoadLinkAcq8 U:G:8, ZD:G:8 /effects
1047     SimpleAddr, Tmp
1048 
1049 # Super confusing fact: this returns 0 to mean success, 1 to mean failure.
1050 arm64: StoreCond8 U:G:8, D:G:8, EZD:G:8 /effects
1051     Tmp, SimpleAddr, Tmp
1052 
1053 arm64: StoreCondRel8 U:G:8, D:G:8, EZD:G:8 /effects
1054     Tmp, SimpleAddr, Tmp
1055 
1056 arm64: LoadLink16 U:G:16, ZD:G:16 /effects
1057     SimpleAddr, Tmp
1058 
1059 arm64: LoadLinkAcq16 U:G:16, ZD:G:16 /effects
1060     SimpleAddr, Tmp
1061 
1062 arm64: StoreCond16 U:G:16, D:G:16, EZD:G:8 /effects
1063     Tmp, SimpleAddr, Tmp
1064 
1065 arm64: StoreCondRel16 U:G:16, D:G:16, EZD:G:8 /effects
1066     Tmp, SimpleAddr, Tmp
1067 
1068 arm64: LoadLink32 U:G:32, ZD:G:32 /effects
1069     SimpleAddr, Tmp
1070 
1071 arm64: LoadLinkAcq32 U:G:32, ZD:G:32 /effects
1072     SimpleAddr, Tmp
1073 
1074 arm64: StoreCond32 U:G:32, D:G:32, EZD:G:8 /effects
1075     Tmp, SimpleAddr, Tmp
1076 
1077 arm64: StoreCondRel32 U:G:32, D:G:32, EZD:G:8 /effects
1078     Tmp, SimpleAddr, Tmp
1079 
1080 arm64: LoadLink64 U:G:64, ZD:G:64 /effects
1081     SimpleAddr, Tmp
1082 
1083 arm64: LoadLinkAcq64 U:G:64, ZD:G:64 /effects
1084     SimpleAddr, Tmp
1085 
1086 arm64: StoreCond64 U:G:64, D:G:64, EZD:G:8 /effects
1087     Tmp, SimpleAddr, Tmp
1088 
1089 arm64: StoreCondRel64 U:G:64, D:G:64, EZD:G:8 /effects
1090     Tmp, SimpleAddr, Tmp
1091 
1092 arm64: Depend32 U:G:32, ZD:G:32
1093     Tmp, Tmp
1094 
1095 arm64: Depend64 U:G:64, ZD:G:64
1096     Tmp, Tmp
1097 
1098 Compare32 U:G:32, U:G:32, U:G:32, ZD:G:32
1099     RelCond, Tmp, Tmp, Tmp
1100     RelCond, Tmp, Imm, Tmp
1101 
1102 64: Compare64 U:G:32, U:G:64, U:G:64, ZD:G:32
1103     RelCond, Tmp, Tmp, Tmp
1104     x86: RelCond, Tmp, Imm, Tmp
1105 
1106 Test32 U:G:32, U:G:32, U:G:32, ZD:G:32
1107     x86: ResCond, Addr, Imm, Tmp
1108     ResCond, Tmp, Tmp, Tmp
1109     ResCond, Tmp, BitImm, Tmp
1110 
1111 64: Test64 U:G:32, U:G:64, U:G:64, ZD:G:32
1112     x86: ResCond, Tmp, Imm, Tmp
1113     ResCond, Tmp, Tmp, Tmp
1114 
1115 CompareDouble U:G:32, U:F:64, U:F:64, ZD:G:32
1116     DoubleCond, Tmp, Tmp, Tmp
1117 
1118 CompareFloat U:G:32, U:F:32, U:F:32, ZD:G:32
1119     DoubleCond, Tmp, Tmp, Tmp
1120 
1121 # Note that branches have some logic in AirOptimizeBlockOrder.cpp. If you add new branches, please make sure
1122 # you opt them into the block order optimizations.
1123 
1124 Branch8 U:G:32, U:G:8, U:G:8 /branch
1125     x86: RelCond, Addr, Imm
1126     x86: RelCond, Index, Imm
1127 
1128 Branch32 U:G:32, U:G:32, U:G:32 /branch
1129     x86: RelCond, Addr, Imm
1130     RelCond, Tmp, Tmp
1131     RelCond, Tmp, Imm
1132     x86: RelCond, Tmp, Addr
1133     x86: RelCond, Addr, Tmp
1134     x86: RelCond, Index, Imm
1135 
1136 64: Branch64 U:G:32, U:G:64, U:G:64 /branch
1137     RelCond, Tmp, Tmp
1138     RelCond, Tmp, Imm
1139     x86: RelCond, Tmp, Addr
1140     x86: RelCond, Addr, Tmp
1141     x86: RelCond, Addr, Imm
1142     x86: RelCond, Index, Tmp
1143 
1144 BranchTest8 U:G:32, U:G:8, U:G:8 /branch
1145     x86: ResCond, Addr, BitImm
1146     x86: ResCond, Index, BitImm
1147 
1148 BranchTest32 U:G:32, U:G:32, U:G:32 /branch
1149     ResCond, Tmp, Tmp
1150     ResCond, Tmp, BitImm
1151     x86: ResCond, Addr, BitImm
1152     x86: ResCond, Index, BitImm
1153 
1154 # Warning: forms that take an immediate will sign-extend their immediate. You probably want
1155 # BranchTest32 in most cases where you use an immediate.
1156 64: BranchTest64 U:G:32, U:G:64, U:G:64 /branch
1157     ResCond, Tmp, Tmp
1158     arm64: ResCond, Tmp, BitImm64
1159     x86: ResCond, Tmp, BitImm
1160     x86: ResCond, Addr, BitImm
1161     x86: ResCond, Addr, Tmp
1162     x86: ResCond, Index, BitImm
1163 
<a name="2" id="anc2"></a><span class="line-added">1164 x86_64: BranchTestBit64 U:G:32, U:G:64, U:G:8 /branch</span>
<span class="line-added">1165     ResCond, Tmp, Imm</span>
<span class="line-added">1166     ResCond, Addr, Imm</span>
<span class="line-added">1167     ResCond, Tmp, Tmp</span>
<span class="line-added">1168 </span>
<span class="line-added">1169 x86: BranchTestBit32 U:G:32, U:G:32, U:G:8 /branch</span>
<span class="line-added">1170     ResCond, Tmp, Imm</span>
<span class="line-added">1171     ResCond, Addr, Imm</span>
<span class="line-added">1172     ResCond, Tmp, Tmp</span>
<span class="line-added">1173 </span>
1174 BranchDouble U:G:32, U:F:64, U:F:64 /branch
1175     DoubleCond, Tmp, Tmp
1176 
1177 BranchFloat U:G:32, U:F:32, U:F:32 /branch
1178     DoubleCond, Tmp, Tmp
1179 
1180 BranchAdd32 U:G:32, U:G:32, U:G:32, ZD:G:32 /branch
1181     ResCond, Tmp, Tmp, Tmp
1182     x86:ResCond, Tmp, Addr, Tmp
1183     x86:ResCond, Addr, Tmp, Tmp
1184 
1185 BranchAdd32 U:G:32, U:G:32, UZD:G:32 /branch
1186     ResCond, Tmp, Tmp
1187     ResCond, Imm, Tmp
1188     x86: ResCond, Imm, Addr
1189     x86: ResCond, Tmp, Addr
1190     x86: ResCond, Addr, Tmp
1191 
1192 BranchAdd64 U:G:32, U:G:64, U:G:64, ZD:G:64 /branch
1193     ResCond, Tmp, Tmp, Tmp
1194     x86:ResCond, Tmp, Addr, Tmp
1195     x86:ResCond, Addr, Tmp, Tmp
1196 
1197 64: BranchAdd64 U:G:32, U:G:64, UD:G:64 /branch
1198     ResCond, Imm, Tmp
1199     ResCond, Tmp, Tmp
1200     x86:ResCond, Addr, Tmp
1201 
1202 x86: BranchMul32 U:G:32, U:G:32, UZD:G:32 /branch
1203     ResCond, Tmp, Tmp
1204     ResCond, Addr, Tmp
1205 
1206 x86: BranchMul32 U:G:32, U:G:32, U:G:32, ZD:G:32 /branch
1207     ResCond, Tmp, Imm, Tmp
1208 
1209 arm64: BranchMul32 U:G:32, U:G:32, U:G:32, S:G:32, S:G:32, ZD:G:32 /branch
1210     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1211 
1212 x86_64: BranchMul64 U:G:32, U:G:64, UZD:G:64 /branch
1213     ResCond, Tmp, Tmp
1214 
1215 arm64: BranchMul64 U:G:32, U:G:64, U:G:64, S:G:64, S:G:64, ZD:G:64 /branch
1216     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1217 
1218 BranchSub32 U:G:32, U:G:32, UZD:G:32 /branch
1219     ResCond, Tmp, Tmp
1220     ResCond, Imm, Tmp
1221     x86: ResCond, Imm, Addr
1222     x86: ResCond, Tmp, Addr
1223     x86: ResCond, Addr, Tmp
1224 
1225 64: BranchSub64 U:G:32, U:G:64, UD:G:64 /branch
1226     ResCond, Imm, Tmp
1227     ResCond, Tmp, Tmp
1228 
1229 BranchNeg32 U:G:32, UZD:G:32 /branch
1230     ResCond, Tmp
1231 
1232 64: BranchNeg64 U:G:32, UZD:G:64 /branch
1233     ResCond, Tmp
1234 
1235 MoveConditionally32 U:G:32, U:G:32, U:G:32, U:G:Ptr, UD:G:Ptr
1236     RelCond, Tmp, Tmp, Tmp, Tmp
1237 
1238 MoveConditionally32 U:G:32, U:G:32, U:G:32, U:G:Ptr, U:G:Ptr, D:G:Ptr
1239     RelCond, Tmp, Tmp, Tmp, Tmp, Tmp
1240     RelCond, Tmp, Imm, Tmp, Tmp, Tmp
1241 
1242 64: MoveConditionally64 U:G:32, U:G:64, U:G:64, U:G:Ptr, UD:G:Ptr
1243     RelCond, Tmp, Tmp, Tmp, Tmp
1244 
1245 64: MoveConditionally64 U:G:32, U:G:64, U:G:64, U:G:Ptr, U:G:Ptr, D:G:Ptr
1246     RelCond, Tmp, Tmp, Tmp, Tmp, Tmp
1247     RelCond, Tmp, Imm, Tmp, Tmp, Tmp
1248 
1249 MoveConditionallyTest32 U:G:32, U:G:32, U:G:32, U:G:Ptr, UD:G:Ptr
1250     ResCond, Tmp, Tmp, Tmp, Tmp
1251     x86: ResCond, Tmp, Imm, Tmp, Tmp
1252 
1253 MoveConditionallyTest32 U:G:32, U:G:32, U:G:32, U:G:Ptr, U:G:Ptr, D:G:Ptr
1254     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1255     ResCond, Tmp, BitImm, Tmp, Tmp, Tmp
1256 
1257 64: MoveConditionallyTest64 U:G:32, U:G:64, U:G:64, U:G:Ptr, UD:G:Ptr
1258     ResCond, Tmp, Tmp, Tmp, Tmp
1259     x86: ResCond, Tmp, Imm, Tmp, Tmp
1260 
1261 64: MoveConditionallyTest64 U:G:32, U:G:32, U:G:32, U:G:Ptr, U:G:Ptr, D:G:Ptr
1262     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1263     x86_64: ResCond, Tmp, Imm, Tmp, Tmp, Tmp
1264 
1265 MoveConditionallyDouble U:G:32, U:F:64, U:F:64, U:G:Ptr, U:G:Ptr, D:G:Ptr
1266     DoubleCond, Tmp, Tmp, Tmp, Tmp, Tmp
1267 
1268 MoveConditionallyDouble U:G:32, U:F:64, U:F:64, U:G:Ptr, UD:G:Ptr
1269     DoubleCond, Tmp, Tmp, Tmp, Tmp
1270 
1271 MoveConditionallyFloat U:G:32, U:F:32, U:F:32, U:G:Ptr, U:G:Ptr, D:G:Ptr
1272     DoubleCond, Tmp, Tmp, Tmp, Tmp, Tmp
1273 
1274 MoveConditionallyFloat U:G:32, U:F:32, U:F:32, U:G:Ptr, UD:G:Ptr
1275     DoubleCond, Tmp, Tmp, Tmp, Tmp
1276 
1277 MoveDoubleConditionally32 U:G:32, U:G:32, U:G:32, U:F:64, U:F:64, D:F:64
1278     RelCond, Tmp, Tmp, Tmp, Tmp, Tmp
1279     RelCond, Tmp, Imm, Tmp, Tmp, Tmp
1280     x86: RelCond, Addr, Imm, Tmp, Tmp, Tmp
1281     x86: RelCond, Tmp, Addr, Tmp, Tmp, Tmp
1282     x86: RelCond, Addr, Tmp, Tmp, Tmp, Tmp
1283     x86: RelCond, Index, Imm, Tmp, Tmp, Tmp
1284 
1285 64: MoveDoubleConditionally64 U:G:32, U:G:64, U:G:64, U:F:64, U:F:64, D:F:64
1286     RelCond, Tmp, Tmp, Tmp, Tmp, Tmp
1287     RelCond, Tmp, Imm, Tmp, Tmp, Tmp
1288     x86_64: RelCond, Tmp, Addr, Tmp, Tmp, Tmp
1289     x86_64: RelCond, Addr, Tmp, Tmp, Tmp, Tmp
1290     x86_64: RelCond, Addr, Imm, Tmp, Tmp, Tmp
1291     x86_64: RelCond, Index, Tmp, Tmp, Tmp, Tmp
1292 
1293 MoveDoubleConditionallyTest32 U:G:32, U:G:32, U:G:32, U:F:64, U:F:64, D:F:64
1294     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1295     ResCond, Tmp, BitImm, Tmp, Tmp, Tmp
1296     x86: ResCond, Addr, Imm, Tmp, Tmp, Tmp
1297     x86: ResCond, Index, Imm, Tmp, Tmp, Tmp
1298 
1299 # Warning: forms that take an immediate will sign-extend their immediate. You probably want
1300 # MoveDoubleConditionallyTest32 in most cases where you use an immediate.
1301 64: MoveDoubleConditionallyTest64 U:G:32, U:G:64, U:G:64, U:F:64, U:F:64, D:F:64
1302     ResCond, Tmp, Tmp, Tmp, Tmp, Tmp
1303     x86_64: ResCond, Tmp, Imm, Tmp, Tmp, Tmp
1304     x86_64: ResCond, Addr, Imm, Tmp, Tmp, Tmp
1305     x86_64: ResCond, Addr, Tmp, Tmp, Tmp, Tmp
1306     x86_64: ResCond, Index, Imm, Tmp, Tmp, Tmp
1307 
1308 MoveDoubleConditionallyDouble U:G:32, U:F:64, U:F:64, U:F:64, U:F:64, D:F:64
1309     DoubleCond, Tmp, Tmp, Tmp, Tmp, Tmp
1310 
1311 MoveDoubleConditionallyFloat U:G:32, U:F:32, U:F:32, U:F:64, U:F:64, D:F:64
1312     DoubleCond, Tmp, Tmp, Tmp, Tmp, Tmp
1313 
1314 MemoryFence /effects
1315 StoreFence /effects
1316 LoadFence /effects
1317 
1318 Jump /branch
1319 
1320 RetVoid /return
1321 
1322 Ret32 U:G:32 /return
1323     Tmp
1324 
1325 64: Ret64 U:G:64 /return
1326     Tmp
1327 
1328 RetFloat U:F:32 /return
1329     Tmp
1330 
1331 RetDouble U:F:64 /return
1332     Tmp
1333 
1334 Oops /terminal
1335 
1336 # This is a terminal but we express it as a Custom because we don&#39;t want it to have a code
1337 # generator.
1338 custom EntrySwitch
1339 
1340 # A Shuffle is a multi-source, multi-destination move. It simultaneously does multiple moves at once.
1341 # The moves are specified as triplets of src, dst, and width. For example you can request a swap this
1342 # way:
1343 #     Shuffle %tmp1, %tmp2, 64, %tmp2, %tmp1, 64
1344 custom Shuffle
1345 
1346 # Air allows for exotic behavior. A Patch&#39;s behavior is determined entirely by the Special operand,
1347 # which must be the first operand.
1348 custom Patch
1349 
1350 # Instructions used for lowering C calls. These don&#39;t make it to Air generation. They get lowered to
1351 # something else first. The origin Value must be a CCallValue.
1352 custom CCall
1353 custom ColdCCall
1354 
1355 # This is a special wasm opcode that branches to a trap handler. This uses the generator located to Air::Code
1356 # to produce the side-exit code.
1357 custom WasmBoundsCheck
1358 
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>