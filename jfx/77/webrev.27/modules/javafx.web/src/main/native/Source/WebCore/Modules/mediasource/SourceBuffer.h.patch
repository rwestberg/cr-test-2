diff a/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.h b/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.h
--- a/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.h
+++ b/modules/javafx.web/src/main/native/Source/WebCore/Modules/mediasource/SourceBuffer.h
@@ -65,10 +65,11 @@
     , private TextTrackClient
 #if !RELEASE_LOG_DISABLED
     , private LoggerHelper
 #endif
 {
+    WTF_MAKE_ISO_ALLOCATED(SourceBuffer);
 public:
     static Ref<SourceBuffer> create(Ref<SourceBufferPrivate>&&, MediaSource*);
     virtual ~SourceBuffer();
 
     bool updating() const { return m_updating; }
@@ -151,12 +152,12 @@
 
     void sourceBufferPrivateDidReceiveInitializationSegment(const InitializationSegment&) final;
     void sourceBufferPrivateDidReceiveSample(MediaSample&) final;
     bool sourceBufferPrivateHasAudio() const final;
     bool sourceBufferPrivateHasVideo() const final;
-    void sourceBufferPrivateReenqueSamples(const AtomicString& trackID) final;
-    void sourceBufferPrivateDidBecomeReadyForMoreSamples(const AtomicString& trackID) final;
+    void sourceBufferPrivateReenqueSamples(const AtomString& trackID) final;
+    void sourceBufferPrivateDidBecomeReadyForMoreSamples(const AtomString& trackID) final;
     MediaTime sourceBufferPrivateFastSeekTimeForMediaTime(const MediaTime&, const MediaTime& negativeThreshold, const MediaTime& positiveThreshold) final;
     void sourceBufferPrivateAppendComplete(AppendResult) final;
     void sourceBufferPrivateDidReceiveRenderingError(int errorCode) final;
 
     void audioTrackEnabledChanged(AudioTrack&) final;
@@ -170,22 +171,22 @@
     void textTrackRemoveCue(TextTrack&, TextTrackCue&) final;
 
     EventTargetInterface eventTargetInterface() const final { return SourceBufferEventTargetInterfaceType; }
 
     bool isRemoved() const;
-    void scheduleEvent(const AtomicString& eventName);
+    void scheduleEvent(const AtomString& eventName);
 
     ExceptionOr<void> appendBufferInternal(const unsigned char*, unsigned);
     void appendBufferTimerFired();
     void resetParserState();
 
     void setActive(bool);
 
     bool validateInitializationSegment(const InitializationSegment&);
 
-    void reenqueueMediaForTime(TrackBuffer&, const AtomicString& trackID, const MediaTime&);
-    void provideMediaData(TrackBuffer&, const AtomicString& trackID);
+    void reenqueueMediaForTime(TrackBuffer&, const AtomString& trackID, const MediaTime&);
+    void provideMediaData(TrackBuffer&, const AtomString& trackID);
     void didDropSample();
     void evictCodedFrames(size_t newDataSize);
     size_t maximumBufferSize() const;
 
     void monitorBufferingRate();
@@ -195,22 +196,26 @@
 
     size_t extraMemoryCost() const;
     void reportExtraMemoryAllocated();
 
     void updateBufferedFromTrackBuffers();
+    void updateMinimumUpcomingPresentationTime(TrackBuffer&, const AtomString& trackID);
+    void resetMinimumUpcomingPresentationTime(TrackBuffer&, const AtomString& trackID);
 
     void appendError(bool);
 
     bool hasAudio() const;
 
     void rangeRemoval(const MediaTime&, const MediaTime&);
 
-    void trySignalAllSamplesInTrackEnqueued(const AtomicString&);
+    void trySignalAllSamplesInTrackEnqueued(const AtomString&);
 
     friend class Internals;
-    WEBCORE_EXPORT Vector<String> bufferedSamplesForTrackID(const AtomicString&);
-    WEBCORE_EXPORT Vector<String> enqueuedSamplesForTrackID(const AtomicString&);
+    WEBCORE_EXPORT Vector<String> bufferedSamplesForTrackID(const AtomString&);
+    WEBCORE_EXPORT Vector<String> enqueuedSamplesForTrackID(const AtomString&);
+    WEBCORE_EXPORT MediaTime minimumUpcomingPresentationTimeForTrackID(const AtomString&);
+    WEBCORE_EXPORT void setMaximumQueueDepthForTrackID(const AtomString&, size_t);
 
     Ref<SourceBufferPrivate> m_private;
     MediaSource* m_source;
     GenericEventQueue m_asyncEventQueue;
     AppendMode m_mode { AppendMode::Segments };
@@ -220,22 +225,22 @@
 
     RefPtr<VideoTrackList> m_videoTracks;
     RefPtr<AudioTrackList> m_audioTracks;
     RefPtr<TextTrackList> m_textTracks;
 
-    Vector<AtomicString> m_videoCodecs;
-    Vector<AtomicString> m_audioCodecs;
-    Vector<AtomicString> m_textCodecs;
+    Vector<AtomString> m_videoCodecs;
+    Vector<AtomString> m_audioCodecs;
+    Vector<AtomString> m_textCodecs;
 
     MediaTime m_timestampOffset;
     MediaTime m_appendWindowStart;
     MediaTime m_appendWindowEnd;
 
     MediaTime m_groupStartTimestamp;
     MediaTime m_groupEndTimestamp;
 
-    HashMap<AtomicString, TrackBuffer> m_trackBufferMap;
+    HashMap<AtomString, TrackBuffer> m_trackBufferMap;
     RefPtr<TimeRanges> m_buffered;
     bool m_bufferedDirty { true };
 
     enum AppendStateType { WaitingForSegment, ParsingInitSegment, ParsingMediaSegment };
     AppendStateType m_appendState;
