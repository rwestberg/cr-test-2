<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGSpeculativeJIT.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (C) 2011-2019 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #pragma once
  27 
  28 #if ENABLE(DFG_JIT)
  29 
  30 #include &quot;BlockDirectory.h&quot;
  31 #include &quot;DFGAbstractInterpreter.h&quot;
  32 #include &quot;DFGGenerationInfo.h&quot;
  33 #include &quot;DFGInPlaceAbstractState.h&quot;
  34 #include &quot;DFGJITCompiler.h&quot;
  35 #include &quot;DFGOSRExit.h&quot;
  36 #include &quot;DFGOSRExitJumpPlaceholder.h&quot;
  37 #include &quot;DFGRegisterBank.h&quot;
  38 #include &quot;DFGSilentRegisterSavePlan.h&quot;
  39 #include &quot;JITMathIC.h&quot;
  40 #include &quot;JITOperations.h&quot;
  41 #include &quot;PutKind.h&quot;
  42 #include &quot;SpillRegistersMode.h&quot;
  43 #include &quot;StructureStubInfo.h&quot;
  44 #include &quot;ValueRecovery.h&quot;
  45 #include &quot;VirtualRegister.h&quot;
  46 
  47 namespace JSC { namespace DFG {
  48 
  49 class GPRTemporary;
  50 class JSValueOperand;
  51 class SlowPathGenerator;
  52 class SpeculativeJIT;
  53 class SpeculateInt32Operand;
  54 class SpeculateStrictInt32Operand;
  55 class SpeculateDoubleOperand;
  56 class SpeculateCellOperand;
  57 class SpeculateBooleanOperand;
  58 
  59 enum GeneratedOperandType { GeneratedOperandTypeUnknown, GeneratedOperandInteger, GeneratedOperandJSValue};
  60 
  61 // === SpeculativeJIT ===
  62 //
  63 // The SpeculativeJIT is used to generate a fast, but potentially
  64 // incomplete code path for the dataflow. When code generating
  65 // we may make assumptions about operand types, dynamically check,
  66 // and bail-out to an alternate code path if these checks fail.
  67 // Importantly, the speculative code path cannot be reentered once
  68 // a speculative check has failed. This allows the SpeculativeJIT
  69 // to propagate type information (including information that has
  70 // only speculatively been asserted) through the dataflow.
  71 class SpeculativeJIT {
  72     WTF_MAKE_FAST_ALLOCATED;
  73 
  74     friend struct OSRExit;
  75 private:
  76     typedef JITCompiler::TrustedImm32 TrustedImm32;
  77     typedef JITCompiler::Imm32 Imm32;
  78     typedef JITCompiler::ImmPtr ImmPtr;
  79     typedef JITCompiler::TrustedImm64 TrustedImm64;
  80     typedef JITCompiler::Imm64 Imm64;
  81 
  82     // These constants are used to set priorities for spill order for
  83     // the register allocator.
  84 #if USE(JSVALUE64)
  85     enum SpillOrder {
  86         SpillOrderConstant = 1, // no spill, and cheap fill
  87         SpillOrderSpilled  = 2, // no spill
  88         SpillOrderJS       = 4, // needs spill
  89         SpillOrderCell     = 4, // needs spill
  90         SpillOrderStorage  = 4, // needs spill
  91         SpillOrderInteger  = 5, // needs spill and box
  92         SpillOrderBoolean  = 5, // needs spill and box
  93         SpillOrderDouble   = 6, // needs spill and convert
  94     };
  95 #elif USE(JSVALUE32_64)
  96     enum SpillOrder {
  97         SpillOrderConstant = 1, // no spill, and cheap fill
  98         SpillOrderSpilled  = 2, // no spill
  99         SpillOrderJS       = 4, // needs spill
 100         SpillOrderStorage  = 4, // needs spill
 101         SpillOrderDouble   = 4, // needs spill
 102         SpillOrderInteger  = 5, // needs spill and box
 103         SpillOrderCell     = 5, // needs spill and box
 104         SpillOrderBoolean  = 5, // needs spill and box
 105     };
 106 #endif
 107 
 108     enum UseChildrenMode { CallUseChildren, UseChildrenCalledExplicitly };
 109 
 110 public:
 111     SpeculativeJIT(JITCompiler&amp;);
 112     ~SpeculativeJIT();
 113 
 114     VM&amp; vm()
 115     {
<a name="1" id="anc1"></a><span class="line-modified"> 116         return m_jit.vm();</span>
 117     }
 118 
 119     struct TrustedImmPtr {
 120         template &lt;typename T&gt;
 121         explicit TrustedImmPtr(T* value)
 122             : m_value(value)
 123         {
 124             static_assert(!std::is_base_of&lt;JSCell, T&gt;::value, &quot;To use a GC pointer, the graph must be aware of it. Use SpeculativeJIT::TrustedImmPtr::weakPointer instead.&quot;);
 125         }
 126 
 127         explicit TrustedImmPtr(RegisteredStructure structure)
 128             : m_value(structure.get())
 129         { }
 130 
 131         explicit TrustedImmPtr(std::nullptr_t)
 132             : m_value(nullptr)
 133         { }
 134 
 135         explicit TrustedImmPtr(FrozenValue* value)
 136             : m_value(value-&gt;cell())
 137         {
 138             RELEASE_ASSERT(value-&gt;value().isCell());
 139         }
 140 
 141         explicit TrustedImmPtr(size_t value)
 142             : m_value(bitwise_cast&lt;void*&gt;(value))
 143         {
 144         }
 145 
 146         static TrustedImmPtr weakPointer(Graph&amp; graph, JSCell* cell)
 147         {
 148             graph.m_plan.weakReferences().addLazily(cell);
 149             return TrustedImmPtr(bitwise_cast&lt;size_t&gt;(cell));
 150         }
 151 
 152         operator MacroAssembler::TrustedImmPtr() const { return m_value; }
 153         operator MacroAssembler::TrustedImm() const { return m_value; }
 154 
 155         intptr_t asIntptr()
 156         {
 157             return m_value.asIntptr();
 158         }
 159 
 160     private:
 161         MacroAssembler::TrustedImmPtr m_value;
 162     };
 163 
 164     bool compile();
 165 
 166     void createOSREntries();
 167     void linkOSREntries(LinkBuffer&amp;);
 168 
 169     BasicBlock* nextBlock()
 170     {
 171         for (BlockIndex resultIndex = m_block-&gt;index + 1; ; resultIndex++) {
 172             if (resultIndex &gt;= m_jit.graph().numBlocks())
 173                 return 0;
 174             if (BasicBlock* result = m_jit.graph().block(resultIndex))
 175                 return result;
 176         }
 177     }
 178 
 179 #if USE(JSVALUE64)
 180     GPRReg fillJSValue(Edge);
 181 #elif USE(JSVALUE32_64)
 182     bool fillJSValue(Edge, GPRReg&amp;, GPRReg&amp;, FPRReg&amp;);
 183 #endif
 184     GPRReg fillStorage(Edge);
 185 
 186     // lock and unlock GPR &amp; FPR registers.
 187     void lock(GPRReg reg)
 188     {
 189         m_gprs.lock(reg);
 190     }
 191     void lock(FPRReg reg)
 192     {
 193         m_fprs.lock(reg);
 194     }
 195     void unlock(GPRReg reg)
 196     {
 197         m_gprs.unlock(reg);
 198     }
 199     void unlock(FPRReg reg)
 200     {
 201         m_fprs.unlock(reg);
 202     }
 203 
 204     // Used to check whether a child node is on its last use,
 205     // and its machine registers may be reused.
 206     bool canReuse(Node* node)
 207     {
 208         return generationInfo(node).useCount() == 1;
 209     }
 210     bool canReuse(Node* nodeA, Node* nodeB)
 211     {
 212         return nodeA == nodeB &amp;&amp; generationInfo(nodeA).useCount() == 2;
 213     }
 214     bool canReuse(Edge nodeUse)
 215     {
 216         return canReuse(nodeUse.node());
 217     }
 218     GPRReg reuse(GPRReg reg)
 219     {
 220         m_gprs.lock(reg);
 221         return reg;
 222     }
 223     FPRReg reuse(FPRReg reg)
 224     {
 225         m_fprs.lock(reg);
 226         return reg;
 227     }
 228 
 229     // Allocate a gpr/fpr.
 230     GPRReg allocate()
 231     {
 232 #if ENABLE(DFG_REGISTER_ALLOCATION_VALIDATION)
 233         m_jit.addRegisterAllocationAtOffset(m_jit.debugOffset());
 234 #endif
 235         VirtualRegister spillMe;
 236         GPRReg gpr = m_gprs.allocate(spillMe);
 237         if (spillMe.isValid()) {
 238 #if USE(JSVALUE32_64)
 239             GenerationInfo&amp; info = generationInfoFromVirtualRegister(spillMe);
 240             if ((info.registerFormat() &amp; DataFormatJS))
 241                 m_gprs.release(info.tagGPR() == gpr ? info.payloadGPR() : info.tagGPR());
 242 #endif
 243             spill(spillMe);
 244         }
 245         return gpr;
 246     }
 247     GPRReg allocate(GPRReg specific)
 248     {
 249 #if ENABLE(DFG_REGISTER_ALLOCATION_VALIDATION)
 250         m_jit.addRegisterAllocationAtOffset(m_jit.debugOffset());
 251 #endif
 252         VirtualRegister spillMe = m_gprs.allocateSpecific(specific);
 253         if (spillMe.isValid()) {
 254 #if USE(JSVALUE32_64)
 255             GenerationInfo&amp; info = generationInfoFromVirtualRegister(spillMe);
 256             RELEASE_ASSERT(info.registerFormat() != DataFormatJSDouble);
 257             if ((info.registerFormat() &amp; DataFormatJS))
 258                 m_gprs.release(info.tagGPR() == specific ? info.payloadGPR() : info.tagGPR());
 259 #endif
 260             spill(spillMe);
 261         }
 262         return specific;
 263     }
 264     GPRReg tryAllocate()
 265     {
 266         return m_gprs.tryAllocate();
 267     }
 268     FPRReg fprAllocate()
 269     {
 270 #if ENABLE(DFG_REGISTER_ALLOCATION_VALIDATION)
 271         m_jit.addRegisterAllocationAtOffset(m_jit.debugOffset());
 272 #endif
 273         VirtualRegister spillMe;
 274         FPRReg fpr = m_fprs.allocate(spillMe);
 275         if (spillMe.isValid())
 276             spill(spillMe);
 277         return fpr;
 278     }
 279 
 280     // Check whether a VirtualRegsiter is currently in a machine register.
 281     // We use this when filling operands to fill those that are already in
 282     // machine registers first (by locking VirtualRegsiters that are already
 283     // in machine register before filling those that are not we attempt to
 284     // avoid spilling values we will need immediately).
 285     bool isFilled(Node* node)
 286     {
 287         return generationInfo(node).registerFormat() != DataFormatNone;
 288     }
 289     bool isFilledDouble(Node* node)
 290     {
 291         return generationInfo(node).registerFormat() == DataFormatDouble;
 292     }
 293 
 294     // Called on an operand once it has been consumed by a parent node.
 295     void use(Node* node)
 296     {
 297         if (!node-&gt;hasResult())
 298             return;
 299         GenerationInfo&amp; info = generationInfo(node);
 300 
 301         // use() returns true when the value becomes dead, and any
 302         // associated resources may be freed.
 303         if (!info.use(*m_stream))
 304             return;
 305 
 306         // Release the associated machine registers.
 307         DataFormat registerFormat = info.registerFormat();
 308 #if USE(JSVALUE64)
 309         if (registerFormat == DataFormatDouble)
 310             m_fprs.release(info.fpr());
 311         else if (registerFormat != DataFormatNone)
 312             m_gprs.release(info.gpr());
 313 #elif USE(JSVALUE32_64)
 314         if (registerFormat == DataFormatDouble)
 315             m_fprs.release(info.fpr());
 316         else if (registerFormat &amp; DataFormatJS) {
 317             m_gprs.release(info.tagGPR());
 318             m_gprs.release(info.payloadGPR());
 319         } else if (registerFormat != DataFormatNone)
 320             m_gprs.release(info.gpr());
 321 #endif
 322     }
 323     void use(Edge nodeUse)
 324     {
 325         use(nodeUse.node());
 326     }
 327 
 328     RegisterSet usedRegisters();
 329 
 330     bool masqueradesAsUndefinedWatchpointIsStillValid(const CodeOrigin&amp; codeOrigin)
 331     {
 332         return m_jit.graph().masqueradesAsUndefinedWatchpointIsStillValid(codeOrigin);
 333     }
 334     bool masqueradesAsUndefinedWatchpointIsStillValid()
 335     {
 336         return masqueradesAsUndefinedWatchpointIsStillValid(m_currentNode-&gt;origin.semantic);
 337     }
 338 
 339     void compileStoreBarrier(Node*);
 340 
 341     // Called by the speculative operand types, below, to fill operand to
 342     // machine registers, implicitly generating speculation checks as needed.
 343     GPRReg fillSpeculateInt32(Edge, DataFormat&amp; returnFormat);
 344     GPRReg fillSpeculateInt32Strict(Edge);
 345     GPRReg fillSpeculateInt52(Edge, DataFormat desiredFormat);
 346     FPRReg fillSpeculateDouble(Edge);
 347     GPRReg fillSpeculateCell(Edge);
 348     GPRReg fillSpeculateBoolean(Edge);
 349     GeneratedOperandType checkGeneratedTypeForToInt32(Node*);
 350 
 351     void addSlowPathGenerator(std::unique_ptr&lt;SlowPathGenerator&gt;);
 352     void addSlowPathGeneratorLambda(Function&lt;void()&gt;&amp;&amp;);
 353     void runSlowPathGenerators(PCToCodeOriginMapBuilder&amp;);
 354 
 355     void compile(Node*);
 356     void noticeOSRBirth(Node*);
 357     void bail(AbortReason);
 358     void compileCurrentBlock();
 359 
 360     void checkArgumentTypes();
 361 
 362     void clearGenerationInfo();
 363 
 364     // These methods are used when generating &#39;unexpected&#39;
 365     // calls out from JIT code to C++ helper routines -
 366     // they spill all live values to the appropriate
 367     // slots in the JSStack without changing any state
 368     // in the GenerationInfo.
 369     SilentRegisterSavePlan silentSavePlanForGPR(VirtualRegister spillMe, GPRReg source);
 370     SilentRegisterSavePlan silentSavePlanForFPR(VirtualRegister spillMe, FPRReg source);
 371     void silentSpill(const SilentRegisterSavePlan&amp;);
 372     void silentFill(const SilentRegisterSavePlan&amp;);
 373 
 374     template&lt;typename CollectionType&gt;
 375     void silentSpill(const CollectionType&amp; savePlans)
 376     {
 377         for (unsigned i = 0; i &lt; savePlans.size(); ++i)
 378             silentSpill(savePlans[i]);
 379     }
 380 
 381     template&lt;typename CollectionType&gt;
 382     void silentFill(const CollectionType&amp; savePlans)
 383     {
 384         for (unsigned i = savePlans.size(); i--;)
 385             silentFill(savePlans[i]);
 386     }
 387 
 388     template&lt;typename CollectionType&gt;
 389     void silentSpillAllRegistersImpl(bool doSpill, CollectionType&amp; plans, GPRReg exclude, GPRReg exclude2 = InvalidGPRReg, FPRReg fprExclude = InvalidFPRReg)
 390     {
 391         ASSERT(plans.isEmpty());
 392         for (gpr_iterator iter = m_gprs.begin(); iter != m_gprs.end(); ++iter) {
 393             GPRReg gpr = iter.regID();
 394             if (iter.name().isValid() &amp;&amp; gpr != exclude &amp;&amp; gpr != exclude2) {
 395                 SilentRegisterSavePlan plan = silentSavePlanForGPR(iter.name(), gpr);
 396                 if (doSpill)
 397                     silentSpill(plan);
 398                 plans.append(plan);
 399             }
 400         }
 401         for (fpr_iterator iter = m_fprs.begin(); iter != m_fprs.end(); ++iter) {
 402             if (iter.name().isValid() &amp;&amp; iter.regID() != fprExclude) {
 403                 SilentRegisterSavePlan plan = silentSavePlanForFPR(iter.name(), iter.regID());
 404                 if (doSpill)
 405                     silentSpill(plan);
 406                 plans.append(plan);
 407             }
 408         }
 409     }
 410     template&lt;typename CollectionType&gt;
 411     void silentSpillAllRegistersImpl(bool doSpill, CollectionType&amp; plans, NoResultTag)
 412     {
 413         silentSpillAllRegistersImpl(doSpill, plans, InvalidGPRReg, InvalidGPRReg, InvalidFPRReg);
 414     }
 415     template&lt;typename CollectionType&gt;
 416     void silentSpillAllRegistersImpl(bool doSpill, CollectionType&amp; plans, FPRReg exclude)
 417     {
 418         silentSpillAllRegistersImpl(doSpill, plans, InvalidGPRReg, InvalidGPRReg, exclude);
 419     }
 420     template&lt;typename CollectionType&gt;
 421     void silentSpillAllRegistersImpl(bool doSpill, CollectionType&amp; plans, JSValueRegs exclude)
 422     {
 423 #if USE(JSVALUE32_64)
 424         silentSpillAllRegistersImpl(doSpill, plans, exclude.tagGPR(), exclude.payloadGPR());
 425 #else
 426         silentSpillAllRegistersImpl(doSpill, plans, exclude.gpr());
 427 #endif
 428     }
 429 
 430     void silentSpillAllRegisters(GPRReg exclude, GPRReg exclude2 = InvalidGPRReg, FPRReg fprExclude = InvalidFPRReg)
 431     {
 432         silentSpillAllRegistersImpl(true, m_plans, exclude, exclude2, fprExclude);
 433     }
 434     void silentSpillAllRegisters(FPRReg exclude)
 435     {
 436         silentSpillAllRegisters(InvalidGPRReg, InvalidGPRReg, exclude);
 437     }
 438     void silentSpillAllRegisters(JSValueRegs exclude)
 439     {
 440 #if USE(JSVALUE64)
 441         silentSpillAllRegisters(exclude.payloadGPR());
 442 #else
 443         silentSpillAllRegisters(exclude.payloadGPR(), exclude.tagGPR());
 444 #endif
 445     }
 446 
 447     void silentFillAllRegisters()
 448     {
 449         while (!m_plans.isEmpty()) {
 450             SilentRegisterSavePlan&amp; plan = m_plans.last();
 451             silentFill(plan);
 452             m_plans.removeLast();
 453         }
 454     }
 455 
 456     // These methods convert between doubles, and doubles boxed and JSValues.
 457 #if USE(JSVALUE64)
 458     GPRReg boxDouble(FPRReg fpr, GPRReg gpr)
 459     {
 460         return m_jit.boxDouble(fpr, gpr);
 461     }
 462     FPRReg unboxDouble(GPRReg gpr, GPRReg resultGPR, FPRReg fpr)
 463     {
 464         return m_jit.unboxDouble(gpr, resultGPR, fpr);
 465     }
 466     GPRReg boxDouble(FPRReg fpr)
 467     {
 468         return boxDouble(fpr, allocate());
 469     }
 470 
 471     void boxInt52(GPRReg sourceGPR, GPRReg targetGPR, DataFormat);
 472 #elif USE(JSVALUE32_64)
 473     void boxDouble(FPRReg fpr, GPRReg tagGPR, GPRReg payloadGPR)
 474     {
 475         m_jit.boxDouble(fpr, tagGPR, payloadGPR);
 476     }
 477     void unboxDouble(GPRReg tagGPR, GPRReg payloadGPR, FPRReg fpr, FPRReg scratchFPR)
 478     {
 479         m_jit.unboxDouble(tagGPR, payloadGPR, fpr, scratchFPR);
 480     }
 481 #endif
 482     void boxDouble(FPRReg fpr, JSValueRegs regs)
 483     {
 484         m_jit.boxDouble(fpr, regs);
 485     }
 486 
 487     // Spill a VirtualRegister to the JSStack.
 488     void spill(VirtualRegister spillMe)
 489     {
 490         GenerationInfo&amp; info = generationInfoFromVirtualRegister(spillMe);
 491 
 492 #if USE(JSVALUE32_64)
 493         if (info.registerFormat() == DataFormatNone) // it has been spilled. JS values which have two GPRs can reach here
 494             return;
 495 #endif
 496         // Check the GenerationInfo to see if this value need writing
 497         // to the JSStack - if not, mark it as spilled &amp; return.
 498         if (!info.needsSpill()) {
 499             info.setSpilled(*m_stream, spillMe);
 500             return;
 501         }
 502 
 503         DataFormat spillFormat = info.registerFormat();
 504         switch (spillFormat) {
 505         case DataFormatStorage: {
 506             // This is special, since it&#39;s not a JS value - as in it&#39;s not visible to JS
 507             // code.
 508             m_jit.storePtr(info.gpr(), JITCompiler::addressFor(spillMe));
 509             info.spill(*m_stream, spillMe, DataFormatStorage);
 510             return;
 511         }
 512 
 513         case DataFormatInt32: {
 514             m_jit.store32(info.gpr(), JITCompiler::payloadFor(spillMe));
 515             info.spill(*m_stream, spillMe, DataFormatInt32);
 516             return;
 517         }
 518 
 519 #if USE(JSVALUE64)
 520         case DataFormatDouble: {
 521             m_jit.storeDouble(info.fpr(), JITCompiler::addressFor(spillMe));
 522             info.spill(*m_stream, spillMe, DataFormatDouble);
 523             return;
 524         }
 525 
 526         case DataFormatInt52:
 527         case DataFormatStrictInt52: {
 528             m_jit.store64(info.gpr(), JITCompiler::addressFor(spillMe));
 529             info.spill(*m_stream, spillMe, spillFormat);
 530             return;
 531         }
 532 
 533         default:
 534             // The following code handles JSValues, int32s, and cells.
 535             RELEASE_ASSERT(spillFormat == DataFormatCell || spillFormat &amp; DataFormatJS);
 536 
 537             GPRReg reg = info.gpr();
 538             // We need to box int32 and cell values ...
 539             // but on JSVALUE64 boxing a cell is a no-op!
 540             if (spillFormat == DataFormatInt32)
 541                 m_jit.or64(GPRInfo::tagTypeNumberRegister, reg);
 542 
 543             // Spill the value, and record it as spilled in its boxed form.
 544             m_jit.store64(reg, JITCompiler::addressFor(spillMe));
 545             info.spill(*m_stream, spillMe, (DataFormat)(spillFormat | DataFormatJS));
 546             return;
 547 #elif USE(JSVALUE32_64)
 548         case DataFormatCell:
 549         case DataFormatBoolean: {
 550             m_jit.store32(info.gpr(), JITCompiler::payloadFor(spillMe));
 551             info.spill(*m_stream, spillMe, spillFormat);
 552             return;
 553         }
 554 
 555         case DataFormatDouble: {
 556             // On JSVALUE32_64 boxing a double is a no-op.
 557             m_jit.storeDouble(info.fpr(), JITCompiler::addressFor(spillMe));
 558             info.spill(*m_stream, spillMe, DataFormatDouble);
 559             return;
 560         }
 561 
 562         default:
 563             // The following code handles JSValues.
 564             RELEASE_ASSERT(spillFormat &amp; DataFormatJS);
 565             m_jit.store32(info.tagGPR(), JITCompiler::tagFor(spillMe));
 566             m_jit.store32(info.payloadGPR(), JITCompiler::payloadFor(spillMe));
 567             info.spill(*m_stream, spillMe, spillFormat);
 568             return;
 569 #endif
 570         }
 571     }
 572 
 573     bool isKnownInteger(Node* node) { return m_state.forNode(node).isType(SpecInt32Only); }
 574     bool isKnownCell(Node* node) { return m_state.forNode(node).isType(SpecCell); }
 575 
 576     bool isKnownNotInteger(Node* node) { return !(m_state.forNode(node).m_type &amp; SpecInt32Only); }
 577     bool isKnownNotNumber(Node* node) { return !(m_state.forNode(node).m_type &amp; SpecFullNumber); }
 578     bool isKnownNotCell(Node* node) { return !(m_state.forNode(node).m_type &amp; SpecCell); }
 579     bool isKnownNotOther(Node* node) { return !(m_state.forNode(node).m_type &amp; SpecOther); }
 580 
<a name="2" id="anc2"></a><span class="line-added"> 581     bool canBeRope(Edge&amp;);</span>
<span class="line-added"> 582 </span>
 583     UniquedStringImpl* identifierUID(unsigned index)
 584     {
 585         return m_jit.graph().identifiers()[index];
 586     }
 587 
 588     // Spill all VirtualRegisters back to the JSStack.
 589     void flushRegisters()
 590     {
 591         for (gpr_iterator iter = m_gprs.begin(); iter != m_gprs.end(); ++iter) {
 592             if (iter.name().isValid()) {
 593                 spill(iter.name());
 594                 iter.release();
 595             }
 596         }
 597         for (fpr_iterator iter = m_fprs.begin(); iter != m_fprs.end(); ++iter) {
 598             if (iter.name().isValid()) {
 599                 spill(iter.name());
 600                 iter.release();
 601             }
 602         }
 603     }
 604 
 605     // Used to ASSERT flushRegisters() has been called prior to
 606     // calling out from JIT code to a C helper function.
 607     bool isFlushed()
 608     {
 609         for (gpr_iterator iter = m_gprs.begin(); iter != m_gprs.end(); ++iter) {
 610             if (iter.name().isValid())
 611                 return false;
 612         }
 613         for (fpr_iterator iter = m_fprs.begin(); iter != m_fprs.end(); ++iter) {
 614             if (iter.name().isValid())
 615                 return false;
 616         }
 617         return true;
 618     }
 619 
 620 #if USE(JSVALUE64)
 621     static MacroAssembler::Imm64 valueOfJSConstantAsImm64(Node* node)
 622     {
 623         return MacroAssembler::Imm64(JSValue::encode(node-&gt;asJSValue()));
 624     }
 625 #endif
 626 
 627     // Helper functions to enable code sharing in implementations of bit/shift ops.
 628     void bitOp(NodeType op, int32_t imm, GPRReg op1, GPRReg result)
 629     {
 630         switch (op) {
 631         case ArithBitAnd:
 632             m_jit.and32(Imm32(imm), op1, result);
 633             break;
 634         case ArithBitOr:
 635             m_jit.or32(Imm32(imm), op1, result);
 636             break;
 637         case ArithBitXor:
 638             m_jit.xor32(Imm32(imm), op1, result);
 639             break;
 640         default:
 641             RELEASE_ASSERT_NOT_REACHED();
 642         }
 643     }
 644     void bitOp(NodeType op, GPRReg op1, GPRReg op2, GPRReg result)
 645     {
 646         switch (op) {
 647         case ArithBitAnd:
 648             m_jit.and32(op1, op2, result);
 649             break;
 650         case ArithBitOr:
 651             m_jit.or32(op1, op2, result);
 652             break;
 653         case ArithBitXor:
 654             m_jit.xor32(op1, op2, result);
 655             break;
 656         default:
 657             RELEASE_ASSERT_NOT_REACHED();
 658         }
 659     }
 660     void shiftOp(NodeType op, GPRReg op1, int32_t shiftAmount, GPRReg result)
 661     {
 662         switch (op) {
 663         case BitRShift:
 664             m_jit.rshift32(op1, Imm32(shiftAmount), result);
 665             break;
<a name="3" id="anc3"></a><span class="line-modified"> 666         case ArithBitLShift:</span>
 667             m_jit.lshift32(op1, Imm32(shiftAmount), result);
 668             break;
 669         case BitURShift:
 670             m_jit.urshift32(op1, Imm32(shiftAmount), result);
 671             break;
 672         default:
 673             RELEASE_ASSERT_NOT_REACHED();
 674         }
 675     }
 676     void shiftOp(NodeType op, GPRReg op1, GPRReg shiftAmount, GPRReg result)
 677     {
 678         switch (op) {
 679         case BitRShift:
 680             m_jit.rshift32(op1, shiftAmount, result);
 681             break;
<a name="4" id="anc4"></a><span class="line-modified"> 682         case ArithBitLShift:</span>
 683             m_jit.lshift32(op1, shiftAmount, result);
 684             break;
 685         case BitURShift:
 686             m_jit.urshift32(op1, shiftAmount, result);
 687             break;
 688         default:
 689             RELEASE_ASSERT_NOT_REACHED();
 690         }
 691     }
 692 
 693     // Returns the index of the branch node if peephole is okay, UINT_MAX otherwise.
 694     unsigned detectPeepHoleBranch()
 695     {
 696         // Check that no intervening nodes will be generated.
 697         for (unsigned index = m_indexInBlock + 1; index &lt; m_block-&gt;size() - 1; ++index) {
 698             Node* node = m_block-&gt;at(index);
 699             if (!node-&gt;shouldGenerate())
 700                 continue;
 701             // Check if it&#39;s a Phantom that can be safely ignored.
 702             if (node-&gt;op() == Phantom &amp;&amp; !node-&gt;child1())
 703                 continue;
 704             return UINT_MAX;
 705         }
 706 
 707         // Check if the lastNode is a branch on this node.
 708         Node* lastNode = m_block-&gt;terminal();
 709         return lastNode-&gt;op() == Branch &amp;&amp; lastNode-&gt;child1() == m_currentNode ? m_block-&gt;size() - 1 : UINT_MAX;
 710     }
 711 
 712     void compileCheckTraps(Node*);
 713 
 714     void compileMovHint(Node*);
 715     void compileMovHintAndCheck(Node*);
 716 
 717     void cachedGetById(CodeOrigin, JSValueRegs base, JSValueRegs result, unsigned identifierNumber, JITCompiler::Jump slowPathTarget, SpillRegistersMode, AccessType);
 718     void cachedPutById(CodeOrigin, GPRReg baseGPR, JSValueRegs valueRegs, GPRReg scratchGPR, unsigned identifierNumber, PutKind, JITCompiler::Jump slowPathTarget = JITCompiler::Jump(), SpillRegistersMode = NeedToSpill);
 719 
 720 #if USE(JSVALUE64)
 721     void cachedGetById(CodeOrigin, GPRReg baseGPR, GPRReg resultGPR, unsigned identifierNumber, JITCompiler::Jump slowPathTarget, SpillRegistersMode, AccessType);
 722     void cachedGetByIdWithThis(CodeOrigin, GPRReg baseGPR, GPRReg thisGPR, GPRReg resultGPR, unsigned identifierNumber, const JITCompiler::JumpList&amp; slowPathTarget = JITCompiler::JumpList());
 723 #elif USE(JSVALUE32_64)
 724     void cachedGetById(CodeOrigin, GPRReg baseTagGPROrNone, GPRReg basePayloadGPR, GPRReg resultTagGPR, GPRReg resultPayloadGPR, unsigned identifierNumber, JITCompiler::Jump slowPathTarget, SpillRegistersMode, AccessType);
 725     void cachedGetByIdWithThis(CodeOrigin, GPRReg baseTagGPROrNone, GPRReg basePayloadGPR, GPRReg thisTagGPROrNone, GPRReg thisPayloadGPR, GPRReg resultTagGPR, GPRReg resultPayloadGPR, unsigned identifierNumber, const JITCompiler::JumpList&amp; slowPathTarget = JITCompiler::JumpList());
 726 #endif
 727 
 728     void compileDeleteById(Node*);
 729     void compileDeleteByVal(Node*);
 730     void compilePushWithScope(Node*);
 731     void compileGetById(Node*, AccessType);
 732     void compileGetByIdFlush(Node*, AccessType);
 733     void compileInById(Node*);
 734     void compileInByVal(Node*);
 735 
 736     void nonSpeculativeNonPeepholeCompareNullOrUndefined(Edge operand);
 737     void nonSpeculativePeepholeBranchNullOrUndefined(Edge operand, Node* branchNode);
 738 
 739     void nonSpeculativePeepholeBranch(Node*, Node* branchNode, MacroAssembler::RelationalCondition, S_JITOperation_EJJ helperFunction);
 740     void nonSpeculativeNonPeepholeCompare(Node*, MacroAssembler::RelationalCondition, S_JITOperation_EJJ helperFunction);
 741 
 742     void nonSpeculativePeepholeStrictEq(Node*, Node* branchNode, bool invert = false);
 743     void nonSpeculativeNonPeepholeStrictEq(Node*, bool invert = false);
 744     bool nonSpeculativeStrictEq(Node*, bool invert = false);
 745 
 746     void compileInstanceOfForCells(Node*, JSValueRegs valueGPR, JSValueRegs prototypeGPR, GPRReg resultGPT, GPRReg scratchGPR, GPRReg scratch2GPR, JITCompiler::Jump slowCase = JITCompiler::Jump());
 747     void compileInstanceOf(Node*);
 748     void compileInstanceOfCustom(Node*);
 749     void compileOverridesHasInstance(Node*);
 750 
 751     void compileIsCellWithType(Node*);
 752     void compileIsTypedArrayView(Node*);
 753 
 754     void emitCall(Node*);
 755 
 756     void emitAllocateButterfly(GPRReg storageGPR, GPRReg sizeGPR, GPRReg scratch1, GPRReg scratch2, GPRReg scratch3, MacroAssembler::JumpList&amp; slowCases);
 757     void emitInitializeButterfly(GPRReg storageGPR, GPRReg sizeGPR, JSValueRegs emptyValueRegs, GPRReg scratchGPR);
 758     void compileAllocateNewArrayWithSize(JSGlobalObject*, GPRReg resultGPR, GPRReg sizeGPR, IndexingType, bool shouldConvertLargeSizeToArrayStorage = true);
 759 
 760     // Called once a node has completed code generation but prior to setting
 761     // its result, to free up its children. (This must happen prior to setting
 762     // the nodes result, since the node may have the same VirtualRegister as
 763     // a child, and as such will use the same GeneratioInfo).
 764     void useChildren(Node*);
 765 
 766     // These method called to initialize the GenerationInfo
 767     // to describe the result of an operation.
 768     void int32Result(GPRReg reg, Node* node, DataFormat format = DataFormatInt32, UseChildrenMode mode = CallUseChildren)
 769     {
 770         if (mode == CallUseChildren)
 771             useChildren(node);
 772 
 773         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 774         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 775 
 776         if (format == DataFormatInt32) {
 777             m_jit.jitAssertIsInt32(reg);
 778             m_gprs.retain(reg, virtualRegister, SpillOrderInteger);
 779             info.initInt32(node, node-&gt;refCount(), reg);
 780         } else {
 781 #if USE(JSVALUE64)
 782             RELEASE_ASSERT(format == DataFormatJSInt32);
 783             m_jit.jitAssertIsJSInt32(reg);
 784             m_gprs.retain(reg, virtualRegister, SpillOrderJS);
 785             info.initJSValue(node, node-&gt;refCount(), reg, format);
 786 #elif USE(JSVALUE32_64)
 787             RELEASE_ASSERT_NOT_REACHED();
 788 #endif
 789         }
 790     }
 791     void int32Result(GPRReg reg, Node* node, UseChildrenMode mode)
 792     {
 793         int32Result(reg, node, DataFormatInt32, mode);
 794     }
 795     void int52Result(GPRReg reg, Node* node, DataFormat format, UseChildrenMode mode = CallUseChildren)
 796     {
 797         if (mode == CallUseChildren)
 798             useChildren(node);
 799 
 800         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 801         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 802 
 803         m_gprs.retain(reg, virtualRegister, SpillOrderJS);
 804         info.initInt52(node, node-&gt;refCount(), reg, format);
 805     }
 806     void int52Result(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 807     {
 808         int52Result(reg, node, DataFormatInt52, mode);
 809     }
 810     void strictInt52Result(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 811     {
 812         int52Result(reg, node, DataFormatStrictInt52, mode);
 813     }
 814     void noResult(Node* node, UseChildrenMode mode = CallUseChildren)
 815     {
 816         if (mode == UseChildrenCalledExplicitly)
 817             return;
 818         useChildren(node);
 819     }
 820     void cellResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 821     {
 822         if (mode == CallUseChildren)
 823             useChildren(node);
 824 
 825         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 826         m_gprs.retain(reg, virtualRegister, SpillOrderCell);
 827         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 828         info.initCell(node, node-&gt;refCount(), reg);
 829     }
 830     void blessedBooleanResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 831     {
 832 #if USE(JSVALUE64)
 833         jsValueResult(reg, node, DataFormatJSBoolean, mode);
 834 #else
 835         booleanResult(reg, node, mode);
 836 #endif
 837     }
 838     void unblessedBooleanResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 839     {
 840 #if USE(JSVALUE64)
 841         blessBoolean(reg);
 842 #endif
 843         blessedBooleanResult(reg, node, mode);
 844     }
 845 #if USE(JSVALUE64)
 846     void jsValueResult(GPRReg reg, Node* node, DataFormat format = DataFormatJS, UseChildrenMode mode = CallUseChildren)
 847     {
 848         if (format == DataFormatJSInt32)
 849             m_jit.jitAssertIsJSInt32(reg);
 850 
 851         if (mode == CallUseChildren)
 852             useChildren(node);
 853 
 854         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 855         m_gprs.retain(reg, virtualRegister, SpillOrderJS);
 856         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 857         info.initJSValue(node, node-&gt;refCount(), reg, format);
 858     }
 859     void jsValueResult(GPRReg reg, Node* node, UseChildrenMode mode)
 860     {
 861         jsValueResult(reg, node, DataFormatJS, mode);
 862     }
 863 #elif USE(JSVALUE32_64)
 864     void booleanResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 865     {
 866         if (mode == CallUseChildren)
 867             useChildren(node);
 868 
 869         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 870         m_gprs.retain(reg, virtualRegister, SpillOrderBoolean);
 871         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 872         info.initBoolean(node, node-&gt;refCount(), reg);
 873     }
 874     void jsValueResult(GPRReg tag, GPRReg payload, Node* node, DataFormat format = DataFormatJS, UseChildrenMode mode = CallUseChildren)
 875     {
 876         if (mode == CallUseChildren)
 877             useChildren(node);
 878 
 879         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 880         m_gprs.retain(tag, virtualRegister, SpillOrderJS);
 881         m_gprs.retain(payload, virtualRegister, SpillOrderJS);
 882         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 883         info.initJSValue(node, node-&gt;refCount(), tag, payload, format);
 884     }
 885     void jsValueResult(GPRReg tag, GPRReg payload, Node* node, UseChildrenMode mode)
 886     {
 887         jsValueResult(tag, payload, node, DataFormatJS, mode);
 888     }
 889 #endif
 890     void jsValueResult(JSValueRegs regs, Node* node, DataFormat format = DataFormatJS, UseChildrenMode mode = CallUseChildren)
 891     {
 892 #if USE(JSVALUE64)
 893         jsValueResult(regs.gpr(), node, format, mode);
 894 #else
 895         jsValueResult(regs.tagGPR(), regs.payloadGPR(), node, format, mode);
 896 #endif
 897     }
 898     void storageResult(GPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 899     {
 900         if (mode == CallUseChildren)
 901             useChildren(node);
 902 
 903         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 904         m_gprs.retain(reg, virtualRegister, SpillOrderStorage);
 905         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 906         info.initStorage(node, node-&gt;refCount(), reg);
 907     }
 908     void doubleResult(FPRReg reg, Node* node, UseChildrenMode mode = CallUseChildren)
 909     {
 910         if (mode == CallUseChildren)
 911             useChildren(node);
 912 
 913         VirtualRegister virtualRegister = node-&gt;virtualRegister();
 914         m_fprs.retain(reg, virtualRegister, SpillOrderDouble);
 915         GenerationInfo&amp; info = generationInfoFromVirtualRegister(virtualRegister);
 916         info.initDouble(node, node-&gt;refCount(), reg);
 917     }
 918     void initConstantInfo(Node* node)
 919     {
 920         ASSERT(node-&gt;hasConstant());
 921         generationInfo(node).initConstant(node, node-&gt;refCount());
 922     }
 923 
 924 #define FIRST_ARGUMENT_TYPE typename FunctionTraits&lt;OperationType&gt;::template ArgumentType&lt;0&gt;
 925 
 926     template&lt;typename OperationType, typename ResultRegType, typename... Args&gt;
 927     std::enable_if_t&lt;
 928         FunctionTraits&lt;OperationType&gt;::hasResult,
 929     JITCompiler::Call&gt;
 930     callOperation(OperationType operation, ResultRegType result, Args... args)
 931     {
 932         m_jit.setupArguments&lt;OperationType&gt;(args...);
 933         return appendCallSetResult(operation, result);
 934     }
 935 
 936     template&lt;typename OperationType, typename Arg, typename... Args&gt;
 937     std::enable_if_t&lt;
 938         !FunctionTraits&lt;OperationType&gt;::hasResult
 939         &amp;&amp; !std::is_same&lt;Arg, NoResultTag&gt;::value,
 940     JITCompiler::Call&gt;
 941     callOperation(OperationType operation, Arg arg, Args... args)
 942     {
 943         m_jit.setupArguments&lt;OperationType&gt;(arg, args...);
 944         return appendCall(operation);
 945     }
 946 
 947     template&lt;typename OperationType, typename... Args&gt;
 948     std::enable_if_t&lt;
 949         !FunctionTraits&lt;OperationType&gt;::hasResult,
 950     JITCompiler::Call&gt;
 951     callOperation(OperationType operation, NoResultTag, Args... args)
 952     {
 953         m_jit.setupArguments&lt;OperationType&gt;(args...);
 954         return appendCall(operation);
 955     }
 956 
 957     template&lt;typename OperationType&gt;
 958     std::enable_if_t&lt;
 959         !FunctionTraits&lt;OperationType&gt;::hasResult,
 960     JITCompiler::Call&gt;
 961     callOperation(OperationType operation)
 962     {
 963         m_jit.setupArguments&lt;OperationType&gt;();
 964         return appendCall(operation);
 965     }
 966 
 967 #undef FIRST_ARGUMENT_TYPE
 968 
 969     JITCompiler::Call callOperationWithCallFrameRollbackOnException(V_JITOperation_ECb operation, void* pointer)
 970     {
 971         m_jit.setupArguments&lt;V_JITOperation_ECb&gt;(TrustedImmPtr(pointer));
 972         return appendCallWithCallFrameRollbackOnException(operation);
 973     }
 974 
 975     JITCompiler::Call callOperationWithCallFrameRollbackOnException(Z_JITOperation_E operation, GPRReg result)
 976     {
 977         m_jit.setupArguments&lt;Z_JITOperation_E&gt;();
 978         return appendCallWithCallFrameRollbackOnExceptionSetResult(operation, result);
 979     }
 980 
 981 #if !defined(NDEBUG) &amp;&amp; !CPU(ARM_THUMB2) &amp;&amp; !CPU(MIPS)
 982     void prepareForExternalCall()
 983     {
 984         // We&#39;re about to call out to a &quot;native&quot; helper function. The helper
 985         // function is expected to set topCallFrame itself with the ExecState
 986         // that is passed to it.
 987         //
 988         // We explicitly trash topCallFrame here so that we&#39;ll know if some of
 989         // the helper functions are not setting topCallFrame when they should
 990         // be doing so. Note: the previous value in topcallFrame was not valid
 991         // anyway since it was not being updated by JIT&#39;ed code by design.
 992 
 993         for (unsigned i = 0; i &lt; sizeof(void*) / 4; i++)
<a name="5" id="anc5"></a><span class="line-modified"> 994             m_jit.store32(TrustedImm32(0xbadbeef), reinterpret_cast&lt;char*&gt;(&amp;vm().topCallFrame) + i * 4);</span>
 995     }
 996 #else
 997     void prepareForExternalCall() { }
 998 #endif
 999 
1000     // These methods add call instructions, optionally setting results, and optionally rolling back the call frame on an exception.
1001     JITCompiler::Call appendCall(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
1002     {
1003         prepareForExternalCall();
1004         m_jit.emitStoreCodeOrigin(m_currentNode-&gt;origin.semantic);
1005         return m_jit.appendCall(function);
1006     }
1007 
1008     JITCompiler::Call appendCallWithCallFrameRollbackOnException(const FunctionPtr&lt;CFunctionPtrTag&gt; function)
1009     {
1010         JITCompiler::Call call = appendCall(function);
1011         m_jit.exceptionCheckWithCallFrameRollback();
1012         return call;
1013     }
1014 
1015     JITCompiler::Call appendCallWithCallFrameRollbackOnExceptionSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, GPRReg result)
1016     {
1017         JITCompiler::Call call = appendCallWithCallFrameRollbackOnException(function);
1018         if ((result != InvalidGPRReg) &amp;&amp; (result != GPRInfo::returnValueGPR))
1019             m_jit.move(GPRInfo::returnValueGPR, result);
1020         return call;
1021     }
1022 
1023     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, GPRReg result)
1024     {
1025         JITCompiler::Call call = appendCall(function);
1026         if (result != InvalidGPRReg)
1027             m_jit.move(GPRInfo::returnValueGPR, result);
1028         return call;
1029     }
1030 
1031     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, GPRReg result1, GPRReg result2)
1032     {
1033         JITCompiler::Call call = appendCall(function);
1034         m_jit.setupResults(result1, result2);
1035         return call;
1036     }
1037 
1038     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, JSValueRegs resultRegs)
1039     {
1040 #if USE(JSVALUE64)
1041         return appendCallSetResult(function, resultRegs.gpr());
1042 #else
1043         return appendCallSetResult(function, resultRegs.payloadGPR(), resultRegs.tagGPR());
1044 #endif
1045     }
1046 
1047 #if CPU(X86)
1048     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, FPRReg result)
1049     {
1050         JITCompiler::Call call = appendCall(function);
1051         if (result != InvalidFPRReg) {
1052             m_jit.assembler().fstpl(0, JITCompiler::stackPointerRegister);
1053             m_jit.loadDouble(JITCompiler::stackPointerRegister, result);
1054         }
1055         return call;
1056     }
1057 #elif CPU(ARM_THUMB2) &amp;&amp; !CPU(ARM_HARDFP)
1058     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, FPRReg result)
1059     {
1060         JITCompiler::Call call = appendCall(function);
1061         if (result != InvalidFPRReg)
1062             m_jit.assembler().vmov(result, GPRInfo::returnValueGPR, GPRInfo::returnValueGPR2);
1063         return call;
1064     }
1065 #else // CPU(X86_64) || (CPU(ARM_THUMB2) &amp;&amp; CPU(ARM_HARDFP)) || CPU(ARM64) || CPU(MIPS)
1066     JITCompiler::Call appendCallSetResult(const FunctionPtr&lt;CFunctionPtrTag&gt; function, FPRReg result)
1067     {
1068         JITCompiler::Call call = appendCall(function);
1069         if (result != InvalidFPRReg)
1070             m_jit.moveDouble(FPRInfo::returnValueFPR, result);
1071         return call;
1072     }
1073 #endif
1074 
1075     void branchDouble(JITCompiler::DoubleCondition cond, FPRReg left, FPRReg right, BasicBlock* destination)
1076     {
1077         return addBranch(m_jit.branchDouble(cond, left, right), destination);
1078     }
1079 
1080     void branchDoubleNonZero(FPRReg value, FPRReg scratch, BasicBlock* destination)
1081     {
1082         return addBranch(m_jit.branchDoubleNonZero(value, scratch), destination);
1083     }
1084 
1085     template&lt;typename T, typename U&gt;
1086     void branch32(JITCompiler::RelationalCondition cond, T left, U right, BasicBlock* destination)
1087     {
1088         return addBranch(m_jit.branch32(cond, left, right), destination);
1089     }
1090 
1091     template&lt;typename T, typename U&gt;
1092     void branchTest32(JITCompiler::ResultCondition cond, T value, U mask, BasicBlock* destination)
1093     {
1094         return addBranch(m_jit.branchTest32(cond, value, mask), destination);
1095     }
1096 
1097     template&lt;typename T&gt;
1098     void branchTest32(JITCompiler::ResultCondition cond, T value, BasicBlock* destination)
1099     {
1100         return addBranch(m_jit.branchTest32(cond, value), destination);
1101     }
1102 
1103 #if USE(JSVALUE64)
1104     template&lt;typename T, typename U&gt;
1105     void branch64(JITCompiler::RelationalCondition cond, T left, U right, BasicBlock* destination)
1106     {
1107         return addBranch(m_jit.branch64(cond, left, right), destination);
1108     }
1109 #endif
1110 
1111     template&lt;typename T, typename U&gt;
1112     void branch8(JITCompiler::RelationalCondition cond, T left, U right, BasicBlock* destination)
1113     {
1114         return addBranch(m_jit.branch8(cond, left, right), destination);
1115     }
1116 
1117     template&lt;typename T, typename U&gt;
1118     void branchPtr(JITCompiler::RelationalCondition cond, T left, U right, BasicBlock* destination)
1119     {
1120         return addBranch(m_jit.branchPtr(cond, left, right), destination);
1121     }
1122 
1123     template&lt;typename T, typename U&gt;
1124     void branchTestPtr(JITCompiler::ResultCondition cond, T value, U mask, BasicBlock* destination)
1125     {
1126         return addBranch(m_jit.branchTestPtr(cond, value, mask), destination);
1127     }
1128 
1129     template&lt;typename T&gt;
1130     void branchTestPtr(JITCompiler::ResultCondition cond, T value, BasicBlock* destination)
1131     {
1132         return addBranch(m_jit.branchTestPtr(cond, value), destination);
1133     }
1134 
1135     template&lt;typename T, typename U&gt;
1136     void branchTest8(JITCompiler::ResultCondition cond, T value, U mask, BasicBlock* destination)
1137     {
1138         return addBranch(m_jit.branchTest8(cond, value, mask), destination);
1139     }
1140 
1141     template&lt;typename T&gt;
1142     void branchTest8(JITCompiler::ResultCondition cond, T value, BasicBlock* destination)
1143     {
1144         return addBranch(m_jit.branchTest8(cond, value), destination);
1145     }
1146 
1147     enum FallThroughMode {
1148         AtFallThroughPoint,
1149         ForceJump
1150     };
1151     void jump(BasicBlock* destination, FallThroughMode fallThroughMode = AtFallThroughPoint)
1152     {
1153         if (destination == nextBlock()
1154             &amp;&amp; fallThroughMode == AtFallThroughPoint)
1155             return;
1156         addBranch(m_jit.jump(), destination);
1157     }
1158 
1159     void addBranch(const MacroAssembler::Jump&amp; jump, BasicBlock* destination)
1160     {
1161         m_branches.append(BranchRecord(jump, destination));
1162     }
1163     void addBranch(const MacroAssembler::JumpList&amp; jump, BasicBlock* destination);
1164 
1165     void linkBranches();
1166 
1167     void dump(const char* label = 0);
1168 
1169     bool betterUseStrictInt52(Node* node)
1170     {
1171         return !generationInfo(node).isInt52();
1172     }
1173     bool betterUseStrictInt52(Edge edge)
1174     {
1175         return betterUseStrictInt52(edge.node());
1176     }
1177 
1178     bool compare(Node*, MacroAssembler::RelationalCondition, MacroAssembler::DoubleCondition, S_JITOperation_EJJ);
1179     void compileCompareUnsigned(Node*, MacroAssembler::RelationalCondition);
1180     bool compilePeepHoleBranch(Node*, MacroAssembler::RelationalCondition, MacroAssembler::DoubleCondition, S_JITOperation_EJJ);
1181     void compilePeepHoleInt32Branch(Node*, Node* branchNode, JITCompiler::RelationalCondition);
1182     void compilePeepHoleInt52Branch(Node*, Node* branchNode, JITCompiler::RelationalCondition);
1183     void compilePeepHoleBooleanBranch(Node*, Node* branchNode, JITCompiler::RelationalCondition);
1184     void compilePeepHoleDoubleBranch(Node*, Node* branchNode, JITCompiler::DoubleCondition);
1185     void compilePeepHoleObjectEquality(Node*, Node* branchNode);
1186     void compilePeepHoleObjectStrictEquality(Edge objectChild, Edge otherChild, Node* branchNode);
1187     void compilePeepHoleObjectToObjectOrOtherEquality(Edge leftChild, Edge rightChild, Node* branchNode);
1188     void compileObjectEquality(Node*);
1189     void compileObjectStrictEquality(Edge objectChild, Edge otherChild);
1190     void compileObjectToObjectOrOtherEquality(Edge leftChild, Edge rightChild);
1191     void compileObjectOrOtherLogicalNot(Edge value);
1192     void compileLogicalNot(Node*);
1193     void compileLogicalNotStringOrOther(Node*);
1194     void compileStringEquality(
1195         Node*, GPRReg leftGPR, GPRReg rightGPR, GPRReg lengthGPR,
1196         GPRReg leftTempGPR, GPRReg rightTempGPR, GPRReg leftTemp2GPR,
1197         GPRReg rightTemp2GPR, const JITCompiler::JumpList&amp; fastTrue,
1198         const JITCompiler::JumpList&amp; fastSlow);
1199     void compileStringEquality(Node*);
1200     void compileStringIdentEquality(Node*);
1201     void compileStringToUntypedEquality(Node*, Edge stringEdge, Edge untypedEdge);
1202     void compileStringIdentToNotStringVarEquality(Node*, Edge stringEdge, Edge notStringVarEdge);
1203     void compileStringZeroLength(Node*);
1204     void compileMiscStrictEq(Node*);
1205 
1206     void compileSymbolEquality(Node*);
1207     void compileBigIntEquality(Node*);
1208     void compilePeepHoleSymbolEquality(Node*, Node* branchNode);
1209     void compileSymbolUntypedEquality(Node*, Edge symbolEdge, Edge untypedEdge);
1210 
1211     void emitObjectOrOtherBranch(Edge value, BasicBlock* taken, BasicBlock* notTaken);
1212     void emitStringBranch(Edge value, BasicBlock* taken, BasicBlock* notTaken);
1213     void emitStringOrOtherBranch(Edge value, BasicBlock* taken, BasicBlock* notTaken);
1214     void emitBranch(Node*);
1215 
1216     struct StringSwitchCase {
1217         StringSwitchCase() { }
1218 
1219         StringSwitchCase(StringImpl* string, BasicBlock* target)
1220             : string(string)
1221             , target(target)
1222         {
1223         }
1224 
1225         bool operator&lt;(const StringSwitchCase&amp; other) const
1226         {
1227             return stringLessThan(*string, *other.string);
1228         }
1229 
1230         StringImpl* string;
1231         BasicBlock* target;
1232     };
1233 
1234     void emitSwitchIntJump(SwitchData*, GPRReg value, GPRReg scratch);
1235     void emitSwitchImm(Node*, SwitchData*);
1236     void emitSwitchCharStringJump(SwitchData*, GPRReg value, GPRReg scratch);
1237     void emitSwitchChar(Node*, SwitchData*);
1238     void emitBinarySwitchStringRecurse(
1239         SwitchData*, const Vector&lt;StringSwitchCase&gt;&amp;, unsigned numChecked,
1240         unsigned begin, unsigned end, GPRReg buffer, GPRReg length, GPRReg temp,
1241         unsigned alreadyCheckedLength, bool checkedExactLength);
1242     void emitSwitchStringOnString(SwitchData*, GPRReg string);
1243     void emitSwitchString(Node*, SwitchData*);
1244     void emitSwitch(Node*);
1245 
1246     void compileToStringOrCallStringConstructorOrStringValueOf(Node*);
1247     void compileNumberToStringWithRadix(Node*);
1248     void compileNumberToStringWithValidRadixConstant(Node*);
1249     void compileNumberToStringWithValidRadixConstant(Node*, int32_t radix);
1250     void compileNewStringObject(Node*);
1251     void compileNewSymbol(Node*);
1252 
1253     void compileNewTypedArrayWithSize(Node*);
1254 
1255     void compileInt32Compare(Node*, MacroAssembler::RelationalCondition);
1256     void compileInt52Compare(Node*, MacroAssembler::RelationalCondition);
1257     void compileBooleanCompare(Node*, MacroAssembler::RelationalCondition);
1258     void compileDoubleCompare(Node*, MacroAssembler::DoubleCondition);
1259     void compileStringCompare(Node*, MacroAssembler::RelationalCondition);
1260     void compileStringIdentCompare(Node*, MacroAssembler::RelationalCondition);
1261 
1262     bool compileStrictEq(Node*);
1263 
1264     void compileSameValue(Node*);
1265 
1266     void compileAllocatePropertyStorage(Node*);
1267     void compileReallocatePropertyStorage(Node*);
1268     void compileNukeStructureAndSetButterfly(Node*);
1269     void compileGetButterfly(Node*);
1270     void compileCallDOMGetter(Node*);
1271     void compileCallDOM(Node*);
1272     void compileCheckSubClass(Node*);
1273     void compileNormalizeMapKey(Node*);
1274     void compileGetMapBucketHead(Node*);
1275     void compileGetMapBucketNext(Node*);
1276     void compileSetAdd(Node*);
1277     void compileMapSet(Node*);
1278     void compileWeakMapGet(Node*);
1279     void compileWeakSetAdd(Node*);
1280     void compileWeakMapSet(Node*);
1281     void compileLoadKeyFromMapBucket(Node*);
1282     void compileLoadValueFromMapBucket(Node*);
1283     void compileExtractValueFromWeakMapGet(Node*);
1284     void compileGetPrototypeOf(Node*);
1285     void compileIdentity(Node*);
1286 
1287 #if USE(JSVALUE32_64)
1288     template&lt;typename BaseOperandType, typename PropertyOperandType, typename ValueOperandType, typename TagType&gt;
1289     void compileContiguousPutByVal(Node*, BaseOperandType&amp;, PropertyOperandType&amp;, ValueOperandType&amp;, GPRReg valuePayloadReg, TagType valueTag);
1290 #endif
1291     void compileDoublePutByVal(Node*, SpeculateCellOperand&amp; base, SpeculateStrictInt32Operand&amp; property);
1292     bool putByValWillNeedExtraRegister(ArrayMode arrayMode)
1293     {
1294         return arrayMode.mayStoreToHole();
1295     }
1296     GPRReg temporaryRegisterForPutByVal(GPRTemporary&amp;, ArrayMode);
1297     GPRReg temporaryRegisterForPutByVal(GPRTemporary&amp; temporary, Node* node)
1298     {
1299         return temporaryRegisterForPutByVal(temporary, node-&gt;arrayMode());
1300     }
1301 
1302     void compileGetCharCodeAt(Node*);
1303     void compileGetByValOnString(Node*);
1304     void compileFromCharCode(Node*);
1305 
1306     void compileGetByValOnDirectArguments(Node*);
1307     void compileGetByValOnScopedArguments(Node*);
1308 
1309     void compileGetScope(Node*);
1310     void compileSkipScope(Node*);
1311     void compileGetGlobalObject(Node*);
1312     void compileGetGlobalThis(Node*);
1313 
1314     void compileGetArrayLength(Node*);
1315 
1316     void compileCheckTypeInfoFlags(Node*);
1317     void compileCheckStringIdent(Node*);
1318 
1319     void compileParseInt(Node*);
1320 
1321     void compileValueRep(Node*);
1322     void compileDoubleRep(Node*);
1323 
1324     void compileValueToInt32(Node*);
1325     void compileUInt32ToNumber(Node*);
1326     void compileDoubleAsInt32(Node*);
1327 
<a name="6" id="anc6"></a><span class="line-added">1328     void compileValueBitNot(Node*);</span>
1329     void compileBitwiseNot(Node*);
1330 
1331     template&lt;typename SnippetGenerator, J_JITOperation_EJJ slowPathFunction&gt;
1332     void emitUntypedBitOp(Node*);
1333     void compileBitwiseOp(Node*);
1334     void compileValueBitwiseOp(Node*);
1335 
1336     void emitUntypedRightShiftBitOp(Node*);
<a name="7" id="anc7"></a><span class="line-added">1337     void compileValueLShiftOp(Node*);</span>
1338     void compileShiftOp(Node*);
1339 
1340     template &lt;typename Generator, typename RepatchingFunction, typename NonRepatchingFunction&gt;
1341     void compileMathIC(Node*, JITBinaryMathIC&lt;Generator&gt;*, bool needsScratchGPRReg, bool needsScratchFPRReg, RepatchingFunction, NonRepatchingFunction);
1342     template &lt;typename Generator, typename RepatchingFunction, typename NonRepatchingFunction&gt;
1343     void compileMathIC(Node*, JITUnaryMathIC&lt;Generator&gt;*, bool needsScratchGPRReg, RepatchingFunction, NonRepatchingFunction);
1344 
1345     void compileArithDoubleUnaryOp(Node*, double (*doubleFunction)(double), double (*operation)(ExecState*, EncodedJSValue));
1346     void compileValueAdd(Node*);
1347     void compileValueSub(Node*);
1348     void compileArithAdd(Node*);
1349     void compileMakeRope(Node*);
1350     void compileArithAbs(Node*);
1351     void compileArithClz32(Node*);
1352     void compileArithSub(Node*);
1353     void compileValueNegate(Node*);
1354     void compileArithNegate(Node*);
1355     void compileValueMul(Node*);
1356     void compileArithMul(Node*);
1357     void compileValueDiv(Node*);
1358     void compileArithDiv(Node*);
1359     void compileArithFRound(Node*);
<a name="8" id="anc8"></a><span class="line-added">1360     void compileValueMod(Node*);</span>
1361     void compileArithMod(Node*);
1362     void compileArithPow(Node*);
<a name="9" id="anc9"></a><span class="line-added">1363     void compileValuePow(Node*);</span>
1364     void compileArithRounding(Node*);
1365     void compileArithRandom(Node*);
1366     void compileArithUnary(Node*);
1367     void compileArithSqrt(Node*);
1368     void compileArithMinMax(Node*);
1369     void compileConstantStoragePointer(Node*);
1370     void compileGetIndexedPropertyStorage(Node*);
1371     JITCompiler::Jump jumpForTypedArrayOutOfBounds(Node*, GPRReg baseGPR, GPRReg indexGPR);
1372     JITCompiler::Jump jumpForTypedArrayIsNeuteredIfOutOfBounds(Node*, GPRReg baseGPR, JITCompiler::Jump outOfBounds);
1373     void emitTypedArrayBoundsCheck(Node*, GPRReg baseGPR, GPRReg indexGPR);
1374     void compileGetTypedArrayByteOffset(Node*);
1375     void compileGetByValOnIntTypedArray(Node*, TypedArrayType);
1376     void compilePutByValForIntTypedArray(GPRReg base, GPRReg property, Node*, TypedArrayType);
1377     void compileGetByValOnFloatTypedArray(Node*, TypedArrayType);
1378     void compilePutByValForFloatTypedArray(GPRReg base, GPRReg property, Node*, TypedArrayType);
1379     void compileGetByValForObjectWithString(Node*);
1380     void compileGetByValForObjectWithSymbol(Node*);
1381     void compilePutByValForCellWithString(Node*, Edge&amp; child1, Edge&amp; child2, Edge&amp; child3);
1382     void compilePutByValForCellWithSymbol(Node*, Edge&amp; child1, Edge&amp; child2, Edge&amp; child3);
1383     void compileGetByValWithThis(Node*);
1384     void compileGetByOffset(Node*);
1385     void compilePutByOffset(Node*);
1386     void compileMatchStructure(Node*);
1387     // If this returns false it means that we terminated speculative execution.
1388     bool getIntTypedArrayStoreOperand(
1389         GPRTemporary&amp; value,
1390         GPRReg property,
1391 #if USE(JSVALUE32_64)
1392         GPRTemporary&amp; propertyTag,
1393         GPRTemporary&amp; valueTag,
1394 #endif
1395         Edge valueUse, JITCompiler::JumpList&amp; slowPathCases, bool isClamped = false);
1396     void loadFromIntTypedArray(GPRReg storageReg, GPRReg propertyReg, GPRReg resultReg, TypedArrayType);
1397     void setIntTypedArrayLoadResult(Node*, GPRReg resultReg, TypedArrayType, bool canSpeculate = false);
1398     template &lt;typename ClassType&gt; void compileNewFunctionCommon(GPRReg, RegisteredStructure, GPRReg, GPRReg, GPRReg, MacroAssembler::JumpList&amp;, size_t, FunctionExecutable*);
1399     void compileNewFunction(Node*);
1400     void compileSetFunctionName(Node*);
1401     void compileNewRegexp(Node*);
1402     void compileForwardVarargs(Node*);
1403     void compileLoadVarargs(Node*);
1404     void compileCreateActivation(Node*);
1405     void compileCreateDirectArguments(Node*);
1406     void compileGetFromArguments(Node*);
1407     void compilePutToArguments(Node*);
1408     void compileGetArgument(Node*);
1409     void compileCreateScopedArguments(Node*);
1410     void compileCreateClonedArguments(Node*);
1411     void compileCreateRest(Node*);
1412     void compileSpread(Node*);
1413     void compileNewArray(Node*);
1414     void compileNewArrayWithSpread(Node*);
1415     void compileGetRestLength(Node*);
1416     void compileArraySlice(Node*);
1417     void compileArrayIndexOf(Node*);
1418     void compileArrayPush(Node*);
1419     void compileNotifyWrite(Node*);
1420     void compileRegExpExec(Node*);
1421     void compileRegExpExecNonGlobalOrSticky(Node*);
1422     void compileRegExpMatchFast(Node*);
1423     void compileRegExpMatchFastGlobal(Node*);
1424     void compileRegExpTest(Node*);
1425     void compileStringReplace(Node*);
1426     void compileIsObject(Node*);
1427     void compileIsObjectOrNull(Node*);
1428     void compileIsFunction(Node*);
1429     void compileTypeOf(Node*);
1430     void compileCheckCell(Node*);
1431     void compileCheckNotEmpty(Node*);
1432     void compileCheckStructure(Node*);
1433     void emitStructureCheck(Node*, GPRReg cellGPR, GPRReg tempGPR);
1434     void compilePutAccessorById(Node*);
1435     void compilePutGetterSetterById(Node*);
1436     void compilePutAccessorByVal(Node*);
1437     void compileGetRegExpObjectLastIndex(Node*);
1438     void compileSetRegExpObjectLastIndex(Node*);
1439     void compileLazyJSConstant(Node*);
1440     void compileMaterializeNewObject(Node*);
1441     void compileRecordRegExpCachedResult(Node*);
1442     void compileToObjectOrCallObjectConstructor(Node*);
1443     void compileResolveScope(Node*);
1444     void compileResolveScopeForHoistingFuncDeclInEval(Node*);
1445     void compileGetGlobalVariable(Node*);
1446     void compilePutGlobalVariable(Node*);
1447     void compileGetDynamicVar(Node*);
1448     void compilePutDynamicVar(Node*);
1449     void compileGetClosureVar(Node*);
1450     void compilePutClosureVar(Node*);
1451     void compileCompareEqPtr(Node*);
1452     void compileDefineDataProperty(Node*);
1453     void compileDefineAccessorProperty(Node*);
1454     void compileStringSlice(Node*);
1455     void compileToLowerCase(Node*);
1456     void compileThrow(Node*);
1457     void compileThrowStaticError(Node*);
1458     void compileGetEnumerableLength(Node*);
1459     void compileHasGenericProperty(Node*);
1460     void compileToIndexString(Node*);
1461     void compilePutByIdFlush(Node*);
1462     void compilePutById(Node*);
1463     void compilePutByIdDirect(Node*);
1464     void compilePutByIdWithThis(Node*);
1465     void compileHasStructureProperty(Node*);
1466     void compileGetDirectPname(Node*);
1467     void compileGetPropertyEnumerator(Node*);
1468     void compileGetEnumeratorPname(Node*);
1469     void compileGetExecutable(Node*);
1470     void compileGetGetter(Node*);
1471     void compileGetSetter(Node*);
1472     void compileGetCallee(Node*);
1473     void compileSetCallee(Node*);
1474     void compileGetArgumentCountIncludingThis(Node*);
1475     void compileSetArgumentCountIncludingThis(Node*);
1476     void compileStrCat(Node*);
1477     void compileNewArrayBuffer(Node*);
1478     void compileNewArrayWithSize(Node*);
1479     void compileNewTypedArray(Node*);
1480     void compileToThis(Node*);
1481     void compileObjectKeys(Node*);
1482     void compileObjectCreate(Node*);
1483     void compileCreateThis(Node*);
1484     void compileNewObject(Node*);
1485     void compileToPrimitive(Node*);
1486     void compileLogShadowChickenPrologue(Node*);
1487     void compileLogShadowChickenTail(Node*);
1488     void compileHasIndexedProperty(Node*);
1489     void compileExtractCatchLocal(Node*);
1490     void compileClearCatchLocals(Node*);
1491     void compileProfileType(Node*);
1492 
1493     void moveTrueTo(GPRReg);
1494     void moveFalseTo(GPRReg);
1495     void blessBoolean(GPRReg);
1496 
1497     // Allocator for a cell of a specific size.
1498     template &lt;typename StructureType&gt; // StructureType can be GPR or ImmPtr.
1499     void emitAllocateJSCell(
1500         GPRReg resultGPR, const JITAllocator&amp; allocator, GPRReg allocatorGPR, StructureType structure,
1501         GPRReg scratchGPR, MacroAssembler::JumpList&amp; slowPath)
1502     {
1503         m_jit.emitAllocateJSCell(resultGPR, allocator, allocatorGPR, structure, scratchGPR, slowPath);
1504     }
1505 
1506     // Allocator for an object of a specific size.
1507     template &lt;typename StructureType, typename StorageType&gt; // StructureType and StorageType can be GPR or ImmPtr.
1508     void emitAllocateJSObject(
1509         GPRReg resultGPR, const JITAllocator&amp; allocator, GPRReg allocatorGPR, StructureType structure,
1510         StorageType storage, GPRReg scratchGPR, MacroAssembler::JumpList&amp; slowPath)
1511     {
1512         m_jit.emitAllocateJSObject(
1513             resultGPR, allocator, allocatorGPR, structure, storage, scratchGPR, slowPath);
1514     }
1515 
1516     template &lt;typename ClassType, typename StructureType, typename StorageType&gt; // StructureType and StorageType can be GPR or ImmPtr.
1517     void emitAllocateJSObjectWithKnownSize(
1518         GPRReg resultGPR, StructureType structure, StorageType storage, GPRReg scratchGPR1,
1519         GPRReg scratchGPR2, MacroAssembler::JumpList&amp; slowPath, size_t size)
1520     {
<a name="10" id="anc10"></a><span class="line-modified">1521         m_jit.emitAllocateJSObjectWithKnownSize&lt;ClassType&gt;(vm(), resultGPR, structure, storage, scratchGPR1, scratchGPR2, slowPath, size);</span>
1522     }
1523 
1524     // Convenience allocator for a built-in object.
1525     template &lt;typename ClassType, typename StructureType, typename StorageType&gt; // StructureType and StorageType can be GPR or ImmPtr.
1526     void emitAllocateJSObject(GPRReg resultGPR, StructureType structure, StorageType storage,
1527         GPRReg scratchGPR1, GPRReg scratchGPR2, MacroAssembler::JumpList&amp; slowPath)
1528     {
<a name="11" id="anc11"></a><span class="line-modified">1529         m_jit.emitAllocateJSObject&lt;ClassType&gt;(vm(), resultGPR, structure, storage, scratchGPR1, scratchGPR2, slowPath);</span>
1530     }
1531 
1532     template &lt;typename ClassType, typename StructureType&gt; // StructureType and StorageType can be GPR or ImmPtr.
1533     void emitAllocateVariableSizedJSObject(GPRReg resultGPR, StructureType structure, GPRReg allocationSize, GPRReg scratchGPR1, GPRReg scratchGPR2, MacroAssembler::JumpList&amp; slowPath)
1534     {
<a name="12" id="anc12"></a><span class="line-modified">1535         m_jit.emitAllocateVariableSizedJSObject&lt;ClassType&gt;(vm(), resultGPR, structure, allocationSize, scratchGPR1, scratchGPR2, slowPath);</span>
1536     }
1537 
1538     template&lt;typename ClassType&gt;
1539     void emitAllocateDestructibleObject(GPRReg resultGPR, RegisteredStructure structure,
1540         GPRReg scratchGPR1, GPRReg scratchGPR2, MacroAssembler::JumpList&amp; slowPath)
1541     {
<a name="13" id="anc13"></a><span class="line-modified">1542         m_jit.emitAllocateDestructibleObject&lt;ClassType&gt;(vm(), resultGPR, structure.get(), scratchGPR1, scratchGPR2, slowPath);</span>
1543     }
1544 
1545     void emitAllocateRawObject(GPRReg resultGPR, RegisteredStructure, GPRReg storageGPR, unsigned numElements, unsigned vectorLength);
1546 
1547     void emitGetLength(InlineCallFrame*, GPRReg lengthGPR, bool includeThis = false);
1548     void emitGetLength(CodeOrigin, GPRReg lengthGPR, bool includeThis = false);
1549     void emitGetCallee(CodeOrigin, GPRReg calleeGPR);
1550     void emitGetArgumentStart(CodeOrigin, GPRReg startGPR);
1551     void emitPopulateSliceIndex(Edge&amp;, Optional&lt;GPRReg&gt; indexGPR, GPRReg lengthGPR, GPRReg resultGPR);
1552 
1553     // Generate an OSR exit fuzz check. Returns Jump() if OSR exit fuzz is not enabled, or if
1554     // it&#39;s in training mode.
1555     MacroAssembler::Jump emitOSRExitFuzzCheck();
1556 
1557     // Add a speculation check.
1558     void speculationCheck(ExitKind, JSValueSource, Node*, MacroAssembler::Jump jumpToFail);
1559     void speculationCheck(ExitKind, JSValueSource, Node*, const MacroAssembler::JumpList&amp; jumpsToFail);
1560 
1561     // Add a speculation check without additional recovery, and with a promise to supply a jump later.
1562     OSRExitJumpPlaceholder speculationCheck(ExitKind, JSValueSource, Node*);
1563     OSRExitJumpPlaceholder speculationCheck(ExitKind, JSValueSource, Edge);
1564     void speculationCheck(ExitKind, JSValueSource, Edge, MacroAssembler::Jump jumpToFail);
1565     void speculationCheck(ExitKind, JSValueSource, Edge, const MacroAssembler::JumpList&amp; jumpsToFail);
1566     // Add a speculation check with additional recovery.
1567     void speculationCheck(ExitKind, JSValueSource, Node*, MacroAssembler::Jump jumpToFail, const SpeculationRecovery&amp;);
1568     void speculationCheck(ExitKind, JSValueSource, Edge, MacroAssembler::Jump jumpToFail, const SpeculationRecovery&amp;);
1569 
1570     void emitInvalidationPoint(Node*);
1571 
1572     void unreachable(Node*);
1573 
1574     // Called when we statically determine that a speculation will fail.
1575     void terminateSpeculativeExecution(ExitKind, JSValueRegs, Node*);
1576     void terminateSpeculativeExecution(ExitKind, JSValueRegs, Edge);
1577 
1578     // Helpers for performing type checks on an edge stored in the given registers.
1579     bool needsTypeCheck(Edge edge, SpeculatedType typesPassedThrough) { return m_interpreter.needsTypeCheck(edge, typesPassedThrough); }
1580     void typeCheck(JSValueSource, Edge, SpeculatedType typesPassedThrough, MacroAssembler::Jump jumpToFail, ExitKind = BadType);
1581 
1582     void speculateCellTypeWithoutTypeFiltering(Edge, GPRReg cellGPR, JSType);
1583     void speculateCellType(Edge, GPRReg cellGPR, SpeculatedType, JSType);
1584 
1585     void speculateInt32(Edge);
1586 #if USE(JSVALUE64)
1587     void convertAnyInt(Edge, GPRReg resultGPR);
1588     void speculateAnyInt(Edge);
1589     void speculateInt32(Edge, JSValueRegs);
1590     void speculateDoubleRepAnyInt(Edge);
1591 #endif // USE(JSVALUE64)
1592     void speculateNumber(Edge);
1593     void speculateRealNumber(Edge);
1594     void speculateDoubleRepReal(Edge);
1595     void speculateBoolean(Edge);
1596     void speculateCell(Edge);
1597     void speculateCellOrOther(Edge);
1598     void speculateObject(Edge, GPRReg cell);
1599     void speculateObject(Edge);
1600     void speculateArray(Edge, GPRReg cell);
1601     void speculateArray(Edge);
1602     void speculateFunction(Edge, GPRReg cell);
1603     void speculateFunction(Edge);
1604     void speculateFinalObject(Edge, GPRReg cell);
1605     void speculateFinalObject(Edge);
1606     void speculateRegExpObject(Edge, GPRReg cell);
1607     void speculateRegExpObject(Edge);
1608     void speculateProxyObject(Edge, GPRReg cell);
1609     void speculateProxyObject(Edge);
1610     void speculateDerivedArray(Edge, GPRReg cell);
1611     void speculateDerivedArray(Edge);
1612     void speculateMapObject(Edge);
1613     void speculateMapObject(Edge, GPRReg cell);
1614     void speculateSetObject(Edge);
1615     void speculateSetObject(Edge, GPRReg cell);
1616     void speculateWeakMapObject(Edge);
1617     void speculateWeakMapObject(Edge, GPRReg cell);
1618     void speculateWeakSetObject(Edge);
1619     void speculateWeakSetObject(Edge, GPRReg cell);
1620     void speculateDataViewObject(Edge);
1621     void speculateDataViewObject(Edge, GPRReg cell);
1622     void speculateObjectOrOther(Edge);
1623     void speculateString(Edge edge, GPRReg cell);
1624     void speculateStringIdentAndLoadStorage(Edge edge, GPRReg string, GPRReg storage);
1625     void speculateStringIdent(Edge edge, GPRReg string);
1626     void speculateStringIdent(Edge);
1627     void speculateString(Edge);
1628     void speculateStringOrOther(Edge, JSValueRegs, GPRReg scratch);
1629     void speculateStringOrOther(Edge);
1630     void speculateNotStringVar(Edge);
1631     void speculateNotSymbol(Edge);
1632     void speculateStringObject(Edge, GPRReg);
1633     void speculateStringObject(Edge);
1634     void speculateStringOrStringObject(Edge);
1635     void speculateSymbol(Edge, GPRReg cell);
1636     void speculateSymbol(Edge);
1637     void speculateBigInt(Edge, GPRReg cell);
1638     void speculateBigInt(Edge);
1639     void speculateNotCell(Edge, JSValueRegs);
1640     void speculateNotCell(Edge);
1641     void speculateOther(Edge, JSValueRegs, GPRReg temp);
1642     void speculateOther(Edge, JSValueRegs);
1643     void speculateOther(Edge);
1644     void speculateMisc(Edge, JSValueRegs);
1645     void speculateMisc(Edge);
1646     void speculate(Node*, Edge);
1647 
1648     JITCompiler::JumpList jumpSlowForUnwantedArrayMode(GPRReg tempWithIndexingTypeReg, ArrayMode);
1649     void checkArray(Node*);
1650     void arrayify(Node*, GPRReg baseReg, GPRReg propertyReg);
1651     void arrayify(Node*);
1652 
1653     template&lt;bool strict&gt;
1654     GPRReg fillSpeculateInt32Internal(Edge, DataFormat&amp; returnFormat);
1655 
<a name="14" id="anc14"></a><span class="line-modified">1656     void cageTypedArrayStorage(GPRReg, GPRReg);</span>






1657 
1658     void recordSetLocal(
1659         VirtualRegister bytecodeReg, VirtualRegister machineReg, DataFormat format)
1660     {
1661         m_stream-&gt;appendAndLog(VariableEvent::setLocal(bytecodeReg, machineReg, format));
1662     }
1663 
1664     void recordSetLocal(DataFormat format)
1665     {
1666         VariableAccessData* variable = m_currentNode-&gt;variableAccessData();
1667         recordSetLocal(variable-&gt;local(), variable-&gt;machineLocal(), format);
1668     }
1669 
1670     GenerationInfo&amp; generationInfoFromVirtualRegister(VirtualRegister virtualRegister)
1671     {
1672         return m_generationInfo[virtualRegister.toLocal()];
1673     }
1674 
1675     GenerationInfo&amp; generationInfo(Node* node)
1676     {
1677         return generationInfoFromVirtualRegister(node-&gt;virtualRegister());
1678     }
1679 
1680     GenerationInfo&amp; generationInfo(Edge edge)
1681     {
1682         return generationInfo(edge.node());
1683     }
1684 
1685     // The JIT, while also provides MacroAssembler functionality.
1686     JITCompiler&amp; m_jit;
1687     Graph&amp; m_graph;
1688 
1689     // The current node being generated.
1690     BasicBlock* m_block;
1691     Node* m_currentNode;
1692     NodeType m_lastGeneratedNode;
1693     unsigned m_indexInBlock;
1694 
1695     // Virtual and physical register maps.
1696     Vector&lt;GenerationInfo, 32&gt; m_generationInfo;
1697     RegisterBank&lt;GPRInfo&gt; m_gprs;
1698     RegisterBank&lt;FPRInfo&gt; m_fprs;
1699 
<a name="15" id="anc15"></a><span class="line-added">1700     // It is possible, during speculative generation, to reach a situation in which we</span>
<span class="line-added">1701     // can statically determine a speculation will fail (for example, when two nodes</span>
<span class="line-added">1702     // will make conflicting speculations about the same operand). In such cases this</span>
<span class="line-added">1703     // flag is cleared, indicating no further code generation should take place.</span>
<span class="line-added">1704     bool m_compileOkay;</span>
<span class="line-added">1705 </span>
1706     Vector&lt;MacroAssembler::Label&gt; m_osrEntryHeads;
1707 
1708     struct BranchRecord {
1709         BranchRecord(MacroAssembler::Jump jump, BasicBlock* destination)
1710             : jump(jump)
1711             , destination(destination)
1712         {
1713         }
1714 
1715         MacroAssembler::Jump jump;
1716         BasicBlock* destination;
1717     };
1718     Vector&lt;BranchRecord, 8&gt; m_branches;
1719 
1720     NodeOrigin m_origin;
1721 
1722     InPlaceAbstractState m_state;
1723     AbstractInterpreter&lt;InPlaceAbstractState&gt; m_interpreter;
1724 
1725     VariableEventStream* m_stream;
1726     MinifiedGraph* m_minifiedGraph;
1727 
1728     Vector&lt;std::unique_ptr&lt;SlowPathGenerator&gt;, 8&gt; m_slowPathGenerators;
1729     struct SlowPathLambda {
1730         Function&lt;void()&gt; generator;
1731         Node* currentNode;
1732         unsigned streamIndex;
1733     };
1734     Vector&lt;SlowPathLambda&gt; m_slowPathLambdas;
1735     Vector&lt;SilentRegisterSavePlan&gt; m_plans;
1736     Optional&lt;unsigned&gt; m_outOfLineStreamIndex;
1737 };
1738 
1739 
1740 // === Operand types ===
1741 //
1742 // These classes are used to lock the operands to a node into machine
1743 // registers. These classes implement of pattern of locking a value
1744 // into register at the point of construction only if it is already in
1745 // registers, and otherwise loading it lazily at the point it is first
1746 // used. We do so in order to attempt to avoid spilling one operand
1747 // in order to make space available for another.
1748 
1749 class JSValueOperand {
<a name="16" id="anc16"></a><span class="line-added">1750     WTF_MAKE_FAST_ALLOCATED;</span>
1751 public:
1752     explicit JSValueOperand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
1753         : m_jit(jit)
1754         , m_edge(edge)
1755 #if USE(JSVALUE64)
1756         , m_gprOrInvalid(InvalidGPRReg)
1757 #elif USE(JSVALUE32_64)
1758         , m_isDouble(false)
1759 #endif
1760     {
1761         ASSERT(m_jit);
1762         if (!edge)
1763             return;
1764         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || edge.useKind() == UntypedUse);
1765 #if USE(JSVALUE64)
1766         if (jit-&gt;isFilled(node()))
1767             gpr();
1768 #elif USE(JSVALUE32_64)
1769         m_register.pair.tagGPR = InvalidGPRReg;
1770         m_register.pair.payloadGPR = InvalidGPRReg;
1771         if (jit-&gt;isFilled(node()))
1772             fill();
1773 #endif
1774     }
1775 
1776     explicit JSValueOperand(JSValueOperand&amp;&amp; other)
1777         : m_jit(other.m_jit)
1778         , m_edge(other.m_edge)
1779     {
1780 #if USE(JSVALUE64)
1781         m_gprOrInvalid = other.m_gprOrInvalid;
1782 #elif USE(JSVALUE32_64)
1783         m_register.pair.tagGPR = InvalidGPRReg;
1784         m_register.pair.payloadGPR = InvalidGPRReg;
1785         m_isDouble = other.m_isDouble;
1786 
1787         if (m_edge) {
1788             if (m_isDouble)
1789                 m_register.fpr = other.m_register.fpr;
1790             else
1791                 m_register.pair = other.m_register.pair;
1792         }
1793 #endif
1794         other.m_edge = Edge();
1795 #if USE(JSVALUE64)
1796         other.m_gprOrInvalid = InvalidGPRReg;
1797 #elif USE(JSVALUE32_64)
1798         other.m_isDouble = false;
1799 #endif
1800     }
1801 
1802     ~JSValueOperand()
1803     {
1804         if (!m_edge)
1805             return;
1806 #if USE(JSVALUE64)
1807         ASSERT(m_gprOrInvalid != InvalidGPRReg);
1808         m_jit-&gt;unlock(m_gprOrInvalid);
1809 #elif USE(JSVALUE32_64)
1810         if (m_isDouble) {
1811             ASSERT(m_register.fpr != InvalidFPRReg);
1812             m_jit-&gt;unlock(m_register.fpr);
1813         } else {
1814             ASSERT(m_register.pair.tagGPR != InvalidGPRReg &amp;&amp; m_register.pair.payloadGPR != InvalidGPRReg);
1815             m_jit-&gt;unlock(m_register.pair.tagGPR);
1816             m_jit-&gt;unlock(m_register.pair.payloadGPR);
1817         }
1818 #endif
1819     }
1820 
1821     Edge edge() const
1822     {
1823         return m_edge;
1824     }
1825 
1826     Node* node() const
1827     {
1828         return edge().node();
1829     }
1830 
1831 #if USE(JSVALUE64)
1832     GPRReg gpr()
1833     {
1834         if (m_gprOrInvalid == InvalidGPRReg)
1835             m_gprOrInvalid = m_jit-&gt;fillJSValue(m_edge);
1836         return m_gprOrInvalid;
1837     }
1838     JSValueRegs jsValueRegs()
1839     {
1840         return JSValueRegs(gpr());
1841     }
1842 #elif USE(JSVALUE32_64)
1843     bool isDouble() { return m_isDouble; }
1844 
1845     void fill()
1846     {
1847         if (m_register.pair.tagGPR == InvalidGPRReg &amp;&amp; m_register.pair.payloadGPR == InvalidGPRReg)
1848             m_isDouble = !m_jit-&gt;fillJSValue(m_edge, m_register.pair.tagGPR, m_register.pair.payloadGPR, m_register.fpr);
1849     }
1850 
1851     GPRReg tagGPR()
1852     {
1853         fill();
1854         ASSERT(!m_isDouble);
1855         return m_register.pair.tagGPR;
1856     }
1857 
1858     GPRReg payloadGPR()
1859     {
1860         fill();
1861         ASSERT(!m_isDouble);
1862         return m_register.pair.payloadGPR;
1863     }
1864 
1865     JSValueRegs jsValueRegs()
1866     {
1867         return JSValueRegs(tagGPR(), payloadGPR());
1868     }
1869 
1870     GPRReg gpr(WhichValueWord which)
1871     {
1872         return jsValueRegs().gpr(which);
1873     }
1874 
1875     FPRReg fpr()
1876     {
1877         fill();
1878         ASSERT(m_isDouble);
1879         return m_register.fpr;
1880     }
1881 #endif
1882 
1883     void use()
1884     {
1885         m_jit-&gt;use(node());
1886     }
1887 
1888 private:
1889     SpeculativeJIT* m_jit;
1890     Edge m_edge;
1891 #if USE(JSVALUE64)
1892     GPRReg m_gprOrInvalid;
1893 #elif USE(JSVALUE32_64)
1894     union {
1895         struct {
1896             GPRReg tagGPR;
1897             GPRReg payloadGPR;
1898         } pair;
1899         FPRReg fpr;
1900     } m_register;
1901     bool m_isDouble;
1902 #endif
1903 };
1904 
1905 class StorageOperand {
<a name="17" id="anc17"></a><span class="line-added">1906     WTF_MAKE_FAST_ALLOCATED;</span>
1907 public:
1908     explicit StorageOperand(SpeculativeJIT* jit, Edge edge)
1909         : m_jit(jit)
1910         , m_edge(edge)
1911         , m_gprOrInvalid(InvalidGPRReg)
1912     {
1913         ASSERT(m_jit);
1914         ASSERT(edge.useKind() == UntypedUse || edge.useKind() == KnownCellUse);
1915         if (jit-&gt;isFilled(node()))
1916             gpr();
1917     }
1918 
1919     ~StorageOperand()
1920     {
1921         ASSERT(m_gprOrInvalid != InvalidGPRReg);
1922         m_jit-&gt;unlock(m_gprOrInvalid);
1923     }
1924 
1925     Edge edge() const
1926     {
1927         return m_edge;
1928     }
1929 
1930     Node* node() const
1931     {
1932         return edge().node();
1933     }
1934 
1935     GPRReg gpr()
1936     {
1937         if (m_gprOrInvalid == InvalidGPRReg)
1938             m_gprOrInvalid = m_jit-&gt;fillStorage(edge());
1939         return m_gprOrInvalid;
1940     }
1941 
1942     void use()
1943     {
1944         m_jit-&gt;use(node());
1945     }
1946 
1947 private:
1948     SpeculativeJIT* m_jit;
1949     Edge m_edge;
1950     GPRReg m_gprOrInvalid;
1951 };
1952 
1953 
1954 // === Temporaries ===
1955 //
1956 // These classes are used to allocate temporary registers.
1957 // A mechanism is provided to attempt to reuse the registers
1958 // currently allocated to child nodes whose value is consumed
1959 // by, and not live after, this operation.
1960 
1961 enum ReuseTag { Reuse };
1962 
1963 class GPRTemporary {
<a name="18" id="anc18"></a><span class="line-added">1964     WTF_MAKE_FAST_ALLOCATED;</span>
1965 public:
1966     GPRTemporary();
1967     GPRTemporary(SpeculativeJIT*);
1968     GPRTemporary(SpeculativeJIT*, GPRReg specific);
1969     template&lt;typename T&gt;
1970     GPRTemporary(SpeculativeJIT* jit, ReuseTag, T&amp; operand)
1971         : m_jit(jit)
1972         , m_gpr(InvalidGPRReg)
1973     {
1974         if (m_jit-&gt;canReuse(operand.node()))
1975             m_gpr = m_jit-&gt;reuse(operand.gpr());
1976         else
1977             m_gpr = m_jit-&gt;allocate();
1978     }
1979     template&lt;typename T1, typename T2&gt;
1980     GPRTemporary(SpeculativeJIT* jit, ReuseTag, T1&amp; op1, T2&amp; op2)
1981         : m_jit(jit)
1982         , m_gpr(InvalidGPRReg)
1983     {
1984         if (m_jit-&gt;canReuse(op1.node()))
1985             m_gpr = m_jit-&gt;reuse(op1.gpr());
1986         else if (m_jit-&gt;canReuse(op2.node()))
1987             m_gpr = m_jit-&gt;reuse(op2.gpr());
1988         else if (m_jit-&gt;canReuse(op1.node(), op2.node()) &amp;&amp; op1.gpr() == op2.gpr())
1989             m_gpr = m_jit-&gt;reuse(op1.gpr());
1990         else
1991             m_gpr = m_jit-&gt;allocate();
1992     }
1993     GPRTemporary(SpeculativeJIT*, ReuseTag, JSValueOperand&amp;, WhichValueWord);
1994 
1995     GPRTemporary(GPRTemporary&amp; other) = delete;
1996 
1997     GPRTemporary(GPRTemporary&amp;&amp; other)
1998     {
1999         ASSERT(other.m_jit);
2000         ASSERT(other.m_gpr != InvalidGPRReg);
2001         m_jit = other.m_jit;
2002         m_gpr = other.m_gpr;
2003         other.m_jit = nullptr;
2004         other.m_gpr = InvalidGPRReg;
2005     }
2006 
2007     GPRTemporary&amp; operator=(GPRTemporary&amp;&amp; other)
2008     {
2009         ASSERT(!m_jit);
2010         ASSERT(m_gpr == InvalidGPRReg);
2011         std::swap(m_jit, other.m_jit);
2012         std::swap(m_gpr, other.m_gpr);
2013         return *this;
2014     }
2015 
2016     void adopt(GPRTemporary&amp;);
2017 
2018     ~GPRTemporary()
2019     {
2020         if (m_jit &amp;&amp; m_gpr != InvalidGPRReg)
2021             m_jit-&gt;unlock(gpr());
2022     }
2023 
2024     GPRReg gpr()
2025     {
2026         return m_gpr;
2027     }
2028 
2029 private:
2030     SpeculativeJIT* m_jit;
2031     GPRReg m_gpr;
2032 };
2033 
2034 class JSValueRegsTemporary {
<a name="19" id="anc19"></a><span class="line-added">2035     WTF_MAKE_FAST_ALLOCATED;</span>
2036 public:
2037     JSValueRegsTemporary();
2038     JSValueRegsTemporary(SpeculativeJIT*);
2039     template&lt;typename T&gt;
2040     JSValueRegsTemporary(SpeculativeJIT*, ReuseTag, T&amp; operand, WhichValueWord resultRegWord = PayloadWord);
2041     JSValueRegsTemporary(SpeculativeJIT*, ReuseTag, JSValueOperand&amp;);
2042     ~JSValueRegsTemporary();
2043 
2044     JSValueRegs regs();
2045 
2046 private:
2047 #if USE(JSVALUE64)
2048     GPRTemporary m_gpr;
2049 #else
2050     GPRTemporary m_payloadGPR;
2051     GPRTemporary m_tagGPR;
2052 #endif
2053 };
2054 
2055 class FPRTemporary {
<a name="20" id="anc20"></a><span class="line-modified">2056     WTF_MAKE_FAST_ALLOCATED;</span>
2057 public:
2058     FPRTemporary(FPRTemporary&amp;&amp;);
2059     FPRTemporary(SpeculativeJIT*);
2060     FPRTemporary(SpeculativeJIT*, SpeculateDoubleOperand&amp;);
2061     FPRTemporary(SpeculativeJIT*, SpeculateDoubleOperand&amp;, SpeculateDoubleOperand&amp;);
2062 #if USE(JSVALUE32_64)
2063     FPRTemporary(SpeculativeJIT*, JSValueOperand&amp;);
2064 #endif
2065 
2066     ~FPRTemporary()
2067     {
2068         if (LIKELY(m_jit))
2069             m_jit-&gt;unlock(fpr());
2070     }
2071 
2072     FPRReg fpr() const
2073     {
2074         ASSERT(m_jit);
2075         ASSERT(m_fpr != InvalidFPRReg);
2076         return m_fpr;
2077     }
2078 
2079 protected:
2080     FPRTemporary(SpeculativeJIT* jit, FPRReg lockedFPR)
2081         : m_jit(jit)
2082         , m_fpr(lockedFPR)
2083     {
2084     }
2085 
2086 private:
2087     SpeculativeJIT* m_jit;
2088     FPRReg m_fpr;
2089 };
2090 
2091 
2092 // === Results ===
2093 //
2094 // These classes lock the result of a call to a C++ helper function.
2095 
2096 class GPRFlushedCallResult : public GPRTemporary {
2097 public:
2098     GPRFlushedCallResult(SpeculativeJIT* jit)
2099         : GPRTemporary(jit, GPRInfo::returnValueGPR)
2100     {
2101     }
2102 };
2103 
2104 #if USE(JSVALUE32_64)
2105 class GPRFlushedCallResult2 : public GPRTemporary {
2106 public:
2107     GPRFlushedCallResult2(SpeculativeJIT* jit)
2108         : GPRTemporary(jit, GPRInfo::returnValueGPR2)
2109     {
2110     }
2111 };
2112 #endif
2113 
2114 class FPRResult : public FPRTemporary {
2115 public:
2116     FPRResult(SpeculativeJIT* jit)
2117         : FPRTemporary(jit, lockedResult(jit))
2118     {
2119     }
2120 
2121 private:
2122     static FPRReg lockedResult(SpeculativeJIT* jit)
2123     {
2124         jit-&gt;lock(FPRInfo::returnValueFPR);
2125         return FPRInfo::returnValueFPR;
2126     }
2127 };
2128 
2129 class JSValueRegsFlushedCallResult {
<a name="21" id="anc21"></a><span class="line-added">2130     WTF_MAKE_FAST_ALLOCATED;</span>
2131 public:
2132     JSValueRegsFlushedCallResult(SpeculativeJIT* jit)
2133 #if USE(JSVALUE64)
2134         : m_gpr(jit)
2135 #else
2136         : m_payloadGPR(jit)
2137         , m_tagGPR(jit)
2138 #endif
2139     {
2140     }
2141 
2142     JSValueRegs regs()
2143     {
2144 #if USE(JSVALUE64)
2145         return JSValueRegs { m_gpr.gpr() };
2146 #else
2147         return JSValueRegs { m_tagGPR.gpr(), m_payloadGPR.gpr() };
2148 #endif
2149     }
2150 
2151 private:
2152 #if USE(JSVALUE64)
2153     GPRFlushedCallResult m_gpr;
2154 #else
2155     GPRFlushedCallResult m_payloadGPR;
2156     GPRFlushedCallResult2 m_tagGPR;
2157 #endif
2158 };
2159 
2160 
2161 // === Speculative Operand types ===
2162 //
2163 // SpeculateInt32Operand, SpeculateStrictInt32Operand and SpeculateCellOperand.
2164 //
2165 // These are used to lock the operands to a node into machine registers within the
2166 // SpeculativeJIT. The classes operate like those above, however these will
2167 // perform a speculative check for a more restrictive type than we can statically
2168 // determine the operand to have. If the operand does not have the requested type,
2169 // a bail-out to the non-speculative path will be taken.
2170 
2171 class SpeculateInt32Operand {
<a name="22" id="anc22"></a><span class="line-added">2172     WTF_MAKE_FAST_ALLOCATED;</span>
2173 public:
2174     explicit SpeculateInt32Operand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
2175         : m_jit(jit)
2176         , m_edge(edge)
2177         , m_gprOrInvalid(InvalidGPRReg)
2178 #ifndef NDEBUG
2179         , m_format(DataFormatNone)
2180 #endif
2181     {
2182         ASSERT(m_jit);
2183         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || (edge.useKind() == Int32Use || edge.useKind() == KnownInt32Use));
2184         if (jit-&gt;isFilled(node()))
2185             gpr();
2186     }
2187 
2188     ~SpeculateInt32Operand()
2189     {
2190         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2191         m_jit-&gt;unlock(m_gprOrInvalid);
2192     }
2193 
2194     Edge edge() const
2195     {
2196         return m_edge;
2197     }
2198 
2199     Node* node() const
2200     {
2201         return edge().node();
2202     }
2203 
2204     DataFormat format()
2205     {
2206         gpr(); // m_format is set when m_gpr is locked.
2207         ASSERT(m_format == DataFormatInt32 || m_format == DataFormatJSInt32);
2208         return m_format;
2209     }
2210 
2211     GPRReg gpr()
2212     {
2213         if (m_gprOrInvalid == InvalidGPRReg)
2214             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt32(edge(), m_format);
2215         return m_gprOrInvalid;
2216     }
2217 
2218     void use()
2219     {
2220         m_jit-&gt;use(node());
2221     }
2222 
2223 private:
2224     SpeculativeJIT* m_jit;
2225     Edge m_edge;
2226     GPRReg m_gprOrInvalid;
2227     DataFormat m_format;
2228 };
2229 
2230 class SpeculateStrictInt32Operand {
<a name="23" id="anc23"></a><span class="line-added">2231     WTF_MAKE_FAST_ALLOCATED;</span>
2232 public:
2233     explicit SpeculateStrictInt32Operand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
2234         : m_jit(jit)
2235         , m_edge(edge)
2236         , m_gprOrInvalid(InvalidGPRReg)
2237     {
2238         ASSERT(m_jit);
2239         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || (edge.useKind() == Int32Use || edge.useKind() == KnownInt32Use));
2240         if (jit-&gt;isFilled(node()))
2241             gpr();
2242     }
2243 
2244     ~SpeculateStrictInt32Operand()
2245     {
2246         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2247         m_jit-&gt;unlock(m_gprOrInvalid);
2248     }
2249 
2250     Edge edge() const
2251     {
2252         return m_edge;
2253     }
2254 
2255     Node* node() const
2256     {
2257         return edge().node();
2258     }
2259 
2260     GPRReg gpr()
2261     {
2262         if (m_gprOrInvalid == InvalidGPRReg)
2263             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt32Strict(edge());
2264         return m_gprOrInvalid;
2265     }
2266 
2267     void use()
2268     {
2269         m_jit-&gt;use(node());
2270     }
2271 
2272 private:
2273     SpeculativeJIT* m_jit;
2274     Edge m_edge;
2275     GPRReg m_gprOrInvalid;
2276 };
2277 
2278 // Gives you a canonical Int52 (i.e. it&#39;s left-shifted by 16, low bits zero).
2279 class SpeculateInt52Operand {
<a name="24" id="anc24"></a><span class="line-added">2280     WTF_MAKE_FAST_ALLOCATED;</span>
2281 public:
2282     explicit SpeculateInt52Operand(SpeculativeJIT* jit, Edge edge)
2283         : m_jit(jit)
2284         , m_edge(edge)
2285         , m_gprOrInvalid(InvalidGPRReg)
2286     {
2287         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2288         if (jit-&gt;isFilled(node()))
2289             gpr();
2290     }
2291 
2292     ~SpeculateInt52Operand()
2293     {
2294         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2295         m_jit-&gt;unlock(m_gprOrInvalid);
2296     }
2297 
2298     Edge edge() const
2299     {
2300         return m_edge;
2301     }
2302 
2303     Node* node() const
2304     {
2305         return edge().node();
2306     }
2307 
2308     GPRReg gpr()
2309     {
2310         if (m_gprOrInvalid == InvalidGPRReg)
2311             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt52(edge(), DataFormatInt52);
2312         return m_gprOrInvalid;
2313     }
2314 
2315     void use()
2316     {
2317         m_jit-&gt;use(node());
2318     }
2319 
2320 private:
2321     SpeculativeJIT* m_jit;
2322     Edge m_edge;
2323     GPRReg m_gprOrInvalid;
2324 };
2325 
2326 // Gives you a strict Int52 (i.e. the payload is in the low 48 bits, high 16 bits are sign-extended).
2327 class SpeculateStrictInt52Operand {
<a name="25" id="anc25"></a><span class="line-added">2328     WTF_MAKE_FAST_ALLOCATED;</span>
2329 public:
2330     explicit SpeculateStrictInt52Operand(SpeculativeJIT* jit, Edge edge)
2331         : m_jit(jit)
2332         , m_edge(edge)
2333         , m_gprOrInvalid(InvalidGPRReg)
2334     {
2335         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2336         if (jit-&gt;isFilled(node()))
2337             gpr();
2338     }
2339 
2340     ~SpeculateStrictInt52Operand()
2341     {
2342         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2343         m_jit-&gt;unlock(m_gprOrInvalid);
2344     }
2345 
2346     Edge edge() const
2347     {
2348         return m_edge;
2349     }
2350 
2351     Node* node() const
2352     {
2353         return edge().node();
2354     }
2355 
2356     GPRReg gpr()
2357     {
2358         if (m_gprOrInvalid == InvalidGPRReg)
2359             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt52(edge(), DataFormatStrictInt52);
2360         return m_gprOrInvalid;
2361     }
2362 
2363     void use()
2364     {
2365         m_jit-&gt;use(node());
2366     }
2367 
2368 private:
2369     SpeculativeJIT* m_jit;
2370     Edge m_edge;
2371     GPRReg m_gprOrInvalid;
2372 };
2373 
2374 enum OppositeShiftTag { OppositeShift };
2375 
2376 class SpeculateWhicheverInt52Operand {
<a name="26" id="anc26"></a><span class="line-added">2377     WTF_MAKE_FAST_ALLOCATED;</span>
2378 public:
2379     explicit SpeculateWhicheverInt52Operand(SpeculativeJIT* jit, Edge edge)
2380         : m_jit(jit)
2381         , m_edge(edge)
2382         , m_gprOrInvalid(InvalidGPRReg)
2383         , m_strict(jit-&gt;betterUseStrictInt52(edge))
2384     {
2385         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2386         if (jit-&gt;isFilled(node()))
2387             gpr();
2388     }
2389 
2390     explicit SpeculateWhicheverInt52Operand(SpeculativeJIT* jit, Edge edge, const SpeculateWhicheverInt52Operand&amp; other)
2391         : m_jit(jit)
2392         , m_edge(edge)
2393         , m_gprOrInvalid(InvalidGPRReg)
2394         , m_strict(other.m_strict)
2395     {
2396         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2397         if (jit-&gt;isFilled(node()))
2398             gpr();
2399     }
2400 
2401     explicit SpeculateWhicheverInt52Operand(SpeculativeJIT* jit, Edge edge, OppositeShiftTag, const SpeculateWhicheverInt52Operand&amp; other)
2402         : m_jit(jit)
2403         , m_edge(edge)
2404         , m_gprOrInvalid(InvalidGPRReg)
2405         , m_strict(!other.m_strict)
2406     {
2407         RELEASE_ASSERT(edge.useKind() == Int52RepUse);
2408         if (jit-&gt;isFilled(node()))
2409             gpr();
2410     }
2411 
2412     ~SpeculateWhicheverInt52Operand()
2413     {
2414         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2415         m_jit-&gt;unlock(m_gprOrInvalid);
2416     }
2417 
2418     Edge edge() const
2419     {
2420         return m_edge;
2421     }
2422 
2423     Node* node() const
2424     {
2425         return edge().node();
2426     }
2427 
2428     GPRReg gpr()
2429     {
2430         if (m_gprOrInvalid == InvalidGPRReg) {
2431             m_gprOrInvalid = m_jit-&gt;fillSpeculateInt52(
2432                 edge(), m_strict ? DataFormatStrictInt52 : DataFormatInt52);
2433         }
2434         return m_gprOrInvalid;
2435     }
2436 
2437     void use()
2438     {
2439         m_jit-&gt;use(node());
2440     }
2441 
2442     DataFormat format() const
2443     {
2444         return m_strict ? DataFormatStrictInt52 : DataFormatInt52;
2445     }
2446 
2447 private:
2448     SpeculativeJIT* m_jit;
2449     Edge m_edge;
2450     GPRReg m_gprOrInvalid;
2451     bool m_strict;
2452 };
2453 
2454 class SpeculateDoubleOperand {
<a name="27" id="anc27"></a><span class="line-added">2455     WTF_MAKE_FAST_ALLOCATED;</span>
2456 public:
2457     explicit SpeculateDoubleOperand(SpeculativeJIT* jit, Edge edge)
2458         : m_jit(jit)
2459         , m_edge(edge)
2460         , m_fprOrInvalid(InvalidFPRReg)
2461     {
2462         ASSERT(m_jit);
2463         RELEASE_ASSERT(isDouble(edge.useKind()));
2464         if (jit-&gt;isFilled(node()))
2465             fpr();
2466     }
2467 
2468     ~SpeculateDoubleOperand()
2469     {
2470         ASSERT(m_fprOrInvalid != InvalidFPRReg);
2471         m_jit-&gt;unlock(m_fprOrInvalid);
2472     }
2473 
2474     Edge edge() const
2475     {
2476         return m_edge;
2477     }
2478 
2479     Node* node() const
2480     {
2481         return edge().node();
2482     }
2483 
2484     FPRReg fpr()
2485     {
2486         if (m_fprOrInvalid == InvalidFPRReg)
2487             m_fprOrInvalid = m_jit-&gt;fillSpeculateDouble(edge());
2488         return m_fprOrInvalid;
2489     }
2490 
2491     void use()
2492     {
2493         m_jit-&gt;use(node());
2494     }
2495 
2496 private:
2497     SpeculativeJIT* m_jit;
2498     Edge m_edge;
2499     FPRReg m_fprOrInvalid;
2500 };
2501 
2502 class SpeculateCellOperand {
<a name="28" id="anc28"></a><span class="line-modified">2503     WTF_MAKE_FAST_ALLOCATED;</span>
2504 
2505 public:
2506     explicit SpeculateCellOperand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
2507         : m_jit(jit)
2508         , m_edge(edge)
2509         , m_gprOrInvalid(InvalidGPRReg)
2510     {
2511         ASSERT(m_jit);
2512         if (!edge)
2513             return;
2514         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || isCell(edge.useKind()));
2515         if (jit-&gt;isFilled(node()))
2516             gpr();
2517     }
2518 
2519     explicit SpeculateCellOperand(SpeculateCellOperand&amp;&amp; other)
2520     {
2521         m_jit = other.m_jit;
2522         m_edge = other.m_edge;
2523         m_gprOrInvalid = other.m_gprOrInvalid;
2524 
2525         other.m_gprOrInvalid = InvalidGPRReg;
2526         other.m_edge = Edge();
2527     }
2528 
2529     ~SpeculateCellOperand()
2530     {
2531         if (!m_edge)
2532             return;
2533         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2534         m_jit-&gt;unlock(m_gprOrInvalid);
2535     }
2536 
2537     Edge edge() const
2538     {
2539         return m_edge;
2540     }
2541 
2542     Node* node() const
2543     {
2544         return edge().node();
2545     }
2546 
2547     GPRReg gpr()
2548     {
2549         ASSERT(m_edge);
2550         if (m_gprOrInvalid == InvalidGPRReg)
2551             m_gprOrInvalid = m_jit-&gt;fillSpeculateCell(edge());
2552         return m_gprOrInvalid;
2553     }
2554 
2555     void use()
2556     {
2557         ASSERT(m_edge);
2558         m_jit-&gt;use(node());
2559     }
2560 
2561 private:
2562     SpeculativeJIT* m_jit;
2563     Edge m_edge;
2564     GPRReg m_gprOrInvalid;
2565 };
2566 
2567 class SpeculateBooleanOperand {
<a name="29" id="anc29"></a><span class="line-added">2568     WTF_MAKE_FAST_ALLOCATED;</span>
2569 public:
2570     explicit SpeculateBooleanOperand(SpeculativeJIT* jit, Edge edge, OperandSpeculationMode mode = AutomaticOperandSpeculation)
2571         : m_jit(jit)
2572         , m_edge(edge)
2573         , m_gprOrInvalid(InvalidGPRReg)
2574     {
2575         ASSERT(m_jit);
2576         ASSERT_UNUSED(mode, mode == ManualOperandSpeculation || edge.useKind() == BooleanUse || edge.useKind() == KnownBooleanUse);
2577         if (jit-&gt;isFilled(node()))
2578             gpr();
2579     }
2580 
2581     ~SpeculateBooleanOperand()
2582     {
2583         ASSERT(m_gprOrInvalid != InvalidGPRReg);
2584         m_jit-&gt;unlock(m_gprOrInvalid);
2585     }
2586 
2587     Edge edge() const
2588     {
2589         return m_edge;
2590     }
2591 
2592     Node* node() const
2593     {
2594         return edge().node();
2595     }
2596 
2597     GPRReg gpr()
2598     {
2599         if (m_gprOrInvalid == InvalidGPRReg)
2600             m_gprOrInvalid = m_jit-&gt;fillSpeculateBoolean(edge());
2601         return m_gprOrInvalid;
2602     }
2603 
2604     void use()
2605     {
2606         m_jit-&gt;use(node());
2607     }
2608 
2609 private:
2610     SpeculativeJIT* m_jit;
2611     Edge m_edge;
2612     GPRReg m_gprOrInvalid;
2613 };
2614 
2615 #define DFG_TYPE_CHECK_WITH_EXIT_KIND(exitKind, source, edge, typesPassedThrough, jumpToFail) do { \
2616         JSValueSource _dtc_source = (source);                           \
2617         Edge _dtc_edge = (edge);                                        \
2618         SpeculatedType _dtc_typesPassedThrough = typesPassedThrough;    \
2619         if (!needsTypeCheck(_dtc_edge, _dtc_typesPassedThrough))        \
2620             break;                                                      \
2621         typeCheck(_dtc_source, _dtc_edge, _dtc_typesPassedThrough, (jumpToFail), exitKind); \
2622     } while (0)
2623 
2624 #define DFG_TYPE_CHECK(source, edge, typesPassedThrough, jumpToFail) \
2625     DFG_TYPE_CHECK_WITH_EXIT_KIND(BadType, source, edge, typesPassedThrough, jumpToFail)
2626 
2627 } } // namespace JSC::DFG
2628 
2629 #endif
<a name="30" id="anc30"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="30" type="hidden" />
</body>
</html>