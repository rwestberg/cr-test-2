<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/MarkedSpace.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  *  Copyright (C) 1999-2000 Harri Porten (porten@kde.org)
  3  *  Copyright (C) 2001 Peter Kelly (pmk@post.com)
  4  *  Copyright (C) 2003-2018 Apple Inc. All rights reserved.
  5  *
  6  *  This library is free software; you can redistribute it and/or
  7  *  modify it under the terms of the GNU Lesser General Public
  8  *  License as published by the Free Software Foundation; either
  9  *  version 2 of the License, or (at your option) any later version.
 10  *
 11  *  This library is distributed in the hope that it will be useful,
 12  *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 13  *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 14  *  Lesser General Public License for more details.
 15  *
 16  *  You should have received a copy of the GNU Lesser General Public
 17  *  License along with this library; if not, write to the Free Software
 18  *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA
 19  *
 20  */
 21 
 22 #pragma once
 23 
 24 #include &quot;BlockDirectory.h&quot;
 25 #include &quot;IterationStatus.h&quot;
 26 #include &quot;LargeAllocation.h&quot;
 27 #include &quot;MarkedBlock.h&quot;
 28 #include &quot;MarkedBlockSet.h&quot;
 29 #include &lt;array&gt;
 30 #include &lt;wtf/Bag.h&gt;
 31 #include &lt;wtf/HashSet.h&gt;
 32 #include &lt;wtf/Noncopyable.h&gt;
 33 #include &lt;wtf/RetainPtr.h&gt;
 34 #include &lt;wtf/SentinelLinkedList.h&gt;
 35 #include &lt;wtf/SinglyLinkedListWithTail.h&gt;
 36 #include &lt;wtf/Vector.h&gt;
 37 
 38 namespace JSC {
 39 
 40 class CompleteSubspace;
 41 class Heap;
 42 class HeapIterationScope;
 43 class LLIntOffsetsExtractor;
 44 class Subspace;
 45 class WeakSet;
 46 
 47 typedef uint32_t HeapVersion;
 48 
 49 class MarkedSpace {
 50     WTF_MAKE_NONCOPYABLE(MarkedSpace);
 51 public:
 52     // sizeStep is really a synonym for atomSize; it&#39;s no accident that they are the same.
 53     static constexpr size_t sizeStep = MarkedBlock::atomSize;
 54 
 55     // Sizes up to this amount get a size class for each size step.
 56     static constexpr size_t preciseCutoff = 80;
 57 
 58     // The amount of available payload in a block is the block&#39;s size minus the footer.
 59     static constexpr size_t blockPayload = MarkedBlock::payloadSize;
 60 
 61     // The largest cell we&#39;re willing to allocate in a MarkedBlock the &quot;normal way&quot; (i.e. using size
 62     // classes, rather than a large allocation) is half the size of the payload, rounded down. This
 63     // ensures that we only use the size class approach if it means being able to pack two things
 64     // into one block.
 65     static constexpr size_t largeCutoff = (blockPayload / 2) &amp; ~(sizeStep - 1);
 66 
 67     // We have an extra size class for size zero.
 68     static constexpr size_t numSizeClasses = largeCutoff / sizeStep + 1;
 69 
 70     static constexpr HeapVersion nullVersion = 0; // The version of freshly allocated blocks.
 71     static constexpr HeapVersion initialVersion = 2; // The version that the heap starts out with. Set to make sure that nextVersion(nullVersion) != initialVersion.
 72 
 73     static HeapVersion nextVersion(HeapVersion version)
 74     {
 75         version++;
 76         if (version == nullVersion)
 77             version = initialVersion;
 78         return version;
 79     }
 80 
 81     static size_t sizeClassToIndex(size_t size)
 82     {
 83         return (size + sizeStep - 1) / sizeStep;
 84     }
 85 
 86     static size_t indexToSizeClass(size_t index)
 87     {
 88         size_t result = index * sizeStep;
 89         ASSERT(sizeClassToIndex(result) == index);
 90         return result;
 91     }
 92 
 93     MarkedSpace(Heap*);
 94     ~MarkedSpace();
 95 
 96     Heap* heap() const { return m_heap; }
 97 
 98     void lastChanceToFinalize(); // Must call stopAllocatingForGood first.
 99     void freeMemory();
100 
101     static size_t optimalSizeFor(size_t);
102 
103     void prepareForAllocation();
104 
105     void visitWeakSets(SlotVisitor&amp;);
106     void reapWeakSets();
107 
108     MarkedBlockSet&amp; blocks() { return m_blocks; }
109 
110     void willStartIterating();
111     bool isIterating() const { return m_isIterating; }
112     void didFinishIterating();
113 
114     void stopAllocating();
115     void stopAllocatingForGood();
116     void resumeAllocating(); // If we just stopped allocation but we didn&#39;t do a collection, we need to resume allocation.
117 
118     void prepareForMarking();
119 
120     void prepareForConservativeScan();
121 
122     typedef HashSet&lt;MarkedBlock*&gt;::iterator BlockIterator;
123 
124     template&lt;typename Functor&gt; void forEachLiveCell(HeapIterationScope&amp;, const Functor&amp;);
125     template&lt;typename Functor&gt; void forEachDeadCell(HeapIterationScope&amp;, const Functor&amp;);
126     template&lt;typename Functor&gt; void forEachBlock(const Functor&amp;);
<a name="1" id="anc1"></a><span class="line-added">127     template&lt;typename Functor&gt; void forEachSubspace(const Functor&amp;);</span>
128 
129     void shrink();
130     void freeBlock(MarkedBlock::Handle*);
131     void freeOrShrinkBlock(MarkedBlock::Handle*);
132 
133     void didAddBlock(MarkedBlock::Handle*);
134     void didConsumeFreeList(MarkedBlock::Handle*);
135     void didAllocateInBlock(MarkedBlock::Handle*);
136 
137     void beginMarking();
138     void endMarking();
139     void snapshotUnswept();
140     void clearNewlyAllocated();
141     void sweep();
142     void sweepLargeAllocations();
143     void assertNoUnswept();
144     size_t objectCount();
145     size_t size();
146     size_t capacity();
147 
148     bool isPagedOut(MonotonicTime deadline);
149 
150     HeapVersion markingVersion() const { return m_markingVersion; }
151     HeapVersion newlyAllocatedVersion() const { return m_newlyAllocatedVersion; }
152 
153     const Vector&lt;LargeAllocation*&gt;&amp; largeAllocations() const { return m_largeAllocations; }
154     unsigned largeAllocationsNurseryOffset() const { return m_largeAllocationsNurseryOffset; }
155     unsigned largeAllocationsOffsetForThisCollection() const { return m_largeAllocationsOffsetForThisCollection; }
156 
157     // These are cached pointers and offsets for quickly searching the large allocations that are
158     // relevant to this collection.
159     LargeAllocation** largeAllocationsForThisCollectionBegin() const { return m_largeAllocationsForThisCollectionBegin; }
160     LargeAllocation** largeAllocationsForThisCollectionEnd() const { return m_largeAllocationsForThisCollectionEnd; }
161     unsigned largeAllocationsForThisCollectionSize() const { return m_largeAllocationsForThisCollectionSize; }
162 
163     BlockDirectory* firstDirectory() const { return m_directories.first(); }
164 
165     Lock&amp; directoryLock() { return m_directoryLock; }
166     void addBlockDirectory(const AbstractLocker&amp;, BlockDirectory*);
167 
168     // When this is true it means that we have flipped but the mark bits haven&#39;t converged yet.
169     bool isMarking() const { return m_isMarking; }
170 
171     WeakSet* activeWeakSetsBegin() { return m_activeWeakSets.begin(); }
172     WeakSet* activeWeakSetsEnd() { return m_activeWeakSets.end(); }
173     WeakSet* newActiveWeakSetsBegin() { return m_newActiveWeakSets.begin(); }
174     WeakSet* newActiveWeakSetsEnd() { return m_newActiveWeakSets.end(); }
175 
176     void dumpBits(PrintStream&amp; = WTF::dataFile());
177 
178     JS_EXPORT_PRIVATE static std::array&lt;size_t, numSizeClasses&gt; s_sizeClassForSizeStep;
179 
180 private:
181     friend class CompleteSubspace;
182     friend class LLIntOffsetsExtractor;
183     friend class JIT;
184     friend class WeakSet;
185     friend class Subspace;
186 
187     // Use this version when calling from within the GC where we know that the directories
188     // have already been stopped.
189     template&lt;typename Functor&gt; void forEachLiveCell(const Functor&amp;);
190 
191     static void initializeSizeClassForStepSize();
192 
193     void initializeSubspace(Subspace&amp;);
194 
195     template&lt;typename Functor&gt; inline void forEachDirectory(const Functor&amp;);
196 
197     void addActiveWeakSet(WeakSet*);
198 
199     Vector&lt;Subspace*&gt; m_subspaces;
200 
201     Vector&lt;LargeAllocation*&gt; m_largeAllocations;
202     unsigned m_largeAllocationsNurseryOffset { 0 };
203     unsigned m_largeAllocationsOffsetForThisCollection { 0 };
204     unsigned m_largeAllocationsNurseryOffsetForSweep { 0 };
205     unsigned m_largeAllocationsForThisCollectionSize { 0 };
206     LargeAllocation** m_largeAllocationsForThisCollectionBegin { nullptr };
207     LargeAllocation** m_largeAllocationsForThisCollectionEnd { nullptr };
208 
209     Heap* m_heap;
210     size_t m_capacity { 0 };
211     HeapVersion m_markingVersion { initialVersion };
212     HeapVersion m_newlyAllocatedVersion { initialVersion };
213     bool m_isIterating { false };
214     bool m_isMarking { false };
215     Lock m_directoryLock;
216     MarkedBlockSet m_blocks;
217 
218     SentinelLinkedList&lt;WeakSet, BasicRawSentinelNode&lt;WeakSet&gt;&gt; m_activeWeakSets;
219     SentinelLinkedList&lt;WeakSet, BasicRawSentinelNode&lt;WeakSet&gt;&gt; m_newActiveWeakSets;
220 
221     SinglyLinkedListWithTail&lt;BlockDirectory&gt; m_directories;
222 
223     friend class HeapVerifier;
224 };
225 
226 template &lt;typename Functor&gt; inline void MarkedSpace::forEachBlock(const Functor&amp; functor)
227 {
228     forEachDirectory(
229         [&amp;] (BlockDirectory&amp; directory) -&gt; IterationStatus {
230             directory.forEachBlock(functor);
231             return IterationStatus::Continue;
232         });
233 }
234 
235 template &lt;typename Functor&gt;
236 void MarkedSpace::forEachDirectory(const Functor&amp; functor)
237 {
238     for (BlockDirectory* directory = m_directories.first(); directory; directory = directory-&gt;nextDirectory()) {
239         if (functor(*directory) == IterationStatus::Done)
240             return;
241     }
242 }
243 
<a name="2" id="anc2"></a><span class="line-added">244 template&lt;typename Functor&gt;</span>
<span class="line-added">245 void MarkedSpace::forEachSubspace(const Functor&amp; functor)</span>
<span class="line-added">246 {</span>
<span class="line-added">247     for (auto subspace : m_subspaces) {</span>
<span class="line-added">248         if (functor(*subspace) == IterationStatus::Done)</span>
<span class="line-added">249             return;</span>
<span class="line-added">250     }</span>
<span class="line-added">251 }</span>
<span class="line-added">252 </span>
<span class="line-added">253 </span>
254 ALWAYS_INLINE size_t MarkedSpace::optimalSizeFor(size_t bytes)
255 {
256     ASSERT(bytes);
257     if (bytes &lt;= preciseCutoff)
258         return WTF::roundUpToMultipleOf&lt;sizeStep&gt;(bytes);
259     if (bytes &lt;= largeCutoff)
260         return s_sizeClassForSizeStep[sizeClassToIndex(bytes)];
261     return bytes;
262 }
263 
264 } // namespace JSC
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>