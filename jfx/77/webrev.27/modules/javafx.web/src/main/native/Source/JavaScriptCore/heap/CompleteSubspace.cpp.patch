diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/CompleteSubspace.cpp b/modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/CompleteSubspace.cpp
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/CompleteSubspace.cpp
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/heap/CompleteSubspace.cpp
@@ -78,19 +78,19 @@
 
     if (false)
         dataLog("Creating BlockDirectory/LocalAllocator for ", m_name, ", ", attributes(), ", ", sizeClass, ".\n");
 
     std::unique_ptr<BlockDirectory> uniqueDirectory =
-        std::make_unique<BlockDirectory>(m_space.heap(), sizeClass);
+        makeUnique<BlockDirectory>(m_space.heap(), sizeClass);
     BlockDirectory* directory = uniqueDirectory.get();
     m_directories.append(WTFMove(uniqueDirectory));
 
     directory->setSubspace(this);
     m_space.addBlockDirectory(locker, directory);
 
     std::unique_ptr<LocalAllocator> uniqueLocalAllocator =
-        std::make_unique<LocalAllocator>(directory);
+        makeUnique<LocalAllocator>(directory);
     LocalAllocator* localAllocator = uniqueLocalAllocator.get();
     m_localAllocators.append(WTFMove(uniqueLocalAllocator));
 
     Allocator allocator(localAllocator);
 
@@ -123,11 +123,11 @@
 void* CompleteSubspace::tryAllocateSlow(VM& vm, size_t size, GCDeferralContext* deferralContext)
 {
     if (validateDFGDoesGC)
         RELEASE_ASSERT(vm.heap.expectDoesGC());
 
-    sanitizeStackForVM(&vm);
+    sanitizeStackForVM(vm);
 
     if (Allocator allocator = allocatorFor(size, AllocatorForMode::EnsureAllocator))
         return allocator.allocate(deferralContext, AllocationFailureMode::ReturnNull);
 
     if (size <= Options::largeAllocationCutoff()
@@ -138,20 +138,70 @@
     }
 
     vm.heap.collectIfNecessaryOrDefer(deferralContext);
 
     size = WTF::roundUpToMultipleOf<MarkedSpace::sizeStep>(size);
-    LargeAllocation* allocation = LargeAllocation::tryCreate(vm.heap, size, this);
+    LargeAllocation* allocation = LargeAllocation::tryCreate(vm.heap, size, this, m_space.m_largeAllocations.size());
     if (!allocation)
         return nullptr;
 
     m_space.m_largeAllocations.append(allocation);
+    ASSERT(allocation->indexInSpace() == m_space.m_largeAllocations.size() - 1);
     vm.heap.didAllocate(size);
     m_space.m_capacity += size;
 
     m_largeAllocations.append(allocation);
 
     return allocation->cell();
 }
 
+void* CompleteSubspace::reallocateLargeAllocationNonVirtual(VM& vm, HeapCell* oldCell, size_t size, GCDeferralContext* deferralContext, AllocationFailureMode failureMode)
+{
+    if (validateDFGDoesGC)
+        RELEASE_ASSERT(vm.heap.expectDoesGC());
+
+    // The following conditions are met in Butterfly for example.
+    ASSERT(oldCell->isLargeAllocation());
+
+    LargeAllocation* oldAllocation = &oldCell->largeAllocation();
+    ASSERT(oldAllocation->cellSize() <= size);
+    ASSERT(oldAllocation->weakSet().isTriviallyDestructible());
+    ASSERT(oldAllocation->attributes().destruction == DoesNotNeedDestruction);
+    ASSERT(oldAllocation->attributes().cellKind == HeapCell::Auxiliary);
+    ASSERT(size > MarkedSpace::largeCutoff);
+
+    sanitizeStackForVM(vm);
+
+    if (size <= Options::largeAllocationCutoff()
+        && size <= MarkedSpace::largeCutoff) {
+        dataLog("FATAL: attampting to allocate small object using large allocation.\n");
+        dataLog("Requested allocation size: ", size, "\n");
+        RELEASE_ASSERT_NOT_REACHED();
+    }
+
+    vm.heap.collectIfNecessaryOrDefer(deferralContext);
+
+    size = WTF::roundUpToMultipleOf<MarkedSpace::sizeStep>(size);
+    size_t difference = size - oldAllocation->cellSize();
+    unsigned oldIndexInSpace = oldAllocation->indexInSpace();
+    if (oldAllocation->isOnList())
+        oldAllocation->remove();
+
+    LargeAllocation* allocation = oldAllocation->tryReallocate(size, this);
+    if (!allocation) {
+        RELEASE_ASSERT(failureMode != AllocationFailureMode::Assert);
+        m_largeAllocations.append(oldAllocation);
+        return nullptr;
+    }
+    ASSERT(oldIndexInSpace == allocation->indexInSpace());
+
+    m_space.m_largeAllocations[oldIndexInSpace] = allocation;
+    vm.heap.didAllocate(difference);
+    m_space.m_capacity += difference;
+
+    m_largeAllocations.append(allocation);
+
+    return allocation->cell();
+}
+
 } // namespace JSC
 
