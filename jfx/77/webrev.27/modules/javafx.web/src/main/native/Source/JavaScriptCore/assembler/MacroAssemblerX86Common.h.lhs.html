<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/MacroAssemblerX86Common.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (C) 2008-2018 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #pragma once
  27 
  28 #if ENABLE(ASSEMBLER)
  29 
  30 #include &quot;X86Assembler.h&quot;
  31 #include &quot;AbstractMacroAssembler.h&quot;
  32 #include &lt;array&gt;
  33 #include &lt;wtf/Optional.h&gt;
  34 
  35 namespace JSC {
  36 
  37 using Assembler = TARGET_ASSEMBLER;
  38 
  39 class MacroAssemblerX86Common : public AbstractMacroAssembler&lt;Assembler&gt; {
  40 public:
  41 #if CPU(X86_64)
  42     // Use this directly only if you&#39;re not generating code with it.
  43     static const X86Registers::RegisterID s_scratchRegister = X86Registers::r11;
  44 
  45     // Use this when generating code so that we get enforcement of the disallowing of scratch register
  46     // usage.
  47     X86Registers::RegisterID scratchRegister()
  48     {
  49         RELEASE_ASSERT(m_allowScratchRegister);
  50         return s_scratchRegister;
  51     }
  52 #endif
  53 
  54 protected:
  55     static const int DoubleConditionBitInvert = 0x10;
  56     static const int DoubleConditionBitSpecial = 0x20;
  57     static const int DoubleConditionBits = DoubleConditionBitInvert | DoubleConditionBitSpecial;
  58 
  59 public:
  60     typedef X86Assembler::XMMRegisterID XMMRegisterID;
  61 
  62     static bool isCompactPtrAlignedAddressOffset(ptrdiff_t value)
  63     {
  64         return value &gt;= -128 &amp;&amp; value &lt;= 127;
  65     }
  66 
  67     enum RelationalCondition {
  68         Equal = X86Assembler::ConditionE,
  69         NotEqual = X86Assembler::ConditionNE,
  70         Above = X86Assembler::ConditionA,
  71         AboveOrEqual = X86Assembler::ConditionAE,
  72         Below = X86Assembler::ConditionB,
  73         BelowOrEqual = X86Assembler::ConditionBE,
  74         GreaterThan = X86Assembler::ConditionG,
  75         GreaterThanOrEqual = X86Assembler::ConditionGE,
  76         LessThan = X86Assembler::ConditionL,
  77         LessThanOrEqual = X86Assembler::ConditionLE
  78     };
  79 
  80     enum ResultCondition {
  81         Overflow = X86Assembler::ConditionO,
  82         Signed = X86Assembler::ConditionS,
  83         PositiveOrZero = X86Assembler::ConditionNS,
  84         Zero = X86Assembler::ConditionE,
  85         NonZero = X86Assembler::ConditionNE
  86     };
  87 
  88     // FIXME: it would be neat to rename this to FloatingPointCondition in every assembler.
  89     enum DoubleCondition {
  90         // These conditions will only evaluate to true if the comparison is ordered - i.e. neither operand is NaN.
  91         DoubleEqual = X86Assembler::ConditionE | DoubleConditionBitSpecial,
  92         DoubleNotEqual = X86Assembler::ConditionNE,
  93         DoubleGreaterThan = X86Assembler::ConditionA,
  94         DoubleGreaterThanOrEqual = X86Assembler::ConditionAE,
  95         DoubleLessThan = X86Assembler::ConditionA | DoubleConditionBitInvert,
  96         DoubleLessThanOrEqual = X86Assembler::ConditionAE | DoubleConditionBitInvert,
  97         // If either operand is NaN, these conditions always evaluate to true.
  98         DoubleEqualOrUnordered = X86Assembler::ConditionE,
  99         DoubleNotEqualOrUnordered = X86Assembler::ConditionNE | DoubleConditionBitSpecial,
 100         DoubleGreaterThanOrUnordered = X86Assembler::ConditionB | DoubleConditionBitInvert,
 101         DoubleGreaterThanOrEqualOrUnordered = X86Assembler::ConditionBE | DoubleConditionBitInvert,
 102         DoubleLessThanOrUnordered = X86Assembler::ConditionB,
 103         DoubleLessThanOrEqualOrUnordered = X86Assembler::ConditionBE,
 104     };
 105     COMPILE_ASSERT(
 106         !((X86Assembler::ConditionE | X86Assembler::ConditionNE | X86Assembler::ConditionA | X86Assembler::ConditionAE | X86Assembler::ConditionB | X86Assembler::ConditionBE) &amp; DoubleConditionBits),
 107         DoubleConditionBits_should_not_interfere_with_X86Assembler_Condition_codes);
 108 
 109     static const RegisterID stackPointerRegister = X86Registers::esp;
 110     static const RegisterID framePointerRegister = X86Registers::ebp;
 111 
 112     static bool canBlind() { return true; }
 113     static bool shouldBlindForSpecificArch(uint32_t value) { return value &gt;= 0x00ffffff; }
 114     static bool shouldBlindForSpecificArch(uint64_t value) { return value &gt;= 0x00ffffff; }
 115 
 116     // Integer arithmetic operations:
 117     //
 118     // Operations are typically two operand - operation(source, srcDst)
 119     // For many operations the source may be an TrustedImm32, the srcDst operand
 120     // may often be a memory location (explictly described using an Address
 121     // object).
 122 
 123     void add32(RegisterID src, RegisterID dest)
 124     {
 125         m_assembler.addl_rr(src, dest);
 126     }
 127 
 128     void add32(TrustedImm32 imm, Address address)
 129     {
 130         m_assembler.addl_im(imm.m_value, address.offset, address.base);
 131     }
 132 
 133     void add32(TrustedImm32 imm, BaseIndex address)
 134     {
 135         m_assembler.addl_im(imm.m_value, address.offset, address.base, address.index, address.scale);
 136     }
 137 
 138     void add8(TrustedImm32 imm, Address address)
 139     {
 140         TrustedImm32 imm8(static_cast&lt;int8_t&gt;(imm.m_value));
 141         m_assembler.addb_im(imm8.m_value, address.offset, address.base);
 142     }
 143 
 144     void add8(TrustedImm32 imm, BaseIndex address)
 145     {
 146         TrustedImm32 imm8(static_cast&lt;int8_t&gt;(imm.m_value));
 147         m_assembler.addb_im(imm8.m_value, address.offset, address.base, address.index, address.scale);
 148     }
 149 
 150     void add16(TrustedImm32 imm, Address address)
 151     {
 152         m_assembler.addw_im(imm.m_value, address.offset, address.base);
 153     }
 154 
 155     void add16(TrustedImm32 imm, BaseIndex address)
 156     {
 157         m_assembler.addw_im(imm.m_value, address.offset, address.base, address.index, address.scale);
 158     }
 159 
 160     void add32(TrustedImm32 imm, RegisterID dest)
 161     {
 162         if (imm.m_value == 1)
 163             m_assembler.inc_r(dest);
 164         else
 165             m_assembler.addl_ir(imm.m_value, dest);
 166     }
 167 
 168     void add32(Address src, RegisterID dest)
 169     {
 170         m_assembler.addl_mr(src.offset, src.base, dest);
 171     }
 172 
 173     void add32(BaseIndex src, RegisterID dest)
 174     {
 175         m_assembler.addl_mr(src.offset, src.base, src.index, src.scale, dest);
 176     }
 177 
 178     void add32(RegisterID src, Address dest)
 179     {
 180         m_assembler.addl_rm(src, dest.offset, dest.base);
 181     }
 182 
 183     void add32(RegisterID src, BaseIndex dest)
 184     {
 185         m_assembler.addl_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 186     }
 187 
 188     void add8(RegisterID src, Address dest)
 189     {
 190         m_assembler.addb_rm(src, dest.offset, dest.base);
 191     }
 192 
 193     void add8(RegisterID src, BaseIndex dest)
 194     {
 195         m_assembler.addb_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 196     }
 197 
 198     void add16(RegisterID src, Address dest)
 199     {
 200         m_assembler.addw_rm(src, dest.offset, dest.base);
 201     }
 202 
 203     void add16(RegisterID src, BaseIndex dest)
 204     {
 205         m_assembler.addw_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 206     }
 207 
 208     void add32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 209     {
 210         if (!imm.m_value) {
 211             zeroExtend32ToPtr(src, dest);
 212             return;
 213         }
 214 
 215         if (src == dest) {
 216             add32(imm, dest);
 217             return;
 218         }
 219 
 220         m_assembler.leal_mr(imm.m_value, src, dest);
 221     }
 222 
 223     void add32(RegisterID a, RegisterID b, RegisterID dest)
 224     {
 225         x86Lea32(BaseIndex(a, b, TimesOne), dest);
 226     }
 227 
 228     void x86Lea32(BaseIndex index, RegisterID dest)
 229     {
 230         if (!index.scale &amp;&amp; !index.offset) {
 231             if (index.base == dest) {
 232                 add32(index.index, dest);
 233                 return;
 234             }
 235             if (index.index == dest) {
 236                 add32(index.base, dest);
 237                 return;
 238             }
 239         }
 240         m_assembler.leal_mr(index.offset, index.base, index.index, index.scale, dest);
 241     }
 242 
 243     void and32(RegisterID src, RegisterID dest)
 244     {
 245         m_assembler.andl_rr(src, dest);
 246     }
 247 
 248     void and32(TrustedImm32 imm, RegisterID dest)
 249     {
 250         m_assembler.andl_ir(imm.m_value, dest);
 251     }
 252 
 253     void and32(RegisterID src, Address dest)
 254     {
 255         m_assembler.andl_rm(src, dest.offset, dest.base);
 256     }
 257 
 258     void and32(RegisterID src, BaseIndex dest)
 259     {
 260         m_assembler.andl_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 261     }
 262 
 263     void and16(RegisterID src, Address dest)
 264     {
 265         m_assembler.andw_rm(src, dest.offset, dest.base);
 266     }
 267 
 268     void and16(RegisterID src, BaseIndex dest)
 269     {
 270         m_assembler.andw_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 271     }
 272 
 273     void and8(RegisterID src, Address dest)
 274     {
 275         m_assembler.andb_rm(src, dest.offset, dest.base);
 276     }
 277 
 278     void and8(RegisterID src, BaseIndex dest)
 279     {
 280         m_assembler.andb_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 281     }
 282 
 283     void and32(Address src, RegisterID dest)
 284     {
 285         m_assembler.andl_mr(src.offset, src.base, dest);
 286     }
 287 
 288     void and32(BaseIndex src, RegisterID dest)
 289     {
 290         m_assembler.andl_mr(src.offset, src.base, src.index, src.scale, dest);
 291     }
 292 
 293     void and16(Address src, RegisterID dest)
 294     {
 295         m_assembler.andw_mr(src.offset, src.base, dest);
 296     }
 297 
 298     void and16(BaseIndex src, RegisterID dest)
 299     {
 300         m_assembler.andw_mr(src.offset, src.base, src.index, src.scale, dest);
 301     }
 302 
 303     void and32(TrustedImm32 imm, Address address)
 304     {
 305         m_assembler.andl_im(imm.m_value, address.offset, address.base);
 306     }
 307 
 308     void and32(TrustedImm32 imm, BaseIndex address)
 309     {
 310         m_assembler.andl_im(imm.m_value, address.offset, address.base, address.index, address.scale);
 311     }
 312 
 313     void and16(TrustedImm32 imm, Address address)
 314     {
 315         m_assembler.andw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base);
 316     }
 317 
 318     void and16(TrustedImm32 imm, BaseIndex address)
 319     {
 320         m_assembler.andw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
 321     }
 322 
 323     void and8(TrustedImm32 imm, Address address)
 324     {
 325         m_assembler.andb_im(static_cast&lt;int8_t&gt;(imm.m_value), address.offset, address.base);
 326     }
 327 
 328     void and8(TrustedImm32 imm, BaseIndex address)
 329     {
 330         m_assembler.andb_im(static_cast&lt;int8_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
 331     }
 332 
 333     void and32(RegisterID op1, RegisterID op2, RegisterID dest)
 334     {
 335         if (op1 == op2)
 336             zeroExtend32ToPtr(op1, dest);
 337         else if (op1 == dest)
 338             and32(op2, dest);
 339         else {
 340             move32IfNeeded(op2, dest);
 341             and32(op1, dest);
 342         }
 343     }
 344 
 345     void and32(Address op1, RegisterID op2, RegisterID dest)
 346     {
 347         if (op2 == dest)
 348             and32(op1, dest);
 349         else if (op1.base == dest) {
 350             load32(op1, dest);
 351             and32(op2, dest);
 352         } else {
 353             zeroExtend32ToPtr(op2, dest);
 354             and32(op1, dest);
 355         }
 356     }
 357 
 358     void and32(RegisterID op1, Address op2, RegisterID dest)
 359     {
 360         and32(op2, op1, dest);
 361     }
 362 
 363     void and32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 364     {
 365         move32IfNeeded(src, dest);
 366         and32(imm, dest);
 367     }
 368 
 369     void countLeadingZeros32(RegisterID src, RegisterID dst)
 370     {
 371         if (supportsLZCNT()) {
 372             m_assembler.lzcnt_rr(src, dst);
 373             return;
 374         }
 375         m_assembler.bsr_rr(src, dst);
 376         clz32AfterBsr(dst);
 377     }
 378 
 379     void countLeadingZeros32(Address src, RegisterID dst)
 380     {
 381         if (supportsLZCNT()) {
 382             m_assembler.lzcnt_mr(src.offset, src.base, dst);
 383             return;
 384         }
 385         m_assembler.bsr_mr(src.offset, src.base, dst);
 386         clz32AfterBsr(dst);
 387     }
 388 
 389     void countTrailingZeros32(RegisterID src, RegisterID dst)
 390     {
 391         if (supportsBMI1()) {
 392             m_assembler.tzcnt_rr(src, dst);
 393             return;
 394         }
 395         m_assembler.bsf_rr(src, dst);
 396         ctzAfterBsf&lt;32&gt;(dst);
 397     }
 398 
 399     void countPopulation32(Address src, RegisterID dst)
 400     {
 401         ASSERT(supportsCountPopulation());
 402         m_assembler.popcnt_mr(src.offset, src.base, dst);
 403     }
 404 
 405     void countPopulation32(RegisterID src, RegisterID dst)
 406     {
 407         ASSERT(supportsCountPopulation());
 408         m_assembler.popcnt_rr(src, dst);
 409     }
 410 
 411     void byteSwap32(RegisterID dst)
 412     {
 413         m_assembler.bswapl_r(dst);
 414     }
 415 
 416     void byteSwap16(RegisterID dst)
 417     {
 418         m_assembler.rolw_i8r(8, dst);
 419         zeroExtend16To32(dst, dst);
 420     }
 421 
 422 #if CPU(X86_64)
 423     void byteSwap64(RegisterID dst)
 424     {
 425         m_assembler.bswapq_r(dst);
 426     }
 427 #endif
 428 
 429     // Only used for testing purposes.
 430     void illegalInstruction()
 431     {
 432         m_assembler.illegalInstruction();
 433     }
 434 
 435     void lshift32(RegisterID shift_amount, RegisterID dest)
 436     {
 437         if (shift_amount == X86Registers::ecx)
 438             m_assembler.shll_CLr(dest);
 439         else {
 440             ASSERT(shift_amount != dest);
 441             // On x86 we can only shift by ecx; if asked to shift by another register we&#39;ll
 442             // need rejig the shift amount into ecx first, and restore the registers afterwards.
 443             // If we dest is ecx, then shift the swapped register!
 444             swap(shift_amount, X86Registers::ecx);
 445             m_assembler.shll_CLr(dest == X86Registers::ecx ? shift_amount : dest);
 446             swap(shift_amount, X86Registers::ecx);
 447         }
 448     }
 449 
 450     void lshift32(RegisterID src, RegisterID shift_amount, RegisterID dest)
 451     {
 452         ASSERT(shift_amount != dest);
 453 
 454         move32IfNeeded(src, dest);
 455         lshift32(shift_amount, dest);
 456     }
 457 
 458     void lshift32(TrustedImm32 imm, RegisterID dest)
 459     {
 460         m_assembler.shll_i8r(imm.m_value, dest);
 461     }
 462 
 463     void lshift32(RegisterID src, TrustedImm32 imm, RegisterID dest)
 464     {
 465         move32IfNeeded(src, dest);
 466         lshift32(imm, dest);
 467     }
 468 
 469     void mul32(RegisterID src, RegisterID dest)
 470     {
 471         m_assembler.imull_rr(src, dest);
 472     }
 473 
 474     void mul32(RegisterID src1, RegisterID src2, RegisterID dest)
 475     {
 476         if (src2 == dest) {
 477             m_assembler.imull_rr(src1, dest);
 478             return;
 479         }
 480         move32IfNeeded(src1, dest);
 481         m_assembler.imull_rr(src2, dest);
 482     }
 483 
 484     void mul32(Address src, RegisterID dest)
 485     {
 486         m_assembler.imull_mr(src.offset, src.base, dest);
 487     }
 488 
 489     void mul32(Address op1, RegisterID op2, RegisterID dest)
 490     {
 491         if (op2 == dest)
 492             mul32(op1, dest);
 493         else if (op1.base == dest) {
 494             load32(op1, dest);
 495             mul32(op2, dest);
 496         } else {
 497             zeroExtend32ToPtr(op2, dest);
 498             mul32(op1, dest);
 499         }
 500     }
 501 
 502     void mul32(RegisterID src1, Address src2, RegisterID dest)
 503     {
 504         mul32(src2, src1, dest);
 505     }
 506 
 507     void mul32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 508     {
 509         m_assembler.imull_i32r(src, imm.m_value, dest);
 510     }
 511 
 512     void x86ConvertToDoubleWord32()
 513     {
 514         m_assembler.cdq();
 515     }
 516 
 517     void x86ConvertToDoubleWord32(RegisterID eax, RegisterID edx)
 518     {
 519         ASSERT_UNUSED(eax, eax == X86Registers::eax);
 520         ASSERT_UNUSED(edx, edx == X86Registers::edx);
 521         x86ConvertToDoubleWord32();
 522     }
 523 
 524     void x86Div32(RegisterID denominator)
 525     {
 526         m_assembler.idivl_r(denominator);
 527     }
 528 
 529     void x86Div32(RegisterID eax, RegisterID edx, RegisterID denominator)
 530     {
 531         ASSERT_UNUSED(eax, eax == X86Registers::eax);
 532         ASSERT_UNUSED(edx, edx == X86Registers::edx);
 533         x86Div32(denominator);
 534     }
 535 
 536     void x86UDiv32(RegisterID denominator)
 537     {
 538         m_assembler.divl_r(denominator);
 539     }
 540 
 541     void x86UDiv32(RegisterID eax, RegisterID edx, RegisterID denominator)
 542     {
 543         ASSERT_UNUSED(eax, eax == X86Registers::eax);
 544         ASSERT_UNUSED(edx, edx == X86Registers::edx);
 545         x86UDiv32(denominator);
 546     }
 547 
 548     void neg32(RegisterID srcDest)
 549     {
 550         m_assembler.negl_r(srcDest);
 551     }
 552 
 553     void neg32(RegisterID src, RegisterID dest)
 554     {
 555         move32IfNeeded(src, dest);
 556         m_assembler.negl_r(dest);
 557     }
 558 
 559     void neg32(Address srcDest)
 560     {
 561         m_assembler.negl_m(srcDest.offset, srcDest.base);
 562     }
 563 
 564     void neg32(BaseIndex srcDest)
 565     {
 566         m_assembler.negl_m(srcDest.offset, srcDest.base, srcDest.index, srcDest.scale);
 567     }
 568 
 569     void neg16(Address srcDest)
 570     {
 571         m_assembler.negw_m(srcDest.offset, srcDest.base);
 572     }
 573 
 574     void neg16(BaseIndex srcDest)
 575     {
 576         m_assembler.negw_m(srcDest.offset, srcDest.base, srcDest.index, srcDest.scale);
 577     }
 578 
 579     void neg8(Address srcDest)
 580     {
 581         m_assembler.negb_m(srcDest.offset, srcDest.base);
 582     }
 583 
 584     void neg8(BaseIndex srcDest)
 585     {
 586         m_assembler.negb_m(srcDest.offset, srcDest.base, srcDest.index, srcDest.scale);
 587     }
 588 
 589     void or32(RegisterID src, RegisterID dest)
 590     {
 591         m_assembler.orl_rr(src, dest);
 592     }
 593 
 594     void or32(TrustedImm32 imm, RegisterID dest)
 595     {
 596         m_assembler.orl_ir(imm.m_value, dest);
 597     }
 598 
 599     void or32(RegisterID src, Address dest)
 600     {
 601         m_assembler.orl_rm(src, dest.offset, dest.base);
 602     }
 603 
 604     void or32(RegisterID src, BaseIndex dest)
 605     {
 606         m_assembler.orl_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 607     }
 608 
 609     void or16(RegisterID src, Address dest)
 610     {
 611         m_assembler.orw_rm(src, dest.offset, dest.base);
 612     }
 613 
 614     void or16(RegisterID src, BaseIndex dest)
 615     {
 616         m_assembler.orw_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 617     }
 618 
 619     void or8(RegisterID src, Address dest)
 620     {
 621         m_assembler.orb_rm(src, dest.offset, dest.base);
 622     }
 623 
 624     void or8(RegisterID src, BaseIndex dest)
 625     {
 626         m_assembler.orb_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 627     }
 628 
 629     void or32(Address src, RegisterID dest)
 630     {
 631         m_assembler.orl_mr(src.offset, src.base, dest);
 632     }
 633 
 634     void or32(BaseIndex src, RegisterID dest)
 635     {
 636         m_assembler.orl_mr(src.offset, src.base, src.index, src.scale, dest);
 637     }
 638 
 639     void or32(TrustedImm32 imm, Address address)
 640     {
 641         m_assembler.orl_im(imm.m_value, address.offset, address.base);
 642     }
 643 
 644     void or32(TrustedImm32 imm, BaseIndex address)
 645     {
 646         m_assembler.orl_im(imm.m_value, address.offset, address.base, address.index, address.scale);
 647     }
 648 
 649     void or16(TrustedImm32 imm, Address address)
 650     {
 651         m_assembler.orw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base);
 652     }
 653 
 654     void or16(TrustedImm32 imm, BaseIndex address)
 655     {
 656         m_assembler.orw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
 657     }
 658 
 659     void or8(TrustedImm32 imm, Address address)
 660     {
 661         m_assembler.orb_im(static_cast&lt;int8_t&gt;(imm.m_value), address.offset, address.base);
 662     }
 663 
 664     void or8(TrustedImm32 imm, BaseIndex address)
 665     {
 666         m_assembler.orb_im(static_cast&lt;int8_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
 667     }
 668 
 669     void or32(RegisterID op1, RegisterID op2, RegisterID dest)
 670     {
 671         if (op1 == op2)
 672             zeroExtend32ToPtr(op1, dest);
 673         else if (op1 == dest)
 674             or32(op2, dest);
 675         else {
 676             move32IfNeeded(op2, dest);
 677             or32(op1, dest);
 678         }
 679     }
 680 
 681     void or32(Address op1, RegisterID op2, RegisterID dest)
 682     {
 683         if (op2 == dest)
 684             or32(op1, dest);
 685         else if (op1.base == dest) {
 686             load32(op1, dest);
 687             or32(op2, dest);
 688         } else {
 689             zeroExtend32ToPtr(op2, dest);
 690             or32(op1, dest);
 691         }
 692     }
 693 
 694     void or32(RegisterID op1, Address op2, RegisterID dest)
 695     {
 696         or32(op2, op1, dest);
 697     }
 698 
 699     void or32(TrustedImm32 imm, RegisterID src, RegisterID dest)
 700     {
 701         move32IfNeeded(src, dest);
 702         or32(imm, dest);
 703     }
 704 
 705     void rshift32(RegisterID shift_amount, RegisterID dest)
 706     {
 707         if (shift_amount == X86Registers::ecx)
 708             m_assembler.sarl_CLr(dest);
 709         else {
 710             ASSERT(shift_amount != dest);
 711 
 712             // On x86 we can only shift by ecx; if asked to shift by another register we&#39;ll
 713             // need rejig the shift amount into ecx first, and restore the registers afterwards.
 714             // If we dest is ecx, then shift the swapped register!
 715             swap(shift_amount, X86Registers::ecx);
 716             m_assembler.sarl_CLr(dest == X86Registers::ecx ? shift_amount : dest);
 717             swap(shift_amount, X86Registers::ecx);
 718         }
 719     }
 720 
 721     void rshift32(RegisterID src, RegisterID shift_amount, RegisterID dest)
 722     {
 723         ASSERT(shift_amount != dest);
 724 
 725         move32IfNeeded(src, dest);
 726         rshift32(shift_amount, dest);
 727     }
 728 
 729     void rshift32(TrustedImm32 imm, RegisterID dest)
 730     {
 731         m_assembler.sarl_i8r(imm.m_value, dest);
 732     }
 733 
 734     void rshift32(RegisterID src, TrustedImm32 imm, RegisterID dest)
 735     {
 736         move32IfNeeded(src, dest);
 737         rshift32(imm, dest);
 738     }
 739 
 740     void urshift32(RegisterID shift_amount, RegisterID dest)
 741     {
 742         if (shift_amount == X86Registers::ecx)
 743             m_assembler.shrl_CLr(dest);
 744         else {
 745             ASSERT(shift_amount != dest);
 746 
 747             // On x86 we can only shift by ecx; if asked to shift by another register we&#39;ll
 748             // need rejig the shift amount into ecx first, and restore the registers afterwards.
 749             // If we dest is ecx, then shift the swapped register!
 750             swap(shift_amount, X86Registers::ecx);
 751             m_assembler.shrl_CLr(dest == X86Registers::ecx ? shift_amount : dest);
 752             swap(shift_amount, X86Registers::ecx);
 753         }
 754     }
 755 
 756     void urshift32(RegisterID src, RegisterID shift_amount, RegisterID dest)
 757     {
 758         ASSERT(shift_amount != dest);
 759 
 760         move32IfNeeded(src, dest);
 761         urshift32(shift_amount, dest);
 762     }
 763 
 764     void urshift32(TrustedImm32 imm, RegisterID dest)
 765     {
 766         m_assembler.shrl_i8r(imm.m_value, dest);
 767     }
 768 
 769     void urshift32(RegisterID src, TrustedImm32 imm, RegisterID dest)
 770     {
 771         move32IfNeeded(src, dest);
 772         urshift32(imm, dest);
 773     }
 774 
 775     void rotateRight32(TrustedImm32 imm, RegisterID dest)
 776     {
 777         m_assembler.rorl_i8r(imm.m_value, dest);
 778     }
 779 
 780     void rotateRight32(RegisterID src, RegisterID dest)
 781     {
 782         if (src == X86Registers::ecx)
 783             m_assembler.rorl_CLr(dest);
 784         else {
 785             ASSERT(src != dest);
 786 
 787             // Can only rotate by ecx, so we do some swapping if we see anything else.
 788             swap(src, X86Registers::ecx);
 789             m_assembler.rorl_CLr(dest == X86Registers::ecx ? src : dest);
 790             swap(src, X86Registers::ecx);
 791         }
 792     }
 793 
 794     void rotateLeft32(TrustedImm32 imm, RegisterID dest)
 795     {
 796         m_assembler.roll_i8r(imm.m_value, dest);
 797     }
 798 
 799     void rotateLeft32(RegisterID src, RegisterID dest)
 800     {
 801         if (src == X86Registers::ecx)
 802             m_assembler.roll_CLr(dest);
 803         else {
 804             ASSERT(src != dest);
 805 
 806             // Can only rotate by ecx, so we do some swapping if we see anything else.
 807             swap(src, X86Registers::ecx);
 808             m_assembler.roll_CLr(dest == X86Registers::ecx ? src : dest);
 809             swap(src, X86Registers::ecx);
 810         }
 811     }
 812 
 813     void sub32(RegisterID src, RegisterID dest)
 814     {
 815         m_assembler.subl_rr(src, dest);
 816     }
 817 
 818     void sub32(RegisterID left, RegisterID right, RegisterID dest)
 819     {
 820         if (dest == right) {
 821             neg32(dest);
 822             add32(left, dest);
 823             return;
 824         }
 825         move(left, dest);
 826         sub32(right, dest);
 827     }
 828 
 829     void sub32(TrustedImm32 imm, RegisterID dest)
 830     {
 831         if (imm.m_value == 1)
 832             m_assembler.dec_r(dest);
 833         else
 834             m_assembler.subl_ir(imm.m_value, dest);
 835     }
 836 
 837     void sub32(TrustedImm32 imm, Address address)
 838     {
 839         m_assembler.subl_im(imm.m_value, address.offset, address.base);
 840     }
 841 
 842     void sub16(TrustedImm32 imm, Address address)
 843     {
 844         m_assembler.subw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base);
 845     }
 846 
 847     void sub8(TrustedImm32 imm, Address address)
 848     {
 849         m_assembler.subb_im(static_cast&lt;int8_t&gt;(imm.m_value), address.offset, address.base);
 850     }
 851 
 852     void sub32(TrustedImm32 imm, BaseIndex address)
 853     {
 854         m_assembler.subl_im(imm.m_value, address.offset, address.base, address.index, address.scale);
 855     }
 856 
 857     void sub16(TrustedImm32 imm, BaseIndex address)
 858     {
 859         m_assembler.subw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
 860     }
 861 
 862     void sub8(TrustedImm32 imm, BaseIndex address)
 863     {
 864         m_assembler.subb_im(static_cast&lt;int8_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
 865     }
 866 
 867     void sub32(Address src, RegisterID dest)
 868     {
 869         m_assembler.subl_mr(src.offset, src.base, dest);
 870     }
 871 
 872     void sub32(BaseIndex src, RegisterID dest)
 873     {
 874         m_assembler.subl_mr(src.offset, src.base, src.index, src.scale, dest);
 875     }
 876 
 877     void sub32(RegisterID src, Address dest)
 878     {
 879         m_assembler.subl_rm(src, dest.offset, dest.base);
 880     }
 881 
 882     void sub16(RegisterID src, Address dest)
 883     {
 884         m_assembler.subw_rm(src, dest.offset, dest.base);
 885     }
 886 
 887     void sub8(RegisterID src, Address dest)
 888     {
 889         m_assembler.subb_rm(src, dest.offset, dest.base);
 890     }
 891 
 892     void sub32(RegisterID src, BaseIndex dest)
 893     {
 894         m_assembler.subl_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 895     }
 896 
 897     void sub16(RegisterID src, BaseIndex dest)
 898     {
 899         m_assembler.subw_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 900     }
 901 
 902     void sub8(RegisterID src, BaseIndex dest)
 903     {
 904         m_assembler.subb_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 905     }
 906 
 907     void xor32(RegisterID src, RegisterID dest)
 908     {
 909         m_assembler.xorl_rr(src, dest);
 910     }
 911 
 912     void xor32(TrustedImm32 imm, Address dest)
 913     {
 914         if (imm.m_value == -1)
 915             m_assembler.notl_m(dest.offset, dest.base);
 916         else
 917             m_assembler.xorl_im(imm.m_value, dest.offset, dest.base);
 918     }
 919 
 920     void xor32(TrustedImm32 imm, BaseIndex dest)
 921     {
 922         if (imm.m_value == -1)
 923             m_assembler.notl_m(dest.offset, dest.base, dest.index, dest.scale);
 924         else
 925             m_assembler.xorl_im(imm.m_value, dest.offset, dest.base, dest.index, dest.scale);
 926     }
 927 
 928     void xor16(TrustedImm32 imm, Address dest)
 929     {
 930         imm.m_value = static_cast&lt;int16_t&gt;(imm.m_value);
 931         if (imm.m_value == -1)
 932             m_assembler.notw_m(dest.offset, dest.base);
 933         else
 934             m_assembler.xorw_im(imm.m_value, dest.offset, dest.base);
 935     }
 936 
 937     void xor16(TrustedImm32 imm, BaseIndex dest)
 938     {
 939         imm.m_value = static_cast&lt;int16_t&gt;(imm.m_value);
 940         if (imm.m_value == -1)
 941             m_assembler.notw_m(dest.offset, dest.base, dest.index, dest.scale);
 942         else
 943             m_assembler.xorw_im(imm.m_value, dest.offset, dest.base, dest.index, dest.scale);
 944     }
 945 
 946     void xor8(TrustedImm32 imm, Address dest)
 947     {
 948         imm.m_value = static_cast&lt;int8_t&gt;(imm.m_value);
 949         if (imm.m_value == -1)
 950             m_assembler.notb_m(dest.offset, dest.base);
 951         else
 952             m_assembler.xorb_im(imm.m_value, dest.offset, dest.base);
 953     }
 954 
 955     void xor8(TrustedImm32 imm, BaseIndex dest)
 956     {
 957         imm.m_value = static_cast&lt;int8_t&gt;(imm.m_value);
 958         if (imm.m_value == -1)
 959             m_assembler.notb_m(dest.offset, dest.base, dest.index, dest.scale);
 960         else
 961             m_assembler.xorb_im(imm.m_value, dest.offset, dest.base, dest.index, dest.scale);
 962     }
 963 
 964     void xor32(TrustedImm32 imm, RegisterID dest)
 965     {
 966         if (imm.m_value == -1)
 967             m_assembler.notl_r(dest);
 968         else
 969             m_assembler.xorl_ir(imm.m_value, dest);
 970     }
 971 
 972     void xor32(RegisterID src, Address dest)
 973     {
 974         m_assembler.xorl_rm(src, dest.offset, dest.base);
 975     }
 976 
 977     void xor32(RegisterID src, BaseIndex dest)
 978     {
 979         m_assembler.xorl_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 980     }
 981 
 982     void xor16(RegisterID src, Address dest)
 983     {
 984         m_assembler.xorw_rm(src, dest.offset, dest.base);
 985     }
 986 
 987     void xor16(RegisterID src, BaseIndex dest)
 988     {
 989         m_assembler.xorw_rm(src, dest.offset, dest.base, dest.index, dest.scale);
 990     }
 991 
 992     void xor8(RegisterID src, Address dest)
 993     {
 994         m_assembler.xorb_rm(src, dest.offset, dest.base);
 995     }
 996 
 997     void xor8(RegisterID src, BaseIndex dest)
 998     {
 999         m_assembler.xorb_rm(src, dest.offset, dest.base, dest.index, dest.scale);
1000     }
1001 
1002     void xor32(Address src, RegisterID dest)
1003     {
1004         m_assembler.xorl_mr(src.offset, src.base, dest);
1005     }
1006 
1007     void xor32(BaseIndex src, RegisterID dest)
1008     {
1009         m_assembler.xorl_mr(src.offset, src.base, src.index, src.scale, dest);
1010     }
1011 
1012     void xor32(RegisterID op1, RegisterID op2, RegisterID dest)
1013     {
1014         if (op1 == op2)
1015             move(TrustedImm32(0), dest);
1016         else if (op1 == dest)
1017             xor32(op2, dest);
1018         else {
1019             move32IfNeeded(op2, dest);
1020             xor32(op1, dest);
1021         }
1022     }
1023 
1024     void xor32(Address op1, RegisterID op2, RegisterID dest)
1025     {
1026         if (op2 == dest)
1027             xor32(op1, dest);
1028         else if (op1.base == dest) {
1029             load32(op1, dest);
1030             xor32(op2, dest);
1031         } else {
1032             zeroExtend32ToPtr(op2, dest);
1033             xor32(op1, dest);
1034         }
1035     }
1036 
1037     void xor32(RegisterID op1, Address op2, RegisterID dest)
1038     {
1039         xor32(op2, op1, dest);
1040     }
1041 
1042     void xor32(TrustedImm32 imm, RegisterID src, RegisterID dest)
1043     {
1044         move32IfNeeded(src, dest);
1045         xor32(imm, dest);
1046     }
1047 
1048     void not32(RegisterID srcDest)
1049     {
1050         m_assembler.notl_r(srcDest);
1051     }
1052 
1053     void not32(Address dest)
1054     {
1055         m_assembler.notl_m(dest.offset, dest.base);
1056     }
1057 
1058     void not32(BaseIndex dest)
1059     {
1060         m_assembler.notl_m(dest.offset, dest.base, dest.index, dest.scale);
1061     }
1062 
1063     void not16(Address dest)
1064     {
1065         m_assembler.notw_m(dest.offset, dest.base);
1066     }
1067 
1068     void not16(BaseIndex dest)
1069     {
1070         m_assembler.notw_m(dest.offset, dest.base, dest.index, dest.scale);
1071     }
1072 
1073     void not8(Address dest)
1074     {
1075         m_assembler.notb_m(dest.offset, dest.base);
1076     }
1077 
1078     void not8(BaseIndex dest)
1079     {
1080         m_assembler.notb_m(dest.offset, dest.base, dest.index, dest.scale);
1081     }
1082 
1083     void sqrtDouble(FPRegisterID src, FPRegisterID dst)
1084     {
1085         m_assembler.sqrtsd_rr(src, dst);
1086     }
1087 
1088     void sqrtDouble(Address src, FPRegisterID dst)
1089     {
1090         m_assembler.sqrtsd_mr(src.offset, src.base, dst);
1091     }
1092 
1093     void sqrtFloat(FPRegisterID src, FPRegisterID dst)
1094     {
1095         m_assembler.sqrtss_rr(src, dst);
1096     }
1097 
1098     void sqrtFloat(Address src, FPRegisterID dst)
1099     {
1100         m_assembler.sqrtss_mr(src.offset, src.base, dst);
1101     }
1102 
1103     void absDouble(FPRegisterID src, FPRegisterID dst)
1104     {
1105         ASSERT(src != dst);
1106         static const double negativeZeroConstant = -0.0;
1107         loadDouble(TrustedImmPtr(&amp;negativeZeroConstant), dst);
1108         m_assembler.andnpd_rr(src, dst);
1109     }
1110 
1111     void negateDouble(FPRegisterID src, FPRegisterID dst)
1112     {
1113         ASSERT(src != dst);
1114         static const double negativeZeroConstant = -0.0;
1115         loadDouble(TrustedImmPtr(&amp;negativeZeroConstant), dst);
1116         m_assembler.xorpd_rr(src, dst);
1117     }
1118 
1119     void ceilDouble(FPRegisterID src, FPRegisterID dst)
1120     {
1121         m_assembler.roundsd_rr(src, dst, X86Assembler::RoundingType::TowardInfiniti);
1122     }
1123 
1124     void ceilDouble(Address src, FPRegisterID dst)
1125     {
1126         m_assembler.roundsd_mr(src.offset, src.base, dst, X86Assembler::RoundingType::TowardInfiniti);
1127     }
1128 
1129     void ceilFloat(FPRegisterID src, FPRegisterID dst)
1130     {
1131         m_assembler.roundss_rr(src, dst, X86Assembler::RoundingType::TowardInfiniti);
1132     }
1133 
1134     void ceilFloat(Address src, FPRegisterID dst)
1135     {
1136         m_assembler.roundss_mr(src.offset, src.base, dst, X86Assembler::RoundingType::TowardInfiniti);
1137     }
1138 
1139     void floorDouble(FPRegisterID src, FPRegisterID dst)
1140     {
1141         m_assembler.roundsd_rr(src, dst, X86Assembler::RoundingType::TowardNegativeInfiniti);
1142     }
1143 
1144     void floorDouble(Address src, FPRegisterID dst)
1145     {
1146         m_assembler.roundsd_mr(src.offset, src.base, dst, X86Assembler::RoundingType::TowardNegativeInfiniti);
1147     }
1148 
1149     void floorFloat(FPRegisterID src, FPRegisterID dst)
1150     {
1151         m_assembler.roundss_rr(src, dst, X86Assembler::RoundingType::TowardNegativeInfiniti);
1152     }
1153 
1154     void floorFloat(Address src, FPRegisterID dst)
1155     {
1156         m_assembler.roundss_mr(src.offset, src.base, dst, X86Assembler::RoundingType::TowardNegativeInfiniti);
1157     }
1158 
1159     void roundTowardNearestIntDouble(FPRegisterID src, FPRegisterID dst)
1160     {
1161         m_assembler.roundsd_rr(src, dst, X86Assembler::RoundingType::ToNearestWithTiesToEven);
1162     }
1163 
1164     void roundTowardNearestIntFloat(FPRegisterID src, FPRegisterID dst)
1165     {
1166         m_assembler.roundss_rr(src, dst, X86Assembler::RoundingType::ToNearestWithTiesToEven);
1167     }
1168 
1169     void roundTowardZeroDouble(FPRegisterID src, FPRegisterID dst)
1170     {
1171         m_assembler.roundsd_rr(src, dst, X86Assembler::RoundingType::TowardZero);
1172     }
1173 
1174     void roundTowardZeroDouble(Address src, FPRegisterID dst)
1175     {
1176         m_assembler.roundsd_mr(src.offset, src.base, dst, X86Assembler::RoundingType::TowardZero);
1177     }
1178 
1179     void roundTowardZeroFloat(FPRegisterID src, FPRegisterID dst)
1180     {
1181         m_assembler.roundss_rr(src, dst, X86Assembler::RoundingType::TowardZero);
1182     }
1183 
1184     void roundTowardZeroFloat(Address src, FPRegisterID dst)
1185     {
1186         m_assembler.roundss_mr(src.offset, src.base, dst, X86Assembler::RoundingType::TowardZero);
1187     }
1188 
1189     // Memory access operations:
1190     //
1191     // Loads are of the form load(address, destination) and stores of the form
1192     // store(source, address).  The source for a store may be an TrustedImm32.  Address
1193     // operand objects to loads and store will be implicitly constructed if a
1194     // register is passed.
1195 
1196     void load32(ImplicitAddress address, RegisterID dest)
1197     {
1198         m_assembler.movl_mr(address.offset, address.base, dest);
1199     }
1200 
1201     void load32(BaseIndex address, RegisterID dest)
1202     {
1203         m_assembler.movl_mr(address.offset, address.base, address.index, address.scale, dest);
1204     }
1205 
1206     void load32WithUnalignedHalfWords(BaseIndex address, RegisterID dest)
1207     {
1208         load32(address, dest);
1209     }
1210 
1211     void load16Unaligned(ImplicitAddress address, RegisterID dest)
1212     {
1213         load16(address, dest);
1214     }
1215 
1216     void load16Unaligned(BaseIndex address, RegisterID dest)
1217     {
1218         load16(address, dest);
1219     }
1220 
1221     DataLabel32 load32WithAddressOffsetPatch(Address address, RegisterID dest)
1222     {
1223         padBeforePatch();
1224         m_assembler.movl_mr_disp32(address.offset, address.base, dest);
1225         return DataLabel32(this);
1226     }
1227 
1228     DataLabelCompact load32WithCompactAddressOffsetPatch(Address address, RegisterID dest)
1229     {
1230         padBeforePatch();
1231         m_assembler.movl_mr_disp8(address.offset, address.base, dest);
1232         return DataLabelCompact(this);
1233     }
1234 
1235     template&lt;PtrTag tag&gt;
1236     static void repatchCompact(CodeLocationDataLabelCompact&lt;tag&gt; dataLabelCompact, int32_t value)
1237     {
1238         ASSERT(isCompactPtrAlignedAddressOffset(value));
1239         AssemblerType_T::repatchCompact(dataLabelCompact.dataLocation(), value);
1240     }
1241 
1242     DataLabelCompact loadCompactWithAddressOffsetPatch(Address address, RegisterID dest)
1243     {
1244         padBeforePatch();
1245         m_assembler.movl_mr_disp8(address.offset, address.base, dest);
1246         return DataLabelCompact(this);
1247     }
1248 
1249     void load8(BaseIndex address, RegisterID dest)
1250     {
1251         m_assembler.movzbl_mr(address.offset, address.base, address.index, address.scale, dest);
1252     }
1253 
1254     void load8(ImplicitAddress address, RegisterID dest)
1255     {
1256         m_assembler.movzbl_mr(address.offset, address.base, dest);
1257     }
1258 
1259     void load8SignedExtendTo32(BaseIndex address, RegisterID dest)
1260     {
1261         m_assembler.movsbl_mr(address.offset, address.base, address.index, address.scale, dest);
1262     }
1263 
1264     void load8SignedExtendTo32(ImplicitAddress address, RegisterID dest)
1265     {
1266         m_assembler.movsbl_mr(address.offset, address.base, dest);
1267     }
1268 
1269     void zeroExtend8To32(RegisterID src, RegisterID dest)
1270     {
1271         m_assembler.movzbl_rr(src, dest);
1272     }
1273 
1274     void signExtend8To32(RegisterID src, RegisterID dest)
1275     {
1276         m_assembler.movsbl_rr(src, dest);
1277     }
1278 
1279     void load16(ImplicitAddress address, RegisterID dest)
1280     {
1281         m_assembler.movzwl_mr(address.offset, address.base, dest);
1282     }
1283 
1284     void load16(BaseIndex address, RegisterID dest)
1285     {
1286         m_assembler.movzwl_mr(address.offset, address.base, address.index, address.scale, dest);
1287     }
1288 
1289     void load16(Address address, RegisterID dest)
1290     {
1291         m_assembler.movzwl_mr(address.offset, address.base, dest);
1292     }
1293 
1294     void load16SignedExtendTo32(BaseIndex address, RegisterID dest)
1295     {
1296         m_assembler.movswl_mr(address.offset, address.base, address.index, address.scale, dest);
1297     }
1298 
1299     void load16SignedExtendTo32(Address address, RegisterID dest)
1300     {
1301         m_assembler.movswl_mr(address.offset, address.base, dest);
1302     }
1303 
1304     void zeroExtend16To32(RegisterID src, RegisterID dest)
1305     {
1306         m_assembler.movzwl_rr(src, dest);
1307     }
1308 
1309     void signExtend16To32(RegisterID src, RegisterID dest)
1310     {
1311         m_assembler.movswl_rr(src, dest);
1312     }
1313 
1314     DataLabel32 store32WithAddressOffsetPatch(RegisterID src, Address address)
1315     {
1316         padBeforePatch();
1317         m_assembler.movl_rm_disp32(src, address.offset, address.base);
1318         return DataLabel32(this);
1319     }
1320 
1321     void store32(RegisterID src, ImplicitAddress address)
1322     {
1323         m_assembler.movl_rm(src, address.offset, address.base);
1324     }
1325 
1326     void store32(RegisterID src, BaseIndex address)
1327     {
1328         m_assembler.movl_rm(src, address.offset, address.base, address.index, address.scale);
1329     }
1330 
1331     void store32(TrustedImm32 imm, ImplicitAddress address)
1332     {
1333         m_assembler.movl_i32m(imm.m_value, address.offset, address.base);
1334     }
1335 
1336     void store32(TrustedImm32 imm, BaseIndex address)
1337     {
1338         m_assembler.movl_i32m(imm.m_value, address.offset, address.base, address.index, address.scale);
1339     }
1340 
1341     void storeZero32(ImplicitAddress address)
1342     {
1343         store32(TrustedImm32(0), address);
1344     }
1345 
1346     void storeZero32(BaseIndex address)
1347     {
1348         store32(TrustedImm32(0), address);
1349     }
1350 
1351     void storeZero16(ImplicitAddress address)
1352     {
1353         store16(TrustedImm32(0), address);
1354     }
1355 
1356     void storeZero16(BaseIndex address)
1357     {
1358         store16(TrustedImm32(0), address);
1359     }
1360 
1361     void store8(TrustedImm32 imm, Address address)
1362     {
1363         TrustedImm32 imm8(static_cast&lt;int8_t&gt;(imm.m_value));
1364         m_assembler.movb_i8m(imm8.m_value, address.offset, address.base);
1365     }
1366 
1367     void store8(TrustedImm32 imm, BaseIndex address)
1368     {
1369         TrustedImm32 imm8(static_cast&lt;int8_t&gt;(imm.m_value));
1370         m_assembler.movb_i8m(imm8.m_value, address.offset, address.base, address.index, address.scale);
1371     }
1372 
1373     static ALWAYS_INLINE RegisterID getUnusedRegister(BaseIndex address)
1374     {
1375         if (address.base != X86Registers::eax &amp;&amp; address.index != X86Registers::eax)
1376             return X86Registers::eax;
1377 
1378         if (address.base != X86Registers::ebx &amp;&amp; address.index != X86Registers::ebx)
1379             return X86Registers::ebx;
1380 
1381         ASSERT(address.base != X86Registers::ecx &amp;&amp; address.index != X86Registers::ecx);
1382         return X86Registers::ecx;
1383     }
1384 
1385     static ALWAYS_INLINE RegisterID getUnusedRegister(Address address)
1386     {
1387         if (address.base != X86Registers::eax)
1388             return X86Registers::eax;
1389 
1390         ASSERT(address.base != X86Registers::edx);
1391         return X86Registers::edx;
1392     }
1393 
1394     void store8(RegisterID src, BaseIndex address)
1395     {
1396 #if CPU(X86)
1397         // On 32-bit x86 we can only store from the first 4 registers;
1398         // esp..edi are mapped to the &#39;h&#39; registers!
1399         if (src &gt;= 4) {
1400             // Pick a temporary register.
1401             RegisterID temp = getUnusedRegister(address);
1402 
1403             // Swap to the temporary register to perform the store.
1404             swap(src, temp);
1405             m_assembler.movb_rm(temp, address.offset, address.base, address.index, address.scale);
1406             swap(src, temp);
1407             return;
1408         }
1409 #endif
1410         m_assembler.movb_rm(src, address.offset, address.base, address.index, address.scale);
1411     }
1412 
1413     void store8(RegisterID src, Address address)
1414     {
1415 #if CPU(X86)
1416         // On 32-bit x86 we can only store from the first 4 registers;
1417         // esp..edi are mapped to the &#39;h&#39; registers!
1418         if (src &gt;= 4) {
1419             // Pick a temporary register.
1420             RegisterID temp = getUnusedRegister(address);
1421 
1422             // Swap to the temporary register to perform the store.
1423             swap(src, temp);
1424             m_assembler.movb_rm(temp, address.offset, address.base);
1425             swap(src, temp);
1426             return;
1427         }
1428 #endif
1429         m_assembler.movb_rm(src, address.offset, address.base);
1430     }
1431 
1432     void store16(RegisterID src, BaseIndex address)
1433     {
1434         m_assembler.movw_rm(src, address.offset, address.base, address.index, address.scale);
1435     }
1436 
1437     void store16(RegisterID src, Address address)
1438     {
1439         m_assembler.movw_rm(src, address.offset, address.base);
1440     }
1441 
1442     void store16(TrustedImm32 imm, BaseIndex address)
1443     {
1444         m_assembler.movw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base, address.index, address.scale);
1445     }
1446 
1447     void store16(TrustedImm32 imm, ImplicitAddress address)
1448     {
1449         m_assembler.movw_im(static_cast&lt;int16_t&gt;(imm.m_value), address.offset, address.base);
1450     }
1451 
1452     // Floating-point operation:
1453     //
<a name="1" id="anc1"></a><span class="line-removed">1454     // Presently only supports SSE, not x87 floating point.</span>
<span class="line-removed">1455 </span>
1456     void moveDouble(FPRegisterID src, FPRegisterID dest)
1457     {
<a name="2" id="anc2"></a><span class="line-removed">1458         ASSERT(isSSE2Present());</span>
1459         if (src != dest)
1460             m_assembler.movaps_rr(src, dest);
1461     }
1462 
1463     void loadDouble(TrustedImmPtr address, FPRegisterID dest)
1464     {
1465 #if CPU(X86)
<a name="3" id="anc3"></a><span class="line-removed">1466         ASSERT(isSSE2Present());</span>
1467         m_assembler.movsd_mr(address.asPtr(), dest);
1468 #else
1469         move(address, scratchRegister());
1470         loadDouble(scratchRegister(), dest);
1471 #endif
1472     }
1473 
1474     void loadDouble(ImplicitAddress address, FPRegisterID dest)
1475     {
<a name="4" id="anc4"></a><span class="line-removed">1476         ASSERT(isSSE2Present());</span>
1477         m_assembler.movsd_mr(address.offset, address.base, dest);
1478     }
1479 
1480     void loadDouble(BaseIndex address, FPRegisterID dest)
1481     {
<a name="5" id="anc5"></a><span class="line-removed">1482         ASSERT(isSSE2Present());</span>
1483         m_assembler.movsd_mr(address.offset, address.base, address.index, address.scale, dest);
1484     }
1485 
1486     void loadFloat(TrustedImmPtr address, FPRegisterID dest)
1487     {
1488 #if CPU(X86)
<a name="6" id="anc6"></a><span class="line-removed">1489         ASSERT(isSSE2Present());</span>
1490         m_assembler.movss_mr(address.asPtr(), dest);
1491 #else
1492         move(address, scratchRegister());
1493         loadFloat(scratchRegister(), dest);
1494 #endif
1495     }
1496 
1497     void loadFloat(ImplicitAddress address, FPRegisterID dest)
1498     {
<a name="7" id="anc7"></a><span class="line-removed">1499         ASSERT(isSSE2Present());</span>
1500         m_assembler.movss_mr(address.offset, address.base, dest);
1501     }
1502 
1503     void loadFloat(BaseIndex address, FPRegisterID dest)
1504     {
<a name="8" id="anc8"></a><span class="line-removed">1505         ASSERT(isSSE2Present());</span>
1506         m_assembler.movss_mr(address.offset, address.base, address.index, address.scale, dest);
1507     }
1508 
1509     void storeDouble(FPRegisterID src, ImplicitAddress address)
1510     {
<a name="9" id="anc9"></a><span class="line-removed">1511         ASSERT(isSSE2Present());</span>
1512         m_assembler.movsd_rm(src, address.offset, address.base);
1513     }
1514 
1515     void storeDouble(FPRegisterID src, BaseIndex address)
1516     {
<a name="10" id="anc10"></a><span class="line-removed">1517         ASSERT(isSSE2Present());</span>
1518         m_assembler.movsd_rm(src, address.offset, address.base, address.index, address.scale);
1519     }
1520 
1521     void storeFloat(FPRegisterID src, ImplicitAddress address)
1522     {
<a name="11" id="anc11"></a><span class="line-removed">1523         ASSERT(isSSE2Present());</span>
1524         m_assembler.movss_rm(src, address.offset, address.base);
1525     }
1526 
1527     void storeFloat(FPRegisterID src, BaseIndex address)
1528     {
<a name="12" id="anc12"></a><span class="line-removed">1529         ASSERT(isSSE2Present());</span>
1530         m_assembler.movss_rm(src, address.offset, address.base, address.index, address.scale);
1531     }
1532 
1533     void convertDoubleToFloat(FPRegisterID src, FPRegisterID dst)
1534     {
<a name="13" id="anc13"></a><span class="line-removed">1535         ASSERT(isSSE2Present());</span>
1536         m_assembler.cvtsd2ss_rr(src, dst);
1537     }
1538 
1539     void convertDoubleToFloat(Address address, FPRegisterID dst)
1540     {
<a name="14" id="anc14"></a><span class="line-removed">1541         ASSERT(isSSE2Present());</span>
1542         m_assembler.cvtsd2ss_mr(address.offset, address.base, dst);
1543     }
1544 
1545     void convertFloatToDouble(FPRegisterID src, FPRegisterID dst)
1546     {
<a name="15" id="anc15"></a><span class="line-removed">1547         ASSERT(isSSE2Present());</span>
1548         m_assembler.cvtss2sd_rr(src, dst);
1549     }
1550 
1551     void convertFloatToDouble(Address address, FPRegisterID dst)
1552     {
<a name="16" id="anc16"></a><span class="line-removed">1553         ASSERT(isSSE2Present());</span>
1554         m_assembler.cvtss2sd_mr(address.offset, address.base, dst);
1555     }
1556 
1557     void addDouble(FPRegisterID src, FPRegisterID dest)
1558     {
1559         addDouble(src, dest, dest);
1560     }
1561 
1562     void addDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1563     {
1564         if (supportsAVX())
1565             m_assembler.vaddsd_rr(op1, op2, dest);
1566         else {
<a name="17" id="anc17"></a><span class="line-removed">1567             ASSERT(isSSE2Present());</span>
1568             if (op1 == dest)
1569                 m_assembler.addsd_rr(op2, dest);
1570             else {
1571                 moveDouble(op2, dest);
1572                 m_assembler.addsd_rr(op1, dest);
1573             }
1574         }
1575     }
1576 
1577     void addDouble(Address src, FPRegisterID dest)
1578     {
1579         addDouble(src, dest, dest);
1580     }
1581 
1582     void addDouble(Address op1, FPRegisterID op2, FPRegisterID dest)
1583     {
1584         if (supportsAVX())
1585             m_assembler.vaddsd_mr(op1.offset, op1.base, op2, dest);
1586         else {
<a name="18" id="anc18"></a><span class="line-removed">1587             ASSERT(isSSE2Present());</span>
1588             if (op2 == dest) {
1589                 m_assembler.addsd_mr(op1.offset, op1.base, dest);
1590                 return;
1591             }
1592 
1593             loadDouble(op1, dest);
1594             addDouble(op2, dest);
1595         }
1596     }
1597 
1598     void addDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1599     {
1600         addDouble(op2, op1, dest);
1601     }
1602 
1603     void addDouble(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1604     {
1605         if (supportsAVX())
1606             m_assembler.vaddsd_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1607         else {
<a name="19" id="anc19"></a><span class="line-removed">1608             ASSERT(isSSE2Present());</span>
1609             if (op2 == dest) {
1610                 m_assembler.addsd_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1611                 return;
1612             }
1613             loadDouble(op1, dest);
1614             addDouble(op2, dest);
1615         }
1616     }
1617 
1618     void addFloat(FPRegisterID src, FPRegisterID dest)
1619     {
1620         addFloat(src, dest, dest);
1621     }
1622 
1623     void addFloat(Address src, FPRegisterID dest)
1624     {
1625         addFloat(src, dest, dest);
1626     }
1627 
1628     void addFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1629     {
1630         if (supportsAVX())
1631             m_assembler.vaddss_rr(op1, op2, dest);
1632         else {
<a name="20" id="anc20"></a><span class="line-removed">1633             ASSERT(isSSE2Present());</span>
1634             if (op1 == dest)
1635                 m_assembler.addss_rr(op2, dest);
1636             else {
1637                 moveDouble(op2, dest);
1638                 m_assembler.addss_rr(op1, dest);
1639             }
1640         }
1641     }
1642 
1643     void addFloat(Address op1, FPRegisterID op2, FPRegisterID dest)
1644     {
1645         if (supportsAVX())
1646             m_assembler.vaddss_mr(op1.offset, op1.base, op2, dest);
1647         else {
<a name="21" id="anc21"></a><span class="line-removed">1648             ASSERT(isSSE2Present());</span>
1649             if (op2 == dest) {
1650                 m_assembler.addss_mr(op1.offset, op1.base, dest);
1651                 return;
1652             }
1653 
1654             loadFloat(op1, dest);
1655             addFloat(op2, dest);
1656         }
1657     }
1658 
1659     void addFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1660     {
1661         addFloat(op2, op1, dest);
1662     }
1663 
1664     void addFloat(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1665     {
1666         if (supportsAVX())
1667             m_assembler.vaddss_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1668         else {
<a name="22" id="anc22"></a><span class="line-removed">1669             ASSERT(isSSE2Present());</span>
1670             if (op2 == dest) {
1671                 m_assembler.addss_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1672                 return;
1673             }
1674             loadFloat(op1, dest);
1675             addFloat(op2, dest);
1676         }
1677     }
1678 
1679     void divDouble(FPRegisterID src, FPRegisterID dest)
1680     {
<a name="23" id="anc23"></a><span class="line-removed">1681         ASSERT(isSSE2Present());</span>
1682         m_assembler.divsd_rr(src, dest);
1683     }
1684 
1685     void divDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1686     {
1687         // B := A / B is invalid.
1688         ASSERT(op1 == dest || op2 != dest);
1689 
1690         moveDouble(op1, dest);
1691         divDouble(op2, dest);
1692     }
1693 
1694     void divDouble(Address src, FPRegisterID dest)
1695     {
<a name="24" id="anc24"></a><span class="line-removed">1696         ASSERT(isSSE2Present());</span>
1697         m_assembler.divsd_mr(src.offset, src.base, dest);
1698     }
1699 
1700     void divFloat(FPRegisterID src, FPRegisterID dest)
1701     {
<a name="25" id="anc25"></a><span class="line-removed">1702         ASSERT(isSSE2Present());</span>
1703         m_assembler.divss_rr(src, dest);
1704     }
1705 
1706     void divFloat(Address src, FPRegisterID dest)
1707     {
<a name="26" id="anc26"></a><span class="line-removed">1708         ASSERT(isSSE2Present());</span>
1709         m_assembler.divss_mr(src.offset, src.base, dest);
1710     }
1711 
1712     void subDouble(FPRegisterID src, FPRegisterID dest)
1713     {
1714         subDouble(dest, src, dest);
1715     }
1716 
1717     void subDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1718     {
1719         if (supportsAVX())
1720             m_assembler.vsubsd_rr(op1, op2, dest);
1721         else {
<a name="27" id="anc27"></a><span class="line-removed">1722             ASSERT(isSSE2Present());</span>
<span class="line-removed">1723 </span>
1724             // B := A - B is invalid.
1725             ASSERT(op1 == dest || op2 != dest);
1726             moveDouble(op1, dest);
1727             m_assembler.subsd_rr(op2, dest);
1728         }
1729     }
1730 
1731     void subDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1732     {
1733         if (supportsAVX())
1734             m_assembler.vsubsd_mr(op1, op2.offset, op2.base, dest);
1735         else {
1736             moveDouble(op1, dest);
1737             m_assembler.subsd_mr(op2.offset, op2.base, dest);
1738         }
1739     }
1740 
1741     void subDouble(FPRegisterID op1, BaseIndex op2, FPRegisterID dest)
1742     {
1743         if (supportsAVX())
1744             m_assembler.vsubsd_mr(op1, op2.offset, op2.base, op2.index, op2.scale, dest);
1745         else {
1746             moveDouble(op1, dest);
1747             m_assembler.subsd_mr(op2.offset, op2.base, op2.index, op2.scale, dest);
1748         }
1749     }
1750 
1751     void subDouble(Address src, FPRegisterID dest)
1752     {
1753         subDouble(dest, src, dest);
1754     }
1755 
1756     void subFloat(FPRegisterID src, FPRegisterID dest)
1757     {
1758         subFloat(dest, src, dest);
1759     }
1760 
1761     void subFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1762     {
1763         if (supportsAVX())
1764             m_assembler.vsubss_rr(op1, op2, dest);
1765         else {
<a name="28" id="anc28"></a><span class="line-removed">1766             ASSERT(isSSE2Present());</span>
1767             // B := A - B is invalid.
1768             ASSERT(op1 == dest || op2 != dest);
1769             moveDouble(op1, dest);
1770             m_assembler.subss_rr(op2, dest);
1771         }
1772     }
1773 
1774     void subFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1775     {
1776         if (supportsAVX())
1777             m_assembler.vsubss_mr(op1, op2.offset, op2.base, dest);
1778         else {
1779             moveDouble(op1, dest);
1780             m_assembler.subss_mr(op2.offset, op2.base, dest);
1781         }
1782     }
1783 
1784     void subFloat(FPRegisterID op1, BaseIndex op2, FPRegisterID dest)
1785     {
1786         if (supportsAVX())
1787             m_assembler.vsubss_mr(op1, op2.offset, op2.base, op2.index, op2.scale, dest);
1788         else {
1789             moveDouble(op1, dest);
1790             m_assembler.subss_mr(op2.offset, op2.base, op2.index, op2.scale, dest);
1791         }
1792     }
1793 
1794     void subFloat(Address src, FPRegisterID dest)
1795     {
1796         subFloat(dest, src, dest);
1797     }
1798 
1799     void mulDouble(FPRegisterID src, FPRegisterID dest)
1800     {
1801         mulDouble(src, dest, dest);
1802     }
1803 
1804     void mulDouble(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1805     {
1806         if (supportsAVX())
1807             m_assembler.vmulsd_rr(op1, op2, dest);
1808         else {
<a name="29" id="anc29"></a><span class="line-removed">1809             ASSERT(isSSE2Present());</span>
1810             if (op1 == dest)
1811                 m_assembler.mulsd_rr(op2, dest);
1812             else {
1813                 moveDouble(op2, dest);
1814                 m_assembler.mulsd_rr(op1, dest);
1815             }
1816         }
1817     }
1818 
1819     void mulDouble(Address src, FPRegisterID dest)
1820     {
1821         mulDouble(src, dest, dest);
1822     }
1823 
1824     void mulDouble(Address op1, FPRegisterID op2, FPRegisterID dest)
1825     {
1826         if (supportsAVX())
1827             m_assembler.vmulsd_mr(op1.offset, op1.base, op2, dest);
1828         else {
<a name="30" id="anc30"></a><span class="line-removed">1829             ASSERT(isSSE2Present());</span>
1830             if (op2 == dest) {
1831                 m_assembler.mulsd_mr(op1.offset, op1.base, dest);
1832                 return;
1833             }
1834             loadDouble(op1, dest);
1835             mulDouble(op2, dest);
1836         }
1837     }
1838 
1839     void mulDouble(FPRegisterID op1, Address op2, FPRegisterID dest)
1840     {
1841         return mulDouble(op2, op1, dest);
1842     }
1843 
1844     void mulDouble(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1845     {
1846         if (supportsAVX())
1847             m_assembler.vmulsd_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1848         else {
<a name="31" id="anc31"></a><span class="line-removed">1849             ASSERT(isSSE2Present());</span>
1850             if (op2 == dest) {
1851                 m_assembler.mulsd_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1852                 return;
1853             }
1854             loadDouble(op1, dest);
1855             mulDouble(op2, dest);
1856         }
1857     }
1858 
1859     void mulFloat(FPRegisterID src, FPRegisterID dest)
1860     {
1861         mulFloat(src, dest, dest);
1862     }
1863 
1864     void mulFloat(Address src, FPRegisterID dest)
1865     {
1866         mulFloat(src, dest, dest);
1867     }
1868 
1869     void mulFloat(FPRegisterID op1, FPRegisterID op2, FPRegisterID dest)
1870     {
1871         if (supportsAVX())
1872             m_assembler.vmulss_rr(op1, op2, dest);
1873         else {
<a name="32" id="anc32"></a><span class="line-removed">1874             ASSERT(isSSE2Present());</span>
1875             if (op1 == dest)
1876                 m_assembler.mulss_rr(op2, dest);
1877             else {
1878                 moveDouble(op2, dest);
1879                 m_assembler.mulss_rr(op1, dest);
1880             }
1881         }
1882     }
1883 
1884     void mulFloat(Address op1, FPRegisterID op2, FPRegisterID dest)
1885     {
1886         if (supportsAVX())
1887             m_assembler.vmulss_mr(op1.offset, op1.base, op2, dest);
1888         else {
<a name="33" id="anc33"></a><span class="line-removed">1889             ASSERT(isSSE2Present());</span>
1890             if (op2 == dest) {
1891                 m_assembler.mulss_mr(op1.offset, op1.base, dest);
1892                 return;
1893             }
1894             loadFloat(op1, dest);
1895             mulFloat(op2, dest);
1896         }
1897     }
1898 
1899     void mulFloat(FPRegisterID op1, Address op2, FPRegisterID dest)
1900     {
1901         mulFloat(op2, op1, dest);
1902     }
1903 
1904     void mulFloat(BaseIndex op1, FPRegisterID op2, FPRegisterID dest)
1905     {
1906         if (supportsAVX())
1907             m_assembler.vmulss_mr(op1.offset, op1.base, op1.index, op1.scale, op2, dest);
1908         else {
<a name="34" id="anc34"></a><span class="line-removed">1909             ASSERT(isSSE2Present());</span>
1910             if (op2 == dest) {
1911                 m_assembler.mulss_mr(op1.offset, op1.base, op1.index, op1.scale, dest);
1912                 return;
1913             }
1914             loadFloat(op1, dest);
1915             mulFloat(op2, dest);
1916         }
1917     }
1918 
1919     void andDouble(FPRegisterID src, FPRegisterID dst)
1920     {
1921         // ANDPS is defined on 128bits and is shorter than ANDPD.
1922         m_assembler.andps_rr(src, dst);
1923     }
1924 
1925     void andDouble(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
1926     {
1927         if (src1 == dst)
1928             andDouble(src2, dst);
1929         else {
1930             moveDouble(src2, dst);
1931             andDouble(src1, dst);
1932         }
1933     }
1934 
1935     void andFloat(FPRegisterID src, FPRegisterID dst)
1936     {
1937         m_assembler.andps_rr(src, dst);
1938     }
1939 
1940     void andFloat(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
1941     {
1942         if (src1 == dst)
1943             andFloat(src2, dst);
1944         else {
1945             moveDouble(src2, dst);
1946             andFloat(src1, dst);
1947         }
1948     }
1949 
1950     void orDouble(FPRegisterID src, FPRegisterID dst)
1951     {
1952         m_assembler.orps_rr(src, dst);
1953     }
1954 
1955     void orDouble(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
1956     {
1957         if (src1 == dst)
1958             orDouble(src2, dst);
1959         else {
1960             moveDouble(src2, dst);
1961             orDouble(src1, dst);
1962         }
1963     }
1964 
1965     void orFloat(FPRegisterID src, FPRegisterID dst)
1966     {
1967         m_assembler.orps_rr(src, dst);
1968     }
1969 
1970     void orFloat(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
1971     {
1972         if (src1 == dst)
1973             orFloat(src2, dst);
1974         else {
1975             moveDouble(src2, dst);
1976             orFloat(src1, dst);
1977         }
1978     }
1979 
1980     void xorDouble(FPRegisterID src, FPRegisterID dst)
1981     {
1982         m_assembler.xorps_rr(src, dst);
1983     }
1984 
1985     void xorDouble(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
1986     {
1987         if (src1 == dst)
1988             xorDouble(src2, dst);
1989         else {
1990             moveDouble(src2, dst);
1991             xorDouble(src1, dst);
1992         }
1993     }
1994 
1995     void xorFloat(FPRegisterID src, FPRegisterID dst)
1996     {
1997         m_assembler.xorps_rr(src, dst);
1998     }
1999 
2000     void xorFloat(FPRegisterID src1, FPRegisterID src2, FPRegisterID dst)
2001     {
2002         if (src1 == dst)
2003             xorFloat(src2, dst);
2004         else {
2005             moveDouble(src2, dst);
2006             xorFloat(src1, dst);
2007         }
2008     }
2009 
2010     void convertInt32ToDouble(RegisterID src, FPRegisterID dest)
2011     {
<a name="35" id="anc35"></a><span class="line-removed">2012         ASSERT(isSSE2Present());</span>
2013         m_assembler.cvtsi2sd_rr(src, dest);
2014     }
2015 
2016     void convertInt32ToDouble(Address src, FPRegisterID dest)
2017     {
<a name="36" id="anc36"></a><span class="line-removed">2018         ASSERT(isSSE2Present());</span>
2019         m_assembler.cvtsi2sd_mr(src.offset, src.base, dest);
2020     }
2021 
2022     void convertInt32ToFloat(RegisterID src, FPRegisterID dest)
2023     {
<a name="37" id="anc37"></a><span class="line-removed">2024         ASSERT(isSSE2Present());</span>
2025         m_assembler.cvtsi2ss_rr(src, dest);
2026     }
2027 
2028     void convertInt32ToFloat(Address src, FPRegisterID dest)
2029     {
<a name="38" id="anc38"></a><span class="line-removed">2030         ASSERT(isSSE2Present());</span>
2031         m_assembler.cvtsi2ss_mr(src.offset, src.base, dest);
2032     }
2033 
2034     Jump branchDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
2035     {
<a name="39" id="anc39"></a><span class="line-removed">2036         ASSERT(isSSE2Present());</span>
<span class="line-removed">2037 </span>
2038         if (cond &amp; DoubleConditionBitInvert)
2039             m_assembler.ucomisd_rr(left, right);
2040         else
2041             m_assembler.ucomisd_rr(right, left);
2042         return jumpAfterFloatingPointCompare(cond, left, right);
2043     }
2044 
2045     Jump branchFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
2046     {
<a name="40" id="anc40"></a><span class="line-removed">2047         ASSERT(isSSE2Present());</span>
<span class="line-removed">2048 </span>
2049         if (cond &amp; DoubleConditionBitInvert)
2050             m_assembler.ucomiss_rr(left, right);
2051         else
2052             m_assembler.ucomiss_rr(right, left);
2053         return jumpAfterFloatingPointCompare(cond, left, right);
2054     }
2055 
2056     void compareDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
2057     {
<a name="41" id="anc41"></a><span class="line-removed">2058         ASSERT(isSSE2Present());</span>
2059         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
2060             m_assembler.ucomisd_rr(arg1, arg2);
2061         });
2062     }
2063 
2064     void compareFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest)
2065     {
<a name="42" id="anc42"></a><span class="line-removed">2066         ASSERT(isSSE2Present());</span>
2067         floatingPointCompare(cond, left, right, dest, [this] (FPRegisterID arg1, FPRegisterID arg2) {
2068             m_assembler.ucomiss_rr(arg1, arg2);
2069         });
2070     }
2071 
2072     // Truncates &#39;src&#39; to an integer, and places the resulting &#39;dest&#39;.
2073     // If the result is not representable as a 32 bit value, branch.
2074     // May also branch for some values that are representable in 32 bits
2075     // (specifically, in this case, INT_MIN).
2076     enum BranchTruncateType { BranchIfTruncateFailed, BranchIfTruncateSuccessful };
2077     Jump branchTruncateDoubleToInt32(FPRegisterID src, RegisterID dest, BranchTruncateType branchType = BranchIfTruncateFailed)
2078     {
<a name="43" id="anc43"></a><span class="line-removed">2079         ASSERT(isSSE2Present());</span>
2080         m_assembler.cvttsd2si_rr(src, dest);
2081         return branch32(branchType ? NotEqual : Equal, dest, TrustedImm32(0x80000000));
2082     }
2083 
2084     void truncateDoubleToInt32(FPRegisterID src, RegisterID dest)
2085     {
<a name="44" id="anc44"></a><span class="line-removed">2086         ASSERT(isSSE2Present());</span>
2087         m_assembler.cvttsd2si_rr(src, dest);
2088     }
2089 
2090     void truncateFloatToInt32(FPRegisterID src, RegisterID dest)
2091     {
<a name="45" id="anc45"></a><span class="line-removed">2092         ASSERT(isSSE2Present());</span>
2093         m_assembler.cvttss2si_rr(src, dest);
2094     }
2095 
2096     // Convert &#39;src&#39; to an integer, and places the resulting &#39;dest&#39;.
2097     // If the result is not representable as a 32 bit value, branch.
2098     // May also branch for some values that are representable in 32 bits
2099     // (specifically, in this case, 0).
2100     void branchConvertDoubleToInt32(FPRegisterID src, RegisterID dest, JumpList&amp; failureCases, FPRegisterID fpTemp, bool negZeroCheck = true)
2101     {
<a name="46" id="anc46"></a><span class="line-removed">2102         ASSERT(isSSE2Present());</span>
2103         m_assembler.cvttsd2si_rr(src, dest);
2104 
2105         // If the result is zero, it might have been -0.0, and the double comparison won&#39;t catch this!
2106 #if CPU(X86_64)
2107         if (negZeroCheck) {
2108             Jump valueIsNonZero = branchTest32(NonZero, dest);
2109             m_assembler.movmskpd_rr(src, scratchRegister());
2110             failureCases.append(branchTest32(NonZero, scratchRegister(), TrustedImm32(1)));
2111             valueIsNonZero.link(this);
2112         }
2113 #else
2114         if (negZeroCheck)
2115             failureCases.append(branchTest32(Zero, dest));
2116 #endif
2117 
2118         // Convert the integer result back to float &amp; compare to the original value - if not equal or unordered (NaN) then jump.
2119         convertInt32ToDouble(dest, fpTemp);
2120         m_assembler.ucomisd_rr(fpTemp, src);
2121         failureCases.append(m_assembler.jp());
2122         failureCases.append(m_assembler.jne());
2123     }
2124 
2125     void moveZeroToDouble(FPRegisterID reg)
2126     {
2127         m_assembler.xorps_rr(reg, reg);
2128     }
2129 
2130     Jump branchDoubleNonZero(FPRegisterID reg, FPRegisterID scratch)
2131     {
<a name="47" id="anc47"></a><span class="line-removed">2132         ASSERT(isSSE2Present());</span>
2133         m_assembler.xorpd_rr(scratch, scratch);
2134         return branchDouble(DoubleNotEqual, reg, scratch);
2135     }
2136 
2137     Jump branchDoubleZeroOrNaN(FPRegisterID reg, FPRegisterID scratch)
2138     {
<a name="48" id="anc48"></a><span class="line-removed">2139         ASSERT(isSSE2Present());</span>
2140         m_assembler.xorpd_rr(scratch, scratch);
2141         return branchDouble(DoubleEqualOrUnordered, reg, scratch);
2142     }
2143 
2144     void lshiftPacked(TrustedImm32 imm, XMMRegisterID reg)
2145     {
<a name="49" id="anc49"></a><span class="line-removed">2146         ASSERT(isSSE2Present());</span>
2147         m_assembler.psllq_i8r(imm.m_value, reg);
2148     }
2149 
2150     void rshiftPacked(TrustedImm32 imm, XMMRegisterID reg)
2151     {
<a name="50" id="anc50"></a><span class="line-removed">2152         ASSERT(isSSE2Present());</span>
2153         m_assembler.psrlq_i8r(imm.m_value, reg);
2154     }
2155 
2156     void orPacked(XMMRegisterID src, XMMRegisterID dst)
2157     {
<a name="51" id="anc51"></a><span class="line-removed">2158         ASSERT(isSSE2Present());</span>
2159         m_assembler.por_rr(src, dst);
2160     }
2161 
2162     void move32ToFloat(RegisterID src, XMMRegisterID dst)
2163     {
<a name="52" id="anc52"></a><span class="line-removed">2164         ASSERT(isSSE2Present());</span>
2165         m_assembler.movd_rr(src, dst);
2166     }
2167 
2168     void moveFloatTo32(XMMRegisterID src, RegisterID dst)
2169     {
<a name="53" id="anc53"></a><span class="line-removed">2170         ASSERT(isSSE2Present());</span>
2171         m_assembler.movd_rr(src, dst);
2172     }
2173 
2174     // Stack manipulation operations:
2175     //
2176     // The ABI is assumed to provide a stack abstraction to memory,
2177     // containing machine word sized units of data.  Push and pop
2178     // operations add and remove a single register sized unit of data
2179     // to or from the stack.  Peek and poke operations read or write
2180     // values on the stack, without moving the current stack position.
2181 
2182     void pop(RegisterID dest)
2183     {
2184         m_assembler.pop_r(dest);
2185     }
2186 
2187     void push(RegisterID src)
2188     {
2189         m_assembler.push_r(src);
2190     }
2191 
2192     void push(Address address)
2193     {
2194         m_assembler.push_m(address.offset, address.base);
2195     }
2196 
2197     void push(TrustedImm32 imm)
2198     {
2199         m_assembler.push_i32(imm.m_value);
2200     }
2201 
2202     void popPair(RegisterID dest1, RegisterID dest2)
2203     {
2204         pop(dest2);
2205         pop(dest1);
2206     }
2207 
2208     void pushPair(RegisterID src1, RegisterID src2)
2209     {
2210         push(src1);
2211         push(src2);
2212     }
2213 
2214     // Register move operations:
2215     //
2216     // Move values in registers.
2217 
2218     void move(TrustedImm32 imm, RegisterID dest)
2219     {
2220         // Note: on 64-bit the TrustedImm32 value is zero extended into the register, it
2221         // may be useful to have a separate version that sign extends the value?
2222         if (!imm.m_value)
2223             m_assembler.xorl_rr(dest, dest);
2224         else
2225             m_assembler.movl_i32r(imm.m_value, dest);
2226     }
2227 
2228 #if CPU(X86_64)
2229     void move(RegisterID src, RegisterID dest)
2230     {
2231         // Note: on 64-bit this is is a full register move; perhaps it would be
2232         // useful to have separate move32 &amp; movePtr, with move32 zero extending?
2233         if (src != dest)
2234             m_assembler.movq_rr(src, dest);
2235     }
2236 
2237     void move(TrustedImmPtr imm, RegisterID dest)
2238     {
2239         if (!imm.m_value)
2240             m_assembler.xorq_rr(dest, dest);
2241         else
2242             m_assembler.movq_i64r(imm.asIntptr(), dest);
2243     }
2244 
2245     void move(TrustedImm64 imm, RegisterID dest)
2246     {
2247         if (!imm.m_value)
2248             m_assembler.xorq_rr(dest, dest);
2249         else
2250             m_assembler.movq_i64r(imm.m_value, dest);
2251     }
2252 
2253     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2254     {
<a name="54" id="anc54"></a><span class="line-removed">2255         ASSERT(isSSE2Present());</span>
<span class="line-removed">2256 </span>
2257         if (cond &amp; DoubleConditionBitInvert)
2258             m_assembler.ucomisd_rr(left, right);
2259         else
2260             m_assembler.ucomisd_rr(right, left);
2261         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2262     }
2263 
2264     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2265     {
<a name="55" id="anc55"></a><span class="line-removed">2266         ASSERT(isSSE2Present());</span>
<span class="line-removed">2267 </span>
2268         if (thenCase != dest &amp;&amp; elseCase != dest) {
2269             move(elseCase, dest);
2270             elseCase = dest;
2271         }
2272 
2273         RegisterID src;
2274         if (elseCase == dest)
2275             src = thenCase;
2276         else {
2277             cond = invert(cond);
2278             src = elseCase;
2279         }
2280 
2281         if (cond &amp; DoubleConditionBitInvert)
2282             m_assembler.ucomisd_rr(left, right);
2283         else
2284             m_assembler.ucomisd_rr(right, left);
2285         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2286     }
2287 
2288     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2289     {
<a name="56" id="anc56"></a><span class="line-removed">2290         ASSERT(isSSE2Present());</span>
<span class="line-removed">2291 </span>
2292         if (cond &amp; DoubleConditionBitInvert)
2293             m_assembler.ucomiss_rr(left, right);
2294         else
2295             m_assembler.ucomiss_rr(right, left);
2296         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2297     }
2298 
2299     void moveConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2300     {
<a name="57" id="anc57"></a><span class="line-removed">2301         ASSERT(isSSE2Present());</span>
<span class="line-removed">2302 </span>
2303         if (thenCase != dest &amp;&amp; elseCase != dest) {
2304             move(elseCase, dest);
2305             elseCase = dest;
2306         }
2307 
2308         RegisterID src;
2309         if (elseCase == dest)
2310             src = thenCase;
2311         else {
2312             cond = invert(cond);
2313             src = elseCase;
2314         }
2315 
2316         if (cond &amp; DoubleConditionBitInvert)
2317             m_assembler.ucomiss_rr(left, right);
2318         else
2319             m_assembler.ucomiss_rr(right, left);
2320         moveConditionallyAfterFloatingPointCompare(cond, left, right, src, dest);
2321     }
2322 
2323     void swap(RegisterID reg1, RegisterID reg2)
2324     {
2325         if (reg1 != reg2)
2326             m_assembler.xchgq_rr(reg1, reg2);
2327     }
2328 
2329     void swap(FPRegisterID reg1, FPRegisterID reg2)
2330     {
2331         if (reg1 == reg2)
2332             return;
2333 
2334         // FIXME: This is kinda a hack since we don&#39;t use xmm7 as a temp.
2335         ASSERT(reg1 != FPRegisterID::xmm7);
2336         ASSERT(reg2 != FPRegisterID::xmm7);
2337         moveDouble(reg1, FPRegisterID::xmm7);
2338         moveDouble(reg2, reg1);
2339         moveDouble(FPRegisterID::xmm7, reg2);
2340     }
2341 
2342     void signExtend32ToPtr(TrustedImm32 imm, RegisterID dest)
2343     {
2344         if (!imm.m_value)
2345             m_assembler.xorq_rr(dest, dest);
2346         else
2347             m_assembler.mov_i32r(imm.m_value, dest);
2348     }
2349 
2350     void signExtend32ToPtr(RegisterID src, RegisterID dest)
2351     {
2352         m_assembler.movsxd_rr(src, dest);
2353     }
2354 
2355     void zeroExtend32ToPtr(RegisterID src, RegisterID dest)
2356     {
2357         m_assembler.movl_rr(src, dest);
2358     }
2359 
2360     void zeroExtend32ToPtr(TrustedImm32 src, RegisterID dest)
2361     {
2362         m_assembler.movl_i32r(src.m_value, dest);
2363     }
2364 #else
2365     void move(RegisterID src, RegisterID dest)
2366     {
2367         if (src != dest)
2368             m_assembler.movl_rr(src, dest);
2369     }
2370 
2371     void move(TrustedImmPtr imm, RegisterID dest)
2372     {
2373         if (!imm.m_value)
2374             m_assembler.xorl_rr(dest, dest);
2375         else
2376             m_assembler.movl_i32r(imm.asIntptr(), dest);
2377     }
2378 
2379     // Only here for templates!
2380     void move(TrustedImm64, RegisterID)
2381     {
2382         UNREACHABLE_FOR_PLATFORM();
2383     }
2384 
2385     void moveConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
2386     {
<a name="58" id="anc58"></a><span class="line-removed">2387         ASSERT(isSSE2Present());</span>
<span class="line-removed">2388 </span>
2389         if (cond &amp; DoubleConditionBitInvert)
2390             m_assembler.ucomisd_rr(left, right);
2391         else
2392             m_assembler.ucomisd_rr(right, left);
2393 
2394         if (cond == DoubleEqual) {
2395             if (left == right) {
2396                 m_assembler.cmovnpl_rr(src, dest);
2397                 return;
2398             }
2399 
2400             Jump isUnordered(m_assembler.jp());
2401             m_assembler.cmovel_rr(src, dest);
2402             isUnordered.link(this);
2403             return;
2404         }
2405 
2406         if (cond == DoubleNotEqualOrUnordered) {
2407             if (left == right) {
2408                 m_assembler.cmovpl_rr(src, dest);
2409                 return;
2410             }
2411 
2412             m_assembler.cmovpl_rr(src, dest);
2413             m_assembler.cmovnel_rr(src, dest);
2414             return;
2415         }
2416 
2417         ASSERT(!(cond &amp; DoubleConditionBitSpecial));
2418         m_assembler.cmovl_rr(static_cast&lt;X86Assembler::Condition&gt;(cond &amp; ~DoubleConditionBits), src, dest);
2419     }
2420 
2421     void swap(RegisterID reg1, RegisterID reg2)
2422     {
2423         if (reg1 != reg2)
2424             m_assembler.xchgl_rr(reg1, reg2);
2425     }
2426 
2427     void swap(FPRegisterID reg1, FPRegisterID reg2)
2428     {
2429         if (reg1 == reg2)
2430             return;
2431 
2432         // FIXME: This is kinda a hack since we don&#39;t use xmm7 as a temp.
2433         ASSERT(reg1 != FPRegisterID::xmm7);
2434         ASSERT(reg2 != FPRegisterID::xmm7);
2435         moveDouble(reg1, FPRegisterID::xmm7);
2436         moveDouble(reg2, reg1);
2437         moveDouble(FPRegisterID::xmm7, reg2);
2438     }
2439 
2440     void signExtend32ToPtr(RegisterID src, RegisterID dest)
2441     {
2442         move(src, dest);
2443     }
2444 
2445     void zeroExtend32ToPtr(RegisterID src, RegisterID dest)
2446     {
2447         move(src, dest);
2448     }
2449 #endif
2450 
2451     void swap32(RegisterID src, RegisterID dest)
2452     {
2453         m_assembler.xchgl_rr(src, dest);
2454     }
2455 
2456     void swap32(RegisterID src, Address dest)
2457     {
2458         m_assembler.xchgl_rm(src, dest.offset, dest.base);
2459     }
2460 
2461     void moveConditionally32(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID src, RegisterID dest)
2462     {
2463         m_assembler.cmpl_rr(right, left);
2464         cmov(x86Condition(cond), src, dest);
2465     }
2466 
2467     void moveConditionally32(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2468     {
2469         m_assembler.cmpl_rr(right, left);
2470 
2471         if (thenCase != dest &amp;&amp; elseCase != dest) {
2472             move(elseCase, dest);
2473             elseCase = dest;
2474         }
2475 
2476         if (elseCase == dest)
2477             cmov(x86Condition(cond), thenCase, dest);
2478         else
2479             cmov(x86Condition(invert(cond)), elseCase, dest);
2480     }
2481 
2482     void moveConditionally32(RelationalCondition cond, RegisterID left, TrustedImm32 right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2483     {
2484         if (!right.m_value) {
2485             if (auto resultCondition = commuteCompareToZeroIntoTest(cond)) {
2486                 moveConditionallyTest32(*resultCondition, left, left, thenCase, elseCase, dest);
2487                 return;
2488             }
2489         }
2490 
2491         m_assembler.cmpl_ir(right.m_value, left);
2492 
2493         if (thenCase != dest &amp;&amp; elseCase != dest) {
2494             move(elseCase, dest);
2495             elseCase = dest;
2496         }
2497 
2498         if (elseCase == dest)
2499             cmov(x86Condition(cond), thenCase, dest);
2500         else
2501             cmov(x86Condition(invert(cond)), elseCase, dest);
2502     }
2503 
2504     void moveConditionallyTest32(ResultCondition cond, RegisterID testReg, RegisterID mask, RegisterID src, RegisterID dest)
2505     {
2506         m_assembler.testl_rr(testReg, mask);
2507         cmov(x86Condition(cond), src, dest);
2508     }
2509 
2510     void moveConditionallyTest32(ResultCondition cond, RegisterID left, RegisterID right, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2511     {
2512         ASSERT(isInvertible(cond));
2513         ASSERT_WITH_MESSAGE(cond != Overflow, &quot;TEST does not set the Overflow Flag.&quot;);
2514 
2515         m_assembler.testl_rr(right, left);
2516 
2517         if (thenCase != dest &amp;&amp; elseCase != dest) {
2518             move(elseCase, dest);
2519             elseCase = dest;
2520         }
2521 
2522         if (elseCase == dest)
2523             cmov(x86Condition(cond), thenCase, dest);
2524         else
2525             cmov(x86Condition(invert(cond)), elseCase, dest);
2526     }
2527 
2528     void moveConditionallyTest32(ResultCondition cond, RegisterID testReg, TrustedImm32 mask, RegisterID src, RegisterID dest)
2529     {
2530         test32(testReg, mask);
2531         cmov(x86Condition(cond), src, dest);
2532     }
2533 
2534     void moveConditionallyTest32(ResultCondition cond, RegisterID testReg, TrustedImm32 mask, RegisterID thenCase, RegisterID elseCase, RegisterID dest)
2535     {
2536         ASSERT(isInvertible(cond));
2537         ASSERT_WITH_MESSAGE(cond != Overflow, &quot;TEST does not set the Overflow Flag.&quot;);
2538 
2539         test32(testReg, mask);
2540 
2541         if (thenCase != dest &amp;&amp; elseCase != dest) {
2542             move(elseCase, dest);
2543             elseCase = dest;
2544         }
2545 
2546         if (elseCase == dest)
2547             cmov(x86Condition(cond), thenCase, dest);
2548         else
2549             cmov(x86Condition(invert(cond)), elseCase, dest);
2550     }
2551 
2552     template&lt;typename LeftType, typename RightType&gt;
2553     void moveDoubleConditionally32(RelationalCondition cond, LeftType left, RightType right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2554     {
2555         static_assert(!std::is_same&lt;LeftType, FPRegisterID&gt;::value &amp;&amp; !std::is_same&lt;RightType, FPRegisterID&gt;::value, &quot;One of the tested argument could be aliased on dest. Use moveDoubleConditionallyDouble().&quot;);
2556 
2557         if (thenCase != dest &amp;&amp; elseCase != dest) {
2558             moveDouble(elseCase, dest);
2559             elseCase = dest;
2560         }
2561 
2562         if (elseCase == dest) {
2563             Jump falseCase = branch32(invert(cond), left, right);
2564             moveDouble(thenCase, dest);
2565             falseCase.link(this);
2566         } else {
2567             Jump trueCase = branch32(cond, left, right);
2568             moveDouble(elseCase, dest);
2569             trueCase.link(this);
2570         }
2571     }
2572 
2573     template&lt;typename TestType, typename MaskType&gt;
2574     void moveDoubleConditionallyTest32(ResultCondition cond, TestType test, MaskType mask, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2575     {
2576         static_assert(!std::is_same&lt;TestType, FPRegisterID&gt;::value &amp;&amp; !std::is_same&lt;MaskType, FPRegisterID&gt;::value, &quot;One of the tested argument could be aliased on dest. Use moveDoubleConditionallyDouble().&quot;);
2577 
2578         if (elseCase == dest &amp;&amp; isInvertible(cond)) {
2579             Jump falseCase = branchTest32(invert(cond), test, mask);
2580             moveDouble(thenCase, dest);
2581             falseCase.link(this);
2582         } else if (thenCase == dest) {
2583             Jump trueCase = branchTest32(cond, test, mask);
2584             moveDouble(elseCase, dest);
2585             trueCase.link(this);
2586         }
2587 
2588         Jump trueCase = branchTest32(cond, test, mask);
2589         moveDouble(elseCase, dest);
2590         Jump falseCase = jump();
2591         trueCase.link(this);
2592         moveDouble(thenCase, dest);
2593         falseCase.link(this);
2594     }
2595 
2596     void moveDoubleConditionallyDouble(DoubleCondition cond, FPRegisterID left, FPRegisterID right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2597     {
2598         if (elseCase == dest) {
2599             Jump falseCase = branchDouble(invert(cond), left, right);
2600             moveDouble(thenCase, dest);
2601             falseCase.link(this);
2602         } else if (thenCase == dest) {
2603             Jump trueCase = branchDouble(cond, left, right);
2604             moveDouble(elseCase, dest);
2605             trueCase.link(this);
2606         } else {
2607             Jump trueCase = branchDouble(cond, left, right);
2608             moveDouble(elseCase, dest);
2609             Jump falseCase = jump();
2610             trueCase.link(this);
2611             moveDouble(thenCase, dest);
2612             falseCase.link(this);
2613         }
2614     }
2615 
2616     void moveDoubleConditionallyFloat(DoubleCondition cond, FPRegisterID left, FPRegisterID right, FPRegisterID thenCase, FPRegisterID elseCase, FPRegisterID dest)
2617     {
2618         if (elseCase == dest) {
2619             Jump falseCase = branchFloat(invert(cond), left, right);
2620             moveDouble(thenCase, dest);
2621             falseCase.link(this);
2622         } else if (thenCase == dest) {
2623             Jump trueCase = branchFloat(cond, left, right);
2624             moveDouble(elseCase, dest);
2625             trueCase.link(this);
2626         } else {
2627             Jump trueCase = branchFloat(cond, left, right);
2628             moveDouble(elseCase, dest);
2629             Jump falseCase = jump();
2630             trueCase.link(this);
2631             moveDouble(thenCase, dest);
2632             falseCase.link(this);
2633         }
2634     }
2635 
2636     // Forwards / external control flow operations:
2637     //
2638     // This set of jump and conditional branch operations return a Jump
2639     // object which may linked at a later point, allow forwards jump,
2640     // or jumps that will require external linkage (after the code has been
2641     // relocated).
2642     //
2643     // For branches, signed &lt;, &gt;, &lt;= and &gt;= are denoted as l, g, le, and ge
2644     // respecitvely, for unsigned comparisons the names b, a, be, and ae are
2645     // used (representing the names &#39;below&#39; and &#39;above&#39;).
2646     //
2647     // Operands to the comparision are provided in the expected order, e.g.
2648     // jle32(reg1, TrustedImm32(5)) will branch if the value held in reg1, when
2649     // treated as a signed 32bit value, is less than or equal to 5.
2650     //
2651     // jz and jnz test whether the first operand is equal to zero, and take
2652     // an optional second operand of a mask under which to perform the test.
2653 
2654 public:
2655     Jump branch8(RelationalCondition cond, Address left, TrustedImm32 right)
2656     {
2657         TrustedImm32 right8(static_cast&lt;int8_t&gt;(right.m_value));
2658         m_assembler.cmpb_im(right8.m_value, left.offset, left.base);
2659         return Jump(m_assembler.jCC(x86Condition(cond)));
2660     }
2661 
2662     Jump branch32(RelationalCondition cond, RegisterID left, RegisterID right)
2663     {
2664         m_assembler.cmpl_rr(right, left);
2665         return Jump(m_assembler.jCC(x86Condition(cond)));
2666     }
2667 
2668     Jump branch32(RelationalCondition cond, RegisterID left, TrustedImm32 right)
2669     {
2670         if (!right.m_value) {
2671             if (auto resultCondition = commuteCompareToZeroIntoTest(cond))
2672                 return branchTest32(*resultCondition, left, left);
2673         }
2674 
2675         m_assembler.cmpl_ir(right.m_value, left);
2676         return Jump(m_assembler.jCC(x86Condition(cond)));
2677     }
2678 
2679     Jump branch32(RelationalCondition cond, RegisterID left, Address right)
2680     {
2681         m_assembler.cmpl_mr(right.offset, right.base, left);
2682         return Jump(m_assembler.jCC(x86Condition(cond)));
2683     }
2684 
2685     Jump branch32(RelationalCondition cond, Address left, RegisterID right)
2686     {
2687         m_assembler.cmpl_rm(right, left.offset, left.base);
2688         return Jump(m_assembler.jCC(x86Condition(cond)));
2689     }
2690 
2691     Jump branch32(RelationalCondition cond, Address left, TrustedImm32 right)
2692     {
2693         m_assembler.cmpl_im(right.m_value, left.offset, left.base);
2694         return Jump(m_assembler.jCC(x86Condition(cond)));
2695     }
2696 
2697     Jump branch32(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2698     {
2699         m_assembler.cmpl_im(right.m_value, left.offset, left.base, left.index, left.scale);
2700         return Jump(m_assembler.jCC(x86Condition(cond)));
2701     }
2702 
2703     Jump branch32WithUnalignedHalfWords(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2704     {
2705         return branch32(cond, left, right);
2706     }
2707 
2708     Jump branchTest32(ResultCondition cond, RegisterID reg, RegisterID mask)
2709     {
2710         m_assembler.testl_rr(reg, mask);
2711         return Jump(m_assembler.jCC(x86Condition(cond)));
2712     }
2713 
<a name="59" id="anc59"></a>





























2714     void test32(RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2715     {
2716         if (mask.m_value == -1)
2717             m_assembler.testl_rr(reg, reg);
2718         else if (!(mask.m_value &amp; ~0xff) &amp;&amp; reg &lt; X86Registers::esp) { // Using esp and greater as a byte register yields the upper half of the 16 bit registers ax, cx, dx and bx, e.g. esp, register 4, is actually ah.
2719             if (mask.m_value == 0xff)
2720                 m_assembler.testb_rr(reg, reg);
2721             else
2722                 m_assembler.testb_i8r(mask.m_value, reg);
2723         } else
2724             m_assembler.testl_i32r(mask.m_value, reg);
2725     }
2726 
2727     Jump branch(ResultCondition cond)
2728     {
2729         return Jump(m_assembler.jCC(x86Condition(cond)));
2730     }
2731 
2732     Jump branchTest32(ResultCondition cond, RegisterID reg, TrustedImm32 mask = TrustedImm32(-1))
2733     {
2734         test32(reg, mask);
2735         return branch(cond);
2736     }
2737 
2738     Jump branchTest32(ResultCondition cond, Address address, TrustedImm32 mask = TrustedImm32(-1))
2739     {
2740         generateTest32(address, mask);
2741         return Jump(m_assembler.jCC(x86Condition(cond)));
2742     }
2743 
2744     Jump branchTest32(ResultCondition cond, BaseIndex address, TrustedImm32 mask = TrustedImm32(-1))
2745     {
2746         if (mask.m_value == -1)
2747             m_assembler.cmpl_im(0, address.offset, address.base, address.index, address.scale);
2748         else
2749             m_assembler.testl_i32m(mask.m_value, address.offset, address.base, address.index, address.scale);
2750         return Jump(m_assembler.jCC(x86Condition(cond)));
2751     }
2752 
2753     Jump branchTest8(ResultCondition cond, Address address, TrustedImm32 mask = TrustedImm32(-1))
2754     {
2755         TrustedImm32 mask8(static_cast&lt;int8_t&gt;(mask.m_value));
2756         if (mask8.m_value == -1)
2757             m_assembler.cmpb_im(0, address.offset, address.base);
2758         else
2759             m_assembler.testb_im(mask8.m_value, address.offset, address.base);
2760         return Jump(m_assembler.jCC(x86Condition(cond)));
2761     }
2762 
2763     Jump branchTest8(ResultCondition cond, BaseIndex address, TrustedImm32 mask = TrustedImm32(-1))
2764     {
2765         TrustedImm32 mask8(static_cast&lt;int8_t&gt;(mask.m_value));
2766         if (mask8.m_value == -1)
2767             m_assembler.cmpb_im(0, address.offset, address.base, address.index, address.scale);
2768         else
2769             m_assembler.testb_im(mask8.m_value, address.offset, address.base, address.index, address.scale);
2770         return Jump(m_assembler.jCC(x86Condition(cond)));
2771     }
2772 
2773     Jump branch8(RelationalCondition cond, BaseIndex left, TrustedImm32 right)
2774     {
2775         TrustedImm32 right8(static_cast&lt;int8_t&gt;(right.m_value));
2776         m_assembler.cmpb_im(right8.m_value, left.offset, left.base, left.index, left.scale);
2777         return Jump(m_assembler.jCC(x86Condition(cond)));
2778     }
2779 
2780     Jump jump()
2781     {
2782         return Jump(m_assembler.jmp());
2783     }
2784 
<a name="60" id="anc60"></a><span class="line-modified">2785     void jump(RegisterID target, PtrTag)</span>
2786     {
2787         m_assembler.jmp_r(target);
2788     }
2789 
2790     // Address is a memory location containing the address to jump to
<a name="61" id="anc61"></a><span class="line-modified">2791     void jump(Address address, PtrTag)</span>
2792     {
2793         m_assembler.jmp_m(address.offset, address.base);
2794     }
2795 
2796     // Address is a memory location containing the address to jump to
<a name="62" id="anc62"></a><span class="line-modified">2797     void jump(BaseIndex address, PtrTag)</span>
2798     {
2799         m_assembler.jmp_m(address.offset, address.base, address.index, address.scale);
2800     }
2801 
<a name="63" id="anc63"></a><span class="line-modified">2802     ALWAYS_INLINE void jump(RegisterID target, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(target, NoPtrTag); }</span>
<span class="line-modified">2803     ALWAYS_INLINE void jump(Address address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(address, NoPtrTag); }</span>
<span class="line-modified">2804     ALWAYS_INLINE void jump(BaseIndex address, RegisterID jumpTag) { UNUSED_PARAM(jumpTag), jump(address, NoPtrTag); }</span>
2805 
2806     // Arithmetic control flow operations:
2807     //
2808     // This set of conditional branch operations branch based
2809     // on the result of an arithmetic operation.  The operation
2810     // is performed as normal, storing the result.
2811     //
2812     // * jz operations branch if the result is zero.
2813     // * jo operations branch if the (signed) arithmetic
2814     //   operation caused an overflow to occur.
2815 
2816     Jump branchAdd32(ResultCondition cond, RegisterID src, RegisterID dest)
2817     {
2818         add32(src, dest);
2819         return Jump(m_assembler.jCC(x86Condition(cond)));
2820     }
2821 
2822     Jump branchAdd32(ResultCondition cond, TrustedImm32 imm, RegisterID dest)
2823     {
2824         add32(imm, dest);
2825         return Jump(m_assembler.jCC(x86Condition(cond)));
2826     }
2827 
2828     Jump branchAdd32(ResultCondition cond, TrustedImm32 src, Address dest)
2829     {
2830         add32(src, dest);
2831         return Jump(m_assembler.jCC(x86Condition(cond)));
2832     }
2833 
2834     Jump branchAdd32(ResultCondition cond, RegisterID src, Address dest)
2835     {
2836         add32(src, dest);
2837         return Jump(m_assembler.jCC(x86Condition(cond)));
2838     }
2839 
2840     Jump branchAdd32(ResultCondition cond, Address src, RegisterID dest)
2841     {
2842         add32(src, dest);
2843         return Jump(m_assembler.jCC(x86Condition(cond)));
2844     }
2845 
2846     Jump branchAdd32(ResultCondition cond, RegisterID src1, RegisterID src2, RegisterID dest)
2847     {
2848         if (src1 == dest)
2849             return branchAdd32(cond, src2, dest);
2850         move32IfNeeded(src2, dest);
2851         return branchAdd32(cond, src1, dest);
2852     }
2853 
2854     Jump branchAdd32(ResultCondition cond, Address op1, RegisterID op2, RegisterID dest)
2855     {
2856         if (op2 == dest)
2857             return branchAdd32(cond, op1, dest);
2858         if (op1.base == dest) {
2859             load32(op1, dest);
2860             return branchAdd32(cond, op2, dest);
2861         }
2862         zeroExtend32ToPtr(op2, dest);
2863         return branchAdd32(cond, op1, dest);
2864     }
2865 
2866     Jump branchAdd32(ResultCondition cond, RegisterID src1, Address src2, RegisterID dest)
2867     {
2868         return branchAdd32(cond, src2, src1, dest);
2869     }
2870 
2871     Jump branchAdd32(ResultCondition cond, RegisterID src, TrustedImm32 imm, RegisterID dest)
2872     {
2873         move32IfNeeded(src, dest);
2874         return branchAdd32(cond, imm, dest);
2875     }
2876 
2877     Jump branchMul32(ResultCondition cond, RegisterID src, RegisterID dest)
2878     {
2879         mul32(src, dest);
2880         if (cond != Overflow)
2881             m_assembler.testl_rr(dest, dest);
2882         return Jump(m_assembler.jCC(x86Condition(cond)));
2883     }
2884 
2885     Jump branchMul32(ResultCondition cond, Address src, RegisterID dest)
2886     {
2887         mul32(src, dest);
2888         if (cond != Overflow)
2889             m_assembler.testl_rr(dest, dest);
2890         return Jump(m_assembler.jCC(x86Condition(cond)));
2891     }
2892 
2893     Jump branchMul32(ResultCondition cond, RegisterID src, TrustedImm32 imm, RegisterID dest)
2894     {
2895         mul32(imm, src, dest);
2896         if (cond != Overflow)
2897             m_assembler.testl_rr(dest, dest);
2898         return Jump(m_assembler.jCC(x86Condition(cond)));
2899     }
2900 
2901     Jump branchMul32(ResultCondition cond, RegisterID src1, RegisterID src2, RegisterID dest)
2902     {
2903         if (src1 == dest)
2904             return branchMul32(cond, src2, dest);
2905         move32IfNeeded(src2, dest);
2906         return branchMul32(cond, src1, dest);
2907     }
2908 
2909     Jump branchSub32(ResultCondition cond, RegisterID src, RegisterID dest)
2910     {
2911         sub32(src, dest);
2912         return Jump(m_assembler.jCC(x86Condition(cond)));
2913     }
2914 
2915     Jump branchSub32(ResultCondition cond, TrustedImm32 imm, RegisterID dest)
2916     {
2917         sub32(imm, dest);
2918         return Jump(m_assembler.jCC(x86Condition(cond)));
2919     }
2920 
2921     Jump branchSub32(ResultCondition cond, TrustedImm32 imm, Address dest)
2922     {
2923         sub32(imm, dest);
2924         return Jump(m_assembler.jCC(x86Condition(cond)));
2925     }
2926 
2927     Jump branchSub32(ResultCondition cond, RegisterID src, Address dest)
2928     {
2929         sub32(src, dest);
2930         return Jump(m_assembler.jCC(x86Condition(cond)));
2931     }
2932 
2933     Jump branchSub32(ResultCondition cond, Address src, RegisterID dest)
2934     {
2935         sub32(src, dest);
2936         return Jump(m_assembler.jCC(x86Condition(cond)));
2937     }
2938 
2939     Jump branchSub32(ResultCondition cond, RegisterID src1, RegisterID src2, RegisterID dest)
2940     {
2941         // B := A - B is invalid.
2942         ASSERT(src1 == dest || src2 != dest);
2943 
2944         move32IfNeeded(src1, dest);
2945         return branchSub32(cond, src2, dest);
2946     }
2947 
2948     Jump branchSub32(ResultCondition cond, RegisterID src1, TrustedImm32 src2, RegisterID dest)
2949     {
2950         move32IfNeeded(src1, dest);
2951         return branchSub32(cond, src2, dest);
2952     }
2953 
2954     Jump branchNeg32(ResultCondition cond, RegisterID srcDest)
2955     {
2956         neg32(srcDest);
2957         return Jump(m_assembler.jCC(x86Condition(cond)));
2958     }
2959 
2960     Jump branchOr32(ResultCondition cond, RegisterID src, RegisterID dest)
2961     {
2962         or32(src, dest);
2963         return Jump(m_assembler.jCC(x86Condition(cond)));
2964     }
2965 
2966 
2967     // Miscellaneous operations:
2968 
2969     void breakpoint()
2970     {
2971         m_assembler.int3();
2972     }
2973 
2974     static bool isBreakpoint(void* address) { return X86Assembler::isInt3(address); }
2975 
2976     Call nearTailCall()
2977     {
2978         return Call(m_assembler.jmp(), Call::LinkableNearTail);
2979     }
2980 
2981     Call nearCall()
2982     {
2983         return Call(m_assembler.call(), Call::LinkableNear);
2984     }
2985 
2986     Call call(RegisterID target, PtrTag)
2987     {
2988         return Call(m_assembler.call(target), Call::None);
2989     }
2990 
2991     void call(Address address, PtrTag)
2992     {
2993         m_assembler.call_m(address.offset, address.base);
2994     }
2995 
2996     ALWAYS_INLINE Call call(RegisterID target, RegisterID callTag) { return UNUSED_PARAM(callTag), call(target, NoPtrTag); }
2997     ALWAYS_INLINE void call(Address address, RegisterID callTag) { UNUSED_PARAM(callTag), call(address, NoPtrTag); }
2998 
2999     void ret()
3000     {
3001         m_assembler.ret();
3002     }
3003 
3004     void compare8(RelationalCondition cond, Address left, TrustedImm32 right, RegisterID dest)
3005     {
3006         TrustedImm32 right8(static_cast&lt;int8_t&gt;(right.m_value));
3007         m_assembler.cmpb_im(right8.m_value, left.offset, left.base);
3008         set32(x86Condition(cond), dest);
3009     }
3010 
3011     void compare32(RelationalCondition cond, RegisterID left, RegisterID right, RegisterID dest)
3012     {
3013         m_assembler.cmpl_rr(right, left);
3014         set32(x86Condition(cond), dest);
3015     }
3016 
3017     void compare32(RelationalCondition cond, RegisterID left, TrustedImm32 right, RegisterID dest)
3018     {
3019         if (!right.m_value) {
3020             if (auto resultCondition = commuteCompareToZeroIntoTest(cond)) {
3021                 test32(*resultCondition, left, left, dest);
3022                 return;
3023             }
3024         }
3025 
3026         m_assembler.cmpl_ir(right.m_value, left);
3027         set32(x86Condition(cond), dest);
3028     }
3029 
3030     // FIXME:
3031     // The mask should be optional... perhaps the argument order should be
3032     // dest-src, operations always have a dest? ... possibly not true, considering
3033     // asm ops like test, or pseudo ops like pop().
3034 
3035     void test8(ResultCondition cond, Address address, TrustedImm32 mask, RegisterID dest)
3036     {
3037         TrustedImm32 mask8(static_cast&lt;int8_t&gt;(mask.m_value));
3038         if (mask8.m_value == -1)
3039             m_assembler.cmpb_im(0, address.offset, address.base);
3040         else
3041             m_assembler.testb_im(mask8.m_value, address.offset, address.base);
3042         set32(x86Condition(cond), dest);
3043     }
3044 
3045     void test32(ResultCondition cond, Address address, TrustedImm32 mask, RegisterID dest)
3046     {
3047         generateTest32(address, mask);
3048         set32(x86Condition(cond), dest);
3049     }
3050 
3051     void test32(ResultCondition cond, RegisterID reg, RegisterID mask, RegisterID dest)
3052     {
3053         m_assembler.testl_rr(reg, mask);
3054         set32(x86Condition(cond), dest);
3055     }
3056 
3057     void test32(ResultCondition cond, RegisterID reg, TrustedImm32 mask, RegisterID dest)
3058     {
3059         test32(reg, mask);
3060         set32(x86Condition(cond), dest);
3061     }
3062 
3063     void setCarry(RegisterID dest)
3064     {
3065         set32(X86Assembler::ConditionC, dest);
3066     }
3067 
3068     // Invert a relational condition, e.g. == becomes !=, &lt; becomes &gt;=, etc.
3069     static RelationalCondition invert(RelationalCondition cond)
3070     {
3071         return static_cast&lt;RelationalCondition&gt;(cond ^ 1);
3072     }
3073 
3074     static DoubleCondition invert(DoubleCondition cond)
3075     {
3076         switch (cond) {
3077         case DoubleEqual:
3078             return DoubleNotEqualOrUnordered;
3079         case DoubleNotEqual:
3080             return DoubleEqualOrUnordered;
3081         case DoubleGreaterThan:
3082             return DoubleLessThanOrEqualOrUnordered;
3083         case DoubleGreaterThanOrEqual:
3084             return DoubleLessThanOrUnordered;
3085         case DoubleLessThan:
3086             return DoubleGreaterThanOrEqualOrUnordered;
3087         case DoubleLessThanOrEqual:
3088             return DoubleGreaterThanOrUnordered;
3089         case DoubleEqualOrUnordered:
3090             return DoubleNotEqual;
3091         case DoubleNotEqualOrUnordered:
3092             return DoubleEqual;
3093         case DoubleGreaterThanOrUnordered:
3094             return DoubleLessThanOrEqual;
3095         case DoubleGreaterThanOrEqualOrUnordered:
3096             return DoubleLessThan;
3097         case DoubleLessThanOrUnordered:
3098             return DoubleGreaterThanOrEqual;
3099         case DoubleLessThanOrEqualOrUnordered:
3100             return DoubleGreaterThan;
3101         }
3102         RELEASE_ASSERT_NOT_REACHED();
3103         return DoubleEqual; // make compiler happy
3104     }
3105 
3106     static bool isInvertible(ResultCondition cond)
3107     {
3108         switch (cond) {
3109         case Zero:
3110         case NonZero:
3111         case Signed:
3112         case PositiveOrZero:
3113             return true;
3114         default:
3115             return false;
3116         }
3117     }
3118 
3119     static ResultCondition invert(ResultCondition cond)
3120     {
3121         switch (cond) {
3122         case Zero:
3123             return NonZero;
3124         case NonZero:
3125             return Zero;
3126         case Signed:
3127             return PositiveOrZero;
3128         case PositiveOrZero:
3129             return Signed;
3130         default:
3131             RELEASE_ASSERT_NOT_REACHED();
3132             return Zero; // Make compiler happy for release builds.
3133         }
3134     }
3135 
3136     static Optional&lt;ResultCondition&gt; commuteCompareToZeroIntoTest(RelationalCondition cond)
3137     {
3138         switch (cond) {
3139         case Equal:
3140             return Zero;
3141         case NotEqual:
3142             return NonZero;
3143         case LessThan:
3144             return Signed;
3145         case GreaterThanOrEqual:
3146             return PositiveOrZero;
3147             break;
3148         default:
3149             return WTF::nullopt;
3150         }
3151     }
3152 
3153     void nop()
3154     {
3155         m_assembler.nop();
3156     }
3157 
3158     void xchg8(RegisterID reg, Address address)
3159     {
3160         m_assembler.xchgb_rm(reg, address.offset, address.base);
3161     }
3162 
3163     void xchg8(RegisterID reg, BaseIndex address)
3164     {
3165         m_assembler.xchgb_rm(reg, address.offset, address.base, address.index, address.scale);
3166     }
3167 
3168     void xchg16(RegisterID reg, Address address)
3169     {
3170         m_assembler.xchgw_rm(reg, address.offset, address.base);
3171     }
3172 
3173     void xchg16(RegisterID reg, BaseIndex address)
3174     {
3175         m_assembler.xchgw_rm(reg, address.offset, address.base, address.index, address.scale);
3176     }
3177 
3178     void xchg32(RegisterID reg, Address address)
3179     {
3180         m_assembler.xchgl_rm(reg, address.offset, address.base);
3181     }
3182 
3183     void xchg32(RegisterID reg, BaseIndex address)
3184     {
3185         m_assembler.xchgl_rm(reg, address.offset, address.base, address.index, address.scale);
3186     }
3187 
3188     // We take memoryFence to mean acqrel. This has acqrel semantics on x86.
3189     void memoryFence()
3190     {
3191         // lock; orl $0, (%rsp)
3192         m_assembler.lock();
3193         m_assembler.orl_im(0, 0, X86Registers::esp);
3194     }
3195 
3196     void atomicStrongCAS8(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, Address address, RegisterID result)
3197     {
3198         atomicStrongCAS(cond, expectedAndResult, result, address, [&amp;] { m_assembler.cmpxchgb_rm(newValue, address.offset, address.base); });
3199     }
3200 
3201     void atomicStrongCAS8(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, BaseIndex address, RegisterID result)
3202     {
3203         atomicStrongCAS(cond, expectedAndResult, result, address, [&amp;] { m_assembler.cmpxchgb_rm(newValue, address.offset, address.base, address.index, address.scale); });
3204     }
3205 
3206     void atomicStrongCAS16(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, Address address, RegisterID result)
3207     {
3208         atomicStrongCAS(cond, expectedAndResult, result, address, [&amp;] { m_assembler.cmpxchgw_rm(newValue, address.offset, address.base); });
3209     }
3210 
3211     void atomicStrongCAS16(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, BaseIndex address, RegisterID result)
3212     {
3213         atomicStrongCAS(cond, expectedAndResult, result, address, [&amp;] { m_assembler.cmpxchgw_rm(newValue, address.offset, address.base, address.index, address.scale); });
3214     }
3215 
3216     void atomicStrongCAS32(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, Address address, RegisterID result)
3217     {
3218         atomicStrongCAS(cond, expectedAndResult, result, address, [&amp;] { m_assembler.cmpxchgl_rm(newValue, address.offset, address.base); });
3219     }
3220 
3221     void atomicStrongCAS32(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, BaseIndex address, RegisterID result)
3222     {
3223         atomicStrongCAS(cond, expectedAndResult, result, address, [&amp;] { m_assembler.cmpxchgl_rm(newValue, address.offset, address.base, address.index, address.scale); });
3224     }
3225 
3226     void atomicStrongCAS8(RegisterID expectedAndResult, RegisterID newValue, Address address)
3227     {
3228         atomicStrongCAS(expectedAndResult, address, [&amp;] { m_assembler.cmpxchgb_rm(newValue, address.offset, address.base); });
3229     }
3230 
3231     void atomicStrongCAS8(RegisterID expectedAndResult, RegisterID newValue, BaseIndex address)
3232     {
3233         atomicStrongCAS(expectedAndResult, address, [&amp;] { m_assembler.cmpxchgb_rm(newValue, address.offset, address.base, address.index, address.scale); });
3234     }
3235 
3236     void atomicStrongCAS16(RegisterID expectedAndResult, RegisterID newValue, Address address)
3237     {
3238         atomicStrongCAS(expectedAndResult, address, [&amp;] { m_assembler.cmpxchgw_rm(newValue, address.offset, address.base); });
3239     }
3240 
3241     void atomicStrongCAS16(RegisterID expectedAndResult, RegisterID newValue, BaseIndex address)
3242     {
3243         atomicStrongCAS(expectedAndResult, address, [&amp;] { m_assembler.cmpxchgw_rm(newValue, address.offset, address.base, address.index, address.scale); });
3244     }
3245 
3246     void atomicStrongCAS32(RegisterID expectedAndResult, RegisterID newValue, Address address)
3247     {
3248         atomicStrongCAS(expectedAndResult, address, [&amp;] { m_assembler.cmpxchgl_rm(newValue, address.offset, address.base); });
3249     }
3250 
3251     void atomicStrongCAS32(RegisterID expectedAndResult, RegisterID newValue, BaseIndex address)
3252     {
3253         atomicStrongCAS(expectedAndResult, address, [&amp;] { m_assembler.cmpxchgl_rm(newValue, address.offset, address.base, address.index, address.scale); });
3254     }
3255 
3256     Jump branchAtomicStrongCAS8(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, Address address)
3257     {
3258         return branchAtomicStrongCAS(cond, expectedAndResult, address, [&amp;] { m_assembler.cmpxchgb_rm(newValue, address.offset, address.base); });
3259     }
3260 
3261     Jump branchAtomicStrongCAS8(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, BaseIndex address)
3262     {
3263         return branchAtomicStrongCAS(cond, expectedAndResult, address, [&amp;] { m_assembler.cmpxchgb_rm(newValue, address.offset, address.base, address.index, address.scale); });
3264     }
3265 
3266     Jump branchAtomicStrongCAS16(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, Address address)
3267     {
3268         return branchAtomicStrongCAS(cond, expectedAndResult, address, [&amp;] { m_assembler.cmpxchgw_rm(newValue, address.offset, address.base); });
3269     }
3270 
3271     Jump branchAtomicStrongCAS16(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, BaseIndex address)
3272     {
3273         return branchAtomicStrongCAS(cond, expectedAndResult, address, [&amp;] { m_assembler.cmpxchgw_rm(newValue, address.offset, address.base, address.index, address.scale); });
3274     }
3275 
3276     Jump branchAtomicStrongCAS32(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, Address address)
3277     {
3278         return branchAtomicStrongCAS(cond, expectedAndResult, address, [&amp;] { m_assembler.cmpxchgl_rm(newValue, address.offset, address.base); });
3279     }
3280 
3281     Jump branchAtomicStrongCAS32(StatusCondition cond, RegisterID expectedAndResult, RegisterID newValue, BaseIndex address)
3282     {
3283         return branchAtomicStrongCAS(cond, expectedAndResult, address, [&amp;] { m_assembler.cmpxchgl_rm(newValue, address.offset, address.base, address.index, address.scale); });
3284     }
3285 
3286     // If you use weak CAS, you cannot rely on expectedAndClobbered to have any particular value after
3287     // this completes. On x86, it will contain the result of the strong CAS. On ARM, it will still have
3288     // the expected value.
3289     void atomicWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address, RegisterID result)
3290     {
3291         atomicStrongCAS8(cond, expectedAndClobbered, newValue, address, result);
3292     }
3293 
3294     void atomicWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address, RegisterID result)
3295     {
3296         atomicStrongCAS8(cond, expectedAndClobbered, newValue, address, result);
3297     }
3298 
3299     void atomicWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address, RegisterID result)
3300     {
3301         atomicStrongCAS16(cond, expectedAndClobbered, newValue, address, result);
3302     }
3303 
3304     void atomicWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address, RegisterID result)
3305     {
3306         atomicStrongCAS16(cond, expectedAndClobbered, newValue, address, result);
3307     }
3308 
3309     void atomicWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address, RegisterID result)
3310     {
3311         atomicStrongCAS32(cond, expectedAndClobbered, newValue, address, result);
3312     }
3313 
3314     void atomicWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address, RegisterID result)
3315     {
3316         atomicStrongCAS32(cond, expectedAndClobbered, newValue, address, result);
3317     }
3318 
3319     Jump branchAtomicWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address)
3320     {
3321         return branchAtomicStrongCAS8(cond, expectedAndClobbered, newValue, address);
3322     }
3323 
3324     Jump branchAtomicWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address)
3325     {
3326         return branchAtomicStrongCAS8(cond, expectedAndClobbered, newValue, address);
3327     }
3328 
3329     Jump branchAtomicWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address)
3330     {
3331         return branchAtomicStrongCAS16(cond, expectedAndClobbered, newValue, address);
3332     }
3333 
3334     Jump branchAtomicWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address)
3335     {
3336         return branchAtomicStrongCAS16(cond, expectedAndClobbered, newValue, address);
3337     }
3338 
3339     Jump branchAtomicWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address)
3340     {
3341         return branchAtomicStrongCAS32(cond, expectedAndClobbered, newValue, address);
3342     }
3343 
3344     Jump branchAtomicWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address)
3345     {
3346         return branchAtomicStrongCAS32(cond, expectedAndClobbered, newValue, address);
3347     }
3348 
3349     void atomicRelaxedWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address, RegisterID result)
3350     {
3351         atomicStrongCAS8(cond, expectedAndClobbered, newValue, address, result);
3352     }
3353 
3354     void atomicRelaxedWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address, RegisterID result)
3355     {
3356         atomicStrongCAS8(cond, expectedAndClobbered, newValue, address, result);
3357     }
3358 
3359     void atomicRelaxedWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address, RegisterID result)
3360     {
3361         atomicStrongCAS16(cond, expectedAndClobbered, newValue, address, result);
3362     }
3363 
3364     void atomicRelaxedWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address, RegisterID result)
3365     {
3366         atomicStrongCAS16(cond, expectedAndClobbered, newValue, address, result);
3367     }
3368 
3369     void atomicRelaxedWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address, RegisterID result)
3370     {
3371         atomicStrongCAS32(cond, expectedAndClobbered, newValue, address, result);
3372     }
3373 
3374     void atomicRelaxedWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address, RegisterID result)
3375     {
3376         atomicStrongCAS32(cond, expectedAndClobbered, newValue, address, result);
3377     }
3378 
3379     Jump branchAtomicRelaxedWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address)
3380     {
3381         return branchAtomicStrongCAS8(cond, expectedAndClobbered, newValue, address);
3382     }
3383 
3384     Jump branchAtomicRelaxedWeakCAS8(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address)
3385     {
3386         return branchAtomicStrongCAS8(cond, expectedAndClobbered, newValue, address);
3387     }
3388 
3389     Jump branchAtomicRelaxedWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address)
3390     {
3391         return branchAtomicStrongCAS16(cond, expectedAndClobbered, newValue, address);
3392     }
3393 
3394     Jump branchAtomicRelaxedWeakCAS16(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address)
3395     {
3396         return branchAtomicStrongCAS16(cond, expectedAndClobbered, newValue, address);
3397     }
3398 
3399     Jump branchAtomicRelaxedWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, Address address)
3400     {
3401         return branchAtomicStrongCAS32(cond, expectedAndClobbered, newValue, address);
3402     }
3403 
3404     Jump branchAtomicRelaxedWeakCAS32(StatusCondition cond, RegisterID expectedAndClobbered, RegisterID newValue, BaseIndex address)
3405     {
3406         return branchAtomicStrongCAS32(cond, expectedAndClobbered, newValue, address);
3407     }
3408 
3409     void atomicAdd8(TrustedImm32 imm, Address address)
3410     {
3411         m_assembler.lock();
3412         add8(imm, address);
3413     }
3414 
3415     void atomicAdd8(TrustedImm32 imm, BaseIndex address)
3416     {
3417         m_assembler.lock();
3418         add8(imm, address);
3419     }
3420 
3421     void atomicAdd8(RegisterID reg, Address address)
3422     {
3423         m_assembler.lock();
3424         add8(reg, address);
3425     }
3426 
3427     void atomicAdd8(RegisterID reg, BaseIndex address)
3428     {
3429         m_assembler.lock();
3430         add8(reg, address);
3431     }
3432 
3433     void atomicAdd16(TrustedImm32 imm, Address address)
3434     {
3435         m_assembler.lock();
3436         add16(imm, address);
3437     }
3438 
3439     void atomicAdd16(TrustedImm32 imm, BaseIndex address)
3440     {
3441         m_assembler.lock();
3442         add16(imm, address);
3443     }
3444 
3445     void atomicAdd16(RegisterID reg, Address address)
3446     {
3447         m_assembler.lock();
3448         add16(reg, address);
3449     }
3450 
3451     void atomicAdd16(RegisterID reg, BaseIndex address)
3452     {
3453         m_assembler.lock();
3454         add16(reg, address);
3455     }
3456 
3457     void atomicAdd32(TrustedImm32 imm, Address address)
3458     {
3459         m_assembler.lock();
3460         add32(imm, address);
3461     }
3462 
3463     void atomicAdd32(TrustedImm32 imm, BaseIndex address)
3464     {
3465         m_assembler.lock();
3466         add32(imm, address);
3467     }
3468 
3469     void atomicAdd32(RegisterID reg, Address address)
3470     {
3471         m_assembler.lock();
3472         add32(reg, address);
3473     }
3474 
3475     void atomicAdd32(RegisterID reg, BaseIndex address)
3476     {
3477         m_assembler.lock();
3478         add32(reg, address);
3479     }
3480 
3481     void atomicSub8(TrustedImm32 imm, Address address)
3482     {
3483         m_assembler.lock();
3484         sub8(imm, address);
3485     }
3486 
3487     void atomicSub8(TrustedImm32 imm, BaseIndex address)
3488     {
3489         m_assembler.lock();
3490         sub8(imm, address);
3491     }
3492 
3493     void atomicSub8(RegisterID reg, Address address)
3494     {
3495         m_assembler.lock();
3496         sub8(reg, address);
3497     }
3498 
3499     void atomicSub8(RegisterID reg, BaseIndex address)
3500     {
3501         m_assembler.lock();
3502         sub8(reg, address);
3503     }
3504 
3505     void atomicSub16(TrustedImm32 imm, Address address)
3506     {
3507         m_assembler.lock();
3508         sub16(imm, address);
3509     }
3510 
3511     void atomicSub16(TrustedImm32 imm, BaseIndex address)
3512     {
3513         m_assembler.lock();
3514         sub16(imm, address);
3515     }
3516 
3517     void atomicSub16(RegisterID reg, Address address)
3518     {
3519         m_assembler.lock();
3520         sub16(reg, address);
3521     }
3522 
3523     void atomicSub16(RegisterID reg, BaseIndex address)
3524     {
3525         m_assembler.lock();
3526         sub16(reg, address);
3527     }
3528 
3529     void atomicSub32(TrustedImm32 imm, Address address)
3530     {
3531         m_assembler.lock();
3532         sub32(imm, address);
3533     }
3534 
3535     void atomicSub32(TrustedImm32 imm, BaseIndex address)
3536     {
3537         m_assembler.lock();
3538         sub32(imm, address);
3539     }
3540 
3541     void atomicSub32(RegisterID reg, Address address)
3542     {
3543         m_assembler.lock();
3544         sub32(reg, address);
3545     }
3546 
3547     void atomicSub32(RegisterID reg, BaseIndex address)
3548     {
3549         m_assembler.lock();
3550         sub32(reg, address);
3551     }
3552 
3553     void atomicAnd8(TrustedImm32 imm, Address address)
3554     {
3555         m_assembler.lock();
3556         and8(imm, address);
3557     }
3558 
3559     void atomicAnd8(TrustedImm32 imm, BaseIndex address)
3560     {
3561         m_assembler.lock();
3562         and8(imm, address);
3563     }
3564 
3565     void atomicAnd8(RegisterID reg, Address address)
3566     {
3567         m_assembler.lock();
3568         and8(reg, address);
3569     }
3570 
3571     void atomicAnd8(RegisterID reg, BaseIndex address)
3572     {
3573         m_assembler.lock();
3574         and8(reg, address);
3575     }
3576 
3577     void atomicAnd16(TrustedImm32 imm, Address address)
3578     {
3579         m_assembler.lock();
3580         and16(imm, address);
3581     }
3582 
3583     void atomicAnd16(TrustedImm32 imm, BaseIndex address)
3584     {
3585         m_assembler.lock();
3586         and16(imm, address);
3587     }
3588 
3589     void atomicAnd16(RegisterID reg, Address address)
3590     {
3591         m_assembler.lock();
3592         and16(reg, address);
3593     }
3594 
3595     void atomicAnd16(RegisterID reg, BaseIndex address)
3596     {
3597         m_assembler.lock();
3598         and16(reg, address);
3599     }
3600 
3601     void atomicAnd32(TrustedImm32 imm, Address address)
3602     {
3603         m_assembler.lock();
3604         and32(imm, address);
3605     }
3606 
3607     void atomicAnd32(TrustedImm32 imm, BaseIndex address)
3608     {
3609         m_assembler.lock();
3610         and32(imm, address);
3611     }
3612 
3613     void atomicAnd32(RegisterID reg, Address address)
3614     {
3615         m_assembler.lock();
3616         and32(reg, address);
3617     }
3618 
3619     void atomicAnd32(RegisterID reg, BaseIndex address)
3620     {
3621         m_assembler.lock();
3622         and32(reg, address);
3623     }
3624 
3625     void atomicOr8(TrustedImm32 imm, Address address)
3626     {
3627         m_assembler.lock();
3628         or8(imm, address);
3629     }
3630 
3631     void atomicOr8(TrustedImm32 imm, BaseIndex address)
3632     {
3633         m_assembler.lock();
3634         or8(imm, address);
3635     }
3636 
3637     void atomicOr8(RegisterID reg, Address address)
3638     {
3639         m_assembler.lock();
3640         or8(reg, address);
3641     }
3642 
3643     void atomicOr8(RegisterID reg, BaseIndex address)
3644     {
3645         m_assembler.lock();
3646         or8(reg, address);
3647     }
3648 
3649     void atomicOr16(TrustedImm32 imm, Address address)
3650     {
3651         m_assembler.lock();
3652         or16(imm, address);
3653     }
3654 
3655     void atomicOr16(TrustedImm32 imm, BaseIndex address)
3656     {
3657         m_assembler.lock();
3658         or16(imm, address);
3659     }
3660 
3661     void atomicOr16(RegisterID reg, Address address)
3662     {
3663         m_assembler.lock();
3664         or16(reg, address);
3665     }
3666 
3667     void atomicOr16(RegisterID reg, BaseIndex address)
3668     {
3669         m_assembler.lock();
3670         or16(reg, address);
3671     }
3672 
3673     void atomicOr32(TrustedImm32 imm, Address address)
3674     {
3675         m_assembler.lock();
3676         or32(imm, address);
3677     }
3678 
3679     void atomicOr32(TrustedImm32 imm, BaseIndex address)
3680     {
3681         m_assembler.lock();
3682         or32(imm, address);
3683     }
3684 
3685     void atomicOr32(RegisterID reg, Address address)
3686     {
3687         m_assembler.lock();
3688         or32(reg, address);
3689     }
3690 
3691     void atomicOr32(RegisterID reg, BaseIndex address)
3692     {
3693         m_assembler.lock();
3694         or32(reg, address);
3695     }
3696 
3697     void atomicXor8(TrustedImm32 imm, Address address)
3698     {
3699         m_assembler.lock();
3700         xor8(imm, address);
3701     }
3702 
3703     void atomicXor8(TrustedImm32 imm, BaseIndex address)
3704     {
3705         m_assembler.lock();
3706         xor8(imm, address);
3707     }
3708 
3709     void atomicXor8(RegisterID reg, Address address)
3710     {
3711         m_assembler.lock();
3712         xor8(reg, address);
3713     }
3714 
3715     void atomicXor8(RegisterID reg, BaseIndex address)
3716     {
3717         m_assembler.lock();
3718         xor8(reg, address);
3719     }
3720 
3721     void atomicXor16(TrustedImm32 imm, Address address)
3722     {
3723         m_assembler.lock();
3724         xor16(imm, address);
3725     }
3726 
3727     void atomicXor16(TrustedImm32 imm, BaseIndex address)
3728     {
3729         m_assembler.lock();
3730         xor16(imm, address);
3731     }
3732 
3733     void atomicXor16(RegisterID reg, Address address)
3734     {
3735         m_assembler.lock();
3736         xor16(reg, address);
3737     }
3738 
3739     void atomicXor16(RegisterID reg, BaseIndex address)
3740     {
3741         m_assembler.lock();
3742         xor16(reg, address);
3743     }
3744 
3745     void atomicXor32(TrustedImm32 imm, Address address)
3746     {
3747         m_assembler.lock();
3748         xor32(imm, address);
3749     }
3750 
3751     void atomicXor32(TrustedImm32 imm, BaseIndex address)
3752     {
3753         m_assembler.lock();
3754         xor32(imm, address);
3755     }
3756 
3757     void atomicXor32(RegisterID reg, Address address)
3758     {
3759         m_assembler.lock();
3760         xor32(reg, address);
3761     }
3762 
3763     void atomicXor32(RegisterID reg, BaseIndex address)
3764     {
3765         m_assembler.lock();
3766         xor32(reg, address);
3767     }
3768 
3769     void atomicNeg8(Address address)
3770     {
3771         m_assembler.lock();
3772         neg8(address);
3773     }
3774 
3775     void atomicNeg8(BaseIndex address)
3776     {
3777         m_assembler.lock();
3778         neg8(address);
3779     }
3780 
3781     void atomicNeg16(Address address)
3782     {
3783         m_assembler.lock();
3784         neg16(address);
3785     }
3786 
3787     void atomicNeg16(BaseIndex address)
3788     {
3789         m_assembler.lock();
3790         neg16(address);
3791     }
3792 
3793     void atomicNeg32(Address address)
3794     {
3795         m_assembler.lock();
3796         neg32(address);
3797     }
3798 
3799     void atomicNeg32(BaseIndex address)
3800     {
3801         m_assembler.lock();
3802         neg32(address);
3803     }
3804 
3805     void atomicNot8(Address address)
3806     {
3807         m_assembler.lock();
3808         not8(address);
3809     }
3810 
3811     void atomicNot8(BaseIndex address)
3812     {
3813         m_assembler.lock();
3814         not8(address);
3815     }
3816 
3817     void atomicNot16(Address address)
3818     {
3819         m_assembler.lock();
3820         not16(address);
3821     }
3822 
3823     void atomicNot16(BaseIndex address)
3824     {
3825         m_assembler.lock();
3826         not16(address);
3827     }
3828 
3829     void atomicNot32(Address address)
3830     {
3831         m_assembler.lock();
3832         not32(address);
3833     }
3834 
3835     void atomicNot32(BaseIndex address)
3836     {
3837         m_assembler.lock();
3838         not32(address);
3839     }
3840 
3841     void atomicXchgAdd8(RegisterID reg, Address address)
3842     {
3843         m_assembler.lock();
3844         m_assembler.xaddb_rm(reg, address.offset, address.base);
3845     }
3846 
3847     void atomicXchgAdd8(RegisterID reg, BaseIndex address)
3848     {
3849         m_assembler.lock();
3850         m_assembler.xaddb_rm(reg, address.offset, address.base, address.index, address.scale);
3851     }
3852 
3853     void atomicXchgAdd16(RegisterID reg, Address address)
3854     {
3855         m_assembler.lock();
3856         m_assembler.xaddw_rm(reg, address.offset, address.base);
3857     }
3858 
3859     void atomicXchgAdd16(RegisterID reg, BaseIndex address)
3860     {
3861         m_assembler.lock();
3862         m_assembler.xaddw_rm(reg, address.offset, address.base, address.index, address.scale);
3863     }
3864 
3865     void atomicXchgAdd32(RegisterID reg, Address address)
3866     {
3867         m_assembler.lock();
3868         m_assembler.xaddl_rm(reg, address.offset, address.base);
3869     }
3870 
3871     void atomicXchgAdd32(RegisterID reg, BaseIndex address)
3872     {
3873         m_assembler.lock();
3874         m_assembler.xaddl_rm(reg, address.offset, address.base, address.index, address.scale);
3875     }
3876 
3877     void atomicXchg8(RegisterID reg, Address address)
3878     {
3879         m_assembler.lock();
3880         m_assembler.xchgb_rm(reg, address.offset, address.base);
3881     }
3882 
3883     void atomicXchg8(RegisterID reg, BaseIndex address)
3884     {
3885         m_assembler.lock();
3886         m_assembler.xchgb_rm(reg, address.offset, address.base, address.index, address.scale);
3887     }
3888 
3889     void atomicXchg16(RegisterID reg, Address address)
3890     {
3891         m_assembler.lock();
3892         m_assembler.xchgw_rm(reg, address.offset, address.base);
3893     }
3894 
3895     void atomicXchg16(RegisterID reg, BaseIndex address)
3896     {
3897         m_assembler.lock();
3898         m_assembler.xchgw_rm(reg, address.offset, address.base, address.index, address.scale);
3899     }
3900 
3901     void atomicXchg32(RegisterID reg, Address address)
3902     {
3903         m_assembler.lock();
3904         m_assembler.xchgl_rm(reg, address.offset, address.base);
3905     }
3906 
3907     void atomicXchg32(RegisterID reg, BaseIndex address)
3908     {
3909         m_assembler.lock();
3910         m_assembler.xchgl_rm(reg, address.offset, address.base, address.index, address.scale);
3911     }
3912 
3913     // We take this to mean that it prevents motion of normal stores. So, it&#39;s a no-op on x86.
3914     void storeFence()
3915     {
3916     }
3917 
3918     // We take this to mean that it prevents motion of normal loads. So, it&#39;s a no-op on x86.
3919     void loadFence()
3920     {
3921     }
3922 
3923 #if ENABLE(FAST_TLS_JIT)
3924     void loadFromTLS32(uint32_t offset, RegisterID dst)
3925     {
3926         m_assembler.gs();
3927         m_assembler.movl_mr(offset, dst);
3928     }
3929 
3930 
3931     static bool loadFromTLSPtrNeedsMacroScratchRegister()
3932     {
3933         return false;
3934     }
3935 
3936     void storeToTLS32(RegisterID src, uint32_t offset)
3937     {
3938         m_assembler.gs();
3939         m_assembler.movl_rm(src, offset);
3940     }
3941 
3942     static bool storeToTLSPtrNeedsMacroScratchRegister()
3943     {
3944         return false;
3945     }
3946 #endif
3947 
3948     template&lt;PtrTag tag&gt;
3949     static void replaceWithVMHalt(CodeLocationLabel&lt;tag&gt; instructionStart)
3950     {
3951         X86Assembler::replaceWithHlt(instructionStart.executableAddress());
3952     }
3953 
3954     template&lt;PtrTag startTag, PtrTag destTag&gt;
3955     static void replaceWithJump(CodeLocationLabel&lt;startTag&gt; instructionStart, CodeLocationLabel&lt;destTag&gt; destination)
3956     {
3957         X86Assembler::replaceWithJump(instructionStart.executableAddress(), destination.executableAddress());
3958     }
3959 
3960     static ptrdiff_t maxJumpReplacementSize()
3961     {
3962         return X86Assembler::maxJumpReplacementSize();
3963     }
3964 
3965     static ptrdiff_t patchableJumpSize()
3966     {
3967         return X86Assembler::patchableJumpSize();
3968     }
3969 
3970     static bool supportsFloatingPointRounding()
3971     {
3972         if (s_sse4_1CheckState == CPUIDCheckState::NotChecked)
3973             collectCPUFeatures();
3974         return s_sse4_1CheckState == CPUIDCheckState::Set;
3975     }
3976 
3977     static bool supportsCountPopulation()
3978     {
3979         if (s_popcntCheckState == CPUIDCheckState::NotChecked)
3980             collectCPUFeatures();
3981         return s_popcntCheckState == CPUIDCheckState::Set;
3982     }
3983 
3984     static bool supportsAVX()
3985     {
3986         // AVX still causes mysterious regressions and those regressions can be massive.
3987         return false;
3988     }
3989 
3990     void lfence()
3991     {
3992         m_assembler.lfence();
3993     }
3994 
3995     void mfence()
3996     {
3997         m_assembler.mfence();
3998     }
3999 
4000     void sfence()
4001     {
4002         m_assembler.sfence();
4003     }
4004 
4005     void rdtsc()
4006     {
4007         m_assembler.rdtsc();
4008     }
4009 
4010     void pause()
4011     {
4012         m_assembler.pause();
4013     }
4014 
4015     void cpuid()
4016     {
4017         m_assembler.cpuid();
4018     }
4019 
4020 protected:
4021     X86Assembler::Condition x86Condition(RelationalCondition cond)
4022     {
4023         return static_cast&lt;X86Assembler::Condition&gt;(cond);
4024     }
4025 
4026     X86Assembler::Condition x86Condition(ResultCondition cond)
4027     {
4028         return static_cast&lt;X86Assembler::Condition&gt;(cond);
4029     }
4030 
4031     X86Assembler::Condition x86Condition(StatusCondition cond)
4032     {
4033         switch (cond) {
4034         case Success:
4035             return X86Assembler::ConditionE;
4036         case Failure:
4037             return X86Assembler::ConditionNE;
4038         }
4039         RELEASE_ASSERT_NOT_REACHED();
4040         return X86Assembler::ConditionE;
4041     }
4042 
4043     void set32(X86Assembler::Condition cond, RegisterID dest)
4044     {
4045 #if CPU(X86)
4046         // On 32-bit x86 we can only set the first 4 registers;
4047         // esp..edi are mapped to the &#39;h&#39; registers!
4048         if (dest &gt;= 4) {
4049             m_assembler.xchgl_rr(dest, X86Registers::eax);
4050             m_assembler.setCC_r(cond, X86Registers::eax);
4051             m_assembler.movzbl_rr(X86Registers::eax, X86Registers::eax);
4052             m_assembler.xchgl_rr(dest, X86Registers::eax);
4053             return;
4054         }
4055 #endif
4056         m_assembler.setCC_r(cond, dest);
4057         m_assembler.movzbl_rr(dest, dest);
4058     }
4059 
4060     void cmov(X86Assembler::Condition cond, RegisterID src, RegisterID dest)
4061     {
4062 #if CPU(X86_64)
4063         m_assembler.cmovq_rr(cond, src, dest);
4064 #else
4065         m_assembler.cmovl_rr(cond, src, dest);
4066 #endif
4067     }
4068 
4069     static bool supportsLZCNT()
4070     {
4071         if (s_lzcntCheckState == CPUIDCheckState::NotChecked)
4072             collectCPUFeatures();
4073         return s_lzcntCheckState == CPUIDCheckState::Set;
4074     }
4075 
4076     static bool supportsBMI1()
4077     {
4078         if (s_bmi1CheckState == CPUIDCheckState::NotChecked)
4079             collectCPUFeatures();
4080         return s_bmi1CheckState == CPUIDCheckState::Set;
4081     }
4082 
4083     template&lt;int sizeOfRegister&gt;
4084     void ctzAfterBsf(RegisterID dst)
4085     {
4086         Jump srcIsNonZero = m_assembler.jCC(x86Condition(NonZero));
4087         move(TrustedImm32(sizeOfRegister), dst);
4088         srcIsNonZero.link(this);
4089     }
4090 
4091     template&lt;typename AddressType, typename Func&gt;
4092     void atomicStrongCAS(StatusCondition cond, RegisterID expectedAndResult, RegisterID result, AddressType&amp; address, const Func&amp; func)
4093     {
4094         address = address.withSwappedRegister(X86Registers::eax, expectedAndResult);
4095         swap(expectedAndResult, X86Registers::eax);
4096         m_assembler.lock();
4097         func();
4098         swap(expectedAndResult, X86Registers::eax);
4099         set32(x86Condition(cond), result);
4100     }
4101 
4102     template&lt;typename AddressType, typename Func&gt;
4103     void atomicStrongCAS(RegisterID expectedAndResult, AddressType&amp; address, const Func&amp; func)
4104     {
4105         address = address.withSwappedRegister(X86Registers::eax, expectedAndResult);
4106         swap(expectedAndResult, X86Registers::eax);
4107         m_assembler.lock();
4108         func();
4109         swap(expectedAndResult, X86Registers::eax);
4110     }
4111 
4112     template&lt;typename AddressType, typename Func&gt;
4113     Jump branchAtomicStrongCAS(StatusCondition cond, RegisterID expectedAndResult, AddressType&amp; address, const Func&amp; func)
4114     {
4115         address = address.withSwappedRegister(X86Registers::eax, expectedAndResult);
4116         swap(expectedAndResult, X86Registers::eax);
4117         m_assembler.lock();
4118         func();
4119         swap(expectedAndResult, X86Registers::eax);
4120         return Jump(m_assembler.jCC(x86Condition(cond)));
4121     }
4122 
4123 private:
4124     // Only MacroAssemblerX86 should be using the following method; SSE2 is always available on
4125     // x86_64, and clients &amp; subclasses of MacroAssembler should be using &#39;supportsFloatingPoint()&#39;.
4126     friend class MacroAssemblerX86;
4127 
4128     ALWAYS_INLINE void generateTest32(Address address, TrustedImm32 mask = TrustedImm32(-1))
4129     {
4130         if (mask.m_value == -1)
4131             m_assembler.cmpl_im(0, address.offset, address.base);
4132         else if (!(mask.m_value &amp; ~0xff))
4133             m_assembler.testb_im(mask.m_value, address.offset, address.base);
4134         else if (!(mask.m_value &amp; ~0xff00))
4135             m_assembler.testb_im(mask.m_value &gt;&gt; 8, address.offset + 1, address.base);
4136         else if (!(mask.m_value &amp; ~0xff0000))
4137             m_assembler.testb_im(mask.m_value &gt;&gt; 16, address.offset + 2, address.base);
4138         else if (!(mask.m_value &amp; ~0xff000000))
4139             m_assembler.testb_im(mask.m_value &gt;&gt; 24, address.offset + 3, address.base);
4140         else
4141             m_assembler.testl_i32m(mask.m_value, address.offset, address.base);
4142     }
4143 
4144     // If lzcnt is not available, use this after BSR
4145     // to count the leading zeros.
4146     void clz32AfterBsr(RegisterID dst)
4147     {
4148         Jump srcIsNonZero = m_assembler.jCC(x86Condition(NonZero));
4149         move(TrustedImm32(32), dst);
4150 
4151         Jump skipNonZeroCase = jump();
4152         srcIsNonZero.link(this);
4153         xor32(TrustedImm32(0x1f), dst);
4154         skipNonZeroCase.link(this);
4155     }
4156 
4157     template&lt;typename Function&gt;
4158     void floatingPointCompare(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID dest, Function compare)
4159     {
4160         if (cond &amp; DoubleConditionBitSpecial) {
4161             ASSERT(!(cond &amp; DoubleConditionBitInvert));
4162             if (cond == DoubleEqual) {
4163                 if (left == right) {
4164                     compare(right, left);
4165                     set32(X86Assembler::ConditionNP, dest);
4166                     return;
4167                 }
4168 
4169                 move(TrustedImm32(0), dest);
4170                 compare(right, left);
4171                 Jump isUnordered = m_assembler.jp();
4172                 set32(X86Assembler::ConditionE, dest);
4173                 isUnordered.link(this);
4174                 return;
4175             }
4176             if (cond == DoubleNotEqualOrUnordered) {
4177                 if (left == right) {
4178                     compare(right, left);
4179                     set32(X86Assembler::ConditionP, dest);
4180                     return;
4181                 }
4182 
4183                 move(TrustedImm32(1), dest);
4184                 compare(right, left);
4185                 Jump isUnordered = m_assembler.jp();
4186                 set32(X86Assembler::ConditionNE, dest);
4187                 isUnordered.link(this);
4188                 return;
4189             }
4190 
4191             RELEASE_ASSERT_NOT_REACHED();
4192             return;
4193         }
4194 
4195         if (cond &amp; DoubleConditionBitInvert)
4196             compare(left, right);
4197         else
4198             compare(right, left);
4199         set32(static_cast&lt;X86Assembler::Condition&gt;(cond &amp; ~DoubleConditionBits), dest);
4200     }
4201 
4202     Jump jumpAfterFloatingPointCompare(DoubleCondition cond, FPRegisterID left, FPRegisterID right)
4203     {
4204         if (cond == DoubleEqual) {
4205             if (left == right)
4206                 return Jump(m_assembler.jnp());
4207             Jump isUnordered(m_assembler.jp());
4208             Jump result = Jump(m_assembler.je());
4209             isUnordered.link(this);
4210             return result;
4211         }
4212         if (cond == DoubleNotEqualOrUnordered) {
4213             if (left == right)
4214                 return Jump(m_assembler.jp());
4215             Jump isUnordered(m_assembler.jp());
4216             Jump isEqual(m_assembler.je());
4217             isUnordered.link(this);
4218             Jump result = jump();
4219             isEqual.link(this);
4220             return result;
4221         }
4222 
4223         ASSERT(!(cond &amp; DoubleConditionBitSpecial));
4224         return Jump(m_assembler.jCC(static_cast&lt;X86Assembler::Condition&gt;(cond &amp; ~DoubleConditionBits)));
4225     }
4226 
4227     // The 32bit Move does not need the REX byte for low registers, making it shorter.
4228     // Use this if the top bits are irrelevant because they will be reset by the next instruction.
4229     void move32IfNeeded(RegisterID src, RegisterID dest)
4230     {
4231         if (src == dest)
4232             return;
4233         m_assembler.movl_rr(src, dest);
4234     }
4235 
4236 #if CPU(X86_64)
4237     void moveConditionallyAfterFloatingPointCompare(DoubleCondition cond, FPRegisterID left, FPRegisterID right, RegisterID src, RegisterID dest)
4238     {
4239         if (cond == DoubleEqual) {
4240             if (left == right) {
4241                 m_assembler.cmovnpq_rr(src, dest);
4242                 return;
4243             }
4244 
4245             Jump isUnordered(m_assembler.jp());
4246             m_assembler.cmoveq_rr(src, dest);
4247             isUnordered.link(this);
4248             return;
4249         }
4250 
4251         if (cond == DoubleNotEqualOrUnordered) {
4252             if (left == right) {
4253                 m_assembler.cmovpq_rr(src, dest);
4254                 return;
4255             }
4256 
4257             m_assembler.cmovpq_rr(src, dest);
4258             m_assembler.cmovneq_rr(src, dest);
4259             return;
4260         }
4261 
4262         ASSERT(!(cond &amp; DoubleConditionBitSpecial));
4263         cmov(static_cast&lt;X86Assembler::Condition&gt;(cond &amp; ~DoubleConditionBits), src, dest);
4264     }
<a name="64" id="anc64"></a><span class="line-removed">4265 #endif</span>
<span class="line-removed">4266 #if !defined(NDEBUG) // CPU(X86)</span>
<span class="line-removed">4267 </span>
<span class="line-removed">4268     // On x86-64 we should never be checking for SSE2 in a non-debug build,</span>
<span class="line-removed">4269     // but non debug add this method to keep the asserts above happy.</span>
<span class="line-removed">4270     static bool isSSE2Present()</span>
<span class="line-removed">4271     {</span>
<span class="line-removed">4272         return true;</span>
<span class="line-removed">4273     }</span>
<span class="line-removed">4274 </span>
4275 #endif
4276 
4277     using CPUID = std::array&lt;unsigned, 4&gt;;
4278     static CPUID getCPUID(unsigned level);
4279     static CPUID getCPUIDEx(unsigned level, unsigned count);
4280     JS_EXPORT_PRIVATE static void collectCPUFeatures();
4281 
4282     JS_EXPORT_PRIVATE static CPUIDCheckState s_sse4_1CheckState;
4283     JS_EXPORT_PRIVATE static CPUIDCheckState s_sse4_2CheckState;
4284     JS_EXPORT_PRIVATE static CPUIDCheckState s_avxCheckState;
4285     JS_EXPORT_PRIVATE static CPUIDCheckState s_lzcntCheckState;
4286     JS_EXPORT_PRIVATE static CPUIDCheckState s_bmi1CheckState;
4287     JS_EXPORT_PRIVATE static CPUIDCheckState s_popcntCheckState;
4288 };
4289 
4290 } // namespace JSC
4291 
4292 #endif // ENABLE(ASSEMBLER)
<a name="65" id="anc65"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="65" type="hidden" />
</body>
</html>