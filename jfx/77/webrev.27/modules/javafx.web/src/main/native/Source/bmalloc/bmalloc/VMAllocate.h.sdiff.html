<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/VMAllocate.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="SmallPage.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="VMHeap.cpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/bmalloc/bmalloc/VMAllocate.h</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
113 }
114 
115 inline void vmValidatePhysical(void* p, size_t vmSize)
116 {
117     vmValidatePhysical(vmSize);
118 
119     BUNUSED(p);
120     BASSERT(p);
121     BASSERT(p == mask(p, ~(vmPageSizePhysical() - 1)));
122 }
123 
124 inline void* tryVMAllocate(size_t vmSize, VMTag usage = VMTag::Malloc)
125 {
126     vmValidate(vmSize);
127     void* result = mmap(0, vmSize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON | BMALLOC_NORESERVE, static_cast&lt;int&gt;(usage), 0);
128     if (result == MAP_FAILED)
129         return nullptr;
130     return result;
131 }
132 
<span class="line-modified">133 inline void* vmAllocate(size_t vmSize)</span>
134 {
<span class="line-modified">135     void* result = tryVMAllocate(vmSize);</span>
136     RELEASE_BASSERT(result);
137     return result;
138 }
139 
140 inline void vmDeallocate(void* p, size_t vmSize)
141 {
142     vmValidate(p, vmSize);
143     munmap(p, vmSize);
144 }
145 
146 inline void vmRevokePermissions(void* p, size_t vmSize)
147 {
148     vmValidate(p, vmSize);
149     mprotect(p, vmSize, PROT_NONE);
150 }
151 
152 inline void vmZeroAndPurge(void* p, size_t vmSize, VMTag usage = VMTag::Malloc)
153 {
154     vmValidate(p, vmSize);
155     // MAP_ANON guarantees the memory is zeroed. This will also cause
</pre>
<hr />
<pre>
172 
173     char* mapped = static_cast&lt;char*&gt;(tryVMAllocate(mappedSize, usage));
174     if (!mapped)
175         return nullptr;
176     char* mappedEnd = mapped + mappedSize;
177 
178     char* aligned = roundUpToMultipleOf(vmAlignment, mapped);
179     char* alignedEnd = aligned + vmSize;
180 
181     RELEASE_BASSERT(alignedEnd &lt;= mappedEnd);
182 
183     if (size_t leftExtra = aligned - mapped)
184         vmDeallocate(mapped, leftExtra);
185 
186     if (size_t rightExtra = mappedEnd - alignedEnd)
187         vmDeallocate(alignedEnd, rightExtra);
188 
189     return aligned;
190 }
191 
<span class="line-modified">192 inline void* vmAllocate(size_t vmAlignment, size_t vmSize)</span>
193 {
<span class="line-modified">194     void* result = tryVMAllocate(vmAlignment, vmSize);</span>
195     RELEASE_BASSERT(result);
196     return result;
197 }
198 
199 inline void vmDeallocatePhysicalPages(void* p, size_t vmSize)
200 {
201     vmValidatePhysical(p, vmSize);
202 #if BOS(DARWIN)
203     SYSCALL(madvise(p, vmSize, MADV_FREE_REUSABLE));


204 #else
205     SYSCALL(madvise(p, vmSize, MADV_DONTNEED));
206 #if BOS(LINUX)
207     SYSCALL(madvise(p, vmSize, MADV_DONTDUMP));
208 #endif
209 #endif
210 }
211 
212 inline void vmAllocatePhysicalPages(void* p, size_t vmSize)
213 {
214     vmValidatePhysical(p, vmSize);
215 #if BOS(DARWIN)
216     SYSCALL(madvise(p, vmSize, MADV_FREE_REUSE));
217 #else
218     SYSCALL(madvise(p, vmSize, MADV_NORMAL));
219 #if BOS(LINUX)
220     SYSCALL(madvise(p, vmSize, MADV_DODUMP));
221 #endif
222 #endif
223 }
</pre>
</td>
<td>
<hr />
<pre>
113 }
114 
115 inline void vmValidatePhysical(void* p, size_t vmSize)
116 {
117     vmValidatePhysical(vmSize);
118 
119     BUNUSED(p);
120     BASSERT(p);
121     BASSERT(p == mask(p, ~(vmPageSizePhysical() - 1)));
122 }
123 
124 inline void* tryVMAllocate(size_t vmSize, VMTag usage = VMTag::Malloc)
125 {
126     vmValidate(vmSize);
127     void* result = mmap(0, vmSize, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON | BMALLOC_NORESERVE, static_cast&lt;int&gt;(usage), 0);
128     if (result == MAP_FAILED)
129         return nullptr;
130     return result;
131 }
132 
<span class="line-modified">133 inline void* vmAllocate(size_t vmSize, VMTag usage = VMTag::Malloc)</span>
134 {
<span class="line-modified">135     void* result = tryVMAllocate(vmSize, usage);</span>
136     RELEASE_BASSERT(result);
137     return result;
138 }
139 
140 inline void vmDeallocate(void* p, size_t vmSize)
141 {
142     vmValidate(p, vmSize);
143     munmap(p, vmSize);
144 }
145 
146 inline void vmRevokePermissions(void* p, size_t vmSize)
147 {
148     vmValidate(p, vmSize);
149     mprotect(p, vmSize, PROT_NONE);
150 }
151 
152 inline void vmZeroAndPurge(void* p, size_t vmSize, VMTag usage = VMTag::Malloc)
153 {
154     vmValidate(p, vmSize);
155     // MAP_ANON guarantees the memory is zeroed. This will also cause
</pre>
<hr />
<pre>
172 
173     char* mapped = static_cast&lt;char*&gt;(tryVMAllocate(mappedSize, usage));
174     if (!mapped)
175         return nullptr;
176     char* mappedEnd = mapped + mappedSize;
177 
178     char* aligned = roundUpToMultipleOf(vmAlignment, mapped);
179     char* alignedEnd = aligned + vmSize;
180 
181     RELEASE_BASSERT(alignedEnd &lt;= mappedEnd);
182 
183     if (size_t leftExtra = aligned - mapped)
184         vmDeallocate(mapped, leftExtra);
185 
186     if (size_t rightExtra = mappedEnd - alignedEnd)
187         vmDeallocate(alignedEnd, rightExtra);
188 
189     return aligned;
190 }
191 
<span class="line-modified">192 inline void* vmAllocate(size_t vmAlignment, size_t vmSize, VMTag usage = VMTag::Malloc)</span>
193 {
<span class="line-modified">194     void* result = tryVMAllocate(vmAlignment, vmSize, usage);</span>
195     RELEASE_BASSERT(result);
196     return result;
197 }
198 
199 inline void vmDeallocatePhysicalPages(void* p, size_t vmSize)
200 {
201     vmValidatePhysical(p, vmSize);
202 #if BOS(DARWIN)
203     SYSCALL(madvise(p, vmSize, MADV_FREE_REUSABLE));
<span class="line-added">204 #elif BOS(FREEBSD)</span>
<span class="line-added">205     SYSCALL(madvise(p, vmSize, MADV_FREE));</span>
206 #else
207     SYSCALL(madvise(p, vmSize, MADV_DONTNEED));
208 #if BOS(LINUX)
209     SYSCALL(madvise(p, vmSize, MADV_DONTDUMP));
210 #endif
211 #endif
212 }
213 
214 inline void vmAllocatePhysicalPages(void* p, size_t vmSize)
215 {
216     vmValidatePhysical(p, vmSize);
217 #if BOS(DARWIN)
218     SYSCALL(madvise(p, vmSize, MADV_FREE_REUSE));
219 #else
220     SYSCALL(madvise(p, vmSize, MADV_NORMAL));
221 #if BOS(LINUX)
222     SYSCALL(madvise(p, vmSize, MADV_DODUMP));
223 #endif
224 #endif
225 }
</pre>
</td>
</tr>
</table>
<center><a href="SmallPage.h.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="VMHeap.cpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>