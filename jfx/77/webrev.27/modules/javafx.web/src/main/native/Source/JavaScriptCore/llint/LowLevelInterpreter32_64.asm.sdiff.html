<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter32_64.asm</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
  </head>
<body>
<center><a href="LowLevelInterpreter.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter64.asm.sdiff.html" target="_top">next &gt;</a></center>    <h2>modules/javafx.web/src/main/native/Source/JavaScriptCore/llint/LowLevelInterpreter32_64.asm</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 
  25 # Utilities
  26 macro nextInstruction()
  27     loadb [PC], t0
  28     leap _g_opcodeMap, t1
  29     jmp [t1, t0, 4], BytecodePtrTag
  30 end
  31 
<span class="line-modified">  32 macro nextInstructionWide()</span>






  33     loadi 1[PC], t0
<span class="line-modified">  34     leap _g_opcodeMapWide, t1</span>
  35     jmp [t1, t0, 4], BytecodePtrTag
  36 end
  37 
  38 macro getuOperandNarrow(opcodeStruct, fieldName, dst)
  39     loadb constexpr %opcodeStruct%_%fieldName%_index[PC], dst
  40 end
  41 
  42 macro getOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  43     loadbsp constexpr %opcodeStruct%_%fieldName%_index[PC], dst</span>
  44 end
  45 
<span class="line-modified">  46 macro getuOperandWide(opcodeStruct, fieldName, dst)</span>








  47     loadi constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PC], dst
  48 end
  49 
<span class="line-modified">  50 macro getOperandWide(opcodeStruct, fieldName, dst)</span>
  51     loadis constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PC], dst
  52 end
  53 
  54 macro makeReturn(get, dispatch, fn)
  55     fn(macro(tag, payload)
  56         move tag, t5
  57         move payload, t3
  58         get(m_dst, t2)
  59         storei t5, TagOffset[cfr, t2, 8]
  60         storei t3, PayloadOffset[cfr, t2, 8]
  61         dispatch()
  62     end)
  63 end
  64 
  65 macro makeReturnProfiled(opcodeStruct, get, metadata, dispatch, fn)
  66     fn(macro (tag, payload)
  67         move tag, t1
  68         move payload, t0
  69 
  70         metadata(t5, t2)
</pre>
<hr />
<pre>
  79 
  80 macro dispatchAfterCall(size, opcodeStruct, dispatch)
  81     loadi ArgumentCount + TagOffset[cfr], PC
  82     get(size, opcodeStruct, m_dst, t3)
  83     storei r1, TagOffset[cfr, t3, 8]
  84     storei r0, PayloadOffset[cfr, t3, 8]
  85     metadata(size, opcodeStruct, t2, t3)
  86     valueProfile(opcodeStruct, t2, r1, r0)
  87     dispatch()
  88 end
  89 
  90 macro cCall2(function)
  91     if ARMv7 or MIPS
  92         call function
  93     elsif X86 or X86_WIN
  94         subp 8, sp
  95         push a1
  96         push a0
  97         call function
  98         addp 16, sp
<span class="line-modified">  99     elsif C_LOOP</span>
 100         cloopCallSlowPath function, a0, a1
 101     else
 102         error
 103     end
 104 end
 105 
 106 macro cCall2Void(function)
<span class="line-modified"> 107     if C_LOOP</span>
 108         cloopCallSlowPathVoid function, a0, a1
 109     else
 110         cCall2(function)
 111     end
 112 end
 113 
 114 macro cCall4(function)
 115     if ARMv7 or MIPS
 116         call function
 117     elsif X86 or X86_WIN
 118         push a3
 119         push a2
 120         push a1
 121         push a0
 122         call function
 123         addp 16, sp
<span class="line-modified"> 124     elsif C_LOOP</span>
 125         error
 126     else
 127         error
 128     end
 129 end
 130 
 131 macro callSlowPath(slowPath)
 132     move cfr, a0
 133     move PC, a1
 134     cCall2(slowPath)
 135     move r0, PC
 136 end
 137 
 138 macro doVMEntry(makeCall)
 139     functionPrologue()
 140     pushCalleeSaves()
 141 
 142     # x86 needs to load arguments from the stack
 143     if X86 or X86_WIN
 144         loadp 16[cfr], a2
</pre>
<hr />
<pre>
 173     if X86_WIN or MIPS
 174         addp CallFrameAlignSlots * SlotSize, sp, t3
 175         andp ~StackAlignmentMask, t3
 176         subp t3, CallFrameAlignSlots * SlotSize, sp
 177     elsif ARMv7
 178         addp CallFrameAlignSlots * SlotSize, sp, t3
 179         clrbp t3, StackAlignmentMask, t3
 180         subp t3, CallFrameAlignSlots * SlotSize, t3
 181         move t3, sp
 182     end
 183 
 184     loadi ProtoCallFrame::paddedArgCount[protoCallFrame], t4
 185     addp CallFrameHeaderSlots, t4, t4
 186     lshiftp 3, t4
 187     subp sp, t4, t3
 188     bpa t3, sp, .throwStackOverflow
 189 
 190     # Ensure that we have enough additional stack capacity for the incoming args,
 191     # and the frame for the JS code we&#39;re executing. We need to do this check
 192     # before we start copying the args from the protoCallFrame below.
<span class="line-modified"> 193     if C_LOOP</span>
 194         bpaeq t3, VM::m_cloopStackLimit[vm], .stackHeightOK
 195         move entry, t4
 196         move vm, t5
 197         cloopCallSlowPath _llint_stack_check_at_vm_entry, vm, t3
 198         bpeq t0, 0, .stackCheckFailed
 199         move t4, entry
 200         move t5, vm
 201         jmp .stackHeightOK
 202 
 203 .stackCheckFailed:
 204         move t4, entry
 205         move t5, vm
 206         jmp .throwStackOverflow
 207     else
 208         bpb t3, VM::m_softStackLimit[vm], .throwStackOverflow
 209     end
 210 
 211 .stackHeightOK:
 212     move t3, sp
 213     move (constexpr ProtoCallFrame::numberOfRegisters), t3
</pre>
<hr />
<pre>
 291     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 292     storep t4, VM::topCallFrame[t5]
 293     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 294     storep t4, VM::topEntryFrame[t5]
 295 
 296     if ARMv7
 297         subp cfr, CalleeRegisterSaveSize, t5
 298         move t5, sp
 299     else
 300         subp cfr, CalleeRegisterSaveSize, sp
 301     end
 302 
 303     popCalleeSaves()
 304     functionEpilogue()
 305     ret
 306 end
 307 
 308 macro makeJavaScriptCall(entry, temp, unused)
 309     addp CallerFrameAndPCSize, sp
 310     checkStackPointerAlignment(temp, 0xbad0dc02)
<span class="line-modified"> 311     if C_LOOP</span>
 312         cloopCallJSFunction entry
 313     else
 314         call entry
 315     end
 316     checkStackPointerAlignment(temp, 0xbad0dc03)
 317     subp CallerFrameAndPCSize, sp
 318 end
 319 
 320 macro makeHostFunctionCall(entry, temp1, temp2)
 321     move entry, temp1
 322     storep cfr, [sp]
<span class="line-modified"> 323     if C_LOOP</span>
 324         move sp, a0
 325         storep lr, PtrSize[sp]
 326         cloopCallNative temp1
 327     elsif X86 or X86_WIN
 328         # Put callee frame pointer on stack as arg0, also put it in ecx for &quot;fastcall&quot; targets
 329         move 0, temp2
 330         move temp2, 4[sp] # put 0 in ReturnPC
 331         move sp, a0 # a0 is ecx
 332         push temp2 # Push dummy arg1
 333         push a0
 334         call temp1
 335         addp 8, sp
 336     else
 337         move sp, a0
 338         call temp1
 339     end
 340 end
 341 
 342 op(handleUncaughtException, macro()
 343     loadp Callee + PayloadOffset[cfr], t3
</pre>
<hr />
<pre>
 430             move cfr, a0
 431             move PC, a1
 432             cCall2(_llint_loop_osr)
 433             btpz r0, .recover
 434             move r1, sp
 435             jmp r0
 436         .recover:
 437             loadi ArgumentCount + TagOffset[cfr], PC
 438         end)
 439 end
 440 
 441 macro loadVariable(get, fieldName, indexReg, tagReg, payloadReg)
 442     get(fieldName, indexReg)
 443     loadi TagOffset[cfr, indexReg, 8], tagReg
 444     loadi PayloadOffset[cfr, indexReg, 8], payloadReg
 445 end
 446 
 447 # Index, tag, and payload must be different registers. Index is not
 448 # changed.
 449 macro loadConstantOrVariable(size, index, tag, payload)
<span class="line-modified"> 450     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide, macro (FirstConstantRegisterIndex)</span>
 451         bigteq index, FirstConstantRegisterIndex, .constant
 452         loadi TagOffset[cfr, index, 8], tag
 453         loadi PayloadOffset[cfr, index, 8], payload
 454         jmp .done
 455     .constant:
 456         loadp CodeBlock[cfr], payload
 457         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload
 458         subp FirstConstantRegisterIndex, index
 459         loadp TagOffset[payload, index, 8], tag
 460         loadp PayloadOffset[payload, index, 8], payload
 461     .done:
 462     end)
 463 end
 464 
 465 macro loadConstantOrVariableTag(size, index, tag)
<span class="line-modified"> 466     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide, macro (FirstConstantRegisterIndex)</span>
 467         bigteq index, FirstConstantRegisterIndex, .constant
 468         loadi TagOffset[cfr, index, 8], tag
 469         jmp .done
 470     .constant:
 471         loadp CodeBlock[cfr], tag
 472         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 473         subi FirstConstantRegisterIndex, index
 474         loadp TagOffset[tag, index, 8], tag
 475     .done:
 476     end)
 477 end
 478 
 479 # Index and payload may be the same register. Index may be clobbered.
 480 macro loadConstantOrVariable2Reg(size, index, tag, payload)
<span class="line-modified"> 481     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide, macro (FirstConstantRegisterIndex)</span>
 482         bigteq index, FirstConstantRegisterIndex, .constant
 483         loadi TagOffset[cfr, index, 8], tag
 484         loadi PayloadOffset[cfr, index, 8], payload
 485         jmp .done
 486     .constant:
 487         loadp CodeBlock[cfr], tag
 488         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 489         subi FirstConstantRegisterIndex, index
 490         lshifti 3, index
 491         addp index, tag
 492         loadp PayloadOffset[tag], payload
 493         loadp TagOffset[tag], tag
 494     .done:
 495     end)
 496 end
 497 
 498 macro loadConstantOrVariablePayloadTagCustom(size, index, tagCheck, payload)
<span class="line-modified"> 499     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide, macro (FirstConstantRegisterIndex)</span>
 500         bigteq index, FirstConstantRegisterIndex, .constant
 501         tagCheck(TagOffset[cfr, index, 8])
 502         loadi PayloadOffset[cfr, index, 8], payload
 503         jmp .done
 504     .constant:
 505         loadp CodeBlock[cfr], payload
 506         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload
 507         subp FirstConstantRegisterIndex, index
 508         tagCheck(TagOffset[payload, index, 8])
 509         loadp PayloadOffset[payload, index, 8], payload
 510     .done:
 511     end)
 512 end
 513 
 514 # Index and payload must be different registers. Index is not mutated. Use
 515 # this if you know what the tag of the variable should be. Doing the tag
 516 # test as part of loading the variable reduces register use, but may not
 517 # be faster than doing loadConstantOrVariable followed by a branch on the
 518 # tag.
 519 macro loadConstantOrVariablePayload(size, index, expectedTag, payload, slow)
 520     loadConstantOrVariablePayloadTagCustom(
 521         size,
 522         index,
 523         macro (actualTag) bineq actualTag, expectedTag, slow end,
 524         payload)
 525 end
 526 
 527 macro loadConstantOrVariablePayloadUnchecked(size, index, payload)
 528     loadConstantOrVariablePayloadTagCustom(
 529         size,
 530         index,
 531         macro (actualTag) end,
 532         payload)
 533 end
 534 
<span class="line-modified"> 535 macro writeBarrierOnOperand(size, get, cellFieldName)</span>
<span class="line-removed"> 536     get(cellFieldName, t1)</span>
<span class="line-removed"> 537     loadConstantOrVariablePayload(size, t1, CellTag, t2, .writeBarrierDone)</span>
 538     skipIfIsRememberedOrInEden(
<span class="line-modified"> 539         t2, </span>
 540         macro()
 541             push cfr, PC
 542             # We make two extra slots because cCall2 will poke.
 543             subp 8, sp
<span class="line-modified"> 544             move t2, a1 # t2 can be a0 on x86</span>
 545             move cfr, a0
 546             cCall2Void(_llint_write_barrier_slow)
 547             addp 8, sp
 548             pop PC, cfr

 549         end)






 550 .writeBarrierDone:
 551 end
 552 
 553 macro writeBarrierOnOperands(size, get, cellFieldName, valueFieldName)
 554     get(valueFieldName, t1)
 555     loadConstantOrVariableTag(size, t1, t0)
 556     bineq t0, CellTag, .writeBarrierDone
 557 
 558     writeBarrierOnOperand(size, get, cellFieldName)
 559 .writeBarrierDone:
 560 end
 561 
 562 macro writeBarrierOnGlobal(size, get, valueFieldName, loadMacro)
 563     get(valueFieldName, t1)
 564     loadConstantOrVariableTag(size, t1, t0)
 565     bineq t0, CellTag, .writeBarrierDone
 566 
 567     loadMacro(t3)
 568 
<span class="line-modified"> 569     skipIfIsRememberedOrInEden(</span>
<span class="line-removed"> 570         t3,</span>
<span class="line-removed"> 571         macro()</span>
<span class="line-removed"> 572             push cfr, PC</span>
<span class="line-removed"> 573             # We make two extra slots because cCall2 will poke.</span>
<span class="line-removed"> 574             subp 8, sp</span>
<span class="line-removed"> 575             move cfr, a0</span>
<span class="line-removed"> 576             move t3, a1</span>
<span class="line-removed"> 577             cCall2Void(_llint_write_barrier_slow)</span>
<span class="line-removed"> 578             addp 8, sp</span>
<span class="line-removed"> 579             pop PC, cfr</span>
<span class="line-removed"> 580         end)</span>
 581 .writeBarrierDone:
 582 end
 583 
 584 macro writeBarrierOnGlobalObject(size, get, valueFieldName)
 585     writeBarrierOnGlobal(size, get, valueFieldName,
 586         macro(registerToStoreGlobal)
 587             loadp CodeBlock[cfr], registerToStoreGlobal
 588             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 589         end)
 590 end
 591 
 592 macro writeBarrierOnGlobalLexicalEnvironment(size, get, valueFieldName)
 593     writeBarrierOnGlobal(size, get, valueFieldName,
 594         macro(registerToStoreGlobal)
 595             loadp CodeBlock[cfr], registerToStoreGlobal
 596             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 597             loadp JSGlobalObject::m_globalLexicalEnvironment[registerToStoreGlobal], registerToStoreGlobal
 598         end)
 599 end
 600 
</pre>
<hr />
<pre>
 676     loadp CodeBlock[cfr], t1
 677     loadp CodeBlock::m_instructionsRawPointer[t1], PC
 678     jmp doneLabel
 679 end
 680 
 681 macro branchIfException(label)
 682     loadp Callee + PayloadOffset[cfr], t3
 683     andp MarkedBlockMask, t3
 684     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
 685     btpz VM::m_exception[t3], .noException
 686     jmp label
 687 .noException:
 688 end
 689 
 690 
 691 # Instruction implementations
 692 
 693 _llint_op_enter:
 694     traceExecution()
 695     checkStackPointerAlignment(t2, 0xdead00e1)
<span class="line-modified"> 696     loadp CodeBlock[cfr], t2                // t2&lt;CodeBlock&gt; = cfr.CodeBlock</span>
<span class="line-modified"> 697     loadi CodeBlock::m_numVars[t2], t2      // t2&lt;size_t&gt; = t2&lt;CodeBlock&gt;.m_numVars</span>
 698     subi CalleeSaveSpaceAsVirtualRegisters, t2
 699     move cfr, t3
 700     subp CalleeSaveSpaceAsVirtualRegisters * SlotSize, t3
 701     btiz t2, .opEnterDone
 702     move UndefinedTag, t0
<span class="line-removed"> 703     move 0, t1</span>
 704     negi t2
 705 .opEnterLoop:
 706     storei t0, TagOffset[t3, t2, 8]
<span class="line-modified"> 707     storei t1, PayloadOffset[t3, t2, 8]</span>
 708     addi 1, t2
 709     btinz t2, .opEnterLoop
 710 .opEnterDone:
<span class="line-modified"> 711     callSlowPath(_slow_path_enter)</span>






 712     dispatchOp(narrow, op_enter)
<span class="line-modified"> 713 </span>


 714 
 715 llintOpWithProfile(op_get_argument, OpGetArgument, macro (size, get, dispatch, return)
 716     get(m_index, t2)
 717     loadi PayloadOffset + ArgumentCount[cfr], t0
 718     bilteq t0, t2, .opGetArgumentOutOfBounds
 719     loadi ThisArgumentOffset + TagOffset[cfr, t2, 8], t0
 720     loadi ThisArgumentOffset + PayloadOffset[cfr, t2, 8], t3
 721     return (t0, t3)
 722 
 723 .opGetArgumentOutOfBounds:
 724     return (UndefinedTag, 0)
 725 end)
 726 
 727 
 728 llintOpWithReturn(op_argument_count, OpArgumentCount, macro (size, get, dispatch, return)
 729     loadi PayloadOffset + ArgumentCount[cfr], t0
 730     subi 1, t0
 731     return(Int32Tag, t0)
 732 end)
 733 
 734 
 735 llintOpWithReturn(op_get_scope, OpGetScope, macro (size, get, dispatch, return)
 736     loadi Callee + PayloadOffset[cfr], t0
 737     loadp JSCallee::m_scope[t0], t0
 738     return (CellTag, t0)
 739 end)
 740 
 741 
 742 llintOpWithMetadata(op_to_this, OpToThis, macro (size, get, dispatch, metadata, return)
 743     get(m_srcDst, t0)
 744     bineq TagOffset[cfr, t0, 8], CellTag, .opToThisSlow
 745     loadi PayloadOffset[cfr, t0, 8], t0
 746     bbneq JSCell::m_type[t0], FinalObjectType, .opToThisSlow
 747     metadata(t2, t3)
<span class="line-modified"> 748     loadp OpToThis::Metadata::m_cachedStructure[t2], t2</span>
 749     bineq JSCell::m_structureID[t0], t2, .opToThisSlow
 750     dispatch()
 751 
 752 .opToThisSlow:
 753     callSlowPath(_slow_path_to_this)
 754     dispatch()
 755 end)
 756 
 757 
 758 llintOp(op_check_tdz, OpCheckTdz, macro (size, get, dispatch)
 759     get(m_targetVirtualRegister, t0)
 760     loadConstantOrVariableTag(size, t0, t1)
 761     bineq t1, EmptyValueTag, .opNotTDZ
 762     callSlowPath(_slow_path_throw_tdz_error)
 763 
 764 .opNotTDZ:
 765     dispatch()
 766 end)
 767 
 768 
</pre>
<hr />
<pre>
 844         cpeq Structure::m_globalObject[t1], t0, t1
 845         jmp .opEqNullNotImmediate
 846     .opEqNullImmediate:
 847         cieq t1, NullTag, t2
 848         cieq t1, UndefinedTag, t1
 849         ori t2, t1
 850     .opEqNullNotImmediate:
 851         fn(t1)
 852         return(BooleanTag, t1)
 853     end)
 854 end
 855 
 856 equalNullComparisonOp(op_eq_null, OpEqNull, macro (value) end)
 857 
 858 equalNullComparisonOp(op_neq_null, OpNeqNull,
 859     macro (value) xori 1, value end)
 860 
 861 
 862 llintOpWithReturn(op_is_undefined_or_null, OpIsUndefinedOrNull, macro (size, get, dispatch, return)
 863     get(m_operand, t0)
<span class="line-modified"> 864     assertNotConstant(size, t0)</span>
<span class="line-removed"> 865     loadi TagOffset[cfr, t0, 8], t1</span>
 866     ori 1, t1
 867     cieq t1, NullTag, t1
 868     return(BooleanTag, t1)
 869 end)
 870 
 871 
 872 macro strictEqOp(opcodeName, opcodeStruct, equalityOperation)
 873     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 874         get(m_rhs, t2)
 875         get(m_lhs, t0)
 876         loadConstantOrVariable(size, t2, t3, t1)
 877         loadConstantOrVariable2Reg(size, t0, t2, t0)
 878         bineq t2, t3, .slow
 879         bib t2, LowestTag, .slow
 880         bineq t2, CellTag, .notStringOrSymbol
 881         bbaeq JSCell::m_type[t0], ObjectType, .notStringOrSymbol
 882         bbb JSCell::m_type[t1], ObjectType, .slow
 883     .notStringOrSymbol:
 884         equalityOperation(t0, t1, t0)
 885         return(BooleanTag, t0)
</pre>
<hr />
<pre>
1139         bineq t3, Int32Tag, .slow
1140         bineq t2, Int32Tag, .slow
1141         operation(t1, t0)
1142         return (t3, t0)
1143 
1144     .slow:
1145         callSlowPath(_slow_path_%opcodeName%)
1146         dispatch()
1147     end)
1148 end
1149 
1150 macro bitOp(opcodeName, opcodeStruct, operation)
1151     commonBitOp(llintOpWithReturn, opcodeName, opcodeStruct, operation)
1152 end
1153 
1154 macro bitOpProfiled(opcodeName, opcodeStruct, operation)
1155     commonBitOp(llintOpWithProfile, opcodeName, opcodeStruct, operation)
1156 end
1157 
1158 
<span class="line-modified">1159 bitOp(lshift, OpLshift,</span>
1160     macro (left, right) lshifti left, right end)
1161 
1162 
1163 bitOp(rshift, OpRshift,
1164     macro (left, right) rshifti left, right end)
1165 
1166 
1167 bitOp(urshift, OpUrshift,
1168     macro (left, right) urshifti left, right end)
1169 
1170 bitOpProfiled(bitxor, OpBitxor,
1171     macro (left, right) xori left, right end)
1172 
1173 bitOpProfiled(bitand, OpBitand,
1174     macro (left, right) andi left, right end)
1175 
1176 bitOpProfiled(bitor, OpBitor,
1177     macro (left, right) ori left, right end)
1178 
1179 llintOpWithProfile(op_bitnot, OpBitnot, macro (size, get, dispatch, return)
</pre>
<hr />
<pre>
1327 
1328 llintOpWithMetadata(op_get_by_id_direct, OpGetByIdDirect, macro (size, get, dispatch, metadata, return)
1329     metadata(t5, t0)
1330     get(m_base, t0)
1331     loadi OpGetByIdDirect::Metadata::m_structureID[t5], t1
1332     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdDirectSlow)
1333     loadi OpGetByIdDirect::Metadata::m_offset[t5], t2
1334     bineq JSCell::m_structureID[t3], t1, .opGetByIdDirectSlow
1335     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1336     valueProfile(OpGetByIdDirect, t5, t0, t1)
1337     return(t0, t1)
1338 
1339 .opGetByIdDirectSlow:
1340     callSlowPath(_llint_slow_path_get_by_id_direct)
1341     dispatch()
1342 end)
1343 
1344 
1345 llintOpWithMetadata(op_get_by_id, OpGetById, macro (size, get, dispatch, metadata, return)
1346     metadata(t5, t0)
<span class="line-modified">1347     loadb OpGetById::Metadata::m_mode[t5], t1</span>
1348     get(m_base, t0)
1349 
1350 .opGetByIdProtoLoad:
1351     bbneq t1, constexpr GetByIdMode::ProtoLoad, .opGetByIdArrayLength
1352     loadi OpGetById::Metadata::m_modeMetadata.protoLoadMode.structureID[t5], t1
1353     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1354     loadis OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedOffset[t5], t2
1355     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1356     loadp OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedSlot[t5], t3
1357     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1358     valueProfile(OpGetById, t5, t0, t1)
1359     return(t0, t1)
1360 
1361 .opGetByIdArrayLength:
1362     bbneq t1, constexpr GetByIdMode::ArrayLength, .opGetByIdUnset
1363     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1364     move t3, t2
1365     arrayProfile(OpGetById::Metadata::m_modeMetadata.arrayLengthMode.arrayProfile, t2, t5, t0)
1366     btiz t2, IsArray, .opGetByIdSlow
1367     btiz t2, IndexingShapeMask, .opGetByIdSlow
</pre>
<hr />
<pre>
1645 equalNullJumpOp(jeq_null, OpJeqNull,
1646     macro (structure, value, target)
1647         btbz value, MasqueradesAsUndefined, .opJeqNullNotMasqueradesAsUndefined
1648         loadp CodeBlock[cfr], t0
1649         loadp CodeBlock::m_globalObject[t0], t0
1650         bpeq Structure::m_globalObject[structure], t0, target
1651     .opJeqNullNotMasqueradesAsUndefined:
1652     end,
1653     macro (value, target) bieq value, NullTag, target end)
1654     
1655 
1656 equalNullJumpOp(jneq_null, OpJneqNull,
1657     macro (structure, value, target)
1658         btbz value, MasqueradesAsUndefined, target
1659         loadp CodeBlock[cfr], t0
1660         loadp CodeBlock::m_globalObject[t0], t0
1661         bpneq Structure::m_globalObject[structure], t0, target
1662     end,
1663     macro (value, target) bineq value, NullTag, target end)
1664 


















1665 
1666 llintOpWithMetadata(op_jneq_ptr, OpJneqPtr, macro (size, get, dispatch, metadata, return)
1667     get(m_value, t0)
1668     getu(size, OpJneqPtr, m_specialPointer, t1)
1669     loadp CodeBlock[cfr], t2
1670     loadp CodeBlock::m_globalObject[t2], t2
1671     bineq TagOffset[cfr, t0, 8], CellTag, .opJneqPtrBranch
1672     loadp JSGlobalObject::m_specialPointers[t2, t1, 4], t1
1673     bpeq PayloadOffset[cfr, t0, 8], t1, .opJneqPtrFallThrough
1674 .opJneqPtrBranch:
1675     metadata(t5, t2)
1676     storeb 1, OpJneqPtr::Metadata::m_hasJumped[t5]
1677     get(m_targetLabel, t0)
1678     jumpImpl(t0)
1679 .opJneqPtrFallThrough:
1680     dispatch()
1681 end)
1682 
1683 
1684 macro compareUnsignedJumpOp(opcodeName, opcodeStruct, integerCompare)
</pre>
<hr />
<pre>
1771 .opSwitchImmFallThrough:
1772     jump(m_defaultOffset)
1773 
1774 .opSwitchImmSlow:
1775     callSlowPath(_llint_slow_path_switch_imm)
1776     nextInstruction()
1777 end)
1778 
1779 
1780 llintOpWithJump(op_switch_char, OpSwitchChar, macro (size, get, jump, dispatch)
1781     get(m_scrutinee, t2)
1782     getu(size, OpSwitchChar, m_tableIndex, t3)
1783     loadConstantOrVariable(size, t2, t1, t0)
1784     loadp CodeBlock[cfr], t2
1785     loadp CodeBlock::m_rareData[t2], t2
1786     muli sizeof SimpleJumpTable, t3
1787     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1788     addp t3, t2
1789     bineq t1, CellTag, .opSwitchCharFallThrough
1790     bbneq JSCell::m_type[t0], StringType, .opSwitchCharFallThrough
<span class="line-modified">1791     loadp JSString::m_fiber[t0], t0</span>
<span class="line-modified">1792     btpnz t0, isRopeInPointer, .opSwitchOnRope</span>
<span class="line-modified">1793     bineq StringImpl::m_length[t0], 1, .opSwitchCharFallThrough</span>
<span class="line-modified">1794     loadp StringImpl::m_data8[t0], t1</span>
<span class="line-modified">1795     btinz StringImpl::m_hashAndFlags[t0], HashFlags8BitBuffer, .opSwitchChar8Bit</span>
<span class="line-modified">1796     loadh [t1], t0</span>
1797     jmp .opSwitchCharReady
1798 .opSwitchChar8Bit:
<span class="line-modified">1799     loadb [t1], t0</span>
1800 .opSwitchCharReady:
1801     subi SimpleJumpTable::min[t2], t0
1802     biaeq t0, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchCharFallThrough
1803     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t2
1804     loadi [t2, t0, 4], t1
1805     btiz t1, .opSwitchCharFallThrough
1806     dispatchIndirect(t1)
1807 
1808 .opSwitchCharFallThrough:
1809     jump(m_defaultOffset)
1810 
1811 .opSwitchOnRope:



1812     callSlowPath(_llint_slow_path_switch_char)
1813     nextInstruction()
1814 end)
1815 
1816 
1817 macro arrayProfileForCall(opcodeStruct, getu)
1818     getu(m_argv, t3)
1819     negi t3
1820     bineq ThisArgumentOffset + TagOffset[cfr, t3, 8], CellTag, .done
1821     loadi ThisArgumentOffset + PayloadOffset[cfr, t3, 8], t0
1822     loadi JSCell::m_structureID[t0], t0
<span class="line-modified">1823     storei t0, %opcodeStruct%::Metadata::m_arrayProfile.m_lastSeenStructureID[t5]</span>
1824 .done:
1825 end
1826 
1827 macro commonCallOp(opcodeName, slowPath, opcodeStruct, prepareCall, prologue)
1828     llintOpWithMetadata(opcodeName, opcodeStruct, macro (size, get, dispatch, metadata, return)
1829         metadata(t5, t0)
1830 
1831         prologue(macro (fieldName, dst)
1832             getu(size, opcodeStruct, fieldName, dst)
1833         end, metadata)
1834 
1835         get(m_callee, t0)
<span class="line-modified">1836         loadp %opcodeStruct%::Metadata::m_callLinkInfo.callee[t5], t2</span>
1837         loadConstantOrVariablePayload(size, t0, CellTag, t3, .opCallSlow)
1838         bineq t3, t2, .opCallSlow
1839         getu(size, opcodeStruct, m_argv, t3)
1840         lshifti 3, t3
1841         negi t3
1842         addp cfr, t3  # t3 contains the new value of cfr
1843         storei t2, Callee + PayloadOffset[t3]
1844         getu(size, opcodeStruct, m_argc, t2)
1845         storei PC, ArgumentCount + TagOffset[cfr]
1846         storei t2, ArgumentCount + PayloadOffset[t3]
1847         storei CellTag, Callee + TagOffset[t3]
1848         move t3, sp
<span class="line-modified">1849         prepareCall(%opcodeStruct%::Metadata::m_callLinkInfo.machineCodeTarget[t5], t2, t3, t4, JSEntryPtrTag)</span>
<span class="line-modified">1850         callTargetFunction(size, opcodeStruct, dispatch, %opcodeStruct%::Metadata::m_callLinkInfo.machineCodeTarget[t5], JSEntryPtrTag)</span>
1851 
1852     .opCallSlow:
1853         slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)
1854     end)
1855 end
1856 
1857 llintOp(op_ret, OpRet, macro (size, get, dispatch)
1858     checkSwitchToJITForEpilogue()
1859     get(m_value, t2)
1860     loadConstantOrVariable(size, t2, t1, t0)
1861     doReturn()
1862 end)
1863 
1864 
1865 llintOpWithReturn(op_to_primitive, OpToPrimitive, macro (size, get, dispatch, return)
1866     get(m_src, t2)
1867     loadConstantOrVariable(size, t2, t1, t0)
1868     bineq t1, CellTag, .opToPrimitiveIsImm
1869     bbaeq JSCell::m_type[t0], ObjectType, .opToPrimitiveSlowCase
1870 .opToPrimitiveIsImm:
</pre>
<hr />
<pre>
1962 
1963     functionPrologue()
1964     storep 0, CodeBlock[cfr]
1965     loadi Callee + PayloadOffset[cfr], t1
1966     // Callee is still in t1 for code below
1967     if X86 or X86_WIN
1968         subp 8, sp # align stack pointer
1969         andp MarkedBlockMask, t1
1970         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t3
1971         storep cfr, VM::topCallFrame[t3]
1972         move cfr, a0  # a0 = ecx
1973         storep a0, [sp]
1974         loadi Callee + PayloadOffset[cfr], t1
1975         loadp JSFunction::m_executable[t1], t1
1976         checkStackPointerAlignment(t3, 0xdead0001)
1977         call executableOffsetToFunction[t1]
1978         loadp Callee + PayloadOffset[cfr], t3
1979         andp MarkedBlockMask, t3
1980         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
1981         addp 8, sp
<span class="line-modified">1982     elsif ARMv7 or C_LOOP or MIPS</span>
1983         if MIPS
1984         # calling convention says to save stack space for 4 first registers in
1985         # all cases. To match our 16-byte alignment, that means we need to
1986         # take 24 bytes
1987             subp 24, sp
1988         else
1989             subp 8, sp # align stack pointer
1990         end
1991         # t1 already contains the Callee.
1992         andp MarkedBlockMask, t1
1993         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1
1994         storep cfr, VM::topCallFrame[t1]
1995         move cfr, a0
1996         loadi Callee + PayloadOffset[cfr], t1
1997         loadp JSFunction::m_executable[t1], t1
1998         checkStackPointerAlignment(t3, 0xdead0001)
<span class="line-modified">1999         if C_LOOP</span>
2000             cloopCallNative executableOffsetToFunction[t1]
2001         else
2002             call executableOffsetToFunction[t1]
2003         end
2004         loadp Callee + PayloadOffset[cfr], t3
2005         andp MarkedBlockMask, t3
2006         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2007         if MIPS
2008             addp 24, sp
2009         else
2010             addp 8, sp
2011         end
2012     else
2013         error
2014     end
2015     
2016     btpnz VM::m_exception[t3], .handleException
2017 
2018     functionEpilogue()
2019     ret
</pre>
<hr />
<pre>
2029 
2030 macro internalFunctionCallTrampoline(offsetOfFunction)
2031     functionPrologue()
2032     storep 0, CodeBlock[cfr]
2033     loadi Callee + PayloadOffset[cfr], t1
2034     // Callee is still in t1 for code below
2035     if X86 or X86_WIN
2036         subp 8, sp # align stack pointer
2037         andp MarkedBlockMask, t1
2038         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t3
2039         storep cfr, VM::topCallFrame[t3]
2040         move cfr, a0  # a0 = ecx
2041         storep a0, [sp]
2042         loadi Callee + PayloadOffset[cfr], t1
2043         checkStackPointerAlignment(t3, 0xdead0001)
2044         call offsetOfFunction[t1]
2045         loadp Callee + PayloadOffset[cfr], t3
2046         andp MarkedBlockMask, t3
2047         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2048         addp 8, sp
<span class="line-modified">2049     elsif ARMv7 or C_LOOP or MIPS</span>
2050         subp 8, sp # align stack pointer
2051         # t1 already contains the Callee.
2052         andp MarkedBlockMask, t1
2053         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1
2054         storep cfr, VM::topCallFrame[t1]
2055         move cfr, a0
2056         loadi Callee + PayloadOffset[cfr], t1
2057         checkStackPointerAlignment(t3, 0xdead0001)
<span class="line-modified">2058         if C_LOOP</span>
2059             cloopCallNative offsetOfFunction[t1]
2060         else
2061             call offsetOfFunction[t1]
2062         end
2063         loadp Callee + PayloadOffset[cfr], t3
2064         andp MarkedBlockMask, t3
2065         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2066         addp 8, sp
2067     else
2068         error
2069     end
2070 
2071     btpnz VM::m_exception[t3], .handleException
2072 
2073     functionEpilogue()
2074     ret
2075 
2076 .handleException:
2077 if X86 or X86_WIN
2078     subp 8, sp # align stack pointer
</pre>
</td>
<td>
<hr />
<pre>
  12 # THIS SOFTWARE IS PROVIDED BY APPLE INC. AND ITS CONTRIBUTORS ``AS IS&#39;&#39;
  13 # AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
  14 # THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  15 # PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL APPLE INC. OR ITS CONTRIBUTORS
  16 # BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
  17 # CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
  18 # SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
  19 # INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
  20 # CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
  21 # ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
  22 # THE POSSIBILITY OF SUCH DAMAGE.
  23 
  24 
  25 # Utilities
  26 macro nextInstruction()
  27     loadb [PC], t0
  28     leap _g_opcodeMap, t1
  29     jmp [t1, t0, 4], BytecodePtrTag
  30 end
  31 
<span class="line-modified">  32 macro nextInstructionWide16()</span>
<span class="line-added">  33     loadh 1[PC], t0</span>
<span class="line-added">  34     leap _g_opcodeMapWide16, t1</span>
<span class="line-added">  35     jmp [t1, t0, 4], BytecodePtrTag</span>
<span class="line-added">  36 end</span>
<span class="line-added">  37 </span>
<span class="line-added">  38 macro nextInstructionWide32()</span>
  39     loadi 1[PC], t0
<span class="line-modified">  40     leap _g_opcodeMapWide32, t1</span>
  41     jmp [t1, t0, 4], BytecodePtrTag
  42 end
  43 
  44 macro getuOperandNarrow(opcodeStruct, fieldName, dst)
  45     loadb constexpr %opcodeStruct%_%fieldName%_index[PC], dst
  46 end
  47 
  48 macro getOperandNarrow(opcodeStruct, fieldName, dst)
<span class="line-modified">  49     loadbsi constexpr %opcodeStruct%_%fieldName%_index[PC], dst</span>
  50 end
  51 
<span class="line-modified">  52 macro getuOperandWide16(opcodeStruct, fieldName, dst)</span>
<span class="line-added">  53     loadh constexpr %opcodeStruct%_%fieldName%_index * 2 + 1[PC], dst</span>
<span class="line-added">  54 end</span>
<span class="line-added">  55 </span>
<span class="line-added">  56 macro getOperandWide16(opcodeStruct, fieldName, dst)</span>
<span class="line-added">  57     loadhsi constexpr %opcodeStruct%_%fieldName%_index * 2 + 1[PC], dst</span>
<span class="line-added">  58 end</span>
<span class="line-added">  59 </span>
<span class="line-added">  60 macro getuOperandWide32(opcodeStruct, fieldName, dst)</span>
  61     loadi constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PC], dst
  62 end
  63 
<span class="line-modified">  64 macro getOperandWide32(opcodeStruct, fieldName, dst)</span>
  65     loadis constexpr %opcodeStruct%_%fieldName%_index * 4 + 1[PC], dst
  66 end
  67 
  68 macro makeReturn(get, dispatch, fn)
  69     fn(macro(tag, payload)
  70         move tag, t5
  71         move payload, t3
  72         get(m_dst, t2)
  73         storei t5, TagOffset[cfr, t2, 8]
  74         storei t3, PayloadOffset[cfr, t2, 8]
  75         dispatch()
  76     end)
  77 end
  78 
  79 macro makeReturnProfiled(opcodeStruct, get, metadata, dispatch, fn)
  80     fn(macro (tag, payload)
  81         move tag, t1
  82         move payload, t0
  83 
  84         metadata(t5, t2)
</pre>
<hr />
<pre>
  93 
  94 macro dispatchAfterCall(size, opcodeStruct, dispatch)
  95     loadi ArgumentCount + TagOffset[cfr], PC
  96     get(size, opcodeStruct, m_dst, t3)
  97     storei r1, TagOffset[cfr, t3, 8]
  98     storei r0, PayloadOffset[cfr, t3, 8]
  99     metadata(size, opcodeStruct, t2, t3)
 100     valueProfile(opcodeStruct, t2, r1, r0)
 101     dispatch()
 102 end
 103 
 104 macro cCall2(function)
 105     if ARMv7 or MIPS
 106         call function
 107     elsif X86 or X86_WIN
 108         subp 8, sp
 109         push a1
 110         push a0
 111         call function
 112         addp 16, sp
<span class="line-modified"> 113     elsif C_LOOP or C_LOOP_WIN</span>
 114         cloopCallSlowPath function, a0, a1
 115     else
 116         error
 117     end
 118 end
 119 
 120 macro cCall2Void(function)
<span class="line-modified"> 121     if C_LOOP or C_LOOP_WIN</span>
 122         cloopCallSlowPathVoid function, a0, a1
 123     else
 124         cCall2(function)
 125     end
 126 end
 127 
 128 macro cCall4(function)
 129     if ARMv7 or MIPS
 130         call function
 131     elsif X86 or X86_WIN
 132         push a3
 133         push a2
 134         push a1
 135         push a0
 136         call function
 137         addp 16, sp
<span class="line-modified"> 138     elsif C_LOOP or C_LOOP_WIN</span>
 139         error
 140     else
 141         error
 142     end
 143 end
 144 
 145 macro callSlowPath(slowPath)
 146     move cfr, a0
 147     move PC, a1
 148     cCall2(slowPath)
 149     move r0, PC
 150 end
 151 
 152 macro doVMEntry(makeCall)
 153     functionPrologue()
 154     pushCalleeSaves()
 155 
 156     # x86 needs to load arguments from the stack
 157     if X86 or X86_WIN
 158         loadp 16[cfr], a2
</pre>
<hr />
<pre>
 187     if X86_WIN or MIPS
 188         addp CallFrameAlignSlots * SlotSize, sp, t3
 189         andp ~StackAlignmentMask, t3
 190         subp t3, CallFrameAlignSlots * SlotSize, sp
 191     elsif ARMv7
 192         addp CallFrameAlignSlots * SlotSize, sp, t3
 193         clrbp t3, StackAlignmentMask, t3
 194         subp t3, CallFrameAlignSlots * SlotSize, t3
 195         move t3, sp
 196     end
 197 
 198     loadi ProtoCallFrame::paddedArgCount[protoCallFrame], t4
 199     addp CallFrameHeaderSlots, t4, t4
 200     lshiftp 3, t4
 201     subp sp, t4, t3
 202     bpa t3, sp, .throwStackOverflow
 203 
 204     # Ensure that we have enough additional stack capacity for the incoming args,
 205     # and the frame for the JS code we&#39;re executing. We need to do this check
 206     # before we start copying the args from the protoCallFrame below.
<span class="line-modified"> 207     if C_LOOP or C_LOOP_WIN</span>
 208         bpaeq t3, VM::m_cloopStackLimit[vm], .stackHeightOK
 209         move entry, t4
 210         move vm, t5
 211         cloopCallSlowPath _llint_stack_check_at_vm_entry, vm, t3
 212         bpeq t0, 0, .stackCheckFailed
 213         move t4, entry
 214         move t5, vm
 215         jmp .stackHeightOK
 216 
 217 .stackCheckFailed:
 218         move t4, entry
 219         move t5, vm
 220         jmp .throwStackOverflow
 221     else
 222         bpb t3, VM::m_softStackLimit[vm], .throwStackOverflow
 223     end
 224 
 225 .stackHeightOK:
 226     move t3, sp
 227     move (constexpr ProtoCallFrame::numberOfRegisters), t3
</pre>
<hr />
<pre>
 305     loadp VMEntryRecord::m_prevTopCallFrame[sp], t4
 306     storep t4, VM::topCallFrame[t5]
 307     loadp VMEntryRecord::m_prevTopEntryFrame[sp], t4
 308     storep t4, VM::topEntryFrame[t5]
 309 
 310     if ARMv7
 311         subp cfr, CalleeRegisterSaveSize, t5
 312         move t5, sp
 313     else
 314         subp cfr, CalleeRegisterSaveSize, sp
 315     end
 316 
 317     popCalleeSaves()
 318     functionEpilogue()
 319     ret
 320 end
 321 
 322 macro makeJavaScriptCall(entry, temp, unused)
 323     addp CallerFrameAndPCSize, sp
 324     checkStackPointerAlignment(temp, 0xbad0dc02)
<span class="line-modified"> 325     if C_LOOP or C_LOOP_WIN</span>
 326         cloopCallJSFunction entry
 327     else
 328         call entry
 329     end
 330     checkStackPointerAlignment(temp, 0xbad0dc03)
 331     subp CallerFrameAndPCSize, sp
 332 end
 333 
 334 macro makeHostFunctionCall(entry, temp1, temp2)
 335     move entry, temp1
 336     storep cfr, [sp]
<span class="line-modified"> 337     if C_LOOP or C_LOOP_WIN</span>
 338         move sp, a0
 339         storep lr, PtrSize[sp]
 340         cloopCallNative temp1
 341     elsif X86 or X86_WIN
 342         # Put callee frame pointer on stack as arg0, also put it in ecx for &quot;fastcall&quot; targets
 343         move 0, temp2
 344         move temp2, 4[sp] # put 0 in ReturnPC
 345         move sp, a0 # a0 is ecx
 346         push temp2 # Push dummy arg1
 347         push a0
 348         call temp1
 349         addp 8, sp
 350     else
 351         move sp, a0
 352         call temp1
 353     end
 354 end
 355 
 356 op(handleUncaughtException, macro()
 357     loadp Callee + PayloadOffset[cfr], t3
</pre>
<hr />
<pre>
 444             move cfr, a0
 445             move PC, a1
 446             cCall2(_llint_loop_osr)
 447             btpz r0, .recover
 448             move r1, sp
 449             jmp r0
 450         .recover:
 451             loadi ArgumentCount + TagOffset[cfr], PC
 452         end)
 453 end
 454 
 455 macro loadVariable(get, fieldName, indexReg, tagReg, payloadReg)
 456     get(fieldName, indexReg)
 457     loadi TagOffset[cfr, indexReg, 8], tagReg
 458     loadi PayloadOffset[cfr, indexReg, 8], payloadReg
 459 end
 460 
 461 # Index, tag, and payload must be different registers. Index is not
 462 # changed.
 463 macro loadConstantOrVariable(size, index, tag, payload)
<span class="line-modified"> 464     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)</span>
 465         bigteq index, FirstConstantRegisterIndex, .constant
 466         loadi TagOffset[cfr, index, 8], tag
 467         loadi PayloadOffset[cfr, index, 8], payload
 468         jmp .done
 469     .constant:
 470         loadp CodeBlock[cfr], payload
 471         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload
 472         subp FirstConstantRegisterIndex, index
 473         loadp TagOffset[payload, index, 8], tag
 474         loadp PayloadOffset[payload, index, 8], payload
 475     .done:
 476     end)
 477 end
 478 
 479 macro loadConstantOrVariableTag(size, index, tag)
<span class="line-modified"> 480     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)</span>
 481         bigteq index, FirstConstantRegisterIndex, .constant
 482         loadi TagOffset[cfr, index, 8], tag
 483         jmp .done
 484     .constant:
 485         loadp CodeBlock[cfr], tag
 486         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 487         subi FirstConstantRegisterIndex, index
 488         loadp TagOffset[tag, index, 8], tag
 489     .done:
 490     end)
 491 end
 492 
 493 # Index and payload may be the same register. Index may be clobbered.
 494 macro loadConstantOrVariable2Reg(size, index, tag, payload)
<span class="line-modified"> 495     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)</span>
 496         bigteq index, FirstConstantRegisterIndex, .constant
 497         loadi TagOffset[cfr, index, 8], tag
 498         loadi PayloadOffset[cfr, index, 8], payload
 499         jmp .done
 500     .constant:
 501         loadp CodeBlock[cfr], tag
 502         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[tag], tag
 503         subi FirstConstantRegisterIndex, index
 504         lshifti 3, index
 505         addp index, tag
 506         loadp PayloadOffset[tag], payload
 507         loadp TagOffset[tag], tag
 508     .done:
 509     end)
 510 end
 511 
 512 macro loadConstantOrVariablePayloadTagCustom(size, index, tagCheck, payload)
<span class="line-modified"> 513     size(FirstConstantRegisterIndexNarrow, FirstConstantRegisterIndexWide16, FirstConstantRegisterIndexWide32, macro (FirstConstantRegisterIndex)</span>
 514         bigteq index, FirstConstantRegisterIndex, .constant
 515         tagCheck(TagOffset[cfr, index, 8])
 516         loadi PayloadOffset[cfr, index, 8], payload
 517         jmp .done
 518     .constant:
 519         loadp CodeBlock[cfr], payload
 520         loadp CodeBlock::m_constantRegisters + VectorBufferOffset[payload], payload
 521         subp FirstConstantRegisterIndex, index
 522         tagCheck(TagOffset[payload, index, 8])
 523         loadp PayloadOffset[payload, index, 8], payload
 524     .done:
 525     end)
 526 end
 527 
 528 # Index and payload must be different registers. Index is not mutated. Use
 529 # this if you know what the tag of the variable should be. Doing the tag
 530 # test as part of loading the variable reduces register use, but may not
 531 # be faster than doing loadConstantOrVariable followed by a branch on the
 532 # tag.
 533 macro loadConstantOrVariablePayload(size, index, expectedTag, payload, slow)
 534     loadConstantOrVariablePayloadTagCustom(
 535         size,
 536         index,
 537         macro (actualTag) bineq actualTag, expectedTag, slow end,
 538         payload)
 539 end
 540 
 541 macro loadConstantOrVariablePayloadUnchecked(size, index, payload)
 542     loadConstantOrVariablePayloadTagCustom(
 543         size,
 544         index,
 545         macro (actualTag) end,
 546         payload)
 547 end
 548 
<span class="line-modified"> 549 macro writeBarrierOnCellWithReload(cell, reloadAfterSlowPath)</span>


 550     skipIfIsRememberedOrInEden(
<span class="line-modified"> 551         cell,</span>
 552         macro()
 553             push cfr, PC
 554             # We make two extra slots because cCall2 will poke.
 555             subp 8, sp
<span class="line-modified"> 556             move cell, a1 # cell can be a0</span>
 557             move cfr, a0
 558             cCall2Void(_llint_write_barrier_slow)
 559             addp 8, sp
 560             pop PC, cfr
<span class="line-added"> 561             reloadAfterSlowPath()</span>
 562         end)
<span class="line-added"> 563 end</span>
<span class="line-added"> 564 </span>
<span class="line-added"> 565 macro writeBarrierOnOperand(size, get, cellFieldName)</span>
<span class="line-added"> 566     get(cellFieldName, t1)</span>
<span class="line-added"> 567     loadConstantOrVariablePayload(size, t1, CellTag, t2, .writeBarrierDone)</span>
<span class="line-added"> 568     writeBarrierOnCellWithReload(t2, macro() end)</span>
 569 .writeBarrierDone:
 570 end
 571 
 572 macro writeBarrierOnOperands(size, get, cellFieldName, valueFieldName)
 573     get(valueFieldName, t1)
 574     loadConstantOrVariableTag(size, t1, t0)
 575     bineq t0, CellTag, .writeBarrierDone
 576 
 577     writeBarrierOnOperand(size, get, cellFieldName)
 578 .writeBarrierDone:
 579 end
 580 
 581 macro writeBarrierOnGlobal(size, get, valueFieldName, loadMacro)
 582     get(valueFieldName, t1)
 583     loadConstantOrVariableTag(size, t1, t0)
 584     bineq t0, CellTag, .writeBarrierDone
 585 
 586     loadMacro(t3)
 587 
<span class="line-modified"> 588     writeBarrierOnCellWithReload(t3, macro() end)</span>











 589 .writeBarrierDone:
 590 end
 591 
 592 macro writeBarrierOnGlobalObject(size, get, valueFieldName)
 593     writeBarrierOnGlobal(size, get, valueFieldName,
 594         macro(registerToStoreGlobal)
 595             loadp CodeBlock[cfr], registerToStoreGlobal
 596             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 597         end)
 598 end
 599 
 600 macro writeBarrierOnGlobalLexicalEnvironment(size, get, valueFieldName)
 601     writeBarrierOnGlobal(size, get, valueFieldName,
 602         macro(registerToStoreGlobal)
 603             loadp CodeBlock[cfr], registerToStoreGlobal
 604             loadp CodeBlock::m_globalObject[registerToStoreGlobal], registerToStoreGlobal
 605             loadp JSGlobalObject::m_globalLexicalEnvironment[registerToStoreGlobal], registerToStoreGlobal
 606         end)
 607 end
 608 
</pre>
<hr />
<pre>
 684     loadp CodeBlock[cfr], t1
 685     loadp CodeBlock::m_instructionsRawPointer[t1], PC
 686     jmp doneLabel
 687 end
 688 
 689 macro branchIfException(label)
 690     loadp Callee + PayloadOffset[cfr], t3
 691     andp MarkedBlockMask, t3
 692     loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
 693     btpz VM::m_exception[t3], .noException
 694     jmp label
 695 .noException:
 696 end
 697 
 698 
 699 # Instruction implementations
 700 
 701 _llint_op_enter:
 702     traceExecution()
 703     checkStackPointerAlignment(t2, 0xdead00e1)
<span class="line-modified"> 704     loadp CodeBlock[cfr], t1                // t1&lt;CodeBlock&gt; = cfr.CodeBlock</span>
<span class="line-modified"> 705     loadi CodeBlock::m_numVars[t1], t2      // t2&lt;size_t&gt; = t1&lt;CodeBlock&gt;.m_numVars</span>
 706     subi CalleeSaveSpaceAsVirtualRegisters, t2
 707     move cfr, t3
 708     subp CalleeSaveSpaceAsVirtualRegisters * SlotSize, t3
 709     btiz t2, .opEnterDone
 710     move UndefinedTag, t0

 711     negi t2
 712 .opEnterLoop:
 713     storei t0, TagOffset[t3, t2, 8]
<span class="line-modified"> 714     storei 0, PayloadOffset[t3, t2, 8]</span>
 715     addi 1, t2
 716     btinz t2, .opEnterLoop
 717 .opEnterDone:
<span class="line-modified"> 718     writeBarrierOnCellWithReload(t1, macro ()</span>
<span class="line-added"> 719         loadp CodeBlock[cfr], t1 # Reload CodeBlock</span>
<span class="line-added"> 720     end)</span>
<span class="line-added"> 721     # Checking traps.</span>
<span class="line-added"> 722     loadp CodeBlock::m_vm[t1], t1</span>
<span class="line-added"> 723     btpnz VM::m_traps + VMTraps::m_needTrapHandling[t1], .handleTraps</span>
<span class="line-added"> 724 .afterHandlingTraps:</span>
 725     dispatchOp(narrow, op_enter)
<span class="line-modified"> 726 .handleTraps:</span>
<span class="line-added"> 727     callTrapHandler(_llint_throw_from_slow_path_trampoline)</span>
<span class="line-added"> 728     jmp .afterHandlingTraps</span>
 729 
 730 llintOpWithProfile(op_get_argument, OpGetArgument, macro (size, get, dispatch, return)
 731     get(m_index, t2)
 732     loadi PayloadOffset + ArgumentCount[cfr], t0
 733     bilteq t0, t2, .opGetArgumentOutOfBounds
 734     loadi ThisArgumentOffset + TagOffset[cfr, t2, 8], t0
 735     loadi ThisArgumentOffset + PayloadOffset[cfr, t2, 8], t3
 736     return (t0, t3)
 737 
 738 .opGetArgumentOutOfBounds:
 739     return (UndefinedTag, 0)
 740 end)
 741 
 742 
 743 llintOpWithReturn(op_argument_count, OpArgumentCount, macro (size, get, dispatch, return)
 744     loadi PayloadOffset + ArgumentCount[cfr], t0
 745     subi 1, t0
 746     return(Int32Tag, t0)
 747 end)
 748 
 749 
 750 llintOpWithReturn(op_get_scope, OpGetScope, macro (size, get, dispatch, return)
 751     loadi Callee + PayloadOffset[cfr], t0
 752     loadp JSCallee::m_scope[t0], t0
 753     return (CellTag, t0)
 754 end)
 755 
 756 
 757 llintOpWithMetadata(op_to_this, OpToThis, macro (size, get, dispatch, metadata, return)
 758     get(m_srcDst, t0)
 759     bineq TagOffset[cfr, t0, 8], CellTag, .opToThisSlow
 760     loadi PayloadOffset[cfr, t0, 8], t0
 761     bbneq JSCell::m_type[t0], FinalObjectType, .opToThisSlow
 762     metadata(t2, t3)
<span class="line-modified"> 763     loadi OpToThis::Metadata::m_cachedStructureID[t2], t2</span>
 764     bineq JSCell::m_structureID[t0], t2, .opToThisSlow
 765     dispatch()
 766 
 767 .opToThisSlow:
 768     callSlowPath(_slow_path_to_this)
 769     dispatch()
 770 end)
 771 
 772 
 773 llintOp(op_check_tdz, OpCheckTdz, macro (size, get, dispatch)
 774     get(m_targetVirtualRegister, t0)
 775     loadConstantOrVariableTag(size, t0, t1)
 776     bineq t1, EmptyValueTag, .opNotTDZ
 777     callSlowPath(_slow_path_throw_tdz_error)
 778 
 779 .opNotTDZ:
 780     dispatch()
 781 end)
 782 
 783 
</pre>
<hr />
<pre>
 859         cpeq Structure::m_globalObject[t1], t0, t1
 860         jmp .opEqNullNotImmediate
 861     .opEqNullImmediate:
 862         cieq t1, NullTag, t2
 863         cieq t1, UndefinedTag, t1
 864         ori t2, t1
 865     .opEqNullNotImmediate:
 866         fn(t1)
 867         return(BooleanTag, t1)
 868     end)
 869 end
 870 
 871 equalNullComparisonOp(op_eq_null, OpEqNull, macro (value) end)
 872 
 873 equalNullComparisonOp(op_neq_null, OpNeqNull,
 874     macro (value) xori 1, value end)
 875 
 876 
 877 llintOpWithReturn(op_is_undefined_or_null, OpIsUndefinedOrNull, macro (size, get, dispatch, return)
 878     get(m_operand, t0)
<span class="line-modified"> 879     loadConstantOrVariableTag(size, t0, t1)</span>

 880     ori 1, t1
 881     cieq t1, NullTag, t1
 882     return(BooleanTag, t1)
 883 end)
 884 
 885 
 886 macro strictEqOp(opcodeName, opcodeStruct, equalityOperation)
 887     llintOpWithReturn(op_%opcodeName%, opcodeStruct, macro (size, get, dispatch, return)
 888         get(m_rhs, t2)
 889         get(m_lhs, t0)
 890         loadConstantOrVariable(size, t2, t3, t1)
 891         loadConstantOrVariable2Reg(size, t0, t2, t0)
 892         bineq t2, t3, .slow
 893         bib t2, LowestTag, .slow
 894         bineq t2, CellTag, .notStringOrSymbol
 895         bbaeq JSCell::m_type[t0], ObjectType, .notStringOrSymbol
 896         bbb JSCell::m_type[t1], ObjectType, .slow
 897     .notStringOrSymbol:
 898         equalityOperation(t0, t1, t0)
 899         return(BooleanTag, t0)
</pre>
<hr />
<pre>
1153         bineq t3, Int32Tag, .slow
1154         bineq t2, Int32Tag, .slow
1155         operation(t1, t0)
1156         return (t3, t0)
1157 
1158     .slow:
1159         callSlowPath(_slow_path_%opcodeName%)
1160         dispatch()
1161     end)
1162 end
1163 
1164 macro bitOp(opcodeName, opcodeStruct, operation)
1165     commonBitOp(llintOpWithReturn, opcodeName, opcodeStruct, operation)
1166 end
1167 
1168 macro bitOpProfiled(opcodeName, opcodeStruct, operation)
1169     commonBitOp(llintOpWithProfile, opcodeName, opcodeStruct, operation)
1170 end
1171 
1172 
<span class="line-modified">1173 bitOpProfiled(lshift, OpLshift,</span>
1174     macro (left, right) lshifti left, right end)
1175 
1176 
1177 bitOp(rshift, OpRshift,
1178     macro (left, right) rshifti left, right end)
1179 
1180 
1181 bitOp(urshift, OpUrshift,
1182     macro (left, right) urshifti left, right end)
1183 
1184 bitOpProfiled(bitxor, OpBitxor,
1185     macro (left, right) xori left, right end)
1186 
1187 bitOpProfiled(bitand, OpBitand,
1188     macro (left, right) andi left, right end)
1189 
1190 bitOpProfiled(bitor, OpBitor,
1191     macro (left, right) ori left, right end)
1192 
1193 llintOpWithProfile(op_bitnot, OpBitnot, macro (size, get, dispatch, return)
</pre>
<hr />
<pre>
1341 
1342 llintOpWithMetadata(op_get_by_id_direct, OpGetByIdDirect, macro (size, get, dispatch, metadata, return)
1343     metadata(t5, t0)
1344     get(m_base, t0)
1345     loadi OpGetByIdDirect::Metadata::m_structureID[t5], t1
1346     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdDirectSlow)
1347     loadi OpGetByIdDirect::Metadata::m_offset[t5], t2
1348     bineq JSCell::m_structureID[t3], t1, .opGetByIdDirectSlow
1349     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1350     valueProfile(OpGetByIdDirect, t5, t0, t1)
1351     return(t0, t1)
1352 
1353 .opGetByIdDirectSlow:
1354     callSlowPath(_llint_slow_path_get_by_id_direct)
1355     dispatch()
1356 end)
1357 
1358 
1359 llintOpWithMetadata(op_get_by_id, OpGetById, macro (size, get, dispatch, metadata, return)
1360     metadata(t5, t0)
<span class="line-modified">1361     loadb OpGetById::Metadata::m_modeMetadata.mode[t5], t1</span>
1362     get(m_base, t0)
1363 
1364 .opGetByIdProtoLoad:
1365     bbneq t1, constexpr GetByIdMode::ProtoLoad, .opGetByIdArrayLength
1366     loadi OpGetById::Metadata::m_modeMetadata.protoLoadMode.structureID[t5], t1
1367     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1368     loadis OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedOffset[t5], t2
1369     bineq JSCell::m_structureID[t3], t1, .opGetByIdSlow
1370     loadp OpGetById::Metadata::m_modeMetadata.protoLoadMode.cachedSlot[t5], t3
1371     loadPropertyAtVariableOffset(t2, t3, t0, t1)
1372     valueProfile(OpGetById, t5, t0, t1)
1373     return(t0, t1)
1374 
1375 .opGetByIdArrayLength:
1376     bbneq t1, constexpr GetByIdMode::ArrayLength, .opGetByIdUnset
1377     loadConstantOrVariablePayload(size, t0, CellTag, t3, .opGetByIdSlow)
1378     move t3, t2
1379     arrayProfile(OpGetById::Metadata::m_modeMetadata.arrayLengthMode.arrayProfile, t2, t5, t0)
1380     btiz t2, IsArray, .opGetByIdSlow
1381     btiz t2, IndexingShapeMask, .opGetByIdSlow
</pre>
<hr />
<pre>
1659 equalNullJumpOp(jeq_null, OpJeqNull,
1660     macro (structure, value, target)
1661         btbz value, MasqueradesAsUndefined, .opJeqNullNotMasqueradesAsUndefined
1662         loadp CodeBlock[cfr], t0
1663         loadp CodeBlock::m_globalObject[t0], t0
1664         bpeq Structure::m_globalObject[structure], t0, target
1665     .opJeqNullNotMasqueradesAsUndefined:
1666     end,
1667     macro (value, target) bieq value, NullTag, target end)
1668     
1669 
1670 equalNullJumpOp(jneq_null, OpJneqNull,
1671     macro (structure, value, target)
1672         btbz value, MasqueradesAsUndefined, target
1673         loadp CodeBlock[cfr], t0
1674         loadp CodeBlock::m_globalObject[t0], t0
1675         bpneq Structure::m_globalObject[structure], t0, target
1676     end,
1677     macro (value, target) bineq value, NullTag, target end)
1678 
<span class="line-added">1679 macro undefinedOrNullJumpOp(opcodeName, opcodeStruct, fn)</span>
<span class="line-added">1680     llintOpWithJump(op_%opcodeName%, opcodeStruct, macro (size, get, jump, dispatch)</span>
<span class="line-added">1681         get(m_value, t1)</span>
<span class="line-added">1682         loadConstantOrVariableTag(size, t1, t0)</span>
<span class="line-added">1683         ori 1, t0</span>
<span class="line-added">1684         fn(t0, .target)</span>
<span class="line-added">1685         dispatch()</span>
<span class="line-added">1686 </span>
<span class="line-added">1687     .target:</span>
<span class="line-added">1688         jump(m_targetLabel)</span>
<span class="line-added">1689     end)</span>
<span class="line-added">1690 end</span>
<span class="line-added">1691 </span>
<span class="line-added">1692 undefinedOrNullJumpOp(jundefined_or_null, OpJundefinedOrNull,</span>
<span class="line-added">1693     macro (value, target) bieq value, NullTag, target end)</span>
<span class="line-added">1694 </span>
<span class="line-added">1695 undefinedOrNullJumpOp(jnundefined_or_null, OpJnundefinedOrNull,</span>
<span class="line-added">1696     macro (value, target) bineq value, NullTag, target end)</span>
1697 
1698 llintOpWithMetadata(op_jneq_ptr, OpJneqPtr, macro (size, get, dispatch, metadata, return)
1699     get(m_value, t0)
1700     getu(size, OpJneqPtr, m_specialPointer, t1)
1701     loadp CodeBlock[cfr], t2
1702     loadp CodeBlock::m_globalObject[t2], t2
1703     bineq TagOffset[cfr, t0, 8], CellTag, .opJneqPtrBranch
1704     loadp JSGlobalObject::m_specialPointers[t2, t1, 4], t1
1705     bpeq PayloadOffset[cfr, t0, 8], t1, .opJneqPtrFallThrough
1706 .opJneqPtrBranch:
1707     metadata(t5, t2)
1708     storeb 1, OpJneqPtr::Metadata::m_hasJumped[t5]
1709     get(m_targetLabel, t0)
1710     jumpImpl(t0)
1711 .opJneqPtrFallThrough:
1712     dispatch()
1713 end)
1714 
1715 
1716 macro compareUnsignedJumpOp(opcodeName, opcodeStruct, integerCompare)
</pre>
<hr />
<pre>
1803 .opSwitchImmFallThrough:
1804     jump(m_defaultOffset)
1805 
1806 .opSwitchImmSlow:
1807     callSlowPath(_llint_slow_path_switch_imm)
1808     nextInstruction()
1809 end)
1810 
1811 
1812 llintOpWithJump(op_switch_char, OpSwitchChar, macro (size, get, jump, dispatch)
1813     get(m_scrutinee, t2)
1814     getu(size, OpSwitchChar, m_tableIndex, t3)
1815     loadConstantOrVariable(size, t2, t1, t0)
1816     loadp CodeBlock[cfr], t2
1817     loadp CodeBlock::m_rareData[t2], t2
1818     muli sizeof SimpleJumpTable, t3
1819     loadp CodeBlock::RareData::m_switchJumpTables + VectorBufferOffset[t2], t2
1820     addp t3, t2
1821     bineq t1, CellTag, .opSwitchCharFallThrough
1822     bbneq JSCell::m_type[t0], StringType, .opSwitchCharFallThrough
<span class="line-modified">1823     loadp JSString::m_fiber[t0], t1</span>
<span class="line-modified">1824     btpnz t1, isRopeInPointer, .opSwitchOnRope</span>
<span class="line-modified">1825     bineq StringImpl::m_length[t1], 1, .opSwitchCharFallThrough</span>
<span class="line-modified">1826     loadp StringImpl::m_data8[t1], t0</span>
<span class="line-modified">1827     btinz StringImpl::m_hashAndFlags[t1], HashFlags8BitBuffer, .opSwitchChar8Bit</span>
<span class="line-modified">1828     loadh [t0], t0</span>
1829     jmp .opSwitchCharReady
1830 .opSwitchChar8Bit:
<span class="line-modified">1831     loadb [t0], t0</span>
1832 .opSwitchCharReady:
1833     subi SimpleJumpTable::min[t2], t0
1834     biaeq t0, SimpleJumpTable::branchOffsets + VectorSizeOffset[t2], .opSwitchCharFallThrough
1835     loadp SimpleJumpTable::branchOffsets + VectorBufferOffset[t2], t2
1836     loadi [t2, t0, 4], t1
1837     btiz t1, .opSwitchCharFallThrough
1838     dispatchIndirect(t1)
1839 
1840 .opSwitchCharFallThrough:
1841     jump(m_defaultOffset)
1842 
1843 .opSwitchOnRope:
<span class="line-added">1844     bineq JSRopeString::m_compactFibers + JSRopeString::CompactFibers::m_length[t0], 1, .opSwitchCharFallThrough</span>
<span class="line-added">1845 </span>
<span class="line-added">1846 .opSwitchOnRopeChar:</span>
1847     callSlowPath(_llint_slow_path_switch_char)
1848     nextInstruction()
1849 end)
1850 
1851 
1852 macro arrayProfileForCall(opcodeStruct, getu)
1853     getu(m_argv, t3)
1854     negi t3
1855     bineq ThisArgumentOffset + TagOffset[cfr, t3, 8], CellTag, .done
1856     loadi ThisArgumentOffset + PayloadOffset[cfr, t3, 8], t0
1857     loadi JSCell::m_structureID[t0], t0
<span class="line-modified">1858     storei t0, %opcodeStruct%::Metadata::m_callLinkInfo.m_arrayProfile.m_lastSeenStructureID[t5]</span>
1859 .done:
1860 end
1861 
1862 macro commonCallOp(opcodeName, slowPath, opcodeStruct, prepareCall, prologue)
1863     llintOpWithMetadata(opcodeName, opcodeStruct, macro (size, get, dispatch, metadata, return)
1864         metadata(t5, t0)
1865 
1866         prologue(macro (fieldName, dst)
1867             getu(size, opcodeStruct, fieldName, dst)
1868         end, metadata)
1869 
1870         get(m_callee, t0)
<span class="line-modified">1871         loadp %opcodeStruct%::Metadata::m_callLinkInfo.m_calleeOrLastSeenCalleeWithLinkBit[t5], t2</span>
1872         loadConstantOrVariablePayload(size, t0, CellTag, t3, .opCallSlow)
1873         bineq t3, t2, .opCallSlow
1874         getu(size, opcodeStruct, m_argv, t3)
1875         lshifti 3, t3
1876         negi t3
1877         addp cfr, t3  # t3 contains the new value of cfr
1878         storei t2, Callee + PayloadOffset[t3]
1879         getu(size, opcodeStruct, m_argc, t2)
1880         storei PC, ArgumentCount + TagOffset[cfr]
1881         storei t2, ArgumentCount + PayloadOffset[t3]
1882         storei CellTag, Callee + TagOffset[t3]
1883         move t3, sp
<span class="line-modified">1884         prepareCall(%opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], t2, t3, t4, JSEntryPtrTag)</span>
<span class="line-modified">1885         callTargetFunction(size, opcodeStruct, dispatch, %opcodeStruct%::Metadata::m_callLinkInfo.m_machineCodeTarget[t5], JSEntryPtrTag)</span>
1886 
1887     .opCallSlow:
1888         slowPathForCall(size, opcodeStruct, dispatch, slowPath, prepareCall)
1889     end)
1890 end
1891 
1892 llintOp(op_ret, OpRet, macro (size, get, dispatch)
1893     checkSwitchToJITForEpilogue()
1894     get(m_value, t2)
1895     loadConstantOrVariable(size, t2, t1, t0)
1896     doReturn()
1897 end)
1898 
1899 
1900 llintOpWithReturn(op_to_primitive, OpToPrimitive, macro (size, get, dispatch, return)
1901     get(m_src, t2)
1902     loadConstantOrVariable(size, t2, t1, t0)
1903     bineq t1, CellTag, .opToPrimitiveIsImm
1904     bbaeq JSCell::m_type[t0], ObjectType, .opToPrimitiveSlowCase
1905 .opToPrimitiveIsImm:
</pre>
<hr />
<pre>
1997 
1998     functionPrologue()
1999     storep 0, CodeBlock[cfr]
2000     loadi Callee + PayloadOffset[cfr], t1
2001     // Callee is still in t1 for code below
2002     if X86 or X86_WIN
2003         subp 8, sp # align stack pointer
2004         andp MarkedBlockMask, t1
2005         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t3
2006         storep cfr, VM::topCallFrame[t3]
2007         move cfr, a0  # a0 = ecx
2008         storep a0, [sp]
2009         loadi Callee + PayloadOffset[cfr], t1
2010         loadp JSFunction::m_executable[t1], t1
2011         checkStackPointerAlignment(t3, 0xdead0001)
2012         call executableOffsetToFunction[t1]
2013         loadp Callee + PayloadOffset[cfr], t3
2014         andp MarkedBlockMask, t3
2015         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2016         addp 8, sp
<span class="line-modified">2017     elsif ARMv7 or C_LOOP or C_LOOP_WIN or MIPS</span>
2018         if MIPS
2019         # calling convention says to save stack space for 4 first registers in
2020         # all cases. To match our 16-byte alignment, that means we need to
2021         # take 24 bytes
2022             subp 24, sp
2023         else
2024             subp 8, sp # align stack pointer
2025         end
2026         # t1 already contains the Callee.
2027         andp MarkedBlockMask, t1
2028         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1
2029         storep cfr, VM::topCallFrame[t1]
2030         move cfr, a0
2031         loadi Callee + PayloadOffset[cfr], t1
2032         loadp JSFunction::m_executable[t1], t1
2033         checkStackPointerAlignment(t3, 0xdead0001)
<span class="line-modified">2034         if C_LOOP or C_LOOP_WIN</span>
2035             cloopCallNative executableOffsetToFunction[t1]
2036         else
2037             call executableOffsetToFunction[t1]
2038         end
2039         loadp Callee + PayloadOffset[cfr], t3
2040         andp MarkedBlockMask, t3
2041         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2042         if MIPS
2043             addp 24, sp
2044         else
2045             addp 8, sp
2046         end
2047     else
2048         error
2049     end
2050     
2051     btpnz VM::m_exception[t3], .handleException
2052 
2053     functionEpilogue()
2054     ret
</pre>
<hr />
<pre>
2064 
2065 macro internalFunctionCallTrampoline(offsetOfFunction)
2066     functionPrologue()
2067     storep 0, CodeBlock[cfr]
2068     loadi Callee + PayloadOffset[cfr], t1
2069     // Callee is still in t1 for code below
2070     if X86 or X86_WIN
2071         subp 8, sp # align stack pointer
2072         andp MarkedBlockMask, t1
2073         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t3
2074         storep cfr, VM::topCallFrame[t3]
2075         move cfr, a0  # a0 = ecx
2076         storep a0, [sp]
2077         loadi Callee + PayloadOffset[cfr], t1
2078         checkStackPointerAlignment(t3, 0xdead0001)
2079         call offsetOfFunction[t1]
2080         loadp Callee + PayloadOffset[cfr], t3
2081         andp MarkedBlockMask, t3
2082         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2083         addp 8, sp
<span class="line-modified">2084     elsif ARMv7 or C_LOOP or C_LOOP_WIN or MIPS</span>
2085         subp 8, sp # align stack pointer
2086         # t1 already contains the Callee.
2087         andp MarkedBlockMask, t1
2088         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t1], t1
2089         storep cfr, VM::topCallFrame[t1]
2090         move cfr, a0
2091         loadi Callee + PayloadOffset[cfr], t1
2092         checkStackPointerAlignment(t3, 0xdead0001)
<span class="line-modified">2093         if C_LOOP or C_LOOP_WIN</span>
2094             cloopCallNative offsetOfFunction[t1]
2095         else
2096             call offsetOfFunction[t1]
2097         end
2098         loadp Callee + PayloadOffset[cfr], t3
2099         andp MarkedBlockMask, t3
2100         loadp MarkedBlockFooterOffset + MarkedBlock::Footer::m_vm[t3], t3
2101         addp 8, sp
2102     else
2103         error
2104     end
2105 
2106     btpnz VM::m_exception[t3], .handleException
2107 
2108     functionEpilogue()
2109     ret
2110 
2111 .handleException:
2112 if X86 or X86_WIN
2113     subp 8, sp # align stack pointer
</pre>
</td>
</tr>
</table>
<center><a href="LowLevelInterpreter.cpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../../../../index.html" target="_top">index</a> <a href="LowLevelInterpreter64.asm.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>