<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/assembler/ARM64Assembler.h</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
<a name="1" id="anc1"></a><span class="line-modified">   2  * Copyright (C) 2012-2018 Apple Inc. All rights reserved.</span>
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #pragma once
  27 
  28 #if ENABLE(ASSEMBLER) &amp;&amp; CPU(ARM64)
  29 
<a name="2" id="anc2"></a>
  30 #include &quot;AssemblerBuffer.h&quot;
  31 #include &quot;AssemblerCommon.h&quot;
  32 #include &quot;CPU.h&quot;
  33 #include &quot;JSCPtrTag.h&quot;
  34 #include &lt;limits.h&gt;
  35 #include &lt;wtf/Assertions.h&gt;
  36 #include &lt;wtf/Vector.h&gt;
  37 #include &lt;stdint.h&gt;
  38 
  39 #if OS(FUCHSIA)
  40 #include &lt;zircon/syscalls.h&gt;
  41 #endif
  42 
  43 #define CHECK_DATASIZE_OF(datasize) ASSERT(datasize == 32 || datasize == 64)
  44 #define CHECK_MEMOPSIZE_OF(size) ASSERT(size == 8 || size == 16 || size == 32 || size == 64 || size == 128);
  45 #define DATASIZE_OF(datasize) ((datasize == 64) ? Datasize_64 : Datasize_32)
  46 #define MEMOPSIZE_OF(datasize) ((datasize == 8 || datasize == 128) ? MemOpSize_8_or_128 : (datasize == 16) ? MemOpSize_16 : (datasize == 32) ? MemOpSize_32 : MemOpSize_64)
  47 #define CHECK_DATASIZE() CHECK_DATASIZE_OF(datasize)
  48 #define CHECK_MEMOPSIZE() CHECK_MEMOPSIZE_OF(datasize)
  49 #define CHECK_VECTOR_DATASIZE() ASSERT(datasize == 64 || datasize == 128)
  50 #define DATASIZE DATASIZE_OF(datasize)
  51 #define MEMOPSIZE MEMOPSIZE_OF(datasize)
  52 #define CHECK_FP_MEMOP_DATASIZE() ASSERT(datasize == 8 || datasize == 16 || datasize == 32 || datasize == 64 || datasize == 128)
  53 #define MEMPAIROPSIZE_INT(datasize) ((datasize == 64) ? MemPairOp_64 : MemPairOp_32)
  54 #define MEMPAIROPSIZE_FP(datasize) ((datasize == 128) ? MemPairOp_V128 : (datasize == 64) ? MemPairOp_V64 : MemPairOp_32)
  55 
  56 namespace JSC {
  57 
  58 template&lt;size_t bits, typename Type&gt;
  59 ALWAYS_INLINE constexpr bool isInt(Type t)
  60 {
  61     constexpr size_t shift = sizeof(Type) * CHAR_BIT - bits;
  62     static_assert(sizeof(Type) * CHAR_BIT &gt; shift, &quot;shift is larger than the size of the value&quot;);
  63     return ((t &lt;&lt; shift) &gt;&gt; shift) == t;
  64 }
  65 
  66 static ALWAYS_INLINE bool is4ByteAligned(const void* ptr)
  67 {
  68     return !(reinterpret_cast&lt;intptr_t&gt;(ptr) &amp; 0x3);
  69 }
  70 
  71 ALWAYS_INLINE bool isUInt5(int32_t value)
  72 {
  73     return !(value &amp; ~0x1f);
  74 }
  75 
  76 class UInt5 {
  77 public:
  78     explicit UInt5(int value)
  79         : m_value(value)
  80     {
  81         ASSERT(isUInt5(value));
  82     }
  83 
  84     operator int() { return m_value; }
  85 
  86 private:
  87     int m_value;
  88 };
  89 
  90 class UInt12 {
  91 public:
  92     explicit UInt12(int value)
  93         : m_value(value)
  94     {
  95         ASSERT(isUInt12(value));
  96     }
  97 
  98     operator int() { return m_value; }
  99 
 100 private:
 101     int m_value;
 102 };
 103 
 104 class PostIndex {
 105 public:
 106     explicit PostIndex(int value)
 107         : m_value(value)
 108     {
 109         ASSERT(isInt9(value));
 110     }
 111 
 112     operator int() { return m_value; }
 113 
 114 private:
 115     int m_value;
 116 };
 117 
 118 class PreIndex {
 119 public:
 120     explicit PreIndex(int value)
 121         : m_value(value)
 122     {
 123         ASSERT(isInt9(value));
 124     }
 125 
 126     operator int() { return m_value; }
 127 
 128 private:
 129     int m_value;
 130 };
 131 
 132 class PairPostIndex {
 133 public:
 134     explicit PairPostIndex(int value)
 135         : m_value(value)
 136     {
 137         ASSERT(isInt&lt;11&gt;(value));
 138     }
 139 
 140     operator int() { return m_value; }
 141 
 142 private:
 143     int m_value;
 144 };
 145 
 146 class PairPreIndex {
 147 public:
 148     explicit PairPreIndex(int value)
 149         : m_value(value)
 150     {
 151         ASSERT(isInt&lt;11&gt;(value));
 152     }
 153 
 154     operator int() { return m_value; }
 155 
 156 private:
 157     int m_value;
 158 };
 159 
 160 typedef ARM64LogicalImmediate LogicalImmediate;
 161 
 162 inline uint16_t getHalfword(uint64_t value, int which)
 163 {
 164     return value &gt;&gt; (which &lt;&lt; 4);
 165 }
 166 
<a name="3" id="anc3"></a><span class="line-modified"> 167 namespace ARM64Registers {</span>
 168 
 169 typedef enum : int8_t {
<a name="4" id="anc4"></a><span class="line-modified"> 170     // Parameter/result registers.</span>
<span class="line-modified"> 171     x0,</span>
<span class="line-modified"> 172     x1,</span>
<span class="line-modified"> 173     x2,</span>
<span class="line-modified"> 174     x3,</span>
<span class="line-modified"> 175     x4,</span>
<span class="line-modified"> 176     x5,</span>
<span class="line-modified"> 177     x6,</span>
<span class="line-removed"> 178     x7,</span>
<span class="line-removed"> 179     // Indirect result location register.</span>
<span class="line-removed"> 180     x8,</span>
<span class="line-removed"> 181     // Temporary registers.</span>
<span class="line-removed"> 182     x9,</span>
<span class="line-removed"> 183     x10,</span>
<span class="line-removed"> 184     x11,</span>
<span class="line-removed"> 185     x12,</span>
<span class="line-removed"> 186     x13,</span>
<span class="line-removed"> 187     x14,</span>
<span class="line-removed"> 188     x15,</span>
<span class="line-removed"> 189     // Intra-procedure-call scratch registers (temporary).</span>
<span class="line-removed"> 190     x16,</span>
<span class="line-removed"> 191     x17,</span>
<span class="line-removed"> 192     // Platform Register (temporary).</span>
<span class="line-removed"> 193     x18,</span>
<span class="line-removed"> 194     // Callee-saved.</span>
<span class="line-removed"> 195     x19,</span>
<span class="line-removed"> 196     x20,</span>
<span class="line-removed"> 197     x21,</span>
<span class="line-removed"> 198     x22,</span>
<span class="line-removed"> 199     x23,</span>
<span class="line-removed"> 200     x24,</span>
<span class="line-removed"> 201     x25,</span>
<span class="line-removed"> 202     x26,</span>
<span class="line-removed"> 203     x27,</span>
<span class="line-removed"> 204     x28,</span>
<span class="line-removed"> 205     // Special.</span>
<span class="line-removed"> 206     fp,</span>
<span class="line-removed"> 207     lr,</span>
<span class="line-removed"> 208     sp,</span>
<span class="line-removed"> 209 </span>
<span class="line-removed"> 210     ip0 = x16,</span>
<span class="line-removed"> 211     ip1 = x17,</span>
<span class="line-removed"> 212     x29 = fp,</span>
<span class="line-removed"> 213     x30 = lr,</span>
<span class="line-removed"> 214     zr = 0x3f,</span>
 215     InvalidGPRReg = -1,
 216 } RegisterID;
 217 
 218 typedef enum : int8_t {
<a name="5" id="anc5"></a><span class="line-modified"> 219     pc,</span>
<span class="line-modified"> 220     nzcv,</span>
<span class="line-modified"> 221     fpsr</span>
 222 } SPRegisterID;
 223 
 224 // ARM64 always has 32 FPU registers 128-bits each. See http://llvm.org/devmtg/2012-11/Northover-AArch64.pdf
 225 // and Section 5.1.2 in http://infocenter.arm.com/help/topic/com.arm.doc.ihi0055b/IHI0055B_aapcs64.pdf.
 226 // However, we only use them for 64-bit doubles.
 227 typedef enum : int8_t {
<a name="6" id="anc6"></a><span class="line-modified"> 228     // Parameter/result registers.</span>
<span class="line-modified"> 229     q0,</span>
<span class="line-modified"> 230     q1,</span>
<span class="line-removed"> 231     q2,</span>
<span class="line-removed"> 232     q3,</span>
<span class="line-removed"> 233     q4,</span>
<span class="line-removed"> 234     q5,</span>
<span class="line-removed"> 235     q6,</span>
<span class="line-removed"> 236     q7,</span>
<span class="line-removed"> 237     // Callee-saved (up to 64-bits only!).</span>
<span class="line-removed"> 238     q8,</span>
<span class="line-removed"> 239     q9,</span>
<span class="line-removed"> 240     q10,</span>
<span class="line-removed"> 241     q11,</span>
<span class="line-removed"> 242     q12,</span>
<span class="line-removed"> 243     q13,</span>
<span class="line-removed"> 244     q14,</span>
<span class="line-removed"> 245     q15,</span>
<span class="line-removed"> 246     // Temporary registers.</span>
<span class="line-removed"> 247     q16,</span>
<span class="line-removed"> 248     q17,</span>
<span class="line-removed"> 249     q18,</span>
<span class="line-removed"> 250     q19,</span>
<span class="line-removed"> 251     q20,</span>
<span class="line-removed"> 252     q21,</span>
<span class="line-removed"> 253     q22,</span>
<span class="line-removed"> 254     q23,</span>
<span class="line-removed"> 255     q24,</span>
<span class="line-removed"> 256     q25,</span>
<span class="line-removed"> 257     q26,</span>
<span class="line-removed"> 258     q27,</span>
<span class="line-removed"> 259     q28,</span>
<span class="line-removed"> 260     q29,</span>
<span class="line-removed"> 261     q30,</span>
<span class="line-removed"> 262     q31,</span>
 263     InvalidFPRReg = -1,
 264 } FPRegisterID;
 265 
 266 static constexpr bool isSp(RegisterID reg) { return reg == sp; }
 267 static constexpr bool isZr(RegisterID reg) { return reg == zr; }
 268 
 269 } // namespace ARM64Registers
 270 
 271 class ARM64Assembler {
 272 public:
 273     static constexpr size_t instructionSize = sizeof(unsigned);
 274 
 275     typedef ARM64Registers::RegisterID RegisterID;
 276     typedef ARM64Registers::SPRegisterID SPRegisterID;
 277     typedef ARM64Registers::FPRegisterID FPRegisterID;
 278 
 279     static constexpr RegisterID firstRegister() { return ARM64Registers::x0; }
 280     static constexpr RegisterID lastRegister() { return ARM64Registers::sp; }
 281     static constexpr unsigned numberOfRegisters() { return lastRegister() - firstRegister() + 1; }
 282 
 283     static constexpr SPRegisterID firstSPRegister() { return ARM64Registers::pc; }
 284     static constexpr SPRegisterID lastSPRegister() { return ARM64Registers::fpsr; }
 285     static constexpr unsigned numberOfSPRegisters() { return lastSPRegister() - firstSPRegister() + 1; }
 286 
 287     static constexpr FPRegisterID firstFPRegister() { return ARM64Registers::q0; }
 288     static constexpr FPRegisterID lastFPRegister() { return ARM64Registers::q31; }
 289     static constexpr unsigned numberOfFPRegisters() { return lastFPRegister() - firstFPRegister() + 1; }
 290 
 291     static const char* gprName(RegisterID id)
 292     {
 293         ASSERT(id &gt;= firstRegister() &amp;&amp; id &lt;= lastRegister());
 294         static const char* const nameForRegister[numberOfRegisters()] = {
<a name="7" id="anc7"></a><span class="line-modified"> 295             &quot;r0&quot;, &quot;r1&quot;, &quot;r2&quot;, &quot;r3&quot;, &quot;r4&quot;, &quot;r5&quot;, &quot;r6&quot;, &quot;r7&quot;,</span>
<span class="line-modified"> 296             &quot;r8&quot;, &quot;r9&quot;, &quot;r10&quot;, &quot;r11&quot;, &quot;r12&quot;, &quot;r13&quot;, &quot;r14&quot;, &quot;r15&quot;,</span>
<span class="line-modified"> 297             &quot;r16&quot;, &quot;r17&quot;, &quot;r18&quot;, &quot;r19&quot;, &quot;r20&quot;, &quot;r21&quot;, &quot;r22&quot;, &quot;r23&quot;,</span>
<span class="line-removed"> 298             &quot;r24&quot;, &quot;r25&quot;, &quot;r26&quot;, &quot;r27&quot;, &quot;r28&quot;, &quot;fp&quot;, &quot;lr&quot;, &quot;sp&quot;</span>
 299         };
 300         return nameForRegister[id];
 301     }
 302 
 303     static const char* sprName(SPRegisterID id)
 304     {
 305         ASSERT(id &gt;= firstSPRegister() &amp;&amp; id &lt;= lastSPRegister());
 306         static const char* const nameForRegister[numberOfSPRegisters()] = {
<a name="8" id="anc8"></a><span class="line-modified"> 307             &quot;pc&quot;, &quot;nzcv&quot;, &quot;fpsr&quot;</span>


 308         };
 309         return nameForRegister[id];
 310     }
 311 
 312     static const char* fprName(FPRegisterID id)
 313     {
 314         ASSERT(id &gt;= firstFPRegister() &amp;&amp; id &lt;= lastFPRegister());
 315         static const char* const nameForRegister[numberOfFPRegisters()] = {
<a name="9" id="anc9"></a><span class="line-modified"> 316             &quot;q0&quot;, &quot;q1&quot;, &quot;q2&quot;, &quot;q3&quot;, &quot;q4&quot;, &quot;q5&quot;, &quot;q6&quot;, &quot;q7&quot;,</span>
<span class="line-modified"> 317             &quot;q8&quot;, &quot;q9&quot;, &quot;q10&quot;, &quot;q11&quot;, &quot;q12&quot;, &quot;q13&quot;, &quot;q14&quot;, &quot;q15&quot;,</span>
<span class="line-modified"> 318             &quot;q16&quot;, &quot;q17&quot;, &quot;q18&quot;, &quot;q19&quot;, &quot;q20&quot;, &quot;q21&quot;, &quot;q22&quot;, &quot;q23&quot;,</span>
<span class="line-removed"> 319             &quot;q24&quot;, &quot;q25&quot;, &quot;q26&quot;, &quot;q27&quot;, &quot;q28&quot;, &quot;q29&quot;, &quot;q30&quot;, &quot;q31&quot;</span>
 320         };
 321         return nameForRegister[id];
 322     }
 323 
 324 protected:
 325     static constexpr bool isSp(RegisterID reg) { return ARM64Registers::isSp(reg); }
 326     static constexpr bool isZr(RegisterID reg) { return ARM64Registers::isZr(reg); }
 327 
 328 public:
 329     ARM64Assembler()
 330         : m_indexOfLastWatchpoint(INT_MIN)
 331         , m_indexOfTailOfLastWatchpoint(INT_MIN)
 332     {
 333     }
 334 
 335     AssemblerBuffer&amp; buffer() { return m_buffer; }
 336 
 337     // (HS, LO, HI, LS) -&gt; (AE, B, A, BE)
 338     // (VS, VC) -&gt; (O, NO)
 339     typedef enum {
 340         ConditionEQ,
 341         ConditionNE,
 342         ConditionHS, ConditionCS = ConditionHS,
 343         ConditionLO, ConditionCC = ConditionLO,
 344         ConditionMI,
 345         ConditionPL,
 346         ConditionVS,
 347         ConditionVC,
 348         ConditionHI,
 349         ConditionLS,
 350         ConditionGE,
 351         ConditionLT,
 352         ConditionGT,
 353         ConditionLE,
 354         ConditionAL,
 355         ConditionInvalid
 356     } Condition;
 357 
 358     static Condition invert(Condition cond)
 359     {
 360         return static_cast&lt;Condition&gt;(cond ^ 1);
 361     }
 362 
 363     typedef enum {
 364         LSL,
 365         LSR,
 366         ASR,
 367         ROR
 368     } ShiftType;
 369 
 370     typedef enum {
 371         UXTB,
 372         UXTH,
 373         UXTW,
 374         UXTX,
 375         SXTB,
 376         SXTH,
 377         SXTW,
 378         SXTX
 379     } ExtendType;
 380 
 381     enum SetFlags {
 382         DontSetFlags,
 383         S
 384     };
 385 
 386 #define JUMP_ENUM_WITH_SIZE(index, value) (((value) &lt;&lt; 4) | (index))
 387 #define JUMP_ENUM_SIZE(jump) ((jump) &gt;&gt; 4)
 388     enum JumpType { JumpFixed = JUMP_ENUM_WITH_SIZE(0, 0),
 389         JumpNoCondition = JUMP_ENUM_WITH_SIZE(1, 1 * sizeof(uint32_t)),
 390         JumpCondition = JUMP_ENUM_WITH_SIZE(2, 2 * sizeof(uint32_t)),
 391         JumpCompareAndBranch = JUMP_ENUM_WITH_SIZE(3, 2 * sizeof(uint32_t)),
 392         JumpTestBit = JUMP_ENUM_WITH_SIZE(4, 2 * sizeof(uint32_t)),
 393         JumpNoConditionFixedSize = JUMP_ENUM_WITH_SIZE(5, 1 * sizeof(uint32_t)),
 394         JumpConditionFixedSize = JUMP_ENUM_WITH_SIZE(6, 2 * sizeof(uint32_t)),
 395         JumpCompareAndBranchFixedSize = JUMP_ENUM_WITH_SIZE(7, 2 * sizeof(uint32_t)),
 396         JumpTestBitFixedSize = JUMP_ENUM_WITH_SIZE(8, 2 * sizeof(uint32_t)),
 397     };
 398     enum JumpLinkType {
 399         LinkInvalid = JUMP_ENUM_WITH_SIZE(0, 0),
 400         LinkJumpNoCondition = JUMP_ENUM_WITH_SIZE(1, 1 * sizeof(uint32_t)),
 401         LinkJumpConditionDirect = JUMP_ENUM_WITH_SIZE(2, 1 * sizeof(uint32_t)),
 402         LinkJumpCondition = JUMP_ENUM_WITH_SIZE(3, 2 * sizeof(uint32_t)),
 403         LinkJumpCompareAndBranch = JUMP_ENUM_WITH_SIZE(4, 2 * sizeof(uint32_t)),
 404         LinkJumpCompareAndBranchDirect = JUMP_ENUM_WITH_SIZE(5, 1 * sizeof(uint32_t)),
 405         LinkJumpTestBit = JUMP_ENUM_WITH_SIZE(6, 2 * sizeof(uint32_t)),
 406         LinkJumpTestBitDirect = JUMP_ENUM_WITH_SIZE(7, 1 * sizeof(uint32_t)),
 407     };
 408 
 409     class LinkRecord {
 410     public:
 411         LinkRecord(intptr_t from, intptr_t to, JumpType type, Condition condition)
 412         {
 413             data.realTypes.m_from = from;
 414             data.realTypes.m_to = to;
 415             data.realTypes.m_type = type;
 416             data.realTypes.m_linkType = LinkInvalid;
 417             data.realTypes.m_condition = condition;
 418         }
 419         LinkRecord(intptr_t from, intptr_t to, JumpType type, Condition condition, bool is64Bit, RegisterID compareRegister)
 420         {
 421             data.realTypes.m_from = from;
 422             data.realTypes.m_to = to;
 423             data.realTypes.m_type = type;
 424             data.realTypes.m_linkType = LinkInvalid;
 425             data.realTypes.m_condition = condition;
 426             data.realTypes.m_is64Bit = is64Bit;
 427             data.realTypes.m_compareRegister = compareRegister;
 428         }
 429         LinkRecord(intptr_t from, intptr_t to, JumpType type, Condition condition, unsigned bitNumber, RegisterID compareRegister)
 430         {
 431             data.realTypes.m_from = from;
 432             data.realTypes.m_to = to;
 433             data.realTypes.m_type = type;
 434             data.realTypes.m_linkType = LinkInvalid;
 435             data.realTypes.m_condition = condition;
 436             data.realTypes.m_bitNumber = bitNumber;
 437             data.realTypes.m_compareRegister = compareRegister;
 438         }
 439         void operator=(const LinkRecord&amp; other)
 440         {
 441             data.copyTypes.content[0] = other.data.copyTypes.content[0];
 442             data.copyTypes.content[1] = other.data.copyTypes.content[1];
 443             data.copyTypes.content[2] = other.data.copyTypes.content[2];
 444         }
 445         intptr_t from() const { return data.realTypes.m_from; }
 446         void setFrom(intptr_t from) { data.realTypes.m_from = from; }
 447         intptr_t to() const { return data.realTypes.m_to; }
 448         JumpType type() const { return data.realTypes.m_type; }
 449         JumpLinkType linkType() const { return data.realTypes.m_linkType; }
 450         void setLinkType(JumpLinkType linkType) { ASSERT(data.realTypes.m_linkType == LinkInvalid); data.realTypes.m_linkType = linkType; }
 451         Condition condition() const { return data.realTypes.m_condition; }
 452         bool is64Bit() const { return data.realTypes.m_is64Bit; }
 453         unsigned bitNumber() const { return data.realTypes.m_bitNumber; }
 454         RegisterID compareRegister() const { return data.realTypes.m_compareRegister; }
 455 
 456     private:
 457         union {
 458             struct RealTypes {
 459                 int64_t m_from;
 460                 int64_t m_to;
 461                 RegisterID m_compareRegister;
 462                 JumpType m_type : 8;
 463                 JumpLinkType m_linkType : 8;
 464                 Condition m_condition : 4;
 465                 unsigned m_bitNumber : 6;
 466                 bool m_is64Bit : 1;
 467             } realTypes;
 468             struct CopyTypes {
 469                 uint64_t content[3];
 470             } copyTypes;
 471             COMPILE_ASSERT(sizeof(RealTypes) == sizeof(CopyTypes), LinkRecordCopyStructSizeEqualsRealStruct);
 472         } data;
 473     };
 474 
 475     // bits(N) VFPExpandImm(bits(8) imm8);
 476     //
 477     // Encoding of floating point immediates is a litte complicated. Here&#39;s a
 478     // high level description:
 479     //     +/-m*2-n where m and n are integers, 16 &lt;= m &lt;= 31, 0 &lt;= n &lt;= 7
 480     // and the algirithm for expanding to a single precision float:
 481     //     return imm8&lt;7&gt;:NOT(imm8&lt;6&gt;):Replicate(imm8&lt;6&gt;,5):imm8&lt;5:0&gt;:Zeros(19);
 482     //
 483     // The trickiest bit is how the exponent is handled. The following table
 484     // may help clarify things a little:
 485     //     654
 486     //     100 01111100 124 -3 1020 01111111100
 487     //     101 01111101 125 -2 1021 01111111101
 488     //     110 01111110 126 -1 1022 01111111110
 489     //     111 01111111 127  0 1023 01111111111
 490     //     000 10000000 128  1 1024 10000000000
 491     //     001 10000001 129  2 1025 10000000001
 492     //     010 10000010 130  3 1026 10000000010
 493     //     011 10000011 131  4 1027 10000000011
 494     // The first column shows the bit pattern stored in bits 6-4 of the arm
 495     // encoded immediate. The second column shows the 8-bit IEEE 754 single
 496     // -precision exponent in binary, the third column shows the raw decimal
 497     // value. IEEE 754 single-precision numbers are stored with a bias of 127
 498     // to the exponent, so the fourth column shows the resulting exponent.
 499     // From this was can see that the exponent can be in the range -3..4,
 500     // which agrees with the high level description given above. The fifth
 501     // and sixth columns shows the value stored in a IEEE 754 double-precision
 502     // number to represent these exponents in decimal and binary, given the
 503     // bias of 1023.
 504     //
 505     // Ultimately, detecting doubles that can be encoded as immediates on arm
 506     // and encoding doubles is actually not too bad. A floating point value can
 507     // be encoded by retaining the sign bit, the low three bits of the exponent
 508     // and the high 4 bits of the mantissa. To validly be able to encode an
 509     // immediate the remainder of the mantissa must be zero, and the high part
 510     // of the exponent must match the top bit retained, bar the highest bit
 511     // which must be its inverse.
 512     static bool canEncodeFPImm(double d)
 513     {
 514         // Discard the sign bit, the low two bits of the exponent &amp; the highest
 515         // four bits of the mantissa.
 516         uint64_t masked = bitwise_cast&lt;uint64_t&gt;(d) &amp; 0x7fc0ffffffffffffull;
 517         return (masked == 0x3fc0000000000000ull) || (masked == 0x4000000000000000ull);
 518     }
 519 
 520     template&lt;int datasize&gt;
 521     static bool canEncodePImmOffset(int32_t offset)
 522     {
 523         return isValidScaledUImm12&lt;datasize&gt;(offset);
 524     }
 525 
 526     static bool canEncodeSImmOffset(int32_t offset)
 527     {
 528         return isValidSignedImm9(offset);
 529     }
 530 
 531 protected:
 532     int encodeFPImm(double d)
 533     {
 534         ASSERT(canEncodeFPImm(d));
 535         uint64_t u64 = bitwise_cast&lt;uint64_t&gt;(d);
 536         return (static_cast&lt;int&gt;(u64 &gt;&gt; 56) &amp; 0x80) | (static_cast&lt;int&gt;(u64 &gt;&gt; 48) &amp; 0x7f);
 537     }
 538 
 539     template&lt;int datasize&gt;
 540     int encodeShiftAmount(int amount)
 541     {
 542         ASSERT(!amount || datasize == (8 &lt;&lt; amount));
 543         return amount;
 544     }
 545 
 546     template&lt;int datasize&gt;
 547     static int encodePositiveImmediate(unsigned pimm)
 548     {
 549         ASSERT(!(pimm &amp; ((datasize / 8) - 1)));
 550         return pimm / (datasize / 8);
 551     }
 552 
 553     enum Datasize {
 554         Datasize_32,
 555         Datasize_64,
 556         Datasize_64_top,
 557         Datasize_16
 558     };
 559 
 560     enum MemOpSize {
 561         MemOpSize_8_or_128,
 562         MemOpSize_16,
 563         MemOpSize_32,
 564         MemOpSize_64,
 565     };
 566 
 567     enum BranchType {
 568         BranchType_JMP,
 569         BranchType_CALL,
 570         BranchType_RET
 571     };
 572 
 573     enum AddOp {
 574         AddOp_ADD,
 575         AddOp_SUB
 576     };
 577 
 578     enum BitfieldOp {
 579         BitfieldOp_SBFM,
 580         BitfieldOp_BFM,
 581         BitfieldOp_UBFM
 582     };
 583 
 584     enum DataOp1Source {
 585         DataOp_RBIT,
 586         DataOp_REV16,
 587         DataOp_REV32,
 588         DataOp_REV64,
 589         DataOp_CLZ,
 590         DataOp_CLS
 591     };
 592 
 593     enum DataOp2Source {
 594         DataOp_UDIV = 2,
 595         DataOp_SDIV = 3,
 596         DataOp_LSLV = 8,
 597         DataOp_LSRV = 9,
 598         DataOp_ASRV = 10,
 599         DataOp_RORV = 11
 600     };
 601 
 602     enum DataOp3Source {
 603         DataOp_MADD = 0,
 604         DataOp_MSUB = 1,
 605         DataOp_SMADDL = 2,
 606         DataOp_SMSUBL = 3,
 607         DataOp_SMULH = 4,
 608         DataOp_UMADDL = 10,
 609         DataOp_UMSUBL = 11,
 610         DataOp_UMULH = 12
 611     };
 612 
 613     enum ExcepnOp {
 614         ExcepnOp_EXCEPTION = 0,
 615         ExcepnOp_BREAKPOINT = 1,
 616         ExcepnOp_HALT = 2,
 617         ExcepnOp_DCPS = 5
 618     };
 619 
 620     enum FPCmpOp {
 621         FPCmpOp_FCMP = 0x00,
 622         FPCmpOp_FCMP0 = 0x08,
 623         FPCmpOp_FCMPE = 0x10,
 624         FPCmpOp_FCMPE0 = 0x18
 625     };
 626 
 627     enum FPCondCmpOp {
 628         FPCondCmpOp_FCMP,
 629         FPCondCmpOp_FCMPE
 630     };
 631 
 632     enum FPDataOp1Source {
 633         FPDataOp_FMOV = 0,
 634         FPDataOp_FABS = 1,
 635         FPDataOp_FNEG = 2,
 636         FPDataOp_FSQRT = 3,
 637         FPDataOp_FCVT_toSingle = 4,
 638         FPDataOp_FCVT_toDouble = 5,
 639         FPDataOp_FCVT_toHalf = 7,
 640         FPDataOp_FRINTN = 8,
 641         FPDataOp_FRINTP = 9,
 642         FPDataOp_FRINTM = 10,
 643         FPDataOp_FRINTZ = 11,
 644         FPDataOp_FRINTA = 12,
 645         FPDataOp_FRINTX = 14,
 646         FPDataOp_FRINTI = 15
 647     };
 648 
 649     enum FPDataOp2Source {
 650         FPDataOp_FMUL,
 651         FPDataOp_FDIV,
 652         FPDataOp_FADD,
 653         FPDataOp_FSUB,
 654         FPDataOp_FMAX,
 655         FPDataOp_FMIN,
 656         FPDataOp_FMAXNM,
 657         FPDataOp_FMINNM,
 658         FPDataOp_FNMUL
 659     };
 660 
 661     enum SIMD3Same {
 662         SIMD_LogicalOp = 0x03
 663     };
 664 
 665     enum SIMD3SameLogical {
 666         // This includes both the U bit and the &quot;size&quot; / opc for convience.
 667         SIMD_LogicalOp_AND = 0x00,
 668         SIMD_LogicalOp_BIC = 0x01,
 669         SIMD_LogicalOp_ORR = 0x02,
 670         SIMD_LogicalOp_ORN = 0x03,
 671         SIMD_LogacalOp_EOR = 0x80,
 672         SIMD_LogicalOp_BSL = 0x81,
 673         SIMD_LogicalOp_BIT = 0x82,
 674         SIMD_LogicalOp_BIF = 0x83,
 675     };
 676 
 677     enum FPIntConvOp {
 678         FPIntConvOp_FCVTNS = 0x00,
 679         FPIntConvOp_FCVTNU = 0x01,
 680         FPIntConvOp_SCVTF = 0x02,
 681         FPIntConvOp_UCVTF = 0x03,
 682         FPIntConvOp_FCVTAS = 0x04,
 683         FPIntConvOp_FCVTAU = 0x05,
 684         FPIntConvOp_FMOV_QtoX = 0x06,
 685         FPIntConvOp_FMOV_XtoQ = 0x07,
 686         FPIntConvOp_FCVTPS = 0x08,
 687         FPIntConvOp_FCVTPU = 0x09,
 688         FPIntConvOp_FMOV_QtoX_top = 0x0e,
 689         FPIntConvOp_FMOV_XtoQ_top = 0x0f,
 690         FPIntConvOp_FCVTMS = 0x10,
 691         FPIntConvOp_FCVTMU = 0x11,
 692         FPIntConvOp_FCVTZS = 0x18,
 693         FPIntConvOp_FCVTZU = 0x19,
 694     };
 695 
 696     enum LogicalOp {
 697         LogicalOp_AND,
 698         LogicalOp_ORR,
 699         LogicalOp_EOR,
 700         LogicalOp_ANDS
 701     };
 702 
 703     enum MemOp {
 704         MemOp_STORE,
 705         MemOp_LOAD,
 706         MemOp_STORE_V128,
 707         MemOp_LOAD_V128,
 708         MemOp_PREFETCH = 2, // size must be 3
 709         MemOp_LOAD_signed64 = 2, // size may be 0, 1 or 2
 710         MemOp_LOAD_signed32 = 3 // size may be 0 or 1
 711     };
 712 
 713     enum MemPairOpSize {
 714         MemPairOp_32 = 0,
 715         MemPairOp_LoadSigned_32 = 1,
 716         MemPairOp_64 = 2,
 717 
 718         MemPairOp_V32 = MemPairOp_32,
 719         MemPairOp_V64 = 1,
 720         MemPairOp_V128 = 2
 721     };
 722 
 723     enum MoveWideOp {
 724         MoveWideOp_N = 0,
 725         MoveWideOp_Z = 2,
 726         MoveWideOp_K = 3
 727     };
 728 
 729     enum LdrLiteralOp {
 730         LdrLiteralOp_32BIT = 0,
 731         LdrLiteralOp_64BIT = 1,
 732         LdrLiteralOp_LDRSW = 2,
 733         LdrLiteralOp_128BIT = 2
 734     };
 735 
 736     enum ExoticLoadFence {
 737         ExoticLoadFence_None,
 738         ExoticLoadFence_Acquire
 739     };
 740 
 741     enum ExoticLoadAtomic {
 742         ExoticLoadAtomic_Link,
 743         ExoticLoadAtomic_None
 744     };
 745 
 746     enum ExoticStoreFence {
 747         ExoticStoreFence_None,
 748         ExoticStoreFence_Release,
 749     };
 750 
 751     static unsigned memPairOffsetShift(bool V, MemPairOpSize size)
 752     {
 753         // return the log2 of the size in bytes, e.g. 64 bit size returns 3
 754         if (V)
 755             return size + 2;
 756         return (size &gt;&gt; 1) + 2;
 757     }
 758 
 759 public:
 760     // Integer Instructions:
 761 
 762     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 763     ALWAYS_INLINE void adc(RegisterID rd, RegisterID rn, RegisterID rm)
 764     {
 765         CHECK_DATASIZE();
 766         insn(addSubtractWithCarry(DATASIZE, AddOp_ADD, setFlags, rm, rn, rd));
 767     }
 768 
 769     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 770     ALWAYS_INLINE void add(RegisterID rd, RegisterID rn, UInt12 imm12, int shift = 0)
 771     {
 772         CHECK_DATASIZE();
 773         ASSERT(!shift || shift == 12);
 774         insn(addSubtractImmediate(DATASIZE, AddOp_ADD, setFlags, shift == 12, imm12, rn, rd));
 775     }
 776 
 777     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 778     ALWAYS_INLINE void add(RegisterID rd, RegisterID rn, RegisterID rm)
 779     {
 780         add&lt;datasize, setFlags&gt;(rd, rn, rm, LSL, 0);
 781     }
 782 
 783     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 784     ALWAYS_INLINE void add(RegisterID rd, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
 785     {
 786         CHECK_DATASIZE();
 787         insn(addSubtractExtendedRegister(DATASIZE, AddOp_ADD, setFlags, rm, extend, amount, rn, rd));
 788     }
 789 
 790     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 791     ALWAYS_INLINE void add(RegisterID rd, RegisterID rn, RegisterID rm, ShiftType shift, int amount)
 792     {
 793         CHECK_DATASIZE();
 794         if (isSp(rd) || isSp(rn)) {
 795             ASSERT(shift == LSL);
 796             ASSERT(!isSp(rm));
 797             add&lt;datasize, setFlags&gt;(rd, rn, rm, UXTX, amount);
 798         } else
 799             insn(addSubtractShiftedRegister(DATASIZE, AddOp_ADD, setFlags, shift, rm, amount, rn, rd));
 800     }
 801 
 802     ALWAYS_INLINE void adr(RegisterID rd, int offset)
 803     {
 804         insn(pcRelative(false, offset, rd));
 805     }
 806 
 807     ALWAYS_INLINE void adrp(RegisterID rd, int offset)
 808     {
 809         ASSERT(!(offset &amp; 0xfff));
 810         insn(pcRelative(true, offset &gt;&gt; 12, rd));
 811         nopCortexA53Fix843419();
 812     }
 813 
 814     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 815     ALWAYS_INLINE void and_(RegisterID rd, RegisterID rn, RegisterID rm)
 816     {
 817         and_&lt;datasize, setFlags&gt;(rd, rn, rm, LSL, 0);
 818     }
 819 
 820     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 821     ALWAYS_INLINE void and_(RegisterID rd, RegisterID rn, RegisterID rm, ShiftType shift, int amount)
 822     {
 823         CHECK_DATASIZE();
 824         insn(logicalShiftedRegister(DATASIZE, setFlags ? LogicalOp_ANDS : LogicalOp_AND, shift, false, rm, amount, rn, rd));
 825     }
 826 
 827     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 828     ALWAYS_INLINE void and_(RegisterID rd, RegisterID rn, LogicalImmediate imm)
 829     {
 830         CHECK_DATASIZE();
 831         insn(logicalImmediate(DATASIZE, setFlags ? LogicalOp_ANDS : LogicalOp_AND, imm.value(), rn, rd));
 832     }
 833 
 834     template&lt;int datasize&gt;
 835     ALWAYS_INLINE void asr(RegisterID rd, RegisterID rn, int shift)
 836     {
 837         ASSERT(shift &lt; datasize);
 838         sbfm&lt;datasize&gt;(rd, rn, shift, datasize - 1);
 839     }
 840 
 841     template&lt;int datasize&gt;
 842     ALWAYS_INLINE void asr(RegisterID rd, RegisterID rn, RegisterID rm)
 843     {
 844         asrv&lt;datasize&gt;(rd, rn, rm);
 845     }
 846 
 847     template&lt;int datasize&gt;
 848     ALWAYS_INLINE void asrv(RegisterID rd, RegisterID rn, RegisterID rm)
 849     {
 850         CHECK_DATASIZE();
 851         insn(dataProcessing2Source(DATASIZE, rm, DataOp_ASRV, rn, rd));
 852     }
 853 
 854     ALWAYS_INLINE void b(int32_t offset = 0)
 855     {
 856         ASSERT(!(offset &amp; 3));
 857         offset &gt;&gt;= 2;
 858         ASSERT(offset == (offset &lt;&lt; 6) &gt;&gt; 6);
 859         insn(unconditionalBranchImmediate(false, offset));
 860     }
 861 
 862     ALWAYS_INLINE void b_cond(Condition cond, int32_t offset = 0)
 863     {
 864         ASSERT(!(offset &amp; 3));
 865         offset &gt;&gt;= 2;
 866         ASSERT(offset == (offset &lt;&lt; 13) &gt;&gt; 13);
 867         insn(conditionalBranchImmediate(offset, cond));
 868     }
 869 
 870     template&lt;int datasize&gt;
 871     ALWAYS_INLINE void bfi(RegisterID rd, RegisterID rn, int lsb, int width)
 872     {
 873         bfm&lt;datasize&gt;(rd, rn, (datasize - lsb) &amp; (datasize - 1), width - 1);
 874     }
 875 
 876     template&lt;int datasize&gt;
 877     ALWAYS_INLINE void bfm(RegisterID rd, RegisterID rn, int immr, int imms)
 878     {
 879         CHECK_DATASIZE();
 880         insn(bitfield(DATASIZE, BitfieldOp_BFM, immr, imms, rn, rd));
 881     }
 882 
 883     template&lt;int datasize&gt;
 884     ALWAYS_INLINE void bfxil(RegisterID rd, RegisterID rn, int lsb, int width)
 885     {
 886         bfm&lt;datasize&gt;(rd, rn, lsb, lsb + width - 1);
 887     }
 888 
 889     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 890     ALWAYS_INLINE void bic(RegisterID rd, RegisterID rn, RegisterID rm)
 891     {
 892         bic&lt;datasize, setFlags&gt;(rd, rn, rm, LSL, 0);
 893     }
 894 
 895     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
 896     ALWAYS_INLINE void bic(RegisterID rd, RegisterID rn, RegisterID rm, ShiftType shift, int amount)
 897     {
 898         CHECK_DATASIZE();
 899         insn(logicalShiftedRegister(DATASIZE, setFlags ? LogicalOp_ANDS : LogicalOp_AND, shift, true, rm, amount, rn, rd));
 900     }
 901 
 902     ALWAYS_INLINE void bl(int32_t offset = 0)
 903     {
 904         ASSERT(!(offset &amp; 3));
 905         offset &gt;&gt;= 2;
 906         insn(unconditionalBranchImmediate(true, offset));
 907     }
 908 
 909     ALWAYS_INLINE void blr(RegisterID rn)
 910     {
 911         insn(unconditionalBranchRegister(BranchType_CALL, rn));
 912     }
 913 
 914     ALWAYS_INLINE void br(RegisterID rn)
 915     {
 916         insn(unconditionalBranchRegister(BranchType_JMP, rn));
 917     }
 918 
 919     ALWAYS_INLINE void brk(uint16_t imm)
 920     {
 921         insn(excepnGeneration(ExcepnOp_BREAKPOINT, imm, 0));
 922     }
 923 
 924     ALWAYS_INLINE static bool isBrk(void* address)
 925     {
 926         int expected = excepnGeneration(ExcepnOp_BREAKPOINT, 0, 0);
 927         int immediateMask = excepnGenerationImmMask();
 928         int candidateInstruction = *reinterpret_cast&lt;int*&gt;(address);
 929         return (candidateInstruction &amp; ~immediateMask) == expected;
 930     }
 931 
 932     template&lt;int datasize&gt;
 933     ALWAYS_INLINE void cbnz(RegisterID rt, int32_t offset = 0)
 934     {
 935         CHECK_DATASIZE();
 936         ASSERT(!(offset &amp; 3));
 937         offset &gt;&gt;= 2;
 938         insn(compareAndBranchImmediate(DATASIZE, true, offset, rt));
 939     }
 940 
 941     template&lt;int datasize&gt;
 942     ALWAYS_INLINE void cbz(RegisterID rt, int32_t offset = 0)
 943     {
 944         CHECK_DATASIZE();
 945         ASSERT(!(offset &amp; 3));
 946         offset &gt;&gt;= 2;
 947         insn(compareAndBranchImmediate(DATASIZE, false, offset, rt));
 948     }
 949 
 950     template&lt;int datasize&gt;
 951     ALWAYS_INLINE void ccmn(RegisterID rn, RegisterID rm, int nzcv, Condition cond)
 952     {
 953         CHECK_DATASIZE();
 954         insn(conditionalCompareRegister(DATASIZE, AddOp_ADD, rm, cond, rn, nzcv));
 955     }
 956 
 957     template&lt;int datasize&gt;
 958     ALWAYS_INLINE void ccmn(RegisterID rn, UInt5 imm, int nzcv, Condition cond)
 959     {
 960         CHECK_DATASIZE();
 961         insn(conditionalCompareImmediate(DATASIZE, AddOp_ADD, imm, cond, rn, nzcv));
 962     }
 963 
 964     template&lt;int datasize&gt;
 965     ALWAYS_INLINE void ccmp(RegisterID rn, RegisterID rm, int nzcv, Condition cond)
 966     {
 967         CHECK_DATASIZE();
 968         insn(conditionalCompareRegister(DATASIZE, AddOp_SUB, rm, cond, rn, nzcv));
 969     }
 970 
 971     template&lt;int datasize&gt;
 972     ALWAYS_INLINE void ccmp(RegisterID rn, UInt5 imm, int nzcv, Condition cond)
 973     {
 974         CHECK_DATASIZE();
 975         insn(conditionalCompareImmediate(DATASIZE, AddOp_SUB, imm, cond, rn, nzcv));
 976     }
 977 
 978     template&lt;int datasize&gt;
 979     ALWAYS_INLINE void cinc(RegisterID rd, RegisterID rn, Condition cond)
 980     {
 981         csinc&lt;datasize&gt;(rd, rn, rn, invert(cond));
 982     }
 983 
 984     template&lt;int datasize&gt;
 985     ALWAYS_INLINE void cinv(RegisterID rd, RegisterID rn, Condition cond)
 986     {
 987         csinv&lt;datasize&gt;(rd, rn, rn, invert(cond));
 988     }
 989 
 990     template&lt;int datasize&gt;
 991     ALWAYS_INLINE void cls(RegisterID rd, RegisterID rn)
 992     {
 993         CHECK_DATASIZE();
 994         insn(dataProcessing1Source(DATASIZE, DataOp_CLS, rn, rd));
 995     }
 996 
 997     template&lt;int datasize&gt;
 998     ALWAYS_INLINE void clz(RegisterID rd, RegisterID rn)
 999     {
1000         CHECK_DATASIZE();
1001         insn(dataProcessing1Source(DATASIZE, DataOp_CLZ, rn, rd));
1002     }
1003 
1004     template&lt;int datasize&gt;
1005     ALWAYS_INLINE void cmn(RegisterID rn, UInt12 imm12, int shift = 0)
1006     {
1007         add&lt;datasize, S&gt;(ARM64Registers::zr, rn, imm12, shift);
1008     }
1009 
1010     template&lt;int datasize&gt;
1011     ALWAYS_INLINE void cmn(RegisterID rn, RegisterID rm)
1012     {
1013         add&lt;datasize, S&gt;(ARM64Registers::zr, rn, rm);
1014     }
1015 
1016     template&lt;int datasize&gt;
1017     ALWAYS_INLINE void cmn(RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1018     {
1019         add&lt;datasize, S&gt;(ARM64Registers::zr, rn, rm, extend, amount);
1020     }
1021 
1022     template&lt;int datasize&gt;
1023     ALWAYS_INLINE void cmn(RegisterID rn, RegisterID rm, ShiftType shift, int amount)
1024     {
1025         add&lt;datasize, S&gt;(ARM64Registers::zr, rn, rm, shift, amount);
1026     }
1027 
1028     template&lt;int datasize&gt;
1029     ALWAYS_INLINE void cmp(RegisterID rn, UInt12 imm12, int shift = 0)
1030     {
1031         sub&lt;datasize, S&gt;(ARM64Registers::zr, rn, imm12, shift);
1032     }
1033 
1034     template&lt;int datasize&gt;
1035     ALWAYS_INLINE void cmp(RegisterID rn, RegisterID rm)
1036     {
1037         sub&lt;datasize, S&gt;(ARM64Registers::zr, rn, rm);
1038     }
1039 
1040     template&lt;int datasize&gt;
1041     ALWAYS_INLINE void cmp(RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1042     {
1043         sub&lt;datasize, S&gt;(ARM64Registers::zr, rn, rm, extend, amount);
1044     }
1045 
1046     template&lt;int datasize&gt;
1047     ALWAYS_INLINE void cmp(RegisterID rn, RegisterID rm, ShiftType shift, int amount)
1048     {
1049         sub&lt;datasize, S&gt;(ARM64Registers::zr, rn, rm, shift, amount);
1050     }
1051 
1052     template&lt;int datasize&gt;
1053     ALWAYS_INLINE void cneg(RegisterID rd, RegisterID rn, Condition cond)
1054     {
1055         csneg&lt;datasize&gt;(rd, rn, rn, invert(cond));
1056     }
1057 
1058     template&lt;int datasize&gt;
1059     ALWAYS_INLINE void csel(RegisterID rd, RegisterID rn, RegisterID rm, Condition cond)
1060     {
1061         CHECK_DATASIZE();
1062         insn(conditionalSelect(DATASIZE, false, rm, cond, false, rn, rd));
1063     }
1064 
1065     template&lt;int datasize&gt;
1066     ALWAYS_INLINE void cset(RegisterID rd, Condition cond)
1067     {
1068         csinc&lt;datasize&gt;(rd, ARM64Registers::zr, ARM64Registers::zr, invert(cond));
1069     }
1070 
1071     template&lt;int datasize&gt;
1072     ALWAYS_INLINE void csetm(RegisterID rd, Condition cond)
1073     {
1074         csinv&lt;datasize&gt;(rd, ARM64Registers::zr, ARM64Registers::zr, invert(cond));
1075     }
1076 
1077     template&lt;int datasize&gt;
1078     ALWAYS_INLINE void csinc(RegisterID rd, RegisterID rn, RegisterID rm, Condition cond)
1079     {
1080         CHECK_DATASIZE();
1081         insn(conditionalSelect(DATASIZE, false, rm, cond, true, rn, rd));
1082     }
1083 
1084     template&lt;int datasize&gt;
1085     ALWAYS_INLINE void csinv(RegisterID rd, RegisterID rn, RegisterID rm, Condition cond)
1086     {
1087         CHECK_DATASIZE();
1088         insn(conditionalSelect(DATASIZE, true, rm, cond, false, rn, rd));
1089     }
1090 
1091     template&lt;int datasize&gt;
1092     ALWAYS_INLINE void csneg(RegisterID rd, RegisterID rn, RegisterID rm, Condition cond)
1093     {
1094         CHECK_DATASIZE();
1095         insn(conditionalSelect(DATASIZE, true, rm, cond, true, rn, rd));
1096     }
1097 
1098     template&lt;int datasize&gt;
1099     ALWAYS_INLINE void eon(RegisterID rd, RegisterID rn, RegisterID rm)
1100     {
1101         eon&lt;datasize&gt;(rd, rn, rm, LSL, 0);
1102     }
1103 
1104     template&lt;int datasize&gt;
1105     ALWAYS_INLINE void eon(RegisterID rd, RegisterID rn, RegisterID rm, ShiftType shift, int amount)
1106     {
1107         CHECK_DATASIZE();
1108         insn(logicalShiftedRegister(DATASIZE, LogicalOp_EOR, shift, true, rm, amount, rn, rd));
1109     }
1110 
1111     template&lt;int datasize&gt;
1112     ALWAYS_INLINE void eor(RegisterID rd, RegisterID rn, RegisterID rm)
1113     {
1114         eor&lt;datasize&gt;(rd, rn, rm, LSL, 0);
1115     }
1116 
1117     template&lt;int datasize&gt;
1118     ALWAYS_INLINE void eor(RegisterID rd, RegisterID rn, RegisterID rm, ShiftType shift, int amount)
1119     {
1120         CHECK_DATASIZE();
1121         insn(logicalShiftedRegister(DATASIZE, LogicalOp_EOR, shift, false, rm, amount, rn, rd));
1122     }
1123 
1124     template&lt;int datasize&gt;
1125     ALWAYS_INLINE void eor(RegisterID rd, RegisterID rn, LogicalImmediate imm)
1126     {
1127         CHECK_DATASIZE();
1128         insn(logicalImmediate(DATASIZE, LogicalOp_EOR, imm.value(), rn, rd));
1129     }
1130 
1131     template&lt;int datasize&gt;
1132     ALWAYS_INLINE void extr(RegisterID rd, RegisterID rn, RegisterID rm, int lsb)
1133     {
1134         CHECK_DATASIZE();
1135         insn(extract(DATASIZE, rm, lsb, rn, rd));
1136     }
1137 
1138     ALWAYS_INLINE void hint(int imm)
1139     {
1140         insn(hintPseudo(imm));
1141     }
1142 
1143     ALWAYS_INLINE void hlt(uint16_t imm)
1144     {
1145         insn(excepnGeneration(ExcepnOp_HALT, imm, 0));
1146     }
1147 
1148     // Only used for testing purposes.
1149     void illegalInstruction()
1150     {
1151         insn(0x0);
1152     }
1153 
1154     template&lt;int datasize&gt;
1155     ALWAYS_INLINE void ldp(RegisterID rt, RegisterID rt2, RegisterID rn, PairPostIndex simm)
1156     {
1157         CHECK_DATASIZE();
1158         insn(loadStoreRegisterPairPostIndex(MEMPAIROPSIZE_INT(datasize), false, MemOp_LOAD, simm, rn, rt, rt2));
1159     }
1160 
1161     template&lt;int datasize&gt;
1162     ALWAYS_INLINE void ldp(RegisterID rt, RegisterID rt2, RegisterID rn, PairPreIndex simm)
1163     {
1164         CHECK_DATASIZE();
1165         insn(loadStoreRegisterPairPreIndex(MEMPAIROPSIZE_INT(datasize), false, MemOp_LOAD, simm, rn, rt, rt2));
1166     }
1167 
1168     template&lt;int datasize&gt;
1169     ALWAYS_INLINE void ldp(RegisterID rt, RegisterID rt2, RegisterID rn, unsigned pimm = 0)
1170     {
1171         CHECK_DATASIZE();
1172         insn(loadStoreRegisterPairOffset(MEMPAIROPSIZE_INT(datasize), false, MemOp_LOAD, pimm, rn, rt, rt2));
1173     }
1174 
1175     template&lt;int datasize&gt;
1176     ALWAYS_INLINE void ldnp(RegisterID rt, RegisterID rt2, RegisterID rn, unsigned pimm = 0)
1177     {
1178         CHECK_DATASIZE();
1179         insn(loadStoreRegisterPairNonTemporal(MEMPAIROPSIZE_INT(datasize), false, MemOp_LOAD, pimm, rn, rt, rt2));
1180     }
1181 
1182     template&lt;int datasize&gt;
1183     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, RegisterID rm)
1184     {
1185         ldr&lt;datasize&gt;(rt, rn, rm, UXTX, 0);
1186     }
1187 
1188     template&lt;int datasize&gt;
1189     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1190     {
1191         CHECK_DATASIZE();
1192         insn(loadStoreRegisterRegisterOffset(MEMOPSIZE, false, MemOp_LOAD, rm, extend, encodeShiftAmount&lt;datasize&gt;(amount), rn, rt));
1193     }
1194 
1195     template&lt;int datasize&gt;
1196     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, unsigned pimm)
1197     {
1198         CHECK_DATASIZE();
1199         insn(loadStoreRegisterUnsignedImmediate(MEMOPSIZE, false, MemOp_LOAD, encodePositiveImmediate&lt;datasize&gt;(pimm), rn, rt));
1200     }
1201 
1202     template&lt;int datasize&gt;
1203     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, PostIndex simm)
1204     {
1205         CHECK_DATASIZE();
1206         insn(loadStoreRegisterPostIndex(MEMOPSIZE, false, MemOp_LOAD, simm, rn, rt));
1207     }
1208 
1209     template&lt;int datasize&gt;
1210     ALWAYS_INLINE void ldr(RegisterID rt, RegisterID rn, PreIndex simm)
1211     {
1212         CHECK_DATASIZE();
1213         insn(loadStoreRegisterPreIndex(MEMOPSIZE, false, MemOp_LOAD, simm, rn, rt));
1214     }
1215 
1216     template&lt;int datasize&gt;
1217     ALWAYS_INLINE void ldr_literal(RegisterID rt, int offset = 0)
1218     {
1219         CHECK_DATASIZE();
1220         ASSERT(!(offset &amp; 3));
1221         insn(loadRegisterLiteral(datasize == 64 ? LdrLiteralOp_64BIT : LdrLiteralOp_32BIT, false, offset &gt;&gt; 2, rt));
1222     }
1223 
1224     ALWAYS_INLINE void ldrb(RegisterID rt, RegisterID rn, RegisterID rm)
1225     {
1226         // Not calling the 5 argument form of ldrb, since is amount is ommitted S is false.
1227         insn(loadStoreRegisterRegisterOffset(MemOpSize_8_or_128, false, MemOp_LOAD, rm, UXTX, false, rn, rt));
1228     }
1229 
1230     ALWAYS_INLINE void ldrb(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1231     {
1232         ASSERT_UNUSED(amount, !amount);
1233         insn(loadStoreRegisterRegisterOffset(MemOpSize_8_or_128, false, MemOp_LOAD, rm, extend, true, rn, rt));
1234     }
1235 
1236     ALWAYS_INLINE void ldrb(RegisterID rt, RegisterID rn, unsigned pimm)
1237     {
1238         insn(loadStoreRegisterUnsignedImmediate(MemOpSize_8_or_128, false, MemOp_LOAD, encodePositiveImmediate&lt;8&gt;(pimm), rn, rt));
1239     }
1240 
1241     ALWAYS_INLINE void ldrb(RegisterID rt, RegisterID rn, PostIndex simm)
1242     {
1243         insn(loadStoreRegisterPostIndex(MemOpSize_8_or_128, false, MemOp_LOAD, simm, rn, rt));
1244     }
1245 
1246     ALWAYS_INLINE void ldrb(RegisterID rt, RegisterID rn, PreIndex simm)
1247     {
1248         insn(loadStoreRegisterPreIndex(MemOpSize_8_or_128, false, MemOp_LOAD, simm, rn, rt));
1249     }
1250 
1251     ALWAYS_INLINE void ldrh(RegisterID rt, RegisterID rn, RegisterID rm)
1252     {
1253         ldrh(rt, rn, rm, UXTX, 0);
1254     }
1255 
1256     ALWAYS_INLINE void ldrh(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1257     {
1258         ASSERT(!amount || amount == 1);
1259         insn(loadStoreRegisterRegisterOffset(MemOpSize_16, false, MemOp_LOAD, rm, extend, amount == 1, rn, rt));
1260     }
1261 
1262     ALWAYS_INLINE void ldrh(RegisterID rt, RegisterID rn, unsigned pimm)
1263     {
1264         insn(loadStoreRegisterUnsignedImmediate(MemOpSize_16, false, MemOp_LOAD, encodePositiveImmediate&lt;16&gt;(pimm), rn, rt));
1265     }
1266 
1267     ALWAYS_INLINE void ldrh(RegisterID rt, RegisterID rn, PostIndex simm)
1268     {
1269         insn(loadStoreRegisterPostIndex(MemOpSize_16, false, MemOp_LOAD, simm, rn, rt));
1270     }
1271 
1272     ALWAYS_INLINE void ldrh(RegisterID rt, RegisterID rn, PreIndex simm)
1273     {
1274         insn(loadStoreRegisterPreIndex(MemOpSize_16, false, MemOp_LOAD, simm, rn, rt));
1275     }
1276 
1277     template&lt;int datasize&gt;
1278     ALWAYS_INLINE void ldrsb(RegisterID rt, RegisterID rn, RegisterID rm)
1279     {
1280         CHECK_DATASIZE();
1281         // Not calling the 5 argument form of ldrsb, since is amount is ommitted S is false.
1282         insn(loadStoreRegisterRegisterOffset(MemOpSize_8_or_128, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, rm, UXTX, false, rn, rt));
1283     }
1284 
1285     template&lt;int datasize&gt;
1286     ALWAYS_INLINE void ldrsb(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1287     {
1288         CHECK_DATASIZE();
1289         ASSERT_UNUSED(amount, !amount);
1290         insn(loadStoreRegisterRegisterOffset(MemOpSize_8_or_128, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, rm, extend, true, rn, rt));
1291     }
1292 
1293     template&lt;int datasize&gt;
1294     ALWAYS_INLINE void ldrsb(RegisterID rt, RegisterID rn, unsigned pimm)
1295     {
1296         CHECK_DATASIZE();
1297         insn(loadStoreRegisterUnsignedImmediate(MemOpSize_8_or_128, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, encodePositiveImmediate&lt;8&gt;(pimm), rn, rt));
1298     }
1299 
1300     template&lt;int datasize&gt;
1301     ALWAYS_INLINE void ldrsb(RegisterID rt, RegisterID rn, PostIndex simm)
1302     {
1303         CHECK_DATASIZE();
1304         insn(loadStoreRegisterPostIndex(MemOpSize_8_or_128, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, simm, rn, rt));
1305     }
1306 
1307     template&lt;int datasize&gt;
1308     ALWAYS_INLINE void ldrsb(RegisterID rt, RegisterID rn, PreIndex simm)
1309     {
1310         CHECK_DATASIZE();
1311         insn(loadStoreRegisterPreIndex(MemOpSize_8_or_128, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, simm, rn, rt));
1312     }
1313 
1314     template&lt;int datasize&gt;
1315     ALWAYS_INLINE void ldrsh(RegisterID rt, RegisterID rn, RegisterID rm)
1316     {
1317         ldrsh&lt;datasize&gt;(rt, rn, rm, UXTX, 0);
1318     }
1319 
1320     template&lt;int datasize&gt;
1321     ALWAYS_INLINE void ldrsh(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1322     {
1323         CHECK_DATASIZE();
1324         ASSERT(!amount || amount == 1);
1325         insn(loadStoreRegisterRegisterOffset(MemOpSize_16, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, rm, extend, amount == 1, rn, rt));
1326     }
1327 
1328     template&lt;int datasize&gt;
1329     ALWAYS_INLINE void ldrsh(RegisterID rt, RegisterID rn, unsigned pimm)
1330     {
1331         CHECK_DATASIZE();
1332         insn(loadStoreRegisterUnsignedImmediate(MemOpSize_16, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, encodePositiveImmediate&lt;16&gt;(pimm), rn, rt));
1333     }
1334 
1335     template&lt;int datasize&gt;
1336     ALWAYS_INLINE void ldrsh(RegisterID rt, RegisterID rn, PostIndex simm)
1337     {
1338         CHECK_DATASIZE();
1339         insn(loadStoreRegisterPostIndex(MemOpSize_16, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, simm, rn, rt));
1340     }
1341 
1342     template&lt;int datasize&gt;
1343     ALWAYS_INLINE void ldrsh(RegisterID rt, RegisterID rn, PreIndex simm)
1344     {
1345         CHECK_DATASIZE();
1346         insn(loadStoreRegisterPreIndex(MemOpSize_16, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, simm, rn, rt));
1347     }
1348 
1349     ALWAYS_INLINE void ldrsw(RegisterID rt, RegisterID rn, RegisterID rm)
1350     {
1351         ldrsw(rt, rn, rm, UXTX, 0);
1352     }
1353 
1354     ALWAYS_INLINE void ldrsw(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1355     {
1356         ASSERT(!amount || amount == 2);
1357         insn(loadStoreRegisterRegisterOffset(MemOpSize_32, false, MemOp_LOAD_signed64, rm, extend, amount == 2, rn, rt));
1358     }
1359 
1360     ALWAYS_INLINE void ldrsw(RegisterID rt, RegisterID rn, unsigned pimm)
1361     {
1362         insn(loadStoreRegisterUnsignedImmediate(MemOpSize_32, false, MemOp_LOAD_signed64, encodePositiveImmediate&lt;32&gt;(pimm), rn, rt));
1363     }
1364 
1365     ALWAYS_INLINE void ldrsw(RegisterID rt, RegisterID rn, PostIndex simm)
1366     {
1367         insn(loadStoreRegisterPostIndex(MemOpSize_32, false, MemOp_LOAD_signed64, simm, rn, rt));
1368     }
1369 
1370     ALWAYS_INLINE void ldrsw(RegisterID rt, RegisterID rn, PreIndex simm)
1371     {
1372         insn(loadStoreRegisterPreIndex(MemOpSize_32, false, MemOp_LOAD_signed64, simm, rn, rt));
1373     }
1374 
1375     ALWAYS_INLINE void ldrsw_literal(RegisterID rt, int offset = 0)
1376     {
1377         ASSERT(!(offset &amp; 3));
1378         insn(loadRegisterLiteral(LdrLiteralOp_LDRSW, false, offset &gt;&gt; 2, rt));
1379     }
1380 
1381     template&lt;int datasize&gt;
1382     ALWAYS_INLINE void ldur(RegisterID rt, RegisterID rn, int simm)
1383     {
1384         CHECK_DATASIZE();
1385         insn(loadStoreRegisterUnscaledImmediate(MEMOPSIZE, false, MemOp_LOAD, simm, rn, rt));
1386     }
1387 
1388     ALWAYS_INLINE void ldurb(RegisterID rt, RegisterID rn, int simm)
1389     {
1390         insn(loadStoreRegisterUnscaledImmediate(MemOpSize_8_or_128, false, MemOp_LOAD, simm, rn, rt));
1391     }
1392 
1393     ALWAYS_INLINE void ldurh(RegisterID rt, RegisterID rn, int simm)
1394     {
1395         insn(loadStoreRegisterUnscaledImmediate(MemOpSize_16, false, MemOp_LOAD, simm, rn, rt));
1396     }
1397 
1398     template&lt;int datasize&gt;
1399     ALWAYS_INLINE void ldursb(RegisterID rt, RegisterID rn, int simm)
1400     {
1401         CHECK_DATASIZE();
1402         insn(loadStoreRegisterUnscaledImmediate(MemOpSize_8_or_128, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, simm, rn, rt));
1403     }
1404 
1405     template&lt;int datasize&gt;
1406     ALWAYS_INLINE void ldursh(RegisterID rt, RegisterID rn, int simm)
1407     {
1408         CHECK_DATASIZE();
1409         insn(loadStoreRegisterUnscaledImmediate(MemOpSize_16, false, (datasize == 64) ? MemOp_LOAD_signed64 : MemOp_LOAD_signed32, simm, rn, rt));
1410     }
1411 
1412     ALWAYS_INLINE void ldursw(RegisterID rt, RegisterID rn, int simm)
1413     {
1414         insn(loadStoreRegisterUnscaledImmediate(MemOpSize_32, false, MemOp_LOAD_signed64, simm, rn, rt));
1415     }
1416 
1417     template&lt;int datasize&gt;
1418     ALWAYS_INLINE void lsl(RegisterID rd, RegisterID rn, int shift)
1419     {
1420         ASSERT(shift &lt; datasize);
1421         ubfm&lt;datasize&gt;(rd, rn, (datasize - shift) &amp; (datasize - 1), datasize - 1 - shift);
1422     }
1423 
1424     template&lt;int datasize&gt;
1425     ALWAYS_INLINE void lsl(RegisterID rd, RegisterID rn, RegisterID rm)
1426     {
1427         lslv&lt;datasize&gt;(rd, rn, rm);
1428     }
1429 
1430     template&lt;int datasize&gt;
1431     ALWAYS_INLINE void lslv(RegisterID rd, RegisterID rn, RegisterID rm)
1432     {
1433         CHECK_DATASIZE();
1434         insn(dataProcessing2Source(DATASIZE, rm, DataOp_LSLV, rn, rd));
1435     }
1436 
1437     template&lt;int datasize&gt;
1438     ALWAYS_INLINE void lsr(RegisterID rd, RegisterID rn, int shift)
1439     {
1440         ASSERT(shift &lt; datasize);
1441         ubfm&lt;datasize&gt;(rd, rn, shift, datasize - 1);
1442     }
1443 
1444     template&lt;int datasize&gt;
1445     ALWAYS_INLINE void lsr(RegisterID rd, RegisterID rn, RegisterID rm)
1446     {
1447         lsrv&lt;datasize&gt;(rd, rn, rm);
1448     }
1449 
1450     template&lt;int datasize&gt;
1451     ALWAYS_INLINE void lsrv(RegisterID rd, RegisterID rn, RegisterID rm)
1452     {
1453         CHECK_DATASIZE();
1454         insn(dataProcessing2Source(DATASIZE, rm, DataOp_LSRV, rn, rd));
1455     }
1456 
1457     template&lt;int datasize&gt;
1458     ALWAYS_INLINE void madd(RegisterID rd, RegisterID rn, RegisterID rm, RegisterID ra)
1459     {
1460         CHECK_DATASIZE();
1461         nopCortexA53Fix835769&lt;datasize&gt;();
1462         insn(dataProcessing3Source(DATASIZE, DataOp_MADD, rm, ra, rn, rd));
1463     }
1464 
1465     template&lt;int datasize&gt;
1466     ALWAYS_INLINE void mneg(RegisterID rd, RegisterID rn, RegisterID rm)
1467     {
1468         msub&lt;datasize&gt;(rd, rn, rm, ARM64Registers::zr);
1469     }
1470 
1471     template&lt;int datasize&gt;
1472     ALWAYS_INLINE void mov(RegisterID rd, RegisterID rm)
1473     {
1474         if (isSp(rd) || isSp(rm))
1475             add&lt;datasize&gt;(rd, rm, UInt12(0));
1476         else
1477             orr&lt;datasize&gt;(rd, ARM64Registers::zr, rm);
1478     }
1479 
1480     template&lt;int datasize&gt;
1481     ALWAYS_INLINE void movi(RegisterID rd, LogicalImmediate imm)
1482     {
1483         orr&lt;datasize&gt;(rd, ARM64Registers::zr, imm);
1484     }
1485 
1486     template&lt;int datasize&gt;
1487     ALWAYS_INLINE void movk(RegisterID rd, uint16_t value, int shift = 0)
1488     {
1489         CHECK_DATASIZE();
1490         ASSERT(!(shift &amp; 0xf));
1491         insn(moveWideImediate(DATASIZE, MoveWideOp_K, shift &gt;&gt; 4, value, rd));
1492     }
1493 
1494     template&lt;int datasize&gt;
1495     ALWAYS_INLINE void movn(RegisterID rd, uint16_t value, int shift = 0)
1496     {
1497         CHECK_DATASIZE();
1498         ASSERT(!(shift &amp; 0xf));
1499         insn(moveWideImediate(DATASIZE, MoveWideOp_N, shift &gt;&gt; 4, value, rd));
1500     }
1501 
1502     template&lt;int datasize&gt;
1503     ALWAYS_INLINE void movz(RegisterID rd, uint16_t value, int shift = 0)
1504     {
1505         CHECK_DATASIZE();
1506         ASSERT(!(shift &amp; 0xf));
1507         insn(moveWideImediate(DATASIZE, MoveWideOp_Z, shift &gt;&gt; 4, value, rd));
1508     }
1509 
1510     template&lt;int datasize&gt;
1511     ALWAYS_INLINE void msub(RegisterID rd, RegisterID rn, RegisterID rm, RegisterID ra)
1512     {
1513         CHECK_DATASIZE();
1514         nopCortexA53Fix835769&lt;datasize&gt;();
1515         insn(dataProcessing3Source(DATASIZE, DataOp_MSUB, rm, ra, rn, rd));
1516     }
1517 
1518     template&lt;int datasize&gt;
1519     ALWAYS_INLINE void mul(RegisterID rd, RegisterID rn, RegisterID rm)
1520     {
1521         madd&lt;datasize&gt;(rd, rn, rm, ARM64Registers::zr);
1522     }
1523 
1524     template&lt;int datasize&gt;
1525     ALWAYS_INLINE void mvn(RegisterID rd, RegisterID rm)
1526     {
1527         orn&lt;datasize&gt;(rd, ARM64Registers::zr, rm);
1528     }
1529 
1530     template&lt;int datasize&gt;
1531     ALWAYS_INLINE void mvn(RegisterID rd, RegisterID rm, ShiftType shift, int amount)
1532     {
1533         orn&lt;datasize&gt;(rd, ARM64Registers::zr, rm, shift, amount);
1534     }
1535 
1536     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1537     ALWAYS_INLINE void neg(RegisterID rd, RegisterID rm)
1538     {
1539         sub&lt;datasize, setFlags&gt;(rd, ARM64Registers::zr, rm);
1540     }
1541 
1542     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1543     ALWAYS_INLINE void neg(RegisterID rd, RegisterID rm, ShiftType shift, int amount)
1544     {
1545         sub&lt;datasize, setFlags&gt;(rd, ARM64Registers::zr, rm, shift, amount);
1546     }
1547 
1548     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1549     ALWAYS_INLINE void ngc(RegisterID rd, RegisterID rm)
1550     {
1551         sbc&lt;datasize, setFlags&gt;(rd, ARM64Registers::zr, rm);
1552     }
1553 
1554     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1555     ALWAYS_INLINE void ngc(RegisterID rd, RegisterID rm, ShiftType shift, int amount)
1556     {
1557         sbc&lt;datasize, setFlags&gt;(rd, ARM64Registers::zr, rm, shift, amount);
1558     }
1559 
1560     ALWAYS_INLINE void nop()
1561     {
1562         insn(nopPseudo());
1563     }
1564 
1565     template &lt;typename CopyFunction&gt;
1566     static void fillNops(void* base, size_t size, CopyFunction copy)
1567     {
1568         RELEASE_ASSERT(!(size % sizeof(int32_t)));
1569         size_t n = size / sizeof(int32_t);
1570         for (int32_t* ptr = static_cast&lt;int32_t*&gt;(base); n--;) {
1571             int insn = nopPseudo();
1572             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(ptr) == ptr);
1573             copy(ptr++, &amp;insn, sizeof(int));
1574         }
1575     }
1576 
1577     ALWAYS_INLINE void dmbISH()
1578     {
1579         insn(0xd5033bbf);
1580     }
1581 
1582     ALWAYS_INLINE void dmbISHST()
1583     {
1584         insn(0xd5033abf);
1585     }
1586 
1587     template&lt;int datasize&gt;
1588     void ldar(RegisterID dst, RegisterID src)
1589     {
1590         CHECK_MEMOPSIZE();
1591         insn(exoticLoad(MEMOPSIZE, ExoticLoadFence_Acquire, ExoticLoadAtomic_None, dst, src));
1592     }
1593 
1594     template&lt;int datasize&gt;
1595     void ldxr(RegisterID dst, RegisterID src)
1596     {
1597         CHECK_MEMOPSIZE();
1598         insn(exoticLoad(MEMOPSIZE, ExoticLoadFence_None, ExoticLoadAtomic_Link, dst, src));
1599     }
1600 
1601     template&lt;int datasize&gt;
1602     void ldaxr(RegisterID dst, RegisterID src)
1603     {
1604         CHECK_MEMOPSIZE();
1605         insn(exoticLoad(MEMOPSIZE, ExoticLoadFence_Acquire, ExoticLoadAtomic_Link, dst, src));
1606     }
1607 
1608     template&lt;int datasize&gt;
1609     void stxr(RegisterID result, RegisterID src, RegisterID dst)
1610     {
1611         CHECK_MEMOPSIZE();
1612         insn(exoticStore(MEMOPSIZE, ExoticStoreFence_None, result, src, dst));
1613     }
1614 
1615     template&lt;int datasize&gt;
1616     void stlr(RegisterID src, RegisterID dst)
1617     {
1618         CHECK_MEMOPSIZE();
1619         insn(storeRelease(MEMOPSIZE, src, dst));
1620     }
1621 
1622     template&lt;int datasize&gt;
1623     void stlxr(RegisterID result, RegisterID src, RegisterID dst)
1624     {
1625         CHECK_MEMOPSIZE();
1626         insn(exoticStore(MEMOPSIZE, ExoticStoreFence_Release, result, src, dst));
1627     }
1628 
1629 #if ENABLE(FAST_TLS_JIT)
1630     void mrs_TPIDRRO_EL0(RegisterID dst)
1631     {
1632         insn(0xd53bd060 | dst); // Thanks, otool -t!
1633     }
1634 #endif
1635 
1636     template&lt;int datasize&gt;
1637     ALWAYS_INLINE void orn(RegisterID rd, RegisterID rn, RegisterID rm)
1638     {
1639         orn&lt;datasize&gt;(rd, rn, rm, LSL, 0);
1640     }
1641 
1642     template&lt;int datasize&gt;
1643     ALWAYS_INLINE void orn(RegisterID rd, RegisterID rn, RegisterID rm, ShiftType shift, int amount)
1644     {
1645         CHECK_DATASIZE();
1646         insn(logicalShiftedRegister(DATASIZE, LogicalOp_ORR, shift, true, rm, amount, rn, rd));
1647     }
1648 
1649     template&lt;int datasize&gt;
1650     ALWAYS_INLINE void orr(RegisterID rd, RegisterID rn, RegisterID rm)
1651     {
1652         orr&lt;datasize&gt;(rd, rn, rm, LSL, 0);
1653     }
1654 
1655     template&lt;int datasize&gt;
1656     ALWAYS_INLINE void orr(RegisterID rd, RegisterID rn, RegisterID rm, ShiftType shift, int amount)
1657     {
1658         CHECK_DATASIZE();
1659         insn(logicalShiftedRegister(DATASIZE, LogicalOp_ORR, shift, false, rm, amount, rn, rd));
1660     }
1661 
1662     template&lt;int datasize&gt;
1663     ALWAYS_INLINE void orr(RegisterID rd, RegisterID rn, LogicalImmediate imm)
1664     {
1665         CHECK_DATASIZE();
1666         insn(logicalImmediate(DATASIZE, LogicalOp_ORR, imm.value(), rn, rd));
1667     }
1668 
1669     template&lt;int datasize&gt;
1670     ALWAYS_INLINE void rbit(RegisterID rd, RegisterID rn)
1671     {
1672         CHECK_DATASIZE();
1673         insn(dataProcessing1Source(DATASIZE, DataOp_RBIT, rn, rd));
1674     }
1675 
1676     ALWAYS_INLINE void ret(RegisterID rn = ARM64Registers::lr)
1677     {
1678         insn(unconditionalBranchRegister(BranchType_RET, rn));
1679     }
1680 
1681     template&lt;int datasize&gt;
1682     ALWAYS_INLINE void rev(RegisterID rd, RegisterID rn)
1683     {
1684         CHECK_DATASIZE();
1685         if (datasize == 32) // &#39;rev&#39; mnemonic means REV32 or REV64 depending on the operand width.
1686             insn(dataProcessing1Source(Datasize_32, DataOp_REV32, rn, rd));
1687         else
1688             insn(dataProcessing1Source(Datasize_64, DataOp_REV64, rn, rd));
1689     }
1690 
1691     template&lt;int datasize&gt;
1692     ALWAYS_INLINE void rev16(RegisterID rd, RegisterID rn)
1693     {
1694         CHECK_DATASIZE();
1695         insn(dataProcessing1Source(DATASIZE, DataOp_REV16, rn, rd));
1696     }
1697 
1698     template&lt;int datasize&gt;
1699     ALWAYS_INLINE void rev32(RegisterID rd, RegisterID rn)
1700     {
1701         ASSERT(datasize == 64); // &#39;rev32&#39; only valid with 64-bit operands.
1702         insn(dataProcessing1Source(Datasize_64, DataOp_REV32, rn, rd));
1703     }
1704 
1705     template&lt;int datasize&gt;
1706     ALWAYS_INLINE void ror(RegisterID rd, RegisterID rn, RegisterID rm)
1707     {
1708         rorv&lt;datasize&gt;(rd, rn, rm);
1709     }
1710 
1711     template&lt;int datasize&gt;
1712     ALWAYS_INLINE void ror(RegisterID rd, RegisterID rs, int shift)
1713     {
1714         extr&lt;datasize&gt;(rd, rs, rs, shift);
1715     }
1716 
1717     template&lt;int datasize&gt;
1718     ALWAYS_INLINE void rorv(RegisterID rd, RegisterID rn, RegisterID rm)
1719     {
1720         CHECK_DATASIZE();
1721         insn(dataProcessing2Source(DATASIZE, rm, DataOp_RORV, rn, rd));
1722     }
1723 
1724     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1725     ALWAYS_INLINE void sbc(RegisterID rd, RegisterID rn, RegisterID rm)
1726     {
1727         CHECK_DATASIZE();
1728         insn(addSubtractWithCarry(DATASIZE, AddOp_SUB, setFlags, rm, rn, rd));
1729     }
1730 
1731     template&lt;int datasize&gt;
1732     ALWAYS_INLINE void sbfiz(RegisterID rd, RegisterID rn, int lsb, int width)
1733     {
1734         sbfm&lt;datasize&gt;(rd, rn, (datasize - lsb) &amp; (datasize - 1), width - 1);
1735     }
1736 
1737     template&lt;int datasize&gt;
1738     ALWAYS_INLINE void sbfm(RegisterID rd, RegisterID rn, int immr, int imms)
1739     {
1740         CHECK_DATASIZE();
1741         insn(bitfield(DATASIZE, BitfieldOp_SBFM, immr, imms, rn, rd));
1742     }
1743 
1744     template&lt;int datasize&gt;
1745     ALWAYS_INLINE void sbfx(RegisterID rd, RegisterID rn, int lsb, int width)
1746     {
1747         sbfm&lt;datasize&gt;(rd, rn, lsb, lsb + width - 1);
1748     }
1749 
1750     template&lt;int datasize&gt;
1751     ALWAYS_INLINE void sdiv(RegisterID rd, RegisterID rn, RegisterID rm)
1752     {
1753         CHECK_DATASIZE();
1754         insn(dataProcessing2Source(DATASIZE, rm, DataOp_SDIV, rn, rd));
1755     }
1756 
1757     ALWAYS_INLINE void smaddl(RegisterID rd, RegisterID rn, RegisterID rm, RegisterID ra)
1758     {
1759         nopCortexA53Fix835769&lt;64&gt;();
1760         insn(dataProcessing3Source(Datasize_64, DataOp_SMADDL, rm, ra, rn, rd));
1761     }
1762 
1763     ALWAYS_INLINE void smnegl(RegisterID rd, RegisterID rn, RegisterID rm)
1764     {
1765         smsubl(rd, rn, rm, ARM64Registers::zr);
1766     }
1767 
1768     ALWAYS_INLINE void smsubl(RegisterID rd, RegisterID rn, RegisterID rm, RegisterID ra)
1769     {
1770         nopCortexA53Fix835769&lt;64&gt;();
1771         insn(dataProcessing3Source(Datasize_64, DataOp_SMSUBL, rm, ra, rn, rd));
1772     }
1773 
1774     ALWAYS_INLINE void smulh(RegisterID rd, RegisterID rn, RegisterID rm)
1775     {
1776         insn(dataProcessing3Source(Datasize_64, DataOp_SMULH, rm, ARM64Registers::zr, rn, rd));
1777     }
1778 
1779     ALWAYS_INLINE void smull(RegisterID rd, RegisterID rn, RegisterID rm)
1780     {
1781         smaddl(rd, rn, rm, ARM64Registers::zr);
1782     }
1783 
1784     template&lt;int datasize&gt;
1785     ALWAYS_INLINE void stp(RegisterID rt, RegisterID rt2, RegisterID rn, PairPostIndex simm)
1786     {
1787         CHECK_DATASIZE();
1788         insn(loadStoreRegisterPairPostIndex(MEMPAIROPSIZE_INT(datasize), false, MemOp_STORE, simm, rn, rt, rt2));
1789     }
1790 
1791     template&lt;int datasize&gt;
1792     ALWAYS_INLINE void stp(RegisterID rt, RegisterID rt2, RegisterID rn, PairPreIndex simm)
1793     {
1794         CHECK_DATASIZE();
1795         insn(loadStoreRegisterPairPreIndex(MEMPAIROPSIZE_INT(datasize), false, MemOp_STORE, simm, rn, rt, rt2));
1796     }
1797 
1798     template&lt;int datasize&gt;
1799     ALWAYS_INLINE void stp(RegisterID rt, RegisterID rt2, RegisterID rn, unsigned pimm = 0)
1800     {
1801         CHECK_DATASIZE();
1802         insn(loadStoreRegisterPairOffset(MEMPAIROPSIZE_INT(datasize), false, MemOp_STORE, pimm, rn, rt, rt2));
1803     }
1804 
1805     template&lt;int datasize&gt;
1806     ALWAYS_INLINE void stnp(RegisterID rt, RegisterID rt2, RegisterID rn, unsigned pimm = 0)
1807     {
1808         CHECK_DATASIZE();
1809         insn(loadStoreRegisterPairNonTemporal(MEMPAIROPSIZE_INT(datasize), false, MemOp_STORE, pimm, rn, rt, rt2));
1810     }
1811 
1812     template&lt;int datasize&gt;
1813     ALWAYS_INLINE void str(RegisterID rt, RegisterID rn, RegisterID rm)
1814     {
1815         str&lt;datasize&gt;(rt, rn, rm, UXTX, 0);
1816     }
1817 
1818     template&lt;int datasize&gt;
1819     ALWAYS_INLINE void str(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1820     {
1821         CHECK_DATASIZE();
1822         insn(loadStoreRegisterRegisterOffset(MEMOPSIZE, false, MemOp_STORE, rm, extend, encodeShiftAmount&lt;datasize&gt;(amount), rn, rt));
1823     }
1824 
1825     template&lt;int datasize&gt;
1826     ALWAYS_INLINE void str(RegisterID rt, RegisterID rn, unsigned pimm)
1827     {
1828         CHECK_DATASIZE();
1829         insn(loadStoreRegisterUnsignedImmediate(MEMOPSIZE, false, MemOp_STORE, encodePositiveImmediate&lt;datasize&gt;(pimm), rn, rt));
1830     }
1831 
1832     template&lt;int datasize&gt;
1833     ALWAYS_INLINE void str(RegisterID rt, RegisterID rn, PostIndex simm)
1834     {
1835         CHECK_DATASIZE();
1836         insn(loadStoreRegisterPostIndex(MEMOPSIZE, false, MemOp_STORE, simm, rn, rt));
1837     }
1838 
1839     template&lt;int datasize&gt;
1840     ALWAYS_INLINE void str(RegisterID rt, RegisterID rn, PreIndex simm)
1841     {
1842         CHECK_DATASIZE();
1843         insn(loadStoreRegisterPreIndex(MEMOPSIZE, false, MemOp_STORE, simm, rn, rt));
1844     }
1845 
1846     ALWAYS_INLINE void strb(RegisterID rt, RegisterID rn, RegisterID rm)
1847     {
1848         // Not calling the 5 argument form of strb, since is amount is ommitted S is false.
1849         insn(loadStoreRegisterRegisterOffset(MemOpSize_8_or_128, false, MemOp_STORE, rm, UXTX, false, rn, rt));
1850     }
1851 
1852     ALWAYS_INLINE void strb(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1853     {
1854         ASSERT_UNUSED(amount, !amount);
1855         insn(loadStoreRegisterRegisterOffset(MemOpSize_8_or_128, false, MemOp_STORE, rm, extend, true, rn, rt));
1856     }
1857 
1858     ALWAYS_INLINE void strb(RegisterID rt, RegisterID rn, unsigned pimm)
1859     {
1860         insn(loadStoreRegisterUnsignedImmediate(MemOpSize_8_or_128, false, MemOp_STORE, encodePositiveImmediate&lt;8&gt;(pimm), rn, rt));
1861     }
1862 
1863     ALWAYS_INLINE void strb(RegisterID rt, RegisterID rn, PostIndex simm)
1864     {
1865         insn(loadStoreRegisterPostIndex(MemOpSize_8_or_128, false, MemOp_STORE, simm, rn, rt));
1866     }
1867 
1868     ALWAYS_INLINE void strb(RegisterID rt, RegisterID rn, PreIndex simm)
1869     {
1870         insn(loadStoreRegisterPreIndex(MemOpSize_8_or_128, false, MemOp_STORE, simm, rn, rt));
1871     }
1872 
1873     ALWAYS_INLINE void strh(RegisterID rt, RegisterID rn, RegisterID rm)
1874     {
1875         strh(rt, rn, rm, UXTX, 0);
1876     }
1877 
1878     ALWAYS_INLINE void strh(RegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1879     {
1880         ASSERT(!amount || amount == 1);
1881         insn(loadStoreRegisterRegisterOffset(MemOpSize_16, false, MemOp_STORE, rm, extend, amount == 1, rn, rt));
1882     }
1883 
1884     ALWAYS_INLINE void strh(RegisterID rt, RegisterID rn, unsigned pimm)
1885     {
1886         insn(loadStoreRegisterUnsignedImmediate(MemOpSize_16, false, MemOp_STORE, encodePositiveImmediate&lt;16&gt;(pimm), rn, rt));
1887     }
1888 
1889     ALWAYS_INLINE void strh(RegisterID rt, RegisterID rn, PostIndex simm)
1890     {
1891         insn(loadStoreRegisterPostIndex(MemOpSize_16, false, MemOp_STORE, simm, rn, rt));
1892     }
1893 
1894     ALWAYS_INLINE void strh(RegisterID rt, RegisterID rn, PreIndex simm)
1895     {
1896         insn(loadStoreRegisterPreIndex(MemOpSize_16, false, MemOp_STORE, simm, rn, rt));
1897     }
1898 
1899     template&lt;int datasize&gt;
1900     ALWAYS_INLINE void stur(RegisterID rt, RegisterID rn, int simm)
1901     {
1902         CHECK_DATASIZE();
1903         insn(loadStoreRegisterUnscaledImmediate(MEMOPSIZE, false, MemOp_STORE, simm, rn, rt));
1904     }
1905 
1906     ALWAYS_INLINE void sturb(RegisterID rt, RegisterID rn, int simm)
1907     {
1908         insn(loadStoreRegisterUnscaledImmediate(MemOpSize_8_or_128, false, MemOp_STORE, simm, rn, rt));
1909     }
1910 
1911     ALWAYS_INLINE void sturh(RegisterID rt, RegisterID rn, int simm)
1912     {
1913         insn(loadStoreRegisterUnscaledImmediate(MemOpSize_16, false, MemOp_STORE, simm, rn, rt));
1914     }
1915 
1916     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1917     ALWAYS_INLINE void sub(RegisterID rd, RegisterID rn, UInt12 imm12, int shift = 0)
1918     {
1919         CHECK_DATASIZE();
1920         ASSERT(!shift || shift == 12);
1921         insn(addSubtractImmediate(DATASIZE, AddOp_SUB, setFlags, shift == 12, imm12, rn, rd));
1922     }
1923 
1924     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1925     ALWAYS_INLINE void sub(RegisterID rd, RegisterID rn, RegisterID rm)
1926     {
1927         ASSERT_WITH_MESSAGE(!isSp(rd) || setFlags == DontSetFlags, &quot;SUBS with shifted register does not support SP for Xd, it uses XZR for the register 31. SUBS with extended register support SP for Xd, but only if SetFlag is not used, otherwise register 31 is Xd.&quot;);
1928         ASSERT_WITH_MESSAGE(!isSp(rm), &quot;No encoding of SUBS supports SP for the third operand.&quot;);
1929 
1930         if (isSp(rd) || isSp(rn))
1931             sub&lt;datasize, setFlags&gt;(rd, rn, rm, UXTX, 0);
1932         else
1933             sub&lt;datasize, setFlags&gt;(rd, rn, rm, LSL, 0);
1934     }
1935 
1936     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1937     ALWAYS_INLINE void sub(RegisterID rd, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
1938     {
1939         CHECK_DATASIZE();
1940         insn(addSubtractExtendedRegister(DATASIZE, AddOp_SUB, setFlags, rm, extend, amount, rn, rd));
1941     }
1942 
1943     template&lt;int datasize, SetFlags setFlags = DontSetFlags&gt;
1944     ALWAYS_INLINE void sub(RegisterID rd, RegisterID rn, RegisterID rm, ShiftType shift, int amount)
1945     {
1946         CHECK_DATASIZE();
1947         ASSERT(!isSp(rd) &amp;&amp; !isSp(rn) &amp;&amp; !isSp(rm));
1948         insn(addSubtractShiftedRegister(DATASIZE, AddOp_SUB, setFlags, shift, rm, amount, rn, rd));
1949     }
1950 
1951     template&lt;int datasize&gt;
1952     ALWAYS_INLINE void sxtb(RegisterID rd, RegisterID rn)
1953     {
1954         sbfm&lt;datasize&gt;(rd, rn, 0, 7);
1955     }
1956 
1957     template&lt;int datasize&gt;
1958     ALWAYS_INLINE void sxth(RegisterID rd, RegisterID rn)
1959     {
1960         sbfm&lt;datasize&gt;(rd, rn, 0, 15);
1961     }
1962 
1963     ALWAYS_INLINE void sxtw(RegisterID rd, RegisterID rn)
1964     {
1965         sbfm&lt;64&gt;(rd, rn, 0, 31);
1966     }
1967 
1968     ALWAYS_INLINE void tbz(RegisterID rt, int imm, int offset = 0)
1969     {
1970         ASSERT(!(offset &amp; 3));
1971         offset &gt;&gt;= 2;
1972         insn(testAndBranchImmediate(false, imm, offset, rt));
1973     }
1974 
1975     ALWAYS_INLINE void tbnz(RegisterID rt, int imm, int offset = 0)
1976     {
1977         ASSERT(!(offset &amp; 3));
1978         offset &gt;&gt;= 2;
1979         insn(testAndBranchImmediate(true, imm, offset, rt));
1980     }
1981 
1982     template&lt;int datasize&gt;
1983     ALWAYS_INLINE void tst(RegisterID rn, RegisterID rm)
1984     {
1985         and_&lt;datasize, S&gt;(ARM64Registers::zr, rn, rm);
1986     }
1987 
1988     template&lt;int datasize&gt;
1989     ALWAYS_INLINE void tst(RegisterID rn, RegisterID rm, ShiftType shift, int amount)
1990     {
1991         and_&lt;datasize, S&gt;(ARM64Registers::zr, rn, rm, shift, amount);
1992     }
1993 
1994     template&lt;int datasize&gt;
1995     ALWAYS_INLINE void tst(RegisterID rn, LogicalImmediate imm)
1996     {
1997         and_&lt;datasize, S&gt;(ARM64Registers::zr, rn, imm);
1998     }
1999 
2000     template&lt;int datasize&gt;
2001     ALWAYS_INLINE void ubfiz(RegisterID rd, RegisterID rn, int lsb, int width)
2002     {
2003         ubfm&lt;datasize&gt;(rd, rn, (datasize - lsb) &amp; (datasize - 1), width - 1);
2004     }
2005 
2006     template&lt;int datasize&gt;
2007     ALWAYS_INLINE void ubfm(RegisterID rd, RegisterID rn, int immr, int imms)
2008     {
2009         CHECK_DATASIZE();
2010         insn(bitfield(DATASIZE, BitfieldOp_UBFM, immr, imms, rn, rd));
2011     }
2012 
2013     template&lt;int datasize&gt;
2014     ALWAYS_INLINE void ubfx(RegisterID rd, RegisterID rn, int lsb, int width)
2015     {
2016         ubfm&lt;datasize&gt;(rd, rn, lsb, lsb + width - 1);
2017     }
2018 
2019     template&lt;int datasize&gt;
2020     ALWAYS_INLINE void udiv(RegisterID rd, RegisterID rn, RegisterID rm)
2021     {
2022         CHECK_DATASIZE();
2023         insn(dataProcessing2Source(DATASIZE, rm, DataOp_UDIV, rn, rd));
2024     }
2025 
2026     ALWAYS_INLINE void umaddl(RegisterID rd, RegisterID rn, RegisterID rm, RegisterID ra)
2027     {
2028         nopCortexA53Fix835769&lt;64&gt;();
2029         insn(dataProcessing3Source(Datasize_64, DataOp_UMADDL, rm, ra, rn, rd));
2030     }
2031 
2032     ALWAYS_INLINE void umnegl(RegisterID rd, RegisterID rn, RegisterID rm)
2033     {
2034         umsubl(rd, rn, rm, ARM64Registers::zr);
2035     }
2036 
2037     ALWAYS_INLINE void umsubl(RegisterID rd, RegisterID rn, RegisterID rm, RegisterID ra)
2038     {
2039         nopCortexA53Fix835769&lt;64&gt;();
2040         insn(dataProcessing3Source(Datasize_64, DataOp_UMSUBL, rm, ra, rn, rd));
2041     }
2042 
2043     ALWAYS_INLINE void umulh(RegisterID rd, RegisterID rn, RegisterID rm)
2044     {
2045         insn(dataProcessing3Source(Datasize_64, DataOp_UMULH, rm, ARM64Registers::zr, rn, rd));
2046     }
2047 
2048     ALWAYS_INLINE void umull(RegisterID rd, RegisterID rn, RegisterID rm)
2049     {
2050         umaddl(rd, rn, rm, ARM64Registers::zr);
2051     }
2052 
2053     template&lt;int datasize&gt;
2054     ALWAYS_INLINE void uxtb(RegisterID rd, RegisterID rn)
2055     {
2056         ubfm&lt;datasize&gt;(rd, rn, 0, 7);
2057     }
2058 
2059     template&lt;int datasize&gt;
2060     ALWAYS_INLINE void uxth(RegisterID rd, RegisterID rn)
2061     {
2062         ubfm&lt;datasize&gt;(rd, rn, 0, 15);
2063     }
2064 
2065     ALWAYS_INLINE void uxtw(RegisterID rd, RegisterID rn)
2066     {
2067         ubfm&lt;64&gt;(rd, rn, 0, 31);
2068     }
2069 
2070     // Floating Point Instructions:
2071 
2072     template&lt;int datasize&gt;
2073     ALWAYS_INLINE void fabs(FPRegisterID vd, FPRegisterID vn)
2074     {
2075         CHECK_DATASIZE();
2076         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FABS, vn, vd));
2077     }
2078 
2079     template&lt;int datasize&gt;
2080     ALWAYS_INLINE void fadd(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2081     {
2082         CHECK_DATASIZE();
2083         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FADD, vn, vd));
2084     }
2085 
2086     template&lt;int datasize&gt;
2087     ALWAYS_INLINE void fccmp(FPRegisterID vn, FPRegisterID vm, int nzcv, Condition cond)
2088     {
2089         CHECK_DATASIZE();
2090         insn(floatingPointConditionalCompare(DATASIZE, vm, cond, vn, FPCondCmpOp_FCMP, nzcv));
2091     }
2092 
2093     template&lt;int datasize&gt;
2094     ALWAYS_INLINE void fccmpe(FPRegisterID vn, FPRegisterID vm, int nzcv, Condition cond)
2095     {
2096         CHECK_DATASIZE();
2097         insn(floatingPointConditionalCompare(DATASIZE, vm, cond, vn, FPCondCmpOp_FCMPE, nzcv));
2098     }
2099 
2100     template&lt;int datasize&gt;
2101     ALWAYS_INLINE void fcmp(FPRegisterID vn, FPRegisterID vm)
2102     {
2103         CHECK_DATASIZE();
2104         insn(floatingPointCompare(DATASIZE, vm, vn, FPCmpOp_FCMP));
2105     }
2106 
2107     template&lt;int datasize&gt;
2108     ALWAYS_INLINE void fcmp_0(FPRegisterID vn)
2109     {
2110         CHECK_DATASIZE();
2111         insn(floatingPointCompare(DATASIZE, static_cast&lt;FPRegisterID&gt;(0), vn, FPCmpOp_FCMP0));
2112     }
2113 
2114     template&lt;int datasize&gt;
2115     ALWAYS_INLINE void fcmpe(FPRegisterID vn, FPRegisterID vm)
2116     {
2117         CHECK_DATASIZE();
2118         insn(floatingPointCompare(DATASIZE, vm, vn, FPCmpOp_FCMPE));
2119     }
2120 
2121     template&lt;int datasize&gt;
2122     ALWAYS_INLINE void fcmpe_0(FPRegisterID vn)
2123     {
2124         CHECK_DATASIZE();
2125         insn(floatingPointCompare(DATASIZE, static_cast&lt;FPRegisterID&gt;(0), vn, FPCmpOp_FCMPE0));
2126     }
2127 
2128     template&lt;int datasize&gt;
2129     ALWAYS_INLINE void fcsel(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm, Condition cond)
2130     {
2131         CHECK_DATASIZE();
2132         insn(floatingPointConditionalSelect(DATASIZE, vm, cond, vn, vd));
2133     }
2134 
2135     template&lt;int dstsize, int srcsize&gt;
2136     ALWAYS_INLINE void fcvt(FPRegisterID vd, FPRegisterID vn)
2137     {
2138         ASSERT(dstsize == 16 || dstsize == 32 || dstsize == 64);
2139         ASSERT(srcsize == 16 || srcsize == 32 || srcsize == 64);
2140         ASSERT(dstsize != srcsize);
2141         Datasize type = (srcsize == 64) ? Datasize_64 : (srcsize == 32) ? Datasize_32 : Datasize_16;
2142         FPDataOp1Source opcode = (dstsize == 64) ? FPDataOp_FCVT_toDouble : (dstsize == 32) ? FPDataOp_FCVT_toSingle : FPDataOp_FCVT_toHalf;
2143         insn(floatingPointDataProcessing1Source(type, opcode, vn, vd));
2144     }
2145 
2146     template&lt;int dstsize, int srcsize&gt;
2147     ALWAYS_INLINE void fcvtas(RegisterID rd, FPRegisterID vn)
2148     {
2149         CHECK_DATASIZE_OF(dstsize);
2150         CHECK_DATASIZE_OF(srcsize);
2151         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTAS, vn, rd));
2152     }
2153 
2154     template&lt;int dstsize, int srcsize&gt;
2155     ALWAYS_INLINE void fcvtau(RegisterID rd, FPRegisterID vn)
2156     {
2157         CHECK_DATASIZE_OF(dstsize);
2158         CHECK_DATASIZE_OF(srcsize);
2159         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTAU, vn, rd));
2160     }
2161 
2162     template&lt;int dstsize, int srcsize&gt;
2163     ALWAYS_INLINE void fcvtms(RegisterID rd, FPRegisterID vn)
2164     {
2165         CHECK_DATASIZE_OF(dstsize);
2166         CHECK_DATASIZE_OF(srcsize);
2167         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTMS, vn, rd));
2168     }
2169 
2170     template&lt;int dstsize, int srcsize&gt;
2171     ALWAYS_INLINE void fcvtmu(RegisterID rd, FPRegisterID vn)
2172     {
2173         CHECK_DATASIZE_OF(dstsize);
2174         CHECK_DATASIZE_OF(srcsize);
2175         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTMU, vn, rd));
2176     }
2177 
2178     template&lt;int dstsize, int srcsize&gt;
2179     ALWAYS_INLINE void fcvtns(RegisterID rd, FPRegisterID vn)
2180     {
2181         CHECK_DATASIZE_OF(dstsize);
2182         CHECK_DATASIZE_OF(srcsize);
2183         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTNS, vn, rd));
2184     }
2185 
2186     template&lt;int dstsize, int srcsize&gt;
2187     ALWAYS_INLINE void fcvtnu(RegisterID rd, FPRegisterID vn)
2188     {
2189         CHECK_DATASIZE_OF(dstsize);
2190         CHECK_DATASIZE_OF(srcsize);
2191         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTNU, vn, rd));
2192     }
2193 
2194     template&lt;int dstsize, int srcsize&gt;
2195     ALWAYS_INLINE void fcvtps(RegisterID rd, FPRegisterID vn)
2196     {
2197         CHECK_DATASIZE_OF(dstsize);
2198         CHECK_DATASIZE_OF(srcsize);
2199         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTPS, vn, rd));
2200     }
2201 
2202     template&lt;int dstsize, int srcsize&gt;
2203     ALWAYS_INLINE void fcvtpu(RegisterID rd, FPRegisterID vn)
2204     {
2205         CHECK_DATASIZE_OF(dstsize);
2206         CHECK_DATASIZE_OF(srcsize);
2207         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTPU, vn, rd));
2208     }
2209 
2210     template&lt;int dstsize, int srcsize&gt;
2211     ALWAYS_INLINE void fcvtzs(RegisterID rd, FPRegisterID vn)
2212     {
2213         CHECK_DATASIZE_OF(dstsize);
2214         CHECK_DATASIZE_OF(srcsize);
2215         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTZS, vn, rd));
2216     }
2217 
2218     template&lt;int dstsize, int srcsize&gt;
2219     ALWAYS_INLINE void fcvtzu(RegisterID rd, FPRegisterID vn)
2220     {
2221         CHECK_DATASIZE_OF(dstsize);
2222         CHECK_DATASIZE_OF(srcsize);
2223         insn(floatingPointIntegerConversions(DATASIZE_OF(dstsize), DATASIZE_OF(srcsize), FPIntConvOp_FCVTZU, vn, rd));
2224     }
2225 
2226     template&lt;int datasize&gt;
2227     ALWAYS_INLINE void fdiv(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2228     {
2229         CHECK_DATASIZE();
2230         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FDIV, vn, vd));
2231     }
2232 
2233     template&lt;int datasize&gt;
2234     ALWAYS_INLINE void fmadd(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm, FPRegisterID va)
2235     {
2236         CHECK_DATASIZE();
2237         insn(floatingPointDataProcessing3Source(DATASIZE, false, vm, AddOp_ADD, va, vn, vd));
2238     }
2239 
2240     template&lt;int datasize&gt;
2241     ALWAYS_INLINE void fmax(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2242     {
2243         CHECK_DATASIZE();
2244         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FMAX, vn, vd));
2245     }
2246 
2247     template&lt;int datasize&gt;
2248     ALWAYS_INLINE void fmaxnm(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2249     {
2250         CHECK_DATASIZE();
2251         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FMAXNM, vn, vd));
2252     }
2253 
2254     template&lt;int datasize&gt;
2255     ALWAYS_INLINE void fmin(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2256     {
2257         CHECK_DATASIZE();
2258         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FMIN, vn, vd));
2259     }
2260 
2261     template&lt;int datasize&gt;
2262     ALWAYS_INLINE void fminnm(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2263     {
2264         CHECK_DATASIZE();
2265         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FMINNM, vn, vd));
2266     }
2267 
2268     template&lt;int datasize&gt;
2269     ALWAYS_INLINE void fmov(FPRegisterID vd, FPRegisterID vn)
2270     {
2271         CHECK_DATASIZE();
2272         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FMOV, vn, vd));
2273     }
2274 
2275     template&lt;int datasize&gt;
2276     ALWAYS_INLINE void fmov(FPRegisterID vd, RegisterID rn)
2277     {
2278         CHECK_DATASIZE();
2279         insn(floatingPointIntegerConversions(DATASIZE, DATASIZE, FPIntConvOp_FMOV_XtoQ, rn, vd));
2280     }
2281 
2282     template&lt;int datasize&gt;
2283     ALWAYS_INLINE void fmov(RegisterID rd, FPRegisterID vn)
2284     {
2285         CHECK_DATASIZE();
2286         insn(floatingPointIntegerConversions(DATASIZE, DATASIZE, FPIntConvOp_FMOV_QtoX, vn, rd));
2287     }
2288 
2289     template&lt;int datasize&gt;
2290     ALWAYS_INLINE void fmov(FPRegisterID vd, double imm)
2291     {
2292         CHECK_DATASIZE();
2293         insn(floatingPointImmediate(DATASIZE, encodeFPImm(imm), vd));
2294     }
2295 
2296     ALWAYS_INLINE void fmov_top(FPRegisterID vd, RegisterID rn)
2297     {
2298         insn(floatingPointIntegerConversions(Datasize_64, Datasize_64, FPIntConvOp_FMOV_XtoQ_top, rn, vd));
2299     }
2300 
2301     ALWAYS_INLINE void fmov_top(RegisterID rd, FPRegisterID vn)
2302     {
2303         insn(floatingPointIntegerConversions(Datasize_64, Datasize_64, FPIntConvOp_FMOV_QtoX_top, vn, rd));
2304     }
2305 
2306     template&lt;int datasize&gt;
2307     ALWAYS_INLINE void fmsub(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm, FPRegisterID va)
2308     {
2309         CHECK_DATASIZE();
2310         insn(floatingPointDataProcessing3Source(DATASIZE, false, vm, AddOp_SUB, va, vn, vd));
2311     }
2312 
2313     template&lt;int datasize&gt;
2314     ALWAYS_INLINE void fmul(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2315     {
2316         CHECK_DATASIZE();
2317         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FMUL, vn, vd));
2318     }
2319 
2320     template&lt;int datasize&gt;
2321     ALWAYS_INLINE void fneg(FPRegisterID vd, FPRegisterID vn)
2322     {
2323         CHECK_DATASIZE();
2324         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FNEG, vn, vd));
2325     }
2326 
2327     template&lt;int datasize&gt;
2328     ALWAYS_INLINE void fnmadd(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm, FPRegisterID va)
2329     {
2330         CHECK_DATASIZE();
2331         insn(floatingPointDataProcessing3Source(DATASIZE, true, vm, AddOp_ADD, va, vn, vd));
2332     }
2333 
2334     template&lt;int datasize&gt;
2335     ALWAYS_INLINE void fnmsub(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm, FPRegisterID va)
2336     {
2337         CHECK_DATASIZE();
2338         insn(floatingPointDataProcessing3Source(DATASIZE, true, vm, AddOp_SUB, va, vn, vd));
2339     }
2340 
2341     template&lt;int datasize&gt;
2342     ALWAYS_INLINE void fnmul(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2343     {
2344         CHECK_DATASIZE();
2345         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FNMUL, vn, vd));
2346     }
2347 
2348     template&lt;int datasize&gt;
2349     ALWAYS_INLINE void vand(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2350     {
2351         CHECK_VECTOR_DATASIZE();
2352         insn(vectorDataProcessingLogical(SIMD_LogicalOp_AND, vm, vn, vd));
2353     }
2354 
2355     template&lt;int datasize&gt;
2356     ALWAYS_INLINE void vorr(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2357     {
2358         CHECK_VECTOR_DATASIZE();
2359         insn(vectorDataProcessingLogical(SIMD_LogicalOp_ORR, vm, vn, vd));
2360     }
2361 
2362     template&lt;int datasize&gt;
2363     ALWAYS_INLINE void frinta(FPRegisterID vd, FPRegisterID vn)
2364     {
2365         CHECK_DATASIZE();
2366         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FRINTA, vn, vd));
2367     }
2368 
2369     template&lt;int datasize&gt;
2370     ALWAYS_INLINE void frinti(FPRegisterID vd, FPRegisterID vn)
2371     {
2372         CHECK_DATASIZE();
2373         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FRINTI, vn, vd));
2374     }
2375 
2376     template&lt;int datasize&gt;
2377     ALWAYS_INLINE void frintm(FPRegisterID vd, FPRegisterID vn)
2378     {
2379         CHECK_DATASIZE();
2380         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FRINTM, vn, vd));
2381     }
2382 
2383     template&lt;int datasize&gt;
2384     ALWAYS_INLINE void frintn(FPRegisterID vd, FPRegisterID vn)
2385     {
2386         CHECK_DATASIZE();
2387         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FRINTN, vn, vd));
2388     }
2389 
2390     template&lt;int datasize&gt;
2391     ALWAYS_INLINE void frintp(FPRegisterID vd, FPRegisterID vn)
2392     {
2393         CHECK_DATASIZE();
2394         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FRINTP, vn, vd));
2395     }
2396 
2397     template&lt;int datasize&gt;
2398     ALWAYS_INLINE void frintx(FPRegisterID vd, FPRegisterID vn)
2399     {
2400         CHECK_DATASIZE();
2401         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FRINTX, vn, vd));
2402     }
2403 
2404     template&lt;int datasize&gt;
2405     ALWAYS_INLINE void frintz(FPRegisterID vd, FPRegisterID vn)
2406     {
2407         CHECK_DATASIZE();
2408         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FRINTZ, vn, vd));
2409     }
2410 
2411     template&lt;int datasize&gt;
2412     ALWAYS_INLINE void fsqrt(FPRegisterID vd, FPRegisterID vn)
2413     {
2414         CHECK_DATASIZE();
2415         insn(floatingPointDataProcessing1Source(DATASIZE, FPDataOp_FSQRT, vn, vd));
2416     }
2417 
2418     template&lt;int datasize&gt;
2419     ALWAYS_INLINE void fsub(FPRegisterID vd, FPRegisterID vn, FPRegisterID vm)
2420     {
2421         CHECK_DATASIZE();
2422         insn(floatingPointDataProcessing2Source(DATASIZE, vm, FPDataOp_FSUB, vn, vd));
2423     }
2424 
2425     template&lt;int datasize&gt;
2426     ALWAYS_INLINE void ldr(FPRegisterID rt, RegisterID rn, RegisterID rm)
2427     {
2428         ldr&lt;datasize&gt;(rt, rn, rm, UXTX, 0);
2429     }
2430 
2431     template&lt;int datasize&gt;
2432     ALWAYS_INLINE void ldr(FPRegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
2433     {
2434         CHECK_FP_MEMOP_DATASIZE();
2435         insn(loadStoreRegisterRegisterOffset(MEMOPSIZE, true, datasize == 128 ? MemOp_LOAD_V128 : MemOp_LOAD, rm, extend, encodeShiftAmount&lt;datasize&gt;(amount), rn, rt));
2436     }
2437 
2438     template&lt;int datasize&gt;
2439     ALWAYS_INLINE void ldr(FPRegisterID rt, RegisterID rn, unsigned pimm)
2440     {
2441         CHECK_FP_MEMOP_DATASIZE();
2442         insn(loadStoreRegisterUnsignedImmediate(MEMOPSIZE, true, datasize == 128 ? MemOp_LOAD_V128 : MemOp_LOAD, encodePositiveImmediate&lt;datasize&gt;(pimm), rn, rt));
2443     }
2444 
2445     template&lt;int datasize&gt;
2446     ALWAYS_INLINE void ldr(FPRegisterID rt, RegisterID rn, PostIndex simm)
2447     {
2448         CHECK_FP_MEMOP_DATASIZE();
2449         insn(loadStoreRegisterPostIndex(MEMOPSIZE, true, datasize == 128 ? MemOp_LOAD_V128 : MemOp_LOAD, simm, rn, rt));
2450     }
2451 
2452     template&lt;int datasize&gt;
2453     ALWAYS_INLINE void ldr(FPRegisterID rt, RegisterID rn, PreIndex simm)
2454     {
2455         CHECK_FP_MEMOP_DATASIZE();
2456         insn(loadStoreRegisterPreIndex(MEMOPSIZE, true, datasize == 128 ? MemOp_LOAD_V128 : MemOp_LOAD, simm, rn, rt));
2457     }
2458 
2459     template&lt;int datasize&gt;
2460     ALWAYS_INLINE void ldr_literal(FPRegisterID rt, int offset = 0)
2461     {
2462         CHECK_FP_MEMOP_DATASIZE();
2463         ASSERT(datasize &gt;= 32);
2464         ASSERT(!(offset &amp; 3));
2465         insn(loadRegisterLiteral(datasize == 128 ? LdrLiteralOp_128BIT : datasize == 64 ? LdrLiteralOp_64BIT : LdrLiteralOp_32BIT, true, offset &gt;&gt; 2, rt));
2466     }
2467 
2468     template&lt;int datasize&gt;
2469     ALWAYS_INLINE void ldur(FPRegisterID rt, RegisterID rn, int simm)
2470     {
2471         CHECK_FP_MEMOP_DATASIZE();
2472         insn(loadStoreRegisterUnscaledImmediate(MEMOPSIZE, true, datasize == 128 ? MemOp_LOAD_V128 : MemOp_LOAD, simm, rn, rt));
2473     }
2474 
2475     template&lt;int dstsize, int srcsize&gt;
2476     ALWAYS_INLINE void scvtf(FPRegisterID vd, RegisterID rn)
2477     {
2478         CHECK_DATASIZE_OF(dstsize);
2479         CHECK_DATASIZE_OF(srcsize);
2480         insn(floatingPointIntegerConversions(DATASIZE_OF(srcsize), DATASIZE_OF(dstsize), FPIntConvOp_SCVTF, rn, vd));
2481     }
2482 
2483     template&lt;int datasize&gt;
2484     ALWAYS_INLINE void str(FPRegisterID rt, RegisterID rn, RegisterID rm)
2485     {
2486         str&lt;datasize&gt;(rt, rn, rm, UXTX, 0);
2487     }
2488 
2489     template&lt;int datasize&gt;
2490     ALWAYS_INLINE void str(FPRegisterID rt, RegisterID rn, RegisterID rm, ExtendType extend, int amount)
2491     {
2492         CHECK_FP_MEMOP_DATASIZE();
2493         insn(loadStoreRegisterRegisterOffset(MEMOPSIZE, true, datasize == 128 ? MemOp_STORE_V128 : MemOp_STORE, rm, extend, encodeShiftAmount&lt;datasize&gt;(amount), rn, rt));
2494     }
2495 
2496     template&lt;int datasize&gt;
2497     ALWAYS_INLINE void str(FPRegisterID rt, RegisterID rn, unsigned pimm)
2498     {
2499         CHECK_FP_MEMOP_DATASIZE();
2500         insn(loadStoreRegisterUnsignedImmediate(MEMOPSIZE, true, datasize == 128 ? MemOp_STORE_V128 : MemOp_STORE, encodePositiveImmediate&lt;datasize&gt;(pimm), rn, rt));
2501     }
2502 
2503     template&lt;int datasize&gt;
2504     ALWAYS_INLINE void str(FPRegisterID rt, RegisterID rn, PostIndex simm)
2505     {
2506         CHECK_FP_MEMOP_DATASIZE();
2507         insn(loadStoreRegisterPostIndex(MEMOPSIZE, true, datasize == 128 ? MemOp_STORE_V128 : MemOp_STORE, simm, rn, rt));
2508     }
2509 
2510     template&lt;int datasize&gt;
2511     ALWAYS_INLINE void str(FPRegisterID rt, RegisterID rn, PreIndex simm)
2512     {
2513         CHECK_FP_MEMOP_DATASIZE();
2514         insn(loadStoreRegisterPreIndex(MEMOPSIZE, true, datasize == 128 ? MemOp_STORE_V128 : MemOp_STORE, simm, rn, rt));
2515     }
2516 
2517     template&lt;int datasize&gt;
2518     ALWAYS_INLINE void stur(FPRegisterID rt, RegisterID rn, int simm)
2519     {
2520         CHECK_DATASIZE();
2521         insn(loadStoreRegisterUnscaledImmediate(MEMOPSIZE, true, datasize == 128 ? MemOp_STORE_V128 : MemOp_STORE, simm, rn, rt));
2522     }
2523 
2524     template&lt;int dstsize, int srcsize&gt;
2525     ALWAYS_INLINE void ucvtf(FPRegisterID vd, RegisterID rn)
2526     {
2527         CHECK_DATASIZE_OF(dstsize);
2528         CHECK_DATASIZE_OF(srcsize);
2529         insn(floatingPointIntegerConversions(DATASIZE_OF(srcsize), DATASIZE_OF(dstsize), FPIntConvOp_UCVTF, rn, vd));
2530     }
2531 
2532     ALWAYS_INLINE void fjcvtzs(RegisterID rd, FPRegisterID dn)
2533     {
2534         insn(fjcvtzsInsn(dn, rd));
2535     }
2536 
2537     // Admin methods:
2538 
2539     AssemblerLabel labelIgnoringWatchpoints()
2540     {
2541         return m_buffer.label();
2542     }
2543 
2544     AssemblerLabel labelForWatchpoint()
2545     {
2546         AssemblerLabel result = m_buffer.label();
2547         if (static_cast&lt;int&gt;(result.m_offset) != m_indexOfLastWatchpoint)
2548             result = label();
2549         m_indexOfLastWatchpoint = result.m_offset;
2550         m_indexOfTailOfLastWatchpoint = result.m_offset + maxJumpReplacementSize();
2551         return result;
2552     }
2553 
2554     AssemblerLabel label()
2555     {
2556         AssemblerLabel result = m_buffer.label();
2557         while (UNLIKELY(static_cast&lt;int&gt;(result.m_offset) &lt; m_indexOfTailOfLastWatchpoint)) {
2558             nop();
2559             result = m_buffer.label();
2560         }
2561         return result;
2562     }
2563 
2564     AssemblerLabel align(int alignment)
2565     {
2566         ASSERT(!(alignment &amp; 3));
2567         while (!m_buffer.isAligned(alignment))
2568             brk(0);
2569         return label();
2570     }
2571 
2572     static void* getRelocatedAddress(void* code, AssemblerLabel label)
2573     {
2574         ASSERT(label.isSet());
2575         return reinterpret_cast&lt;void*&gt;(reinterpret_cast&lt;ptrdiff_t&gt;(code) + label.m_offset);
2576     }
2577 
2578     static int getDifferenceBetweenLabels(AssemblerLabel a, AssemblerLabel b)
2579     {
2580         return b.m_offset - a.m_offset;
2581     }
2582 
2583     size_t codeSize() const { return m_buffer.codeSize(); }
2584 
2585     static unsigned getCallReturnOffset(AssemblerLabel call)
2586     {
2587         ASSERT(call.isSet());
2588         return call.m_offset;
2589     }
2590 
2591     // Linking &amp; patching:
2592     //
2593     // &#39;link&#39; and &#39;patch&#39; methods are for use on unprotected code - such as the code
2594     // within the AssemblerBuffer, and code being patched by the patch buffer. Once
2595     // code has been finalized it is (platform support permitting) within a non-
2596     // writable region of memory; to modify the code in an execute-only execuable
2597     // pool the &#39;repatch&#39; and &#39;relink&#39; methods should be used.
2598 
2599     void linkJump(AssemblerLabel from, AssemblerLabel to, JumpType type, Condition condition)
2600     {
2601         ASSERT(to.isSet());
2602         ASSERT(from.isSet());
2603         m_jumpsToLink.append(LinkRecord(from.m_offset, to.m_offset, type, condition));
2604     }
2605 
2606     void linkJump(AssemblerLabel from, AssemblerLabel to, JumpType type, Condition condition, bool is64Bit, RegisterID compareRegister)
2607     {
2608         ASSERT(to.isSet());
2609         ASSERT(from.isSet());
2610         m_jumpsToLink.append(LinkRecord(from.m_offset, to.m_offset, type, condition, is64Bit, compareRegister));
2611     }
2612 
2613     void linkJump(AssemblerLabel from, AssemblerLabel to, JumpType type, Condition condition, unsigned bitNumber, RegisterID compareRegister)
2614     {
2615         ASSERT(to.isSet());
2616         ASSERT(from.isSet());
2617         m_jumpsToLink.append(LinkRecord(from.m_offset, to.m_offset, type, condition, bitNumber, compareRegister));
2618     }
2619 
2620     static void linkJump(void* code, AssemblerLabel from, void* to)
2621     {
2622         ASSERT(from.isSet());
2623         relinkJumpOrCall&lt;false&gt;(addressOf(code, from), addressOf(code, from), to);
2624     }
2625 
2626     static void linkCall(void* code, AssemblerLabel from, void* to)
2627     {
2628         ASSERT(from.isSet());
2629         linkJumpOrCall&lt;true&gt;(addressOf(code, from) - 1, addressOf(code, from) - 1, to);
2630     }
2631 
2632     static void linkPointer(void* code, AssemblerLabel where, void* valuePtr)
2633     {
2634         linkPointer(addressOf(code, where), valuePtr);
2635     }
2636 
2637     static void replaceWithVMHalt(void* where)
2638     {
2639         // This should try to write to null which should always Segfault.
2640         int insn = dataCacheZeroVirtualAddress(ARM64Registers::zr);
2641         RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(where) == where);
2642         performJITMemcpy(where, &amp;insn, sizeof(int));
2643         cacheFlush(where, sizeof(int));
2644     }
2645 
2646     static void replaceWithJump(void* where, void* to)
2647     {
2648         intptr_t offset = (reinterpret_cast&lt;intptr_t&gt;(to) - reinterpret_cast&lt;intptr_t&gt;(where)) &gt;&gt; 2;
2649         ASSERT(static_cast&lt;int&gt;(offset) == offset);
2650         int insn = unconditionalBranchImmediate(false, static_cast&lt;int&gt;(offset));
2651         RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(where) == where);
2652         performJITMemcpy(where, &amp;insn, sizeof(int));
2653         cacheFlush(where, sizeof(int));
2654     }
2655 
2656     static ptrdiff_t maxJumpReplacementSize()
2657     {
2658         return 4;
2659     }
2660 
2661     static constexpr ptrdiff_t patchableJumpSize()
2662     {
2663         return 4;
2664     }
2665 
2666     static void replaceWithLoad(void* where)
2667     {
2668         Datasize sf;
2669         AddOp op;
2670         SetFlags S;
2671         int shift;
2672         int imm12;
2673         RegisterID rn;
2674         RegisterID rd;
2675         if (disassembleAddSubtractImmediate(where, sf, op, S, shift, imm12, rn, rd)) {
2676             ASSERT(sf == Datasize_64);
2677             ASSERT(op == AddOp_ADD);
2678             ASSERT(!S);
2679             ASSERT(!shift);
2680             ASSERT(!(imm12 &amp; ~0xff8));
2681             int insn = loadStoreRegisterUnsignedImmediate(MemOpSize_64, false, MemOp_LOAD, encodePositiveImmediate&lt;64&gt;(imm12), rn, rd);
2682             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(where) == where);
2683             performJITMemcpy(where, &amp;insn, sizeof(int));
2684             cacheFlush(where, sizeof(int));
2685         }
2686 #if !ASSERT_DISABLED
2687         else {
2688             MemOpSize size;
2689             bool V;
2690             MemOp opc;
2691             int imm12;
2692             RegisterID rn;
2693             RegisterID rt;
2694             ASSERT(disassembleLoadStoreRegisterUnsignedImmediate(where, size, V, opc, imm12, rn, rt));
2695             ASSERT(size == MemOpSize_64);
2696             ASSERT(!V);
2697             ASSERT(opc == MemOp_LOAD);
2698             ASSERT(!(imm12 &amp; ~0x1ff));
2699         }
2700 #endif
2701     }
2702 
2703     static void replaceWithAddressComputation(void* where)
2704     {
2705         MemOpSize size;
2706         bool V;
2707         MemOp opc;
2708         int imm12;
2709         RegisterID rn;
2710         RegisterID rt;
2711         if (disassembleLoadStoreRegisterUnsignedImmediate(where, size, V, opc, imm12, rn, rt)) {
2712             ASSERT(size == MemOpSize_64);
2713             ASSERT(!V);
2714             ASSERT(opc == MemOp_LOAD);
2715             ASSERT(!(imm12 &amp; ~0x1ff));
2716             int insn = addSubtractImmediate(Datasize_64, AddOp_ADD, DontSetFlags, 0, imm12 * sizeof(void*), rn, rt);
2717             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(where) == where);
2718             performJITMemcpy(where, &amp;insn, sizeof(int));
2719             cacheFlush(where, sizeof(int));
2720         }
2721 #if !ASSERT_DISABLED
2722         else {
2723             Datasize sf;
2724             AddOp op;
2725             SetFlags S;
2726             int shift;
2727             int imm12;
2728             RegisterID rn;
2729             RegisterID rd;
2730             ASSERT(disassembleAddSubtractImmediate(where, sf, op, S, shift, imm12, rn, rd));
2731             ASSERT(sf == Datasize_64);
2732             ASSERT(op == AddOp_ADD);
2733             ASSERT(!S);
2734             ASSERT(!shift);
2735             ASSERT(!(imm12 &amp; ~0xff8));
2736         }
2737 #endif
2738     }
2739 
2740     static void repatchPointer(void* where, void* valuePtr)
2741     {
2742         linkPointer(static_cast&lt;int*&gt;(where), valuePtr, true);
2743     }
2744 
2745     static void setPointer(int* address, void* valuePtr, RegisterID rd, bool flush)
2746     {
2747         uintptr_t value = reinterpret_cast&lt;uintptr_t&gt;(valuePtr);
2748         int buffer[3];
2749         buffer[0] = moveWideImediate(Datasize_64, MoveWideOp_Z, 0, getHalfword(value, 0), rd);
2750         buffer[1] = moveWideImediate(Datasize_64, MoveWideOp_K, 1, getHalfword(value, 1), rd);
2751         buffer[2] = moveWideImediate(Datasize_64, MoveWideOp_K, 2, getHalfword(value, 2), rd);
2752         RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(address) == address);
2753         performJITMemcpy(address, buffer, sizeof(int) * 3);
2754 
2755         if (flush)
2756             cacheFlush(address, sizeof(int) * 3);
2757     }
2758 
2759     static void repatchInt32(void* where, int32_t value)
2760     {
2761         int* address = static_cast&lt;int*&gt;(where);
2762 
2763         Datasize sf;
2764         MoveWideOp opc;
2765         int hw;
2766         uint16_t imm16;
2767         RegisterID rd;
2768         bool expected = disassembleMoveWideImediate(address, sf, opc, hw, imm16, rd);
2769         ASSERT_UNUSED(expected, expected &amp;&amp; !sf &amp;&amp; (opc == MoveWideOp_Z || opc == MoveWideOp_N) &amp;&amp; !hw);
2770         ASSERT(checkMovk&lt;Datasize_32&gt;(address[1], 1, rd));
2771 
2772         int buffer[2];
2773         if (value &gt;= 0) {
2774             buffer[0] = moveWideImediate(Datasize_32, MoveWideOp_Z, 0, getHalfword(value, 0), rd);
2775             buffer[1] = moveWideImediate(Datasize_32, MoveWideOp_K, 1, getHalfword(value, 1), rd);
2776         } else {
2777             buffer[0] = moveWideImediate(Datasize_32, MoveWideOp_N, 0, ~getHalfword(value, 0), rd);
2778             buffer[1] = moveWideImediate(Datasize_32, MoveWideOp_K, 1, getHalfword(value, 1), rd);
2779         }
2780         RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(where) == where);
2781         performJITMemcpy(where, &amp;buffer, sizeof(int) * 2);
2782 
2783         cacheFlush(where, sizeof(int) * 2);
2784     }
2785 
2786     static void* readPointer(void* where)
2787     {
2788         int* address = static_cast&lt;int*&gt;(where);
2789 
2790         Datasize sf;
2791         MoveWideOp opc;
2792         int hw;
2793         uint16_t imm16;
2794         RegisterID rdFirst, rd;
2795 
2796         bool expected = disassembleMoveWideImediate(address, sf, opc, hw, imm16, rdFirst);
2797         ASSERT_UNUSED(expected, expected &amp;&amp; sf &amp;&amp; opc == MoveWideOp_Z &amp;&amp; !hw);
2798         uintptr_t result = imm16;
2799 
2800         expected = disassembleMoveWideImediate(address + 1, sf, opc, hw, imm16, rd);
2801         ASSERT_UNUSED(expected, expected &amp;&amp; sf &amp;&amp; opc == MoveWideOp_K &amp;&amp; hw == 1 &amp;&amp; rd == rdFirst);
2802         result |= static_cast&lt;uintptr_t&gt;(imm16) &lt;&lt; 16;
2803 
2804 #if CPU(ADDRESS64)
2805         expected = disassembleMoveWideImediate(address + 2, sf, opc, hw, imm16, rd);
2806         ASSERT_UNUSED(expected, expected &amp;&amp; sf &amp;&amp; opc == MoveWideOp_K &amp;&amp; hw == 2 &amp;&amp; rd == rdFirst);
2807         result |= static_cast&lt;uintptr_t&gt;(imm16) &lt;&lt; 32;
2808 #endif
2809 
2810         return reinterpret_cast&lt;void*&gt;(result);
2811     }
2812 
2813     static void* readCallTarget(void* from)
2814     {
2815         return readPointer(reinterpret_cast&lt;int*&gt;(from) - (isAddress64Bit() ? 4 : 3));
2816     }
2817 
2818     // The static relink, repatch, and replace methods can use can
2819     // use |from| for both the write and executable address for call
2820     // and jump patching as they&#39;re modifying existing (linked) code,
2821     // so the address being provided is correct for relative address
2822     // computation.
2823     static void relinkJump(void* from, void* to)
2824     {
2825         relinkJumpOrCall&lt;false&gt;(reinterpret_cast&lt;int*&gt;(from), reinterpret_cast&lt;const int*&gt;(from), to);
2826         cacheFlush(from, sizeof(int));
2827     }
2828 
2829     static void relinkJumpToNop(void* from)
2830     {
2831         relinkJump(from, static_cast&lt;char*&gt;(from) + 4);
2832     }
2833 
2834     static void relinkCall(void* from, void* to)
2835     {
2836         relinkJumpOrCall&lt;true&gt;(reinterpret_cast&lt;int*&gt;(from) - 1, reinterpret_cast&lt;const int*&gt;(from) - 1, to);
2837         cacheFlush(reinterpret_cast&lt;int*&gt;(from) - 1, sizeof(int));
2838     }
2839 
2840     static void repatchCompact(void* where, int32_t value)
2841     {
2842         ASSERT(!(value &amp; ~0x3ff8));
2843 
2844         MemOpSize size;
2845         bool V;
2846         MemOp opc;
2847         int imm12;
2848         RegisterID rn;
2849         RegisterID rt;
2850         bool expected = disassembleLoadStoreRegisterUnsignedImmediate(where, size, V, opc, imm12, rn, rt);
2851         ASSERT_UNUSED(expected, expected &amp;&amp; size &gt;= MemOpSize_32 &amp;&amp; !V &amp;&amp; opc == MemOp_LOAD); // expect 32/64 bit load to GPR.
2852 
2853         if (size == MemOpSize_32)
2854             imm12 = encodePositiveImmediate&lt;32&gt;(value);
2855         else
2856             imm12 = encodePositiveImmediate&lt;64&gt;(value);
2857         int insn = loadStoreRegisterUnsignedImmediate(size, V, opc, imm12, rn, rt);
2858         RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(where) == where);
2859         performJITMemcpy(where, &amp;insn, sizeof(int));
2860 
2861         cacheFlush(where, sizeof(int));
2862     }
2863 
2864     unsigned debugOffset() { return m_buffer.debugOffset(); }
2865 
2866 #if OS(LINUX) &amp;&amp; COMPILER(GCC_COMPATIBLE)
2867     static inline void linuxPageFlush(uintptr_t begin, uintptr_t end)
2868     {
2869         __builtin___clear_cache(reinterpret_cast&lt;char*&gt;(begin), reinterpret_cast&lt;char*&gt;(end));
2870     }
2871 #endif
2872 
2873     static void cacheFlush(void* code, size_t size)
2874     {
2875 #if OS(IOS_FAMILY)
2876         sys_cache_control(kCacheFunctionPrepareForExecution, code, size);
2877 #elif OS(FUCHSIA)
2878         zx_cache_flush(code, size, ZX_CACHE_FLUSH_INSN);
2879 #elif OS(LINUX)
2880         size_t page = pageSize();
2881         uintptr_t current = reinterpret_cast&lt;uintptr_t&gt;(code);
2882         uintptr_t end = current + size;
2883         uintptr_t firstPageEnd = (current &amp; ~(page - 1)) + page;
2884 
2885         if (end &lt;= firstPageEnd) {
2886             linuxPageFlush(current, end);
2887             return;
2888         }
2889 
2890         linuxPageFlush(current, firstPageEnd);
2891 
2892         for (current = firstPageEnd; current + page &lt; end; current += page)
2893             linuxPageFlush(current, current + page);
2894 
2895         linuxPageFlush(current, end);
2896 #else
2897 #error &quot;The cacheFlush support is missing on this platform.&quot;
2898 #endif
2899     }
2900 
2901     // Assembler admin methods:
2902 
2903     static int jumpSizeDelta(JumpType jumpType, JumpLinkType jumpLinkType) { return JUMP_ENUM_SIZE(jumpType) - JUMP_ENUM_SIZE(jumpLinkType); }
2904 
2905     static ALWAYS_INLINE bool linkRecordSourceComparator(const LinkRecord&amp; a, const LinkRecord&amp; b)
2906     {
2907         return a.from() &lt; b.from();
2908     }
2909 
2910     static bool canCompact(JumpType jumpType)
2911     {
2912         // Fixed jumps cannot be compacted
2913         return (jumpType == JumpNoCondition) || (jumpType == JumpCondition) || (jumpType == JumpCompareAndBranch) || (jumpType == JumpTestBit);
2914     }
2915 
2916     static JumpLinkType computeJumpType(JumpType jumpType, const uint8_t* from, const uint8_t* to)
2917     {
2918         switch (jumpType) {
2919         case JumpFixed:
2920             return LinkInvalid;
2921         case JumpNoConditionFixedSize:
2922             return LinkJumpNoCondition;
2923         case JumpConditionFixedSize:
2924             return LinkJumpCondition;
2925         case JumpCompareAndBranchFixedSize:
2926             return LinkJumpCompareAndBranch;
2927         case JumpTestBitFixedSize:
2928             return LinkJumpTestBit;
2929         case JumpNoCondition:
2930             return LinkJumpNoCondition;
2931         case JumpCondition: {
2932             ASSERT(is4ByteAligned(from));
2933             ASSERT(is4ByteAligned(to));
2934             intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(to) - (reinterpret_cast&lt;intptr_t&gt;(from));
2935 
2936             if (isInt&lt;21&gt;(relative))
2937                 return LinkJumpConditionDirect;
2938 
2939             return LinkJumpCondition;
2940             }
2941         case JumpCompareAndBranch:  {
2942             ASSERT(is4ByteAligned(from));
2943             ASSERT(is4ByteAligned(to));
2944             intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(to) - (reinterpret_cast&lt;intptr_t&gt;(from));
2945 
2946             if (isInt&lt;21&gt;(relative))
2947                 return LinkJumpCompareAndBranchDirect;
2948 
2949             return LinkJumpCompareAndBranch;
2950         }
2951         case JumpTestBit:   {
2952             ASSERT(is4ByteAligned(from));
2953             ASSERT(is4ByteAligned(to));
2954             intptr_t relative = reinterpret_cast&lt;intptr_t&gt;(to) - (reinterpret_cast&lt;intptr_t&gt;(from));
2955 
2956             if (isInt&lt;14&gt;(relative))
2957                 return LinkJumpTestBitDirect;
2958 
2959             return LinkJumpTestBit;
2960         }
2961         default:
2962             ASSERT_NOT_REACHED();
2963         }
2964 
2965         return LinkJumpNoCondition;
2966     }
2967 
2968     static JumpLinkType computeJumpType(LinkRecord&amp; record, const uint8_t* from, const uint8_t* to)
2969     {
2970         JumpLinkType linkType = computeJumpType(record.type(), from, to);
2971         record.setLinkType(linkType);
2972         return linkType;
2973     }
2974 
2975     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt;&amp; jumpsToLink()
2976     {
2977         std::sort(m_jumpsToLink.begin(), m_jumpsToLink.end(), linkRecordSourceComparator);
2978         return m_jumpsToLink;
2979     }
2980 
<a name="10" id="anc10"></a>


















2981     typedef void* (*CopyFunction)(void*, const void*, size_t);
<a name="11" id="anc11"></a>
2982 
2983     static void ALWAYS_INLINE link(LinkRecord&amp; record, uint8_t* from, const uint8_t* fromInstruction8, uint8_t* to, CopyFunction copy)
2984     {
2985         const int* fromInstruction = reinterpret_cast&lt;const int*&gt;(fromInstruction8);
2986         switch (record.linkType()) {
2987         case LinkJumpNoCondition:
2988             linkJumpOrCall&lt;false&gt;(reinterpret_cast&lt;int*&gt;(from), fromInstruction, to, copy);
2989             break;
2990         case LinkJumpConditionDirect:
2991             linkConditionalBranch&lt;true&gt;(record.condition(), reinterpret_cast&lt;int*&gt;(from), fromInstruction, to, copy);
2992             break;
2993         case LinkJumpCondition:
2994             linkConditionalBranch&lt;false&gt;(record.condition(), reinterpret_cast&lt;int*&gt;(from) - 1, fromInstruction - 1, to, copy);
2995             break;
2996         case LinkJumpCompareAndBranchDirect:
2997             linkCompareAndBranch&lt;true&gt;(record.condition(), record.is64Bit(), record.compareRegister(), reinterpret_cast&lt;int*&gt;(from), fromInstruction, to, copy);
2998             break;
2999         case LinkJumpCompareAndBranch:
3000             linkCompareAndBranch&lt;false&gt;(record.condition(), record.is64Bit(), record.compareRegister(), reinterpret_cast&lt;int*&gt;(from) - 1, fromInstruction - 1, to, copy);
3001             break;
3002         case LinkJumpTestBitDirect:
3003             linkTestAndBranch&lt;true&gt;(record.condition(), record.bitNumber(), record.compareRegister(), reinterpret_cast&lt;int*&gt;(from), fromInstruction, to, copy);
3004             break;
3005         case LinkJumpTestBit:
3006             linkTestAndBranch&lt;false&gt;(record.condition(), record.bitNumber(), record.compareRegister(), reinterpret_cast&lt;int*&gt;(from) - 1, fromInstruction - 1, to, copy);
3007             break;
3008         default:
3009             ASSERT_NOT_REACHED();
3010             break;
3011         }
3012     }
3013 
3014 protected:
3015     template&lt;Datasize size&gt;
3016     static bool checkMovk(int insn, int _hw, RegisterID _rd)
3017     {
3018         Datasize sf;
3019         MoveWideOp opc;
3020         int hw;
3021         uint16_t imm16;
3022         RegisterID rd;
3023         bool expected = disassembleMoveWideImediate(&amp;insn, sf, opc, hw, imm16, rd);
3024 
3025         return expected
3026             &amp;&amp; sf == size
3027             &amp;&amp; opc == MoveWideOp_K
3028             &amp;&amp; hw == _hw
3029             &amp;&amp; rd == _rd;
3030     }
3031 
3032     static void linkPointer(int* address, void* valuePtr, bool flush = false)
3033     {
3034         Datasize sf;
3035         MoveWideOp opc;
3036         int hw;
3037         uint16_t imm16;
3038         RegisterID rd;
3039         bool expected = disassembleMoveWideImediate(address, sf, opc, hw, imm16, rd);
3040         ASSERT_UNUSED(expected, expected &amp;&amp; sf &amp;&amp; opc == MoveWideOp_Z &amp;&amp; !hw);
3041         ASSERT(checkMovk&lt;Datasize_64&gt;(address[1], 1, rd));
3042         ASSERT(checkMovk&lt;Datasize_64&gt;(address[2], 2, rd));
3043 
3044         setPointer(address, valuePtr, rd, flush);
3045     }
3046 
3047     template&lt;bool isCall&gt;
<a name="12" id="anc12"></a><span class="line-modified">3048     static void linkJumpOrCall(int* from, const int* fromInstruction, void* to, CopyFunction copy = performJITMemcpy)</span>
3049     {
3050         bool link;
3051         int imm26;
3052         bool isUnconditionalBranchImmediateOrNop = disassembleUnconditionalBranchImmediate(from, link, imm26) || disassembleNop(from);
3053 
3054         ASSERT_UNUSED(isUnconditionalBranchImmediateOrNop, isUnconditionalBranchImmediateOrNop);
3055         ASSERT_UNUSED(isCall, (link == isCall) || disassembleNop(from));
3056         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(from) &amp; 3));
3057         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(to) &amp; 3));
3058         assertIsNotTagged(to);
3059         assertIsNotTagged(fromInstruction);
3060         intptr_t offset = (reinterpret_cast&lt;intptr_t&gt;(to) - reinterpret_cast&lt;intptr_t&gt;(fromInstruction)) &gt;&gt; 2;
3061         ASSERT(static_cast&lt;int&gt;(offset) == offset);
3062 
3063         int insn = unconditionalBranchImmediate(isCall, static_cast&lt;int&gt;(offset));
3064         RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from) == from);
3065         copy(from, &amp;insn, sizeof(int));
3066     }
3067 
3068     template&lt;bool isDirect&gt;
<a name="13" id="anc13"></a><span class="line-modified">3069     static void linkCompareAndBranch(Condition condition, bool is64Bit, RegisterID rt, int* from, const int* fromInstruction, void* to, CopyFunction copy = performJITMemcpy)</span>
3070     {
3071         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(from) &amp; 3));
3072         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(to) &amp; 3));
3073         intptr_t offset = (reinterpret_cast&lt;intptr_t&gt;(to) - reinterpret_cast&lt;intptr_t&gt;(fromInstruction)) &gt;&gt; 2;
3074         ASSERT(isInt&lt;26&gt;(offset));
3075 
3076         bool useDirect = isInt&lt;19&gt;(offset);
3077         ASSERT(!isDirect || useDirect);
3078 
3079         if (useDirect || isDirect) {
3080             int insn = compareAndBranchImmediate(is64Bit ? Datasize_64 : Datasize_32, condition == ConditionNE, static_cast&lt;int&gt;(offset), rt);
3081             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from) == from);
3082             copy(from, &amp;insn, sizeof(int));
3083             if (!isDirect) {
3084                 insn = nopPseudo();
3085                 RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from + 1) == (from + 1));
3086                 copy(from + 1, &amp;insn, sizeof(int));
3087             }
3088         } else {
3089             int insn = compareAndBranchImmediate(is64Bit ? Datasize_64 : Datasize_32, invert(condition) == ConditionNE, 2, rt);
3090             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from) == from);
3091             copy(from, &amp;insn, sizeof(int));
3092             linkJumpOrCall&lt;false&gt;(from + 1, fromInstruction + 1, to, copy);
3093         }
3094     }
3095 
3096     template&lt;bool isDirect&gt;
<a name="14" id="anc14"></a><span class="line-modified">3097     static void linkConditionalBranch(Condition condition, int* from, const int* fromInstruction, void* to, CopyFunction copy = performJITMemcpy)</span>
3098     {
3099         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(from) &amp; 3));
3100         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(to) &amp; 3));
3101         intptr_t offset = (reinterpret_cast&lt;intptr_t&gt;(to) - reinterpret_cast&lt;intptr_t&gt;(fromInstruction)) &gt;&gt; 2;
3102         ASSERT(isInt&lt;26&gt;(offset));
3103 
3104         bool useDirect = isInt&lt;19&gt;(offset);
3105         ASSERT(!isDirect || useDirect);
3106 
3107         if (useDirect || isDirect) {
3108             int insn = conditionalBranchImmediate(static_cast&lt;int&gt;(offset), condition);
3109             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from) == from);
3110             copy(from, &amp;insn, sizeof(int));
3111             if (!isDirect) {
3112                 insn = nopPseudo();
3113                 RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from + 1) == (from + 1));
3114                 copy(from + 1, &amp;insn, sizeof(int));
3115             }
3116         } else {
3117             int insn = conditionalBranchImmediate(2, invert(condition));
3118             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from) == from);
3119             copy(from, &amp;insn, sizeof(int));
3120             linkJumpOrCall&lt;false&gt;(from + 1, fromInstruction + 1, to, copy);
3121         }
3122     }
3123 
3124     template&lt;bool isDirect&gt;
<a name="15" id="anc15"></a><span class="line-modified">3125     static void linkTestAndBranch(Condition condition, unsigned bitNumber, RegisterID rt, int* from, const int* fromInstruction, void* to, CopyFunction copy = performJITMemcpy)</span>
3126     {
3127         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(from) &amp; 3));
3128         ASSERT(!(reinterpret_cast&lt;intptr_t&gt;(to) &amp; 3));
3129         intptr_t offset = (reinterpret_cast&lt;intptr_t&gt;(to) - reinterpret_cast&lt;intptr_t&gt;(fromInstruction)) &gt;&gt; 2;
3130         ASSERT(static_cast&lt;int&gt;(offset) == offset);
3131         ASSERT(isInt&lt;26&gt;(offset));
3132 
3133         bool useDirect = isInt&lt;14&gt;(offset);
3134         ASSERT(!isDirect || useDirect);
3135 
3136         if (useDirect || isDirect) {
3137             int insn = testAndBranchImmediate(condition == ConditionNE, static_cast&lt;int&gt;(bitNumber), static_cast&lt;int&gt;(offset), rt);
3138             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from) == from);
3139             copy(from, &amp;insn, sizeof(int));
3140             if (!isDirect) {
3141                 insn = nopPseudo();
3142                 RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from + 1) == (from + 1));
3143                 copy(from + 1, &amp;insn, sizeof(int));
3144             }
3145         } else {
3146             int insn = testAndBranchImmediate(invert(condition) == ConditionNE, static_cast&lt;int&gt;(bitNumber), 2, rt);
3147             RELEASE_ASSERT(roundUpToMultipleOf&lt;instructionSize&gt;(from) == from);
3148             copy(from, &amp;insn, sizeof(int));
3149             linkJumpOrCall&lt;false&gt;(from + 1, fromInstruction + 1, to, copy);
3150         }
3151     }
3152 
3153     template&lt;bool isCall&gt;
3154     static void relinkJumpOrCall(int* from, const int* fromInstruction, void* to)
3155     {
3156         if (!isCall &amp;&amp; disassembleNop(from)) {
3157             unsigned op01;
3158             int imm19;
3159             Condition condition;
3160             bool isConditionalBranchImmediate = disassembleConditionalBranchImmediate(from - 1, op01, imm19, condition);
3161 
3162             if (isConditionalBranchImmediate) {
3163                 ASSERT_UNUSED(op01, !op01);
3164                 ASSERT_UNUSED(isCall, !isCall);
3165 
3166                 if (imm19 == 8)
3167                     condition = invert(condition);
3168 
3169                 linkConditionalBranch&lt;false&gt;(condition, from - 1, fromInstruction - 1, to);
3170                 return;
3171             }
3172 
3173             Datasize opSize;
3174             bool op;
3175             RegisterID rt;
3176             bool isCompareAndBranchImmediate = disassembleCompareAndBranchImmediate(from - 1, opSize, op, imm19, rt);
3177 
3178             if (isCompareAndBranchImmediate) {
3179                 if (imm19 == 8)
3180                     op = !op;
3181 
3182                 linkCompareAndBranch&lt;false&gt;(op ? ConditionNE : ConditionEQ, opSize == Datasize_64, rt, from - 1, fromInstruction - 1, to);
3183                 return;
3184             }
3185 
3186             int imm14;
3187             unsigned bitNumber;
3188             bool isTestAndBranchImmediate = disassembleTestAndBranchImmediate(from - 1, op, bitNumber, imm14, rt);
3189 
3190             if (isTestAndBranchImmediate) {
3191                 if (imm14 == 8)
3192                     op = !op;
3193 
3194                 linkTestAndBranch&lt;false&gt;(op ? ConditionNE : ConditionEQ, bitNumber, rt, from - 1, fromInstruction - 1, to);
3195                 return;
3196             }
3197         }
3198 
3199         linkJumpOrCall&lt;isCall&gt;(from, fromInstruction, to);
3200     }
3201 
3202     static int* addressOf(void* code, AssemblerLabel label)
3203     {
3204         return reinterpret_cast&lt;int*&gt;(static_cast&lt;char*&gt;(code) + label.m_offset);
3205     }
3206 
3207     static RegisterID disassembleXOrSp(int reg) { return reg == 31 ? ARM64Registers::sp : static_cast&lt;RegisterID&gt;(reg); }
3208     static RegisterID disassembleXOrZr(int reg) { return reg == 31 ? ARM64Registers::zr : static_cast&lt;RegisterID&gt;(reg); }
3209     static RegisterID disassembleXOrZrOrSp(bool useZr, int reg) { return reg == 31 ? (useZr ? ARM64Registers::zr : ARM64Registers::sp) : static_cast&lt;RegisterID&gt;(reg); }
3210 
3211     static bool disassembleAddSubtractImmediate(void* address, Datasize&amp; sf, AddOp&amp; op, SetFlags&amp; S, int&amp; shift, int&amp; imm12, RegisterID&amp; rn, RegisterID&amp; rd)
3212     {
3213         int insn = *static_cast&lt;int*&gt;(address);
3214         sf = static_cast&lt;Datasize&gt;((insn &gt;&gt; 31) &amp; 1);
3215         op = static_cast&lt;AddOp&gt;((insn &gt;&gt; 30) &amp; 1);
3216         S = static_cast&lt;SetFlags&gt;((insn &gt;&gt; 29) &amp; 1);
3217         shift = (insn &gt;&gt; 22) &amp; 3;
3218         imm12 = (insn &gt;&gt; 10) &amp; 0x3ff;
3219         rn = disassembleXOrSp((insn &gt;&gt; 5) &amp; 0x1f);
3220         rd = disassembleXOrZrOrSp(S, insn &amp; 0x1f);
3221         return (insn &amp; 0x1f000000) == 0x11000000;
3222     }
3223 
3224     static bool disassembleLoadStoreRegisterUnsignedImmediate(void* address, MemOpSize&amp; size, bool&amp; V, MemOp&amp; opc, int&amp; imm12, RegisterID&amp; rn, RegisterID&amp; rt)
3225     {
3226         int insn = *static_cast&lt;int*&gt;(address);
3227         size = static_cast&lt;MemOpSize&gt;((insn &gt;&gt; 30) &amp; 3);
3228         V = (insn &gt;&gt; 26) &amp; 1;
3229         opc = static_cast&lt;MemOp&gt;((insn &gt;&gt; 22) &amp; 3);
3230         imm12 = (insn &gt;&gt; 10) &amp; 0xfff;
3231         rn = disassembleXOrSp((insn &gt;&gt; 5) &amp; 0x1f);
3232         rt = disassembleXOrZr(insn &amp; 0x1f);
3233         return (insn &amp; 0x3b000000) == 0x39000000;
3234     }
3235 
3236     static bool disassembleMoveWideImediate(void* address, Datasize&amp; sf, MoveWideOp&amp; opc, int&amp; hw, uint16_t&amp; imm16, RegisterID&amp; rd)
3237     {
3238         int insn = *static_cast&lt;int*&gt;(address);
3239         sf = static_cast&lt;Datasize&gt;((insn &gt;&gt; 31) &amp; 1);
3240         opc = static_cast&lt;MoveWideOp&gt;((insn &gt;&gt; 29) &amp; 3);
3241         hw = (insn &gt;&gt; 21) &amp; 3;
3242         imm16 = insn &gt;&gt; 5;
3243         rd = disassembleXOrZr(insn &amp; 0x1f);
3244         return (insn &amp; 0x1f800000) == 0x12800000;
3245     }
3246 
3247     static bool disassembleNop(void* address)
3248     {
3249         unsigned insn = *static_cast&lt;unsigned*&gt;(address);
3250         return insn == 0xd503201f;
3251     }
3252 
3253     static bool disassembleCompareAndBranchImmediate(void* address, Datasize&amp; sf, bool&amp; op, int&amp; imm19, RegisterID&amp; rt)
3254     {
3255         int insn = *static_cast&lt;int*&gt;(address);
3256         sf = static_cast&lt;Datasize&gt;((insn &gt;&gt; 31) &amp; 1);
3257         op = (insn &gt;&gt; 24) &amp; 0x1;
3258         imm19 = (insn &lt;&lt; 8) &gt;&gt; 13;
3259         rt = static_cast&lt;RegisterID&gt;(insn &amp; 0x1f);
3260         return (insn &amp; 0x7e000000) == 0x34000000;
3261 
3262     }
3263 
3264     static bool disassembleConditionalBranchImmediate(void* address, unsigned&amp; op01, int&amp; imm19, Condition &amp;condition)
3265     {
3266         int insn = *static_cast&lt;int*&gt;(address);
3267         op01 = ((insn &gt;&gt; 23) &amp; 0x2) | ((insn &gt;&gt; 4) &amp; 0x1);
3268         imm19 = (insn &lt;&lt; 8) &gt;&gt; 13;
3269         condition = static_cast&lt;Condition&gt;(insn &amp; 0xf);
3270         return (insn &amp; 0xfe000000) == 0x54000000;
3271     }
3272 
3273     static bool disassembleTestAndBranchImmediate(void* address, bool&amp; op, unsigned&amp; bitNumber, int&amp; imm14, RegisterID&amp; rt)
3274     {
3275         int insn = *static_cast&lt;int*&gt;(address);
3276         op = (insn &gt;&gt; 24) &amp; 0x1;
3277         imm14 = (insn &lt;&lt; 13) &gt;&gt; 18;
3278         bitNumber = static_cast&lt;unsigned&gt;((((insn &gt;&gt; 26) &amp; 0x20)) | ((insn &gt;&gt; 19) &amp; 0x1f));
3279         rt = static_cast&lt;RegisterID&gt;(insn &amp; 0x1f);
3280         return (insn &amp; 0x7e000000) == 0x36000000;
3281 
3282     }
3283 
3284     static bool disassembleUnconditionalBranchImmediate(void* address, bool&amp; op, int&amp; imm26)
3285     {
3286         int insn = *static_cast&lt;int*&gt;(address);
3287         op = (insn &gt;&gt; 31) &amp; 1;
3288         imm26 = (insn &lt;&lt; 6) &gt;&gt; 6;
3289         return (insn &amp; 0x7c000000) == 0x14000000;
3290     }
3291 
3292     static int xOrSp(RegisterID reg)
3293     {
3294         ASSERT(!isZr(reg));
3295         ASSERT(!isIOS() || reg != ARM64Registers::x18);
3296         return reg;
3297     }
3298     static int xOrZr(RegisterID reg)
3299     {
3300         ASSERT(!isSp(reg));
3301         ASSERT(!isIOS() || reg != ARM64Registers::x18);
3302         return reg &amp; 31;
3303     }
3304     static FPRegisterID xOrZrAsFPR(RegisterID reg) { return static_cast&lt;FPRegisterID&gt;(xOrZr(reg)); }
3305     static int xOrZrOrSp(bool useZr, RegisterID reg) { return useZr ? xOrZr(reg) : xOrSp(reg); }
3306 
3307     ALWAYS_INLINE void insn(int instruction)
3308     {
3309         m_buffer.putInt(instruction);
3310     }
3311 
3312     ALWAYS_INLINE static int addSubtractExtendedRegister(Datasize sf, AddOp op, SetFlags S, RegisterID rm, ExtendType option, int imm3, RegisterID rn, RegisterID rd)
3313     {
3314         ASSERT(imm3 &lt; 5);
3315         // The only allocated values for opt is 0.
3316         const int opt = 0;
3317         return (0x0b200000 | sf &lt;&lt; 31 | op &lt;&lt; 30 | S &lt;&lt; 29 | opt &lt;&lt; 22 | xOrZr(rm) &lt;&lt; 16 | option &lt;&lt; 13 | (imm3 &amp; 0x7) &lt;&lt; 10 | xOrSp(rn) &lt;&lt; 5 | xOrZrOrSp(S, rd));
3318     }
3319 
3320     ALWAYS_INLINE static int addSubtractImmediate(Datasize sf, AddOp op, SetFlags S, int shift, int imm12, RegisterID rn, RegisterID rd)
3321     {
3322         ASSERT(shift &lt; 2);
3323         ASSERT(isUInt12(imm12));
3324         return (0x11000000 | sf &lt;&lt; 31 | op &lt;&lt; 30 | S &lt;&lt; 29 | shift &lt;&lt; 22 | (imm12 &amp; 0xfff) &lt;&lt; 10 | xOrSp(rn) &lt;&lt; 5 | xOrZrOrSp(S, rd));
3325     }
3326 
3327     ALWAYS_INLINE static int addSubtractShiftedRegister(Datasize sf, AddOp op, SetFlags S, ShiftType shift, RegisterID rm, int imm6, RegisterID rn, RegisterID rd)
3328     {
3329         ASSERT(shift &lt; 3);
3330         ASSERT(!(imm6 &amp; (sf ? ~63 : ~31)));
3331         return (0x0b000000 | sf &lt;&lt; 31 | op &lt;&lt; 30 | S &lt;&lt; 29 | shift &lt;&lt; 22 | xOrZr(rm) &lt;&lt; 16 | (imm6 &amp; 0x3f) &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3332     }
3333 
3334     ALWAYS_INLINE static int addSubtractWithCarry(Datasize sf, AddOp op, SetFlags S, RegisterID rm, RegisterID rn, RegisterID rd)
3335     {
3336         const int opcode2 = 0;
3337         return (0x1a000000 | sf &lt;&lt; 31 | op &lt;&lt; 30 | S &lt;&lt; 29 | xOrZr(rm) &lt;&lt; 16 | opcode2 &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3338     }
3339 
3340     ALWAYS_INLINE static int bitfield(Datasize sf, BitfieldOp opc, int immr, int imms, RegisterID rn, RegisterID rd)
3341     {
3342         ASSERT(immr &lt; (sf ? 64 : 32));
3343         ASSERT(imms &lt; (sf ? 64 : 32));
3344         const int N = sf;
3345         return (0x13000000 | sf &lt;&lt; 31 | opc &lt;&lt; 29 | N &lt;&lt; 22 | immr &lt;&lt; 16 | imms &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3346     }
3347 
3348     // &#39;op&#39; means negate
3349     ALWAYS_INLINE static int compareAndBranchImmediate(Datasize sf, bool op, int32_t imm19, RegisterID rt)
3350     {
3351         ASSERT(imm19 == (imm19 &lt;&lt; 13) &gt;&gt; 13);
3352         return (0x34000000 | sf &lt;&lt; 31 | op &lt;&lt; 24 | (imm19 &amp; 0x7ffff) &lt;&lt; 5 | xOrZr(rt));
3353     }
3354 
3355     ALWAYS_INLINE static int conditionalBranchImmediate(int32_t imm19, Condition cond)
3356     {
3357         ASSERT(imm19 == (imm19 &lt;&lt; 13) &gt;&gt; 13);
3358         ASSERT(!(cond &amp; ~15));
3359         // The only allocated values for o1 &amp; o0 are 0.
3360         const int o1 = 0;
3361         const int o0 = 0;
3362         return (0x54000000 | o1 &lt;&lt; 24 | (imm19 &amp; 0x7ffff) &lt;&lt; 5 | o0 &lt;&lt; 4 | cond);
3363     }
3364 
3365     ALWAYS_INLINE static int conditionalCompareImmediate(Datasize sf, AddOp op, int imm5, Condition cond, RegisterID rn, int nzcv)
3366     {
3367         ASSERT(!(imm5 &amp; ~0x1f));
3368         ASSERT(nzcv &lt; 16);
3369         const int S = 1;
3370         const int o2 = 0;
3371         const int o3 = 0;
3372         return (0x1a400800 | sf &lt;&lt; 31 | op &lt;&lt; 30 | S &lt;&lt; 29 | (imm5 &amp; 0x1f) &lt;&lt; 16 | cond &lt;&lt; 12 | o2 &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | o3 &lt;&lt; 4 | nzcv);
3373     }
3374 
3375     ALWAYS_INLINE static int conditionalCompareRegister(Datasize sf, AddOp op, RegisterID rm, Condition cond, RegisterID rn, int nzcv)
3376     {
3377         ASSERT(nzcv &lt; 16);
3378         const int S = 1;
3379         const int o2 = 0;
3380         const int o3 = 0;
3381         return (0x1a400000 | sf &lt;&lt; 31 | op &lt;&lt; 30 | S &lt;&lt; 29 | xOrZr(rm) &lt;&lt; 16 | cond &lt;&lt; 12 | o2 &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | o3 &lt;&lt; 4 | nzcv);
3382     }
3383 
3384     // &#39;op&#39; means negate
3385     // &#39;op2&#39; means increment
3386     ALWAYS_INLINE static int conditionalSelect(Datasize sf, bool op, RegisterID rm, Condition cond, bool op2, RegisterID rn, RegisterID rd)
3387     {
3388         const int S = 0;
3389         return (0x1a800000 | sf &lt;&lt; 31 | op &lt;&lt; 30 | S &lt;&lt; 29 | xOrZr(rm) &lt;&lt; 16 | cond &lt;&lt; 12 | op2 &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3390     }
3391 
3392     ALWAYS_INLINE static int dataProcessing1Source(Datasize sf, DataOp1Source opcode, RegisterID rn, RegisterID rd)
3393     {
3394         const int S = 0;
3395         const int opcode2 = 0;
3396         return (0x5ac00000 | sf &lt;&lt; 31 | S &lt;&lt; 29 | opcode2 &lt;&lt; 16 | opcode &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3397     }
3398 
3399     ALWAYS_INLINE static int dataProcessing2Source(Datasize sf, RegisterID rm, DataOp2Source opcode, RegisterID rn, RegisterID rd)
3400     {
3401         const int S = 0;
3402         return (0x1ac00000 | sf &lt;&lt; 31 | S &lt;&lt; 29 | xOrZr(rm) &lt;&lt; 16 | opcode &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3403     }
3404 
3405     ALWAYS_INLINE static int dataProcessing3Source(Datasize sf, DataOp3Source opcode, RegisterID rm, RegisterID ra, RegisterID rn, RegisterID rd)
3406     {
3407         int op54 = opcode &gt;&gt; 4;
3408         int op31 = (opcode &gt;&gt; 1) &amp; 7;
3409         int op0 = opcode &amp; 1;
3410         return (0x1b000000 | sf &lt;&lt; 31 | op54 &lt;&lt; 29 | op31 &lt;&lt; 21 | xOrZr(rm) &lt;&lt; 16 | op0 &lt;&lt; 15 | xOrZr(ra) &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3411     }
3412 
3413     ALWAYS_INLINE static int excepnGeneration(ExcepnOp opc, uint16_t imm16, int LL)
3414     {
3415         ASSERT((opc == ExcepnOp_BREAKPOINT || opc == ExcepnOp_HALT) ? !LL : (LL &amp;&amp; (LL &lt; 4)));
3416         const int op2 = 0;
3417         return (0xd4000000 | opc &lt;&lt; 21 | imm16 &lt;&lt; 5 | op2 &lt;&lt; 2 | LL);
3418     }
3419     ALWAYS_INLINE static int excepnGenerationImmMask()
3420     {
3421         uint16_t imm16 =  std::numeric_limits&lt;uint16_t&gt;::max();
3422         return (static_cast&lt;int&gt;(imm16) &lt;&lt; 5);
3423     }
3424 
3425     ALWAYS_INLINE static int extract(Datasize sf, RegisterID rm, int imms, RegisterID rn, RegisterID rd)
3426     {
3427         ASSERT(imms &lt; (sf ? 64 : 32));
3428         const int op21 = 0;
3429         const int N = sf;
3430         const int o0 = 0;
3431         return (0x13800000 | sf &lt;&lt; 31 | op21 &lt;&lt; 29 | N &lt;&lt; 22 | o0 &lt;&lt; 21 | xOrZr(rm) &lt;&lt; 16 | imms &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3432     }
3433 
3434     ALWAYS_INLINE static int floatingPointCompare(Datasize type, FPRegisterID rm, FPRegisterID rn, FPCmpOp opcode2)
3435     {
3436         const int M = 0;
3437         const int S = 0;
3438         const int op = 0;
3439         return (0x1e202000 | M &lt;&lt; 31 | S &lt;&lt; 29 | type &lt;&lt; 22 | rm &lt;&lt; 16 | op &lt;&lt; 14 | rn &lt;&lt; 5 | opcode2);
3440     }
3441 
3442     ALWAYS_INLINE static int floatingPointConditionalCompare(Datasize type, FPRegisterID rm, Condition cond, FPRegisterID rn, FPCondCmpOp op, int nzcv)
3443     {
3444         ASSERT(nzcv &lt; 16);
3445         const int M = 0;
3446         const int S = 0;
3447         return (0x1e200400 | M &lt;&lt; 31 | S &lt;&lt; 29 | type &lt;&lt; 22 | rm &lt;&lt; 16 | cond &lt;&lt; 12 | rn &lt;&lt; 5 | op &lt;&lt; 4 | nzcv);
3448     }
3449 
3450     ALWAYS_INLINE static int floatingPointConditionalSelect(Datasize type, FPRegisterID rm, Condition cond, FPRegisterID rn, FPRegisterID rd)
3451     {
3452         const int M = 0;
3453         const int S = 0;
3454         return (0x1e200c00 | M &lt;&lt; 31 | S &lt;&lt; 29 | type &lt;&lt; 22 | rm &lt;&lt; 16 | cond &lt;&lt; 12 | rn &lt;&lt; 5 | rd);
3455     }
3456 
3457     ALWAYS_INLINE static int floatingPointImmediate(Datasize type, int imm8, FPRegisterID rd)
3458     {
3459         const int M = 0;
3460         const int S = 0;
3461         const int imm5 = 0;
3462         return (0x1e201000 | M &lt;&lt; 31 | S &lt;&lt; 29 | type &lt;&lt; 22 | (imm8 &amp; 0xff) &lt;&lt; 13 | imm5 &lt;&lt; 5 | rd);
3463     }
3464 
3465     ALWAYS_INLINE static int floatingPointIntegerConversions(Datasize sf, Datasize type, FPIntConvOp rmodeOpcode, FPRegisterID rn, FPRegisterID rd)
3466     {
3467         const int S = 0;
3468         return (0x1e200000 | sf &lt;&lt; 31 | S &lt;&lt; 29 | type &lt;&lt; 22 | rmodeOpcode &lt;&lt; 16 | rn &lt;&lt; 5 | rd);
3469     }
3470 
3471     ALWAYS_INLINE static int floatingPointIntegerConversions(Datasize sf, Datasize type, FPIntConvOp rmodeOpcode, FPRegisterID rn, RegisterID rd)
3472     {
3473         return floatingPointIntegerConversions(sf, type, rmodeOpcode, rn, xOrZrAsFPR(rd));
3474     }
3475 
3476     ALWAYS_INLINE static int floatingPointIntegerConversions(Datasize sf, Datasize type, FPIntConvOp rmodeOpcode, RegisterID rn, FPRegisterID rd)
3477     {
3478         return floatingPointIntegerConversions(sf, type, rmodeOpcode, xOrZrAsFPR(rn), rd);
3479     }
3480 
3481     ALWAYS_INLINE static int floatingPointDataProcessing1Source(Datasize type, FPDataOp1Source opcode, FPRegisterID rn, FPRegisterID rd)
3482     {
3483         const int M = 0;
3484         const int S = 0;
3485         return (0x1e204000 | M &lt;&lt; 31 | S &lt;&lt; 29 | type &lt;&lt; 22 | opcode &lt;&lt; 15 | rn &lt;&lt; 5 | rd);
3486     }
3487 
3488     ALWAYS_INLINE static int floatingPointDataProcessing2Source(Datasize type, FPRegisterID rm, FPDataOp2Source opcode, FPRegisterID rn, FPRegisterID rd)
3489     {
3490         const int M = 0;
3491         const int S = 0;
3492         return (0x1e200800 | M &lt;&lt; 31 | S &lt;&lt; 29 | type &lt;&lt; 22 | rm &lt;&lt; 16 | opcode &lt;&lt; 12 | rn &lt;&lt; 5 | rd);
3493     }
3494 
3495     ALWAYS_INLINE static int vectorDataProcessingLogical(SIMD3SameLogical uAndSize, FPRegisterID vm, FPRegisterID vn, FPRegisterID vd)
3496     {
3497         const int Q = 0;
3498         return (0xe200400 | Q &lt;&lt; 30 | uAndSize &lt;&lt; 22 | vm &lt;&lt; 16 | SIMD_LogicalOp &lt;&lt; 11 | vn &lt;&lt; 5 | vd);
3499     }
3500 
3501     // &#39;o1&#39; means negate
3502     ALWAYS_INLINE static int floatingPointDataProcessing3Source(Datasize type, bool o1, FPRegisterID rm, AddOp o2, FPRegisterID ra, FPRegisterID rn, FPRegisterID rd)
3503     {
3504         const int M = 0;
3505         const int S = 0;
3506         return (0x1f000000 | M &lt;&lt; 31 | S &lt;&lt; 29 | type &lt;&lt; 22 | o1 &lt;&lt; 21 | rm &lt;&lt; 16 | o2 &lt;&lt; 15 | ra &lt;&lt; 10 | rn &lt;&lt; 5 | rd);
3507     }
3508 
3509     // &#39;V&#39; means vector
3510     ALWAYS_INLINE static int loadRegisterLiteral(LdrLiteralOp opc, bool V, int imm19, FPRegisterID rt)
3511     {
3512         ASSERT(isInt&lt;19&gt;(imm19));
3513         return (0x18000000 | opc &lt;&lt; 30 | V &lt;&lt; 26 | (imm19 &amp; 0x7ffff) &lt;&lt; 5 | rt);
3514     }
3515 
3516     ALWAYS_INLINE static int loadRegisterLiteral(LdrLiteralOp opc, bool V, int imm19, RegisterID rt)
3517     {
3518         return loadRegisterLiteral(opc, V, imm19, xOrZrAsFPR(rt));
3519     }
3520 
3521     // &#39;V&#39; means vector
3522     ALWAYS_INLINE static int loadStoreRegisterPostIndex(MemOpSize size, bool V, MemOp opc, int imm9, RegisterID rn, FPRegisterID rt)
3523     {
3524         ASSERT(!(size &amp;&amp; V &amp;&amp; (opc &amp; 2))); // Maximum vector size is 128 bits.
3525         ASSERT(!((size &amp; 2) &amp;&amp; !V &amp;&amp; (opc == 3))); // signed 32-bit load must be extending from 8/16 bits.
3526         ASSERT(isInt9(imm9));
3527         return (0x38000400 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | (imm9 &amp; 0x1ff) &lt;&lt; 12 | xOrSp(rn) &lt;&lt; 5 | rt);
3528     }
3529 
3530     ALWAYS_INLINE static int loadStoreRegisterPostIndex(MemOpSize size, bool V, MemOp opc, int imm9, RegisterID rn, RegisterID rt)
3531     {
3532         return loadStoreRegisterPostIndex(size, V, opc, imm9, rn, xOrZrAsFPR(rt));
3533     }
3534 
3535     // &#39;V&#39; means vector
3536     ALWAYS_INLINE static int loadStoreRegisterPairPostIndex(MemPairOpSize size, bool V, MemOp opc, int immediate, RegisterID rn, FPRegisterID rt, FPRegisterID rt2)
3537     {
3538         ASSERT(size &lt; 3);
3539         ASSERT(opc == (opc &amp; 1)); // Only load or store, load signed 64 is handled via size.
3540         ASSERT(V || (size != MemPairOp_LoadSigned_32) || (opc == MemOp_LOAD)); // There isn&#39;t an integer store signed.
3541         unsigned immedShiftAmount = memPairOffsetShift(V, size);
3542         int imm7 = immediate &gt;&gt; immedShiftAmount;
3543         ASSERT((imm7 &lt;&lt; immedShiftAmount) == immediate &amp;&amp; isInt&lt;7&gt;(imm7));
3544         return (0x28800000 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | (imm7 &amp; 0x7f) &lt;&lt; 15 | rt2 &lt;&lt; 10 | xOrSp(rn) &lt;&lt; 5 | rt);
3545     }
3546 
3547     ALWAYS_INLINE static int loadStoreRegisterPairPostIndex(MemPairOpSize size, bool V, MemOp opc, int immediate, RegisterID rn, RegisterID rt, RegisterID rt2)
3548     {
3549         return loadStoreRegisterPairPostIndex(size, V, opc, immediate, rn, xOrZrAsFPR(rt), xOrZrAsFPR(rt2));
3550     }
3551 
3552     // &#39;V&#39; means vector
3553     ALWAYS_INLINE static int loadStoreRegisterPreIndex(MemOpSize size, bool V, MemOp opc, int imm9, RegisterID rn, FPRegisterID rt)
3554     {
3555         ASSERT(!(size &amp;&amp; V &amp;&amp; (opc &amp; 2))); // Maximum vector size is 128 bits.
3556         ASSERT(!((size &amp; 2) &amp;&amp; !V &amp;&amp; (opc == 3))); // signed 32-bit load must be extending from 8/16 bits.
3557         ASSERT(isInt9(imm9));
3558         return (0x38000c00 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | (imm9 &amp; 0x1ff) &lt;&lt; 12 | xOrSp(rn) &lt;&lt; 5 | rt);
3559     }
3560 
3561     ALWAYS_INLINE static int loadStoreRegisterPreIndex(MemOpSize size, bool V, MemOp opc, int imm9, RegisterID rn, RegisterID rt)
3562     {
3563         return loadStoreRegisterPreIndex(size, V, opc, imm9, rn, xOrZrAsFPR(rt));
3564     }
3565 
3566     // &#39;V&#39; means vector
3567     ALWAYS_INLINE static int loadStoreRegisterPairPreIndex(MemPairOpSize size, bool V, MemOp opc, int immediate, RegisterID rn, FPRegisterID rt, FPRegisterID rt2)
3568     {
3569         ASSERT(size &lt; 3);
3570         ASSERT(opc == (opc &amp; 1)); // Only load or store, load signed 64 is handled via size.
3571         ASSERT(V || (size != MemPairOp_LoadSigned_32) || (opc == MemOp_LOAD)); // There isn&#39;t an integer store signed.
3572         unsigned immedShiftAmount = memPairOffsetShift(V, size);
3573         int imm7 = immediate &gt;&gt; immedShiftAmount;
3574         ASSERT((imm7 &lt;&lt; immedShiftAmount) == immediate &amp;&amp; isInt&lt;7&gt;(imm7));
3575         return (0x29800000 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | (imm7 &amp; 0x7f) &lt;&lt; 15 | rt2 &lt;&lt; 10 | xOrSp(rn) &lt;&lt; 5 | rt);
3576     }
3577 
3578     ALWAYS_INLINE static int loadStoreRegisterPairPreIndex(MemPairOpSize size, bool V, MemOp opc, int immediate, RegisterID rn, RegisterID rt, RegisterID rt2)
3579     {
3580         return loadStoreRegisterPairPreIndex(size, V, opc, immediate, rn, xOrZrAsFPR(rt), xOrZrAsFPR(rt2));
3581     }
3582 
3583     // &#39;V&#39; means vector
3584     ALWAYS_INLINE static int loadStoreRegisterPairOffset(MemPairOpSize size, bool V, MemOp opc, int immediate, RegisterID rn, FPRegisterID rt, FPRegisterID rt2)
3585     {
3586         ASSERT(size &lt; 3);
3587         ASSERT(opc == (opc &amp; 1)); // Only load or store, load signed 64 is handled via size.
3588         ASSERT(V || (size != MemPairOp_LoadSigned_32) || (opc == MemOp_LOAD)); // There isn&#39;t an integer store signed.
3589         unsigned immedShiftAmount = memPairOffsetShift(V, size);
3590         int imm7 = immediate &gt;&gt; immedShiftAmount;
3591         ASSERT((imm7 &lt;&lt; immedShiftAmount) == immediate &amp;&amp; isInt&lt;7&gt;(imm7));
3592         return (0x29000000 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | (imm7 &amp; 0x7f) &lt;&lt; 15 | rt2 &lt;&lt; 10 | xOrSp(rn) &lt;&lt; 5 | rt);
3593     }
3594 
3595     ALWAYS_INLINE static int loadStoreRegisterPairOffset(MemPairOpSize size, bool V, MemOp opc, int immediate, RegisterID rn, RegisterID rt, RegisterID rt2)
3596     {
3597         return loadStoreRegisterPairOffset(size, V, opc, immediate, rn, xOrZrAsFPR(rt), xOrZrAsFPR(rt2));
3598     }
3599 
3600     // &#39;V&#39; means vector
3601     ALWAYS_INLINE static int loadStoreRegisterPairNonTemporal(MemPairOpSize size, bool V, MemOp opc, int immediate, RegisterID rn, FPRegisterID rt, FPRegisterID rt2)
3602     {
3603         ASSERT(size &lt; 3);
3604         ASSERT(opc == (opc &amp; 1)); // Only load or store, load signed 64 is handled via size.
3605         ASSERT(V || (size != MemPairOp_LoadSigned_32) || (opc == MemOp_LOAD)); // There isn&#39;t an integer store signed.
3606         unsigned immedShiftAmount = memPairOffsetShift(V, size);
3607         int imm7 = immediate &gt;&gt; immedShiftAmount;
3608         ASSERT((imm7 &lt;&lt; immedShiftAmount) == immediate &amp;&amp; isInt&lt;7&gt;(imm7));
3609         return (0x28000000 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | (imm7 &amp; 0x7f) &lt;&lt; 15 | rt2 &lt;&lt; 10 | xOrSp(rn) &lt;&lt; 5 | rt);
3610     }
3611 
3612     ALWAYS_INLINE static int loadStoreRegisterPairNonTemporal(MemPairOpSize size, bool V, MemOp opc, int immediate, RegisterID rn, RegisterID rt, RegisterID rt2)
3613     {
3614         return loadStoreRegisterPairNonTemporal(size, V, opc, immediate, rn, xOrZrAsFPR(rt), xOrZrAsFPR(rt2));
3615     }
3616 
3617     // &#39;V&#39; means vector
3618     // &#39;S&#39; means shift rm
3619     ALWAYS_INLINE static int loadStoreRegisterRegisterOffset(MemOpSize size, bool V, MemOp opc, RegisterID rm, ExtendType option, bool S, RegisterID rn, FPRegisterID rt)
3620     {
3621         ASSERT(!(size &amp;&amp; V &amp;&amp; (opc &amp; 2))); // Maximum vector size is 128 bits.
3622         ASSERT(!((size &amp; 2) &amp;&amp; !V &amp;&amp; (opc == 3))); // signed 32-bit load must be extending from 8/16 bits.
3623         ASSERT(option &amp; 2); // The ExtendType for the address must be 32/64 bit, signed or unsigned - not 8/16bit.
3624         return (0x38200800 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | xOrZr(rm) &lt;&lt; 16 | option &lt;&lt; 13 | S &lt;&lt; 12 | xOrSp(rn) &lt;&lt; 5 | rt);
3625     }
3626 
3627     ALWAYS_INLINE static int loadStoreRegisterRegisterOffset(MemOpSize size, bool V, MemOp opc, RegisterID rm, ExtendType option, bool S, RegisterID rn, RegisterID rt)
3628     {
3629         return loadStoreRegisterRegisterOffset(size, V, opc, rm, option, S, rn, xOrZrAsFPR(rt));
3630     }
3631 
3632     // &#39;V&#39; means vector
3633     ALWAYS_INLINE static int loadStoreRegisterUnscaledImmediate(MemOpSize size, bool V, MemOp opc, int imm9, RegisterID rn, FPRegisterID rt)
3634     {
3635         ASSERT(!(size &amp;&amp; V &amp;&amp; (opc &amp; 2))); // Maximum vector size is 128 bits.
3636         ASSERT(!((size &amp; 2) &amp;&amp; !V &amp;&amp; (opc == 3))); // signed 32-bit load must be extending from 8/16 bits.
3637         ASSERT(isInt9(imm9));
3638         return (0x38000000 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | (imm9 &amp; 0x1ff) &lt;&lt; 12 | xOrSp(rn) &lt;&lt; 5 | rt);
3639     }
3640 
3641     ALWAYS_INLINE static int loadStoreRegisterUnscaledImmediate(MemOpSize size, bool V, MemOp opc, int imm9, RegisterID rn, RegisterID rt)
3642     {
3643         ASSERT(isInt9(imm9));
3644         return loadStoreRegisterUnscaledImmediate(size, V, opc, imm9, rn, xOrZrAsFPR(rt));
3645     }
3646 
3647     // &#39;V&#39; means vector
3648     ALWAYS_INLINE static int loadStoreRegisterUnsignedImmediate(MemOpSize size, bool V, MemOp opc, int imm12, RegisterID rn, FPRegisterID rt)
3649     {
3650         ASSERT(!(size &amp;&amp; V &amp;&amp; (opc &amp; 2))); // Maximum vector size is 128 bits.
3651         ASSERT(!((size &amp; 2) &amp;&amp; !V &amp;&amp; (opc == 3))); // signed 32-bit load must be extending from 8/16 bits.
3652         ASSERT(isUInt12(imm12));
3653         return (0x39000000 | size &lt;&lt; 30 | V &lt;&lt; 26 | opc &lt;&lt; 22 | (imm12 &amp; 0xfff) &lt;&lt; 10 | xOrSp(rn) &lt;&lt; 5 | rt);
3654     }
3655 
3656     ALWAYS_INLINE static int loadStoreRegisterUnsignedImmediate(MemOpSize size, bool V, MemOp opc, int imm12, RegisterID rn, RegisterID rt)
3657     {
3658         return loadStoreRegisterUnsignedImmediate(size, V, opc, imm12, rn, xOrZrAsFPR(rt));
3659     }
3660 
3661     ALWAYS_INLINE static int logicalImmediate(Datasize sf, LogicalOp opc, int N_immr_imms, RegisterID rn, RegisterID rd)
3662     {
3663         ASSERT(!(N_immr_imms &amp; (sf ? ~0x1fff : ~0xfff)));
3664         return (0x12000000 | sf &lt;&lt; 31 | opc &lt;&lt; 29 | N_immr_imms &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZrOrSp(opc == LogicalOp_ANDS, rd));
3665     }
3666 
3667     // &#39;N&#39; means negate rm
3668     ALWAYS_INLINE static int logicalShiftedRegister(Datasize sf, LogicalOp opc, ShiftType shift, bool N, RegisterID rm, int imm6, RegisterID rn, RegisterID rd)
3669     {
3670         ASSERT(!(imm6 &amp; (sf ? ~63 : ~31)));
3671         return (0x0a000000 | sf &lt;&lt; 31 | opc &lt;&lt; 29 | shift &lt;&lt; 22 | N &lt;&lt; 21 | xOrZr(rm) &lt;&lt; 16 | (imm6 &amp; 0x3f) &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | xOrZr(rd));
3672     }
3673 
3674     ALWAYS_INLINE static int moveWideImediate(Datasize sf, MoveWideOp opc, int hw, uint16_t imm16, RegisterID rd)
3675     {
3676         ASSERT(hw &lt; (sf ? 4 : 2));
3677         return (0x12800000 | sf &lt;&lt; 31 | opc &lt;&lt; 29 | hw &lt;&lt; 21 | (int)imm16 &lt;&lt; 5 | xOrZr(rd));
3678     }
3679 
3680     // &#39;op&#39; means link
3681     ALWAYS_INLINE static int unconditionalBranchImmediate(bool op, int32_t imm26)
3682     {
3683         ASSERT(imm26 == (imm26 &lt;&lt; 6) &gt;&gt; 6);
3684         return (0x14000000 | op &lt;&lt; 31 | (imm26 &amp; 0x3ffffff));
3685     }
3686 
3687     // &#39;op&#39; means page
3688     ALWAYS_INLINE static int pcRelative(bool op, int32_t imm21, RegisterID rd)
3689     {
3690         ASSERT(imm21 == (imm21 &lt;&lt; 11) &gt;&gt; 11);
3691         int32_t immlo = imm21 &amp; 3;
3692         int32_t immhi = (imm21 &gt;&gt; 2) &amp; 0x7ffff;
3693         return (0x10000000 | op &lt;&lt; 31 | immlo &lt;&lt; 29 | immhi &lt;&lt; 5 | xOrZr(rd));
3694     }
3695 
3696     ALWAYS_INLINE static int system(bool L, int op0, int op1, int crn, int crm, int op2, RegisterID rt)
3697     {
3698         return (0xd5000000 | L &lt;&lt; 21 | op0 &lt;&lt; 19 | op1 &lt;&lt; 16 | crn &lt;&lt; 12 | crm &lt;&lt; 8 | op2 &lt;&lt; 5 | xOrZr(rt));
3699     }
3700 
3701     ALWAYS_INLINE static int hintPseudo(int imm)
3702     {
3703         ASSERT(!(imm &amp; ~0x7f));
3704         return system(0, 0, 3, 2, (imm &gt;&gt; 3) &amp; 0xf, imm &amp; 0x7, ARM64Registers::zr);
3705     }
3706 
3707     ALWAYS_INLINE static int nopPseudo()
3708     {
3709         return hintPseudo(0);
3710     }
3711 
3712     ALWAYS_INLINE static int dataCacheZeroVirtualAddress(RegisterID rt)
3713     {
3714         return system(0, 1, 0x3, 0x7, 0x4, 0x1, rt);
3715     }
3716 
3717     // &#39;op&#39; means negate
3718     ALWAYS_INLINE static int testAndBranchImmediate(bool op, int b50, int imm14, RegisterID rt)
3719     {
3720         ASSERT(!(b50 &amp; ~0x3f));
3721         ASSERT(imm14 == (imm14 &lt;&lt; 18) &gt;&gt; 18);
3722         int b5 = b50 &gt;&gt; 5;
3723         int b40 = b50 &amp; 0x1f;
3724         return (0x36000000 | b5 &lt;&lt; 31 | op &lt;&lt; 24 | b40 &lt;&lt; 19 | (imm14 &amp; 0x3fff) &lt;&lt; 5 | xOrZr(rt));
3725     }
3726 
3727     ALWAYS_INLINE static int unconditionalBranchRegister(BranchType opc, RegisterID rn)
3728     {
3729         // The only allocated values for op2 is 0x1f, for op3 &amp; op4 are 0.
3730         const int op2 = 0x1f;
3731         const int op3 = 0;
3732         const int op4 = 0;
3733         return (0xd6000000 | opc &lt;&lt; 21 | op2 &lt;&lt; 16 | op3 &lt;&lt; 10 | xOrZr(rn) &lt;&lt; 5 | op4);
3734     }
3735 
3736     static int exoticLoad(MemOpSize size, ExoticLoadFence fence, ExoticLoadAtomic atomic, RegisterID dst, RegisterID src)
3737     {
3738         return 0x085f7c00 | size &lt;&lt; 30 | fence &lt;&lt; 15 | atomic &lt;&lt; 23 | src &lt;&lt; 5 | dst;
3739     }
3740 
3741     static int storeRelease(MemOpSize size, RegisterID src, RegisterID dst)
3742     {
3743         return 0x089ffc00 | size &lt;&lt; 30 | dst &lt;&lt; 5 | src;
3744     }
3745 
3746     static int exoticStore(MemOpSize size, ExoticStoreFence fence, RegisterID result, RegisterID src, RegisterID dst)
3747     {
3748         return 0x08007c00 | size &lt;&lt; 30 | result &lt;&lt; 16 | fence &lt;&lt; 15 | dst &lt;&lt; 5 | src;
3749     }
3750 
3751     static int fjcvtzsInsn(FPRegisterID dn, RegisterID rd)
3752     {
3753         return 0x1e7e0000 | (dn &lt;&lt; 5) | rd;
3754     }
3755 
3756     // Workaround for Cortex-A53 erratum (835769). Emit an extra nop if the
3757     // last instruction in the buffer is a load, store or prefetch. Needed
3758     // before 64-bit multiply-accumulate instructions.
3759     template&lt;int datasize&gt;
3760     ALWAYS_INLINE void nopCortexA53Fix835769()
3761     {
3762 #if CPU(ARM64_CORTEXA53)
3763         CHECK_DATASIZE();
3764         if (datasize == 64) {
3765             if (LIKELY(m_buffer.codeSize() &gt;= sizeof(int32_t))) {
3766                 // From ARMv8 Reference Manual, Section C4.1: the encoding of the
3767                 // instructions in the Loads and stores instruction group is:
3768                 // ---- 1-0- ---- ---- ---- ---- ---- ----
3769                 if (UNLIKELY((*reinterpret_cast_ptr&lt;int32_t*&gt;(reinterpret_cast_ptr&lt;char*&gt;(m_buffer.data()) + m_buffer.codeSize() - sizeof(int32_t)) &amp; 0x0a000000) == 0x08000000))
3770                     nop();
3771             }
3772         }
3773 #endif
3774     }
3775 
3776     // Workaround for Cortex-A53 erratum (843419). Emit extra nops to avoid
3777     // wrong address access after ADRP instruction.
3778     ALWAYS_INLINE void nopCortexA53Fix843419()
3779     {
3780 #if CPU(ARM64_CORTEXA53)
3781         nop();
3782         nop();
3783         nop();
3784 #endif
3785     }
3786 
3787     Vector&lt;LinkRecord, 0, UnsafeVectorOverflow&gt; m_jumpsToLink;
3788     int m_indexOfLastWatchpoint;
3789     int m_indexOfTailOfLastWatchpoint;
3790     AssemblerBuffer m_buffer;
3791 
3792 public:
3793     static constexpr ptrdiff_t MAX_POINTER_BITS = 48;
3794 };
3795 
3796 } // namespace JSC
3797 
3798 #undef CHECK_DATASIZE_OF
3799 #undef DATASIZE_OF
3800 #undef MEMOPSIZE_OF
3801 #undef CHECK_DATASIZE
3802 #undef DATASIZE
3803 #undef MEMOPSIZE
3804 #undef CHECK_FP_MEMOP_DATASIZE
3805 
3806 #endif // ENABLE(ASSEMBLER) &amp;&amp; CPU(ARM64)
<a name="16" id="anc16"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="16" type="hidden" />
</body>
</html>