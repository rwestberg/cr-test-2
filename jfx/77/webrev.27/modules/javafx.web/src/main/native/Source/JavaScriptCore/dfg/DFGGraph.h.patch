diff a/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.h b/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.h
--- a/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.h
+++ b/modules/javafx.web/src/main/native/Source/JavaScriptCore/dfg/DFGGraph.h
@@ -1,7 +1,7 @@
 /*
- * Copyright (C) 2011-2018 Apple Inc. All rights reserved.
+ * Copyright (C) 2011-2019 Apple Inc. All rights reserved.
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
  * are met:
  * 1. Redistributions of source code must retain the above copyright
@@ -117,10 +117,44 @@
     DontSpeculateInt32,
     SpeculateInt32AndTruncateConstants,
     SpeculateInt32
 };
 
+struct Prefix {
+    enum NoHeaderTag { NoHeader };
+
+    Prefix() { }
+
+    Prefix(const char* prefixStr, NoHeaderTag tag = NoHeader)
+        : prefixStr(prefixStr)
+        , noHeader(tag == NoHeader)
+    { }
+
+    Prefix(NoHeaderTag)
+        : noHeader(true)
+    { }
+
+    void dump(PrintStream& out) const;
+
+    void clearBlockIndex() { blockIndex = -1; }
+    void clearNodeIndex() { nodeIndex = -1; }
+
+    void enable() { m_enabled = true; }
+    void disable() { m_enabled = false; }
+
+    int32_t phaseNumber { -1 };
+    int32_t blockIndex { -1 };
+    int32_t nodeIndex { -1 };
+    const char* prefixStr { nullptr };
+    bool noHeader { false };
+
+    static constexpr const char* noString = nullptr;
+
+private:
+    bool m_enabled { true };
+};
+
 //
 // === Graph ===
 //
 // The order may be significant for nodes with side-effects (property accesses, value conversions).
 // Nodes that are 'dead' remain in the vector with refCount 0.
@@ -282,42 +316,38 @@
     bool addShouldSpeculateInt32(Node* add, PredictionPass pass)
     {
         return addSpeculationMode(add, pass) != DontSpeculateInt32;
     }
 
-    bool addShouldSpeculateAnyInt(Node* add)
+    bool addShouldSpeculateInt52(Node* add)
     {
         if (!enableInt52())
             return false;
 
         Node* left = add->child1().node();
         Node* right = add->child2().node();
 
         if (hasExitSite(add, Int52Overflow))
             return false;
 
-        if (Node::shouldSpeculateAnyInt(left, right))
+        if (Node::shouldSpeculateInt52(left, right))
             return true;
 
-        auto shouldSpeculateAnyIntForAdd = [](Node* node) {
-            auto isAnyIntSpeculationForAdd = [](SpeculatedType value) {
-                return !!value && (value & (SpecAnyInt | SpecAnyIntAsDouble)) == value;
-            };
-
+        auto shouldSpeculateInt52ForAdd = [] (Node* node) {
             // When DoubleConstant node appears, it means that users explicitly write a constant in their code with double form instead of integer form (1.0 instead of 1).
             // In that case, we should honor this decision: using it as integer is not appropriate.
             if (node->op() == DoubleConstant)
                 return false;
-            return isAnyIntSpeculationForAdd(node->prediction());
+            return isIntAnyFormat(node->prediction());
         };
 
-        // Allow AnyInt ArithAdd only when the one side of the binary operation should be speculated AnyInt. It is a bit conservative
+        // Allow Int52 ArithAdd only when the one side of the binary operation should be speculated Int52. It is a bit conservative
         // decision. This is because Double to Int52 conversion is not so cheap. Frequent back-and-forth conversions between Double and Int52
         // rather hurt the performance. If the one side of the operation is already Int52, the cost for constructing ArithAdd becomes
         // cheap since only one Double to Int52 conversion could be required.
         // This recovers some regression in assorted tests while keeping kraken crypto improvements.
-        if (!left->shouldSpeculateAnyInt() && !right->shouldSpeculateAnyInt())
+        if (!left->shouldSpeculateInt52() && !right->shouldSpeculateInt52())
             return false;
 
         auto usesAsNumbers = [](Node* node) {
             NodeFlags flags = node->flags() & NodeBytecodeBackPropMask;
             if (!flags)
@@ -327,11 +357,11 @@
 
         // Wrapping Int52 to Value is also not so cheap. Thus, we allow Int52 addition only when the node is used as number.
         if (!usesAsNumbers(add))
             return false;
 
-        return shouldSpeculateAnyIntForAdd(left) && shouldSpeculateAnyIntForAdd(right);
+        return shouldSpeculateInt52ForAdd(left) && shouldSpeculateInt52ForAdd(right);
     }
 
     bool binaryArithShouldSpeculateInt32(Node* node, PredictionPass pass)
     {
         Node* left = node->child1().node();
@@ -339,34 +369,34 @@
 
         return Node::shouldSpeculateInt32OrBooleanForArithmetic(left, right)
             && node->canSpeculateInt32(node->sourceFor(pass));
     }
 
-    bool binaryArithShouldSpeculateAnyInt(Node* node, PredictionPass pass)
+    bool binaryArithShouldSpeculateInt52(Node* node, PredictionPass pass)
     {
         if (!enableInt52())
             return false;
 
         Node* left = node->child1().node();
         Node* right = node->child2().node();
 
-        return Node::shouldSpeculateAnyInt(left, right)
+        return Node::shouldSpeculateInt52(left, right)
             && node->canSpeculateInt52(pass)
             && !hasExitSite(node, Int52Overflow);
     }
 
     bool unaryArithShouldSpeculateInt32(Node* node, PredictionPass pass)
     {
         return node->child1()->shouldSpeculateInt32OrBooleanForArithmetic()
             && node->canSpeculateInt32(pass);
     }
 
-    bool unaryArithShouldSpeculateAnyInt(Node* node, PredictionPass pass)
+    bool unaryArithShouldSpeculateInt52(Node* node, PredictionPass pass)
     {
         if (!enableInt52())
             return false;
-        return node->child1()->shouldSpeculateAnyInt()
+        return node->child1()->shouldSpeculateInt52()
             && node->canSpeculateInt52(pass)
             && !hasExitSite(node, Int52Overflow);
     }
 
     bool canOptimizeStringObjectAccess(const CodeOrigin&);
@@ -422,11 +452,11 @@
         return inlineCallFrame->baselineCodeBlock->ownerExecutable();
     }
 
     ScriptExecutable* executableFor(const CodeOrigin& codeOrigin)
     {
-        return executableFor(codeOrigin.inlineCallFrame);
+        return executableFor(codeOrigin.inlineCallFrame());
     }
 
     CodeBlock* baselineCodeBlockFor(InlineCallFrame* inlineCallFrame)
     {
         if (!inlineCallFrame)
@@ -439,13 +469,13 @@
         return baselineCodeBlockForOriginAndBaselineCodeBlock(codeOrigin, m_profiledBlock);
     }
 
     bool isStrictModeFor(CodeOrigin codeOrigin)
     {
-        if (!codeOrigin.inlineCallFrame)
+        if (!codeOrigin.inlineCallFrame())
             return m_codeBlock->isStrictMode();
-        return codeOrigin.inlineCallFrame->isStrictMode();
+        return codeOrigin.inlineCallFrame()->isStrictMode();
     }
 
     ECMAMode ecmaModeFor(CodeOrigin codeOrigin)
     {
         return isStrictModeFor(codeOrigin) ? StrictMode : NotStrictMode;
@@ -461,11 +491,11 @@
         return baselineCodeBlockFor(codeOrigin)->unlinkedCodeBlock()->hasExitSite(FrequentExitSite(exitKind));
     }
 
     bool hasExitSite(const CodeOrigin& codeOrigin, ExitKind exitKind)
     {
-        return baselineCodeBlockFor(codeOrigin)->unlinkedCodeBlock()->hasExitSite(FrequentExitSite(codeOrigin.bytecodeIndex, exitKind));
+        return baselineCodeBlockFor(codeOrigin)->unlinkedCodeBlock()->hasExitSite(FrequentExitSite(codeOrigin.bytecodeIndex(), exitKind));
     }
 
     bool hasExitSite(Node* node, ExitKind exitKind)
     {
         return hasExitSite(node->origin.semantic, exitKind);
@@ -768,18 +798,18 @@
     }
 
     bool isWatchingArrayIteratorProtocolWatchpoint(Node* node)
     {
         JSGlobalObject* globalObject = globalObjectFor(node->origin.semantic);
-        InlineWatchpointSet& set = globalObject->arrayIteratorProtocolWatchpoint();
+        InlineWatchpointSet& set = globalObject->arrayIteratorProtocolWatchpointSet();
         return isWatchingGlobalObjectWatchpoint(globalObject, set);
     }
 
     bool isWatchingNumberToStringWatchpoint(Node* node)
     {
         JSGlobalObject* globalObject = globalObjectFor(node->origin.semantic);
-        InlineWatchpointSet& set = globalObject->numberToStringWatchpoint();
+        InlineWatchpointSet& set = globalObject->numberToStringWatchpointSet();
         return isWatchingGlobalObjectWatchpoint(globalObject, set);
     }
 
     Profiler::Compilation* compilation() { return m_plan.compilation(); }
 
@@ -825,11 +855,11 @@
         VirtualRegister exclusionEnd;
 
         CodeOrigin* codeOriginPtr = &codeOrigin;
 
         for (;;) {
-            InlineCallFrame* inlineCallFrame = codeOriginPtr->inlineCallFrame;
+            InlineCallFrame* inlineCallFrame = codeOriginPtr->inlineCallFrame();
             VirtualRegister stackOffset(inlineCallFrame ? inlineCallFrame->stackOffset : 0);
 
             if (inlineCallFrame) {
                 if (inlineCallFrame->isClosureCall)
                     functor(stackOffset + CallFrameSlot::callee);
@@ -837,11 +867,11 @@
                     functor(stackOffset + CallFrameSlot::argumentCount);
             }
 
             CodeBlock* codeBlock = baselineCodeBlockFor(inlineCallFrame);
             FullBytecodeLiveness& fullLiveness = livenessFor(codeBlock);
-            const FastBitVector& liveness = fullLiveness.getLiveness(codeOriginPtr->bytecodeIndex);
+            const FastBitVector& liveness = fullLiveness.getLiveness(codeOriginPtr->bytecodeIndex());
             for (unsigned relativeLocal = codeBlock->numCalleeLocals(); relativeLocal--;) {
                 VirtualRegister reg = stackOffset + virtualRegisterForLocal(relativeLocal);
 
                 // Don't report if our callee already reported.
                 if (reg >= exclusionStart && reg < exclusionEnd)
@@ -864,15 +894,13 @@
             ASSERT(exclusionStart < exclusionEnd);
 
             for (VirtualRegister reg = exclusionStart; reg < exclusionEnd; reg += 1)
                 functor(reg);
 
-            codeOriginPtr = inlineCallFrame->getCallerSkippingTailCalls();
-
-            // The first inline call frame could be an inline tail call
-            if (!codeOriginPtr)
-                break;
+            // We need to handle tail callers because we may decide to exit to the
+            // the return bytecode following the tail call.
+            codeOriginPtr = &inlineCallFrame->directCaller;
         }
     }
 
     // Get a BitVector of all of the non-argument locals live right now. This is mostly useful if
     // you want to compare two sets of live locals from two different CodeOrigins.
@@ -973,10 +1001,13 @@
         bool result = m_rootToArguments.contains(block);
         ASSERT(result == m_roots.contains(block));
         return result;
     }
 
+    Prefix& prefix() { return m_prefix; }
+    void nextPhase() { m_prefix.phaseNumber++; }
+
     VM& m_vm;
     Plan& m_plan;
     CodeBlock* m_codeBlock;
     CodeBlock* m_profiledBlock;
 
@@ -989,11 +1020,11 @@
 
     Vector<uint32_t> m_uint32ValuesInUse;
 
     Bag<StorageAccessData> m_storageAccessData;
 
-    // In CPS, this is all of the SetArgument nodes for the arguments in the machine code block
+    // In CPS, this is all of the SetArgumentDefinitely nodes for the arguments in the machine code block
     // that survived DCE. All of them except maybe "this" will survive DCE, because of the Flush
     // nodes. In SSA, this has no meaning. It's empty.
     HashMap<BasicBlock*, ArgumentsVector> m_rootToArguments;
 
     // In SSA, this is the argument speculation that we've locked in for an entrypoint block.
@@ -1020,20 +1051,10 @@
     //
     // By convention, entrypoint index 0 is used for the CodeBlock's op_enter entrypoint.
     // So argumentFormats[0] are the argument formats for the normal call entrypoint.
     Vector<Vector<FlushFormat>> m_argumentFormats;
 
-    // This maps an entrypoint index to a particular op_catch bytecode offset. By convention,
-    // it'll never have zero as a key because we use zero to mean the op_enter entrypoint.
-    HashMap<unsigned, unsigned> m_entrypointIndexToCatchBytecodeOffset;
-
-    // This is the number of logical entrypoints that we're compiling. This is only used
-    // in SSA. Each EntrySwitch node must have m_numberOfEntrypoints cases. Note, this is
-    // not the same as m_roots.size(). m_roots.size() represents the number of roots in
-    // the CFG. In SSA, m_roots.size() == 1 even if we're compiling more than one entrypoint.
-    unsigned m_numberOfEntrypoints { UINT_MAX };
-
     SegmentedVector<VariableAccessData, 16> m_variableAccessData;
     SegmentedVector<ArgumentPosition, 8> m_argumentPositions;
     Bag<Transition> m_transitions;
     Bag<BranchData> m_branchData;
     Bag<SwitchData> m_switchData;
@@ -1063,10 +1084,20 @@
     std::unique_ptr<ControlEquivalenceAnalysis> m_controlEquivalenceAnalysis;
     unsigned m_localVars;
     unsigned m_nextMachineLocal;
     unsigned m_parameterSlots;
 
+    // This is the number of logical entrypoints that we're compiling. This is only used
+    // in SSA. Each EntrySwitch node must have m_numberOfEntrypoints cases. Note, this is
+    // not the same as m_roots.size(). m_roots.size() represents the number of roots in
+    // the CFG. In SSA, m_roots.size() == 1 even if we're compiling more than one entrypoint.
+    unsigned m_numberOfEntrypoints { UINT_MAX };
+
+    // This maps an entrypoint index to a particular op_catch bytecode offset. By convention,
+    // it'll never have zero as a key because we use zero to mean the op_enter entrypoint.
+    HashMap<unsigned, unsigned> m_entrypointIndexToCatchBytecodeOffset;
+
     HashSet<String> m_localStrings;
     HashMap<const StringImpl*, String> m_copiedStrings;
 
 #if USE(JSVALUE32_64)
     StdUnorderedMap<int64_t, double*> m_doubleConstantsMap;
@@ -1123,10 +1154,11 @@
         return bytecodeCanTruncateInteger(add->arithNodeFlags()) ? SpeculateInt32AndTruncateConstants : DontSpeculateInt32;
     }
 
     B3::SparseCollection<Node> m_nodes;
     SegmentedVector<RegisteredStructureSet, 16> m_structureSets;
+    Prefix m_prefix;
 };
 
 } } // namespace JSC::DFG
 
 #endif
