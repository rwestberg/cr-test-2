<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames modules/javafx.web/src/main/native/Source/JavaScriptCore/wasm/WasmAirIRGenerator.cpp</title>
    <link rel="stylesheet" href="../../../../../../../../style.css" />
    <script type="text/javascript" src="../../../../../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>   1 /*
   2  * Copyright (C) 2019 Apple Inc. All rights reserved.
   3  *
   4  * Redistribution and use in source and binary forms, with or without
   5  * modification, are permitted provided that the following conditions
   6  * are met:
   7  * 1. Redistributions of source code must retain the above copyright
   8  *    notice, this list of conditions and the following disclaimer.
   9  * 2. Redistributions in binary form must reproduce the above copyright
  10  *    notice, this list of conditions and the following disclaimer in the
  11  *    documentation and/or other materials provided with the distribution.
  12  *
  13  * THIS SOFTWARE IS PROVIDED BY APPLE INC. ``AS IS&#39;&#39; AND ANY
  14  * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  15  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
  16  * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL APPLE INC. OR
  17  * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
  18  * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
  19  * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
  20  * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
  21  * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
  22  * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  23  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  24  */
  25 
  26 #include &quot;config.h&quot;
  27 #include &quot;WasmAirIRGenerator.h&quot;
  28 
  29 #if ENABLE(WEBASSEMBLY)
  30 
  31 #include &quot;AirCode.h&quot;
  32 #include &quot;AirGenerate.h&quot;
  33 #include &quot;AirOpcodeUtils.h&quot;
  34 #include &quot;AirValidate.h&quot;
  35 #include &quot;AllowMacroScratchRegisterUsageIf.h&quot;
  36 #include &quot;B3CCallValue.h&quot;
  37 #include &quot;B3CheckSpecial.h&quot;
  38 #include &quot;B3CheckValue.h&quot;
  39 #include &quot;B3PatchpointSpecial.h&quot;
  40 #include &quot;B3Procedure.h&quot;
  41 #include &quot;B3ProcedureInlines.h&quot;
  42 #include &quot;BinarySwitch.h&quot;
<a name="1" id="anc1"></a>


  43 #include &quot;ScratchRegisterAllocator.h&quot;
  44 #include &quot;VirtualRegister.h&quot;
  45 #include &quot;WasmCallingConvention.h&quot;
  46 #include &quot;WasmContextInlines.h&quot;
  47 #include &quot;WasmExceptionType.h&quot;
  48 #include &quot;WasmFunctionParser.h&quot;
  49 #include &quot;WasmInstance.h&quot;
  50 #include &quot;WasmMemory.h&quot;
  51 #include &quot;WasmOMGPlan.h&quot;
<a name="2" id="anc2"></a>
  52 #include &quot;WasmOpcodeOrigin.h&quot;
<a name="3" id="anc3"></a>
  53 #include &quot;WasmSignatureInlines.h&quot;
  54 #include &quot;WasmThunks.h&quot;
  55 #include &lt;limits&gt;
  56 #include &lt;wtf/Box.h&gt;
  57 #include &lt;wtf/Optional.h&gt;
  58 #include &lt;wtf/StdLibExtras.h&gt;
  59 
  60 namespace JSC { namespace Wasm {
  61 
  62 using namespace B3::Air;
  63 
  64 struct ConstrainedTmp {
  65     ConstrainedTmp(Tmp tmp)
  66         : ConstrainedTmp(tmp, tmp.isReg() ? B3::ValueRep::reg(tmp.reg()) : B3::ValueRep::SomeRegister)
  67     { }
  68 
  69     ConstrainedTmp(Tmp tmp, B3::ValueRep rep)
  70         : tmp(tmp)
  71         , rep(rep)
  72     {
  73     }
  74 
  75     Tmp tmp;
  76     B3::ValueRep rep;
  77 };
  78 
  79 class TypedTmp {
  80 public:
  81     constexpr TypedTmp()
  82         : m_tmp()
  83         , m_type(Type::Void)
  84     { }
  85 
  86     TypedTmp(Tmp tmp, Type type)
  87         : m_tmp(tmp)
  88         , m_type(type)
  89     { }
  90 
  91     TypedTmp(const TypedTmp&amp;) = default;
  92     TypedTmp(TypedTmp&amp;&amp;) = default;
  93     TypedTmp&amp; operator=(TypedTmp&amp;&amp;) = default;
  94     TypedTmp&amp; operator=(const TypedTmp&amp;) = default;
  95 
  96     bool operator==(const TypedTmp&amp; other) const
  97     {
  98         return m_tmp == other.m_tmp &amp;&amp; m_type == other.m_type;
  99     }
 100     bool operator!=(const TypedTmp&amp; other) const
 101     {
 102         return !(*this == other);
 103     }
 104 
 105     explicit operator bool() const { return !!tmp(); }
 106 
 107     operator Tmp() const { return tmp(); }
 108     operator Arg() const { return Arg(tmp()); }
 109     Tmp tmp() const { return m_tmp; }
 110     Type type() const { return m_type; }
 111 
 112 private:
 113 
 114     Tmp m_tmp;
 115     Type m_type;
 116 };
 117 
 118 class AirIRGenerator {
 119 public:
 120     struct ControlData {
 121         ControlData(B3::Origin origin, Type returnType, TypedTmp resultTmp, BlockType type, BasicBlock* continuation, BasicBlock* special = nullptr)
 122             : blockType(type)
 123             , continuation(continuation)
 124             , special(special)
 125             , returnType(returnType)
 126         {
 127             UNUSED_PARAM(origin); // FIXME: Use origin.
 128             if (resultTmp) {
 129                 ASSERT(returnType != Type::Void);
 130                 result.append(resultTmp);
 131             } else
 132                 ASSERT(returnType == Type::Void);
 133         }
 134 
 135         ControlData()
 136         {
 137         }
 138 
 139         void dump(PrintStream&amp; out) const
 140         {
 141             switch (type()) {
 142             case BlockType::If:
 143                 out.print(&quot;If:       &quot;);
 144                 break;
 145             case BlockType::Block:
 146                 out.print(&quot;Block:    &quot;);
 147                 break;
 148             case BlockType::Loop:
 149                 out.print(&quot;Loop:     &quot;);
 150                 break;
 151             case BlockType::TopLevel:
 152                 out.print(&quot;TopLevel: &quot;);
 153                 break;
 154             }
 155             out.print(&quot;Continuation: &quot;, *continuation, &quot;, Special: &quot;);
 156             if (special)
 157                 out.print(*special);
 158             else
 159                 out.print(&quot;None&quot;);
 160         }
 161 
 162         BlockType type() const { return blockType; }
 163 
 164         Type signature() const { return returnType; }
 165 
 166         bool hasNonVoidSignature() const { return result.size(); }
 167 
 168         BasicBlock* targetBlockForBranch()
 169         {
 170             if (type() == BlockType::Loop)
 171                 return special;
 172             return continuation;
 173         }
 174 
 175         void convertIfToBlock()
 176         {
 177             ASSERT(type() == BlockType::If);
 178             blockType = BlockType::Block;
 179             special = nullptr;
 180         }
 181 
 182         using ResultList = Vector&lt;TypedTmp, 1&gt;;
 183 
 184         ResultList resultForBranch() const
 185         {
 186             if (type() == BlockType::Loop)
 187                 return ResultList();
 188             return result;
 189         }
 190 
 191     private:
 192         friend class AirIRGenerator;
 193         BlockType blockType;
 194         BasicBlock* continuation;
 195         BasicBlock* special;
 196         ResultList result;
 197         Type returnType;
 198     };
 199 
 200     using ExpressionType = TypedTmp;
 201     using ControlType = ControlData;
 202     using ExpressionList = Vector&lt;ExpressionType, 1&gt;;
<a name="4" id="anc4"></a>
 203     using ResultList = ControlData::ResultList;
 204     using ControlEntry = FunctionParser&lt;AirIRGenerator&gt;::ControlEntry;
 205 
 206     static ExpressionType emptyExpression() { return { }; };
<a name="5" id="anc5"></a>
 207 
 208     using ErrorType = String;
 209     using UnexpectedResult = Unexpected&lt;ErrorType&gt;;
 210     using Result = Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, ErrorType&gt;;
 211     using PartialResult = Expected&lt;void, ErrorType&gt;;
 212 
 213     template &lt;typename ...Args&gt;
 214     NEVER_INLINE UnexpectedResult WARN_UNUSED_RETURN fail(Args... args) const
 215     {
 216         using namespace FailureHelper; // See ADL comment in WasmParser.h.
 217         return UnexpectedResult(makeString(&quot;WebAssembly.Module failed compiling: &quot;_s, makeString(args)...));
 218     }
 219 
 220 #define WASM_COMPILE_FAIL_IF(condition, ...) do { \
 221         if (UNLIKELY(condition))                  \
 222             return fail(__VA_ARGS__);             \
 223     } while (0)
 224 
 225     AirIRGenerator(const ModuleInformation&amp;, B3::Procedure&amp;, InternalFunction*, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp;, MemoryMode, unsigned functionIndex, TierUpCount*, ThrowWasmException, const Signature&amp;);
 226 
 227     PartialResult WARN_UNUSED_RETURN addArguments(const Signature&amp;);
 228     PartialResult WARN_UNUSED_RETURN addLocal(Type, uint32_t);
 229     ExpressionType addConstant(Type, uint64_t);
 230     ExpressionType addConstant(BasicBlock*, Type, uint64_t);
 231 
<a name="6" id="anc6"></a>










 232     // Locals
 233     PartialResult WARN_UNUSED_RETURN getLocal(uint32_t index, ExpressionType&amp; result);
 234     PartialResult WARN_UNUSED_RETURN setLocal(uint32_t index, ExpressionType value);
 235 
 236     // Globals
 237     PartialResult WARN_UNUSED_RETURN getGlobal(uint32_t index, ExpressionType&amp; result);
 238     PartialResult WARN_UNUSED_RETURN setGlobal(uint32_t index, ExpressionType value);
 239 
 240     // Memory
 241     PartialResult WARN_UNUSED_RETURN load(LoadOpType, ExpressionType pointer, ExpressionType&amp; result, uint32_t offset);
 242     PartialResult WARN_UNUSED_RETURN store(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 243     PartialResult WARN_UNUSED_RETURN addGrowMemory(ExpressionType delta, ExpressionType&amp; result);
 244     PartialResult WARN_UNUSED_RETURN addCurrentMemory(ExpressionType&amp; result);
 245 
 246     // Basic operators
 247     template&lt;OpType&gt;
 248     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType arg, ExpressionType&amp; result);
 249     template&lt;OpType&gt;
 250     PartialResult WARN_UNUSED_RETURN addOp(ExpressionType left, ExpressionType right, ExpressionType&amp; result);
 251     PartialResult WARN_UNUSED_RETURN addSelect(ExpressionType condition, ExpressionType nonZero, ExpressionType zero, ExpressionType&amp; result);
 252 
 253     // Control flow
 254     ControlData WARN_UNUSED_RETURN addTopLevel(Type signature);
 255     ControlData WARN_UNUSED_RETURN addBlock(Type signature);
<a name="7" id="anc7"></a><span class="line-modified"> 256     ControlData WARN_UNUSED_RETURN addLoop(Type signature);</span>
 257     PartialResult WARN_UNUSED_RETURN addIf(ExpressionType condition, Type signature, ControlData&amp; result);
<a name="8" id="anc8"></a><span class="line-modified"> 258     PartialResult WARN_UNUSED_RETURN addElse(ControlData&amp;, const ExpressionList&amp;);</span>
 259     PartialResult WARN_UNUSED_RETURN addElseToUnreachable(ControlData&amp;);
 260 
 261     PartialResult WARN_UNUSED_RETURN addReturn(const ControlData&amp;, const ExpressionList&amp; returnValues);
<a name="9" id="anc9"></a><span class="line-modified"> 262     PartialResult WARN_UNUSED_RETURN addBranch(ControlData&amp;, ExpressionType condition, const ExpressionList&amp; returnValues);</span>
<span class="line-modified"> 263     PartialResult WARN_UNUSED_RETURN addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTargets, const ExpressionList&amp; expressionStack);</span>
<span class="line-modified"> 264     PartialResult WARN_UNUSED_RETURN endBlock(ControlEntry&amp;, ExpressionList&amp; expressionStack);</span>
 265     PartialResult WARN_UNUSED_RETURN addEndToUnreachable(ControlEntry&amp;);
 266 
 267     // Calls
 268     PartialResult WARN_UNUSED_RETURN addCall(uint32_t calleeIndex, const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result);
<a name="10" id="anc10"></a><span class="line-modified"> 269     PartialResult WARN_UNUSED_RETURN addCallIndirect(const Signature&amp;, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result);</span>
 270     PartialResult WARN_UNUSED_RETURN addUnreachable();
 271 
 272     PartialResult addShift(Type, B3::Air::Opcode, ExpressionType value, ExpressionType shift, ExpressionType&amp; result);
 273     PartialResult addIntegerSub(B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 274     PartialResult addFloatingPointAbs(B3::Air::Opcode, ExpressionType value, ExpressionType&amp; result);
 275     PartialResult addFloatingPointBinOp(Type, B3::Air::Opcode, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 276 
<a name="11" id="anc11"></a><span class="line-modified"> 277     void dump(const Vector&lt;ControlEntry&gt;&amp; controlStack, const ExpressionList* expressionStack);</span>
 278     void setParser(FunctionParser&lt;AirIRGenerator&gt;* parser) { m_parser = parser; };
 279 
 280     static Vector&lt;Tmp&gt; toTmpVector(const Vector&lt;TypedTmp&gt;&amp; vector)
 281     {
 282         Vector&lt;Tmp&gt; result;
 283         for (const auto&amp; item : vector)
 284             result.append(item.tmp());
 285         return result;
 286     }
 287 
 288     ALWAYS_INLINE void didKill(const ExpressionType&amp; typedTmp)
 289     {
 290         Tmp tmp = typedTmp.tmp();
 291         if (!tmp)
 292             return;
 293         if (tmp.isGP())
 294             m_freeGPs.append(tmp);
 295         else
 296             m_freeFPs.append(tmp);
 297     }
 298 
<a name="12" id="anc12"></a>




 299 private:
 300     ALWAYS_INLINE void validateInst(Inst&amp; inst)
 301     {
 302         if (!ASSERT_DISABLED) {
 303             if (!inst.isValidForm()) {
 304                 dataLogLn(inst);
 305                 CRASH();
 306             }
 307         }
 308     }
 309 
 310     static Arg extractArg(const TypedTmp&amp; tmp) { return tmp.tmp(); }
 311     static Arg extractArg(const Tmp&amp; tmp) { return Arg(tmp); }
 312     static Arg extractArg(const Arg&amp; arg) { return arg; }
 313 
 314     template&lt;typename... Arguments&gt;
 315     void append(BasicBlock* block, Kind kind, Arguments&amp;&amp;... arguments)
 316     {
 317         // FIXME: Find a way to use origin here.
 318         auto&amp; inst = block-&gt;append(kind, nullptr, extractArg(arguments)...);
 319         validateInst(inst);
 320     }
 321 
 322     template&lt;typename... Arguments&gt;
 323     void append(Kind kind, Arguments&amp;&amp;... arguments)
 324     {
 325         append(m_currentBlock, kind, std::forward&lt;Arguments&gt;(arguments)...);
 326     }
 327 
 328     template&lt;typename... Arguments&gt;
 329     void appendEffectful(B3::Air::Opcode op, Arguments&amp;&amp;... arguments)
 330     {
 331         Kind kind = op;
 332         kind.effects = true;
 333         append(m_currentBlock, kind, std::forward&lt;Arguments&gt;(arguments)...);
 334     }
 335 
 336     Tmp newTmp(B3::Bank bank)
 337     {
 338         switch (bank) {
 339         case B3::GP:
 340             if (m_freeGPs.size())
 341                 return m_freeGPs.takeLast();
 342             break;
 343         case B3::FP:
 344             if (m_freeFPs.size())
 345                 return m_freeFPs.takeLast();
 346             break;
 347         }
 348         return m_code.newTmp(bank);
 349     }
 350 
 351     TypedTmp g32() { return { newTmp(B3::GP), Type::I32 }; }
 352     TypedTmp g64() { return { newTmp(B3::GP), Type::I64 }; }
<a name="13" id="anc13"></a>

 353     TypedTmp f32() { return { newTmp(B3::FP), Type::F32 }; }
 354     TypedTmp f64() { return { newTmp(B3::FP), Type::F64 }; }
 355 
 356     TypedTmp tmpForType(Type type)
 357     {
 358         switch (type) {
 359         case Type::I32:
 360             return g32();
 361         case Type::I64:
 362             return g64();
<a name="14" id="anc14"></a>



 363         case Type::F32:
 364             return f32();
 365         case Type::F64:
 366             return f64();
 367         case Type::Void:
 368             return { };
 369         default:
 370             RELEASE_ASSERT_NOT_REACHED();
 371         }
 372     }
 373 
 374     B3::PatchpointValue* addPatchpoint(B3::Type type)
 375     {
<a name="15" id="anc15"></a><span class="line-modified"> 376         return m_proc.add&lt;B3::PatchpointValue&gt;(type, B3::Origin());</span>



 377     }
 378 
 379     template &lt;typename ...Args&gt;
 380     void emitPatchpoint(B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 381     {
 382         emitPatchpoint(m_currentBlock, patch, result, std::forward&lt;Args&gt;(theArgs)...);
 383     }
 384 
 385     template &lt;typename ...Args&gt;
 386     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Args... theArgs)
 387     {
 388         emitPatchpoint(basicBlock, patch, result, Vector&lt;ConstrainedTmp, sizeof...(Args)&gt;::from(theArgs...));
 389     }
 390 
 391     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result)
 392     {
 393         emitPatchpoint(basicBlock, patch, result, Vector&lt;ConstrainedTmp&gt;());
 394     }
 395 
 396     template &lt;size_t inlineSize&gt;
 397     void emitPatchpoint(BasicBlock* basicBlock, B3::PatchpointValue* patch, Tmp result, Vector&lt;ConstrainedTmp, inlineSize&gt;&amp;&amp; args)
 398     {
 399         if (!m_patchpointSpecial)
<a name="16" id="anc16"></a><span class="line-modified"> 400             m_patchpointSpecial = static_cast&lt;B3::PatchpointSpecial*&gt;(m_code.addSpecial(std::make_unique&lt;B3::PatchpointSpecial&gt;()));</span>
 401 
 402         Inst inst(Patch, patch, Arg::special(m_patchpointSpecial));
 403         Inst resultMov;
 404         if (result) {
 405             ASSERT(patch-&gt;type() != B3::Void);
<a name="17" id="anc17"></a><span class="line-modified"> 406             switch (patch-&gt;resultConstraint.kind()) {</span>
 407             case B3::ValueRep::Register:
<a name="18" id="anc18"></a><span class="line-modified"> 408                 inst.args.append(Tmp(patch-&gt;resultConstraint.reg()));</span>
<span class="line-modified"> 409                 resultMov = Inst(result.isGP() ? Move : MoveDouble, nullptr, Tmp(patch-&gt;resultConstraint.reg()), result);</span>
 410                 break;
 411             case B3::ValueRep::SomeRegister:
 412                 inst.args.append(result);
 413                 break;
 414             default:
 415                 RELEASE_ASSERT_NOT_REACHED();
 416             }
 417         } else
 418             ASSERT(patch-&gt;type() == B3::Void);
 419 
 420         for (ConstrainedTmp&amp; tmp : args) {
 421             // FIXME: This is less than ideal to create dummy values just to satisfy Air&#39;s
 422             // validation. We should abstrcat Patch enough so ValueRep&#39;s don&#39;t need to be
 423             // backed by Values.
 424             // https://bugs.webkit.org/show_bug.cgi?id=194040
 425             B3::Value* dummyValue = m_proc.addConstant(B3::Origin(), tmp.tmp.isGP() ? B3::Int64 : B3::Double, 0);
 426             patch-&gt;append(dummyValue, tmp.rep);
 427             switch (tmp.rep.kind()) {
<a name="19" id="anc19"></a>
 428             case B3::ValueRep::SomeRegister:
 429                 inst.args.append(tmp.tmp);
 430                 break;
 431             case B3::ValueRep::Register:
 432                 patch-&gt;earlyClobbered().clear(tmp.rep.reg());
 433                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, tmp.rep.reg());
 434                 inst.args.append(Tmp(tmp.rep.reg()));
 435                 break;
 436             case B3::ValueRep::StackArgument: {
 437                 auto arg = Arg::callArg(tmp.rep.offsetFromSP());
 438                 append(basicBlock, tmp.tmp.isGP() ? Move : MoveDouble, tmp.tmp, arg);
 439                 inst.args.append(arg);
 440                 break;
 441             }
 442             default:
 443                 RELEASE_ASSERT_NOT_REACHED();
 444             }
 445         }
 446 
<a name="20" id="anc20"></a><span class="line-modified"> 447         if (patch-&gt;resultConstraint.isReg())</span>
<span class="line-modified"> 448             patch-&gt;lateClobbered().clear(patch-&gt;resultConstraint.reg());</span>
 449         for (unsigned i = patch-&gt;numGPScratchRegisters; i--;)
 450             inst.args.append(g64().tmp());
 451         for (unsigned i = patch-&gt;numFPScratchRegisters; i--;)
 452             inst.args.append(f64().tmp());
 453 
 454         validateInst(inst);
 455         basicBlock-&gt;append(WTFMove(inst));
 456         if (resultMov) {
 457             validateInst(resultMov);
 458             basicBlock-&gt;append(WTFMove(resultMov));
 459         }
 460     }
 461 
 462     template &lt;typename Branch, typename Generator&gt;
 463     void emitCheck(const Branch&amp; makeBranch, const Generator&amp; generator)
 464     {
 465         // We fail along the truthy edge of &#39;branch&#39;.
 466         Inst branch = makeBranch();
 467 
 468         // FIXME: Make a hashmap of these.
 469         B3::CheckSpecial::Key key(branch);
<a name="21" id="anc21"></a><span class="line-modified"> 470         B3::CheckSpecial* special = static_cast&lt;B3::CheckSpecial*&gt;(m_code.addSpecial(std::make_unique&lt;B3::CheckSpecial&gt;(key)));</span>
 471 
 472         // FIXME: Remove the need for dummy values
 473         // https://bugs.webkit.org/show_bug.cgi?id=194040
 474         B3::Value* dummyPredicate = m_proc.addConstant(B3::Origin(), B3::Int32, 42);
 475         B3::CheckValue* checkValue = m_proc.add&lt;B3::CheckValue&gt;(B3::Check, B3::Origin(), dummyPredicate);
 476         checkValue-&gt;setGenerator(generator);
 477 
 478         Inst inst(Patch, checkValue, Arg::special(special));
 479         inst.args.appendVector(branch.args);
 480         m_currentBlock-&gt;append(WTFMove(inst));
 481     }
 482 
 483     template &lt;typename Func, typename ...Args&gt;
 484     void emitCCall(Func func, TypedTmp result, Args... args)
 485     {
 486         emitCCall(m_currentBlock, func, result, std::forward&lt;Args&gt;(args)...);
 487     }
 488     template &lt;typename Func, typename ...Args&gt;
 489     void emitCCall(BasicBlock* block, Func func, TypedTmp result, Args... theArgs)
 490     {
 491         B3::Type resultType = B3::Void;
 492         if (result) {
 493             switch (result.type()) {
 494             case Type::I32:
 495                 resultType = B3::Int32;
 496                 break;
 497             case Type::I64:
<a name="22" id="anc22"></a>

 498                 resultType = B3::Int64;
 499                 break;
 500             case Type::F32:
 501                 resultType = B3::Float;
 502                 break;
 503             case Type::F64:
 504                 resultType = B3::Double;
 505                 break;
 506             default:
 507                 RELEASE_ASSERT_NOT_REACHED();
 508             }
 509         }
 510 
 511         auto makeDummyValue = [&amp;] (Tmp tmp) {
 512             // FIXME: This is less than ideal to create dummy values just to satisfy Air&#39;s
 513             // validation. We should abstrcat CCall enough so we&#39;re not reliant on arguments
 514             // to the B3::CCallValue.
 515             // https://bugs.webkit.org/show_bug.cgi?id=194040
 516             if (tmp.isGP())
 517                 return m_proc.addConstant(B3::Origin(), B3::Int64, 0);
 518             return m_proc.addConstant(B3::Origin(), B3::Double, 0);
 519         };
 520 
 521         B3::Value* dummyFunc = m_proc.addConstant(B3::Origin(), B3::Int64, bitwise_cast&lt;uintptr_t&gt;(func));
 522         B3::Value* origin = m_proc.add&lt;B3::CCallValue&gt;(resultType, B3::Origin(), B3::Effects::none(), dummyFunc, makeDummyValue(theArgs)...);
 523 
 524         Inst inst(CCall, origin);
 525 
 526         Tmp callee = g64();
<a name="23" id="anc23"></a><span class="line-modified"> 527         append(Move, Arg::immPtr(tagCFunctionPtr&lt;void*&gt;(func, B3CCallPtrTag)), callee);</span>
 528         inst.args.append(callee);
 529 
 530         if (result)
 531             inst.args.append(result.tmp());
 532 
 533         for (Tmp tmp : Vector&lt;Tmp, sizeof...(Args)&gt;::from(theArgs.tmp()...))
 534             inst.args.append(tmp);
 535 
 536         block-&gt;append(WTFMove(inst));
 537     }
 538 
 539     static B3::Air::Opcode moveOpForValueType(Type type)
 540     {
 541         switch (type) {
 542         case Type::I32:
 543             return Move32;
 544         case Type::I64:
<a name="24" id="anc24"></a>

 545             return Move;
 546         case Type::F32:
 547             return MoveFloat;
 548         case Type::F64:
 549             return MoveDouble;
 550         default:
 551             RELEASE_ASSERT_NOT_REACHED();
 552         }
 553     }
 554 
 555     void emitThrowException(CCallHelpers&amp;, ExceptionType);
 556 
<a name="25" id="anc25"></a><span class="line-modified"> 557     void emitTierUpCheck(uint32_t decrementCount, B3::Origin);</span>

 558 
<a name="26" id="anc26"></a>
 559     ExpressionType emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOp);
 560     ExpressionType emitLoadOp(LoadOpType, ExpressionType pointer, uint32_t offset);
 561     void emitStoreOp(StoreOpType, ExpressionType pointer, ExpressionType value, uint32_t offset);
 562 
 563     void unify(const ExpressionType&amp; dst, const ExpressionType&amp; source);
<a name="27" id="anc27"></a><span class="line-modified"> 564     void unifyValuesWithBlock(const ExpressionList&amp; resultStack, const ResultList&amp; stack);</span>
 565 
 566     template &lt;typename IntType&gt;
 567     void emitChecksForModOrDiv(bool isSignedDiv, ExpressionType left, ExpressionType right);
 568 
 569     template &lt;typename IntType&gt;
 570     void emitModOrDiv(bool isDiv, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result);
 571 
<a name="28" id="anc28"></a>



 572     int32_t WARN_UNUSED_RETURN fixupPointerPlusOffset(ExpressionType&amp;, uint32_t);
 573 
 574     void restoreWasmContextInstance(BasicBlock*, TypedTmp);
 575     enum class RestoreCachedStackLimit { No, Yes };
 576     void restoreWebAssemblyGlobalState(RestoreCachedStackLimit, const MemoryInformation&amp;, TypedTmp instance, BasicBlock*);
 577 
 578     B3::Origin origin();
 579 
<a name="29" id="anc29"></a>






 580     FunctionParser&lt;AirIRGenerator&gt;* m_parser { nullptr };
 581     const ModuleInformation&amp; m_info;
 582     const MemoryMode m_mode { MemoryMode::BoundsChecking };
 583     const unsigned m_functionIndex { UINT_MAX };
<a name="30" id="anc30"></a><span class="line-modified"> 584     const TierUpCount* m_tierUp { nullptr };</span>
 585 
 586     B3::Procedure&amp; m_proc;
 587     Code&amp; m_code;
<a name="31" id="anc31"></a>
 588     BasicBlock* m_currentBlock { nullptr };
 589     BasicBlock* m_rootBlock { nullptr };
 590     Vector&lt;TypedTmp&gt; m_locals;
 591     Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; m_unlinkedWasmToWasmCalls; // List each call site and the function index whose address it should be patched with.
 592     GPRReg m_memoryBaseGPR { InvalidGPRReg };
 593     GPRReg m_memorySizeGPR { InvalidGPRReg };
 594     GPRReg m_wasmContextInstanceGPR { InvalidGPRReg };
 595     bool m_makesCalls { false };
 596 
 597     Vector&lt;Tmp, 8&gt; m_freeGPs;
 598     Vector&lt;Tmp, 8&gt; m_freeFPs;
 599 
<a name="32" id="anc32"></a>


 600     TypedTmp m_instanceValue; // Always use the accessor below to ensure the instance value is materialized when used.
 601     bool m_usesInstanceValue { false };
 602     TypedTmp instanceValue()
 603     {
 604         m_usesInstanceValue = true;
 605         return m_instanceValue;
 606     }
 607 
 608     uint32_t m_maxNumJSCallArguments { 0 };
<a name="33" id="anc33"></a>
 609 
 610     B3::PatchpointSpecial* m_patchpointSpecial { nullptr };
 611 };
 612 
 613 // Memory accesses in WebAssembly have unsigned 32-bit offsets, whereas they have signed 32-bit offsets in B3.
 614 int32_t AirIRGenerator::fixupPointerPlusOffset(ExpressionType&amp; ptr, uint32_t offset)
 615 {
 616     if (static_cast&lt;uint64_t&gt;(offset) &gt; static_cast&lt;uint64_t&gt;(std::numeric_limits&lt;int32_t&gt;::max())) {
 617         auto previousPtr = ptr;
 618         ptr = g64();
 619         auto constant = g64();
 620         append(Move, Arg::bigImm(offset), constant);
 621         append(Add64, constant, previousPtr, ptr);
 622         return 0;
 623     }
 624     return offset;
 625 }
 626 
 627 void AirIRGenerator::restoreWasmContextInstance(BasicBlock* block, TypedTmp instance)
 628 {
 629     if (Context::useFastTLS()) {
 630         auto* patchpoint = addPatchpoint(B3::Void);
 631         if (CCallHelpers::storeWasmContextInstanceNeedsMacroScratchRegister())
 632             patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
 633         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
 634             AllowMacroScratchRegisterUsageIf allowScratch(jit, CCallHelpers::storeWasmContextInstanceNeedsMacroScratchRegister());
 635             jit.storeWasmContextInstance(params[0].gpr());
 636         });
 637         emitPatchpoint(block, patchpoint, Tmp(), instance);
 638         return;
 639     }
 640 
 641     // FIXME: Because WasmToWasm call clobbers wasmContextInstance register and does not restore it, we need to restore it in the caller side.
 642     // This prevents us from using ArgumentReg to this (logically) immutable pinned register.
 643     auto* patchpoint = addPatchpoint(B3::Void);
 644     B3::Effects effects = B3::Effects::none();
 645     effects.writesPinned = true;
 646     effects.reads = B3::HeapRange::top();
 647     patchpoint-&gt;effects = effects;
 648     patchpoint-&gt;clobberLate(RegisterSet(m_wasmContextInstanceGPR));
 649     GPRReg wasmContextInstanceGPR = m_wasmContextInstanceGPR;
 650     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; param) {
 651         jit.move(param[0].gpr(), wasmContextInstanceGPR);
 652     });
 653     emitPatchpoint(block, patchpoint, Tmp(), instance);
 654 }
 655 
 656 AirIRGenerator::AirIRGenerator(const ModuleInformation&amp; info, B3::Procedure&amp; procedure, InternalFunction* compilation, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, MemoryMode mode, unsigned functionIndex, TierUpCount* tierUp, ThrowWasmException throwWasmException, const Signature&amp; signature)
 657     : m_info(info)
 658     , m_mode(mode)
 659     , m_functionIndex(functionIndex)
 660     , m_tierUp(tierUp)
 661     , m_proc(procedure)
 662     , m_code(m_proc.code())
 663     , m_unlinkedWasmToWasmCalls(unlinkedWasmToWasmCalls)
<a name="34" id="anc34"></a>
 664 {
 665     m_currentBlock = m_code.addBlock();
 666     m_rootBlock = m_currentBlock;
 667 
 668     // FIXME we don&#39;t really need to pin registers here if there&#39;s no memory. It makes wasm -&gt; wasm thunks simpler for now. https://bugs.webkit.org/show_bug.cgi?id=166623
 669     const PinnedRegisterInfo&amp; pinnedRegs = PinnedRegisterInfo::get();
 670 
 671     m_memoryBaseGPR = pinnedRegs.baseMemoryPointer;
 672     m_code.pinRegister(m_memoryBaseGPR);
 673 
 674     m_wasmContextInstanceGPR = pinnedRegs.wasmContextInstancePointer;
 675     if (!Context::useFastTLS())
 676         m_code.pinRegister(m_wasmContextInstanceGPR);
 677 
 678     if (mode != MemoryMode::Signaling) {
<a name="35" id="anc35"></a><span class="line-modified"> 679         ASSERT(!pinnedRegs.sizeRegisters[0].sizeOffset);</span>
<span class="line-modified"> 680         m_memorySizeGPR = pinnedRegs.sizeRegisters[0].sizeRegister;</span>
<span class="line-removed"> 681         for (const PinnedSizeRegisterInfo&amp; regInfo : pinnedRegs.sizeRegisters)</span>
<span class="line-removed"> 682             m_code.pinRegister(regInfo.sizeRegister);</span>
 683     }
 684 
 685     if (throwWasmException)
 686         Thunks::singleton().setThrowWasmException(throwWasmException);
 687 
 688     if (info.memory) {
 689         switch (m_mode) {
 690         case MemoryMode::BoundsChecking:
 691             break;
 692         case MemoryMode::Signaling:
 693             // Most memory accesses in signaling mode don&#39;t do an explicit
 694             // exception check because they can rely on fault handling to detect
 695             // out-of-bounds accesses. FaultSignalHandler nonetheless needs the
 696             // thunk to exist so that it can jump to that thunk.
 697             if (UNLIKELY(!Thunks::singleton().stub(throwExceptionFromWasmThunkGenerator)))
 698                 CRASH();
 699             break;
 700         }
 701     }
 702 
 703     m_code.setNumEntrypoints(1);
 704 
 705     GPRReg contextInstance = Context::useFastTLS() ? wasmCallingConventionAir().prologueScratch(1) : m_wasmContextInstanceGPR;
 706 
 707     Ref&lt;B3::Air::PrologueGenerator&gt; prologueGenerator = createSharedTask&lt;B3::Air::PrologueGeneratorFunction&gt;([=] (CCallHelpers&amp; jit, B3::Air::Code&amp; code) {
 708         AllowMacroScratchRegisterUsage allowScratch(jit);
 709         code.emitDefaultPrologue(jit);
 710 
 711         {
 712             GPRReg calleeGPR = wasmCallingConventionAir().prologueScratch(0);
 713             auto moveLocation = jit.moveWithPatch(MacroAssembler::TrustedImmPtr(nullptr), calleeGPR);
 714             jit.addLinkTask([compilation, moveLocation] (LinkBuffer&amp; linkBuffer) {
 715                 compilation-&gt;calleeMoveLocation = linkBuffer.locationOf&lt;WasmEntryPtrTag&gt;(moveLocation);
 716             });
 717             jit.emitPutToCallFrameHeader(calleeGPR, CallFrameSlot::callee);
 718             jit.emitPutToCallFrameHeader(nullptr, CallFrameSlot::codeBlock);
 719         }
 720 
 721         {
 722             const Checked&lt;int32_t&gt; wasmFrameSize = m_code.frameSize();
 723             const unsigned minimumParentCheckSize = WTF::roundUpToMultipleOf(stackAlignmentBytes(), 1024);
 724             const unsigned extraFrameSize = WTF::roundUpToMultipleOf(stackAlignmentBytes(), std::max&lt;uint32_t&gt;(
 725                 // This allows us to elide stack checks for functions that are terminal nodes in the call
 726                 // tree, (e.g they don&#39;t make any calls) and have a small enough frame size. This works by
 727                 // having any such terminal node have its parent caller include some extra size in its
 728                 // own check for it. The goal here is twofold:
 729                 // 1. Emit less code.
 730                 // 2. Try to speed things up by skipping stack checks.
 731                 minimumParentCheckSize,
 732                 // This allows us to elide stack checks in the Wasm -&gt; Embedder call IC stub. Since these will
 733                 // spill all arguments to the stack, we ensure that a stack check here covers the
 734                 // stack that such a stub would use.
 735                 (Checked&lt;uint32_t&gt;(m_maxNumJSCallArguments) * sizeof(Register) + jscCallingConvention().headerSizeInBytes()).unsafeGet()
 736             ));
 737             const int32_t checkSize = m_makesCalls ? (wasmFrameSize + extraFrameSize).unsafeGet() : wasmFrameSize.unsafeGet();
 738             bool needUnderflowCheck = static_cast&lt;unsigned&gt;(checkSize) &gt; Options::reservedZoneSize();
 739             bool needsOverflowCheck = m_makesCalls || wasmFrameSize &gt;= minimumParentCheckSize || needUnderflowCheck;
 740 
 741             // This allows leaf functions to not do stack checks if their frame size is within
 742             // certain limits since their caller would have already done the check.
 743             if (needsOverflowCheck) {
 744                 GPRReg scratch = wasmCallingConventionAir().prologueScratch(0);
 745 
 746                 if (Context::useFastTLS())
 747                     jit.loadWasmContextInstance(contextInstance);
 748 
 749                 jit.addPtr(CCallHelpers::TrustedImm32(-checkSize), GPRInfo::callFrameRegister, scratch);
 750                 MacroAssembler::JumpList overflow;
 751                 if (UNLIKELY(needUnderflowCheck))
 752                     overflow.append(jit.branchPtr(CCallHelpers::Above, scratch, GPRInfo::callFrameRegister));
 753                 overflow.append(jit.branchPtr(CCallHelpers::Below, scratch, CCallHelpers::Address(contextInstance, Instance::offsetOfCachedStackLimit())));
 754                 jit.addLinkTask([overflow] (LinkBuffer&amp; linkBuffer) {
 755                     linkBuffer.link(overflow, CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(throwStackOverflowFromWasmThunkGenerator).code()));
 756                 });
 757             } else if (m_usesInstanceValue &amp;&amp; Context::useFastTLS()) {
 758                 // No overflow check is needed, but the instance values still needs to be correct.
 759                 jit.loadWasmContextInstance(contextInstance);
 760             }
 761         }
 762     });
 763 
 764     m_code.setPrologueForEntrypoint(0, WTFMove(prologueGenerator));
 765 
 766     if (Context::useFastTLS()) {
 767         m_instanceValue = g64();
 768         // FIXME: Would be nice to only do this if we use instance value.
 769         append(Move, Tmp(contextInstance), m_instanceValue);
 770     } else
 771         m_instanceValue = { Tmp(contextInstance), Type::I64 };
 772 
 773     ASSERT(!m_locals.size());
 774     m_locals.grow(signature.argumentCount());
 775     for (unsigned i = 0; i &lt; signature.argumentCount(); ++i) {
 776         Type type = signature.argument(i);
 777         m_locals[i] = tmpForType(type);
 778     }
 779 
 780     wasmCallingConventionAir().loadArguments(signature, [&amp;] (const Arg&amp; arg, unsigned i) {
 781         switch (signature.argument(i)) {
 782         case Type::I32:
 783             append(Move32, arg, m_locals[i]);
 784             break;
 785         case Type::I64:
<a name="36" id="anc36"></a>

 786             append(Move, arg, m_locals[i]);
 787             break;
 788         case Type::F32:
 789             append(MoveFloat, arg, m_locals[i]);
 790             break;
 791         case Type::F64:
 792             append(MoveDouble, arg, m_locals[i]);
 793             break;
 794         default:
 795             RELEASE_ASSERT_NOT_REACHED();
 796         }
 797     });
 798 
<a name="37" id="anc37"></a><span class="line-modified"> 799     emitTierUpCheck(TierUpCount::functionEntryDecrement(), B3::Origin());</span>
 800 }
 801 
 802 void AirIRGenerator::restoreWebAssemblyGlobalState(RestoreCachedStackLimit restoreCachedStackLimit, const MemoryInformation&amp; memory, TypedTmp instance, BasicBlock* block)
 803 {
 804     restoreWasmContextInstance(block, instance);
 805 
 806     if (restoreCachedStackLimit == RestoreCachedStackLimit::Yes) {
 807         // The Instance caches the stack limit, but also knows where its canonical location is.
 808         static_assert(sizeof(decltype(static_cast&lt;Instance*&gt;(nullptr)-&gt;cachedStackLimit())) == sizeof(uint64_t), &quot;&quot;);
 809 
 810         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfPointerToActualStackLimit(), B3::Width64));
 811         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfCachedStackLimit(), B3::Width64));
 812         auto temp = g64();
 813         append(block, Move, Arg::addr(instanceValue(), Instance::offsetOfPointerToActualStackLimit()), temp);
 814         append(block, Move, Arg::addr(temp), temp);
 815         append(block, Move, temp, Arg::addr(instanceValue(), Instance::offsetOfCachedStackLimit()));
 816     }
 817 
 818     if (!!memory) {
 819         const PinnedRegisterInfo* pinnedRegs = &amp;PinnedRegisterInfo::get();
 820         RegisterSet clobbers;
 821         clobbers.set(pinnedRegs-&gt;baseMemoryPointer);
<a name="38" id="anc38"></a><span class="line-modified"> 822         for (auto info : pinnedRegs-&gt;sizeRegisters)</span>
<span class="line-modified"> 823             clobbers.set(info.sizeRegister);</span>

 824 
 825         auto* patchpoint = addPatchpoint(B3::Void);
 826         B3::Effects effects = B3::Effects::none();
 827         effects.writesPinned = true;
 828         effects.reads = B3::HeapRange::top();
 829         patchpoint-&gt;effects = effects;
 830         patchpoint-&gt;clobber(clobbers);
<a name="39" id="anc39"></a>
 831 
 832         patchpoint-&gt;setGenerator([pinnedRegs] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
<a name="40" id="anc40"></a>
 833             GPRReg baseMemory = pinnedRegs-&gt;baseMemoryPointer;
<a name="41" id="anc41"></a><span class="line-modified"> 834             const auto&amp; sizeRegs = pinnedRegs-&gt;sizeRegisters;</span>
<span class="line-modified"> 835             ASSERT(sizeRegs.size() &gt;= 1);</span>
<span class="line-modified"> 836             ASSERT(!sizeRegs[0].sizeOffset); // The following code assumes we start at 0, and calculates subsequent size registers relative to 0.</span>
<span class="line-removed"> 837             jit.loadPtr(CCallHelpers::Address(params[0].gpr(), Instance::offsetOfCachedMemorySize()), sizeRegs[0].sizeRegister);</span>
 838             jit.loadPtr(CCallHelpers::Address(params[0].gpr(), Instance::offsetOfCachedMemory()), baseMemory);
<a name="42" id="anc42"></a><span class="line-modified"> 839             for (unsigned i = 1; i &lt; sizeRegs.size(); ++i)</span>
<span class="line-modified"> 840                 jit.add64(CCallHelpers::TrustedImm32(-sizeRegs[i].sizeOffset), sizeRegs[0].sizeRegister, sizeRegs[i].sizeRegister);</span>
 841         });
 842 
 843         emitPatchpoint(block, patchpoint, Tmp(), instance);
 844     }
 845 }
 846 
 847 void AirIRGenerator::emitThrowException(CCallHelpers&amp; jit, ExceptionType type)
 848 {
 849     jit.move(CCallHelpers::TrustedImm32(static_cast&lt;uint32_t&gt;(type)), GPRInfo::argumentGPR1);
 850     auto jumpToExceptionStub = jit.jump();
 851 
 852     jit.addLinkTask([jumpToExceptionStub] (LinkBuffer&amp; linkBuffer) {
 853         linkBuffer.link(jumpToExceptionStub, CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(throwExceptionFromWasmThunkGenerator).code()));
 854     });
 855 }
 856 
 857 auto AirIRGenerator::addLocal(Type type, uint32_t count) -&gt; PartialResult
 858 {
<a name="43" id="anc43"></a><span class="line-modified"> 859     Checked&lt;uint32_t, RecordOverflow&gt; totalBytesChecked = count;</span>
<span class="line-modified"> 860     totalBytesChecked += m_locals.size();</span>
<span class="line-modified"> 861     uint32_t totalBytes;</span>
<span class="line-modified"> 862     WASM_COMPILE_FAIL_IF((totalBytesChecked.safeGet(totalBytes) == CheckedState::DidOverflow) || !m_locals.tryReserveCapacity(totalBytes), &quot;can&#39;t allocate memory for &quot;, totalBytes, &quot; locals&quot;);</span>
 863 
 864     for (uint32_t i = 0; i &lt; count; ++i) {
 865         auto local = tmpForType(type);
 866         m_locals.uncheckedAppend(local);
 867         switch (type) {
<a name="44" id="anc44"></a>



 868         case Type::I32:
 869         case Type::I64: {
 870             append(Xor64, local, local);
 871             break;
 872         }
 873         case Type::F32:
 874         case Type::F64: {
 875             auto temp = g64();
 876             // IEEE 754 &quot;0&quot; is just int32/64 zero.
 877             append(Xor64, temp, temp);
 878             append(type == Type::F32 ? Move32ToFloat : Move64ToDouble, temp, local);
 879             break;
 880         }
 881         default:
 882             RELEASE_ASSERT_NOT_REACHED();
 883         }
 884     }
 885     return { };
 886 }
 887 
 888 auto AirIRGenerator::addConstant(Type type, uint64_t value) -&gt; ExpressionType
 889 {
 890     return addConstant(m_currentBlock, type, value);
 891 }
 892 
 893 auto AirIRGenerator::addConstant(BasicBlock* block, Type type, uint64_t value) -&gt; ExpressionType
 894 {
 895     auto result = tmpForType(type);
 896     switch (type) {
 897     case Type::I32:
 898     case Type::I64:
<a name="45" id="anc45"></a>

 899         append(block, Move, Arg::bigImm(value), result);
 900         break;
 901     case Type::F32:
 902     case Type::F64: {
 903         auto tmp = g64();
 904         append(block, Move, Arg::bigImm(value), tmp);
 905         append(block, type == Type::F32 ? Move32ToFloat : Move64ToDouble, tmp, result);
 906         break;
 907     }
 908 
 909     default:
 910         RELEASE_ASSERT_NOT_REACHED();
 911     }
 912 
 913     return result;
 914 }
 915 
 916 auto AirIRGenerator::addArguments(const Signature&amp; signature) -&gt; PartialResult
 917 {
 918     RELEASE_ASSERT(m_locals.size() == signature.argumentCount()); // We handle arguments in the prologue
 919     return { };
 920 }
 921 
<a name="46" id="anc46"></a>








































































































 922 auto AirIRGenerator::getLocal(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
 923 {
 924     ASSERT(m_locals[index].tmp());
 925     result = tmpForType(m_locals[index].type());
 926     append(moveOpForValueType(m_locals[index].type()), m_locals[index].tmp(), result);
 927     return { };
 928 }
 929 
 930 auto AirIRGenerator::addUnreachable() -&gt; PartialResult
 931 {
 932     B3::PatchpointValue* unreachable = addPatchpoint(B3::Void);
 933     unreachable-&gt;setGenerator([this] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
 934         this-&gt;emitThrowException(jit, ExceptionType::Unreachable);
 935     });
 936     unreachable-&gt;effects.terminal = true;
 937     emitPatchpoint(unreachable, Tmp());
 938     return { };
 939 }
 940 
 941 auto AirIRGenerator::addGrowMemory(ExpressionType delta, ExpressionType&amp; result) -&gt; PartialResult
 942 {
 943     int32_t (*growMemory)(void*, Instance*, int32_t) = [] (void* callFrame, Instance* instance, int32_t delta) -&gt; int32_t {
 944         instance-&gt;storeTopCallFrame(callFrame);
 945 
 946         if (delta &lt; 0)
 947             return -1;
 948 
 949         auto grown = instance-&gt;memory()-&gt;grow(PageCount(delta));
 950         if (!grown) {
 951             switch (grown.error()) {
 952             case Memory::GrowFailReason::InvalidDelta:
 953             case Memory::GrowFailReason::InvalidGrowSize:
 954             case Memory::GrowFailReason::WouldExceedMaximum:
 955             case Memory::GrowFailReason::OutOfMemory:
 956                 return -1;
 957             }
 958             RELEASE_ASSERT_NOT_REACHED();
 959         }
 960 
 961         return grown.value().pageCount();
 962     };
 963 
 964     result = g32();
 965     emitCCall(growMemory, result, TypedTmp { Tmp(GPRInfo::callFrameRegister), Type::I64 }, instanceValue(), delta);
 966     restoreWebAssemblyGlobalState(RestoreCachedStackLimit::No, m_info.memory, instanceValue(), m_currentBlock);
 967 
 968     return { };
 969 }
 970 
 971 auto AirIRGenerator::addCurrentMemory(ExpressionType&amp; result) -&gt; PartialResult
 972 {
 973     static_assert(sizeof(decltype(static_cast&lt;Memory*&gt;(nullptr)-&gt;size())) == sizeof(uint64_t), &quot;codegen relies on this size&quot;);
 974 
 975     auto temp1 = g64();
 976     auto temp2 = g64();
 977 
 978     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfCachedMemorySize(), B3::Width64));
 979     append(Move, Arg::addr(instanceValue(), Instance::offsetOfCachedMemorySize()), temp1);
 980     constexpr uint32_t shiftValue = 16;
 981     static_assert(PageCount::pageSize == 1ull &lt;&lt; shiftValue, &quot;This must hold for the code below to be correct.&quot;);
 982     append(Move, Arg::imm(16), temp2);
 983     addShift(Type::I32, Urshift64, temp1, temp2, result);
 984     append(Move32, result, result);
 985 
 986     return { };
 987 }
 988 
 989 auto AirIRGenerator::setLocal(uint32_t index, ExpressionType value) -&gt; PartialResult
 990 {
 991     ASSERT(m_locals[index].tmp());
 992     append(moveOpForValueType(m_locals[index].type()), value, m_locals[index].tmp());
 993     return { };
 994 }
 995 
 996 auto AirIRGenerator::getGlobal(uint32_t index, ExpressionType&amp; result) -&gt; PartialResult
 997 {
 998     Type type = m_info.globals[index].type;
 999 
1000     result = tmpForType(type);
1001 
1002     auto temp = g64();
1003 
1004     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfGlobals(), B3::Width64));
1005     append(Move, Arg::addr(instanceValue(), Instance::offsetOfGlobals()), temp);
1006 
1007     int32_t offset = safeCast&lt;int32_t&gt;(index * sizeof(Register));
1008     if (Arg::isValidAddrForm(offset, B3::widthForType(toB3Type(type))))
1009         append(moveOpForValueType(type), Arg::addr(temp, offset), result);
1010     else {
1011         auto temp2 = g64();
1012         append(Move, Arg::bigImm(offset), temp2);
1013         append(Add64, temp2, temp, temp);
1014         append(moveOpForValueType(type), Arg::addr(temp), result);
1015     }
1016     return { };
1017 }
1018 
1019 auto AirIRGenerator::setGlobal(uint32_t index, ExpressionType value) -&gt; PartialResult
1020 {
1021     auto temp = g64();
1022 
1023     RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfGlobals(), B3::Width64));
1024     append(Move, Arg::addr(instanceValue(), Instance::offsetOfGlobals()), temp);
1025 
1026     Type type = m_info.globals[index].type;
1027 
1028     int32_t offset = safeCast&lt;int32_t&gt;(index * sizeof(Register));
1029     if (Arg::isValidAddrForm(offset, B3::widthForType(toB3Type(type))))
1030         append(moveOpForValueType(type), value, Arg::addr(temp, offset));
1031     else {
1032         auto temp2 = g64();
1033         append(Move, Arg::bigImm(offset), temp2);
1034         append(Add64, temp2, temp, temp);
1035         append(moveOpForValueType(type), value, Arg::addr(temp));
1036     }
1037 
<a name="47" id="anc47"></a>


1038     return { };
1039 }
1040 
<a name="48" id="anc48"></a>















































1041 inline AirIRGenerator::ExpressionType AirIRGenerator::emitCheckAndPreparePointer(ExpressionType pointer, uint32_t offset, uint32_t sizeOfOperation)
1042 {
1043     ASSERT(m_memoryBaseGPR);
1044 
1045     auto result = g64();
1046     append(Move32, pointer, result);
1047 
1048     switch (m_mode) {
1049     case MemoryMode::BoundsChecking: {
1050         // We&#39;re not using signal handling at all, we must therefore check that no memory access exceeds the current memory size.
1051         ASSERT(m_memorySizeGPR);
1052         ASSERT(sizeOfOperation + offset &gt; offset);
1053         auto temp = g64();
1054         append(Move, Arg::bigImm(static_cast&lt;uint64_t&gt;(sizeOfOperation) + offset - 1), temp);
1055         append(Add64, result, temp);
1056 
1057         emitCheck([&amp;] {
1058             return Inst(Branch64, nullptr, Arg::relCond(MacroAssembler::AboveOrEqual), temp, Tmp(m_memorySizeGPR));
1059         }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1060             this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsMemoryAccess);
1061         });
1062         break;
1063     }
1064 
1065     case MemoryMode::Signaling: {
1066         // We&#39;ve virtually mapped 4GiB+redzone for this memory. Only the user-allocated pages are addressable, contiguously in range [0, current],
1067         // and everything above is mapped PROT_NONE. We don&#39;t need to perform any explicit bounds check in the 4GiB range because WebAssembly register
1068         // memory accesses are 32-bit. However WebAssembly register + offset accesses perform the addition in 64-bit which can push an access above
1069         // the 32-bit limit (the offset is unsigned 32-bit). The redzone will catch most small offsets, and we&#39;ll explicitly bounds check any
1070         // register + large offset access. We don&#39;t think this will be generated frequently.
1071         //
1072         // We could check that register + large offset doesn&#39;t exceed 4GiB+redzone since that&#39;s technically the limit we need to avoid overflowing the
1073         // PROT_NONE region, but it&#39;s better if we use a smaller immediate because it can codegens better. We know that anything equal to or greater
1074         // than the declared &#39;maximum&#39; will trap, so we can compare against that number. If there was no declared &#39;maximum&#39; then we still know that
1075         // any access equal to or greater than 4GiB will trap, no need to add the redzone.
1076         if (offset &gt;= Memory::fastMappedRedzoneBytes()) {
1077             uint64_t maximum = m_info.memory.maximum() ? m_info.memory.maximum().bytes() : std::numeric_limits&lt;uint32_t&gt;::max();
1078             auto temp = g64();
1079             append(Move, Arg::bigImm(static_cast&lt;uint64_t&gt;(sizeOfOperation) + offset - 1), temp);
1080             append(Add64, result, temp);
1081             auto sizeMax = addConstant(Type::I64, maximum);
1082 
1083             emitCheck([&amp;] {
1084                 return Inst(Branch64, nullptr, Arg::relCond(MacroAssembler::AboveOrEqual), temp, sizeMax);
1085             }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1086                 this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsMemoryAccess);
1087             });
1088         }
1089         break;
1090     }
1091     }
1092 
1093     append(Add64, Tmp(m_memoryBaseGPR), result);
1094     return result;
1095 }
1096 
1097 inline uint32_t sizeOfLoadOp(LoadOpType op)
1098 {
1099     switch (op) {
1100     case LoadOpType::I32Load8S:
1101     case LoadOpType::I32Load8U:
1102     case LoadOpType::I64Load8S:
1103     case LoadOpType::I64Load8U:
1104         return 1;
1105     case LoadOpType::I32Load16S:
1106     case LoadOpType::I64Load16S:
1107     case LoadOpType::I32Load16U:
1108     case LoadOpType::I64Load16U:
1109         return 2;
1110     case LoadOpType::I32Load:
1111     case LoadOpType::I64Load32S:
1112     case LoadOpType::I64Load32U:
1113     case LoadOpType::F32Load:
1114         return 4;
1115     case LoadOpType::I64Load:
1116     case LoadOpType::F64Load:
1117         return 8;
1118     }
1119     RELEASE_ASSERT_NOT_REACHED();
1120 }
1121 
1122 inline TypedTmp AirIRGenerator::emitLoadOp(LoadOpType op, ExpressionType pointer, uint32_t uoffset)
1123 {
1124     uint32_t offset = fixupPointerPlusOffset(pointer, uoffset);
1125 
1126     TypedTmp immTmp;
1127     TypedTmp newPtr;
1128     TypedTmp result;
1129 
1130     Arg addrArg;
1131     if (Arg::isValidAddrForm(offset, B3::widthForBytes(sizeOfLoadOp(op))))
1132         addrArg = Arg::addr(pointer, offset);
1133     else {
1134         immTmp = g64();
1135         newPtr = g64();
1136         append(Move, Arg::bigImm(offset), immTmp);
1137         append(Add64, immTmp, pointer, newPtr);
1138         addrArg = Arg::addr(newPtr);
1139     }
1140 
1141     switch (op) {
1142     case LoadOpType::I32Load8S: {
1143         result = g32();
1144         appendEffectful(Load8SignedExtendTo32, addrArg, result);
1145         break;
1146     }
1147 
1148     case LoadOpType::I64Load8S: {
1149         result = g64();
1150         appendEffectful(Load8SignedExtendTo32, addrArg, result);
1151         append(SignExtend32ToPtr, result, result);
1152         break;
1153     }
1154 
1155     case LoadOpType::I32Load8U: {
1156         result = g32();
1157         appendEffectful(Load8, addrArg, result);
1158         break;
1159     }
1160 
1161     case LoadOpType::I64Load8U: {
1162         result = g64();
1163         appendEffectful(Load8, addrArg, result);
1164         break;
1165     }
1166 
1167     case LoadOpType::I32Load16S: {
1168         result = g32();
1169         appendEffectful(Load16SignedExtendTo32, addrArg, result);
1170         break;
1171     }
1172 
1173     case LoadOpType::I64Load16S: {
1174         result = g64();
1175         appendEffectful(Load16SignedExtendTo32, addrArg, result);
1176         append(SignExtend32ToPtr, result, result);
1177         break;
1178     }
1179 
1180     case LoadOpType::I32Load16U: {
1181         result = g32();
1182         appendEffectful(Load16, addrArg, result);
1183         break;
1184     }
1185 
1186     case LoadOpType::I64Load16U: {
1187         result = g64();
1188         appendEffectful(Load16, addrArg, result);
1189         break;
1190     }
1191 
1192     case LoadOpType::I32Load:
1193         result = g32();
1194         appendEffectful(Move32, addrArg, result);
1195         break;
1196 
1197     case LoadOpType::I64Load32U: {
1198         result = g64();
1199         appendEffectful(Move32, addrArg, result);
1200         break;
1201     }
1202 
1203     case LoadOpType::I64Load32S: {
1204         result = g64();
1205         appendEffectful(Move32, addrArg, result);
1206         append(SignExtend32ToPtr, result, result);
1207         break;
1208     }
1209 
1210     case LoadOpType::I64Load: {
1211         result = g64();
1212         appendEffectful(Move, addrArg, result);
1213         break;
1214     }
1215 
1216     case LoadOpType::F32Load: {
1217         result = f32();
1218         appendEffectful(MoveFloat, addrArg, result);
1219         break;
1220     }
1221 
1222     case LoadOpType::F64Load: {
1223         result = f64();
1224         appendEffectful(MoveDouble, addrArg, result);
1225         break;
1226     }
1227     }
1228 
1229     return result;
1230 }
1231 
1232 auto AirIRGenerator::load(LoadOpType op, ExpressionType pointer, ExpressionType&amp; result, uint32_t offset) -&gt; PartialResult
1233 {
1234     ASSERT(pointer.tmp().isGP());
1235 
1236     if (UNLIKELY(sumOverflows&lt;uint32_t&gt;(offset, sizeOfLoadOp(op)))) {
1237         // FIXME: Even though this is provably out of bounds, it&#39;s not a validation error, so we have to handle it
1238         // as a runtime exception. However, this may change: https://bugs.webkit.org/show_bug.cgi?id=166435
1239         auto* patch = addPatchpoint(B3::Void);
1240         patch-&gt;setGenerator([this] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1241             this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsMemoryAccess);
1242         });
1243         emitPatchpoint(patch, Tmp());
1244 
1245         // We won&#39;t reach here, so we just pick a random reg.
1246         switch (op) {
1247         case LoadOpType::I32Load8S:
1248         case LoadOpType::I32Load16S:
1249         case LoadOpType::I32Load:
1250         case LoadOpType::I32Load16U:
1251         case LoadOpType::I32Load8U:
1252             result = g32();
1253             break;
1254         case LoadOpType::I64Load8S:
1255         case LoadOpType::I64Load8U:
1256         case LoadOpType::I64Load16S:
1257         case LoadOpType::I64Load32U:
1258         case LoadOpType::I64Load32S:
1259         case LoadOpType::I64Load:
1260         case LoadOpType::I64Load16U:
1261             result = g64();
1262             break;
1263         case LoadOpType::F32Load:
1264             result = f32();
1265             break;
1266         case LoadOpType::F64Load:
1267             result = f64();
1268             break;
1269         }
1270     } else
1271         result = emitLoadOp(op, emitCheckAndPreparePointer(pointer, offset, sizeOfLoadOp(op)), offset);
1272 
1273     return { };
1274 }
1275 
1276 inline uint32_t sizeOfStoreOp(StoreOpType op)
1277 {
1278     switch (op) {
1279     case StoreOpType::I32Store8:
1280     case StoreOpType::I64Store8:
1281         return 1;
1282     case StoreOpType::I32Store16:
1283     case StoreOpType::I64Store16:
1284         return 2;
1285     case StoreOpType::I32Store:
1286     case StoreOpType::I64Store32:
1287     case StoreOpType::F32Store:
1288         return 4;
1289     case StoreOpType::I64Store:
1290     case StoreOpType::F64Store:
1291         return 8;
1292     }
1293     RELEASE_ASSERT_NOT_REACHED();
1294 }
1295 
1296 
1297 inline void AirIRGenerator::emitStoreOp(StoreOpType op, ExpressionType pointer, ExpressionType value, uint32_t uoffset)
1298 {
1299     uint32_t offset = fixupPointerPlusOffset(pointer, uoffset);
1300 
1301     TypedTmp immTmp;
1302     TypedTmp newPtr;
1303 
1304     Arg addrArg;
1305     if (Arg::isValidAddrForm(offset, B3::widthForBytes(sizeOfStoreOp(op))))
1306         addrArg = Arg::addr(pointer, offset);
1307     else {
1308         immTmp = g64();
1309         newPtr = g64();
1310         append(Move, Arg::bigImm(offset), immTmp);
1311         append(Add64, immTmp, pointer, newPtr);
1312         addrArg = Arg::addr(newPtr);
1313     }
1314 
1315     switch (op) {
1316     case StoreOpType::I64Store8:
1317     case StoreOpType::I32Store8:
1318         append(Store8, value, addrArg);
1319         return;
1320 
1321     case StoreOpType::I64Store16:
1322     case StoreOpType::I32Store16:
1323         append(Store16, value, addrArg);
1324         return;
1325 
1326     case StoreOpType::I64Store32:
1327     case StoreOpType::I32Store:
1328         append(Move32, value, addrArg);
1329         return;
1330 
1331     case StoreOpType::I64Store:
1332         append(Move, value, addrArg);
1333         return;
1334 
1335     case StoreOpType::F32Store:
1336         append(MoveFloat, value, addrArg);
1337         return;
1338 
1339     case StoreOpType::F64Store:
1340         append(MoveDouble, value, addrArg);
1341         return;
1342     }
1343 
1344     RELEASE_ASSERT_NOT_REACHED();
1345 }
1346 
1347 auto AirIRGenerator::store(StoreOpType op, ExpressionType pointer, ExpressionType value, uint32_t offset) -&gt; PartialResult
1348 {
1349     ASSERT(pointer.tmp().isGP());
1350 
1351     if (UNLIKELY(sumOverflows&lt;uint32_t&gt;(offset, sizeOfStoreOp(op)))) {
1352         // FIXME: Even though this is provably out of bounds, it&#39;s not a validation error, so we have to handle it
1353         // as a runtime exception. However, this may change: https://bugs.webkit.org/show_bug.cgi?id=166435
1354         auto* throwException = addPatchpoint(B3::Void);
1355         throwException-&gt;setGenerator([this] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1356             this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsMemoryAccess);
1357         });
1358         emitPatchpoint(throwException, Tmp());
1359     } else
1360         emitStoreOp(op, emitCheckAndPreparePointer(pointer, offset, sizeOfStoreOp(op)), value, offset);
1361 
1362     return { };
1363 }
1364 
1365 auto AirIRGenerator::addSelect(ExpressionType condition, ExpressionType nonZero, ExpressionType zero, ExpressionType&amp; result) -&gt; PartialResult
1366 {
1367     ASSERT(nonZero.type() == zero.type());
1368     result = tmpForType(nonZero.type());
1369     append(moveOpForValueType(nonZero.type()), nonZero, result);
1370 
1371     BasicBlock* isZero = m_code.addBlock();
1372     BasicBlock* continuation = m_code.addBlock();
1373 
1374     append(BranchTest32, Arg::resCond(MacroAssembler::Zero), condition, condition);
1375     m_currentBlock-&gt;setSuccessors(isZero, continuation);
1376 
1377     append(isZero, moveOpForValueType(zero.type()), zero, result);
1378     append(isZero, Jump);
1379     isZero-&gt;setSuccessors(continuation);
1380 
1381     m_currentBlock = continuation;
1382 
1383     return { };
1384 }
1385 
<a name="49" id="anc49"></a><span class="line-modified">1386 void AirIRGenerator::emitTierUpCheck(uint32_t decrementCount, B3::Origin origin)</span>
1387 {
1388     UNUSED_PARAM(origin);
1389 
1390     if (!m_tierUp)
1391         return;
1392 
1393     auto countdownPtr = g64();
<a name="50" id="anc50"></a><span class="line-removed">1394     auto oldCountdown = g64();</span>
<span class="line-removed">1395     auto newCountdown = g64();</span>
<span class="line-removed">1396 </span>
<span class="line-removed">1397     append(Move, Arg::bigImm(reinterpret_cast&lt;uint64_t&gt;(m_tierUp)), countdownPtr);</span>
<span class="line-removed">1398     append(Move32, Arg::addr(countdownPtr), oldCountdown);</span>
1399 
<a name="51" id="anc51"></a><span class="line-modified">1400     RELEASE_ASSERT(Arg::isValidImmForm(decrementCount));</span>
<span class="line-removed">1401     append(Move32, oldCountdown, newCountdown);</span>
<span class="line-removed">1402     append(Sub32, Arg::imm(decrementCount), newCountdown);</span>
<span class="line-removed">1403     append(Move32, newCountdown, Arg::addr(countdownPtr));</span>
1404 
1405     auto* patch = addPatchpoint(B3::Void);
1406     B3::Effects effects = B3::Effects::none();
1407     effects.reads = B3::HeapRange::top();
1408     effects.writes = B3::HeapRange::top();
1409     patch-&gt;effects = effects;
<a name="52" id="anc52"></a>
1410 
1411     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
<a name="53" id="anc53"></a><span class="line-modified">1412         MacroAssembler::Jump tierUp = jit.branch32(MacroAssembler::Above, params[0].gpr(), params[1].gpr());</span>
<span class="line-modified">1413         MacroAssembler::Label tierUpResume = jit.label();</span>


1414 
1415         params.addLatePath([=] (CCallHelpers&amp; jit) {
1416             tierUp.link(&amp;jit);
1417 
1418             const unsigned extraPaddingBytes = 0;
1419             RegisterSet registersToSpill = { };
1420             registersToSpill.add(GPRInfo::argumentGPR1);
1421             unsigned numberOfStackBytesUsedForRegisterPreservation = ScratchRegisterAllocator::preserveRegistersToStackForCall(jit, registersToSpill, extraPaddingBytes);
1422 
1423             jit.move(MacroAssembler::TrustedImm32(m_functionIndex), GPRInfo::argumentGPR1);
1424             MacroAssembler::Call call = jit.nearCall();
1425 
1426             ScratchRegisterAllocator::restoreRegistersFromStackForCall(jit, registersToSpill, RegisterSet(), numberOfStackBytesUsedForRegisterPreservation, extraPaddingBytes);
1427             jit.jump(tierUpResume);
1428 
1429             jit.addLinkTask([=] (LinkBuffer&amp; linkBuffer) {
<a name="54" id="anc54"></a><span class="line-modified">1430                 MacroAssembler::repatchNearCall(linkBuffer.locationOfNearCall&lt;NoPtrTag&gt;(call), CodeLocationLabel&lt;JITThunkPtrTag&gt;(Thunks::singleton().stub(triggerOMGTierUpThunkGenerator).code()));</span>
<span class="line-removed">1431 </span>
1432             });
1433         });
1434     });
1435 
<a name="55" id="anc55"></a><span class="line-modified">1436     emitPatchpoint(patch, Tmp(), newCountdown, oldCountdown);</span>
1437 }
1438 
<a name="56" id="anc56"></a><span class="line-modified">1439 AirIRGenerator::ControlData AirIRGenerator::addLoop(Type signature)</span>




































































1440 {
1441     BasicBlock* body = m_code.addBlock();
1442     BasicBlock* continuation = m_code.addBlock();
1443 
1444     append(Jump);
1445     m_currentBlock-&gt;setSuccessors(body);
1446 
<a name="57" id="anc57"></a>

1447     m_currentBlock = body;
<a name="58" id="anc58"></a><span class="line-modified">1448     emitTierUpCheck(TierUpCount::loopDecrement(), origin());</span>
1449 
1450     return ControlData(origin(), signature, tmpForType(signature), BlockType::Loop, continuation, body);
1451 }
1452 
1453 AirIRGenerator::ControlData AirIRGenerator::addTopLevel(Type signature)
1454 {
1455     return ControlData(B3::Origin(), signature, tmpForType(signature), BlockType::TopLevel, m_code.addBlock());
1456 }
1457 
1458 AirIRGenerator::ControlData AirIRGenerator::addBlock(Type signature)
1459 {
1460     return ControlData(origin(), signature, tmpForType(signature), BlockType::Block, m_code.addBlock());
1461 }
1462 
1463 auto AirIRGenerator::addIf(ExpressionType condition, Type signature, ControlType&amp; result) -&gt; PartialResult
1464 {
1465     BasicBlock* taken = m_code.addBlock();
1466     BasicBlock* notTaken = m_code.addBlock();
1467     BasicBlock* continuation = m_code.addBlock();
1468 
1469     // Wasm bools are i32.
1470     append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1471     m_currentBlock-&gt;setSuccessors(taken, notTaken);
1472 
1473     m_currentBlock = taken;
1474     result = ControlData(origin(), signature, tmpForType(signature), BlockType::If, continuation, notTaken);
1475     return { };
1476 }
1477 
<a name="59" id="anc59"></a><span class="line-modified">1478 auto AirIRGenerator::addElse(ControlData&amp; data, const ExpressionList&amp; currentStack) -&gt; PartialResult</span>
1479 {
1480     unifyValuesWithBlock(currentStack, data.result);
1481     append(Jump);
1482     m_currentBlock-&gt;setSuccessors(data.continuation);
1483     return addElseToUnreachable(data);
1484 }
1485 
1486 auto AirIRGenerator::addElseToUnreachable(ControlData&amp; data) -&gt; PartialResult
1487 {
1488     ASSERT(data.type() == BlockType::If);
1489     m_currentBlock = data.special;
1490     data.convertIfToBlock();
1491     return { };
1492 }
1493 
1494 auto AirIRGenerator::addReturn(const ControlData&amp; data, const ExpressionList&amp; returnValues) -&gt; PartialResult
1495 {
1496     ASSERT(returnValues.size() &lt;= 1);
1497     if (returnValues.size()) {
1498         Tmp returnValueGPR = Tmp(GPRInfo::returnValueGPR);
1499         Tmp returnValueFPR = Tmp(FPRInfo::returnValueFPR);
1500         switch (data.signature()) {
1501         case Type::I32:
1502             append(Move32, returnValues[0], returnValueGPR);
1503             append(Ret32, returnValueGPR);
1504             break;
1505         case Type::I64:
<a name="60" id="anc60"></a>

1506             append(Move, returnValues[0], returnValueGPR);
1507             append(Ret64, returnValueGPR);
1508             break;
1509         case Type::F32:
1510             append(MoveFloat, returnValues[0], returnValueFPR);
1511             append(RetFloat, returnValueFPR);
1512             break;
1513         case Type::F64:
1514             append(MoveDouble, returnValues[0], returnValueFPR);
1515             append(RetFloat, returnValueFPR);
1516             break;
1517         default:
1518             RELEASE_ASSERT_NOT_REACHED();
1519         }
1520     } else
1521         append(RetVoid);
1522     return { };
1523 }
1524 
1525 // NOTE: All branches in Wasm are on 32-bit ints
1526 
<a name="61" id="anc61"></a><span class="line-modified">1527 auto AirIRGenerator::addBranch(ControlData&amp; data, ExpressionType condition, const ExpressionList&amp; returnValues) -&gt; PartialResult</span>
1528 {
1529     unifyValuesWithBlock(returnValues, data.resultForBranch());
1530 
1531     BasicBlock* target = data.targetBlockForBranch();
1532     if (condition) {
1533         BasicBlock* continuation = m_code.addBlock();
1534         append(BranchTest32, Arg::resCond(MacroAssembler::NonZero), condition, condition);
1535         m_currentBlock-&gt;setSuccessors(target, continuation);
1536         m_currentBlock = continuation;
1537     } else {
1538         append(Jump);
1539         m_currentBlock-&gt;setSuccessors(target);
1540     }
1541 
1542     return { };
1543 }
1544 
<a name="62" id="anc62"></a><span class="line-modified">1545 auto AirIRGenerator::addSwitch(ExpressionType condition, const Vector&lt;ControlData*&gt;&amp; targets, ControlData&amp; defaultTarget, const ExpressionList&amp; expressionStack) -&gt; PartialResult</span>
1546 {
1547     auto&amp; successors = m_currentBlock-&gt;successors();
1548     ASSERT(successors.isEmpty());
1549     for (const auto&amp; target : targets) {
1550         unifyValuesWithBlock(expressionStack, target-&gt;resultForBranch());
1551         successors.append(target-&gt;targetBlockForBranch());
1552     }
1553     unifyValuesWithBlock(expressionStack, defaultTarget.resultForBranch());
1554     successors.append(defaultTarget.targetBlockForBranch());
1555 
1556     ASSERT(condition.type() == Type::I32);
1557 
1558     // FIXME: We should consider dynamically switching between a jump table
1559     // and a binary switch depending on the number of successors.
1560     // https://bugs.webkit.org/show_bug.cgi?id=194477
1561 
1562     size_t numTargets = targets.size();
1563 
1564     auto* patchpoint = addPatchpoint(B3::Void);
1565     patchpoint-&gt;effects = B3::Effects::none();
1566     patchpoint-&gt;effects.terminal = true;
1567     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
1568 
1569     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1570         AllowMacroScratchRegisterUsage allowScratch(jit);
1571 
1572         Vector&lt;int64_t&gt; cases;
1573         cases.reserveInitialCapacity(numTargets);
1574         for (size_t i = 0; i &lt; numTargets; ++i)
1575             cases.uncheckedAppend(i);
1576 
1577         GPRReg valueReg = params[0].gpr();
1578         BinarySwitch binarySwitch(valueReg, cases, BinarySwitch::Int32);
1579 
1580         Vector&lt;CCallHelpers::Jump&gt; caseJumps;
1581         caseJumps.resize(numTargets);
1582 
1583         while (binarySwitch.advance(jit)) {
1584             unsigned value = binarySwitch.caseValue();
1585             unsigned index = binarySwitch.caseIndex();
1586             ASSERT_UNUSED(value, value == index);
1587             ASSERT(index &lt; numTargets);
1588             caseJumps[index] = jit.jump();
1589         }
1590 
1591         CCallHelpers::JumpList fallThrough = binarySwitch.fallThrough();
1592 
1593         Vector&lt;Box&lt;CCallHelpers::Label&gt;&gt; successorLabels = params.successorLabels();
1594         ASSERT(successorLabels.size() == caseJumps.size() + 1);
1595 
1596         params.addLatePath([=, caseJumps = WTFMove(caseJumps), successorLabels = WTFMove(successorLabels)] (CCallHelpers&amp; jit) {
1597             for (size_t i = 0; i &lt; numTargets; ++i)
1598                 caseJumps[i].linkTo(*successorLabels[i], &amp;jit);
1599             fallThrough.linkTo(*successorLabels[numTargets], &amp;jit);
1600         });
1601     });
1602 
1603     emitPatchpoint(patchpoint, TypedTmp(), condition);
1604 
1605     return { };
1606 }
1607 
<a name="63" id="anc63"></a><span class="line-modified">1608 auto AirIRGenerator::endBlock(ControlEntry&amp; entry, ExpressionList&amp; expressionStack) -&gt; PartialResult</span>
1609 {
1610     ControlData&amp; data = entry.controlData;
1611 
1612     unifyValuesWithBlock(expressionStack, data.result);
1613     append(Jump);
1614     m_currentBlock-&gt;setSuccessors(data.continuation);
1615 
1616     return addEndToUnreachable(entry);
1617 }
1618 
1619 
1620 auto AirIRGenerator::addEndToUnreachable(ControlEntry&amp; entry) -&gt; PartialResult
1621 {
1622     ControlData&amp; data = entry.controlData;
1623     m_currentBlock = data.continuation;
1624 
1625     if (data.type() == BlockType::If) {
1626         append(data.special, Jump);
1627         data.special-&gt;setSuccessors(m_currentBlock);
1628     }
1629 
<a name="64" id="anc64"></a>


1630     for (const auto&amp; result : data.result)
1631         entry.enclosedExpressionStack.append(result);
1632 
1633     // TopLevel does not have any code after this so we need to make sure we emit a return here.
1634     if (data.type() == BlockType::TopLevel)
1635         return addReturn(data, entry.enclosedExpressionStack);
1636 
1637     return { };
1638 }
1639 
1640 auto AirIRGenerator::addCall(uint32_t functionIndex, const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result) -&gt; PartialResult
1641 {
1642     ASSERT(signature.argumentCount() == args.size());
1643 
1644     m_makesCalls = true;
1645 
1646     Type returnType = signature.returnType();
1647     if (returnType != Type::Void)
1648         result = tmpForType(returnType);
1649 
1650     Vector&lt;UnlinkedWasmToWasmCall&gt;* unlinkedWasmToWasmCalls = &amp;m_unlinkedWasmToWasmCalls;
1651 
1652     if (m_info.isImportedFunctionFromFunctionIndexSpace(functionIndex)) {
1653         m_maxNumJSCallArguments = std::max(m_maxNumJSCallArguments, static_cast&lt;uint32_t&gt;(args.size()));
1654 
1655         auto currentInstance = g64();
1656         append(Move, instanceValue(), currentInstance);
1657 
1658         auto targetInstance = g64();
1659 
1660         // FIXME: We should have better isel here.
1661         // https://bugs.webkit.org/show_bug.cgi?id=193999
1662         append(Move, Arg::bigImm(Instance::offsetOfTargetInstance(functionIndex)), targetInstance);
1663         append(Add64, instanceValue(), targetInstance);
1664         append(Move, Arg::addr(targetInstance), targetInstance);
1665 
1666         BasicBlock* isWasmBlock = m_code.addBlock();
1667         BasicBlock* isEmbedderBlock = m_code.addBlock();
1668         BasicBlock* continuation = m_code.addBlock();
1669 
1670         append(BranchTest64, Arg::resCond(MacroAssembler::NonZero), targetInstance, targetInstance);
1671         m_currentBlock-&gt;setSuccessors(isWasmBlock, isEmbedderBlock);
1672 
1673         {
1674             auto* patchpoint = addPatchpoint(toB3Type(returnType));
1675             patchpoint-&gt;effects.writesPinned = true;
1676             patchpoint-&gt;effects.readsPinned = true;
1677             // We need to clobber all potential pinned registers since we might be leaving the instance.
1678             // We pessimistically assume we could be calling to something that is bounds checking.
1679             // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
1680             patchpoint-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
1681 
1682             Vector&lt;ConstrainedTmp&gt; patchArgs;
1683             wasmCallingConventionAir().setupCall(m_code, returnType, patchpoint, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {
1684                 patchArgs.append({ tmp, rep });
1685             });
1686 
1687             patchpoint-&gt;setGenerator([unlinkedWasmToWasmCalls, functionIndex] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1688                 AllowMacroScratchRegisterUsage allowScratch(jit);
1689                 CCallHelpers::Call call = jit.threadSafePatchableNearCall();
1690                 jit.addLinkTask([unlinkedWasmToWasmCalls, call, functionIndex] (LinkBuffer&amp; linkBuffer) {
1691                     unlinkedWasmToWasmCalls-&gt;append({ linkBuffer.locationOfNearCall&lt;WasmEntryPtrTag&gt;(call), functionIndex });
1692                 });
1693             });
1694 
1695             emitPatchpoint(isWasmBlock, patchpoint, result, WTFMove(patchArgs));
1696             append(isWasmBlock, Jump);
1697             isWasmBlock-&gt;setSuccessors(continuation);
1698         }
1699 
1700         {
1701             auto jumpDestination = g64();
1702             append(isEmbedderBlock, Move, Arg::bigImm(Instance::offsetOfWasmToEmbedderStub(functionIndex)), jumpDestination);
1703             append(isEmbedderBlock, Add64, instanceValue(), jumpDestination);
1704             append(isEmbedderBlock, Move, Arg::addr(jumpDestination), jumpDestination);
1705 
1706             auto* patchpoint = addPatchpoint(toB3Type(returnType));
1707             patchpoint-&gt;effects.writesPinned = true;
1708             patchpoint-&gt;effects.readsPinned = true;
1709             // We need to clobber all potential pinned registers since we might be leaving the instance.
1710             // We pessimistically assume we could be calling to something that is bounds checking.
1711             // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
1712             patchpoint-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
1713 
1714             Vector&lt;ConstrainedTmp&gt; patchArgs;
1715             patchArgs.append(jumpDestination);
1716 
1717             wasmCallingConventionAir().setupCall(m_code, returnType, patchpoint, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {
1718                 patchArgs.append({ tmp, rep });
1719             });
1720 
1721             patchpoint-&gt;setGenerator([returnType] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1722                 AllowMacroScratchRegisterUsage allowScratch(jit);
1723                 jit.call(params[returnType == Void ? 0 : 1].gpr(), WasmEntryPtrTag);
1724             });
1725 
1726             emitPatchpoint(isEmbedderBlock, patchpoint, result, WTFMove(patchArgs));
1727             append(isEmbedderBlock, Jump);
1728             isEmbedderBlock-&gt;setSuccessors(continuation);
1729         }
1730 
1731         m_currentBlock = continuation;
1732         // The call could have been to another WebAssembly instance, and / or could have modified our Memory.
1733         restoreWebAssemblyGlobalState(RestoreCachedStackLimit::Yes, m_info.memory, currentInstance, continuation);
1734     } else {
1735         auto* patchpoint = addPatchpoint(toB3Type(returnType));
1736         patchpoint-&gt;effects.writesPinned = true;
1737         patchpoint-&gt;effects.readsPinned = true;
1738 
1739         Vector&lt;ConstrainedTmp&gt; patchArgs;
1740         wasmCallingConventionAir().setupCall(m_code, returnType, patchpoint, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {
1741             patchArgs.append({ tmp, rep });
1742         });
1743 
1744         patchpoint-&gt;setGenerator([unlinkedWasmToWasmCalls, functionIndex] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1745             AllowMacroScratchRegisterUsage allowScratch(jit);
1746             CCallHelpers::Call call = jit.threadSafePatchableNearCall();
1747             jit.addLinkTask([unlinkedWasmToWasmCalls, call, functionIndex] (LinkBuffer&amp; linkBuffer) {
1748                 unlinkedWasmToWasmCalls-&gt;append({ linkBuffer.locationOfNearCall&lt;WasmEntryPtrTag&gt;(call), functionIndex });
1749             });
1750         });
1751 
1752         emitPatchpoint(m_currentBlock, patchpoint, result, WTFMove(patchArgs));
1753     }
1754 
1755     return { };
1756 }
1757 
<a name="65" id="anc65"></a><span class="line-modified">1758 auto AirIRGenerator::addCallIndirect(const Signature&amp; signature, Vector&lt;ExpressionType&gt;&amp; args, ExpressionType&amp; result) -&gt; PartialResult</span>
1759 {
1760     ExpressionType calleeIndex = args.takeLast();
1761     ASSERT(signature.argumentCount() == args.size());
<a name="66" id="anc66"></a>

1762 
1763     m_makesCalls = true;
1764     // Note: call indirect can call either WebAssemblyFunction or WebAssemblyWrapperFunction. Because
1765     // WebAssemblyWrapperFunction is like calling into the embedder, we conservatively assume all call indirects
1766     // can be to the embedder for our stack check calculation.
1767     m_maxNumJSCallArguments = std::max(m_maxNumJSCallArguments, static_cast&lt;uint32_t&gt;(args.size()));
1768 
1769     auto currentInstance = g64();
1770     append(Move, instanceValue(), currentInstance);
1771 
1772     ExpressionType callableFunctionBuffer = g64();
1773     ExpressionType instancesBuffer = g64();
1774     ExpressionType callableFunctionBufferLength = g64();
1775     {
<a name="67" id="anc67"></a><span class="line-modified">1776         RELEASE_ASSERT(Arg::isValidAddrForm(Instance::offsetOfTable(), B3::Width64));</span>
<span class="line-modified">1777         RELEASE_ASSERT(Arg::isValidAddrForm(Table::offsetOfFunctions(), B3::Width64));</span>
<span class="line-modified">1778         RELEASE_ASSERT(Arg::isValidAddrForm(Table::offsetOfInstances(), B3::Width64));</span>
<span class="line-modified">1779         RELEASE_ASSERT(Arg::isValidAddrForm(Table::offsetOfLength(), B3::Width64));</span>
<span class="line-modified">1780 </span>
<span class="line-modified">1781         append(Move, Arg::addr(instanceValue(), Instance::offsetOfTable()), callableFunctionBufferLength);</span>
<span class="line-modified">1782         append(Move, Arg::addr(callableFunctionBufferLength, Table::offsetOfFunctions()), callableFunctionBuffer);</span>
<span class="line-modified">1783         append(Move, Arg::addr(callableFunctionBufferLength, Table::offsetOfInstances()), instancesBuffer);</span>




1784         append(Move32, Arg::addr(callableFunctionBufferLength, Table::offsetOfLength()), callableFunctionBufferLength);
1785     }
1786 
1787     append(Move32, calleeIndex, calleeIndex);
1788 
1789     // Check the index we are looking for is valid.
1790     emitCheck([&amp;] {
1791         return Inst(Branch32, nullptr, Arg::relCond(MacroAssembler::AboveOrEqual), calleeIndex, callableFunctionBufferLength);
1792     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1793         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsCallIndirect);
1794     });
1795 
1796     ExpressionType calleeCode = g64();
1797     {
1798         ExpressionType calleeSignatureIndex = g64();
1799         // Compute the offset in the table index space we are looking for.
1800         append(Move, Arg::imm(sizeof(WasmToWasmImportableFunction)), calleeSignatureIndex);
1801         append(Mul64, calleeIndex, calleeSignatureIndex);
1802         append(Add64, callableFunctionBuffer, calleeSignatureIndex);
1803 
1804         append(Move, Arg::addr(calleeSignatureIndex, WasmToWasmImportableFunction::offsetOfEntrypointLoadLocation()), calleeCode); // Pointer to callee code.
1805 
1806         // Check that the WasmToWasmImportableFunction is initialized. We trap if it isn&#39;t. An &quot;invalid&quot; SignatureIndex indicates it&#39;s not initialized.
1807         // FIXME: when we have trap handlers, we can just let the call fail because Signature::invalidIndex is 0. https://bugs.webkit.org/show_bug.cgi?id=177210
1808         static_assert(sizeof(WasmToWasmImportableFunction::signatureIndex) == sizeof(uint64_t), &quot;Load codegen assumes i64&quot;);
1809 
1810         // FIXME: This seems dumb to do two checks just for a nicer error message.
1811         // We should move just to use a single branch and then figure out what
1812         // error to use in the exception handler.
1813 
1814         append(Move, Arg::addr(calleeSignatureIndex, WasmToWasmImportableFunction::offsetOfSignatureIndex()), calleeSignatureIndex);
1815 
1816         emitCheck([&amp;] {
1817             static_assert(Signature::invalidIndex == 0, &quot;&quot;);
1818             return Inst(BranchTest64, nullptr, Arg::resCond(MacroAssembler::Zero), calleeSignatureIndex, calleeSignatureIndex);
1819         }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1820             this-&gt;emitThrowException(jit, ExceptionType::NullTableEntry);
1821         });
1822 
1823         ExpressionType expectedSignatureIndex = g64();
1824         append(Move, Arg::bigImm(SignatureInformation::get(signature)), expectedSignatureIndex);
1825         emitCheck([&amp;] {
1826             return Inst(Branch64, nullptr, Arg::relCond(MacroAssembler::NotEqual), calleeSignatureIndex, expectedSignatureIndex);
1827         }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1828             this-&gt;emitThrowException(jit, ExceptionType::BadSignature);
1829         });
1830     }
1831 
1832     // Do a context switch if needed.
1833     {
1834         auto newContextInstance = g64();
1835         append(Move, Arg::index(instancesBuffer, calleeIndex, 8, 0), newContextInstance);
1836 
1837         BasicBlock* doContextSwitch = m_code.addBlock();
1838         BasicBlock* continuation = m_code.addBlock();
1839 
1840         append(Branch64, Arg::relCond(MacroAssembler::Equal), newContextInstance, instanceValue());
1841         m_currentBlock-&gt;setSuccessors(continuation, doContextSwitch);
1842 
1843         auto* patchpoint = addPatchpoint(B3::Void);
1844         patchpoint-&gt;effects.writesPinned = true;
1845         // We pessimistically assume we&#39;re calling something with BoundsChecking memory.
1846         // FIXME: We shouldn&#39;t have to do this: https://bugs.webkit.org/show_bug.cgi?id=172181
1847         patchpoint-&gt;clobber(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
1848         patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
<a name="68" id="anc68"></a>

1849         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1850             AllowMacroScratchRegisterUsage allowScratch(jit);
1851             GPRReg newContextInstance = params[0].gpr();
1852             GPRReg oldContextInstance = params[1].gpr();
1853             const PinnedRegisterInfo&amp; pinnedRegs = PinnedRegisterInfo::get();
<a name="69" id="anc69"></a><span class="line-removed">1854             const auto&amp; sizeRegs = pinnedRegs.sizeRegisters;</span>
1855             GPRReg baseMemory = pinnedRegs.baseMemoryPointer;
1856             ASSERT(newContextInstance != baseMemory);
1857             jit.loadPtr(CCallHelpers::Address(oldContextInstance, Instance::offsetOfCachedStackLimit()), baseMemory);
1858             jit.storePtr(baseMemory, CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedStackLimit()));
1859             jit.storeWasmContextInstance(newContextInstance);
<a name="70" id="anc70"></a><span class="line-removed">1860             ASSERT(sizeRegs[0].sizeRegister != baseMemory);</span>
1861             // FIXME: We should support more than one memory size register
1862             //   see: https://bugs.webkit.org/show_bug.cgi?id=162952
<a name="71" id="anc71"></a><span class="line-modified">1863             ASSERT(sizeRegs.size() == 1);</span>
<span class="line-modified">1864             ASSERT(sizeRegs[0].sizeRegister != newContextInstance);</span>
<span class="line-modified">1865             ASSERT(!sizeRegs[0].sizeOffset);</span>
<span class="line-modified">1866             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemorySize()), sizeRegs[0].sizeRegister); // Memory size.</span>
1867             jit.loadPtr(CCallHelpers::Address(newContextInstance, Instance::offsetOfCachedMemory()), baseMemory); // Memory::void*.
<a name="72" id="anc72"></a>

1868         });
1869 
1870         emitPatchpoint(doContextSwitch, patchpoint, Tmp(), newContextInstance, instanceValue());
1871         append(doContextSwitch, Jump);
1872         doContextSwitch-&gt;setSuccessors(continuation);
1873 
1874         m_currentBlock = continuation;
1875     }
1876 
1877     append(Move, Arg::addr(calleeCode), calleeCode);
1878 
1879     Type returnType = signature.returnType();
1880     if (returnType != Type::Void)
1881         result = tmpForType(returnType);
1882 
1883     auto* patch = addPatchpoint(toB3Type(returnType));
1884     patch-&gt;effects.writesPinned = true;
1885     patch-&gt;effects.readsPinned = true;
1886     // We need to clobber all potential pinned registers since we might be leaving the instance.
1887     // We pessimistically assume we&#39;re always calling something that is bounds checking so
1888     // because the wasm-&gt;wasm thunk unconditionally overrides the size registers.
1889     // FIXME: We should not have to do this, but the wasm-&gt;wasm stub assumes it can
1890     // use all the pinned registers as scratch: https://bugs.webkit.org/show_bug.cgi?id=172181
1891     patch-&gt;clobberLate(PinnedRegisterInfo::get().toSave(MemoryMode::BoundsChecking));
1892 
1893     Vector&lt;ConstrainedTmp&gt; emitArgs;
1894     emitArgs.append(calleeCode);
1895     wasmCallingConventionAir().setupCall(m_code, returnType, patch, toTmpVector(args), [&amp;] (Tmp tmp, B3::ValueRep rep) {
1896         emitArgs.append({ tmp, rep });
1897     });
1898     patch-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
1899         AllowMacroScratchRegisterUsage allowScratch(jit);
1900         jit.call(params[returnType == Void ? 0 : 1].gpr(), WasmEntryPtrTag);
1901     });
1902 
1903     emitPatchpoint(m_currentBlock, patch, result, WTFMove(emitArgs));
1904 
1905     // The call could have been to another WebAssembly instance, and / or could have modified our Memory.
1906     restoreWebAssemblyGlobalState(RestoreCachedStackLimit::Yes, m_info.memory, currentInstance, m_currentBlock);
1907 
1908     return { };
1909 }
1910 
1911 void AirIRGenerator::unify(const ExpressionType&amp; dst, const ExpressionType&amp; source)
1912 {
<a name="73" id="anc73"></a><span class="line-modified">1913     ASSERT(dst.type() == source.type());</span>
1914     append(moveOpForValueType(dst.type()), source, dst);
1915 }
1916 
<a name="74" id="anc74"></a><span class="line-modified">1917 void AirIRGenerator::unifyValuesWithBlock(const ExpressionList&amp; resultStack, const ResultList&amp; result)</span>
1918 {
1919     ASSERT(result.size() &lt;= resultStack.size());
1920 
1921     for (size_t i = 0; i &lt; result.size(); ++i)
1922         unify(result[result.size() - 1 - i], resultStack[resultStack.size() - 1 - i]);
1923 }
1924 
<a name="75" id="anc75"></a><span class="line-modified">1925 void AirIRGenerator::dump(const Vector&lt;ControlEntry&gt;&amp;, const ExpressionList*)</span>
1926 {
1927 }
1928 
1929 auto AirIRGenerator::origin() -&gt; B3::Origin
1930 {
1931     // FIXME: We should implement a way to give Inst&#39;s an origin.
1932     return B3::Origin();
1933 }
1934 
1935 Expected&lt;std::unique_ptr&lt;InternalFunction&gt;, String&gt; parseAndCompileAir(CompilationContext&amp; compilationContext, const uint8_t* functionStart, size_t functionLength, const Signature&amp; signature, Vector&lt;UnlinkedWasmToWasmCall&gt;&amp; unlinkedWasmToWasmCalls, const ModuleInformation&amp; info, MemoryMode mode, uint32_t functionIndex, TierUpCount* tierUp, ThrowWasmException throwWasmException)
1936 {
<a name="76" id="anc76"></a><span class="line-modified">1937     auto result = std::make_unique&lt;InternalFunction&gt;();</span>
1938 
<a name="77" id="anc77"></a><span class="line-modified">1939     compilationContext.embedderEntrypointJIT = std::make_unique&lt;CCallHelpers&gt;();</span>
<span class="line-modified">1940     compilationContext.wasmEntrypointJIT = std::make_unique&lt;CCallHelpers&gt;();</span>
1941 
1942     B3::Procedure procedure;
1943     Code&amp; code = procedure.code();
1944 
1945     procedure.setOriginPrinter([] (PrintStream&amp; out, B3::Origin origin) {
1946         if (origin.data())
1947             out.print(&quot;Wasm: &quot;, bitwise_cast&lt;OpcodeOrigin&gt;(origin));
1948     });
1949 
1950     // This means we cannot use either StackmapGenerationParams::usedRegisters() or
1951     // StackmapGenerationParams::unavailableRegisters(). In exchange for this concession, we
1952     // don&#39;t strictly need to run Air::reportUsedRegisters(), which saves a bit of CPU time at
1953     // optLevel=1.
1954     procedure.setNeedsUsedRegisters(false);
1955 
<a name="78" id="anc78"></a><span class="line-modified">1956     procedure.setOptLevel(Options::webAssemblyBBQOptimizationLevel());</span>
1957 
1958     AirIRGenerator irGenerator(info, procedure, result.get(), unlinkedWasmToWasmCalls, mode, functionIndex, tierUp, throwWasmException, signature);
1959     FunctionParser&lt;AirIRGenerator&gt; parser(irGenerator, functionStart, functionLength, signature, info);
1960     WASM_FAIL_IF_HELPER_FAILS(parser.parse());
1961 
1962 
1963     for (BasicBlock* block : code) {
1964         for (size_t i = 0; i &lt; block-&gt;numSuccessors(); ++i)
1965             block-&gt;successorBlock(i)-&gt;addPredecessor(block);
1966     }
1967 
1968     {
<a name="79" id="anc79"></a>





1969         B3::Air::prepareForGeneration(code);
1970         B3::Air::generate(code, *compilationContext.wasmEntrypointJIT);
1971         compilationContext.wasmEntrypointByproducts = procedure.releaseByproducts();
1972         result-&gt;entrypoint.calleeSaveRegisters = code.calleeSaveRegisterAtOffsetList();
1973     }
1974 
<a name="80" id="anc80"></a><span class="line-modified">1975     return WTFMove(result);</span>
1976 }
1977 
1978 template &lt;typename IntType&gt;
1979 void AirIRGenerator::emitChecksForModOrDiv(bool isSignedDiv, ExpressionType left, ExpressionType right)
1980 {
1981     static_assert(sizeof(IntType) == 4 || sizeof(IntType) == 8, &quot;&quot;);
1982 
1983     emitCheck([&amp;] {
1984         return Inst(sizeof(IntType) == 4 ? BranchTest32 : BranchTest64, nullptr, Arg::resCond(MacroAssembler::Zero), right, right);
1985     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
1986         this-&gt;emitThrowException(jit, ExceptionType::DivisionByZero);
1987     });
1988 
1989     if (isSignedDiv) {
1990         ASSERT(std::is_signed&lt;IntType&gt;::value);
1991         IntType min = std::numeric_limits&lt;IntType&gt;::min();
1992 
1993         // FIXME: Better isel for compare with imms here.
1994         // https://bugs.webkit.org/show_bug.cgi?id=193999
1995         auto minTmp = sizeof(IntType) == 4 ? g32() : g64();
1996         auto negOne = sizeof(IntType) == 4 ? g32() : g64();
1997 
1998         B3::Air::Opcode op = sizeof(IntType) == 4 ? Compare32 : Compare64;
1999         append(Move, Arg::bigImm(static_cast&lt;uint64_t&gt;(min)), minTmp);
2000         append(op, Arg::relCond(MacroAssembler::Equal), left, minTmp, minTmp);
2001 
2002         append(Move, Arg::imm(-1), negOne);
2003         append(op, Arg::relCond(MacroAssembler::Equal), right, negOne, negOne);
2004 
2005         emitCheck([&amp;] {
2006             return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), minTmp, negOne);
2007         },
2008         [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2009             this-&gt;emitThrowException(jit, ExceptionType::IntegerOverflow);
2010         });
2011     }
2012 }
2013 
2014 template &lt;typename IntType&gt;
2015 void AirIRGenerator::emitModOrDiv(bool isDiv, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result)
2016 {
2017     static_assert(sizeof(IntType) == 4 || sizeof(IntType) == 8, &quot;&quot;);
2018 
2019     result = sizeof(IntType) == 4 ? g32() : g64();
2020 
2021     bool isSigned = std::is_signed&lt;IntType&gt;::value;
2022 
2023     if (isARM64()) {
2024         B3::Air::Opcode div;
2025         switch (sizeof(IntType)) {
2026         case 4:
2027             div = isSigned ? Div32 : UDiv32;
2028             break;
2029         case 8:
2030             div = isSigned ? Div64 : UDiv64;
2031             break;
2032         }
2033 
2034         append(div, lhs, rhs, result);
2035 
2036         if (!isDiv) {
2037             append(sizeof(IntType) == 4 ? Mul32 : Mul64, result, rhs, result);
2038             append(sizeof(IntType) == 4 ? Sub32 : Sub64, lhs, result, result);
2039         }
2040 
2041         return;
2042     }
2043 
2044 #if CPU(X86) || CPU(X86_64)
2045     Tmp eax(X86Registers::eax);
2046     Tmp edx(X86Registers::edx);
2047 
2048     if (isSigned) {
2049         B3::Air::Opcode convertToDoubleWord;
2050         B3::Air::Opcode div;
2051         switch (sizeof(IntType)) {
2052         case 4:
2053             convertToDoubleWord = X86ConvertToDoubleWord32;
2054             div = X86Div32;
2055             break;
2056         case 8:
2057             convertToDoubleWord = X86ConvertToQuadWord64;
2058             div = X86Div64;
2059             break;
2060         default:
2061             RELEASE_ASSERT_NOT_REACHED();
2062         }
2063 
2064         // We implement &quot;res = Div&lt;Chill&gt;/Mod&lt;Chill&gt;(num, den)&quot; as follows:
2065         //
2066         //     if (den + 1 &lt;=_unsigned 1) {
2067         //         if (!den) {
2068         //             res = 0;
2069         //             goto done;
2070         //         }
2071         //         if (num == -2147483648) {
2072         //             res = isDiv ? num : 0;
2073         //             goto done;
2074         //         }
2075         //     }
2076         //     res = num (/ or %) dev;
2077         // done:
2078 
2079         BasicBlock* denIsGood = m_code.addBlock();
2080         BasicBlock* denMayBeBad = m_code.addBlock();
2081         BasicBlock* denNotZero = m_code.addBlock();
2082         BasicBlock* continuation = m_code.addBlock();
2083 
2084         auto temp = sizeof(IntType) == 4 ? g32() : g64();
2085         auto one = addConstant(sizeof(IntType) == 4 ? Type::I32 : Type::I64, 1);
2086 
2087         append(sizeof(IntType) == 4 ? Add32 : Add64, rhs, one, temp);
2088         append(sizeof(IntType) == 4 ? Branch32 : Branch64, Arg::relCond(MacroAssembler::Above), temp, one);
2089         m_currentBlock-&gt;setSuccessors(denIsGood, denMayBeBad);
2090 
2091         append(denMayBeBad, Xor64, result, result);
2092         append(denMayBeBad, sizeof(IntType) == 4 ? BranchTest32 : BranchTest64, Arg::resCond(MacroAssembler::Zero), rhs, rhs);
2093         denMayBeBad-&gt;setSuccessors(continuation, denNotZero);
2094 
2095         auto min = addConstant(denNotZero, sizeof(IntType) == 4 ? Type::I32 : Type::I64, std::numeric_limits&lt;IntType&gt;::min());
2096         if (isDiv)
2097             append(denNotZero, sizeof(IntType) == 4 ? Move32 : Move, min, result);
2098         else {
2099             // Result is zero, as set above...
2100         }
2101         append(denNotZero, sizeof(IntType) == 4 ? Branch32 : Branch64, Arg::relCond(MacroAssembler::Equal), lhs, min);
2102         denNotZero-&gt;setSuccessors(continuation, denIsGood);
2103 
2104         auto divResult = isDiv ? eax : edx;
2105         append(denIsGood, Move, lhs, eax);
2106         append(denIsGood, convertToDoubleWord, eax, edx);
2107         append(denIsGood, div, eax, edx, rhs);
2108         append(denIsGood, sizeof(IntType) == 4 ? Move32 : Move, divResult, result);
2109         append(denIsGood, Jump);
2110         denIsGood-&gt;setSuccessors(continuation);
2111 
2112         m_currentBlock = continuation;
2113         return;
2114     }
2115 
2116     B3::Air::Opcode div = sizeof(IntType) == 4 ? X86UDiv32 : X86UDiv64;
2117 
2118     Tmp divResult = isDiv ? eax : edx;
2119 
2120     append(Move, lhs, eax);
2121     append(Xor64, edx, edx);
2122     append(div, eax, edx, rhs);
2123     append(sizeof(IntType) == 4 ? Move32 : Move, divResult, result);
2124 #else
2125     RELEASE_ASSERT_NOT_REACHED();
2126 #endif
2127 }
2128 
2129 template&lt;&gt;
2130 auto AirIRGenerator::addOp&lt;OpType::I32DivS&gt;(ExpressionType left, ExpressionType right, ExpressionType&amp; result) -&gt; PartialResult
2131 {
2132     emitChecksForModOrDiv&lt;int32_t&gt;(true, left, right);
2133     emitModOrDiv&lt;int32_t&gt;(true, left, right, result);
2134     return { };
2135 }
2136 
2137 template&lt;&gt;
2138 auto AirIRGenerator::addOp&lt;OpType::I32RemS&gt;(ExpressionType left, ExpressionType right, ExpressionType&amp; result) -&gt; PartialResult
2139 {
2140     emitChecksForModOrDiv&lt;int32_t&gt;(false, left, right);
2141     emitModOrDiv&lt;int32_t&gt;(false, left, right, result);
2142     return { };
2143 }
2144 
2145 template&lt;&gt;
2146 auto AirIRGenerator::addOp&lt;OpType::I32DivU&gt;(ExpressionType left, ExpressionType right, ExpressionType&amp; result) -&gt; PartialResult
2147 {
2148     emitChecksForModOrDiv&lt;uint32_t&gt;(false, left, right);
2149     emitModOrDiv&lt;uint32_t&gt;(true, left, right, result);
2150     return { };
2151 }
2152 
2153 template&lt;&gt;
2154 auto AirIRGenerator::addOp&lt;OpType::I32RemU&gt;(ExpressionType left, ExpressionType right, ExpressionType&amp; result) -&gt; PartialResult
2155 {
2156     emitChecksForModOrDiv&lt;uint32_t&gt;(false, left, right);
2157     emitModOrDiv&lt;uint32_t&gt;(false, left, right, result);
2158     return { };
2159 }
2160 
2161 template&lt;&gt;
2162 auto AirIRGenerator::addOp&lt;OpType::I64DivS&gt;(ExpressionType left, ExpressionType right, ExpressionType&amp; result) -&gt; PartialResult
2163 {
2164     emitChecksForModOrDiv&lt;int64_t&gt;(true, left, right);
2165     emitModOrDiv&lt;int64_t&gt;(true, left, right, result);
2166     return { };
2167 }
2168 
2169 template&lt;&gt;
2170 auto AirIRGenerator::addOp&lt;OpType::I64RemS&gt;(ExpressionType left, ExpressionType right, ExpressionType&amp; result) -&gt; PartialResult
2171 {
2172     emitChecksForModOrDiv&lt;int64_t&gt;(false, left, right);
2173     emitModOrDiv&lt;int64_t&gt;(false, left, right, result);
2174     return { };
2175 }
2176 
2177 template&lt;&gt;
2178 auto AirIRGenerator::addOp&lt;OpType::I64DivU&gt;(ExpressionType left, ExpressionType right, ExpressionType&amp; result) -&gt; PartialResult
2179 {
2180     emitChecksForModOrDiv&lt;uint64_t&gt;(false, left, right);
2181     emitModOrDiv&lt;uint64_t&gt;(true, left, right, result);
2182     return { };
2183 }
2184 
2185 template&lt;&gt;
2186 auto AirIRGenerator::addOp&lt;OpType::I64RemU&gt;(ExpressionType left, ExpressionType right, ExpressionType&amp; result) -&gt; PartialResult
2187 {
2188     emitChecksForModOrDiv&lt;uint64_t&gt;(false, left, right);
2189     emitModOrDiv&lt;uint64_t&gt;(false, left, right, result);
2190     return { };
2191 }
2192 
2193 template&lt;&gt;
2194 auto AirIRGenerator::addOp&lt;OpType::I32Ctz&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2195 {
2196     auto* patchpoint = addPatchpoint(B3::Int32);
2197     patchpoint-&gt;effects = B3::Effects::none();
2198     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2199         jit.countTrailingZeros32(params[1].gpr(), params[0].gpr());
2200     });
2201     result = g32();
2202     emitPatchpoint(patchpoint, result, arg);
2203     return { };
2204 }
2205 
2206 template&lt;&gt;
2207 auto AirIRGenerator::addOp&lt;OpType::I64Ctz&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2208 {
2209     auto* patchpoint = addPatchpoint(B3::Int64);
2210     patchpoint-&gt;effects = B3::Effects::none();
2211     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2212         jit.countTrailingZeros64(params[1].gpr(), params[0].gpr());
2213     });
2214     result = g64();
2215     emitPatchpoint(patchpoint, result, arg);
2216     return { };
2217 }
2218 
2219 template&lt;&gt;
2220 auto AirIRGenerator::addOp&lt;OpType::I32Popcnt&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2221 {
2222     result = g32();
2223 
2224 #if CPU(X86_64)
2225     if (MacroAssembler::supportsCountPopulation()) {
2226         auto* patchpoint = addPatchpoint(B3::Int32);
2227         patchpoint-&gt;effects = B3::Effects::none();
2228         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2229             jit.countPopulation32(params[1].gpr(), params[0].gpr());
2230         });
2231         emitPatchpoint(patchpoint, result, arg);
2232         return { };
2233     }
2234 #endif
2235 
2236     uint32_t (*popcount)(int32_t) = [] (int32_t value) -&gt; uint32_t { return __builtin_popcount(value); };
2237     emitCCall(popcount, result, arg);
2238     return { };
2239 }
2240 
2241 template&lt;&gt;
2242 auto AirIRGenerator::addOp&lt;OpType::I64Popcnt&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2243 {
2244     result = g64();
2245 
2246 #if CPU(X86_64)
2247     if (MacroAssembler::supportsCountPopulation()) {
2248         auto* patchpoint = addPatchpoint(B3::Int64);
2249         patchpoint-&gt;effects = B3::Effects::none();
2250         patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2251             jit.countPopulation64(params[1].gpr(), params[0].gpr());
2252         });
2253         emitPatchpoint(patchpoint, result, arg);
2254         return { };
2255     }
2256 #endif
2257 
2258     uint64_t (*popcount)(int64_t) = [] (int64_t value) -&gt; uint64_t { return __builtin_popcountll(value); };
2259     emitCCall(popcount, result, arg);
2260     return { };
2261 }
2262 
2263 template&lt;&gt;
2264 auto AirIRGenerator::addOp&lt;F64ConvertUI64&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2265 {
2266     auto* patchpoint = addPatchpoint(B3::Double);
2267     patchpoint-&gt;effects = B3::Effects::none();
2268     if (isX86())
2269         patchpoint-&gt;numGPScratchRegisters = 1;
2270     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
2271     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2272         AllowMacroScratchRegisterUsage allowScratch(jit);
2273 #if CPU(X86_64)
2274         jit.convertUInt64ToDouble(params[1].gpr(), params[0].fpr(), params.gpScratch(0));
2275 #else
2276         jit.convertUInt64ToDouble(params[1].gpr(), params[0].fpr());
2277 #endif
2278     });
2279     result = f64();
2280     emitPatchpoint(patchpoint, result, arg);
2281     return { };
2282 }
2283 
2284 template&lt;&gt;
2285 auto AirIRGenerator::addOp&lt;OpType::F32ConvertUI64&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2286 {
2287     auto* patchpoint = addPatchpoint(B3::Float);
2288     patchpoint-&gt;effects = B3::Effects::none();
2289     if (isX86())
2290         patchpoint-&gt;numGPScratchRegisters = 1;
2291     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
2292     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2293         AllowMacroScratchRegisterUsage allowScratch(jit);
2294 #if CPU(X86_64)
2295         jit.convertUInt64ToFloat(params[1].gpr(), params[0].fpr(), params.gpScratch(0));
2296 #else
2297         jit.convertUInt64ToFloat(params[1].gpr(), params[0].fpr());
2298 #endif
2299     });
2300     result = f32();
2301     emitPatchpoint(patchpoint, result, arg);
2302     return { };
2303 }
2304 
2305 template&lt;&gt;
2306 auto AirIRGenerator::addOp&lt;OpType::F64Nearest&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2307 {
2308     auto* patchpoint = addPatchpoint(B3::Double);
2309     patchpoint-&gt;effects = B3::Effects::none();
2310     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2311         jit.roundTowardNearestIntDouble(params[1].fpr(), params[0].fpr());
2312     });
2313     result = f64();
2314     emitPatchpoint(patchpoint, result, arg);
2315     return { };
2316 }
2317 
2318 template&lt;&gt;
2319 auto AirIRGenerator::addOp&lt;OpType::F32Nearest&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2320 {
2321     auto* patchpoint = addPatchpoint(B3::Float);
2322     patchpoint-&gt;effects = B3::Effects::none();
2323     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2324         jit.roundTowardNearestIntFloat(params[1].fpr(), params[0].fpr());
2325     });
2326     result = f32();
2327     emitPatchpoint(patchpoint, result, arg);
2328     return { };
2329 }
2330 
2331 template&lt;&gt;
2332 auto AirIRGenerator::addOp&lt;OpType::F64Trunc&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2333 {
2334     auto* patchpoint = addPatchpoint(B3::Double);
2335     patchpoint-&gt;effects = B3::Effects::none();
2336     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2337         jit.roundTowardZeroDouble(params[1].fpr(), params[0].fpr());
2338     });
2339     result = f64();
2340     emitPatchpoint(patchpoint, result, arg);
2341     return { };
2342 }
2343 
2344 template&lt;&gt;
2345 auto AirIRGenerator::addOp&lt;OpType::F32Trunc&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2346 {
2347     auto* patchpoint = addPatchpoint(B3::Float);
2348     patchpoint-&gt;effects = B3::Effects::none();
2349     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2350         jit.roundTowardZeroFloat(params[1].fpr(), params[0].fpr());
2351     });
2352     result = f32();
2353     emitPatchpoint(patchpoint, result, arg);
2354     return { };
2355 }
2356 
2357 template&lt;&gt;
2358 auto AirIRGenerator::addOp&lt;OpType::I32TruncSF64&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2359 {
2360     auto max = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(-static_cast&lt;double&gt;(std::numeric_limits&lt;int32_t&gt;::min())));
2361     auto min = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(static_cast&lt;double&gt;(std::numeric_limits&lt;int32_t&gt;::min())));
2362 
2363     auto temp1 = g32();
2364     auto temp2 = g32();
2365     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThanOrUnordered), arg, min, temp1);
2366     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2367     append(Or32, temp1, temp2);
2368 
2369     emitCheck([&amp;] {
2370         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2371     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2372         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2373     });
2374 
2375     auto* patchpoint = addPatchpoint(B3::Int32);
2376     patchpoint-&gt;effects = B3::Effects::none();
2377     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2378         jit.truncateDoubleToInt32(params[1].fpr(), params[0].gpr());
2379     });
2380     result = g32();
2381     emitPatchpoint(patchpoint, result, arg);
2382 
2383     return { };
2384 }
2385 
2386 template&lt;&gt;
2387 auto AirIRGenerator::addOp&lt;OpType::I32TruncSF32&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2388 {
2389     auto max = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(-static_cast&lt;float&gt;(std::numeric_limits&lt;int32_t&gt;::min())));
2390     auto min = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;int32_t&gt;::min())));
2391 
2392     auto temp1 = g32();
2393     auto temp2 = g32();
2394     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrUnordered), arg, min, temp1);
2395     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2396     append(Or32, temp1, temp2);
2397 
2398     emitCheck([&amp;] {
2399         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2400     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2401         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2402     });
2403 
2404     auto* patchpoint = addPatchpoint(B3::Int32);
2405     patchpoint-&gt;effects = B3::Effects::none();
2406     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2407         jit.truncateFloatToInt32(params[1].fpr(), params[0].gpr());
2408     });
2409     result = g32();
2410     emitPatchpoint(patchpoint, result, arg);
2411     return { };
2412 }
2413 
2414 
2415 template&lt;&gt;
2416 auto AirIRGenerator::addOp&lt;OpType::I32TruncUF64&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2417 {
2418     auto max = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(static_cast&lt;double&gt;(std::numeric_limits&lt;int32_t&gt;::min()) * -2.0));
2419     auto min = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(-1.0));
2420 
2421     auto temp1 = g32();
2422     auto temp2 = g32();
2423     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqualOrUnordered), arg, min, temp1);
2424     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2425     append(Or32, temp1, temp2);
2426 
2427     emitCheck([&amp;] {
2428         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2429     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2430         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2431     });
2432 
2433     auto* patchpoint = addPatchpoint(B3::Int32);
2434     patchpoint-&gt;effects = B3::Effects::none();
2435     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2436         jit.truncateDoubleToUint32(params[1].fpr(), params[0].gpr());
2437     });
2438     result = g32();
2439     emitPatchpoint(patchpoint, result, arg);
2440     return { };
2441 }
2442 
2443 template&lt;&gt;
2444 auto AirIRGenerator::addOp&lt;OpType::I32TruncUF32&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2445 {
2446     auto max = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;int32_t&gt;::min()) * static_cast&lt;float&gt;(-2.0)));
2447     auto min = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(-1.0)));
2448 
2449     auto temp1 = g32();
2450     auto temp2 = g32();
2451     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqualOrUnordered), arg, min, temp1);
2452     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2453     append(Or32, temp1, temp2);
2454 
2455     emitCheck([&amp;] {
2456         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2457     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2458         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2459     });
2460 
2461     auto* patchpoint = addPatchpoint(B3::Int32);
2462     patchpoint-&gt;effects = B3::Effects::none();
2463     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2464         jit.truncateFloatToUint32(params[1].fpr(), params[0].gpr());
2465     });
2466     result = g32();
2467     emitPatchpoint(patchpoint, result, arg);
2468     return { };
2469 }
2470 
2471 template&lt;&gt;
2472 auto AirIRGenerator::addOp&lt;OpType::I64TruncSF64&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2473 {
2474     auto max = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(-static_cast&lt;double&gt;(std::numeric_limits&lt;int64_t&gt;::min())));
2475     auto min = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(static_cast&lt;double&gt;(std::numeric_limits&lt;int64_t&gt;::min())));
2476 
2477     auto temp1 = g32();
2478     auto temp2 = g32();
2479     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThanOrUnordered), arg, min, temp1);
2480     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2481     append(Or32, temp1, temp2);
2482 
2483     emitCheck([&amp;] {
2484         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2485     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2486         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2487     });
2488 
2489     auto* patchpoint = addPatchpoint(B3::Int64);
2490     patchpoint-&gt;effects = B3::Effects::none();
2491     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2492         jit.truncateDoubleToInt64(params[1].fpr(), params[0].gpr());
2493     });
2494 
2495     result = g64();
2496     emitPatchpoint(patchpoint, result, arg);
2497     return { };
2498 }
2499 
2500 template&lt;&gt;
2501 auto AirIRGenerator::addOp&lt;OpType::I64TruncUF64&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2502 {
2503     auto max = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(static_cast&lt;double&gt;(std::numeric_limits&lt;int64_t&gt;::min()) * -2.0));
2504     auto min = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(-1.0));
2505 
2506     auto temp1 = g32();
2507     auto temp2 = g32();
2508     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqualOrUnordered), arg, min, temp1);
2509     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2510     append(Or32, temp1, temp2);
2511 
2512     emitCheck([&amp;] {
2513         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2514     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2515         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2516     });
2517 
2518     TypedTmp signBitConstant;
2519     if (isX86())
2520         signBitConstant = addConstant(Type::F64, bitwise_cast&lt;uint64_t&gt;(static_cast&lt;double&gt;(std::numeric_limits&lt;uint64_t&gt;::max() - std::numeric_limits&lt;int64_t&gt;::max())));
2521 
2522     Vector&lt;ConstrainedTmp&gt; args;
2523     auto* patchpoint = addPatchpoint(B3::Int64);
2524     patchpoint-&gt;effects = B3::Effects::none();
2525     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
2526     args.append(arg);
2527     if (isX86()) {
2528         args.append(signBitConstant);
2529         patchpoint-&gt;numFPScratchRegisters = 1;
2530     }
2531     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2532         AllowMacroScratchRegisterUsage allowScratch(jit);
2533         FPRReg scratch = InvalidFPRReg;
2534         FPRReg constant = InvalidFPRReg;
2535         if (isX86()) {
2536             scratch = params.fpScratch(0);
2537             constant = params[2].fpr();
2538         }
2539         jit.truncateDoubleToUint64(params[1].fpr(), params[0].gpr(), scratch, constant);
2540     });
2541 
2542     result = g64();
2543     emitPatchpoint(m_currentBlock, patchpoint, result, WTFMove(args));
2544     return { };
2545 }
2546 
2547 template&lt;&gt;
2548 auto AirIRGenerator::addOp&lt;OpType::I64TruncSF32&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2549 {
2550     auto max = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(-static_cast&lt;float&gt;(std::numeric_limits&lt;int64_t&gt;::min())));
2551     auto min = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;int64_t&gt;::min())));
2552 
2553     auto temp1 = g32();
2554     auto temp2 = g32();
2555     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrUnordered), arg, min, temp1);
2556     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2557     append(Or32, temp1, temp2);
2558 
2559     emitCheck([&amp;] {
2560         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2561     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2562         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2563     });
2564 
2565     auto* patchpoint = addPatchpoint(B3::Int64);
2566     patchpoint-&gt;effects = B3::Effects::none();
2567     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2568         jit.truncateFloatToInt64(params[1].fpr(), params[0].gpr());
2569     });
2570     result = g64();
2571     emitPatchpoint(patchpoint, result, arg);
2572     return { };
2573 }
2574 
2575 template&lt;&gt;
2576 auto AirIRGenerator::addOp&lt;OpType::I64TruncUF32&gt;(ExpressionType arg, ExpressionType&amp; result) -&gt; PartialResult
2577 {
2578     auto max = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;int64_t&gt;::min()) * static_cast&lt;float&gt;(-2.0)));
2579     auto min = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(-1.0)));
2580 
2581     auto temp1 = g32();
2582     auto temp2 = g32();
2583     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqualOrUnordered), arg, min, temp1);
2584     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqualOrUnordered), arg, max, temp2);
2585     append(Or32, temp1, temp2);
2586 
2587     emitCheck([&amp;] {
2588         return Inst(BranchTest32, nullptr, Arg::resCond(MacroAssembler::NonZero), temp2, temp2);
2589     }, [=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp;) {
2590         this-&gt;emitThrowException(jit, ExceptionType::OutOfBoundsTrunc);
2591     });
2592 
2593     TypedTmp signBitConstant;
2594     if (isX86())
2595         signBitConstant = addConstant(Type::F32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(std::numeric_limits&lt;uint64_t&gt;::max() - std::numeric_limits&lt;int64_t&gt;::max())));
2596 
2597     auto* patchpoint = addPatchpoint(B3::Int64);
2598     patchpoint-&gt;effects = B3::Effects::none();
2599     patchpoint-&gt;clobber(RegisterSet::macroScratchRegisters());
2600     Vector&lt;ConstrainedTmp&gt; args;
2601     args.append(arg);
2602     if (isX86()) {
2603         args.append(signBitConstant);
2604         patchpoint-&gt;numFPScratchRegisters = 1;
2605     }
2606     patchpoint-&gt;setGenerator([=] (CCallHelpers&amp; jit, const B3::StackmapGenerationParams&amp; params) {
2607         AllowMacroScratchRegisterUsage allowScratch(jit);
2608         FPRReg scratch = InvalidFPRReg;
2609         FPRReg constant = InvalidFPRReg;
2610         if (isX86()) {
2611             scratch = params.fpScratch(0);
2612             constant = params[2].fpr();
2613         }
2614         jit.truncateFloatToUint64(params[1].fpr(), params[0].gpr(), scratch, constant);
2615     });
2616 
2617     result = g64();
2618     emitPatchpoint(m_currentBlock, patchpoint, result, WTFMove(args));
2619 
2620     return { };
2621 }
2622 
2623 auto AirIRGenerator::addShift(Type type, B3::Air::Opcode op, ExpressionType value, ExpressionType shift, ExpressionType&amp; result) -&gt; PartialResult
2624 {
2625     ASSERT(type == Type::I64 || type == Type::I32);
2626     result = tmpForType(type);
2627 
2628     if (isValidForm(op, Arg::Tmp, Arg::Tmp, Arg::Tmp)) {
2629         append(op, value, shift, result);
2630         return { };
2631     }
2632 
2633 #if CPU(X86_64)
2634     Tmp ecx = Tmp(X86Registers::ecx);
2635     append(Move, value, result);
2636     append(Move, shift, ecx);
2637     append(op, ecx, result);
2638 #else
2639     RELEASE_ASSERT_NOT_REACHED();
2640 #endif
2641     return { };
2642 }
2643 
2644 auto AirIRGenerator::addIntegerSub(B3::Air::Opcode op, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result) -&gt; PartialResult
2645 {
2646     ASSERT(op == Sub32 || op == Sub64);
2647 
2648     result = op == Sub32 ? g32() : g64();
2649 
2650     if (isValidForm(op, Arg::Tmp, Arg::Tmp, Arg::Tmp)) {
2651         append(op, lhs, rhs, result);
2652         return { };
2653     }
2654 
2655     RELEASE_ASSERT(isX86());
2656     // Sub a, b
2657     // means
2658     // b = b Sub a
2659     append(Move, lhs, result);
2660     append(op, rhs, result);
2661     return { };
2662 }
2663 
2664 auto AirIRGenerator::addFloatingPointAbs(B3::Air::Opcode op, ExpressionType value, ExpressionType&amp; result) -&gt; PartialResult
2665 {
2666     RELEASE_ASSERT(op == AbsFloat || op == AbsDouble);
2667 
2668     result = op == AbsFloat ? f32() : f64();
2669 
2670     if (isValidForm(op, Arg::Tmp, Arg::Tmp)) {
2671         append(op, value, result);
2672         return { };
2673     }
2674 
2675     RELEASE_ASSERT(isX86());
2676 
2677     if (op == AbsFloat) {
2678         auto constant = g32();
2679         append(Move, Arg::imm(static_cast&lt;uint32_t&gt;(~(1ull &lt;&lt; 31))), constant);
2680         append(Move32ToFloat, constant, result);
2681         append(AndFloat, value, result);
2682     } else {
2683         auto constant = g64();
2684         append(Move, Arg::bigImm(~(1ull &lt;&lt; 63)), constant);
2685         append(Move64ToDouble, constant, result);
2686         append(AndDouble, value, result);
2687     }
2688     return { };
2689 }
2690 
2691 auto AirIRGenerator::addFloatingPointBinOp(Type type, B3::Air::Opcode op, ExpressionType lhs, ExpressionType rhs, ExpressionType&amp; result) -&gt; PartialResult
2692 {
2693     ASSERT(type == Type::F32 || type == Type::F64);
2694     result = tmpForType(type);
2695 
2696     if (isValidForm(op, Arg::Tmp, Arg::Tmp, Arg::Tmp)) {
2697         append(op, lhs, rhs, result);
2698         return { };
2699     }
2700 
2701     RELEASE_ASSERT(isX86());
2702 
2703     // Op a, b
2704     // means
2705     // b = b Op a
2706     append(moveOpForValueType(type), lhs, result);
2707     append(op, rhs, result);
2708     return { };
2709 }
2710 
2711 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Ceil&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2712 {
2713     result = f32();
2714     append(CeilFloat, arg0, result);
2715     return { };
2716 }
2717 
2718 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Mul&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2719 {
2720     result = g32();
2721     append(Mul32, arg0, arg1, result);
2722     return { };
2723 }
2724 
2725 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Sub&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2726 {
2727     return addIntegerSub(Sub32, arg0, arg1, result);
2728 }
2729 
2730 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Le&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2731 {
2732     result = g32();
2733     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqual), arg0, arg1, result);
2734     return { };
2735 }
2736 
2737 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32DemoteF64&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2738 {
2739     result = f32();
2740     append(ConvertDoubleToFloat, arg0, result);
2741     return { };
2742 }
2743 
2744 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Min&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2745 {
<a name="81" id="anc81"></a><span class="line-modified">2746     result = f32();</span>
<span class="line-removed">2747 </span>
<span class="line-removed">2748     BasicBlock* isEqual = m_code.addBlock();</span>
<span class="line-removed">2749     BasicBlock* notEqual = m_code.addBlock();</span>
<span class="line-removed">2750     BasicBlock* greaterThanOrEqual = m_code.addBlock();</span>
<span class="line-removed">2751     BasicBlock* continuation = m_code.addBlock();</span>
<span class="line-removed">2752 </span>
<span class="line-removed">2753     append(m_currentBlock, BranchFloat, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>
<span class="line-removed">2754     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);</span>
<span class="line-removed">2755 </span>
<span class="line-removed">2756     append(isEqual, OrFloat, arg0, arg1, result);</span>
<span class="line-removed">2757     append(isEqual, Jump);</span>
<span class="line-removed">2758     isEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">2759 </span>
<span class="line-removed">2760     append(notEqual, MoveFloat, arg0, result);</span>
<span class="line-removed">2761     append(notEqual, BranchFloat, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-removed">2762     notEqual-&gt;setSuccessors(continuation, greaterThanOrEqual);</span>
<span class="line-removed">2763 </span>
<span class="line-removed">2764     append(greaterThanOrEqual, MoveFloat, arg1, result);</span>
<span class="line-removed">2765     append(greaterThanOrEqual, Jump);</span>
<span class="line-removed">2766     greaterThanOrEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">2767 </span>
<span class="line-removed">2768     m_currentBlock = continuation;</span>
<span class="line-removed">2769 </span>
<span class="line-removed">2770     return { };</span>
2771 }
2772 
2773 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Ne&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2774 {
2775     result = g32();
2776     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleNotEqualOrUnordered), arg0, arg1, result);
2777     return { };
2778 }
2779 
2780 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Lt&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2781 {
2782     result = g32();
2783     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1, result);
2784     return { };
2785 }
2786 
<a name="82" id="anc82"></a><span class="line-modified">2787 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Max&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult</span>
2788 {
<a name="83" id="anc83"></a><span class="line-modified">2789     result = f32();</span>

2790 
2791     BasicBlock* isEqual = m_code.addBlock();
2792     BasicBlock* notEqual = m_code.addBlock();
<a name="84" id="anc84"></a><span class="line-modified">2793     BasicBlock* lessThan = m_code.addBlock();</span>



2794     BasicBlock* continuation = m_code.addBlock();
2795 
<a name="85" id="anc85"></a><span class="line-modified">2796     append(m_currentBlock, BranchFloat, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>

2797     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);
2798 
<a name="86" id="anc86"></a><span class="line-modified">2799     append(isEqual, AndFloat, arg0, arg1, result);</span>








2800     append(isEqual, Jump);
2801     isEqual-&gt;setSuccessors(continuation);
2802 
<a name="87" id="anc87"></a><span class="line-modified">2803     append(notEqual, MoveFloat, arg0, result);</span>
<span class="line-modified">2804     append(notEqual, BranchFloat, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-modified">2805     notEqual-&gt;setSuccessors(lessThan, continuation);</span>






2806 
<a name="88" id="anc88"></a><span class="line-modified">2807     append(lessThan, MoveFloat, arg1, result);</span>
<span class="line-modified">2808     append(lessThan, Jump);</span>
<span class="line-modified">2809     lessThan-&gt;setSuccessors(continuation);</span>

2810 
2811     m_currentBlock = continuation;
2812 
2813     return { };
2814 }
2815 
<a name="89" id="anc89"></a>




2816 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Mul&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2817 {
2818     return addFloatingPointBinOp(Type::F64, MulDouble, arg0, arg1, result);
2819 }
2820 
2821 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Div&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2822 {
2823     return addFloatingPointBinOp(Type::F32, DivFloat, arg0, arg1, result);
2824 }
2825 
2826 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Clz&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2827 {
2828     result = g32();
2829     append(CountLeadingZeros32, arg0, result);
2830     return { };
2831 }
2832 
2833 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Copysign&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2834 {
2835     // FIXME: We can have better codegen here for the imms and two operand forms on x86
2836     // https://bugs.webkit.org/show_bug.cgi?id=193999
2837     result = f32();
2838     auto temp1 = g32();
2839     auto sign = g32();
2840     auto value = g32();
2841 
2842     // FIXME: Try to use Imm where possible:
2843     // https://bugs.webkit.org/show_bug.cgi?id=193999
2844     append(MoveFloatTo32, arg1, temp1);
2845     append(Move, Arg::bigImm(0x80000000), sign);
2846     append(And32, temp1, sign, sign);
2847 
2848     append(MoveDoubleTo64, arg0, temp1);
2849     append(Move, Arg::bigImm(0x7fffffff), value);
2850     append(And32, temp1, value, value);
2851 
2852     append(Or32, sign, value, value);
2853     append(Move32ToFloat, value, result);
2854 
2855     return { };
2856 }
2857 
2858 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64ConvertUI32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2859 {
2860     result = f64();
2861     auto temp = g64();
2862     append(Move32, arg0, temp);
2863     append(ConvertInt64ToDouble, temp, result);
2864     return { };
2865 }
2866 
2867 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32ReinterpretI32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2868 {
2869     result = f32();
2870     append(Move32ToFloat, arg0, result);
2871     return { };
2872 }
2873 
2874 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64And&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2875 {
2876     result = g64();
2877     append(And64, arg0, arg1, result);
2878     return { };
2879 }
2880 
2881 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Ne&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2882 {
2883     result = g32();
2884     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleNotEqualOrUnordered), arg0, arg1, result);
2885     return { };
2886 }
2887 
2888 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Gt&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2889 {
2890     result = g32();
2891     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleGreaterThan), arg0, arg1, result);
2892     return { };
2893 }
2894 
2895 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Sqrt&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2896 {
2897     result = f32();
2898     append(SqrtFloat, arg0, result);
2899     return { };
2900 }
2901 
2902 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Ge&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2903 {
2904     result = g32();
2905     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqual), arg0, arg1, result);
2906     return { };
2907 }
2908 
2909 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64GtS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2910 {
2911     result = g32();
2912     append(Compare64, Arg::relCond(MacroAssembler::GreaterThan), arg0, arg1, result);
2913     return { };
2914 }
2915 
2916 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64GtU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2917 {
2918     result = g32();
2919     append(Compare64, Arg::relCond(MacroAssembler::Above), arg0, arg1, result);
2920     return { };
2921 }
2922 
2923 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Eqz&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2924 {
2925     result = g32();
2926     append(Test64, Arg::resCond(MacroAssembler::Zero), arg0, arg0, result);
2927     return { };
2928 }
2929 
2930 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Div&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2931 {
2932     return addFloatingPointBinOp(Type::F64, DivDouble, arg0, arg1, result);
2933 }
2934 
2935 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Add&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2936 {
2937     result = f32();
2938     append(AddFloat, arg0, arg1, result);
2939     return { };
2940 }
2941 
2942 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Or&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2943 {
2944     result = g64();
2945     append(Or64, arg0, arg1, result);
2946     return { };
2947 }
2948 
2949 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32LeU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2950 {
2951     result = g32();
2952     append(Compare32, Arg::relCond(MacroAssembler::BelowOrEqual), arg0, arg1, result);
2953     return { };
2954 }
2955 
2956 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32LeS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2957 {
2958     result = g32();
2959     append(Compare32, Arg::relCond(MacroAssembler::LessThanOrEqual), arg0, arg1, result);
2960     return { };
2961 }
2962 
2963 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Ne&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2964 {
2965     result = g32();
2966     append(Compare64, Arg::relCond(MacroAssembler::NotEqual), arg0, arg1, result);
2967     return { };
2968 }
2969 
2970 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Clz&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2971 {
2972     result = g64();
2973     append(CountLeadingZeros64, arg0, result);
2974     return { };
2975 }
2976 
2977 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Neg&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
2978 {
2979     result = f32();
2980     if (isValidForm(NegateFloat, Arg::Tmp, Arg::Tmp))
2981         append(NegateFloat, arg0, result);
2982     else {
2983         auto constant = addConstant(Type::I32, bitwise_cast&lt;uint32_t&gt;(static_cast&lt;float&gt;(-0.0)));
2984         auto temp = g32();
2985         append(MoveFloatTo32, arg0, temp);
2986         append(Xor32, constant, temp);
2987         append(Move32ToFloat, temp, result);
2988     }
2989     return { };
2990 }
2991 
2992 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32And&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
2993 {
2994     result = g32();
2995     append(And32, arg0, arg1, result);
2996     return { };
2997 }
2998 
2999 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32LtU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3000 {
3001     result = g32();
3002     append(Compare32, Arg::relCond(MacroAssembler::Below), arg0, arg1, result);
3003     return { };
3004 }
3005 
3006 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Rotr&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3007 {
3008     return addShift(Type::I64, RotateRight64, arg0, arg1, result);
3009 }
3010 
3011 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Abs&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3012 {
3013     return addFloatingPointAbs(AbsDouble, arg0, result);
3014 }
3015 
3016 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32LtS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3017 {
3018     result = g32();
3019     append(Compare32, Arg::relCond(MacroAssembler::LessThan), arg0, arg1, result);
3020     return { };
3021 }
3022 
3023 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Eq&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3024 {
3025     result = g32();
3026     append(Compare32, Arg::relCond(MacroAssembler::Equal), arg0, arg1, result);
3027     return { };
3028 }
3029 
3030 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Copysign&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3031 {
3032     // FIXME: We can have better codegen here for the imms and two operand forms on x86
3033     // https://bugs.webkit.org/show_bug.cgi?id=193999
3034     result = f64();
3035     auto temp1 = g64();
3036     auto sign = g64();
3037     auto value = g64();
3038 
3039     append(MoveDoubleTo64, arg1, temp1);
3040     append(Move, Arg::bigImm(0x8000000000000000), sign);
3041     append(And64, temp1, sign, sign);
3042 
3043     append(MoveDoubleTo64, arg0, temp1);
3044     append(Move, Arg::bigImm(0x7fffffffffffffff), value);
3045     append(And64, temp1, value, value);
3046 
3047     append(Or64, sign, value, value);
3048     append(Move64ToDouble, value, result);
3049 
3050     return { };
3051 }
3052 
3053 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32ConvertSI64&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3054 {
3055     result = f32();
3056     append(ConvertInt64ToFloat, arg0, result);
3057     return { };
3058 }
3059 
3060 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Rotl&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3061 {
3062     if (isARM64()) {
3063         // ARM64 doesn&#39;t have a rotate left.
3064         auto newShift = g64();
3065         append(Move, arg1, newShift);
3066         append(Neg64, newShift);
3067         return addShift(Type::I64, RotateRight64, arg0, newShift, result);
3068     } else
3069         return addShift(Type::I64, RotateLeft64, arg0, arg1, result);
3070 }
3071 
3072 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Lt&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3073 {
3074     result = g32();
3075     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1, result);
3076     return { };
3077 }
3078 
3079 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64ConvertSI32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3080 {
3081     result = f64();
3082     append(ConvertInt32ToDouble, arg0, result);
3083     return { };
3084 }
3085 
3086 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Eq&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3087 {
3088     result = g32();
3089     append(CompareDouble, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1, result);
3090     return { };
3091 }
3092 
3093 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Le&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3094 {
3095     result = g32();
3096     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleLessThanOrEqual), arg0, arg1, result);
3097     return { };
3098 }
3099 
3100 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Ge&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3101 {
3102     result = g32();
3103     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThanOrEqual), arg0, arg1, result);
3104     return { };
3105 }
3106 
3107 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32ShrU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3108 {
3109     return addShift(Type::I32, Urshift32, arg0, arg1, result);
3110 }
3111 
3112 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32ConvertUI32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3113 {
3114     result = f32();
3115     auto temp = g64();
3116     append(Move32, arg0, temp);
3117     append(ConvertInt64ToFloat, temp, result);
3118     return { };
3119 }
3120 
3121 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32ShrS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3122 {
3123     return addShift(Type::I32, Rshift32, arg0, arg1, result);
3124 }
3125 
3126 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32GeU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3127 {
3128     result = g32();
3129     append(Compare32, Arg::relCond(MacroAssembler::AboveOrEqual), arg0, arg1, result);
3130     return { };
3131 }
3132 
3133 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Ceil&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3134 {
3135     result = f64();
3136     append(CeilDouble, arg0, result);
3137     return { };
3138 }
3139 
3140 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32GeS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3141 {
3142     result = g32();
3143     append(Compare32, Arg::relCond(MacroAssembler::GreaterThanOrEqual), arg0, arg1, result);
3144     return { };
3145 }
3146 
3147 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Shl&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3148 {
3149     return addShift(Type::I32, Lshift32, arg0, arg1, result);
3150 }
3151 
3152 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Floor&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3153 {
3154     result = f64();
3155     append(FloorDouble, arg0, result);
3156     return { };
3157 }
3158 
3159 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Xor&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3160 {
3161     result = g32();
3162     append(Xor32, arg0, arg1, result);
3163     return { };
3164 }
3165 
3166 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Abs&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3167 {
3168     return addFloatingPointAbs(AbsFloat, arg0, result);
3169 }
3170 
3171 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Min&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3172 {
<a name="90" id="anc90"></a><span class="line-modified">3173     result = f64();</span>
<span class="line-removed">3174 </span>
<span class="line-removed">3175     BasicBlock* isEqual = m_code.addBlock();</span>
<span class="line-removed">3176     BasicBlock* notEqual = m_code.addBlock();</span>
<span class="line-removed">3177     BasicBlock* greaterThanOrEqual = m_code.addBlock();</span>
<span class="line-removed">3178     BasicBlock* continuation = m_code.addBlock();</span>
<span class="line-removed">3179 </span>
<span class="line-removed">3180     append(m_currentBlock, BranchDouble, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>
<span class="line-removed">3181     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);</span>
<span class="line-removed">3182 </span>
<span class="line-removed">3183     append(isEqual, OrDouble, arg0, arg1, result);</span>
<span class="line-removed">3184     append(isEqual, Jump);</span>
<span class="line-removed">3185     isEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">3186 </span>
<span class="line-removed">3187     append(notEqual, MoveDouble, arg0, result);</span>
<span class="line-removed">3188     append(notEqual, BranchDouble, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-removed">3189     notEqual-&gt;setSuccessors(continuation, greaterThanOrEqual);</span>
<span class="line-removed">3190 </span>
<span class="line-removed">3191     append(greaterThanOrEqual, MoveDouble, arg1, result);</span>
<span class="line-removed">3192     append(greaterThanOrEqual, Jump);</span>
<span class="line-removed">3193     greaterThanOrEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">3194 </span>
<span class="line-removed">3195     m_currentBlock = continuation;</span>
<span class="line-removed">3196 </span>
<span class="line-removed">3197     return { };</span>
3198 }
3199 
3200 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Mul&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3201 {
3202     result = f32();
3203     append(MulFloat, arg0, arg1, result);
3204     return { };
3205 }
3206 
3207 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Sub&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3208 {
3209     return addIntegerSub(Sub64, arg0, arg1, result);
3210 }
3211 
3212 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32ReinterpretF32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3213 {
3214     result = g32();
3215     append(MoveFloatTo32, arg0, result);
3216     return { };
3217 }
3218 
3219 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Add&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3220 {
3221     result = g32();
3222     append(Add32, arg0, arg1, result);
3223     return { };
3224 }
3225 
3226 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Sub&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3227 {
3228     return addFloatingPointBinOp(Type::F64, SubDouble, arg0, arg1, result);
3229 }
3230 
3231 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Or&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3232 {
3233     result = g32();
3234     append(Or32, arg0, arg1, result);
3235     return { };
3236 }
3237 
3238 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64LtU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3239 {
3240     result = g32();
3241     append(Compare64, Arg::relCond(MacroAssembler::Below), arg0, arg1, result);
3242     return { };
3243 }
3244 
3245 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64LtS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3246 {
3247     result = g32();
3248     append(Compare64, Arg::relCond(MacroAssembler::LessThan), arg0, arg1, result);
3249     return { };
3250 }
3251 
3252 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64ConvertSI64&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3253 {
3254     result = f64();
3255     append(ConvertInt64ToDouble, arg0, result);
3256     return { };
3257 }
3258 
3259 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Xor&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3260 {
3261     result = g64();
3262     append(Xor64, arg0, arg1, result);
3263     return { };
3264 }
3265 
3266 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64GeU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3267 {
3268     result = g32();
3269     append(Compare64, Arg::relCond(MacroAssembler::AboveOrEqual), arg0, arg1, result);
3270     return { };
3271 }
3272 
3273 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Mul&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3274 {
3275     result = g64();
3276     append(Mul64, arg0, arg1, result);
3277     return { };
3278 }
3279 
3280 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Sub&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3281 {
3282     result = f32();
3283     if (isValidForm(SubFloat, Arg::Tmp, Arg::Tmp, Arg::Tmp))
3284         append(SubFloat, arg0, arg1, result);
3285     else {
3286         RELEASE_ASSERT(isX86());
3287         append(MoveFloat, arg0, result);
3288         append(SubFloat, arg1, result);
3289     }
3290     return { };
3291 }
3292 
3293 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64PromoteF32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3294 {
3295     result = f64();
3296     append(ConvertFloatToDouble, arg0, result);
3297     return { };
3298 }
3299 
3300 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Add&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3301 {
3302     result = f64();
3303     append(AddDouble, arg0, arg1, result);
3304     return { };
3305 }
3306 
3307 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64GeS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3308 {
3309     result = g32();
3310     append(Compare64, Arg::relCond(MacroAssembler::GreaterThanOrEqual), arg0, arg1, result);
3311     return { };
3312 }
3313 
3314 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64ExtendUI32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3315 {
3316     result = g64();
3317     append(Move32, arg0, result);
3318     return { };
3319 }
3320 
3321 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Ne&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3322 {
3323     result = g32();
3324     RELEASE_ASSERT(arg0 &amp;&amp; arg1);
3325     append(Compare32, Arg::relCond(MacroAssembler::NotEqual), arg0, arg1, result);
3326     return { };
3327 }
3328 
3329 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64ReinterpretI64&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3330 {
3331     result = f64();
3332     append(Move64ToDouble, arg0, result);
3333     return { };
3334 }
3335 
3336 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Eq&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3337 {
3338     result = g32();
3339     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1, result);
3340     return { };
3341 }
3342 
3343 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Eq&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3344 {
3345     result = g32();
3346     append(Compare64, Arg::relCond(MacroAssembler::Equal), arg0, arg1, result);
3347     return { };
3348 }
3349 
3350 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Floor&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3351 {
3352     result = f32();
3353     append(FloorFloat, arg0, result);
3354     return { };
3355 }
3356 
3357 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32ConvertSI32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3358 {
3359     result = f32();
3360     append(ConvertInt32ToFloat, arg0, result);
3361     return { };
3362 }
3363 
3364 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Eqz&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3365 {
3366     result = g32();
3367     append(Test32, Arg::resCond(MacroAssembler::Zero), arg0, arg0, result);
3368     return { };
3369 }
3370 
3371 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64ReinterpretF64&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3372 {
3373     result = g64();
3374     append(MoveDoubleTo64, arg0, result);
3375     return { };
3376 }
3377 
3378 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64ShrS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3379 {
3380     return addShift(Type::I64, Rshift64, arg0, arg1, result);
3381 }
3382 
3383 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64ShrU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3384 {
3385     return addShift(Type::I64, Urshift64, arg0, arg1, result);
3386 }
3387 
3388 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Sqrt&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3389 {
3390     result = f64();
3391     append(SqrtDouble, arg0, result);
3392     return { };
3393 }
3394 
3395 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Shl&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3396 {
3397     return addShift(Type::I64, Lshift64, arg0, arg1, result);
3398 }
3399 
3400 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F32Gt&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3401 {
3402     result = g32();
3403     append(CompareFloat, Arg::doubleCond(MacroAssembler::DoubleGreaterThan), arg0, arg1, result);
3404     return { };
3405 }
3406 
3407 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32WrapI64&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3408 {
3409     result = g32();
3410     append(Move32, arg0, result);
3411     return { };
3412 }
3413 
3414 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Rotl&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3415 {
3416     if (isARM64()) {
3417         // ARM64 doesn&#39;t have a rotate left.
3418         auto newShift = g64();
3419         append(Move, arg1, newShift);
3420         append(Neg64, newShift);
3421         return addShift(Type::I32, RotateRight32, arg0, newShift, result);
3422     } else
3423         return addShift(Type::I32, RotateLeft32, arg0, arg1, result);
3424 }
3425 
3426 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32Rotr&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3427 {
3428     return addShift(Type::I32, RotateRight32, arg0, arg1, result);
3429 }
3430 
3431 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32GtU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3432 {
3433     result = g32();
3434     append(Compare32, Arg::relCond(MacroAssembler::Above), arg0, arg1, result);
3435     return { };
3436 }
3437 
3438 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64ExtendSI32&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3439 {
3440     result = g64();
3441     append(SignExtend32ToPtr, arg0, result);
3442     return { };
3443 }
3444 
3445 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I32GtS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3446 {
3447     result = g32();
3448     append(Compare32, Arg::relCond(MacroAssembler::GreaterThan), arg0, arg1, result);
3449     return { };
3450 }
3451 
3452 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Neg&gt;(ExpressionType arg0, ExpressionType&amp; result) -&gt; PartialResult
3453 {
3454     result = f64();
3455     if (isValidForm(NegateDouble, Arg::Tmp, Arg::Tmp))
3456         append(NegateDouble, arg0, result);
3457     else {
3458         auto constant = addConstant(Type::I64, bitwise_cast&lt;uint64_t&gt;(static_cast&lt;double&gt;(-0.0)));
3459         auto temp = g64();
3460         append(MoveDoubleTo64, arg0, temp);
3461         append(Xor64, constant, temp);
3462         append(Move64ToDouble, temp, result);
3463     }
3464     return { };
3465 }
3466 
3467 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::F64Max&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3468 {
<a name="91" id="anc91"></a><span class="line-modified">3469     result = f64();</span>
<span class="line-removed">3470 </span>
<span class="line-removed">3471     BasicBlock* isEqual = m_code.addBlock();</span>
<span class="line-removed">3472     BasicBlock* notEqual = m_code.addBlock();</span>
<span class="line-removed">3473     BasicBlock* lessThan = m_code.addBlock();</span>
<span class="line-removed">3474     BasicBlock* continuation = m_code.addBlock();</span>
<span class="line-removed">3475 </span>
<span class="line-removed">3476     append(m_currentBlock, BranchDouble, Arg::doubleCond(MacroAssembler::DoubleEqual), arg0, arg1);</span>
<span class="line-removed">3477     m_currentBlock-&gt;setSuccessors(isEqual, notEqual);</span>
<span class="line-removed">3478 </span>
<span class="line-removed">3479     append(isEqual, AndDouble, arg0, arg1, result);</span>
<span class="line-removed">3480     append(isEqual, Jump);</span>
<span class="line-removed">3481     isEqual-&gt;setSuccessors(continuation);</span>
<span class="line-removed">3482 </span>
<span class="line-removed">3483     append(notEqual, MoveDouble, arg0, result);</span>
<span class="line-removed">3484     append(notEqual, BranchDouble, Arg::doubleCond(MacroAssembler::DoubleLessThan), arg0, arg1);</span>
<span class="line-removed">3485     notEqual-&gt;setSuccessors(lessThan, continuation);</span>
<span class="line-removed">3486 </span>
<span class="line-removed">3487     append(lessThan, MoveDouble, arg1, result);</span>
<span class="line-removed">3488     append(lessThan, Jump);</span>
<span class="line-removed">3489     lessThan-&gt;setSuccessors(continuation);</span>
<span class="line-removed">3490 </span>
<span class="line-removed">3491     m_currentBlock = continuation;</span>
<span class="line-removed">3492 </span>
<span class="line-removed">3493     return { };</span>
3494 }
3495 
3496 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64LeU&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3497 {
3498     result = g32();
3499     append(Compare64, Arg::relCond(MacroAssembler::BelowOrEqual), arg0, arg1, result);
3500     return { };
3501 }
3502 
3503 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64LeS&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3504 {
3505     result = g32();
3506     append(Compare64, Arg::relCond(MacroAssembler::LessThanOrEqual), arg0, arg1, result);
3507     return { };
3508 }
3509 
3510 template&lt;&gt; auto AirIRGenerator::addOp&lt;OpType::I64Add&gt;(ExpressionType arg0, ExpressionType arg1, ExpressionType&amp; result) -&gt; PartialResult
3511 {
3512     result = g64();
3513     append(Add64, arg0, arg1, result);
3514     return { };
3515 }
3516 
3517 } } // namespace JSC::Wasm
3518 
3519 #endif // ENABLE(WEBASSEMBLY)
<a name="92" id="anc92"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="92" type="hidden" />
</body>
</html>