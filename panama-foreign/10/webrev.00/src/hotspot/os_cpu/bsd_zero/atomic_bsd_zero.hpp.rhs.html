<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/os_cpu/bsd_zero/atomic_bsd_zero.hpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>  1 /*
  2  * Copyright (c) 2003, 2019, Oracle and/or its affiliates. All rights reserved.
  3  * Copyright 2007, 2008, 2011, 2015, Red Hat, Inc.
  4  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  5  *
  6  * This code is free software; you can redistribute it and/or modify it
  7  * under the terms of the GNU General Public License version 2 only, as
  8  * published by the Free Software Foundation.
  9  *
 10  * This code is distributed in the hope that it will be useful, but WITHOUT
 11  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 12  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 13  * version 2 for more details (a copy is included in the LICENSE file that
 14  * accompanied this code).
 15  *
 16  * You should have received a copy of the GNU General Public License version
 17  * 2 along with this work; if not, write to the Free Software Foundation,
 18  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 19  *
 20  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 21  * or visit www.oracle.com if you need additional information or have any
 22  * questions.
 23  *
 24  */
 25 
 26 #ifndef OS_CPU_BSD_ZERO_ATOMIC_BSD_ZERO_HPP
 27 #define OS_CPU_BSD_ZERO_ATOMIC_BSD_ZERO_HPP
 28 
 29 #include &quot;runtime/os.hpp&quot;
 30 
 31 // Implementation of class atomic
 32 
 33 #ifdef M68K
 34 
 35 /*
 36  * __m68k_cmpxchg
 37  *
 38  * Atomically store newval in *ptr if *ptr is equal to oldval for user space.
 39  * Returns newval on success and oldval if no exchange happened.
 40  * This implementation is processor specific and works on
 41  * 68020 68030 68040 and 68060.
 42  *
 43  * It will not work on ColdFire, 68000 and 68010 since they lack the CAS
 44  * instruction.
 45  * Using a kernelhelper would be better for arch complete implementation.
 46  *
 47  */
 48 
 49 static inline int __m68k_cmpxchg(int oldval, int newval, volatile int *ptr) {
 50   int ret;
 51   __asm __volatile (&quot;cas%.l %0,%2,%1&quot;
 52                    : &quot;=d&quot; (ret), &quot;+m&quot; (*(ptr))
 53                    : &quot;d&quot; (newval), &quot;0&quot; (oldval));
 54   return ret;
 55 }
 56 
 57 /* Perform an atomic compare and swap: if the current value of `*PTR&#39;
 58    is OLDVAL, then write NEWVAL into `*PTR&#39;.  Return the contents of
 59    `*PTR&#39; before the operation.*/
 60 static inline int m68k_compare_and_swap(int newval,
 61                                         volatile int *ptr,
 62                                         int oldval) {
 63   for (;;) {
 64       int prev = *ptr;
 65       if (prev != oldval)
 66         return prev;
 67 
 68       if (__m68k_cmpxchg (prev, newval, ptr) == newval)
 69         // Success.
 70         return prev;
 71 
 72       // We failed even though prev == oldval.  Try again.
 73     }
 74 }
 75 
 76 /* Atomically add an int to memory.  */
 77 static inline int m68k_add_and_fetch(int add_value, volatile int *ptr) {
 78   for (;;) {
 79       // Loop until success.
 80 
 81       int prev = *ptr;
 82 
 83       if (__m68k_cmpxchg (prev, prev + add_value, ptr) == prev + add_value)
 84         return prev + add_value;
 85     }
 86 }
 87 
 88 /* Atomically write VALUE into `*PTR&#39; and returns the previous
 89    contents of `*PTR&#39;.  */
 90 static inline int m68k_lock_test_and_set(int newval, volatile int *ptr) {
 91   for (;;) {
 92       // Loop until success.
 93       int prev = *ptr;
 94 
 95       if (__m68k_cmpxchg (prev, newval, ptr) == prev)
 96         return prev;
 97     }
 98 }
 99 #endif // M68K
100 
101 #ifdef ARM
102 
103 /*
104  * __kernel_cmpxchg
105  *
106  * Atomically store newval in *ptr if *ptr is equal to oldval for user space.
107  * Return zero if *ptr was changed or non-zero if no exchange happened.
108  * The C flag is also set if *ptr was changed to allow for assembly
109  * optimization in the calling code.
110  *
111  */
112 
113 typedef int (__kernel_cmpxchg_t)(int oldval, int newval, volatile int *ptr);
114 #define __kernel_cmpxchg (*(__kernel_cmpxchg_t *) 0xffff0fc0)
115 
116 
117 
118 /* Perform an atomic compare and swap: if the current value of `*PTR&#39;
119    is OLDVAL, then write NEWVAL into `*PTR&#39;.  Return the contents of
120    `*PTR&#39; before the operation.*/
121 static inline int arm_compare_and_swap(int newval,
122                                        volatile int *ptr,
123                                        int oldval) {
124   for (;;) {
125       int prev = *ptr;
126       if (prev != oldval)
127         return prev;
128 
129       if (__kernel_cmpxchg (prev, newval, ptr) == 0)
130         // Success.
131         return prev;
132 
133       // We failed even though prev == oldval.  Try again.
134     }
135 }
136 
137 /* Atomically add an int to memory.  */
138 static inline int arm_add_and_fetch(int add_value, volatile int *ptr) {
139   for (;;) {
140       // Loop until a __kernel_cmpxchg succeeds.
141 
142       int prev = *ptr;
143 
144       if (__kernel_cmpxchg (prev, prev + add_value, ptr) == 0)
145         return prev + add_value;
146     }
147 }
148 
149 /* Atomically write VALUE into `*PTR&#39; and returns the previous
150    contents of `*PTR&#39;.  */
151 static inline int arm_lock_test_and_set(int newval, volatile int *ptr) {
152   for (;;) {
153       // Loop until a __kernel_cmpxchg succeeds.
154       int prev = *ptr;
155 
156       if (__kernel_cmpxchg (prev, newval, ptr) == 0)
157         return prev;
158     }
159 }
160 #endif // ARM
161 
162 template&lt;size_t byte_size&gt;
163 struct Atomic::PlatformAdd {
164   template&lt;typename D, typename I&gt;
165   D add_and_fetch(D volatile* dest, I add_value, atomic_memory_order order) const;
166 
167   template&lt;typename D, typename I&gt;
168   D fetch_and_add(D volatile* dest, I add_value, atomic_memory_order order) const {
169     return add_and_fetch(dest, add_value, order) - add_value;
170   }
171 };
172 
173 template&lt;&gt;
174 template&lt;typename D, typename I&gt;
175 inline D Atomic::PlatformAdd&lt;4&gt;::add_and_fetch(D volatile* dest, I add_value,
176                                                atomic_memory_order order) const {
177   STATIC_ASSERT(4 == sizeof(I));
178   STATIC_ASSERT(4 == sizeof(D));
179 
180 #ifdef ARM
181   return add_using_helper&lt;int&gt;(arm_add_and_fetch, dest, add_value);
182 #else
183 #ifdef M68K
184   return add_using_helper&lt;int&gt;(m68k_add_and_fetch, dest, add_value);
185 #else
186   return __sync_add_and_fetch(dest, add_value);
187 #endif // M68K
188 #endif // ARM
189 }
190 
191 template&lt;&gt;
<a name="1" id="anc1"></a><span class="line-modified">192 template&lt;typename D, typename I&gt;</span>
193 inline D Atomic::PlatformAdd&lt;8&gt;::add_and_fetch(D volatile* dest, I add_value,
194                                                atomic_memory_order order) const {
195   STATIC_ASSERT(8 == sizeof(I));
196   STATIC_ASSERT(8 == sizeof(D));
197 
198   return __sync_add_and_fetch(dest, add_value);
199 }
200 
201 template&lt;&gt;
202 template&lt;typename T&gt;
203 inline T Atomic::PlatformXchg&lt;4&gt;::operator()(T volatile* dest,
204                                              T exchange_value,
205                                              atomic_memory_order order) const {
206   STATIC_ASSERT(4 == sizeof(T));
207 #ifdef ARM
208   return xchg_using_helper&lt;int&gt;(arm_lock_test_and_set, dest, exchange_value);
209 #else
210 #ifdef M68K
211   return xchg_using_helper&lt;int&gt;(m68k_lock_test_and_set, dest, exchange_value);
212 #else
213   // __sync_lock_test_and_set is a bizarrely named atomic exchange
214   // operation.  Note that some platforms only support this with the
215   // limitation that the only valid value to store is the immediate
216   // constant 1.  There is a test for this in JNI_CreateJavaVM().
217   T result = __sync_lock_test_and_set (dest, exchange_value);
218   // All atomic operations are expected to be full memory barriers
219   // (see atomic.hpp). However, __sync_lock_test_and_set is not
220   // a full memory barrier, but an acquire barrier. Hence, this added
221   // barrier.
222   __sync_synchronize();
223   return result;
224 #endif // M68K
225 #endif // ARM
226 }
227 
228 template&lt;&gt;
229 template&lt;typename T&gt;
230 inline T Atomic::PlatformXchg&lt;8&gt;::operator()(T volatile* dest,
231                                              T exchange_value,
232                                              atomic_memory_order order) const {
233   STATIC_ASSERT(8 == sizeof(T));
234   T result = __sync_lock_test_and_set (dest, exchange_value);
235   __sync_synchronize();
236   return result;
237 }
238 
239 // No direct support for cmpxchg of bytes; emulate using int.
240 template&lt;&gt;
241 struct Atomic::PlatformCmpxchg&lt;1&gt; : Atomic::CmpxchgByteUsingInt {};
242 
243 template&lt;&gt;
244 template&lt;typename T&gt;
245 inline T Atomic::PlatformCmpxchg&lt;4&gt;::operator()(T volatile* dest,
246                                                 T compare_value,
247                                                 T exchange_value,
248                                                 atomic_memory_order order) const {
249   STATIC_ASSERT(4 == sizeof(T));
250 #ifdef ARM
251   return cmpxchg_using_helper&lt;int&gt;(arm_compare_and_swap, dest, compare_value, exchange_value);
252 #else
253 #ifdef M68K
254   return cmpxchg_using_helper&lt;int&gt;(m68k_compare_and_swap, dest, compare_value, exchange_value);
255 #else
256   return __sync_val_compare_and_swap(dest, compare_value, exchange_value);
257 #endif // M68K
258 #endif // ARM
259 }
260 
261 template&lt;&gt;
262 template&lt;typename T&gt;
263 inline T Atomic::PlatformCmpxchg&lt;8&gt;::operator()(T volatile* dest,
264                                                 T compare_value,
265                                                 T exchange_value,
266                                                 atomic_memory_order order) const {
267   STATIC_ASSERT(8 == sizeof(T));
268   return __sync_val_compare_and_swap(dest, compare_value, exchange_value);
269 }
270 
271 template&lt;&gt;
272 template&lt;typename T&gt;
273 inline T Atomic::PlatformLoad&lt;8&gt;::operator()(T const volatile* src) const {
274   STATIC_ASSERT(8 == sizeof(T));
275   volatile int64_t dest;
276   os::atomic_copy64(reinterpret_cast&lt;const volatile int64_t*&gt;(src), reinterpret_cast&lt;volatile int64_t*&gt;(&amp;dest));
277   return PrimitiveConversions::cast&lt;T&gt;(dest);
278 }
279 
280 template&lt;&gt;
281 template&lt;typename T&gt;
282 inline void Atomic::PlatformStore&lt;8&gt;::operator()(T volatile* dest,
283                                                  T store_value) const {
284   STATIC_ASSERT(8 == sizeof(T));
285   os::atomic_copy64(reinterpret_cast&lt;const volatile int64_t*&gt;(&amp;store_value), reinterpret_cast&lt;volatile int64_t*&gt;(dest));
286 }
287 
288 #endif // OS_CPU_BSD_ZERO_ATOMIC_BSD_ZERO_HPP
<a name="2" id="anc2"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="2" type="hidden" />
</body>
</html>