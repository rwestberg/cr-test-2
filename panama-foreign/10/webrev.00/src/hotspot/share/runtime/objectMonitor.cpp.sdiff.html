<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/runtime/objectMonitor.cpp</title>
    <link rel="stylesheet" href="../../../../style.css" />
  </head>
<body>
<center><a href="mutexLocker.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="objectMonitor.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/runtime/objectMonitor.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 1998, 2019, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
 228   return AllocateHeap(size, mtInternal);
 229 }
 230 void* ObjectMonitor::operator new[] (size_t size) throw() {
 231   return operator new (size);
 232 }
 233 void ObjectMonitor::operator delete(void* p) {
 234   FreeHeap(p);
 235 }
 236 void ObjectMonitor::operator delete[] (void *p) {
 237   operator delete(p);
 238 }
 239 
 240 // -----------------------------------------------------------------------------
 241 // Enter support
 242 
 243 void ObjectMonitor::enter(TRAPS) {
 244   // The following code is ordered to check the most common cases first
 245   // and to reduce RTS-&gt;RTO cache line upgrades on SPARC and IA32 processors.
 246   Thread * const Self = THREAD;
 247 
<span class="line-modified"> 248   void * cur = Atomic::cmpxchg(&amp;_owner, (void*)NULL, Self);</span>
 249   if (cur == NULL) {
 250     assert(_recursions == 0, &quot;invariant&quot;);
 251     return;
 252   }
 253 
 254   if (cur == Self) {
 255     // TODO-FIXME: check for integer overflow!  BUGID 6557169.
 256     _recursions++;
 257     return;
 258   }
 259 
 260   if (Self-&gt;is_lock_owned((address)cur)) {
 261     assert(_recursions == 0, &quot;internal state error&quot;);
 262     _recursions = 1;
<span class="line-modified"> 263     // Commute owner from a thread-specific on-stack BasicLockObject address to</span>
<span class="line-removed"> 264     // a full-fledged &quot;Thread *&quot;.</span>
<span class="line-removed"> 265     _owner = Self;</span>
 266     return;
 267   }
 268 
 269   // We&#39;ve encountered genuine contention.
 270   assert(Self-&gt;_Stalled == 0, &quot;invariant&quot;);
 271   Self-&gt;_Stalled = intptr_t(this);
 272 
 273   // Try one round of spinning *before* enqueueing Self
 274   // and before going through the awkward and expensive state
 275   // transitions.  The following spin is strictly optional ...
 276   // Note that if we acquire the monitor from an initial spin
 277   // we forgo posting JVMTI events and firing DTRACE probes.
 278   if (TrySpin(Self) &gt; 0) {
 279     assert(_owner == Self, &quot;must be Self: owner=&quot; INTPTR_FORMAT, p2i(_owner));
 280     assert(_recursions == 0, &quot;must be 0: recursions=&quot; INTX_FORMAT, _recursions);
 281     assert(((oop)object())-&gt;mark() == markWord::encode(this),
 282            &quot;object mark must match encoded this: mark=&quot; INTPTR_FORMAT
 283            &quot;, encoded this=&quot; INTPTR_FORMAT, ((oop)object())-&gt;mark().value(),
 284            markWord::encode(this).value());
 285     Self-&gt;_Stalled = 0;
</pre>
<hr />
<pre>
 386 
 387     // The current thread already owns the monitor and is not going to
 388     // call park() for the remainder of the monitor enter protocol. So
 389     // it doesn&#39;t matter if the JVMTI_EVENT_MONITOR_CONTENDED_ENTERED
 390     // event handler consumed an unpark() issued by the thread that
 391     // just exited the monitor.
 392   }
 393   if (event.should_commit()) {
 394     event.set_previousOwner((uintptr_t)_previous_owner_tid);
 395     event.commit();
 396   }
 397   OM_PERFDATA_OP(ContendedLockAttempts, inc());
 398 }
 399 
 400 // Caveat: TryLock() is not necessarily serializing if it returns failure.
 401 // Callers must compensate as needed.
 402 
 403 int ObjectMonitor::TryLock(Thread * Self) {
 404   void * own = _owner;
 405   if (own != NULL) return 0;
<span class="line-modified"> 406   if (Atomic::replace_if_null(&amp;_owner, Self)) {</span>
 407     assert(_recursions == 0, &quot;invariant&quot;);
 408     return 1;
 409   }
 410   // The lock had been free momentarily, but we lost the race to the lock.
 411   // Interference -- the CAS failed.
 412   // We can either return -1 or retry.
 413   // Retry doesn&#39;t make as much sense because the lock was just acquired.
 414   return -1;
 415 }
 416 
 417 // Convert the fields used by is_busy() to a string that can be
 418 // used for diagnostic output.
 419 const char* ObjectMonitor::is_busy_to_string(stringStream* ss) {
 420   ss-&gt;print(&quot;is_busy: contentions=%d, waiters=%d, owner=&quot; INTPTR_FORMAT
 421             &quot;, cxq=&quot; INTPTR_FORMAT &quot;, EntryList=&quot; INTPTR_FORMAT, _contentions,
 422             _waiters, p2i(_owner), p2i(_cxq), p2i(_EntryList));
 423   return ss-&gt;base();
 424 }
 425 
 426 #define MAX_RECHECK_INTERVAL 1000
</pre>
<hr />
<pre>
 845 // thread acquires the lock and then drops the lock, at which time the
 846 // exiting thread will notice and unpark the stranded thread, or, (b)
 847 // the timer expires.  If the lock is high traffic then the stranding latency
 848 // will be low due to (a).  If the lock is low traffic then the odds of
 849 // stranding are lower, although the worst-case stranding latency
 850 // is longer.  Critically, we don&#39;t want to put excessive load in the
 851 // platform&#39;s timer subsystem.  We want to minimize both the timer injection
 852 // rate (timers created/sec) as well as the number of timers active at
 853 // any one time.  (more precisely, we want to minimize timer-seconds, which is
 854 // the integral of the # of active timers at any instant over time).
 855 // Both impinge on OS scalability.  Given that, at most one thread parked on
 856 // a monitor will use a timer.
 857 //
 858 // There is also the risk of a futile wake-up. If we drop the lock
 859 // another thread can reacquire the lock immediately, and we can
 860 // then wake a thread unnecessarily. This is benign, and we&#39;ve
 861 // structured the code so the windows are short and the frequency
 862 // of such futile wakups is low.
 863 
 864 void ObjectMonitor::exit(bool not_suspended, TRAPS) {
<span class="line-modified"> 865   Thread * const Self = THREAD;</span>
<span class="line-modified"> 866   if (THREAD != _owner) {</span>
<span class="line-modified"> 867     if (THREAD-&gt;is_lock_owned((address) _owner)) {</span>
<span class="line-modified"> 868       // Transmute _owner from a BasicLock pointer to a Thread address.</span>
<span class="line-removed"> 869       // We don&#39;t need to hold _mutex for this transition.</span>
<span class="line-removed"> 870       // Non-null to Non-null is safe as long as all readers can</span>
<span class="line-removed"> 871       // tolerate either flavor.</span>
 872       assert(_recursions == 0, &quot;invariant&quot;);
<span class="line-modified"> 873       _owner = THREAD;</span>
 874       _recursions = 0;
 875     } else {
 876       // Apparent unbalanced locking ...
 877       // Naively we&#39;d like to throw IllegalMonitorStateException.
 878       // As a practical matter we can neither allocate nor throw an
 879       // exception as ::exit() can be called from leaf routines.
 880       // see x86_32.ad Fast_Unlock() and the I1 and I2 properties.
 881       // Upon deeper reflection, however, in a properly run JVM the only
 882       // way we should encounter this situation is in the presence of
 883       // unbalanced JNI locking. TODO: CheckJNICalls.
 884       // See also: CR4414101
 885 #ifdef ASSERT
 886       LogStreamHandle(Error, monitorinflation) lsh;
 887       lsh.print_cr(&quot;ERROR: ObjectMonitor::exit(): thread=&quot; INTPTR_FORMAT
 888                     &quot; is exiting an ObjectMonitor it does not own.&quot;, p2i(THREAD));
 889       lsh.print_cr(&quot;The imbalance is possibly caused by JNI locking.&quot;);
 890       print_debug_style_on(&amp;lsh);
 891 #endif
 892       assert(false, &quot;Non-balanced monitor enter/exit!&quot;);
 893       return;
</pre>
<hr />
<pre>
 897   if (_recursions != 0) {
 898     _recursions--;        // this is simple recursive enter
 899     return;
 900   }
 901 
 902   // Invariant: after setting Responsible=null an thread must execute
 903   // a MEMBAR or other serializing instruction before fetching EntryList|cxq.
 904   _Responsible = NULL;
 905 
 906 #if INCLUDE_JFR
 907   // get the owner&#39;s thread id for the MonitorEnter event
 908   // if it is enabled and the thread isn&#39;t suspended
 909   if (not_suspended &amp;&amp; EventJavaMonitorEnter::is_enabled()) {
 910     _previous_owner_tid = JFR_THREAD_ID(Self);
 911   }
 912 #endif
 913 
 914   for (;;) {
 915     assert(THREAD == _owner, &quot;invariant&quot;);
 916 

 917     // release semantics: prior loads and stores from within the critical section
 918     // must not float (reorder) past the following store that drops the lock.
<span class="line-modified"> 919     Atomic::release_store(&amp;_owner, (void*)NULL);   // drop the lock</span>
<span class="line-modified"> 920     OrderAccess::storeload();                      // See if we need to wake a successor</span>




 921     if ((intptr_t(_EntryList)|intptr_t(_cxq)) == 0 || _succ != NULL) {
 922       return;
 923     }
 924     // Other threads are blocked trying to acquire the lock.
 925 
 926     // Normally the exiting thread is responsible for ensuring succession,
 927     // but if other successors are ready or other entering threads are spinning
 928     // then this thread can simply store NULL into _owner and exit without
 929     // waking a successor.  The existence of spinners or ready successors
 930     // guarantees proper succession (liveness).  Responsibility passes to the
 931     // ready or running successors.  The exiting thread delegates the duty.
 932     // More precisely, if a successor already exists this thread is absolved
 933     // of the responsibility of waking (unparking) one.
 934     //
 935     // The _succ variable is critical to reducing futile wakeup frequency.
 936     // _succ identifies the &quot;heir presumptive&quot; thread that has been made
 937     // ready (unparked) but that has not yet run.  We need only one such
 938     // successor thread to guarantee progress.
 939     // See http://www.usenix.org/events/jvm01/full_papers/dice/dice.pdf
 940     // section 3.3 &quot;Futile Wakeup Throttling&quot; for details.
</pre>
<hr />
<pre>
 942     // Note that spinners in Enter() also set _succ non-null.
 943     // In the current implementation spinners opportunistically set
 944     // _succ so that exiting threads might avoid waking a successor.
 945     // Another less appealing alternative would be for the exiting thread
 946     // to drop the lock and then spin briefly to see if a spinner managed
 947     // to acquire the lock.  If so, the exiting thread could exit
 948     // immediately without waking a successor, otherwise the exiting
 949     // thread would need to dequeue and wake a successor.
 950     // (Note that we&#39;d need to make the post-drop spin short, but no
 951     // shorter than the worst-case round-trip cache-line migration time.
 952     // The dropped lock needs to become visible to the spinner, and then
 953     // the acquisition of the lock by the spinner must become visible to
 954     // the exiting thread).
 955 
 956     // It appears that an heir-presumptive (successor) must be made ready.
 957     // Only the current lock owner can manipulate the EntryList or
 958     // drain _cxq, so we need to reacquire the lock.  If we fail
 959     // to reacquire the lock the responsibility for ensuring succession
 960     // falls to the new owner.
 961     //
<span class="line-modified"> 962     if (!Atomic::replace_if_null(&amp;_owner, THREAD)) {</span>
 963       return;
 964     }
 965 
 966     guarantee(_owner == THREAD, &quot;invariant&quot;);
 967 
 968     ObjectWaiter * w = NULL;
 969 
 970     w = _EntryList;
 971     if (w != NULL) {
 972       // I&#39;d like to write: guarantee (w-&gt;_thread != Self).
 973       // But in practice an exiting thread may find itself on the EntryList.
 974       // Let&#39;s say thread T1 calls O.wait().  Wait() enqueues T1 on O&#39;s waitset and
 975       // then calls exit().  Exit release the lock by setting O._owner to NULL.
 976       // Let&#39;s say T1 then stalls.  T2 acquires O and calls O.notify().  The
 977       // notify() operation moves T1 from O&#39;s waitset to O&#39;s EntryList. T2 then
 978       // release the lock &quot;O&quot;.  T2 resumes immediately after the ST of null into
 979       // _owner, above.  T2 notices that the EntryList is populated, so it
 980       // reacquires the lock and then finds itself on the EntryList.
 981       // Given all that, we have to tolerate the circumstance where &quot;w&quot; is
 982       // associated with Self.
</pre>
<hr />
<pre>
1075 
1076 
1077 void ObjectMonitor::ExitEpilog(Thread * Self, ObjectWaiter * Wakee) {
1078   assert(_owner == Self, &quot;invariant&quot;);
1079 
1080   // Exit protocol:
1081   // 1. ST _succ = wakee
1082   // 2. membar #loadstore|#storestore;
1083   // 2. ST _owner = NULL
1084   // 3. unpark(wakee)
1085 
1086   _succ = Wakee-&gt;_thread;
1087   ParkEvent * Trigger = Wakee-&gt;_event;
1088 
1089   // Hygiene -- once we&#39;ve set _owner = NULL we can&#39;t safely dereference Wakee again.
1090   // The thread associated with Wakee may have grabbed the lock and &quot;Wakee&quot; may be
1091   // out-of-scope (non-extant).
1092   Wakee  = NULL;
1093 
1094   // Drop the lock
<span class="line-modified">1095   Atomic::release_store(&amp;_owner, (void*)NULL);</span>
<span class="line-modified">1096   OrderAccess::fence();                               // ST _owner vs LD in unpark()</span>

1097 
1098   DTRACE_MONITOR_PROBE(contended__exit, this, object(), Self);
1099   Trigger-&gt;unpark();
1100 
1101   // Maintain stats and report events to JVMTI
1102   OM_PERFDATA_OP(Parks, inc());
1103 }
1104 
1105 
1106 // -----------------------------------------------------------------------------
1107 // Class Loader deadlock handling.
1108 //
1109 // complete_exit exits a lock returning recursion count
1110 // complete_exit/reenter operate as a wait without waiting
1111 // complete_exit requires an inflated monitor
1112 // The _owner field is not always the Thread addr even with an
1113 // inflated monitor, e.g. the monitor can be inflated by a non-owning
1114 // thread due to contention.
1115 intx ObjectMonitor::complete_exit(TRAPS) {
1116   Thread * const Self = THREAD;
1117   assert(Self-&gt;is_Java_thread(), &quot;Must be Java thread!&quot;);
1118   JavaThread *jt = (JavaThread *)THREAD;
1119 
1120   assert(InitDone, &quot;Unexpectedly not initialized&quot;);
1121 
<span class="line-modified">1122   if (THREAD != _owner) {</span>
<span class="line-modified">1123     if (THREAD-&gt;is_lock_owned ((address)_owner)) {</span>

1124       assert(_recursions == 0, &quot;internal state error&quot;);
<span class="line-modified">1125       _owner = THREAD;   // Convert from basiclock addr to Thread addr</span>
1126       _recursions = 0;
1127     }
1128   }
1129 
1130   guarantee(Self == _owner, &quot;complete_exit not owner&quot;);
1131   intx save = _recursions; // record the old recursion count
1132   _recursions = 0;        // set the recursion level to be 0
1133   exit(true, Self);           // exit the monitor
1134   guarantee(_owner != Self, &quot;invariant&quot;);
1135   return save;
1136 }
1137 
1138 // reenter() enters a lock and sets recursion count
1139 // complete_exit/reenter operate as a wait without waiting
1140 void ObjectMonitor::reenter(intx recursions, TRAPS) {
1141   Thread * const Self = THREAD;
1142   assert(Self-&gt;is_Java_thread(), &quot;Must be Java thread!&quot;);
1143   JavaThread *jt = (JavaThread *)THREAD;
1144 
1145   guarantee(_owner != Self, &quot;reenter already owner&quot;);
</pre>
<hr />
<pre>
1150 }
1151 
1152 // Checks that the current THREAD owns this monitor and causes an
1153 // immediate return if it doesn&#39;t. We don&#39;t use the CHECK macro
1154 // because we want the IMSE to be the only exception that is thrown
1155 // from the call site when false is returned. Any other pending
1156 // exception is ignored.
1157 #define CHECK_OWNER()                                                  \
1158   do {                                                                 \
1159     if (!check_owner(THREAD)) {                                        \
1160        assert(HAS_PENDING_EXCEPTION, &quot;expected a pending IMSE here.&quot;); \
1161        return;                                                         \
1162      }                                                                 \
1163   } while (false)
1164 
1165 // Returns true if the specified thread owns the ObjectMonitor.
1166 // Otherwise returns false and throws IllegalMonitorStateException
1167 // (IMSE). If there is a pending exception and the specified thread
1168 // is not the owner, that exception will be replaced by the IMSE.
1169 bool ObjectMonitor::check_owner(Thread* THREAD) {
<span class="line-modified">1170   if (_owner == THREAD) {</span>

1171     return true;
1172   }
<span class="line-modified">1173   if (THREAD-&gt;is_lock_owned((address)_owner)) {</span>
<span class="line-modified">1174     _owner = THREAD;  // convert from BasicLock addr to Thread addr</span>
1175     _recursions = 0;
1176     return true;
1177   }
1178   THROW_MSG_(vmSymbols::java_lang_IllegalMonitorStateException(),
1179              &quot;current thread is not owner&quot;, false);
1180 }
1181 
1182 static void post_monitor_wait_event(EventJavaMonitorWait* event,
1183                                     ObjectMonitor* monitor,
1184                                     jlong notifier_tid,
1185                                     jlong timeout,
1186                                     bool timedout) {
1187   assert(event != NULL, &quot;invariant&quot;);
1188   assert(monitor != NULL, &quot;invariant&quot;);
1189   event-&gt;set_monitorClass(((oop)monitor-&gt;object())-&gt;klass());
1190   event-&gt;set_timeout(timeout);
1191   event-&gt;set_address((uintptr_t)monitor-&gt;object_addr());
1192   event-&gt;set_notifier(notifier_tid);
1193   event-&gt;set_timedOut(timedout);
1194   event-&gt;commit();
</pre>
<hr />
<pre>
1663     // We periodically check to see if there&#39;s a safepoint pending.
1664     if ((ctr &amp; 0xFF) == 0) {
1665       if (SafepointMechanism::should_block(Self)) {
1666         goto Abort;           // abrupt spin egress
1667       }
1668       SpinPause();
1669     }
1670 
1671     // Probe _owner with TATAS
1672     // If this thread observes the monitor transition or flicker
1673     // from locked to unlocked to locked, then the odds that this
1674     // thread will acquire the lock in this spin attempt go down
1675     // considerably.  The same argument applies if the CAS fails
1676     // or if we observe _owner change from one non-null value to
1677     // another non-null value.   In such cases we might abort
1678     // the spin without prejudice or apply a &quot;penalty&quot; to the
1679     // spin count-down variable &quot;ctr&quot;, reducing it by 100, say.
1680 
1681     Thread * ox = (Thread *) _owner;
1682     if (ox == NULL) {
<span class="line-modified">1683       ox = (Thread*)Atomic::cmpxchg(&amp;_owner, (void*)NULL, Self);</span>
1684       if (ox == NULL) {
1685         // The CAS succeeded -- this thread acquired ownership
1686         // Take care of some bookkeeping to exit spin state.
1687         if (_succ == Self) {
1688           _succ = NULL;
1689         }
1690 
1691         // Increase _SpinDuration :
1692         // The spin was successful (profitable) so we tend toward
1693         // longer spin attempts in the future.
1694         // CONSIDER: factor &quot;ctr&quot; into the _SpinDuration adjustment.
1695         // If we acquired the lock early in the spin cycle it
1696         // makes sense to increase _SpinDuration proportionally.
1697         // Note that we don&#39;t clamp SpinDuration precisely at SpinLimit.
1698         int x = _SpinDuration;
1699         if (x &lt; Knob_SpinLimit) {
1700           if (x &lt; Knob_Poverty) x = Knob_Poverty;
1701           _SpinDuration = x + Knob_Bonus;
1702         }
1703         return 1;
</pre>
<hr />
<pre>
1967 //   }
1968 //   _owner = 0x0000000000000000
1969 //   _previous_owner_tid = 0
1970 //   _recursions = 0
1971 //   _EntryList = 0x0000000000000000
1972 //   _cxq = 0x0000000000000000
1973 //   _succ = 0x0000000000000000
1974 //   _Responsible = 0x0000000000000000
1975 //   _Spinner = 0
1976 //   _SpinDuration = 5000
1977 //   _contentions = 0
1978 //   _WaitSet = 0x0000700009756248
1979 //   _waiters = 1
1980 //   _WaitSetLock = 0
1981 // }
1982 //
1983 void ObjectMonitor::print_debug_style_on(outputStream* st) const {
1984   st-&gt;print_cr(&quot;(ObjectMonitor*) &quot; INTPTR_FORMAT &quot; = {&quot;, p2i(this));
1985   st-&gt;print_cr(&quot;  _header = &quot; INTPTR_FORMAT, header().value());
1986   st-&gt;print_cr(&quot;  _object = &quot; INTPTR_FORMAT, p2i(_object));
<span class="line-modified">1987   st-&gt;print_cr(&quot;  _next_om = &quot; INTPTR_FORMAT, p2i(_next_om));</span>
1988   st-&gt;print_cr(&quot;  _pad_buf0 = {&quot;);
1989   st-&gt;print_cr(&quot;    [0] = &#39;\\0&#39;&quot;);
1990   st-&gt;print_cr(&quot;    ...&quot;);
1991   st-&gt;print_cr(&quot;    [%d] = &#39;\\0&#39;&quot;, (int)sizeof(_pad_buf0) - 1);
1992   st-&gt;print_cr(&quot;  }&quot;);
1993   st-&gt;print_cr(&quot;  _owner = &quot; INTPTR_FORMAT, p2i(_owner));
1994   st-&gt;print_cr(&quot;  _previous_owner_tid = &quot; JLONG_FORMAT, _previous_owner_tid);
1995   st-&gt;print_cr(&quot;  _recursions = &quot; INTX_FORMAT, _recursions);
1996   st-&gt;print_cr(&quot;  _EntryList = &quot; INTPTR_FORMAT, p2i(_EntryList));
1997   st-&gt;print_cr(&quot;  _cxq = &quot; INTPTR_FORMAT, p2i(_cxq));
1998   st-&gt;print_cr(&quot;  _succ = &quot; INTPTR_FORMAT, p2i(_succ));
1999   st-&gt;print_cr(&quot;  _Responsible = &quot; INTPTR_FORMAT, p2i(_Responsible));
2000   st-&gt;print_cr(&quot;  _Spinner = %d&quot;, _Spinner);
2001   st-&gt;print_cr(&quot;  _SpinDuration = %d&quot;, _SpinDuration);
2002   st-&gt;print_cr(&quot;  _contentions = %d&quot;, _contentions);
2003   st-&gt;print_cr(&quot;  _WaitSet = &quot; INTPTR_FORMAT, p2i(_WaitSet));
2004   st-&gt;print_cr(&quot;  _waiters = %d&quot;, _waiters);
2005   st-&gt;print_cr(&quot;  _WaitSetLock = %d&quot;, _WaitSetLock);
2006   st-&gt;print_cr(&quot;}&quot;);
2007 }
</pre>
</td>
<td>
<hr />
<pre>
   1 /*
<span class="line-modified">   2  * Copyright (c) 1998, 2020, Oracle and/or its affiliates. All rights reserved.</span>
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
</pre>
<hr />
<pre>
 228   return AllocateHeap(size, mtInternal);
 229 }
 230 void* ObjectMonitor::operator new[] (size_t size) throw() {
 231   return operator new (size);
 232 }
 233 void ObjectMonitor::operator delete(void* p) {
 234   FreeHeap(p);
 235 }
 236 void ObjectMonitor::operator delete[] (void *p) {
 237   operator delete(p);
 238 }
 239 
 240 // -----------------------------------------------------------------------------
 241 // Enter support
 242 
 243 void ObjectMonitor::enter(TRAPS) {
 244   // The following code is ordered to check the most common cases first
 245   // and to reduce RTS-&gt;RTO cache line upgrades on SPARC and IA32 processors.
 246   Thread * const Self = THREAD;
 247 
<span class="line-modified"> 248   void* cur = try_set_owner_from(NULL, Self);</span>
 249   if (cur == NULL) {
 250     assert(_recursions == 0, &quot;invariant&quot;);
 251     return;
 252   }
 253 
 254   if (cur == Self) {
 255     // TODO-FIXME: check for integer overflow!  BUGID 6557169.
 256     _recursions++;
 257     return;
 258   }
 259 
 260   if (Self-&gt;is_lock_owned((address)cur)) {
 261     assert(_recursions == 0, &quot;internal state error&quot;);
 262     _recursions = 1;
<span class="line-modified"> 263     set_owner_from_BasicLock(cur, Self);  // Convert from BasicLock* to Thread*.</span>


 264     return;
 265   }
 266 
 267   // We&#39;ve encountered genuine contention.
 268   assert(Self-&gt;_Stalled == 0, &quot;invariant&quot;);
 269   Self-&gt;_Stalled = intptr_t(this);
 270 
 271   // Try one round of spinning *before* enqueueing Self
 272   // and before going through the awkward and expensive state
 273   // transitions.  The following spin is strictly optional ...
 274   // Note that if we acquire the monitor from an initial spin
 275   // we forgo posting JVMTI events and firing DTRACE probes.
 276   if (TrySpin(Self) &gt; 0) {
 277     assert(_owner == Self, &quot;must be Self: owner=&quot; INTPTR_FORMAT, p2i(_owner));
 278     assert(_recursions == 0, &quot;must be 0: recursions=&quot; INTX_FORMAT, _recursions);
 279     assert(((oop)object())-&gt;mark() == markWord::encode(this),
 280            &quot;object mark must match encoded this: mark=&quot; INTPTR_FORMAT
 281            &quot;, encoded this=&quot; INTPTR_FORMAT, ((oop)object())-&gt;mark().value(),
 282            markWord::encode(this).value());
 283     Self-&gt;_Stalled = 0;
</pre>
<hr />
<pre>
 384 
 385     // The current thread already owns the monitor and is not going to
 386     // call park() for the remainder of the monitor enter protocol. So
 387     // it doesn&#39;t matter if the JVMTI_EVENT_MONITOR_CONTENDED_ENTERED
 388     // event handler consumed an unpark() issued by the thread that
 389     // just exited the monitor.
 390   }
 391   if (event.should_commit()) {
 392     event.set_previousOwner((uintptr_t)_previous_owner_tid);
 393     event.commit();
 394   }
 395   OM_PERFDATA_OP(ContendedLockAttempts, inc());
 396 }
 397 
 398 // Caveat: TryLock() is not necessarily serializing if it returns failure.
 399 // Callers must compensate as needed.
 400 
 401 int ObjectMonitor::TryLock(Thread * Self) {
 402   void * own = _owner;
 403   if (own != NULL) return 0;
<span class="line-modified"> 404   if (try_set_owner_from(NULL, Self) == NULL) {</span>
 405     assert(_recursions == 0, &quot;invariant&quot;);
 406     return 1;
 407   }
 408   // The lock had been free momentarily, but we lost the race to the lock.
 409   // Interference -- the CAS failed.
 410   // We can either return -1 or retry.
 411   // Retry doesn&#39;t make as much sense because the lock was just acquired.
 412   return -1;
 413 }
 414 
 415 // Convert the fields used by is_busy() to a string that can be
 416 // used for diagnostic output.
 417 const char* ObjectMonitor::is_busy_to_string(stringStream* ss) {
 418   ss-&gt;print(&quot;is_busy: contentions=%d, waiters=%d, owner=&quot; INTPTR_FORMAT
 419             &quot;, cxq=&quot; INTPTR_FORMAT &quot;, EntryList=&quot; INTPTR_FORMAT, _contentions,
 420             _waiters, p2i(_owner), p2i(_cxq), p2i(_EntryList));
 421   return ss-&gt;base();
 422 }
 423 
 424 #define MAX_RECHECK_INTERVAL 1000
</pre>
<hr />
<pre>
 843 // thread acquires the lock and then drops the lock, at which time the
 844 // exiting thread will notice and unpark the stranded thread, or, (b)
 845 // the timer expires.  If the lock is high traffic then the stranding latency
 846 // will be low due to (a).  If the lock is low traffic then the odds of
 847 // stranding are lower, although the worst-case stranding latency
 848 // is longer.  Critically, we don&#39;t want to put excessive load in the
 849 // platform&#39;s timer subsystem.  We want to minimize both the timer injection
 850 // rate (timers created/sec) as well as the number of timers active at
 851 // any one time.  (more precisely, we want to minimize timer-seconds, which is
 852 // the integral of the # of active timers at any instant over time).
 853 // Both impinge on OS scalability.  Given that, at most one thread parked on
 854 // a monitor will use a timer.
 855 //
 856 // There is also the risk of a futile wake-up. If we drop the lock
 857 // another thread can reacquire the lock immediately, and we can
 858 // then wake a thread unnecessarily. This is benign, and we&#39;ve
 859 // structured the code so the windows are short and the frequency
 860 // of such futile wakups is low.
 861 
 862 void ObjectMonitor::exit(bool not_suspended, TRAPS) {
<span class="line-modified"> 863   Thread* const Self = THREAD;</span>
<span class="line-modified"> 864   void* cur = Atomic::load(&amp;_owner);</span>
<span class="line-modified"> 865   if (THREAD != cur) {</span>
<span class="line-modified"> 866     if (THREAD-&gt;is_lock_owned((address)cur)) {</span>



 867       assert(_recursions == 0, &quot;invariant&quot;);
<span class="line-modified"> 868       set_owner_from_BasicLock(cur, Self);  // Convert from BasicLock* to Thread*.</span>
 869       _recursions = 0;
 870     } else {
 871       // Apparent unbalanced locking ...
 872       // Naively we&#39;d like to throw IllegalMonitorStateException.
 873       // As a practical matter we can neither allocate nor throw an
 874       // exception as ::exit() can be called from leaf routines.
 875       // see x86_32.ad Fast_Unlock() and the I1 and I2 properties.
 876       // Upon deeper reflection, however, in a properly run JVM the only
 877       // way we should encounter this situation is in the presence of
 878       // unbalanced JNI locking. TODO: CheckJNICalls.
 879       // See also: CR4414101
 880 #ifdef ASSERT
 881       LogStreamHandle(Error, monitorinflation) lsh;
 882       lsh.print_cr(&quot;ERROR: ObjectMonitor::exit(): thread=&quot; INTPTR_FORMAT
 883                     &quot; is exiting an ObjectMonitor it does not own.&quot;, p2i(THREAD));
 884       lsh.print_cr(&quot;The imbalance is possibly caused by JNI locking.&quot;);
 885       print_debug_style_on(&amp;lsh);
 886 #endif
 887       assert(false, &quot;Non-balanced monitor enter/exit!&quot;);
 888       return;
</pre>
<hr />
<pre>
 892   if (_recursions != 0) {
 893     _recursions--;        // this is simple recursive enter
 894     return;
 895   }
 896 
 897   // Invariant: after setting Responsible=null an thread must execute
 898   // a MEMBAR or other serializing instruction before fetching EntryList|cxq.
 899   _Responsible = NULL;
 900 
 901 #if INCLUDE_JFR
 902   // get the owner&#39;s thread id for the MonitorEnter event
 903   // if it is enabled and the thread isn&#39;t suspended
 904   if (not_suspended &amp;&amp; EventJavaMonitorEnter::is_enabled()) {
 905     _previous_owner_tid = JFR_THREAD_ID(Self);
 906   }
 907 #endif
 908 
 909   for (;;) {
 910     assert(THREAD == _owner, &quot;invariant&quot;);
 911 
<span class="line-added"> 912     // Drop the lock.</span>
 913     // release semantics: prior loads and stores from within the critical section
 914     // must not float (reorder) past the following store that drops the lock.
<span class="line-modified"> 915     // Uses a storeload to separate release_store(owner) from the</span>
<span class="line-modified"> 916     // successor check. The try_set_owner() below uses cmpxchg() so</span>
<span class="line-added"> 917     // we get the fence down there.</span>
<span class="line-added"> 918     release_clear_owner(Self);</span>
<span class="line-added"> 919     OrderAccess::storeload();</span>
<span class="line-added"> 920 </span>
 921     if ((intptr_t(_EntryList)|intptr_t(_cxq)) == 0 || _succ != NULL) {
 922       return;
 923     }
 924     // Other threads are blocked trying to acquire the lock.
 925 
 926     // Normally the exiting thread is responsible for ensuring succession,
 927     // but if other successors are ready or other entering threads are spinning
 928     // then this thread can simply store NULL into _owner and exit without
 929     // waking a successor.  The existence of spinners or ready successors
 930     // guarantees proper succession (liveness).  Responsibility passes to the
 931     // ready or running successors.  The exiting thread delegates the duty.
 932     // More precisely, if a successor already exists this thread is absolved
 933     // of the responsibility of waking (unparking) one.
 934     //
 935     // The _succ variable is critical to reducing futile wakeup frequency.
 936     // _succ identifies the &quot;heir presumptive&quot; thread that has been made
 937     // ready (unparked) but that has not yet run.  We need only one such
 938     // successor thread to guarantee progress.
 939     // See http://www.usenix.org/events/jvm01/full_papers/dice/dice.pdf
 940     // section 3.3 &quot;Futile Wakeup Throttling&quot; for details.
</pre>
<hr />
<pre>
 942     // Note that spinners in Enter() also set _succ non-null.
 943     // In the current implementation spinners opportunistically set
 944     // _succ so that exiting threads might avoid waking a successor.
 945     // Another less appealing alternative would be for the exiting thread
 946     // to drop the lock and then spin briefly to see if a spinner managed
 947     // to acquire the lock.  If so, the exiting thread could exit
 948     // immediately without waking a successor, otherwise the exiting
 949     // thread would need to dequeue and wake a successor.
 950     // (Note that we&#39;d need to make the post-drop spin short, but no
 951     // shorter than the worst-case round-trip cache-line migration time.
 952     // The dropped lock needs to become visible to the spinner, and then
 953     // the acquisition of the lock by the spinner must become visible to
 954     // the exiting thread).
 955 
 956     // It appears that an heir-presumptive (successor) must be made ready.
 957     // Only the current lock owner can manipulate the EntryList or
 958     // drain _cxq, so we need to reacquire the lock.  If we fail
 959     // to reacquire the lock the responsibility for ensuring succession
 960     // falls to the new owner.
 961     //
<span class="line-modified"> 962     if (try_set_owner_from(NULL, Self) != NULL) {</span>
 963       return;
 964     }
 965 
 966     guarantee(_owner == THREAD, &quot;invariant&quot;);
 967 
 968     ObjectWaiter * w = NULL;
 969 
 970     w = _EntryList;
 971     if (w != NULL) {
 972       // I&#39;d like to write: guarantee (w-&gt;_thread != Self).
 973       // But in practice an exiting thread may find itself on the EntryList.
 974       // Let&#39;s say thread T1 calls O.wait().  Wait() enqueues T1 on O&#39;s waitset and
 975       // then calls exit().  Exit release the lock by setting O._owner to NULL.
 976       // Let&#39;s say T1 then stalls.  T2 acquires O and calls O.notify().  The
 977       // notify() operation moves T1 from O&#39;s waitset to O&#39;s EntryList. T2 then
 978       // release the lock &quot;O&quot;.  T2 resumes immediately after the ST of null into
 979       // _owner, above.  T2 notices that the EntryList is populated, so it
 980       // reacquires the lock and then finds itself on the EntryList.
 981       // Given all that, we have to tolerate the circumstance where &quot;w&quot; is
 982       // associated with Self.
</pre>
<hr />
<pre>
1075 
1076 
1077 void ObjectMonitor::ExitEpilog(Thread * Self, ObjectWaiter * Wakee) {
1078   assert(_owner == Self, &quot;invariant&quot;);
1079 
1080   // Exit protocol:
1081   // 1. ST _succ = wakee
1082   // 2. membar #loadstore|#storestore;
1083   // 2. ST _owner = NULL
1084   // 3. unpark(wakee)
1085 
1086   _succ = Wakee-&gt;_thread;
1087   ParkEvent * Trigger = Wakee-&gt;_event;
1088 
1089   // Hygiene -- once we&#39;ve set _owner = NULL we can&#39;t safely dereference Wakee again.
1090   // The thread associated with Wakee may have grabbed the lock and &quot;Wakee&quot; may be
1091   // out-of-scope (non-extant).
1092   Wakee  = NULL;
1093 
1094   // Drop the lock
<span class="line-modified">1095   // Uses a fence to separate release_store(owner) from the LD in unpark().</span>
<span class="line-modified">1096   release_clear_owner(Self);</span>
<span class="line-added">1097   OrderAccess::fence();</span>
1098 
1099   DTRACE_MONITOR_PROBE(contended__exit, this, object(), Self);
1100   Trigger-&gt;unpark();
1101 
1102   // Maintain stats and report events to JVMTI
1103   OM_PERFDATA_OP(Parks, inc());
1104 }
1105 
1106 
1107 // -----------------------------------------------------------------------------
1108 // Class Loader deadlock handling.
1109 //
1110 // complete_exit exits a lock returning recursion count
1111 // complete_exit/reenter operate as a wait without waiting
1112 // complete_exit requires an inflated monitor
1113 // The _owner field is not always the Thread addr even with an
1114 // inflated monitor, e.g. the monitor can be inflated by a non-owning
1115 // thread due to contention.
1116 intx ObjectMonitor::complete_exit(TRAPS) {
1117   Thread * const Self = THREAD;
1118   assert(Self-&gt;is_Java_thread(), &quot;Must be Java thread!&quot;);
1119   JavaThread *jt = (JavaThread *)THREAD;
1120 
1121   assert(InitDone, &quot;Unexpectedly not initialized&quot;);
1122 
<span class="line-modified">1123   void* cur = Atomic::load(&amp;_owner);</span>
<span class="line-modified">1124   if (THREAD != cur) {</span>
<span class="line-added">1125     if (THREAD-&gt;is_lock_owned((address)cur)) {</span>
1126       assert(_recursions == 0, &quot;internal state error&quot;);
<span class="line-modified">1127       set_owner_from_BasicLock(cur, Self);  // Convert from BasicLock* to Thread*.</span>
1128       _recursions = 0;
1129     }
1130   }
1131 
1132   guarantee(Self == _owner, &quot;complete_exit not owner&quot;);
1133   intx save = _recursions; // record the old recursion count
1134   _recursions = 0;        // set the recursion level to be 0
1135   exit(true, Self);           // exit the monitor
1136   guarantee(_owner != Self, &quot;invariant&quot;);
1137   return save;
1138 }
1139 
1140 // reenter() enters a lock and sets recursion count
1141 // complete_exit/reenter operate as a wait without waiting
1142 void ObjectMonitor::reenter(intx recursions, TRAPS) {
1143   Thread * const Self = THREAD;
1144   assert(Self-&gt;is_Java_thread(), &quot;Must be Java thread!&quot;);
1145   JavaThread *jt = (JavaThread *)THREAD;
1146 
1147   guarantee(_owner != Self, &quot;reenter already owner&quot;);
</pre>
<hr />
<pre>
1152 }
1153 
1154 // Checks that the current THREAD owns this monitor and causes an
1155 // immediate return if it doesn&#39;t. We don&#39;t use the CHECK macro
1156 // because we want the IMSE to be the only exception that is thrown
1157 // from the call site when false is returned. Any other pending
1158 // exception is ignored.
1159 #define CHECK_OWNER()                                                  \
1160   do {                                                                 \
1161     if (!check_owner(THREAD)) {                                        \
1162        assert(HAS_PENDING_EXCEPTION, &quot;expected a pending IMSE here.&quot;); \
1163        return;                                                         \
1164      }                                                                 \
1165   } while (false)
1166 
1167 // Returns true if the specified thread owns the ObjectMonitor.
1168 // Otherwise returns false and throws IllegalMonitorStateException
1169 // (IMSE). If there is a pending exception and the specified thread
1170 // is not the owner, that exception will be replaced by the IMSE.
1171 bool ObjectMonitor::check_owner(Thread* THREAD) {
<span class="line-modified">1172   void* cur = Atomic::load(&amp;_owner);</span>
<span class="line-added">1173   if (cur == THREAD) {</span>
1174     return true;
1175   }
<span class="line-modified">1176   if (THREAD-&gt;is_lock_owned((address)cur)) {</span>
<span class="line-modified">1177     set_owner_from_BasicLock(cur, THREAD);  // Convert from BasicLock* to Thread*.</span>
1178     _recursions = 0;
1179     return true;
1180   }
1181   THROW_MSG_(vmSymbols::java_lang_IllegalMonitorStateException(),
1182              &quot;current thread is not owner&quot;, false);
1183 }
1184 
1185 static void post_monitor_wait_event(EventJavaMonitorWait* event,
1186                                     ObjectMonitor* monitor,
1187                                     jlong notifier_tid,
1188                                     jlong timeout,
1189                                     bool timedout) {
1190   assert(event != NULL, &quot;invariant&quot;);
1191   assert(monitor != NULL, &quot;invariant&quot;);
1192   event-&gt;set_monitorClass(((oop)monitor-&gt;object())-&gt;klass());
1193   event-&gt;set_timeout(timeout);
1194   event-&gt;set_address((uintptr_t)monitor-&gt;object_addr());
1195   event-&gt;set_notifier(notifier_tid);
1196   event-&gt;set_timedOut(timedout);
1197   event-&gt;commit();
</pre>
<hr />
<pre>
1666     // We periodically check to see if there&#39;s a safepoint pending.
1667     if ((ctr &amp; 0xFF) == 0) {
1668       if (SafepointMechanism::should_block(Self)) {
1669         goto Abort;           // abrupt spin egress
1670       }
1671       SpinPause();
1672     }
1673 
1674     // Probe _owner with TATAS
1675     // If this thread observes the monitor transition or flicker
1676     // from locked to unlocked to locked, then the odds that this
1677     // thread will acquire the lock in this spin attempt go down
1678     // considerably.  The same argument applies if the CAS fails
1679     // or if we observe _owner change from one non-null value to
1680     // another non-null value.   In such cases we might abort
1681     // the spin without prejudice or apply a &quot;penalty&quot; to the
1682     // spin count-down variable &quot;ctr&quot;, reducing it by 100, say.
1683 
1684     Thread * ox = (Thread *) _owner;
1685     if (ox == NULL) {
<span class="line-modified">1686       ox = (Thread*)try_set_owner_from(NULL, Self);</span>
1687       if (ox == NULL) {
1688         // The CAS succeeded -- this thread acquired ownership
1689         // Take care of some bookkeeping to exit spin state.
1690         if (_succ == Self) {
1691           _succ = NULL;
1692         }
1693 
1694         // Increase _SpinDuration :
1695         // The spin was successful (profitable) so we tend toward
1696         // longer spin attempts in the future.
1697         // CONSIDER: factor &quot;ctr&quot; into the _SpinDuration adjustment.
1698         // If we acquired the lock early in the spin cycle it
1699         // makes sense to increase _SpinDuration proportionally.
1700         // Note that we don&#39;t clamp SpinDuration precisely at SpinLimit.
1701         int x = _SpinDuration;
1702         if (x &lt; Knob_SpinLimit) {
1703           if (x &lt; Knob_Poverty) x = Knob_Poverty;
1704           _SpinDuration = x + Knob_Bonus;
1705         }
1706         return 1;
</pre>
<hr />
<pre>
1970 //   }
1971 //   _owner = 0x0000000000000000
1972 //   _previous_owner_tid = 0
1973 //   _recursions = 0
1974 //   _EntryList = 0x0000000000000000
1975 //   _cxq = 0x0000000000000000
1976 //   _succ = 0x0000000000000000
1977 //   _Responsible = 0x0000000000000000
1978 //   _Spinner = 0
1979 //   _SpinDuration = 5000
1980 //   _contentions = 0
1981 //   _WaitSet = 0x0000700009756248
1982 //   _waiters = 1
1983 //   _WaitSetLock = 0
1984 // }
1985 //
1986 void ObjectMonitor::print_debug_style_on(outputStream* st) const {
1987   st-&gt;print_cr(&quot;(ObjectMonitor*) &quot; INTPTR_FORMAT &quot; = {&quot;, p2i(this));
1988   st-&gt;print_cr(&quot;  _header = &quot; INTPTR_FORMAT, header().value());
1989   st-&gt;print_cr(&quot;  _object = &quot; INTPTR_FORMAT, p2i(_object));
<span class="line-modified">1990   st-&gt;print_cr(&quot;  _next_om = &quot; INTPTR_FORMAT, p2i(next_om()));</span>
1991   st-&gt;print_cr(&quot;  _pad_buf0 = {&quot;);
1992   st-&gt;print_cr(&quot;    [0] = &#39;\\0&#39;&quot;);
1993   st-&gt;print_cr(&quot;    ...&quot;);
1994   st-&gt;print_cr(&quot;    [%d] = &#39;\\0&#39;&quot;, (int)sizeof(_pad_buf0) - 1);
1995   st-&gt;print_cr(&quot;  }&quot;);
1996   st-&gt;print_cr(&quot;  _owner = &quot; INTPTR_FORMAT, p2i(_owner));
1997   st-&gt;print_cr(&quot;  _previous_owner_tid = &quot; JLONG_FORMAT, _previous_owner_tid);
1998   st-&gt;print_cr(&quot;  _recursions = &quot; INTX_FORMAT, _recursions);
1999   st-&gt;print_cr(&quot;  _EntryList = &quot; INTPTR_FORMAT, p2i(_EntryList));
2000   st-&gt;print_cr(&quot;  _cxq = &quot; INTPTR_FORMAT, p2i(_cxq));
2001   st-&gt;print_cr(&quot;  _succ = &quot; INTPTR_FORMAT, p2i(_succ));
2002   st-&gt;print_cr(&quot;  _Responsible = &quot; INTPTR_FORMAT, p2i(_Responsible));
2003   st-&gt;print_cr(&quot;  _Spinner = %d&quot;, _Spinner);
2004   st-&gt;print_cr(&quot;  _SpinDuration = %d&quot;, _SpinDuration);
2005   st-&gt;print_cr(&quot;  _contentions = %d&quot;, _contentions);
2006   st-&gt;print_cr(&quot;  _WaitSet = &quot; INTPTR_FORMAT, p2i(_WaitSet));
2007   st-&gt;print_cr(&quot;  _waiters = %d&quot;, _waiters);
2008   st-&gt;print_cr(&quot;  _WaitSetLock = %d&quot;, _WaitSetLock);
2009   st-&gt;print_cr(&quot;}&quot;);
2010 }
</pre>
</td>
</tr>
</table>
<center><a href="mutexLocker.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../index.html" target="_top">index</a> <a href="objectMonitor.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>