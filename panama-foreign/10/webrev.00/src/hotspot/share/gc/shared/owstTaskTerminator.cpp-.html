<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Old src/hotspot/share/gc/shared/owstTaskTerminator.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
  <body>
    <pre>
  1 /*
  2  * Copyright (c) 2018, 2019, Red Hat, Inc. All rights reserved.
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 
 27 #include &quot;gc/shared/owstTaskTerminator.hpp&quot;
 28 #include &quot;logging/log.hpp&quot;
 29 
 30 bool OWSTTaskTerminator::exit_termination(size_t tasks, TerminatorTerminator* terminator) {
 31   return tasks &gt; 0 || (terminator != NULL &amp;&amp; terminator-&gt;should_exit_termination());
 32 }
 33 
 34 bool OWSTTaskTerminator::offer_termination(TerminatorTerminator* terminator) {
 35   assert(_n_threads &gt; 0, &quot;Initialization is incorrect&quot;);
 36   assert(_offered_termination &lt; _n_threads, &quot;Invariant&quot;);
 37   assert(_blocker != NULL, &quot;Invariant&quot;);
 38 
 39   // Single worker, done
 40   if (_n_threads == 1) {
 41     _offered_termination = 1;
 42     assert(!peek_in_queue_set(), &quot;Precondition&quot;);
 43     return true;
 44   }
 45 
 46   _blocker-&gt;lock_without_safepoint_check();
 47   _offered_termination++;
 48   // All arrived, done
 49   if (_offered_termination == _n_threads) {
 50     _blocker-&gt;notify_all();
 51     _blocker-&gt;unlock();
 52     assert(!peek_in_queue_set(), &quot;Precondition&quot;);
 53     return true;
 54   }
 55 
 56   Thread* the_thread = Thread::current();
 57   while (true) {
 58     if (_spin_master == NULL) {
 59       _spin_master = the_thread;
 60 
 61       _blocker-&gt;unlock();
 62 
 63       if (do_spin_master_work(terminator)) {
 64         assert(_offered_termination == _n_threads, &quot;termination condition&quot;);
 65         assert(!peek_in_queue_set(), &quot;Precondition&quot;);
 66         return true;
 67       } else {
 68         _blocker-&gt;lock_without_safepoint_check();
 69         // There is possibility that termination is reached between dropping the lock
 70         // before returning from do_spin_master_work() and acquiring lock above.
 71         if (_offered_termination == _n_threads) {
 72           _blocker-&gt;unlock();
 73           assert(!peek_in_queue_set(), &quot;Precondition&quot;);
 74           return true;
 75         }
 76       }
 77     } else {
 78       _blocker-&gt;wait_without_safepoint_check(WorkStealingSleepMillis);
 79 
 80       if (_offered_termination == _n_threads) {
 81         _blocker-&gt;unlock();
 82         assert(!peek_in_queue_set(), &quot;Precondition&quot;);
 83         return true;
 84       }
 85     }
 86 
 87     size_t tasks = tasks_in_queue_set();
 88     if (exit_termination(tasks, terminator)) {
 89       assert_lock_strong(_blocker);
 90       _offered_termination--;
 91       _blocker-&gt;unlock();
 92       return false;
 93     }
 94   }
 95 }
 96 
 97 bool OWSTTaskTerminator::do_spin_master_work(TerminatorTerminator* terminator) {
 98   uint yield_count = 0;
 99   // Number of hard spin loops done since last yield
100   uint hard_spin_count = 0;
101   // Number of iterations in the hard spin loop.
102   uint hard_spin_limit = WorkStealingHardSpins;
103 
104   // If WorkStealingSpinToYieldRatio is 0, no hard spinning is done.
105   // If it is greater than 0, then start with a small number
106   // of spins and increase number with each turn at spinning until
107   // the count of hard spins exceeds WorkStealingSpinToYieldRatio.
108   // Then do a yield() call and start spinning afresh.
109   if (WorkStealingSpinToYieldRatio &gt; 0) {
110     hard_spin_limit = WorkStealingHardSpins &gt;&gt; WorkStealingSpinToYieldRatio;
111     hard_spin_limit = MAX2(hard_spin_limit, 1U);
112   }
113   // Remember the initial spin limit.
114   uint hard_spin_start = hard_spin_limit;
115 
116   // Loop waiting for all threads to offer termination or
117   // more work.
118   while (true) {
119     // Look for more work.
120     // Periodically sleep() instead of yield() to give threads
121     // waiting on the cores the chance to grab this code
122     if (yield_count &lt;= WorkStealingYieldsBeforeSleep) {
123       // Do a yield or hardspin.  For purposes of deciding whether
124       // to sleep, count this as a yield.
125       yield_count++;
126 
127       // Periodically call yield() instead spinning
128       // After WorkStealingSpinToYieldRatio spins, do a yield() call
129       // and reset the counts and starting limit.
130       if (hard_spin_count &gt; WorkStealingSpinToYieldRatio) {
131         yield();
132         hard_spin_count = 0;
133         hard_spin_limit = hard_spin_start;
134 #ifdef TRACESPINNING
135         _total_yields++;
136 #endif
137       } else {
138         // Hard spin this time
139         // Increase the hard spinning period but only up to a limit.
140         hard_spin_limit = MIN2(2*hard_spin_limit,
141                                (uint) WorkStealingHardSpins);
142         for (uint j = 0; j &lt; hard_spin_limit; j++) {
143           SpinPause();
144         }
145         hard_spin_count++;
146 #ifdef TRACESPINNING
147         _total_spins++;
148 #endif
149       }
150     } else {
151       log_develop_trace(gc, task)(&quot;OWSTTaskTerminator::do_spin_master_work() thread &quot; PTR_FORMAT &quot; sleeps after %u yields&quot;,
152                                   p2i(Thread::current()), yield_count);
153       yield_count = 0;
154 
155       MonitorLocker locker(_blocker, Mutex::_no_safepoint_check_flag);
156       _spin_master = NULL;
157       locker.wait(WorkStealingSleepMillis);
158       if (_spin_master == NULL) {
159         _spin_master = Thread::current();
160       } else {
161         return false;
162       }
163     }
164 
165 #ifdef TRACESPINNING
166       _total_peeks++;
167 #endif
168     size_t tasks = tasks_in_queue_set();
169     bool exit = exit_termination(tasks, terminator);
170     {
171       MonitorLocker locker(_blocker, Mutex::_no_safepoint_check_flag);
172       // Termination condition reached
173       if (_offered_termination == _n_threads) {
174         _spin_master = NULL;
175         return true;
176       } else if (exit) {
177         if (tasks &gt;= _offered_termination - 1) {
178           locker.notify_all();
179         } else {
180           for (; tasks &gt; 1; tasks--) {
181             locker.notify();
182           }
183         }
184         _spin_master = NULL;
185         return false;
186       }
187     }
188   }
189 }
    </pre>
  </body>
</html>