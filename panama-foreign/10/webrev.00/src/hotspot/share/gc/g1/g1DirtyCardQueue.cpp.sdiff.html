<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Sdiff src/hotspot/share/gc/g1/g1DirtyCardQueue.cpp</title>
    <link rel="stylesheet" href="../../../../../style.css" />
  </head>
<body>
<center><a href="g1ConcurrentRefineThread.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1DirtyCardQueue.hpp.sdiff.html" target="_top">next &gt;</a></center>    <h2>src/hotspot/share/gc/g1/g1DirtyCardQueue.cpp</h2>
     <a class="print" href="javascript:print()">Print this page</a>
<table>
<tr valign="top">
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2019, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/g1/g1BufferNodeList.hpp&quot;
 27 #include &quot;gc/g1/g1CardTableEntryClosure.hpp&quot;
 28 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;

 29 #include &quot;gc/g1/g1DirtyCardQueue.hpp&quot;
 30 #include &quot;gc/g1/g1FreeIdSet.hpp&quot;
 31 #include &quot;gc/g1/g1RedirtyCardsQueue.hpp&quot;
 32 #include &quot;gc/g1/g1RemSet.hpp&quot;
 33 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
 34 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
 35 #include &quot;gc/shared/suspendibleThreadSet.hpp&quot;
<span class="line-removed"> 36 #include &quot;gc/shared/workgroup.hpp&quot;</span>
 37 #include &quot;memory/iterator.hpp&quot;
<span class="line-modified"> 38 #include &quot;runtime/flags/flagSetting.hpp&quot;</span>
<span class="line-removed"> 39 #include &quot;runtime/mutexLocker.hpp&quot;</span>
<span class="line-removed"> 40 #include &quot;runtime/orderAccess.hpp&quot;</span>
 41 #include &quot;runtime/os.hpp&quot;
 42 #include &quot;runtime/safepoint.hpp&quot;
 43 #include &quot;runtime/thread.inline.hpp&quot;
 44 #include &quot;runtime/threadSMR.hpp&quot;


 45 #include &quot;utilities/quickSort.hpp&quot;
 46 
 47 G1DirtyCardQueue::G1DirtyCardQueue(G1DirtyCardQueueSet* qset) :
 48   // Dirty card queues are always active, so we create them with their
 49   // active field set to true.
 50   PtrQueue(qset, true /* active */)
 51 { }
 52 
 53 G1DirtyCardQueue::~G1DirtyCardQueue() {
 54   flush();
 55 }
 56 
 57 void G1DirtyCardQueue::handle_completed_buffer() {
 58   assert(_buf != NULL, &quot;precondition&quot;);
 59   BufferNode* node = BufferNode::make_node_from_buffer(_buf, index());
 60   G1DirtyCardQueueSet* dcqs = dirty_card_qset();
 61   if (dcqs-&gt;process_or_enqueue_completed_buffer(node)) {
 62     reset();                    // Buffer fully processed, reset index.
 63   } else {
 64     allocate_buffer();          // Buffer enqueued, get a new one.
 65   }
 66 }
 67 
 68 // Assumed to be zero by concurrent threads.
 69 static uint par_ids_start() { return 0; }
 70 
<span class="line-modified"> 71 G1DirtyCardQueueSet::G1DirtyCardQueueSet(Monitor* cbl_mon,</span>
<span class="line-removed"> 72                                          BufferNode::Allocator* allocator) :</span>
 73   PtrQueueSet(allocator),
<span class="line-modified"> 74   _cbl_mon(cbl_mon),</span>
<span class="line-removed"> 75   _completed_buffers_head(NULL),</span>
<span class="line-removed"> 76   _completed_buffers_tail(NULL),</span>
 77   _num_cards(0),



 78   _process_cards_threshold(ProcessCardsThresholdNever),
<span class="line-removed"> 79   _process_completed_buffers(false),</span>
 80   _max_cards(MaxCardsUnlimited),
 81   _max_cards_padding(0),
<span class="line-removed"> 82   _free_ids(par_ids_start(), num_par_ids()),</span>
 83   _mutator_refined_cards_counters(NEW_C_HEAP_ARRAY(size_t, num_par_ids(), mtGC))
 84 {
 85   ::memset(_mutator_refined_cards_counters, 0, num_par_ids() * sizeof(size_t));
 86   _all_active = true;
 87 }
 88 
 89 G1DirtyCardQueueSet::~G1DirtyCardQueueSet() {
 90   abandon_completed_buffers();
 91   FREE_C_HEAP_ARRAY(size_t, _mutator_refined_cards_counters);
 92 }
 93 
 94 // Determines how many mutator threads can process the buffers in parallel.
 95 uint G1DirtyCardQueueSet::num_par_ids() {
 96   return (uint)os::initial_active_processor_count();
 97 }
 98 
 99 size_t G1DirtyCardQueueSet::total_mutator_refined_cards() const {
100   size_t sum = 0;
101   for (uint i = 0; i &lt; num_par_ids(); ++i) {
102     sum += _mutator_refined_cards_counters[i];
103   }
104   return sum;
105 }
106 
107 void G1DirtyCardQueueSet::handle_zero_index_for_thread(Thread* t) {
108   G1ThreadLocalData::dirty_card_queue(t).handle_zero_index();
109 }
110 
<span class="line-modified">111 void G1DirtyCardQueueSet::enqueue_completed_buffer(BufferNode* cbn) {</span>
<span class="line-modified">112   MonitorLocker ml(_cbl_mon, Mutex::_no_safepoint_check_flag);</span>
<span class="line-modified">113   cbn-&gt;set_next(NULL);</span>
<span class="line-modified">114   if (_completed_buffers_tail == NULL) {</span>
<span class="line-modified">115     assert(_completed_buffers_head == NULL, &quot;Well-formedness&quot;);</span>
<span class="line-modified">116     _completed_buffers_head = cbn;</span>
<span class="line-modified">117     _completed_buffers_tail = cbn;</span>



























118   } else {
<span class="line-modified">119     _completed_buffers_tail-&gt;set_next(cbn);</span>
<span class="line-modified">120     _completed_buffers_tail = cbn;</span>
121   }
<span class="line-modified">122   _num_cards += buffer_size() - cbn-&gt;index();</span>
123 
<span class="line-modified">124   if (!process_completed_buffers() &amp;&amp;</span>
<span class="line-modified">125       (num_cards() &gt; process_cards_threshold())) {</span>
<span class="line-modified">126     set_process_completed_buffers(true);</span>
<span class="line-modified">127     ml.notify_all();</span>































































128   }
<span class="line-removed">129   verify_num_cards();</span>
130 }
131 
132 BufferNode* G1DirtyCardQueueSet::get_completed_buffer(size_t stop_at) {
<span class="line-modified">133   MutexLocker x(_cbl_mon, Mutex::_no_safepoint_check_flag);</span>
134 
<span class="line-modified">135   if (num_cards() &lt;= stop_at) {</span>



136     return NULL;
137   }
138 
<span class="line-modified">139   assert(num_cards() &gt; 0, &quot;invariant&quot;);</span>
<span class="line-modified">140   assert(_completed_buffers_head != NULL, &quot;invariant&quot;);</span>
<span class="line-modified">141   assert(_completed_buffers_tail != NULL, &quot;invariant&quot;);</span>
<span class="line-removed">142 </span>
<span class="line-removed">143   BufferNode* bn = _completed_buffers_head;</span>
<span class="line-removed">144   _num_cards -= buffer_size() - bn-&gt;index();</span>
<span class="line-removed">145   _completed_buffers_head = bn-&gt;next();</span>
<span class="line-removed">146   if (_completed_buffers_head == NULL) {</span>
<span class="line-removed">147     assert(num_cards() == 0, &quot;invariant&quot;);</span>
<span class="line-removed">148     _completed_buffers_tail = NULL;</span>
<span class="line-removed">149     set_process_completed_buffers(false);</span>
150   }
<span class="line-modified">151   verify_num_cards();</span>
<span class="line-removed">152   bn-&gt;set_next(NULL);</span>
<span class="line-removed">153   return bn;</span>
154 }
155 
156 #ifdef ASSERT
157 void G1DirtyCardQueueSet::verify_num_cards() const {
158   size_t actual = 0;
<span class="line-modified">159   BufferNode* cur = _completed_buffers_head;</span>
<span class="line-modified">160   while (cur != NULL) {</span>
161     actual += buffer_size() - cur-&gt;index();
<span class="line-removed">162     cur = cur-&gt;next();</span>
163   }
<span class="line-modified">164   assert(actual == _num_cards,</span>
165          &quot;Num entries in completed buffers should be &quot; SIZE_FORMAT &quot; but are &quot; SIZE_FORMAT,
<span class="line-modified">166          _num_cards, actual);</span>
167 }
<span class="line-modified">168 #endif</span>
169 
<span class="line-modified">170 void G1DirtyCardQueueSet::abandon_completed_buffers() {</span>
<span class="line-modified">171   BufferNode* buffers_to_delete = NULL;</span>






































































172   {
<span class="line-modified">173     MutexLocker x(_cbl_mon, Mutex::_no_safepoint_check_flag);</span>
<span class="line-modified">174     buffers_to_delete = _completed_buffers_head;</span>
<span class="line-modified">175     _completed_buffers_head = NULL;</span>
<span class="line-modified">176     _completed_buffers_tail = NULL;</span>
<span class="line-modified">177     _num_cards = 0;</span>
<span class="line-modified">178     set_process_completed_buffers(false);</span>























179   }























































180   while (buffers_to_delete != NULL) {
181     BufferNode* bn = buffers_to_delete;
182     buffers_to_delete = bn-&gt;next();
183     bn-&gt;set_next(NULL);
184     deallocate_buffer(bn);
185   }
186 }
187 
188 void G1DirtyCardQueueSet::notify_if_necessary() {
<span class="line-modified">189   MonitorLocker ml(_cbl_mon, Mutex::_no_safepoint_check_flag);</span>
<span class="line-modified">190   if (num_cards() &gt; process_cards_threshold()) {</span>
<span class="line-modified">191     set_process_completed_buffers(true);</span>
<span class="line-removed">192     ml.notify_all();</span>
193   }
194 }
195 
<span class="line-modified">196 // Merge lists of buffers. Notify the processing threads.</span>
<span class="line-modified">197 // The source queue is emptied as a result. The queues</span>
<span class="line-removed">198 // must share the monitor.</span>
199 void G1DirtyCardQueueSet::merge_bufferlists(G1RedirtyCardsQueueSet* src) {
200   assert(allocator() == src-&gt;allocator(), &quot;precondition&quot;);
201   const G1BufferNodeList from = src-&gt;take_all_completed_buffers();
<span class="line-modified">202   if (from._head == NULL) return;</span>
<span class="line-modified">203 </span>
<span class="line-modified">204   MutexLocker x(_cbl_mon, Mutex::_no_safepoint_check_flag);</span>
<span class="line-removed">205   if (_completed_buffers_tail == NULL) {</span>
<span class="line-removed">206     assert(_completed_buffers_head == NULL, &quot;Well-formedness&quot;);</span>
<span class="line-removed">207     _completed_buffers_head = from._head;</span>
<span class="line-removed">208     _completed_buffers_tail = from._tail;</span>
<span class="line-removed">209   } else {</span>
<span class="line-removed">210     assert(_completed_buffers_head != NULL, &quot;Well formedness&quot;);</span>
<span class="line-removed">211     _completed_buffers_tail-&gt;set_next(from._head);</span>
<span class="line-removed">212     _completed_buffers_tail = from._tail;</span>
213   }
<span class="line-removed">214   _num_cards += from._entry_count;</span>
<span class="line-removed">215 </span>
<span class="line-removed">216   assert(_completed_buffers_head == NULL &amp;&amp; _completed_buffers_tail == NULL ||</span>
<span class="line-removed">217          _completed_buffers_head != NULL &amp;&amp; _completed_buffers_tail != NULL,</span>
<span class="line-removed">218          &quot;Sanity&quot;);</span>
<span class="line-removed">219   verify_num_cards();</span>
220 }
221 
222 G1BufferNodeList G1DirtyCardQueueSet::take_all_completed_buffers() {
<span class="line-modified">223   MutexLocker x(_cbl_mon, Mutex::_no_safepoint_check_flag);</span>
<span class="line-modified">224   G1BufferNodeList result(_completed_buffers_head, _completed_buffers_tail, _num_cards);</span>
<span class="line-modified">225   _completed_buffers_head = NULL;</span>
<span class="line-modified">226   _completed_buffers_tail = NULL;</span>
<span class="line-modified">227   _num_cards = 0;</span>
<span class="line-modified">228   return result;</span>
229 }
230 
231 class G1RefineBufferedCards : public StackObj {
232   BufferNode* const _node;
233   CardTable::CardValue** const _node_buffer;
234   const size_t _node_buffer_size;
235   const uint _worker_id;
236   size_t* _total_refined_cards;
237   G1RemSet* const _g1rs;
238 
239   static inline int compare_card(const CardTable::CardValue* p1,
240                                  const CardTable::CardValue* p2) {
241     return p2 - p1;
242   }
243 
244   // Sorts the cards from start_index to _node_buffer_size in *decreasing*
245   // address order. Tests showed that this order is preferable to not sorting
246   // or increasing address order.
247   void sort_cards(size_t start_index) {
248     QuickSort::sort(&amp;_node_buffer[start_index],
</pre>
<hr />
<pre>
351   return buffered_cards.refine();
352 }
353 
354 #ifndef ASSERT
355 #define assert_fully_consumed(node, buffer_size)
356 #else
357 #define assert_fully_consumed(node, buffer_size)                \
358   do {                                                          \
359     size_t _afc_index = (node)-&gt;index();                        \
360     size_t _afc_size = (buffer_size);                           \
361     assert(_afc_index == _afc_size,                             \
362            &quot;Buffer was not fully consumed as claimed: index: &quot;  \
363            SIZE_FORMAT &quot;, size: &quot; SIZE_FORMAT,                  \
364             _afc_index, _afc_size);                             \
365   } while (0)
366 #endif // ASSERT
367 
368 bool G1DirtyCardQueueSet::process_or_enqueue_completed_buffer(BufferNode* node) {
369   if (Thread::current()-&gt;is_Java_thread()) {
370     // If the number of buffers exceeds the limit, make this Java
<span class="line-modified">371     // thread do the processing itself.  We don&#39;t lock to access</span>
<span class="line-modified">372     // buffer count or padding; it is fine to be imprecise here.  The</span>
<span class="line-modified">373     // add of padding could overflow, which is treated as unlimited.</span>
374     size_t limit = max_cards() + max_cards_padding();
375     if ((num_cards() &gt; limit) &amp;&amp; (limit &gt;= max_cards())) {
376       if (mut_process_buffer(node)) {
377         return true;
378       }






379     }
380   }
381   enqueue_completed_buffer(node);
382   return false;
383 }
384 
385 bool G1DirtyCardQueueSet::mut_process_buffer(BufferNode* node) {
386   uint worker_id = _free_ids.claim_par_id(); // temporarily claim an id
387   uint counter_index = worker_id - par_ids_start();
388   size_t* counter = &amp;_mutator_refined_cards_counters[counter_index];
389   bool result = refine_buffer(node, worker_id, counter);
390   _free_ids.release_par_id(worker_id); // release the id
391 
392   if (result) {
393     assert_fully_consumed(node, buffer_size());
394   }
395   return result;
396 }
397 
398 bool G1DirtyCardQueueSet::refine_completed_buffer_concurrently(uint worker_id,
399                                                                size_t stop_at,
400                                                                size_t* total_refined_cards) {
401   BufferNode* node = get_completed_buffer(stop_at);
402   if (node == NULL) {
403     return false;
404   } else if (refine_buffer(node, worker_id, total_refined_cards)) {
405     assert_fully_consumed(node, buffer_size());
406     // Done with fully processed buffer.
407     deallocate_buffer(node);
408     return true;
409   } else {
<span class="line-modified">410     // Return partially processed buffer to the queue.</span>
<span class="line-modified">411     enqueue_completed_buffer(node);</span>

412     return true;
413   }
414 }
415 
416 void G1DirtyCardQueueSet::abandon_logs() {
<span class="line-modified">417   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at safepoint.&quot;);</span>
418   abandon_completed_buffers();
419 
420   // Since abandon is done only at safepoints, we can safely manipulate
421   // these queues.
422   struct AbandonThreadLogClosure : public ThreadClosure {
423     virtual void do_thread(Thread* t) {
424       G1ThreadLocalData::dirty_card_queue(t).reset();
425     }
426   } closure;
427   Threads::threads_do(&amp;closure);
428 
429   G1BarrierSet::shared_dirty_card_queue().reset();
430 }
431 
432 void G1DirtyCardQueueSet::concatenate_logs() {
433   // Iterate over all the threads, if we find a partial log add it to
434   // the global list of logs.  Temporarily turn off the limit on the number
435   // of outstanding buffers.
<span class="line-modified">436   assert(SafepointSynchronize::is_at_safepoint(), &quot;Must be at safepoint.&quot;);</span>
437   size_t old_limit = max_cards();
438   set_max_cards(MaxCardsUnlimited);
439 
440   struct ConcatenateThreadLogClosure : public ThreadClosure {
441     virtual void do_thread(Thread* t) {
442       G1DirtyCardQueue&amp; dcq = G1ThreadLocalData::dirty_card_queue(t);
443       if (!dcq.is_empty()) {
444         dcq.flush();
445       }
446     }
447   } closure;
448   Threads::threads_do(&amp;closure);
449 
450   G1BarrierSet::shared_dirty_card_queue().flush();


451   set_max_cards(old_limit);
452 }
</pre>
</td>
<td>
<hr />
<pre>
  1 /*
<span class="line-modified">  2  * Copyright (c) 2001, 2020, Oracle and/or its affiliates. All rights reserved.</span>
  3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
  4  *
  5  * This code is free software; you can redistribute it and/or modify it
  6  * under the terms of the GNU General Public License version 2 only, as
  7  * published by the Free Software Foundation.
  8  *
  9  * This code is distributed in the hope that it will be useful, but WITHOUT
 10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 12  * version 2 for more details (a copy is included in the LICENSE file that
 13  * accompanied this code).
 14  *
 15  * You should have received a copy of the GNU General Public License version
 16  * 2 along with this work; if not, write to the Free Software Foundation,
 17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 18  *
 19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 20  * or visit www.oracle.com if you need additional information or have any
 21  * questions.
 22  *
 23  */
 24 
 25 #include &quot;precompiled.hpp&quot;
 26 #include &quot;gc/g1/g1BufferNodeList.hpp&quot;
 27 #include &quot;gc/g1/g1CardTableEntryClosure.hpp&quot;
 28 #include &quot;gc/g1/g1CollectedHeap.inline.hpp&quot;
<span class="line-added"> 29 #include &quot;gc/g1/g1ConcurrentRefineThread.hpp&quot;</span>
 30 #include &quot;gc/g1/g1DirtyCardQueue.hpp&quot;
 31 #include &quot;gc/g1/g1FreeIdSet.hpp&quot;
 32 #include &quot;gc/g1/g1RedirtyCardsQueue.hpp&quot;
 33 #include &quot;gc/g1/g1RemSet.hpp&quot;
 34 #include &quot;gc/g1/g1ThreadLocalData.hpp&quot;
 35 #include &quot;gc/g1/heapRegionRemSet.hpp&quot;
 36 #include &quot;gc/shared/suspendibleThreadSet.hpp&quot;

 37 #include &quot;memory/iterator.hpp&quot;
<span class="line-modified"> 38 #include &quot;runtime/atomic.hpp&quot;</span>


 39 #include &quot;runtime/os.hpp&quot;
 40 #include &quot;runtime/safepoint.hpp&quot;
 41 #include &quot;runtime/thread.inline.hpp&quot;
 42 #include &quot;runtime/threadSMR.hpp&quot;
<span class="line-added"> 43 #include &quot;utilities/globalCounter.inline.hpp&quot;</span>
<span class="line-added"> 44 #include &quot;utilities/macros.hpp&quot;</span>
 45 #include &quot;utilities/quickSort.hpp&quot;
 46 
 47 G1DirtyCardQueue::G1DirtyCardQueue(G1DirtyCardQueueSet* qset) :
 48   // Dirty card queues are always active, so we create them with their
 49   // active field set to true.
 50   PtrQueue(qset, true /* active */)
 51 { }
 52 
 53 G1DirtyCardQueue::~G1DirtyCardQueue() {
 54   flush();
 55 }
 56 
 57 void G1DirtyCardQueue::handle_completed_buffer() {
 58   assert(_buf != NULL, &quot;precondition&quot;);
 59   BufferNode* node = BufferNode::make_node_from_buffer(_buf, index());
 60   G1DirtyCardQueueSet* dcqs = dirty_card_qset();
 61   if (dcqs-&gt;process_or_enqueue_completed_buffer(node)) {
 62     reset();                    // Buffer fully processed, reset index.
 63   } else {
 64     allocate_buffer();          // Buffer enqueued, get a new one.
 65   }
 66 }
 67 
 68 // Assumed to be zero by concurrent threads.
 69 static uint par_ids_start() { return 0; }
 70 
<span class="line-modified"> 71 G1DirtyCardQueueSet::G1DirtyCardQueueSet(BufferNode::Allocator* allocator) :</span>

 72   PtrQueueSet(allocator),
<span class="line-modified"> 73   _primary_refinement_thread(NULL),</span>


 74   _num_cards(0),
<span class="line-added"> 75   _completed(),</span>
<span class="line-added"> 76   _paused(),</span>
<span class="line-added"> 77   _free_ids(par_ids_start(), num_par_ids()),</span>
 78   _process_cards_threshold(ProcessCardsThresholdNever),

 79   _max_cards(MaxCardsUnlimited),
 80   _max_cards_padding(0),

 81   _mutator_refined_cards_counters(NEW_C_HEAP_ARRAY(size_t, num_par_ids(), mtGC))
 82 {
 83   ::memset(_mutator_refined_cards_counters, 0, num_par_ids() * sizeof(size_t));
 84   _all_active = true;
 85 }
 86 
 87 G1DirtyCardQueueSet::~G1DirtyCardQueueSet() {
 88   abandon_completed_buffers();
 89   FREE_C_HEAP_ARRAY(size_t, _mutator_refined_cards_counters);
 90 }
 91 
 92 // Determines how many mutator threads can process the buffers in parallel.
 93 uint G1DirtyCardQueueSet::num_par_ids() {
 94   return (uint)os::initial_active_processor_count();
 95 }
 96 
 97 size_t G1DirtyCardQueueSet::total_mutator_refined_cards() const {
 98   size_t sum = 0;
 99   for (uint i = 0; i &lt; num_par_ids(); ++i) {
100     sum += _mutator_refined_cards_counters[i];
101   }
102   return sum;
103 }
104 
105 void G1DirtyCardQueueSet::handle_zero_index_for_thread(Thread* t) {
106   G1ThreadLocalData::dirty_card_queue(t).handle_zero_index();
107 }
108 
<span class="line-modified">109 #ifdef ASSERT</span>
<span class="line-modified">110 G1DirtyCardQueueSet::Queue::~Queue() {</span>
<span class="line-modified">111   assert(_head == NULL, &quot;precondition&quot;);</span>
<span class="line-modified">112   assert(_tail == NULL, &quot;precondition&quot;);</span>
<span class="line-modified">113 }</span>
<span class="line-modified">114 #endif // ASSERT</span>
<span class="line-modified">115 </span>
<span class="line-added">116 BufferNode* G1DirtyCardQueueSet::Queue::top() const {</span>
<span class="line-added">117   return Atomic::load(&amp;_head);</span>
<span class="line-added">118 }</span>
<span class="line-added">119 </span>
<span class="line-added">120 // An append operation atomically exchanges the new tail with the queue tail.</span>
<span class="line-added">121 // It then sets the &quot;next&quot; value of the old tail to the head of the list being</span>
<span class="line-added">122 // appended; it is an invariant that the old tail&#39;s &quot;next&quot; value is NULL.</span>
<span class="line-added">123 // But if the old tail is NULL then the queue was empty.  In this case the</span>
<span class="line-added">124 // head of the list being appended is instead stored in the queue head; it is</span>
<span class="line-added">125 // an invariant that the queue head is NULL in this case.</span>
<span class="line-added">126 //</span>
<span class="line-added">127 // This means there is a period between the exchange and the old tail update</span>
<span class="line-added">128 // where the queue sequence is split into two parts, the list from the queue</span>
<span class="line-added">129 // head to the old tail, and the list being appended.  If there are concurrent</span>
<span class="line-added">130 // push/append operations, each may introduce another such segment.  But they</span>
<span class="line-added">131 // all eventually get resolved by their respective updates of their old tail&#39;s</span>
<span class="line-added">132 // &quot;next&quot; value.  This also means that pop operations must handle a buffer</span>
<span class="line-added">133 // with a NULL &quot;next&quot; value specially.</span>
<span class="line-added">134 //</span>
<span class="line-added">135 // A push operation is just a degenerate append, where the buffer being pushed</span>
<span class="line-added">136 // is both the head and the tail of the list being appended.</span>
<span class="line-added">137 void G1DirtyCardQueueSet::Queue::append(BufferNode&amp; first, BufferNode&amp; last) {</span>
<span class="line-added">138   assert(last.next() == NULL, &quot;precondition&quot;);</span>
<span class="line-added">139   BufferNode* old_tail = Atomic::xchg(&amp;_tail, &amp;last);</span>
<span class="line-added">140   if (old_tail == NULL) {       // Was empty.</span>
<span class="line-added">141     assert(Atomic::load(&amp;_head) == NULL, &quot;invariant&quot;);</span>
<span class="line-added">142     Atomic::store(&amp;_head, &amp;first);</span>
143   } else {
<span class="line-modified">144     assert(old_tail-&gt;next() == NULL, &quot;invariant&quot;);</span>
<span class="line-modified">145     old_tail-&gt;set_next(&amp;first);</span>
146   }
<span class="line-modified">147 }</span>
148 
<span class="line-modified">149 // pop gets the queue head as the candidate result (returning NULL if the</span>
<span class="line-modified">150 // queue head was NULL), and then gets that result node&#39;s &quot;next&quot; value.  If</span>
<span class="line-modified">151 // that &quot;next&quot; value is NULL and the queue head hasn&#39;t changed, then there</span>
<span class="line-modified">152 // is only one element in the accessible part of the list (the sequence from</span>
<span class="line-added">153 // head to a node with a NULL &quot;next&quot; value).  We can&#39;t return that element,</span>
<span class="line-added">154 // because it may be the old tail of a concurrent push/append that has not</span>
<span class="line-added">155 // yet had its &quot;next&quot; field set to the new tail.  So return NULL in this case.</span>
<span class="line-added">156 // Otherwise, attempt to cmpxchg that &quot;next&quot; value into the queue head,</span>
<span class="line-added">157 // retrying the whole operation if that fails. This is the &quot;usual&quot; lock-free</span>
<span class="line-added">158 // pop from the head of a singly linked list, with the additional restriction</span>
<span class="line-added">159 // on taking the last element.</span>
<span class="line-added">160 BufferNode* G1DirtyCardQueueSet::Queue::pop() {</span>
<span class="line-added">161   Thread* current_thread = Thread::current();</span>
<span class="line-added">162   while (true) {</span>
<span class="line-added">163     // Use a critical section per iteration, rather than over the whole</span>
<span class="line-added">164     // operation.  We&#39;re not guaranteed to make progress, because of possible</span>
<span class="line-added">165     // contention on the queue head.  Lingering in one CS the whole time could</span>
<span class="line-added">166     // lead to excessive allocation of buffers, because the CS blocks return</span>
<span class="line-added">167     // of released buffers to the free list for reuse.</span>
<span class="line-added">168     GlobalCounter::CriticalSection cs(current_thread);</span>
<span class="line-added">169 </span>
<span class="line-added">170     BufferNode* result = Atomic::load_acquire(&amp;_head);</span>
<span class="line-added">171     // Check for empty queue.  Only needs to be done on first iteration,</span>
<span class="line-added">172     // since we never take the last element, but it&#39;s messy to make use</span>
<span class="line-added">173     // of that and we expect one iteration to be the common case.</span>
<span class="line-added">174     if (result == NULL) return NULL;</span>
<span class="line-added">175 </span>
<span class="line-added">176     BufferNode* next = Atomic::load_acquire(BufferNode::next_ptr(*result));</span>
<span class="line-added">177     if (next != NULL) {</span>
<span class="line-added">178       next = Atomic::cmpxchg(&amp;_head, result, next);</span>
<span class="line-added">179       if (next == result) {</span>
<span class="line-added">180         // Former head successfully taken; it is not the last.</span>
<span class="line-added">181         assert(Atomic::load(&amp;_tail) != result, &quot;invariant&quot;);</span>
<span class="line-added">182         assert(result-&gt;next() != NULL, &quot;invariant&quot;);</span>
<span class="line-added">183         result-&gt;set_next(NULL);</span>
<span class="line-added">184         return result;</span>
<span class="line-added">185       }</span>
<span class="line-added">186       // cmpxchg failed; try again.</span>
<span class="line-added">187     } else if (result == Atomic::load_acquire(&amp;_head)) {</span>
<span class="line-added">188       // If follower of head is NULL and head hasn&#39;t changed, then only</span>
<span class="line-added">189       // the one element is currently accessible.  We don&#39;t take the last</span>
<span class="line-added">190       // accessible element, because there may be a concurrent add using it.</span>
<span class="line-added">191       // The check for unchanged head isn&#39;t needed for correctness, but the</span>
<span class="line-added">192       // retry on change may sometimes let us get a buffer after all.</span>
<span class="line-added">193       return NULL;</span>
<span class="line-added">194     }</span>
<span class="line-added">195     // Head changed; try again.</span>
<span class="line-added">196   }</span>
<span class="line-added">197 }</span>
<span class="line-added">198 </span>
<span class="line-added">199 G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::Queue::take_all() {</span>
<span class="line-added">200   assert_at_safepoint();</span>
<span class="line-added">201   HeadTail result(Atomic::load(&amp;_head), Atomic::load(&amp;_tail));</span>
<span class="line-added">202   Atomic::store(&amp;_head, (BufferNode*)NULL);</span>
<span class="line-added">203   Atomic::store(&amp;_tail, (BufferNode*)NULL);</span>
<span class="line-added">204   return result;</span>
<span class="line-added">205 }</span>
<span class="line-added">206 </span>
<span class="line-added">207 void G1DirtyCardQueueSet::enqueue_completed_buffer(BufferNode* cbn) {</span>
<span class="line-added">208   assert(cbn != NULL, &quot;precondition&quot;);</span>
<span class="line-added">209   // Increment _num_cards before adding to queue, so queue removal doesn&#39;t</span>
<span class="line-added">210   // need to deal with _num_cards possibly going negative.</span>
<span class="line-added">211   size_t new_num_cards = Atomic::add(&amp;_num_cards, buffer_size() - cbn-&gt;index());</span>
<span class="line-added">212   _completed.push(*cbn);</span>
<span class="line-added">213   if ((new_num_cards &gt; process_cards_threshold()) &amp;&amp;</span>
<span class="line-added">214       (_primary_refinement_thread != NULL)) {</span>
<span class="line-added">215     _primary_refinement_thread-&gt;activate();</span>
216   }

217 }
218 
219 BufferNode* G1DirtyCardQueueSet::get_completed_buffer(size_t stop_at) {
<span class="line-modified">220   enqueue_previous_paused_buffers();</span>
221 
<span class="line-modified">222   // Check for insufficient cards to satisfy request.  We only do this once,</span>
<span class="line-added">223   // up front, rather than on each iteration below, since the test is racy</span>
<span class="line-added">224   // regardless of when we do it.</span>
<span class="line-added">225   if (Atomic::load_acquire(&amp;_num_cards) &lt;= stop_at) {</span>
226     return NULL;
227   }
228 
<span class="line-modified">229   BufferNode* result = _completed.pop();</span>
<span class="line-modified">230   if (result != NULL) {</span>
<span class="line-modified">231     Atomic::sub(&amp;_num_cards, buffer_size() - result-&gt;index());</span>








232   }
<span class="line-modified">233   return result;</span>


234 }
235 
236 #ifdef ASSERT
237 void G1DirtyCardQueueSet::verify_num_cards() const {
238   size_t actual = 0;
<span class="line-modified">239   BufferNode* cur = _completed.top();</span>
<span class="line-modified">240   for ( ; cur != NULL; cur = cur-&gt;next()) {</span>
241     actual += buffer_size() - cur-&gt;index();

242   }
<span class="line-modified">243   assert(actual == Atomic::load(&amp;_num_cards),</span>
244          &quot;Num entries in completed buffers should be &quot; SIZE_FORMAT &quot; but are &quot; SIZE_FORMAT,
<span class="line-modified">245          Atomic::load(&amp;_num_cards), actual);</span>
246 }
<span class="line-modified">247 #endif // ASSERT</span>
248 
<span class="line-modified">249 G1DirtyCardQueueSet::PausedBuffers::PausedList::PausedList() :</span>
<span class="line-modified">250   _head(NULL), _tail(NULL),</span>
<span class="line-added">251   _safepoint_id(SafepointSynchronize::safepoint_id())</span>
<span class="line-added">252 {}</span>
<span class="line-added">253 </span>
<span class="line-added">254 #ifdef ASSERT</span>
<span class="line-added">255 G1DirtyCardQueueSet::PausedBuffers::PausedList::~PausedList() {</span>
<span class="line-added">256   assert(Atomic::load(&amp;_head) == NULL, &quot;precondition&quot;);</span>
<span class="line-added">257   assert(_tail == NULL, &quot;precondition&quot;);</span>
<span class="line-added">258 }</span>
<span class="line-added">259 #endif // ASSERT</span>
<span class="line-added">260 </span>
<span class="line-added">261 bool G1DirtyCardQueueSet::PausedBuffers::PausedList::is_next() const {</span>
<span class="line-added">262   assert_not_at_safepoint();</span>
<span class="line-added">263   return _safepoint_id == SafepointSynchronize::safepoint_id();</span>
<span class="line-added">264 }</span>
<span class="line-added">265 </span>
<span class="line-added">266 void G1DirtyCardQueueSet::PausedBuffers::PausedList::add(BufferNode* node) {</span>
<span class="line-added">267   assert_not_at_safepoint();</span>
<span class="line-added">268   assert(is_next(), &quot;precondition&quot;);</span>
<span class="line-added">269   BufferNode* old_head = Atomic::xchg(&amp;_head, node);</span>
<span class="line-added">270   if (old_head == NULL) {</span>
<span class="line-added">271     assert(_tail == NULL, &quot;invariant&quot;);</span>
<span class="line-added">272     _tail = node;</span>
<span class="line-added">273   } else {</span>
<span class="line-added">274     node-&gt;set_next(old_head);</span>
<span class="line-added">275   }</span>
<span class="line-added">276 }</span>
<span class="line-added">277 </span>
<span class="line-added">278 G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::PausedBuffers::PausedList::take() {</span>
<span class="line-added">279   BufferNode* head = Atomic::load(&amp;_head);</span>
<span class="line-added">280   BufferNode* tail = _tail;</span>
<span class="line-added">281   Atomic::store(&amp;_head, (BufferNode*)NULL);</span>
<span class="line-added">282   _tail = NULL;</span>
<span class="line-added">283   return HeadTail(head, tail);</span>
<span class="line-added">284 }</span>
<span class="line-added">285 </span>
<span class="line-added">286 G1DirtyCardQueueSet::PausedBuffers::PausedBuffers() : _plist(NULL) {}</span>
<span class="line-added">287 </span>
<span class="line-added">288 #ifdef ASSERT</span>
<span class="line-added">289 G1DirtyCardQueueSet::PausedBuffers::~PausedBuffers() {</span>
<span class="line-added">290   assert(is_empty(), &quot;invariant&quot;);</span>
<span class="line-added">291 }</span>
<span class="line-added">292 #endif // ASSERT</span>
<span class="line-added">293 </span>
<span class="line-added">294 bool G1DirtyCardQueueSet::PausedBuffers::is_empty() const {</span>
<span class="line-added">295   return Atomic::load(&amp;_plist) == NULL;</span>
<span class="line-added">296 }</span>
<span class="line-added">297 </span>
<span class="line-added">298 void G1DirtyCardQueueSet::PausedBuffers::add(BufferNode* node) {</span>
<span class="line-added">299   assert_not_at_safepoint();</span>
<span class="line-added">300   PausedList* plist = Atomic::load_acquire(&amp;_plist);</span>
<span class="line-added">301   if (plist != NULL) {</span>
<span class="line-added">302     // Already have a next list, so use it.  We know it&#39;s a next list because</span>
<span class="line-added">303     // of the precondition that take_previous() has already been called.</span>
<span class="line-added">304     assert(plist-&gt;is_next(), &quot;invariant&quot;);</span>
<span class="line-added">305   } else {</span>
<span class="line-added">306     // Try to install a new next list.</span>
<span class="line-added">307     plist = new PausedList();</span>
<span class="line-added">308     PausedList* old_plist = Atomic::cmpxchg(&amp;_plist, (PausedList*)NULL, plist);</span>
<span class="line-added">309     if (old_plist != NULL) {</span>
<span class="line-added">310       // Some other thread installed a new next list. Use it instead.</span>
<span class="line-added">311       delete plist;</span>
<span class="line-added">312       plist = old_plist;</span>
<span class="line-added">313     }</span>
<span class="line-added">314   }</span>
<span class="line-added">315   plist-&gt;add(node);</span>
<span class="line-added">316 }</span>
<span class="line-added">317 </span>
<span class="line-added">318 G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::PausedBuffers::take_previous() {</span>
<span class="line-added">319   assert_not_at_safepoint();</span>
<span class="line-added">320   PausedList* previous;</span>
321   {
<span class="line-modified">322     // Deal with plist in a critical section, to prevent it from being</span>
<span class="line-modified">323     // deleted out from under us by a concurrent take_previous().</span>
<span class="line-modified">324     GlobalCounter::CriticalSection cs(Thread::current());</span>
<span class="line-modified">325     previous = Atomic::load_acquire(&amp;_plist);</span>
<span class="line-modified">326     if ((previous == NULL) ||   // Nothing to take.</span>
<span class="line-modified">327         previous-&gt;is_next() ||  // Not from a previous safepoint.</span>
<span class="line-added">328         // Some other thread stole it.</span>
<span class="line-added">329         (Atomic::cmpxchg(&amp;_plist, previous, (PausedList*)NULL) != previous)) {</span>
<span class="line-added">330       return HeadTail();</span>
<span class="line-added">331     }</span>
<span class="line-added">332   }</span>
<span class="line-added">333   // We now own previous.</span>
<span class="line-added">334   HeadTail result = previous-&gt;take();</span>
<span class="line-added">335   // There might be other threads examining previous (in concurrent</span>
<span class="line-added">336   // take_previous()).  Synchronize to wait until any such threads are</span>
<span class="line-added">337   // done with such examination before deleting.</span>
<span class="line-added">338   GlobalCounter::write_synchronize();</span>
<span class="line-added">339   delete previous;</span>
<span class="line-added">340   return result;</span>
<span class="line-added">341 }</span>
<span class="line-added">342 </span>
<span class="line-added">343 G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::PausedBuffers::take_all() {</span>
<span class="line-added">344   assert_at_safepoint();</span>
<span class="line-added">345   HeadTail result;</span>
<span class="line-added">346   PausedList* plist = Atomic::load(&amp;_plist);</span>
<span class="line-added">347   if (plist != NULL) {</span>
<span class="line-added">348     Atomic::store(&amp;_plist, (PausedList*)NULL);</span>
<span class="line-added">349     result = plist-&gt;take();</span>
<span class="line-added">350     delete plist;</span>
351   }
<span class="line-added">352   return result;</span>
<span class="line-added">353 }</span>
<span class="line-added">354 </span>
<span class="line-added">355 void G1DirtyCardQueueSet::record_paused_buffer(BufferNode* node) {</span>
<span class="line-added">356   assert_not_at_safepoint();</span>
<span class="line-added">357   assert(node-&gt;next() == NULL, &quot;precondition&quot;);</span>
<span class="line-added">358   // Cards for paused buffers are included in count, to contribute to</span>
<span class="line-added">359   // notification checking after the coming safepoint if it doesn&#39;t GC.</span>
<span class="line-added">360   // Note that this means the queue&#39;s _num_cards differs from the number</span>
<span class="line-added">361   // of cards in the queued buffers when there are paused buffers.</span>
<span class="line-added">362   Atomic::add(&amp;_num_cards, buffer_size() - node-&gt;index());</span>
<span class="line-added">363   _paused.add(node);</span>
<span class="line-added">364 }</span>
<span class="line-added">365 </span>
<span class="line-added">366 void G1DirtyCardQueueSet::enqueue_paused_buffers_aux(const HeadTail&amp; paused) {</span>
<span class="line-added">367   if (paused._head != NULL) {</span>
<span class="line-added">368     assert(paused._tail != NULL, &quot;invariant&quot;);</span>
<span class="line-added">369     // Cards from paused buffers are already recorded in the queue count.</span>
<span class="line-added">370     _completed.append(*paused._head, *paused._tail);</span>
<span class="line-added">371   }</span>
<span class="line-added">372 }</span>
<span class="line-added">373 </span>
<span class="line-added">374 void G1DirtyCardQueueSet::enqueue_previous_paused_buffers() {</span>
<span class="line-added">375   assert_not_at_safepoint();</span>
<span class="line-added">376   // The fast-path still satisfies the precondition for record_paused_buffer</span>
<span class="line-added">377   // and PausedBuffers::add, even with a racy test.  If there are paused</span>
<span class="line-added">378   // buffers from a previous safepoint, is_empty() will return false; there</span>
<span class="line-added">379   // will have been a safepoint between recording and test, so there can&#39;t be</span>
<span class="line-added">380   // a false negative (is_empty() returns true) while such buffers are present.</span>
<span class="line-added">381   // If is_empty() is false, there are two cases:</span>
<span class="line-added">382   //</span>
<span class="line-added">383   // (1) There were paused buffers from a previous safepoint.  A concurrent</span>
<span class="line-added">384   // caller may take and enqueue them first, but that&#39;s okay; the precondition</span>
<span class="line-added">385   // for a possible later record_paused_buffer by this thread will still hold.</span>
<span class="line-added">386   //</span>
<span class="line-added">387   // (2) There are paused buffers for a requested next safepoint.</span>
<span class="line-added">388   //</span>
<span class="line-added">389   // In each of those cases some effort may be spent detecting and dealing</span>
<span class="line-added">390   // with those circumstances; any wasted effort in such cases is expected to</span>
<span class="line-added">391   // be well compensated by the fast path.</span>
<span class="line-added">392   if (!_paused.is_empty()) {</span>
<span class="line-added">393     enqueue_paused_buffers_aux(_paused.take_previous());</span>
<span class="line-added">394   }</span>
<span class="line-added">395 }</span>
<span class="line-added">396 </span>
<span class="line-added">397 void G1DirtyCardQueueSet::enqueue_all_paused_buffers() {</span>
<span class="line-added">398   assert_at_safepoint();</span>
<span class="line-added">399   enqueue_paused_buffers_aux(_paused.take_all());</span>
<span class="line-added">400 }</span>
<span class="line-added">401 </span>
<span class="line-added">402 void G1DirtyCardQueueSet::abandon_completed_buffers() {</span>
<span class="line-added">403   enqueue_all_paused_buffers();</span>
<span class="line-added">404   verify_num_cards();</span>
<span class="line-added">405   G1BufferNodeList list = take_all_completed_buffers();</span>
<span class="line-added">406   BufferNode* buffers_to_delete = list._head;</span>
407   while (buffers_to_delete != NULL) {
408     BufferNode* bn = buffers_to_delete;
409     buffers_to_delete = bn-&gt;next();
410     bn-&gt;set_next(NULL);
411     deallocate_buffer(bn);
412   }
413 }
414 
415 void G1DirtyCardQueueSet::notify_if_necessary() {
<span class="line-modified">416   if ((_primary_refinement_thread != NULL) &amp;&amp;</span>
<span class="line-modified">417       (num_cards() &gt; process_cards_threshold())) {</span>
<span class="line-modified">418     _primary_refinement_thread-&gt;activate();</span>

419   }
420 }
421 
<span class="line-modified">422 // Merge lists of buffers. The source queue set is emptied as a</span>
<span class="line-modified">423 // result. The queue sets must share the same allocator.</span>

424 void G1DirtyCardQueueSet::merge_bufferlists(G1RedirtyCardsQueueSet* src) {
425   assert(allocator() == src-&gt;allocator(), &quot;precondition&quot;);
426   const G1BufferNodeList from = src-&gt;take_all_completed_buffers();
<span class="line-modified">427   if (from._head != NULL) {</span>
<span class="line-modified">428     Atomic::add(&amp;_num_cards, from._entry_count);</span>
<span class="line-modified">429     _completed.append(*from._head, *from._tail);</span>








430   }






431 }
432 
433 G1BufferNodeList G1DirtyCardQueueSet::take_all_completed_buffers() {
<span class="line-modified">434   enqueue_all_paused_buffers();</span>
<span class="line-modified">435   verify_num_cards();</span>
<span class="line-modified">436   HeadTail buffers = _completed.take_all();</span>
<span class="line-modified">437   size_t num_cards = Atomic::load(&amp;_num_cards);</span>
<span class="line-modified">438   Atomic::store(&amp;_num_cards, size_t(0));</span>
<span class="line-modified">439   return G1BufferNodeList(buffers._head, buffers._tail, num_cards);</span>
440 }
441 
442 class G1RefineBufferedCards : public StackObj {
443   BufferNode* const _node;
444   CardTable::CardValue** const _node_buffer;
445   const size_t _node_buffer_size;
446   const uint _worker_id;
447   size_t* _total_refined_cards;
448   G1RemSet* const _g1rs;
449 
450   static inline int compare_card(const CardTable::CardValue* p1,
451                                  const CardTable::CardValue* p2) {
452     return p2 - p1;
453   }
454 
455   // Sorts the cards from start_index to _node_buffer_size in *decreasing*
456   // address order. Tests showed that this order is preferable to not sorting
457   // or increasing address order.
458   void sort_cards(size_t start_index) {
459     QuickSort::sort(&amp;_node_buffer[start_index],
</pre>
<hr />
<pre>
562   return buffered_cards.refine();
563 }
564 
565 #ifndef ASSERT
566 #define assert_fully_consumed(node, buffer_size)
567 #else
568 #define assert_fully_consumed(node, buffer_size)                \
569   do {                                                          \
570     size_t _afc_index = (node)-&gt;index();                        \
571     size_t _afc_size = (buffer_size);                           \
572     assert(_afc_index == _afc_size,                             \
573            &quot;Buffer was not fully consumed as claimed: index: &quot;  \
574            SIZE_FORMAT &quot;, size: &quot; SIZE_FORMAT,                  \
575             _afc_index, _afc_size);                             \
576   } while (0)
577 #endif // ASSERT
578 
579 bool G1DirtyCardQueueSet::process_or_enqueue_completed_buffer(BufferNode* node) {
580   if (Thread::current()-&gt;is_Java_thread()) {
581     // If the number of buffers exceeds the limit, make this Java
<span class="line-modified">582     // thread do the processing itself.  Calculation is racy but we</span>
<span class="line-modified">583     // don&#39;t need precision here.  The add of padding could overflow,</span>
<span class="line-modified">584     // which is treated as unlimited.</span>
585     size_t limit = max_cards() + max_cards_padding();
586     if ((num_cards() &gt; limit) &amp;&amp; (limit &gt;= max_cards())) {
587       if (mut_process_buffer(node)) {
588         return true;
589       }
<span class="line-added">590       // Buffer was incompletely processed because of a pending safepoint</span>
<span class="line-added">591       // request.  Unlike with refinement thread processing, for mutator</span>
<span class="line-added">592       // processing the buffer did not come from the completed buffer queue,</span>
<span class="line-added">593       // so it is okay to add it to the queue rather than to the paused set.</span>
<span class="line-added">594       // Indeed, it can&#39;t be added to the paused set because we didn&#39;t pass</span>
<span class="line-added">595       // through enqueue_previous_paused_buffers.</span>
596     }
597   }
598   enqueue_completed_buffer(node);
599   return false;
600 }
601 
602 bool G1DirtyCardQueueSet::mut_process_buffer(BufferNode* node) {
603   uint worker_id = _free_ids.claim_par_id(); // temporarily claim an id
604   uint counter_index = worker_id - par_ids_start();
605   size_t* counter = &amp;_mutator_refined_cards_counters[counter_index];
606   bool result = refine_buffer(node, worker_id, counter);
607   _free_ids.release_par_id(worker_id); // release the id
608 
609   if (result) {
610     assert_fully_consumed(node, buffer_size());
611   }
612   return result;
613 }
614 
615 bool G1DirtyCardQueueSet::refine_completed_buffer_concurrently(uint worker_id,
616                                                                size_t stop_at,
617                                                                size_t* total_refined_cards) {
618   BufferNode* node = get_completed_buffer(stop_at);
619   if (node == NULL) {
620     return false;
621   } else if (refine_buffer(node, worker_id, total_refined_cards)) {
622     assert_fully_consumed(node, buffer_size());
623     // Done with fully processed buffer.
624     deallocate_buffer(node);
625     return true;
626   } else {
<span class="line-modified">627     // Buffer incompletely processed because there is a pending safepoint.</span>
<span class="line-modified">628     // Record partially processed buffer, to be finished later.</span>
<span class="line-added">629     record_paused_buffer(node);</span>
630     return true;
631   }
632 }
633 
634 void G1DirtyCardQueueSet::abandon_logs() {
<span class="line-modified">635   assert_at_safepoint();</span>
636   abandon_completed_buffers();
637 
638   // Since abandon is done only at safepoints, we can safely manipulate
639   // these queues.
640   struct AbandonThreadLogClosure : public ThreadClosure {
641     virtual void do_thread(Thread* t) {
642       G1ThreadLocalData::dirty_card_queue(t).reset();
643     }
644   } closure;
645   Threads::threads_do(&amp;closure);
646 
647   G1BarrierSet::shared_dirty_card_queue().reset();
648 }
649 
650 void G1DirtyCardQueueSet::concatenate_logs() {
651   // Iterate over all the threads, if we find a partial log add it to
652   // the global list of logs.  Temporarily turn off the limit on the number
653   // of outstanding buffers.
<span class="line-modified">654   assert_at_safepoint();</span>
655   size_t old_limit = max_cards();
656   set_max_cards(MaxCardsUnlimited);
657 
658   struct ConcatenateThreadLogClosure : public ThreadClosure {
659     virtual void do_thread(Thread* t) {
660       G1DirtyCardQueue&amp; dcq = G1ThreadLocalData::dirty_card_queue(t);
661       if (!dcq.is_empty()) {
662         dcq.flush();
663       }
664     }
665   } closure;
666   Threads::threads_do(&amp;closure);
667 
668   G1BarrierSet::shared_dirty_card_queue().flush();
<span class="line-added">669   enqueue_all_paused_buffers();</span>
<span class="line-added">670   verify_num_cards();</span>
671   set_max_cards(old_limit);
672 }
</pre>
</td>
</tr>
</table>
<center><a href="g1ConcurrentRefineThread.hpp.sdiff.html" target="_top">&lt; prev</a> <a href="../../../../../index.html" target="_top">index</a> <a href="g1DirtyCardQueue.hpp.sdiff.html" target="_top">next &gt;</a></center>  </body>
</html>