<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/arm/arm.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
<a name="1" id="anc1"></a><span class="line-modified">    2 // Copyright (c) 2008, 2018, Oracle and/or its affiliates. All rights reserved.</span>
    3 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    4 //
    5 // This code is free software; you can redistribute it and/or modify it
    6 // under the terms of the GNU General Public License version 2 only, as
    7 // published by the Free Software Foundation.
    8 //
    9 // This code is distributed in the hope that it will be useful, but WITHOUT
   10 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   11 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   12 // version 2 for more details (a copy is included in the LICENSE file that
   13 // accompanied this code).
   14 //
   15 // You should have received a copy of the GNU General Public License version
   16 // 2 along with this work; if not, write to the Free Software Foundation,
   17 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   18 //
   19 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   20 // or visit www.oracle.com if you need additional information or have any
   21 // questions.
   22 //
   23 
   24 // ARM Architecture Description File
   25 
   26 //----------DEFINITION BLOCK---------------------------------------------------
   27 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
   28 // Current support includes integer values in the range [0, 0x7FFFFFFF]
   29 // Format:
   30 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
   31 // Generated Code in ad_&lt;arch&gt;.hpp
   32 //        #define  &lt;name&gt;   (&lt;expression&gt;)
   33 //        // value == &lt;int_value&gt;
   34 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
   35 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
   36 //
   37 definitions %{
   38 // The default cost (of an ALU instruction).
   39   int_def DEFAULT_COST      (    100,     100);
   40   int_def HUGE_COST         (1000000, 1000000);
   41 
   42 // Memory refs are twice as expensive as run-of-the-mill.
   43   int_def MEMORY_REF_COST   (    200, DEFAULT_COST * 2);
   44 
   45 // Branches are even more expensive.
   46   int_def BRANCH_COST       (    300, DEFAULT_COST * 3);
   47   int_def CALL_COST         (    300, DEFAULT_COST * 3);
   48 %}
   49 
   50 
   51 //----------SOURCE BLOCK-------------------------------------------------------
   52 // This is a block of C++ code which provides values, functions, and
   53 // definitions necessary in the rest of the architecture description
   54 source_hpp %{
   55 // Header information of the source block.
   56 // Method declarations/definitions which are used outside
   57 // the ad-scope can conveniently be defined here.
   58 //
   59 // To keep related declarations/definitions/uses close together,
   60 // we switch between source %{ }% and source_hpp %{ }% freely as needed.
   61 
   62 // Does destination need to be loaded in a register then passed to a
   63 // branch instruction?
   64 extern bool maybe_far_call(const CallNode *n);
   65 extern bool maybe_far_call(const MachCallNode *n);
   66 static inline bool cache_reachable() {
   67   return MacroAssembler::_cache_fully_reachable();
   68 }
   69 
   70 #define ldr_32 ldr
   71 #define str_32 str
   72 #define tst_32 tst
   73 #define teq_32 teq
   74 #if 1
   75 extern bool PrintOptoAssembly;
   76 #endif
   77 
   78 class c2 {
   79 public:
   80   static OptoRegPair return_value(int ideal_reg);
   81 };
   82 
   83 class CallStubImpl {
   84 
   85   //--------------------------------------------------------------
   86   //---&lt;  Used for optimization in Compile::Shorten_branches  &gt;---
   87   //--------------------------------------------------------------
   88 
   89  public:
   90   // Size of call trampoline stub.
   91   static uint size_call_trampoline() {
   92     return 0; // no call trampolines on this platform
   93   }
   94 
   95   // number of relocations needed by a call trampoline stub
   96   static uint reloc_call_trampoline() {
   97     return 0; // no call trampolines on this platform
   98   }
   99 };
  100 
  101 class HandlerImpl {
  102 
  103  public:
  104 
  105   static int emit_exception_handler(CodeBuffer &amp;cbuf);
  106   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
  107 
  108   static uint size_exception_handler() {
  109     return ( 3 * 4 );
  110   }
  111 
  112 
  113   static uint size_deopt_handler() {
  114     return ( 9 * 4 );
  115   }
  116 
  117 };
  118 
  119 %}
  120 
  121 source %{
  122 #define __ _masm.
  123 
  124 static FloatRegister reg_to_FloatRegister_object(int register_encoding);
  125 static Register reg_to_register_object(int register_encoding);
  126 
  127 
  128 // ****************************************************************************
  129 
  130 // REQUIRED FUNCTIONALITY
  131 
  132 // Indicate if the safepoint node needs the polling page as an input.
  133 // Since ARM does not have absolute addressing, it does.
  134 bool SafePointNode::needs_polling_address_input() {
  135   return true;
  136 }
  137 
  138 // emit an interrupt that is caught by the debugger (for debugging compiler)
  139 void emit_break(CodeBuffer &amp;cbuf) {
  140   MacroAssembler _masm(&amp;cbuf);
  141   __ breakpoint();
  142 }
  143 
  144 #ifndef PRODUCT
  145 void MachBreakpointNode::format( PhaseRegAlloc *, outputStream *st ) const {
  146   st-&gt;print(&quot;TA&quot;);
  147 }
  148 #endif
  149 
  150 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  151   emit_break(cbuf);
  152 }
  153 
  154 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
  155   return MachNode::size(ra_);
  156 }
  157 
  158 
  159 void emit_nop(CodeBuffer &amp;cbuf) {
  160   MacroAssembler _masm(&amp;cbuf);
  161   __ nop();
  162 }
  163 
  164 
  165 void emit_call_reloc(CodeBuffer &amp;cbuf, const MachCallNode *n, MachOper *m, RelocationHolder const&amp; rspec) {
  166   int ret_addr_offset0 = n-&gt;as_MachCall()-&gt;ret_addr_offset();
  167   int call_site_offset = cbuf.insts()-&gt;mark_off();
  168   MacroAssembler _masm(&amp;cbuf);
  169   __ set_inst_mark(); // needed in emit_to_interp_stub() to locate the call
  170   address target = (address)m-&gt;method();
  171   assert(n-&gt;as_MachCall()-&gt;entry_point() == target, &quot;sanity&quot;);
  172   assert(maybe_far_call(n) == !__ reachable_from_cache(target), &quot;sanity&quot;);
  173   assert(cache_reachable() == __ cache_fully_reachable(), &quot;sanity&quot;);
  174 
  175   assert(target != NULL, &quot;need real address&quot;);
  176 
  177   int ret_addr_offset = -1;
  178   if (rspec.type() == relocInfo::runtime_call_type) {
  179     __ call(target, rspec);
  180     ret_addr_offset = __ offset();
  181   } else {
  182     // scratches Rtemp
  183     ret_addr_offset = __ patchable_call(target, rspec, true);
  184   }
  185   assert(ret_addr_offset - call_site_offset == ret_addr_offset0, &quot;fix ret_addr_offset()&quot;);
  186 }
  187 
  188 //=============================================================================
  189 // REQUIRED FUNCTIONALITY for encoding
  190 void emit_lo(CodeBuffer &amp;cbuf, int val) {  }
  191 void emit_hi(CodeBuffer &amp;cbuf, int val) {  }
  192 
  193 
  194 //=============================================================================
  195 const RegMask&amp; MachConstantBaseNode::_out_RegMask = PTR_REG_mask();
  196 
  197 int Compile::ConstantTable::calculate_table_base_offset() const {
  198   int offset = -(size() / 2);
  199   // flds, fldd: 8-bit  offset multiplied by 4: +/- 1024
  200   // ldr, ldrb : 12-bit offset:                 +/- 4096
  201   if (!Assembler::is_simm10(offset)) {
  202     offset = Assembler::min_simm10();
  203   }
  204   return offset;
  205 }
  206 
  207 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
  208 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
  209   ShouldNotReachHere();
  210 }
  211 
  212 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
  213   Compile* C = ra_-&gt;C;
  214   Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();
  215   MacroAssembler _masm(&amp;cbuf);
  216 
  217   Register r = as_Register(ra_-&gt;get_encode(this));
  218   CodeSection* consts_section = __ code()-&gt;consts();
  219   int consts_size = consts_section-&gt;align_at_start(consts_section-&gt;size());
  220   assert(constant_table.size() == consts_size, &quot;must be: %d == %d&quot;, constant_table.size(), consts_size);
  221 
  222   // Materialize the constant table base.
  223   address baseaddr = consts_section-&gt;start() + -(constant_table.table_base_offset());
  224   RelocationHolder rspec = internal_word_Relocation::spec(baseaddr);
  225   __ mov_address(r, baseaddr, rspec);
  226 }
  227 
  228 uint MachConstantBaseNode::size(PhaseRegAlloc*) const {
  229   return 8;
  230 }
  231 
  232 #ifndef PRODUCT
  233 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
  234   char reg[128];
  235   ra_-&gt;dump_register(this, reg);
  236   st-&gt;print(&quot;MOV_SLOW    &amp;constanttable,%s\t! constant table base&quot;, reg);
  237 }
  238 #endif
  239 
  240 #ifndef PRODUCT
  241 void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  242   Compile* C = ra_-&gt;C;
  243 
  244   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  245     st-&gt;print_cr(&quot;NOP&quot;); st-&gt;print(&quot;\t&quot;);
  246   }
  247 
  248   size_t framesize = C-&gt;frame_size_in_bytes();
  249   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
  250   int bangsize = C-&gt;bang_size_in_bytes();
  251   // Remove two words for return addr and rbp,
  252   framesize -= 2*wordSize;
  253   bangsize -= 2*wordSize;
  254 
  255   // Calls to C2R adapters often do not accept exceptional returns.
  256   // We require that their callers must bang for them.  But be careful, because
  257   // some VM calls (such as call site linkage) can use several kilobytes of
  258   // stack.  But the stack safety zone should account for that.
  259   // See bugs 4446381, 4468289, 4497237.
  260   if (C-&gt;need_stack_bang(bangsize)) {
  261     st-&gt;print_cr(&quot;! stack bang (%d bytes)&quot;, bangsize); st-&gt;print(&quot;\t&quot;);
  262   }
  263   st-&gt;print_cr(&quot;PUSH   R_FP|R_LR_LR&quot;); st-&gt;print(&quot;\t&quot;);
  264   if (framesize != 0) {
  265     st-&gt;print   (&quot;SUB    R_SP, R_SP, &quot; SIZE_FORMAT,framesize);
  266   }
  267 }
  268 #endif
  269 
  270 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  271   Compile* C = ra_-&gt;C;
  272   MacroAssembler _masm(&amp;cbuf);
  273 
  274   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  275     __ nop();
  276   }
  277 
  278   size_t framesize = C-&gt;frame_size_in_bytes();
  279   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
  280   int bangsize = C-&gt;bang_size_in_bytes();
  281   // Remove two words for return addr and fp,
  282   framesize -= 2*wordSize;
  283   bangsize -= 2*wordSize;
  284 
  285   // Calls to C2R adapters often do not accept exceptional returns.
  286   // We require that their callers must bang for them.  But be careful, because
  287   // some VM calls (such as call site linkage) can use several kilobytes of
  288   // stack.  But the stack safety zone should account for that.
  289   // See bugs 4446381, 4468289, 4497237.
  290   if (C-&gt;need_stack_bang(bangsize)) {
  291     __ arm_stack_overflow_check(bangsize, Rtemp);
  292   }
  293 
  294   __ raw_push(FP, LR);
  295   if (framesize != 0) {
  296     __ sub_slow(SP, SP, framesize);
  297   }
  298 
  299   // offset from scratch buffer is not valid
  300   if (strcmp(cbuf.name(), &quot;Compile::Fill_buffer&quot;) == 0) {
  301     C-&gt;set_frame_complete( __ offset() );
  302   }
  303 
  304   if (C-&gt;has_mach_constant_base_node()) {
  305     // NOTE: We set the table base offset here because users might be
  306     // emitted before MachConstantBaseNode.
  307     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();
  308     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
  309   }
  310 }
  311 
  312 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
  313   return MachNode::size(ra_);
  314 }
  315 
  316 int MachPrologNode::reloc() const {
  317   return 10; // a large enough number
  318 }
  319 
  320 //=============================================================================
  321 #ifndef PRODUCT
  322 void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  323   Compile* C = ra_-&gt;C;
  324 
  325   size_t framesize = C-&gt;frame_size_in_bytes();
  326   framesize -= 2*wordSize;
  327 
  328   if (framesize != 0) {
  329     st-&gt;print(&quot;ADD    R_SP, R_SP, &quot; SIZE_FORMAT &quot;\n\t&quot;,framesize);
  330   }
  331   st-&gt;print(&quot;POP    R_FP|R_LR_LR&quot;);
  332 
  333   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
  334     st-&gt;print(&quot;\n\t&quot;);
  335     st-&gt;print(&quot;MOV    Rtemp, #PollAddr\t! Load Polling address\n\t&quot;);
  336     st-&gt;print(&quot;LDR    Rtemp,[Rtemp]\t!Poll for Safepointing&quot;);
  337   }
  338 }
  339 #endif
  340 
  341 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  342   MacroAssembler _masm(&amp;cbuf);
  343   Compile* C = ra_-&gt;C;
  344 
  345   size_t framesize = C-&gt;frame_size_in_bytes();
  346   framesize -= 2*wordSize;
  347   if (framesize != 0) {
  348     __ add_slow(SP, SP, framesize);
  349   }
  350   __ raw_pop(FP, LR);
  351 
  352   // If this does safepoint polling, then do it here
  353   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
<a name="2" id="anc2"></a><span class="line-modified">  354     // mov_slow here is usually one or two instruction</span>
<span class="line-removed">  355     __ mov_address(Rtemp, (address)os::get_polling_page());</span>
<span class="line-removed">  356     __ relocate(relocInfo::poll_return_type);</span>
<span class="line-removed">  357     __ ldr(Rtemp, Address(Rtemp));</span>
  358   }
  359 }
  360 
  361 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  362   return MachNode::size(ra_);
  363 }
  364 
  365 int MachEpilogNode::reloc() const {
  366   return 16; // a large enough number
  367 }
  368 
  369 const Pipeline * MachEpilogNode::pipeline() const {
  370   return MachNode::pipeline_class();
  371 }
  372 
  373 int MachEpilogNode::safepoint_offset() const {
  374   assert( do_polling(), &quot;no return for this epilog node&quot;);
  375   //  return MacroAssembler::size_of_sethi(os::get_polling_page());
  376   Unimplemented();
  377   return 0;
  378 }
  379 
  380 //=============================================================================
  381 
  382 // Figure out which register class each belongs in: rc_int, rc_float, rc_stack
  383 enum RC { rc_bad, rc_int, rc_float, rc_stack };
  384 static enum RC rc_class( OptoReg::Name reg ) {
  385   if (!OptoReg::is_valid(reg)) return rc_bad;
  386   if (OptoReg::is_stack(reg)) return rc_stack;
  387   VMReg r = OptoReg::as_VMReg(reg);
  388   if (r-&gt;is_Register()) return rc_int;
  389   assert(r-&gt;is_FloatRegister(), &quot;must be&quot;);
  390   return rc_float;
  391 }
  392 
  393 static inline bool is_iRegLd_memhd(OptoReg::Name src_first, OptoReg::Name src_second, int offset) {
  394   int rlo = Matcher::_regEncode[src_first];
  395   int rhi = Matcher::_regEncode[src_second];
  396   if (!((rlo&amp;1)==0 &amp;&amp; (rlo+1 == rhi))) {
  397     tty-&gt;print_cr(&quot;CAUGHT BAD LDRD/STRD&quot;);
  398   }
  399   return (rlo&amp;1)==0 &amp;&amp; (rlo+1 == rhi) &amp;&amp; is_memoryHD(offset);
  400 }
  401 
  402 uint MachSpillCopyNode::implementation( CodeBuffer *cbuf,
  403                                         PhaseRegAlloc *ra_,
  404                                         bool do_size,
  405                                         outputStream* st ) const {
  406   // Get registers to move
  407   OptoReg::Name src_second = ra_-&gt;get_reg_second(in(1));
  408   OptoReg::Name src_first = ra_-&gt;get_reg_first(in(1));
  409   OptoReg::Name dst_second = ra_-&gt;get_reg_second(this );
  410   OptoReg::Name dst_first = ra_-&gt;get_reg_first(this );
  411 
  412   enum RC src_second_rc = rc_class(src_second);
  413   enum RC src_first_rc = rc_class(src_first);
  414   enum RC dst_second_rc = rc_class(dst_second);
  415   enum RC dst_first_rc = rc_class(dst_first);
  416 
  417   assert( OptoReg::is_valid(src_first) &amp;&amp; OptoReg::is_valid(dst_first), &quot;must move at least 1 register&quot; );
  418 
  419   // Generate spill code!
  420   int size = 0;
  421 
  422   if (src_first == dst_first &amp;&amp; src_second == dst_second)
  423     return size;            // Self copy, no move
  424 
  425 #ifdef TODO
  426   if (bottom_type()-&gt;isa_vect() != NULL) {
  427   }
  428 #endif
  429 
  430   // Shared code does not expect instruction set capability based bailouts here.
  431   // Handle offset unreachable bailout with minimal change in shared code.
  432   // Bailout only for real instruction emit.
  433   // This requires a single comment change in shared code. ( see output.cpp &quot;Normal&quot; instruction case )
  434 
  435   MacroAssembler _masm(cbuf);
  436 
  437   // --------------------------------------
  438   // Check for mem-mem move.  Load into unused float registers and fall into
  439   // the float-store case.
  440   if (src_first_rc == rc_stack &amp;&amp; dst_first_rc == rc_stack) {
  441     int offset = ra_-&gt;reg2offset(src_first);
  442     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  443       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  444       return 0;
  445     } else {
  446       if (src_second_rc != rc_bad) {
  447         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  448         src_first     = OptoReg::Name(R_mem_copy_lo_num);
  449         src_second    = OptoReg::Name(R_mem_copy_hi_num);
  450         src_first_rc  = rc_float;
  451         src_second_rc = rc_float;
  452         if (cbuf) {
  453           __ ldr_double(Rmemcopy, Address(SP, offset));
  454         } else if (!do_size) {
  455           st-&gt;print(LDR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  456         }
  457       } else {
  458         src_first     = OptoReg::Name(R_mem_copy_lo_num);
  459         src_first_rc  = rc_float;
  460         if (cbuf) {
  461           __ ldr_float(Rmemcopy, Address(SP, offset));
  462         } else if (!do_size) {
  463           st-&gt;print(LDR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  464         }
  465       }
  466       size += 4;
  467     }
  468   }
  469 
  470   if (src_second_rc == rc_stack &amp;&amp; dst_second_rc == rc_stack) {
  471     Unimplemented();
  472   }
  473 
  474   // --------------------------------------
  475   // Check for integer reg-reg copy
  476   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_int) {
  477     // Else normal reg-reg copy
  478     assert( src_second != dst_first, &quot;smashed second before evacuating it&quot; );
  479     if (cbuf) {
  480       __ mov(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]));
  481 #ifndef PRODUCT
  482     } else if (!do_size) {
  483       st-&gt;print(&quot;MOV    R_%s, R_%s\t# spill&quot;,
  484                 Matcher::regName[dst_first],
  485                 Matcher::regName[src_first]);
  486 #endif
  487     }
  488     size += 4;
  489   }
  490 
  491   // Check for integer store
  492   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_stack) {
  493     int offset = ra_-&gt;reg2offset(dst_first);
  494     if (cbuf &amp;&amp; !is_memoryI(offset)) {
  495       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  496       return 0;
  497     } else {
  498       if (src_second_rc != rc_bad &amp;&amp; is_iRegLd_memhd(src_first, src_second, offset)) {
  499         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  500         if (cbuf) {
  501           __ str_64(reg_to_register_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  502 #ifndef PRODUCT
  503         } else if (!do_size) {
  504           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  505           st-&gt;print(STR_64 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first), offset);
  506 #endif
  507         }
  508         return size + 4;
  509       } else {
  510         if (cbuf) {
  511           __ str_32(reg_to_register_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  512 #ifndef PRODUCT
  513         } else if (!do_size) {
  514           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  515           st-&gt;print(STR_32 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first), offset);
  516 #endif
  517         }
  518       }
  519     }
  520     size += 4;
  521   }
  522 
  523   // Check for integer load
  524   if (dst_first_rc == rc_int &amp;&amp; src_first_rc == rc_stack) {
  525     int offset = ra_-&gt;reg2offset(src_first);
  526     if (cbuf &amp;&amp; !is_memoryI(offset)) {
  527       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  528       return 0;
  529     } else {
  530       if (src_second_rc != rc_bad &amp;&amp; is_iRegLd_memhd(dst_first, dst_second, offset)) {
  531         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  532         if (cbuf) {
  533           __ ldr_64(reg_to_register_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  534 #ifndef PRODUCT
  535         } else if (!do_size) {
  536           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  537           st-&gt;print(LDR_64 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first), offset);
  538 #endif
  539         }
  540         return size + 4;
  541       } else {
  542         if (cbuf) {
  543           __ ldr_32(reg_to_register_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  544 #ifndef PRODUCT
  545         } else if (!do_size) {
  546           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  547           st-&gt;print(LDR_32 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first), offset);
  548 #endif
  549         }
  550       }
  551     }
  552     size += 4;
  553   }
  554 
  555   // Check for float reg-reg copy
  556   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_float) {
  557     if (src_second_rc != rc_bad) {
  558       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  559       if (cbuf) {
  560       __ mov_double(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  561 #ifndef PRODUCT
  562       } else if (!do_size) {
  563         st-&gt;print(MOV_DOUBLE &quot;    R_%s, R_%s\t# spill&quot;,
  564                   Matcher::regName[dst_first],
  565                   Matcher::regName[src_first]);
  566 #endif
  567       }
  568       return 4;
  569     }
  570     if (cbuf) {
  571       __ mov_float(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  572 #ifndef PRODUCT
  573     } else if (!do_size) {
  574       st-&gt;print(MOV_FLOAT &quot;    R_%s, R_%s\t# spill&quot;,
  575                 Matcher::regName[dst_first],
  576                 Matcher::regName[src_first]);
  577 #endif
  578     }
  579     size = 4;
  580   }
  581 
  582   // Check for float store
  583   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_stack) {
  584     int offset = ra_-&gt;reg2offset(dst_first);
  585     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  586       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  587       return 0;
  588     } else {
  589       // Further check for aligned-adjacent pair, so we can use a double store
  590       if (src_second_rc != rc_bad) {
  591         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers and stack slots must be aligned/contiguous&quot;);
  592         if (cbuf) {
  593           __ str_double(reg_to_FloatRegister_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  594 #ifndef PRODUCT
  595         } else if (!do_size) {
  596           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  597           st-&gt;print(STR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  598 #endif
  599         }
  600         return size + 4;
  601       } else {
  602         if (cbuf) {
  603           __ str_float(reg_to_FloatRegister_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  604 #ifndef PRODUCT
  605         } else if (!do_size) {
  606           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  607           st-&gt;print(STR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  608 #endif
  609         }
  610       }
  611     }
  612     size += 4;
  613   }
  614 
  615   // Check for float load
  616   if (dst_first_rc == rc_float &amp;&amp; src_first_rc == rc_stack) {
  617     int offset = ra_-&gt;reg2offset(src_first);
  618     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  619       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  620       return 0;
  621     } else {
  622       // Further check for aligned-adjacent pair, so we can use a double store
  623       if (src_second_rc != rc_bad) {
  624         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers and stack slots must be aligned/contiguous&quot;);
  625         if (cbuf) {
  626           __ ldr_double(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  627 #ifndef PRODUCT
  628         } else if (!do_size) {
  629           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  630           st-&gt;print(LDR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first),offset);
  631 #endif
  632         }
  633         return size + 4;
  634       } else {
  635         if (cbuf) {
  636           __ ldr_float(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  637 #ifndef PRODUCT
  638         } else if (!do_size) {
  639           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  640           st-&gt;print(LDR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first),offset);
  641 #endif
  642         }
  643       }
  644     }
  645     size += 4;
  646   }
  647 
  648   // check for int reg -&gt; float reg move
  649   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_float) {
  650     // Further check for aligned-adjacent pair, so we can use a single instruction
  651     if (src_second_rc != rc_bad) {
  652       assert((dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  653       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  654       assert(src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_float, &quot;unsupported&quot;);
  655       if (cbuf) {
  656         __ fmdrr(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]), reg_to_register_object(Matcher::_regEncode[src_second]));
  657 #ifndef PRODUCT
  658       } else if (!do_size) {
  659         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  660         st-&gt;print(&quot;FMDRR   R_%s, R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first), OptoReg::regname(src_second));
  661 #endif
  662       }
  663       return size + 4;
  664     } else {
  665       if (cbuf) {
  666         __ fmsr(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]));
  667 #ifndef PRODUCT
  668       } else if (!do_size) {
  669         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  670         st-&gt;print(FMSR &quot;   R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first));
  671 #endif
  672       }
  673       size += 4;
  674     }
  675   }
  676 
  677   // check for float reg -&gt; int reg move
  678   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_int) {
  679     // Further check for aligned-adjacent pair, so we can use a single instruction
  680     if (src_second_rc != rc_bad) {
  681       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  682       assert((dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  683       assert(src_second_rc == rc_float &amp;&amp; dst_second_rc == rc_int, &quot;unsupported&quot;);
  684       if (cbuf) {
  685         __ fmrrd(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[dst_second]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  686 #ifndef PRODUCT
  687       } else if (!do_size) {
  688         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  689         st-&gt;print(&quot;FMRRD   R_%s, R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(dst_second), OptoReg::regname(src_first));
  690 #endif
  691       }
  692       return size + 4;
  693     } else {
  694       if (cbuf) {
  695         __ fmrs(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  696 #ifndef PRODUCT
  697       } else if (!do_size) {
  698         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  699         st-&gt;print(FMRS &quot;   R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first));
  700 #endif
  701       }
  702       size += 4;
  703     }
  704   }
  705 
  706   // --------------------------------------------------------------------
  707   // Check for hi bits still needing moving.  Only happens for misaligned
  708   // arguments to native calls.
  709   if (src_second == dst_second)
  710     return size;               // Self copy; no move
  711   assert( src_second_rc != rc_bad &amp;&amp; dst_second_rc != rc_bad, &quot;src_second &amp; dst_second cannot be Bad&quot; );
  712 
  713   // Check for integer reg-reg copy.  Hi bits are stuck up in the top
  714   // 32-bits of a 64-bit register, but are needed in low bits of another
  715   // register (else it&#39;s a hi-bits-to-hi-bits copy which should have
  716   // happened already as part of a 64-bit move)
  717   if (src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_int) {
  718     if (cbuf) {
  719       __ mov(reg_to_register_object(Matcher::_regEncode[dst_second]), reg_to_register_object(Matcher::_regEncode[src_second]));
  720 #ifndef PRODUCT
  721     } else if (!do_size) {
  722       if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  723       st-&gt;print(&quot;MOV    R_%s, R_%s\t# spill high&quot;,
  724                 Matcher::regName[dst_second],
  725                 Matcher::regName[src_second]);
  726 #endif
  727     }
  728     return size+4;
  729   }
  730 
  731   // Check for high word integer store
  732   if (src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_stack) {
  733     int offset = ra_-&gt;reg2offset(dst_second);
  734 
  735     if (cbuf &amp;&amp; !is_memoryP(offset)) {
  736       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  737       return 0;
  738     } else {
  739       if (cbuf) {
  740         __ str(reg_to_register_object(Matcher::_regEncode[src_second]), Address(SP, offset));
  741 #ifndef PRODUCT
  742       } else if (!do_size) {
  743         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  744         st-&gt;print(&quot;STR   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_second), offset);
  745 #endif
  746       }
  747     }
  748     return size + 4;
  749   }
  750 
  751   // Check for high word integer load
  752   if (dst_second_rc == rc_int &amp;&amp; src_second_rc == rc_stack) {
  753     int offset = ra_-&gt;reg2offset(src_second);
  754     if (cbuf &amp;&amp; !is_memoryP(offset)) {
  755       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  756       return 0;
  757     } else {
  758       if (cbuf) {
  759         __ ldr(reg_to_register_object(Matcher::_regEncode[dst_second]), Address(SP, offset));
  760 #ifndef PRODUCT
  761       } else if (!do_size) {
  762         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  763         st-&gt;print(&quot;LDR   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_second), offset);
  764 #endif
  765       }
  766     }
  767     return size + 4;
  768   }
  769 
  770   Unimplemented();
  771   return 0; // Mute compiler
  772 }
  773 
  774 #ifndef PRODUCT
  775 void MachSpillCopyNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  776   implementation( NULL, ra_, false, st );
  777 }
  778 #endif
  779 
  780 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  781   implementation( &amp;cbuf, ra_, false, NULL );
  782 }
  783 
  784 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
  785   return implementation( NULL, ra_, true, NULL );
  786 }
  787 
  788 //=============================================================================
  789 #ifndef PRODUCT
  790 void MachNopNode::format( PhaseRegAlloc *, outputStream *st ) const {
  791   st-&gt;print(&quot;NOP \t# %d bytes pad for loops and calls&quot;, 4 * _count);
  792 }
  793 #endif
  794 
  795 void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc * ) const {
  796   MacroAssembler _masm(&amp;cbuf);
  797   for(int i = 0; i &lt; _count; i += 1) {
  798     __ nop();
  799   }
  800 }
  801 
  802 uint MachNopNode::size(PhaseRegAlloc *ra_) const {
  803   return 4 * _count;
  804 }
  805 
  806 
  807 //=============================================================================
  808 #ifndef PRODUCT
  809 void BoxLockNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  810   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
  811   int reg = ra_-&gt;get_reg_first(this);
  812   st-&gt;print(&quot;ADD    %s,R_SP+#%d&quot;,Matcher::regName[reg], offset);
  813 }
  814 #endif
  815 
  816 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  817   MacroAssembler _masm(&amp;cbuf);
  818   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
  819   int reg = ra_-&gt;get_encode(this);
  820   Register dst = reg_to_register_object(reg);
  821 
  822   if (is_aimm(offset)) {
  823     __ add(dst, SP, offset);
  824   } else {
  825     __ mov_slow(dst, offset);
  826     __ add(dst, SP, dst);
  827   }
  828 }
  829 
  830 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
  831   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
  832   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
  833   return ra_-&gt;C-&gt;scratch_emit_size(this);
  834 }
  835 
  836 //=============================================================================
  837 #ifndef PRODUCT
  838 #define R_RTEMP &quot;R_R12&quot;
  839 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  840   st-&gt;print_cr(&quot;\nUEP:&quot;);
  841   if (UseCompressedClassPointers) {
  842     st-&gt;print_cr(&quot;\tLDR_w &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  843     st-&gt;print_cr(&quot;\tdecode_klass &quot; R_RTEMP);
  844   } else {
  845     st-&gt;print_cr(&quot;\tLDR   &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  846   }
  847   st-&gt;print_cr(&quot;\tCMP   &quot; R_RTEMP &quot;,R_R8&quot; );
  848   st-&gt;print   (&quot;\tB.NE  SharedRuntime::handle_ic_miss_stub&quot;);
  849 }
  850 #endif
  851 
  852 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  853   MacroAssembler _masm(&amp;cbuf);
  854   Register iCache  = reg_to_register_object(Matcher::inline_cache_reg_encode());
  855   assert(iCache == Ricklass, &quot;should be&quot;);
  856   Register receiver = R0;
  857 
  858   __ load_klass(Rtemp, receiver);
  859   __ cmp(Rtemp, iCache);
  860   __ jump(SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type, noreg, ne);
  861 }
  862 
  863 uint MachUEPNode::size(PhaseRegAlloc *ra_) const {
  864   return MachNode::size(ra_);
  865 }
  866 
  867 
  868 //=============================================================================
  869 
  870 // Emit exception handler code.
  871 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf) {
  872   MacroAssembler _masm(&amp;cbuf);
  873 
  874   address base = __ start_a_stub(size_exception_handler());
  875   if (base == NULL) {
  876     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
  877     return 0;  // CodeBuffer::expand failed
  878   }
  879 
  880   int offset = __ offset();
  881 
  882   // OK to trash LR, because exception blob will kill it
  883   __ jump(OptoRuntime::exception_blob()-&gt;entry_point(), relocInfo::runtime_call_type, LR_tmp);
  884 
  885   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
  886 
  887   __ end_a_stub();
  888 
  889   return offset;
  890 }
  891 
  892 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf) {
  893   // Can&#39;t use any of the current frame&#39;s registers as we may have deopted
  894   // at a poll and everything can be live.
  895   MacroAssembler _masm(&amp;cbuf);
  896 
  897   address base = __ start_a_stub(size_deopt_handler());
  898   if (base == NULL) {
  899     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
  900     return 0;  // CodeBuffer::expand failed
  901   }
  902 
  903   int offset = __ offset();
  904   address deopt_pc = __ pc();
  905 
  906   __ sub(SP, SP, wordSize); // make room for saved PC
  907   __ push(LR); // save LR that may be live when we get here
  908   __ mov_relative_address(LR, deopt_pc);
  909   __ str(LR, Address(SP, wordSize)); // save deopt PC
  910   __ pop(LR); // restore LR
  911   __ jump(SharedRuntime::deopt_blob()-&gt;unpack(), relocInfo::runtime_call_type, noreg);
  912 
  913   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
  914 
  915   __ end_a_stub();
  916   return offset;
  917 }
  918 
  919 const bool Matcher::match_rule_supported(int opcode) {
  920   if (!has_match_rule(opcode))
  921     return false;
  922 
  923   switch (opcode) {
  924   case Op_PopCountI:
  925   case Op_PopCountL:
  926     if (!UsePopCountInstruction)
  927       return false;
  928     break;
  929   case Op_LShiftCntV:
  930   case Op_RShiftCntV:
  931   case Op_AddVB:
  932   case Op_AddVS:
  933   case Op_AddVI:
  934   case Op_AddVL:
  935   case Op_SubVB:
  936   case Op_SubVS:
  937   case Op_SubVI:
  938   case Op_SubVL:
  939   case Op_MulVS:
  940   case Op_MulVI:
  941   case Op_LShiftVB:
  942   case Op_LShiftVS:
  943   case Op_LShiftVI:
  944   case Op_LShiftVL:
  945   case Op_RShiftVB:
  946   case Op_RShiftVS:
  947   case Op_RShiftVI:
  948   case Op_RShiftVL:
  949   case Op_URShiftVB:
  950   case Op_URShiftVS:
  951   case Op_URShiftVI:
  952   case Op_URShiftVL:
  953   case Op_AndV:
  954   case Op_OrV:
  955   case Op_XorV:
  956     return VM_Version::has_simd();
  957   case Op_LoadVector:
  958   case Op_StoreVector:
  959   case Op_AddVF:
  960   case Op_SubVF:
  961   case Op_MulVF:
  962     return VM_Version::has_vfp() || VM_Version::has_simd();
  963   case Op_AddVD:
  964   case Op_SubVD:
  965   case Op_MulVD:
  966   case Op_DivVF:
  967   case Op_DivVD:
  968     return VM_Version::has_vfp();
  969   }
  970 
  971   return true;  // Per default match rules are supported.
  972 }
  973 
  974 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
  975 
  976   // TODO
  977   // identify extra cases that we might want to provide match rules for
  978   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
  979   bool ret_value = match_rule_supported(opcode);
  980   // Add rules here.
  981 
  982   return ret_value;  // Per default match rules are supported.
  983 }
  984 
  985 const bool Matcher::has_predicated_vectors(void) {
  986   return false;
  987 }
  988 
  989 const int Matcher::float_pressure(int default_pressure_threshold) {
  990   return default_pressure_threshold;
  991 }
  992 
  993 int Matcher::regnum_to_fpu_offset(int regnum) {
  994   return regnum - 32; // The FP registers are in the second chunk
  995 }
  996 
  997 // Vector width in bytes
  998 const int Matcher::vector_width_in_bytes(BasicType bt) {
  999   return MaxVectorSize;
 1000 }
 1001 
 1002 // Vector ideal reg corresponding to specified size in bytes
 1003 const uint Matcher::vector_ideal_reg(int size) {
 1004   assert(MaxVectorSize &gt;= size, &quot;&quot;);
 1005   switch(size) {
 1006     case  8: return Op_VecD;
 1007     case 16: return Op_VecX;
 1008   }
 1009   ShouldNotReachHere();
 1010   return 0;
 1011 }
 1012 
 1013 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 1014   return vector_ideal_reg(size);
 1015 }
 1016 
 1017 // Limits on vector size (number of elements) loaded into vector.
 1018 const int Matcher::max_vector_size(const BasicType bt) {
 1019   assert(is_java_primitive(bt), &quot;only primitive type vectors&quot;);
 1020   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 1021 }
 1022 
 1023 const int Matcher::min_vector_size(const BasicType bt) {
 1024   assert(is_java_primitive(bt), &quot;only primitive type vectors&quot;);
 1025   return 8/type2aelembytes(bt);
 1026 }
 1027 
 1028 // ARM doesn&#39;t support misaligned vectors store/load.
 1029 const bool Matcher::misaligned_vectors_ok() {
 1030   return false;
 1031 }
 1032 
 1033 // ARM doesn&#39;t support AES intrinsics
 1034 const bool Matcher::pass_original_key_for_aes() {
 1035   return false;
 1036 }
 1037 
 1038 const bool Matcher::convL2FSupported(void) {
 1039   return false;
 1040 }
 1041 
 1042 // Is this branch offset short enough that a short branch can be used?
 1043 //
 1044 // NOTE: If the platform does not provide any short branch variants, then
 1045 //       this method should return false for offset 0.
 1046 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 1047   // The passed offset is relative to address of the branch.
 1048   // On ARM a branch displacement is calculated relative to address
 1049   // of the branch + 8.
 1050   //
 1051   // offset -= 8;
 1052   // return (Assembler::is_simm24(offset));
 1053   return false;
 1054 }
 1055 
 1056 const bool Matcher::isSimpleConstant64(jlong value) {
 1057   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 1058   return false;
 1059 }
 1060 
 1061 // No scaling for the parameter the ClearArray node.
 1062 const bool Matcher::init_array_count_is_in_bytes = true;
 1063 
 1064 // Needs 2 CMOV&#39;s for longs.
 1065 const int Matcher::long_cmove_cost() { return 2; }
 1066 
 1067 // CMOVF/CMOVD are expensive on ARM.
 1068 const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }
 1069 
 1070 // Does the CPU require late expand (see block.cpp for description of late expand)?
 1071 const bool Matcher::require_postalloc_expand = false;
 1072 
 1073 // Do we need to mask the count passed to shift instructions or does
 1074 // the cpu only look at the lower 5/6 bits anyway?
 1075 // FIXME: does this handle vector shifts as well?
 1076 const bool Matcher::need_masked_shift_count = true;
 1077 
 1078 const bool Matcher::convi2l_type_required = true;
 1079 
 1080 // No support for generic vector operands.
 1081 const bool Matcher::supports_generic_vector_operands  = false;
 1082 
 1083 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 1084   ShouldNotReachHere(); // generic vector operands not supported
 1085   return NULL;
 1086 }
 1087 
 1088 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 1089   ShouldNotReachHere();  // generic vector operands not supported
 1090   return false;
 1091 }
 1092 
 1093 bool Matcher::is_generic_vector(MachOper* opnd)  {
 1094   ShouldNotReachHere();  // generic vector operands not supported
 1095   return false;
 1096 }
 1097 
 1098 // Should the Matcher clone shifts on addressing modes, expecting them
 1099 // to be subsumed into complex addressing expressions or compute them
 1100 // into registers?
 1101 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 1102   return clone_base_plus_offset_address(m, mstack, address_visited);
 1103 }
 1104 
 1105 void Compile::reshape_address(AddPNode* addp) {
 1106 }
 1107 
 1108 bool Matcher::narrow_oop_use_complex_address() {
 1109   NOT_LP64(ShouldNotCallThis());
 1110   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1111   return false;
 1112 }
 1113 
 1114 bool Matcher::narrow_klass_use_complex_address() {
 1115   NOT_LP64(ShouldNotCallThis());
 1116   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1117   return false;
 1118 }
 1119 
 1120 bool Matcher::const_oop_prefer_decode() {
 1121   NOT_LP64(ShouldNotCallThis());
 1122   return true;
 1123 }
 1124 
 1125 bool Matcher::const_klass_prefer_decode() {
 1126   NOT_LP64(ShouldNotCallThis());
 1127   return true;
 1128 }
 1129 
 1130 // Is it better to copy float constants, or load them directly from memory?
 1131 // Intel can load a float constant from a direct address, requiring no
 1132 // extra registers.  Most RISCs will have to materialize an address into a
 1133 // register first, so they would do better to copy the constant from stack.
 1134 const bool Matcher::rematerialize_float_constants = false;
 1135 
 1136 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1137 // needed.  Else we split the double into 2 integer pieces and move it
 1138 // piece-by-piece.  Only happens when passing doubles into C code as the
 1139 // Java calling convention forces doubles to be aligned.
 1140 const bool Matcher::misaligned_doubles_ok = false;
 1141 
 1142 // No-op on ARM.
 1143 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1144 }
 1145 
 1146 // Advertise here if the CPU requires explicit rounding operations
 1147 // to implement the UseStrictFP mode.
 1148 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1149 
 1150 // Are floats converted to double when stored to stack during deoptimization?
 1151 // ARM does not handle callee-save floats.
 1152 bool Matcher::float_in_double() {
 1153   return false;
 1154 }
 1155 
 1156 // Do ints take an entire long register or just half?
 1157 // Note that we if-def off of _LP64.
 1158 // The relevant question is how the int is callee-saved.  In _LP64
 1159 // the whole long is written but de-opt&#39;ing will have to extract
 1160 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1161 #ifdef _LP64
 1162 const bool Matcher::int_in_long = true;
 1163 #else
 1164 const bool Matcher::int_in_long = false;
 1165 #endif
 1166 
 1167 // Return whether or not this register is ever used as an argument.  This
 1168 // function is used on startup to build the trampoline stubs in generateOptoStub.
 1169 // Registers not mentioned will be killed by the VM call in the trampoline, and
 1170 // arguments in those registers not be available to the callee.
 1171 bool Matcher::can_be_java_arg( int reg ) {
 1172   if (reg == R_R0_num ||
 1173       reg == R_R1_num ||
 1174       reg == R_R2_num ||
 1175       reg == R_R3_num) return true;
 1176 
 1177   if (reg &gt;= R_S0_num &amp;&amp;
 1178       reg &lt;= R_S13_num) return true;
 1179   return false;
 1180 }
 1181 
 1182 bool Matcher::is_spillable_arg( int reg ) {
 1183   return can_be_java_arg(reg);
 1184 }
 1185 
 1186 bool Matcher::use_asm_for_ldiv_by_con( jlong divisor ) {
 1187   return false;
 1188 }
 1189 
 1190 // Register for DIVI projection of divmodI
 1191 RegMask Matcher::divI_proj_mask() {
 1192   ShouldNotReachHere();
 1193   return RegMask();
 1194 }
 1195 
 1196 // Register for MODI projection of divmodI
 1197 RegMask Matcher::modI_proj_mask() {
 1198   ShouldNotReachHere();
 1199   return RegMask();
 1200 }
 1201 
 1202 // Register for DIVL projection of divmodL
 1203 RegMask Matcher::divL_proj_mask() {
 1204   ShouldNotReachHere();
 1205   return RegMask();
 1206 }
 1207 
 1208 // Register for MODL projection of divmodL
 1209 RegMask Matcher::modL_proj_mask() {
 1210   ShouldNotReachHere();
 1211   return RegMask();
 1212 }
 1213 
 1214 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 1215   return FP_REGP_mask();
 1216 }
 1217 
 1218 bool maybe_far_call(const CallNode *n) {
 1219   return !MacroAssembler::_reachable_from_cache(n-&gt;as_Call()-&gt;entry_point());
 1220 }
 1221 
 1222 bool maybe_far_call(const MachCallNode *n) {
 1223   return !MacroAssembler::_reachable_from_cache(n-&gt;as_MachCall()-&gt;entry_point());
 1224 }
 1225 
 1226 %}
 1227 
 1228 //----------ENCODING BLOCK-----------------------------------------------------
 1229 // This block specifies the encoding classes used by the compiler to output
 1230 // byte streams.  Encoding classes are parameterized macros used by
 1231 // Machine Instruction Nodes in order to generate the bit encoding of the
 1232 // instruction.  Operands specify their base encoding interface with the
 1233 // interface keyword.  There are currently supported four interfaces,
 1234 // REG_INTER, CONST_INTER, MEMORY_INTER, &amp; COND_INTER.  REG_INTER causes an
 1235 // operand to generate a function which returns its register number when
 1236 // queried.   CONST_INTER causes an operand to generate a function which
 1237 // returns the value of the constant when queried.  MEMORY_INTER causes an
 1238 // operand to generate four functions which return the Base Register, the
 1239 // Index Register, the Scale Value, and the Offset Value of the operand when
 1240 // queried.  COND_INTER causes an operand to generate six functions which
 1241 // return the encoding code (ie - encoding bits for the instruction)
 1242 // associated with each basic boolean condition for a conditional instruction.
 1243 //
 1244 // Instructions specify two basic values for encoding.  Again, a function
 1245 // is available to check if the constant displacement is an oop. They use the
 1246 // ins_encode keyword to specify their encoding classes (which must be
 1247 // a sequence of enc_class names, and their parameters, specified in
 1248 // the encoding block), and they use the
 1249 // opcode keyword to specify, in order, their primary, secondary, and
 1250 // tertiary opcode.  Only the opcode sections which a particular instruction
 1251 // needs for encoding need to be specified.
 1252 encode %{
 1253   enc_class call_epilog %{
 1254     // nothing
 1255   %}
 1256 
 1257   enc_class Java_To_Runtime (method meth) %{
 1258     // CALL directly to the runtime
 1259     emit_call_reloc(cbuf, as_MachCall(), $meth, runtime_call_Relocation::spec());
 1260   %}
 1261 
 1262   enc_class Java_Static_Call (method meth) %{
 1263     // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
 1264     // who we intended to call.
 1265 
 1266     if ( !_method) {
 1267       emit_call_reloc(cbuf, as_MachCall(), $meth, runtime_call_Relocation::spec());
 1268     } else {
 1269       int method_index = resolved_method_index(cbuf);
 1270       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 1271                                                   : static_call_Relocation::spec(method_index);
 1272       emit_call_reloc(cbuf, as_MachCall(), $meth, rspec);
 1273 
 1274       // Emit stubs for static call.
 1275       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 1276       if (stub == NULL) {
 1277         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 1278         return;
 1279       }
 1280     }
 1281   %}
 1282 
 1283   enc_class save_last_PC %{
 1284     // preserve mark
 1285     address mark = cbuf.insts()-&gt;mark();
 1286     debug_only(int off0 = cbuf.insts_size());
 1287     MacroAssembler _masm(&amp;cbuf);
 1288     int ret_addr_offset = as_MachCall()-&gt;ret_addr_offset();
 1289     __ adr(LR, mark + ret_addr_offset);
 1290     __ str(LR, Address(Rthread, JavaThread::last_Java_pc_offset()));
 1291     debug_only(int off1 = cbuf.insts_size());
 1292     assert(off1 - off0 == 2 * Assembler::InstructionSize, &quot;correct size prediction&quot;);
 1293     // restore mark
 1294     cbuf.insts()-&gt;set_mark(mark);
 1295   %}
 1296 
 1297   enc_class preserve_SP %{
 1298     // preserve mark
 1299     address mark = cbuf.insts()-&gt;mark();
 1300     debug_only(int off0 = cbuf.insts_size());
 1301     MacroAssembler _masm(&amp;cbuf);
 1302     // FP is preserved across all calls, even compiled calls.
 1303     // Use it to preserve SP in places where the callee might change the SP.
 1304     __ mov(Rmh_SP_save, SP);
 1305     debug_only(int off1 = cbuf.insts_size());
 1306     assert(off1 - off0 == 4, &quot;correct size prediction&quot;);
 1307     // restore mark
 1308     cbuf.insts()-&gt;set_mark(mark);
 1309   %}
 1310 
 1311   enc_class restore_SP %{
 1312     MacroAssembler _masm(&amp;cbuf);
 1313     __ mov(SP, Rmh_SP_save);
 1314   %}
 1315 
 1316   enc_class Java_Dynamic_Call (method meth) %{
 1317     MacroAssembler _masm(&amp;cbuf);
 1318     Register R8_ic_reg = reg_to_register_object(Matcher::inline_cache_reg_encode());
 1319     assert(R8_ic_reg == Ricklass, &quot;should be&quot;);
 1320     __ set_inst_mark();
 1321     __ movw(R8_ic_reg, ((unsigned int)Universe::non_oop_word()) &amp; 0xffff);
 1322     __ movt(R8_ic_reg, ((unsigned int)Universe::non_oop_word()) &gt;&gt; 16);
 1323     address  virtual_call_oop_addr = __ inst_mark();
 1324     // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
 1325     // who we intended to call.
 1326     int method_index = resolved_method_index(cbuf);
 1327     __ relocate(virtual_call_Relocation::spec(virtual_call_oop_addr, method_index));
 1328     emit_call_reloc(cbuf, as_MachCall(), $meth, RelocationHolder::none);
 1329   %}
 1330 
 1331   enc_class LdReplImmI(immI src, regD dst, iRegI tmp, int cnt, int wth) %{
 1332     // FIXME: load from constant table?
 1333     // Load a constant replicated &quot;count&quot; times with width &quot;width&quot;
 1334     int count = $cnt$$constant;
 1335     int width = $wth$$constant;
 1336     assert(count*width == 4, &quot;sanity&quot;);
 1337     int val = $src$$constant;
 1338     if (width &lt; 4) {
 1339       int bit_width = width * 8;
 1340       val &amp;= (((int)1) &lt;&lt; bit_width) - 1; // mask off sign bits
 1341       for (int i = 0; i &lt; count - 1; i++) {
 1342         val |= (val &lt;&lt; bit_width);
 1343       }
 1344     }
 1345     MacroAssembler _masm(&amp;cbuf);
 1346 
 1347     if (val == -1) {
 1348       __ mvn($tmp$$Register, 0);
 1349     } else if (val == 0) {
 1350       __ mov($tmp$$Register, 0);
 1351     } else {
 1352       __ movw($tmp$$Register, val &amp; 0xffff);
 1353       __ movt($tmp$$Register, (unsigned int)val &gt;&gt; 16);
 1354     }
 1355     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 1356   %}
 1357 
 1358   enc_class LdReplImmF(immF src, regD dst, iRegI tmp) %{
 1359     // Replicate float con 2 times and pack into vector (8 bytes) in regD.
 1360     float fval = $src$$constant;
 1361     int val = *((int*)&amp;fval);
 1362     MacroAssembler _masm(&amp;cbuf);
 1363 
 1364     if (val == -1) {
 1365       __ mvn($tmp$$Register, 0);
 1366     } else if (val == 0) {
 1367       __ mov($tmp$$Register, 0);
 1368     } else {
 1369       __ movw($tmp$$Register, val &amp; 0xffff);
 1370       __ movt($tmp$$Register, (unsigned int)val &gt;&gt; 16);
 1371     }
 1372     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 1373   %}
 1374 
 1375   enc_class enc_String_Compare(R0RegP str1, R1RegP str2, R2RegI cnt1, R3RegI cnt2, iRegI result, iRegI tmp1, iRegI tmp2) %{
 1376     Label Ldone, Lloop;
 1377     MacroAssembler _masm(&amp;cbuf);
 1378 
 1379     Register   str1_reg = $str1$$Register;
 1380     Register   str2_reg = $str2$$Register;
 1381     Register   cnt1_reg = $cnt1$$Register; // int
 1382     Register   cnt2_reg = $cnt2$$Register; // int
 1383     Register   tmp1_reg = $tmp1$$Register;
 1384     Register   tmp2_reg = $tmp2$$Register;
 1385     Register result_reg = $result$$Register;
 1386 
 1387     assert_different_registers(str1_reg, str2_reg, cnt1_reg, cnt2_reg, tmp1_reg, tmp2_reg);
 1388 
 1389     // Compute the minimum of the string lengths(str1_reg) and the
 1390     // difference of the string lengths (stack)
 1391 
 1392     // See if the lengths are different, and calculate min in str1_reg.
 1393     // Stash diff in tmp2 in case we need it for a tie-breaker.
 1394     __ subs_32(tmp2_reg, cnt1_reg, cnt2_reg);
 1395     __ mov(cnt1_reg, AsmOperand(cnt1_reg, lsl, exact_log2(sizeof(jchar)))); // scale the limit
 1396     __ mov(cnt1_reg, AsmOperand(cnt2_reg, lsl, exact_log2(sizeof(jchar))), pl); // scale the limit
 1397 
 1398     // reallocate cnt1_reg, cnt2_reg, result_reg
 1399     // Note:  limit_reg holds the string length pre-scaled by 2
 1400     Register limit_reg = cnt1_reg;
 1401     Register  chr2_reg = cnt2_reg;
 1402     Register  chr1_reg = tmp1_reg;
 1403     // str{12} are the base pointers
 1404 
 1405     // Is the minimum length zero?
 1406     __ cmp_32(limit_reg, 0);
 1407     if (result_reg != tmp2_reg) {
 1408       __ mov(result_reg, tmp2_reg, eq);
 1409     }
 1410     __ b(Ldone, eq);
 1411 
 1412     // Load first characters
 1413     __ ldrh(chr1_reg, Address(str1_reg, 0));
 1414     __ ldrh(chr2_reg, Address(str2_reg, 0));
 1415 
 1416     // Compare first characters
 1417     __ subs(chr1_reg, chr1_reg, chr2_reg);
 1418     if (result_reg != chr1_reg) {
 1419       __ mov(result_reg, chr1_reg, ne);
 1420     }
 1421     __ b(Ldone, ne);
 1422 
 1423     {
 1424       // Check after comparing first character to see if strings are equivalent
 1425       // Check if the strings start at same location
 1426       __ cmp(str1_reg, str2_reg);
 1427       // Check if the length difference is zero
 1428       __ cond_cmp(tmp2_reg, 0, eq);
 1429       __ mov(result_reg, 0, eq); // result is zero
 1430       __ b(Ldone, eq);
 1431       // Strings might not be equal
 1432     }
 1433 
 1434     __ subs(chr1_reg, limit_reg, 1 * sizeof(jchar));
 1435     if (result_reg != tmp2_reg) {
 1436       __ mov(result_reg, tmp2_reg, eq);
 1437     }
 1438     __ b(Ldone, eq);
 1439 
 1440     // Shift str1_reg and str2_reg to the end of the arrays, negate limit
 1441     __ add(str1_reg, str1_reg, limit_reg);
 1442     __ add(str2_reg, str2_reg, limit_reg);
 1443     __ neg(limit_reg, chr1_reg);  // limit = -(limit-2)
 1444 
 1445     // Compare the rest of the characters
 1446     __ bind(Lloop);
 1447     __ ldrh(chr1_reg, Address(str1_reg, limit_reg));
 1448     __ ldrh(chr2_reg, Address(str2_reg, limit_reg));
 1449     __ subs(chr1_reg, chr1_reg, chr2_reg);
 1450     if (result_reg != chr1_reg) {
 1451       __ mov(result_reg, chr1_reg, ne);
 1452     }
 1453     __ b(Ldone, ne);
 1454 
 1455     __ adds(limit_reg, limit_reg, sizeof(jchar));
 1456     __ b(Lloop, ne);
 1457 
 1458     // If strings are equal up to min length, return the length difference.
 1459     if (result_reg != tmp2_reg) {
 1460       __ mov(result_reg, tmp2_reg);
 1461     }
 1462 
 1463     // Otherwise, return the difference between the first mismatched chars.
 1464     __ bind(Ldone);
 1465   %}
 1466 
 1467   enc_class enc_String_Equals(R0RegP str1, R1RegP str2, R2RegI cnt, iRegI result, iRegI tmp1, iRegI tmp2) %{
 1468     Label Lchar, Lchar_loop, Ldone, Lequal;
 1469     MacroAssembler _masm(&amp;cbuf);
 1470 
 1471     Register   str1_reg = $str1$$Register;
 1472     Register   str2_reg = $str2$$Register;
 1473     Register    cnt_reg = $cnt$$Register; // int
 1474     Register   tmp1_reg = $tmp1$$Register;
 1475     Register   tmp2_reg = $tmp2$$Register;
 1476     Register result_reg = $result$$Register;
 1477 
 1478     assert_different_registers(str1_reg, str2_reg, cnt_reg, tmp1_reg, tmp2_reg, result_reg);
 1479 
 1480     __ cmp(str1_reg, str2_reg); //same char[] ?
 1481     __ b(Lequal, eq);
 1482 
 1483     __ cbz_32(cnt_reg, Lequal); // count == 0
 1484 
 1485     //rename registers
 1486     Register limit_reg = cnt_reg;
 1487     Register  chr1_reg = tmp1_reg;
 1488     Register  chr2_reg = tmp2_reg;
 1489 
 1490     __ logical_shift_left(limit_reg, limit_reg, exact_log2(sizeof(jchar)));
 1491 
 1492     //check for alignment and position the pointers to the ends
 1493     __ orr(chr1_reg, str1_reg, str2_reg);
 1494     __ tst(chr1_reg, 0x3);
 1495 
 1496     // notZero means at least one not 4-byte aligned.
 1497     // We could optimize the case when both arrays are not aligned
 1498     // but it is not frequent case and it requires additional checks.
 1499     __ b(Lchar, ne);
 1500 
 1501     // Compare char[] arrays aligned to 4 bytes.
 1502     __ char_arrays_equals(str1_reg, str2_reg, limit_reg, result_reg,
 1503                           chr1_reg, chr2_reg, Ldone);
 1504 
 1505     __ b(Lequal); // equal
 1506 
 1507     // char by char compare
 1508     __ bind(Lchar);
 1509     __ mov(result_reg, 0);
 1510     __ add(str1_reg, limit_reg, str1_reg);
 1511     __ add(str2_reg, limit_reg, str2_reg);
 1512     __ neg(limit_reg, limit_reg); //negate count
 1513 
 1514     // Lchar_loop
 1515     __ bind(Lchar_loop);
 1516     __ ldrh(chr1_reg, Address(str1_reg, limit_reg));
 1517     __ ldrh(chr2_reg, Address(str2_reg, limit_reg));
 1518     __ cmp(chr1_reg, chr2_reg);
 1519     __ b(Ldone, ne);
 1520     __ adds(limit_reg, limit_reg, sizeof(jchar));
 1521     __ b(Lchar_loop, ne);
 1522 
 1523     __ bind(Lequal);
 1524     __ mov(result_reg, 1);  //equal
 1525 
 1526     __ bind(Ldone);
 1527   %}
 1528 
 1529   enc_class enc_Array_Equals(R0RegP ary1, R1RegP ary2, iRegI tmp1, iRegI tmp2, iRegI tmp3, iRegI result) %{
 1530     Label Ldone, Lloop, Lequal;
 1531     MacroAssembler _masm(&amp;cbuf);
 1532 
 1533     Register   ary1_reg = $ary1$$Register;
 1534     Register   ary2_reg = $ary2$$Register;
 1535     Register   tmp1_reg = $tmp1$$Register;
 1536     Register   tmp2_reg = $tmp2$$Register;
 1537     Register   tmp3_reg = $tmp3$$Register;
 1538     Register result_reg = $result$$Register;
 1539 
 1540     assert_different_registers(ary1_reg, ary2_reg, tmp1_reg, tmp2_reg, tmp3_reg, result_reg);
 1541 
 1542     int length_offset  = arrayOopDesc::length_offset_in_bytes();
 1543     int base_offset    = arrayOopDesc::base_offset_in_bytes(T_CHAR);
 1544 
 1545     // return true if the same array
 1546     __ teq(ary1_reg, ary2_reg);
 1547     __ mov(result_reg, 1, eq);
 1548     __ b(Ldone, eq); // equal
 1549 
 1550     __ tst(ary1_reg, ary1_reg);
 1551     __ mov(result_reg, 0, eq);
 1552     __ b(Ldone, eq);    // not equal
 1553 
 1554     __ tst(ary2_reg, ary2_reg);
 1555     __ mov(result_reg, 0, eq);
 1556     __ b(Ldone, eq);    // not equal
 1557 
 1558     //load the lengths of arrays
 1559     __ ldr_s32(tmp1_reg, Address(ary1_reg, length_offset)); // int
 1560     __ ldr_s32(tmp2_reg, Address(ary2_reg, length_offset)); // int
 1561 
 1562     // return false if the two arrays are not equal length
 1563     __ teq_32(tmp1_reg, tmp2_reg);
 1564     __ mov(result_reg, 0, ne);
 1565     __ b(Ldone, ne);    // not equal
 1566 
 1567     __ tst(tmp1_reg, tmp1_reg);
 1568     __ mov(result_reg, 1, eq);
 1569     __ b(Ldone, eq);    // zero-length arrays are equal
 1570 
 1571     // load array addresses
 1572     __ add(ary1_reg, ary1_reg, base_offset);
 1573     __ add(ary2_reg, ary2_reg, base_offset);
 1574 
 1575     // renaming registers
 1576     Register chr1_reg  =  tmp3_reg;   // for characters in ary1
 1577     Register chr2_reg  =  tmp2_reg;   // for characters in ary2
 1578     Register limit_reg =  tmp1_reg;   // length
 1579 
 1580     // set byte count
 1581     __ logical_shift_left_32(limit_reg, limit_reg, exact_log2(sizeof(jchar)));
 1582 
 1583     // Compare char[] arrays aligned to 4 bytes.
 1584     __ char_arrays_equals(ary1_reg, ary2_reg, limit_reg, result_reg,
 1585                           chr1_reg, chr2_reg, Ldone);
 1586     __ bind(Lequal);
 1587     __ mov(result_reg, 1);  //equal
 1588 
 1589     __ bind(Ldone);
 1590     %}
 1591 %}
 1592 
 1593 //----------FRAME--------------------------------------------------------------
 1594 // Definition of frame structure and management information.
 1595 //
 1596 //  S T A C K   L A Y O U T    Allocators stack-slot number
 1597 //                             |   (to get allocators register number
 1598 //  G  Owned by    |        |  v    add VMRegImpl::stack0)
 1599 //  r   CALLER     |        |
 1600 //  o     |        +--------+      pad to even-align allocators stack-slot
 1601 //  w     V        |  pad0  |        numbers; owned by CALLER
 1602 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 1603 //  h     ^        |   in   |  5
 1604 //        |        |  args  |  4   Holes in incoming args owned by SELF
 1605 //  |     |        |        |  3
 1606 //  |     |        +--------+
 1607 //  V     |        | old out|      Empty on Intel, window on Sparc
 1608 //        |    old |preserve|      Must be even aligned.
 1609 //        |     SP-+--------+----&gt; Matcher::_old_SP, 8 (or 16 in LP64)-byte aligned
 1610 //        |        |   in   |  3   area for Intel ret address
 1611 //     Owned by    |preserve|      Empty on Sparc.
 1612 //       SELF      +--------+
 1613 //        |        |  pad2  |  2   pad to align old SP
 1614 //        |        +--------+  1
 1615 //        |        | locks  |  0
 1616 //        |        +--------+----&gt; VMRegImpl::stack0, 8 (or 16 in LP64)-byte aligned
 1617 //        |        |  pad1  | 11   pad to align new SP
 1618 //        |        +--------+
 1619 //        |        |        | 10
 1620 //        |        | spills |  9   spills
 1621 //        V        |        |  8   (pad0 slot for callee)
 1622 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 1623 //        ^        |  out   |  7
 1624 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 1625 //     Owned by    +--------+
 1626 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 1627 //        |    new |preserve|      Must be even-aligned.
 1628 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 1629 //        |        |        |
 1630 //
 1631 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 1632 //         known from SELF&#39;s arguments and the Java calling convention.
 1633 //         Region 6-7 is determined per call site.
 1634 // Note 2: If the calling convention leaves holes in the incoming argument
 1635 //         area, those holes are owned by SELF.  Holes in the outgoing area
 1636 //         are owned by the CALLEE.  Holes should not be nessecary in the
 1637 //         incoming area, as the Java calling convention is completely under
 1638 //         the control of the AD file.  Doubles can be sorted and packed to
 1639 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 1640 //         varargs C calling conventions.
 1641 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 1642 //         even aligned with pad0 as needed.
 1643 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 1644 //         region 6-11 is even aligned; it may be padded out more so that
 1645 //         the region from SP to FP meets the minimum stack alignment.
 1646 
 1647 frame %{
 1648   // What direction does stack grow in (assumed to be same for native &amp; Java)
 1649   stack_direction(TOWARDS_LOW);
 1650 
 1651   // These two registers define part of the calling convention
 1652   // between compiled code and the interpreter.
 1653   inline_cache_reg(R_Ricklass);          // Inline Cache Register or Method* for I2C
 1654   interpreter_method_oop_reg(R_Rmethod); // Method Oop Register when calling interpreter
 1655 
 1656   // Optional: name the operand used by cisc-spilling to access [stack_pointer + offset]
 1657   cisc_spilling_operand_name(indOffset);
 1658 
 1659   // Number of stack slots consumed by a Monitor enter
 1660   sync_stack_slots(1 * VMRegImpl::slots_per_word);
 1661 
 1662   // Compiled code&#39;s Frame Pointer
 1663   frame_pointer(R_R13);
 1664 
 1665   // Stack alignment requirement
 1666   stack_alignment(StackAlignmentInBytes);
 1667   //  LP64: Alignment size in bytes (128-bit -&gt; 16 bytes)
 1668   // !LP64: Alignment size in bytes (64-bit  -&gt;  8 bytes)
 1669 
 1670   // Number of stack slots between incoming argument block and the start of
 1671   // a new frame.  The PROLOG must add this many slots to the stack.  The
 1672   // EPILOG must remove this many slots.
 1673   // FP + LR
 1674   in_preserve_stack_slots(2 * VMRegImpl::slots_per_word);
 1675 
 1676   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 1677   // for calls to C.  Supports the var-args backing area for register parms.
 1678   // ADLC doesn&#39;t support parsing expressions, so I folded the math by hand.
 1679   varargs_C_out_slots_killed( 0);
 1680 
 1681   // The after-PROLOG location of the return address.  Location of
 1682   // return address specifies a type (REG or STACK) and a number
 1683   // representing the register number (i.e. - use a register name) or
 1684   // stack slot.
 1685   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 1686   // Otherwise, it is above the locks and verification slot and alignment word
 1687   return_addr(STACK - 1*VMRegImpl::slots_per_word +
 1688               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 1689                         Compile::current()-&gt;fixed_slots()),
 1690                        stack_alignment_in_slots()));
 1691 
 1692   // Body of function which returns an OptoRegs array locating
 1693   // arguments either in registers or in stack slots for calling
 1694   // java
 1695   calling_convention %{
 1696     (void) SharedRuntime::java_calling_convention(sig_bt, regs, length, is_outgoing);
 1697 
 1698   %}
 1699 
 1700   // Body of function which returns an OptoRegs array locating
 1701   // arguments either in registers or in stack slots for callin
 1702   // C.
 1703   c_calling_convention %{
 1704     // This is obviously always outgoing
 1705     (void) SharedRuntime::c_calling_convention(sig_bt, regs, /*regs2=*/NULL, length);
 1706   %}
 1707 
 1708   // Location of compiled Java return values.  Same as C
 1709   return_value %{
 1710     return c2::return_value(ideal_reg);
 1711   %}
 1712 
 1713 %}
 1714 
 1715 //----------ATTRIBUTES---------------------------------------------------------
 1716 //----------Instruction Attributes---------------------------------------------
 1717 ins_attrib ins_cost(DEFAULT_COST); // Required cost attribute
 1718 ins_attrib ins_size(32);           // Required size attribute (in bits)
 1719 ins_attrib ins_short_branch(0);    // Required flag: is this instruction a
 1720                                    // non-matching short branch variant of some
 1721                                                             // long branch?
 1722 
 1723 //----------OPERANDS-----------------------------------------------------------
 1724 // Operand definitions must precede instruction definitions for correct parsing
 1725 // in the ADLC because operands constitute user defined types which are used in
 1726 // instruction definitions.
 1727 
 1728 //----------Simple Operands----------------------------------------------------
 1729 // Immediate Operands
 1730 // Integer Immediate: 32-bit
 1731 operand immI() %{
 1732   match(ConI);
 1733 
 1734   op_cost(0);
 1735   // formats are generated automatically for constants and base registers
 1736   format %{ %}
 1737   interface(CONST_INTER);
 1738 %}
 1739 
 1740 // Integer Immediate: 8-bit unsigned - for VMOV
 1741 operand immU8() %{
 1742   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 255));
 1743   match(ConI);
 1744   op_cost(0);
 1745 
 1746   format %{ %}
 1747   interface(CONST_INTER);
 1748 %}
 1749 
 1750 // Integer Immediate: 16-bit
 1751 operand immI16() %{
 1752   predicate((n-&gt;get_int() &gt;&gt; 16) == 0 &amp;&amp; VM_Version::supports_movw());
 1753   match(ConI);
 1754   op_cost(0);
 1755 
 1756   format %{ %}
 1757   interface(CONST_INTER);
 1758 %}
 1759 
 1760 // Integer Immediate: offset for half and double word loads and stores
 1761 operand immIHD() %{
 1762   predicate(is_memoryHD(n-&gt;get_int()));
 1763   match(ConI);
 1764   op_cost(0);
 1765   format %{ %}
 1766   interface(CONST_INTER);
 1767 %}
 1768 
 1769 // Integer Immediate: offset for fp loads and stores
 1770 operand immIFP() %{
 1771   predicate(is_memoryfp(n-&gt;get_int()) &amp;&amp; ((n-&gt;get_int() &amp; 3) == 0));
 1772   match(ConI);
 1773   op_cost(0);
 1774 
 1775   format %{ %}
 1776   interface(CONST_INTER);
 1777 %}
 1778 
 1779 // Valid scale values for addressing modes and shifts
 1780 operand immU5() %{
 1781   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 31));
 1782   match(ConI);
 1783   op_cost(0);
 1784 
 1785   format %{ %}
 1786   interface(CONST_INTER);
 1787 %}
 1788 
 1789 // Integer Immediate: 6-bit
 1790 operand immU6Big() %{
 1791   predicate(n-&gt;get_int() &gt;= 32 &amp;&amp; n-&gt;get_int() &lt;= 63);
 1792   match(ConI);
 1793   op_cost(0);
 1794   format %{ %}
 1795   interface(CONST_INTER);
 1796 %}
 1797 
 1798 // Integer Immediate: 0-bit
 1799 operand immI0() %{
 1800   predicate(n-&gt;get_int() == 0);
 1801   match(ConI);
 1802   op_cost(0);
 1803 
 1804   format %{ %}
 1805   interface(CONST_INTER);
 1806 %}
 1807 
 1808 // Integer Immediate: the value 1
 1809 operand immI_1() %{
 1810   predicate(n-&gt;get_int() == 1);
 1811   match(ConI);
 1812   op_cost(0);
 1813 
 1814   format %{ %}
 1815   interface(CONST_INTER);
 1816 %}
 1817 
 1818 // Integer Immediate: the value 2
 1819 operand immI_2() %{
 1820   predicate(n-&gt;get_int() == 2);
 1821   match(ConI);
 1822   op_cost(0);
 1823 
 1824   format %{ %}
 1825   interface(CONST_INTER);
 1826 %}
 1827 
 1828 // Integer Immediate: the value 3
 1829 operand immI_3() %{
 1830   predicate(n-&gt;get_int() == 3);
 1831   match(ConI);
 1832   op_cost(0);
 1833 
 1834   format %{ %}
 1835   interface(CONST_INTER);
 1836 %}
 1837 
 1838 // Integer Immediate: the value 4
 1839 operand immI_4() %{
 1840   predicate(n-&gt;get_int() == 4);
 1841   match(ConI);
 1842   op_cost(0);
 1843 
 1844   format %{ %}
 1845   interface(CONST_INTER);
 1846 %}
 1847 
 1848 // Integer Immediate: the value 8
 1849 operand immI_8() %{
 1850   predicate(n-&gt;get_int() == 8);
 1851   match(ConI);
 1852   op_cost(0);
 1853 
 1854   format %{ %}
 1855   interface(CONST_INTER);
 1856 %}
 1857 
 1858 // Int Immediate non-negative
 1859 operand immU31()
 1860 %{
 1861   predicate(n-&gt;get_int() &gt;= 0);
 1862   match(ConI);
 1863 
 1864   op_cost(0);
 1865   format %{ %}
 1866   interface(CONST_INTER);
 1867 %}
 1868 
 1869 // Integer Immediate: the values 32-63
 1870 operand immI_32_63() %{
 1871   predicate(n-&gt;get_int() &gt;= 32 &amp;&amp; n-&gt;get_int() &lt;= 63);
 1872   match(ConI);
 1873   op_cost(0);
 1874 
 1875   format %{ %}
 1876   interface(CONST_INTER);
 1877 %}
 1878 
 1879 // Immediates for special shifts (sign extend)
 1880 
 1881 // Integer Immediate: the value 16
 1882 operand immI_16() %{
 1883   predicate(n-&gt;get_int() == 16);
 1884   match(ConI);
 1885   op_cost(0);
 1886 
 1887   format %{ %}
 1888   interface(CONST_INTER);
 1889 %}
 1890 
 1891 // Integer Immediate: the value 24
 1892 operand immI_24() %{
 1893   predicate(n-&gt;get_int() == 24);
 1894   match(ConI);
 1895   op_cost(0);
 1896 
 1897   format %{ %}
 1898   interface(CONST_INTER);
 1899 %}
 1900 
 1901 // Integer Immediate: the value 255
 1902 operand immI_255() %{
 1903   predicate( n-&gt;get_int() == 255 );
 1904   match(ConI);
 1905   op_cost(0);
 1906 
 1907   format %{ %}
 1908   interface(CONST_INTER);
 1909 %}
 1910 
 1911 // Integer Immediate: the value 65535
 1912 operand immI_65535() %{
 1913   predicate(n-&gt;get_int() == 65535);
 1914   match(ConI);
 1915   op_cost(0);
 1916 
 1917   format %{ %}
 1918   interface(CONST_INTER);
 1919 %}
 1920 
 1921 // Integer Immediates for arithmetic instructions
 1922 
 1923 operand aimmI() %{
 1924   predicate(is_aimm(n-&gt;get_int()));
 1925   match(ConI);
 1926   op_cost(0);
 1927 
 1928   format %{ %}
 1929   interface(CONST_INTER);
 1930 %}
 1931 
 1932 operand aimmIneg() %{
 1933   predicate(is_aimm(-n-&gt;get_int()));
 1934   match(ConI);
 1935   op_cost(0);
 1936 
 1937   format %{ %}
 1938   interface(CONST_INTER);
 1939 %}
 1940 
 1941 operand aimmU31() %{
 1942   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; is_aimm(n-&gt;get_int()));
 1943   match(ConI);
 1944   op_cost(0);
 1945 
 1946   format %{ %}
 1947   interface(CONST_INTER);
 1948 %}
 1949 
 1950 // Integer Immediates for logical instructions
 1951 
 1952 operand limmI() %{
 1953   predicate(is_limmI(n-&gt;get_int()));
 1954   match(ConI);
 1955   op_cost(0);
 1956 
 1957   format %{ %}
 1958   interface(CONST_INTER);
 1959 %}
 1960 
 1961 operand limmIlow8() %{
 1962   predicate(is_limmI_low(n-&gt;get_int(), 8));
 1963   match(ConI);
 1964   op_cost(0);
 1965 
 1966   format %{ %}
 1967   interface(CONST_INTER);
 1968 %}
 1969 
 1970 operand limmU31() %{
 1971   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; is_limmI(n-&gt;get_int()));
 1972   match(ConI);
 1973   op_cost(0);
 1974 
 1975   format %{ %}
 1976   interface(CONST_INTER);
 1977 %}
 1978 
 1979 operand limmIn() %{
 1980   predicate(is_limmI(~n-&gt;get_int()));
 1981   match(ConI);
 1982   op_cost(0);
 1983 
 1984   format %{ %}
 1985   interface(CONST_INTER);
 1986 %}
 1987 
 1988 
 1989 // Long Immediate: the value FF
 1990 operand immL_FF() %{
 1991   predicate( n-&gt;get_long() == 0xFFL );
 1992   match(ConL);
 1993   op_cost(0);
 1994 
 1995   format %{ %}
 1996   interface(CONST_INTER);
 1997 %}
 1998 
 1999 // Long Immediate: the value FFFF
 2000 operand immL_FFFF() %{
 2001   predicate( n-&gt;get_long() == 0xFFFFL );
 2002   match(ConL);
 2003   op_cost(0);
 2004 
 2005   format %{ %}
 2006   interface(CONST_INTER);
 2007 %}
 2008 
 2009 // Pointer Immediate: 32 or 64-bit
 2010 operand immP() %{
 2011   match(ConP);
 2012 
 2013   op_cost(5);
 2014   // formats are generated automatically for constants and base registers
 2015   format %{ %}
 2016   interface(CONST_INTER);
 2017 %}
 2018 
 2019 operand immP0() %{
 2020   predicate(n-&gt;get_ptr() == 0);
 2021   match(ConP);
 2022   op_cost(0);
 2023 
 2024   format %{ %}
 2025   interface(CONST_INTER);
 2026 %}
 2027 
 2028 operand immP_poll() %{
 2029   predicate(n-&gt;get_ptr() != 0 &amp;&amp; n-&gt;get_ptr() == (intptr_t)os::get_polling_page());
 2030   match(ConP);
 2031 
 2032   // formats are generated automatically for constants and base registers
 2033   format %{ %}
 2034   interface(CONST_INTER);
 2035 %}
 2036 
 2037 // Pointer Immediate
 2038 operand immN()
 2039 %{
 2040   match(ConN);
 2041 
 2042   op_cost(10);
 2043   format %{ %}
 2044   interface(CONST_INTER);
 2045 %}
 2046 
 2047 operand immNKlass()
 2048 %{
 2049   match(ConNKlass);
 2050 
 2051   op_cost(10);
 2052   format %{ %}
 2053   interface(CONST_INTER);
 2054 %}
 2055 
 2056 // NULL Pointer Immediate
 2057 operand immN0()
 2058 %{
 2059   predicate(n-&gt;get_narrowcon() == 0);
 2060   match(ConN);
 2061 
 2062   op_cost(0);
 2063   format %{ %}
 2064   interface(CONST_INTER);
 2065 %}
 2066 
 2067 operand immL() %{
 2068   match(ConL);
 2069   op_cost(40);
 2070   // formats are generated automatically for constants and base registers
 2071   format %{ %}
 2072   interface(CONST_INTER);
 2073 %}
 2074 
 2075 operand immL0() %{
 2076   predicate(n-&gt;get_long() == 0L);
 2077   match(ConL);
 2078   op_cost(0);
 2079   // formats are generated automatically for constants and base registers
 2080   format %{ %}
 2081   interface(CONST_INTER);
 2082 %}
 2083 
 2084 // Long Immediate: 16-bit
 2085 operand immL16() %{
 2086   predicate(n-&gt;get_long() &gt;= 0 &amp;&amp; n-&gt;get_long() &lt; (1&lt;&lt;16)  &amp;&amp; VM_Version::supports_movw());
 2087   match(ConL);
 2088   op_cost(0);
 2089 
 2090   format %{ %}
 2091   interface(CONST_INTER);
 2092 %}
 2093 
 2094 // Long Immediate: low 32-bit mask
 2095 operand immL_32bits() %{
 2096   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 2097   match(ConL);
 2098   op_cost(0);
 2099 
 2100   format %{ %}
 2101   interface(CONST_INTER);
 2102 %}
 2103 
 2104 // Double Immediate
 2105 operand immD() %{
 2106   match(ConD);
 2107 
 2108   op_cost(40);
 2109   format %{ %}
 2110   interface(CONST_INTER);
 2111 %}
 2112 
 2113 // Double Immediate: +0.0d.
 2114 operand immD0() %{
 2115   predicate(jlong_cast(n-&gt;getd()) == 0);
 2116 
 2117   match(ConD);
 2118   op_cost(0);
 2119   format %{ %}
 2120   interface(CONST_INTER);
 2121 %}
 2122 
 2123 operand imm8D() %{
 2124   predicate(Assembler::double_num(n-&gt;getd()).can_be_imm8());
 2125   match(ConD);
 2126 
 2127   op_cost(0);
 2128   format %{ %}
 2129   interface(CONST_INTER);
 2130 %}
 2131 
 2132 // Float Immediate
 2133 operand immF() %{
 2134   match(ConF);
 2135 
 2136   op_cost(20);
 2137   format %{ %}
 2138   interface(CONST_INTER);
 2139 %}
 2140 
 2141 // Float Immediate: +0.0f
 2142 operand immF0() %{
 2143   predicate(jint_cast(n-&gt;getf()) == 0);
 2144   match(ConF);
 2145 
 2146   op_cost(0);
 2147   format %{ %}
 2148   interface(CONST_INTER);
 2149 %}
 2150 
 2151 // Float Immediate: encoded as 8 bits
 2152 operand imm8F() %{
 2153   predicate(Assembler::float_num(n-&gt;getf()).can_be_imm8());
 2154   match(ConF);
 2155 
 2156   op_cost(0);
 2157   format %{ %}
 2158   interface(CONST_INTER);
 2159 %}
 2160 
 2161 // Integer Register Operands
 2162 // Integer Register
 2163 operand iRegI() %{
 2164   constraint(ALLOC_IN_RC(int_reg));
 2165   match(RegI);
 2166   match(R0RegI);
 2167   match(R1RegI);
 2168   match(R2RegI);
 2169   match(R3RegI);
 2170   match(R12RegI);
 2171 
 2172   format %{ %}
 2173   interface(REG_INTER);
 2174 %}
 2175 
 2176 // Pointer Register
 2177 operand iRegP() %{
 2178   constraint(ALLOC_IN_RC(ptr_reg));
 2179   match(RegP);
 2180   match(R0RegP);
 2181   match(R1RegP);
 2182   match(R2RegP);
 2183   match(RExceptionRegP);
 2184   match(R8RegP);
 2185   match(R9RegP);
 2186   match(RthreadRegP); // FIXME: move to sp_ptr_RegP?
 2187   match(R12RegP);
 2188   match(LRRegP);
 2189 
 2190   match(sp_ptr_RegP);
 2191   match(store_ptr_RegP);
 2192 
 2193   format %{ %}
 2194   interface(REG_INTER);
 2195 %}
 2196 
 2197 // GPRs + Rthread + SP
 2198 operand sp_ptr_RegP() %{
 2199   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2200   match(RegP);
 2201   match(iRegP);
 2202   match(SPRegP); // FIXME: check cost
 2203 
 2204   format %{ %}
 2205   interface(REG_INTER);
 2206 %}
 2207 
 2208 
 2209 operand R0RegP() %{
 2210   constraint(ALLOC_IN_RC(R0_regP));
 2211   match(iRegP);
 2212 
 2213   format %{ %}
 2214   interface(REG_INTER);
 2215 %}
 2216 
 2217 operand R1RegP() %{
 2218   constraint(ALLOC_IN_RC(R1_regP));
 2219   match(iRegP);
 2220 
 2221   format %{ %}
 2222   interface(REG_INTER);
 2223 %}
 2224 
 2225 operand R8RegP() %{
 2226   constraint(ALLOC_IN_RC(R8_regP));
 2227   match(iRegP);
 2228 
 2229   format %{ %}
 2230   interface(REG_INTER);
 2231 %}
 2232 
 2233 operand R9RegP() %{
 2234   constraint(ALLOC_IN_RC(R9_regP));
 2235   match(iRegP);
 2236 
 2237   format %{ %}
 2238   interface(REG_INTER);
 2239 %}
 2240 
 2241 operand R12RegP() %{
 2242   constraint(ALLOC_IN_RC(R12_regP));
 2243   match(iRegP);
 2244 
 2245   format %{ %}
 2246   interface(REG_INTER);
 2247 %}
 2248 
 2249 operand R2RegP() %{
 2250   constraint(ALLOC_IN_RC(R2_regP));
 2251   match(iRegP);
 2252 
 2253   format %{ %}
 2254   interface(REG_INTER);
 2255 %}
 2256 
 2257 operand RExceptionRegP() %{
 2258   constraint(ALLOC_IN_RC(Rexception_regP));
 2259   match(iRegP);
 2260 
 2261   format %{ %}
 2262   interface(REG_INTER);
 2263 %}
 2264 
 2265 operand RthreadRegP() %{
 2266   constraint(ALLOC_IN_RC(Rthread_regP));
 2267   match(iRegP);
 2268 
 2269   format %{ %}
 2270   interface(REG_INTER);
 2271 %}
 2272 
 2273 operand IPRegP() %{
 2274   constraint(ALLOC_IN_RC(IP_regP));
 2275   match(iRegP);
 2276 
 2277   format %{ %}
 2278   interface(REG_INTER);
 2279 %}
 2280 
 2281 operand SPRegP() %{
 2282   constraint(ALLOC_IN_RC(SP_regP));
 2283   match(iRegP);
 2284 
 2285   format %{ %}
 2286   interface(REG_INTER);
 2287 %}
 2288 
 2289 operand LRRegP() %{
 2290   constraint(ALLOC_IN_RC(LR_regP));
 2291   match(iRegP);
 2292 
 2293   format %{ %}
 2294   interface(REG_INTER);
 2295 %}
 2296 
 2297 operand R0RegI() %{
 2298   constraint(ALLOC_IN_RC(R0_regI));
 2299   match(iRegI);
 2300 
 2301   format %{ %}
 2302   interface(REG_INTER);
 2303 %}
 2304 
 2305 operand R1RegI() %{
 2306   constraint(ALLOC_IN_RC(R1_regI));
 2307   match(iRegI);
 2308 
 2309   format %{ %}
 2310   interface(REG_INTER);
 2311 %}
 2312 
 2313 operand R2RegI() %{
 2314   constraint(ALLOC_IN_RC(R2_regI));
 2315   match(iRegI);
 2316 
 2317   format %{ %}
 2318   interface(REG_INTER);
 2319 %}
 2320 
 2321 operand R3RegI() %{
 2322   constraint(ALLOC_IN_RC(R3_regI));
 2323   match(iRegI);
 2324 
 2325   format %{ %}
 2326   interface(REG_INTER);
 2327 %}
 2328 
 2329 operand R12RegI() %{
 2330   constraint(ALLOC_IN_RC(R12_regI));
 2331   match(iRegI);
 2332 
 2333   format %{ %}
 2334   interface(REG_INTER);
 2335 %}
 2336 
 2337 // Long Register
 2338 operand iRegL() %{
 2339   constraint(ALLOC_IN_RC(long_reg));
 2340   match(RegL);
 2341   match(R0R1RegL);
 2342   match(R2R3RegL);
 2343 //match(iRegLex);
 2344 
 2345   format %{ %}
 2346   interface(REG_INTER);
 2347 %}
 2348 
 2349 operand iRegLd() %{
 2350   constraint(ALLOC_IN_RC(long_reg_align));
 2351   match(iRegL); // FIXME: allows unaligned R11/R12?
 2352 
 2353   format %{ %}
 2354   interface(REG_INTER);
 2355 %}
 2356 
 2357 // first long arg, or return value
 2358 operand R0R1RegL() %{
 2359   constraint(ALLOC_IN_RC(R0R1_regL));
 2360   match(iRegL);
 2361 
 2362   format %{ %}
 2363   interface(REG_INTER);
 2364 %}
 2365 
 2366 operand R2R3RegL() %{
 2367   constraint(ALLOC_IN_RC(R2R3_regL));
 2368   match(iRegL);
 2369 
 2370   format %{ %}
 2371   interface(REG_INTER);
 2372 %}
 2373 
 2374 // Condition Code Flag Register
 2375 operand flagsReg() %{
 2376   constraint(ALLOC_IN_RC(int_flags));
 2377   match(RegFlags);
 2378 
 2379   format %{ &quot;apsr&quot; %}
 2380   interface(REG_INTER);
 2381 %}
 2382 
 2383 // Result of compare to 0 (TST)
 2384 operand flagsReg_EQNELTGE() %{
 2385   constraint(ALLOC_IN_RC(int_flags));
 2386   match(RegFlags);
 2387 
 2388   format %{ &quot;apsr_EQNELTGE&quot; %}
 2389   interface(REG_INTER);
 2390 %}
 2391 
 2392 // Condition Code Register, unsigned comparisons.
 2393 operand flagsRegU() %{
 2394   constraint(ALLOC_IN_RC(int_flags));
 2395   match(RegFlags);
 2396 #ifdef TODO
 2397   match(RegFlagsP);
 2398 #endif
 2399 
 2400   format %{ &quot;apsr_U&quot; %}
 2401   interface(REG_INTER);
 2402 %}
 2403 
 2404 // Condition Code Register, pointer comparisons.
 2405 operand flagsRegP() %{
 2406   constraint(ALLOC_IN_RC(int_flags));
 2407   match(RegFlags);
 2408 
 2409   format %{ &quot;apsr_P&quot; %}
 2410   interface(REG_INTER);
 2411 %}
 2412 
 2413 // Condition Code Register, long comparisons.
 2414 operand flagsRegL_LTGE() %{
 2415   constraint(ALLOC_IN_RC(int_flags));
 2416   match(RegFlags);
 2417 
 2418   format %{ &quot;apsr_L_LTGE&quot; %}
 2419   interface(REG_INTER);
 2420 %}
 2421 
 2422 operand flagsRegL_EQNE() %{
 2423   constraint(ALLOC_IN_RC(int_flags));
 2424   match(RegFlags);
 2425 
 2426   format %{ &quot;apsr_L_EQNE&quot; %}
 2427   interface(REG_INTER);
 2428 %}
 2429 
 2430 operand flagsRegL_LEGT() %{
 2431   constraint(ALLOC_IN_RC(int_flags));
 2432   match(RegFlags);
 2433 
 2434   format %{ &quot;apsr_L_LEGT&quot; %}
 2435   interface(REG_INTER);
 2436 %}
 2437 
 2438 operand flagsRegUL_LTGE() %{
 2439   constraint(ALLOC_IN_RC(int_flags));
 2440   match(RegFlags);
 2441 
 2442   format %{ &quot;apsr_UL_LTGE&quot; %}
 2443   interface(REG_INTER);
 2444 %}
 2445 
 2446 operand flagsRegUL_EQNE() %{
 2447   constraint(ALLOC_IN_RC(int_flags));
 2448   match(RegFlags);
 2449 
 2450   format %{ &quot;apsr_UL_EQNE&quot; %}
 2451   interface(REG_INTER);
 2452 %}
 2453 
 2454 operand flagsRegUL_LEGT() %{
 2455   constraint(ALLOC_IN_RC(int_flags));
 2456   match(RegFlags);
 2457 
 2458   format %{ &quot;apsr_UL_LEGT&quot; %}
 2459   interface(REG_INTER);
 2460 %}
 2461 
 2462 // Condition Code Register, floating comparisons, unordered same as &quot;less&quot;.
 2463 operand flagsRegF() %{
 2464   constraint(ALLOC_IN_RC(float_flags));
 2465   match(RegFlags);
 2466 
 2467   format %{ &quot;fpscr_F&quot; %}
 2468   interface(REG_INTER);
 2469 %}
 2470 
 2471 // Vectors
 2472 operand vecD() %{
 2473   constraint(ALLOC_IN_RC(actual_dflt_reg));
 2474   match(VecD);
 2475 
 2476   format %{ %}
 2477   interface(REG_INTER);
 2478 %}
 2479 
 2480 operand vecX() %{
 2481   constraint(ALLOC_IN_RC(vectorx_reg));
 2482   match(VecX);
 2483 
 2484   format %{ %}
 2485   interface(REG_INTER);
 2486 %}
 2487 
 2488 operand regD() %{
 2489   constraint(ALLOC_IN_RC(actual_dflt_reg));
 2490   match(RegD);
 2491   match(regD_low);
 2492 
 2493   format %{ %}
 2494   interface(REG_INTER);
 2495 %}
 2496 
 2497 operand regF() %{
 2498   constraint(ALLOC_IN_RC(sflt_reg));
 2499   match(RegF);
 2500 
 2501   format %{ %}
 2502   interface(REG_INTER);
 2503 %}
 2504 
 2505 operand regD_low() %{
 2506   constraint(ALLOC_IN_RC(dflt_low_reg));
 2507   match(RegD);
 2508 
 2509   format %{ %}
 2510   interface(REG_INTER);
 2511 %}
 2512 
 2513 // Special Registers
 2514 
 2515 // Method Register
 2516 operand inline_cache_regP(iRegP reg) %{
 2517   constraint(ALLOC_IN_RC(Ricklass_regP));
 2518   match(reg);
 2519   format %{ %}
 2520   interface(REG_INTER);
 2521 %}
 2522 
 2523 operand interpreter_method_oop_regP(iRegP reg) %{
 2524   constraint(ALLOC_IN_RC(Rmethod_regP));
 2525   match(reg);
 2526   format %{ %}
 2527   interface(REG_INTER);
 2528 %}
 2529 
 2530 
 2531 //----------Complex Operands---------------------------------------------------
 2532 // Indirect Memory Reference
 2533 operand indirect(sp_ptr_RegP reg) %{
 2534   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2535   match(reg);
 2536 
 2537   op_cost(100);
 2538   format %{ &quot;[$reg]&quot; %}
 2539   interface(MEMORY_INTER) %{
 2540     base($reg);
 2541     index(0xf); // PC =&gt; no index
 2542     scale(0x0);
 2543     disp(0x0);
 2544   %}
 2545 %}
 2546 
 2547 
 2548 // Indirect with Offset in ]-4096, 4096[
 2549 operand indOffset12(sp_ptr_RegP reg, immI12 offset) %{
 2550   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2551   match(AddP reg offset);
 2552 
 2553   op_cost(100);
 2554   format %{ &quot;[$reg + $offset]&quot; %}
 2555   interface(MEMORY_INTER) %{
 2556     base($reg);
 2557     index(0xf); // PC =&gt; no index
 2558     scale(0x0);
 2559     disp($offset);
 2560   %}
 2561 %}
 2562 
 2563 // Indirect with offset for float load/store
 2564 operand indOffsetFP(sp_ptr_RegP reg, immIFP offset) %{
 2565   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2566   match(AddP reg offset);
 2567 
 2568   op_cost(100);
 2569   format %{ &quot;[$reg + $offset]&quot; %}
 2570   interface(MEMORY_INTER) %{
 2571     base($reg);
 2572     index(0xf); // PC =&gt; no index
 2573     scale(0x0);
 2574     disp($offset);
 2575   %}
 2576 %}
 2577 
 2578 // Indirect with Offset for half and double words
 2579 operand indOffsetHD(sp_ptr_RegP reg, immIHD offset) %{
 2580   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2581   match(AddP reg offset);
 2582 
 2583   op_cost(100);
 2584   format %{ &quot;[$reg + $offset]&quot; %}
 2585   interface(MEMORY_INTER) %{
 2586     base($reg);
 2587     index(0xf); // PC =&gt; no index
 2588     scale(0x0);
 2589     disp($offset);
 2590   %}
 2591 %}
 2592 
 2593 // Indirect with Offset and Offset+4 in ]-1024, 1024[
 2594 operand indOffsetFPx2(sp_ptr_RegP reg, immX10x2 offset) %{
 2595   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2596   match(AddP reg offset);
 2597 
 2598   op_cost(100);
 2599   format %{ &quot;[$reg + $offset]&quot; %}
 2600   interface(MEMORY_INTER) %{
 2601     base($reg);
 2602     index(0xf); // PC =&gt; no index
 2603     scale(0x0);
 2604     disp($offset);
 2605   %}
 2606 %}
 2607 
 2608 // Indirect with Offset and Offset+4 in ]-4096, 4096[
 2609 operand indOffset12x2(sp_ptr_RegP reg, immI12x2 offset) %{
 2610   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2611   match(AddP reg offset);
 2612 
 2613   op_cost(100);
 2614   format %{ &quot;[$reg + $offset]&quot; %}
 2615   interface(MEMORY_INTER) %{
 2616     base($reg);
 2617     index(0xf); // PC =&gt; no index
 2618     scale(0x0);
 2619     disp($offset);
 2620   %}
 2621 %}
 2622 
 2623 // Indirect with Register Index
 2624 operand indIndex(iRegP addr, iRegX index) %{
 2625   constraint(ALLOC_IN_RC(ptr_reg));
 2626   match(AddP addr index);
 2627 
 2628   op_cost(100);
 2629   format %{ &quot;[$addr + $index]&quot; %}
 2630   interface(MEMORY_INTER) %{
 2631     base($addr);
 2632     index($index);
 2633     scale(0x0);
 2634     disp(0x0);
 2635   %}
 2636 %}
 2637 
 2638 // Indirect Memory Times Scale Plus Index Register
 2639 operand indIndexScale(iRegP addr, iRegX index, immU5 scale) %{
 2640   constraint(ALLOC_IN_RC(ptr_reg));
 2641   match(AddP addr (LShiftX index scale));
 2642 
 2643   op_cost(100);
 2644   format %{&quot;[$addr + $index &lt;&lt; $scale]&quot; %}
 2645   interface(MEMORY_INTER) %{
 2646     base($addr);
 2647     index($index);
 2648     scale($scale);
 2649     disp(0x0);
 2650   %}
 2651 %}
 2652 
 2653 // Operands for expressing Control Flow
 2654 // NOTE:  Label is a predefined operand which should not be redefined in
 2655 //        the AD file.  It is generically handled within the ADLC.
 2656 
 2657 //----------Conditional Branch Operands----------------------------------------
 2658 // Comparison Op  - This is the operation of the comparison, and is limited to
 2659 //                  the following set of codes:
 2660 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 2661 //
 2662 // Other attributes of the comparison, such as unsignedness, are specified
 2663 // by the comparison instruction that sets a condition code flags register.
 2664 // That result is represented by a flags operand whose subtype is appropriate
 2665 // to the unsignedness (etc.) of the comparison.
 2666 //
 2667 // Later, the instruction which matches both the Comparison Op (a Bool) and
 2668 // the flags (produced by the Cmp) specifies the coding of the comparison op
 2669 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 2670 
 2671 operand cmpOp() %{
 2672   match(Bool);
 2673 
 2674   format %{ &quot;&quot; %}
 2675   interface(COND_INTER) %{
 2676     equal(0x0);
 2677     not_equal(0x1);
 2678     less(0xb);
 2679     greater_equal(0xa);
 2680     less_equal(0xd);
 2681     greater(0xc);
 2682     overflow(0x0); // unsupported/unimplemented
 2683     no_overflow(0x0); // unsupported/unimplemented
 2684   %}
 2685 %}
 2686 
 2687 // integer comparison with 0, signed
 2688 operand cmpOp0() %{
 2689   match(Bool);
 2690 
 2691   format %{ &quot;&quot; %}
 2692   interface(COND_INTER) %{
 2693     equal(0x0);
 2694     not_equal(0x1);
 2695     less(0x4);
 2696     greater_equal(0x5);
 2697     less_equal(0xd); // unsupported
 2698     greater(0xc); // unsupported
 2699     overflow(0x0); // unsupported/unimplemented
 2700     no_overflow(0x0); // unsupported/unimplemented
 2701   %}
 2702 %}
 2703 
 2704 // Comparison Op, unsigned
 2705 operand cmpOpU() %{
 2706   match(Bool);
 2707 
 2708   format %{ &quot;u&quot; %}
 2709   interface(COND_INTER) %{
 2710     equal(0x0);
 2711     not_equal(0x1);
 2712     less(0x3);
 2713     greater_equal(0x2);
 2714     less_equal(0x9);
 2715     greater(0x8);
 2716     overflow(0x0); // unsupported/unimplemented
 2717     no_overflow(0x0); // unsupported/unimplemented
 2718   %}
 2719 %}
 2720 
 2721 // Comparison Op, pointer (same as unsigned)
 2722 operand cmpOpP() %{
 2723   match(Bool);
 2724 
 2725   format %{ &quot;p&quot; %}
 2726   interface(COND_INTER) %{
 2727     equal(0x0);
 2728     not_equal(0x1);
 2729     less(0x3);
 2730     greater_equal(0x2);
 2731     less_equal(0x9);
 2732     greater(0x8);
 2733     overflow(0x0); // unsupported/unimplemented
 2734     no_overflow(0x0); // unsupported/unimplemented
 2735   %}
 2736 %}
 2737 
 2738 operand cmpOpL() %{
 2739   match(Bool);
 2740 
 2741   format %{ &quot;L&quot; %}
 2742   interface(COND_INTER) %{
 2743     equal(0x0);
 2744     not_equal(0x1);
 2745     less(0xb);
 2746     greater_equal(0xa);
 2747     less_equal(0xd);
 2748     greater(0xc);
 2749     overflow(0x0); // unsupported/unimplemented
 2750     no_overflow(0x0); // unsupported/unimplemented
 2751   %}
 2752 %}
 2753 
 2754 operand cmpOpL_commute() %{
 2755   match(Bool);
 2756 
 2757   format %{ &quot;L&quot; %}
 2758   interface(COND_INTER) %{
 2759     equal(0x0);
 2760     not_equal(0x1);
 2761     less(0xc);
 2762     greater_equal(0xd);
 2763     less_equal(0xa);
 2764     greater(0xb);
 2765     overflow(0x0); // unsupported/unimplemented
 2766     no_overflow(0x0); // unsupported/unimplemented
 2767   %}
 2768 %}
 2769 
 2770 operand cmpOpUL() %{
 2771   match(Bool);
 2772 
 2773   format %{ &quot;UL&quot; %}
 2774   interface(COND_INTER) %{
 2775     equal(0x0);
 2776     not_equal(0x1);
 2777     less(0x3);
 2778     greater_equal(0x2);
 2779     less_equal(0x9);
 2780     greater(0x8);
 2781     overflow(0x0); // unsupported/unimplemented
 2782     no_overflow(0x0); // unsupported/unimplemented
 2783   %}
 2784 %}
 2785 
 2786 operand cmpOpUL_commute() %{
 2787   match(Bool);
 2788 
 2789   format %{ &quot;UL&quot; %}
 2790   interface(COND_INTER) %{
 2791     equal(0x0);
 2792     not_equal(0x1);
 2793     less(0x8);
 2794     greater_equal(0x9);
 2795     less_equal(0x2);
 2796     greater(0x3);
 2797     overflow(0x0); // unsupported/unimplemented
 2798     no_overflow(0x0); // unsupported/unimplemented
 2799   %}
 2800 %}
 2801 
 2802 
 2803 //----------OPERAND CLASSES----------------------------------------------------
 2804 // Operand Classes are groups of operands that are used to simplify
 2805 // instruction definitions by not requiring the AD writer to specify separate
 2806 // instructions for every form of operand when the instruction accepts
 2807 // multiple operand types with the same basic encoding and format.  The classic
 2808 // case of this is memory operands.
 2809 
 2810 opclass memoryI ( indirect, indOffset12, indIndex, indIndexScale );
 2811 opclass memoryP ( indirect, indOffset12, indIndex, indIndexScale );
 2812 opclass memoryF ( indirect, indOffsetFP );
 2813 opclass memoryF2 ( indirect, indOffsetFPx2 );
 2814 opclass memoryD ( indirect, indOffsetFP );
 2815 opclass memoryfp( indirect, indOffsetFP );
 2816 opclass memoryB ( indirect, indIndex, indOffsetHD );
 2817 opclass memoryS ( indirect, indIndex, indOffsetHD );
 2818 opclass memoryL ( indirect, indIndex, indOffsetHD );
 2819 
 2820 opclass memoryScaledI(indIndexScale);
 2821 opclass memoryScaledP(indIndexScale);
 2822 
 2823 // when ldrex/strex is used:
 2824 opclass memoryex ( indirect );
 2825 opclass indIndexMemory( indIndex );
 2826 opclass memorylong ( indirect, indOffset12x2 );
 2827 opclass memoryvld ( indirect /* , write back mode not implemented */ );
 2828 
 2829 //----------PIPELINE-----------------------------------------------------------
 2830 pipeline %{
 2831 
 2832 //----------ATTRIBUTES---------------------------------------------------------
 2833 attributes %{
 2834   fixed_size_instructions;           // Fixed size instructions
 2835   max_instructions_per_bundle = 4;   // Up to 4 instructions per bundle
 2836   instruction_unit_size = 4;         // An instruction is 4 bytes long
 2837   instruction_fetch_unit_size = 16;  // The processor fetches one line
 2838   instruction_fetch_units = 1;       // of 16 bytes
 2839 
 2840   // List of nop instructions
 2841   nops( Nop_A0, Nop_A1, Nop_MS, Nop_FA, Nop_BR );
 2842 %}
 2843 
 2844 //----------RESOURCES----------------------------------------------------------
 2845 // Resources are the functional units available to the machine
 2846 resources(A0, A1, MS, BR, FA, FM, IDIV, FDIV, IALU = A0 | A1);
 2847 
 2848 //----------PIPELINE DESCRIPTION-----------------------------------------------
 2849 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 2850 
 2851 pipe_desc(A, P, F, B, I, J, S, R, E, C, M, W, X, T, D);
 2852 
 2853 //----------PIPELINE CLASSES---------------------------------------------------
 2854 // Pipeline Classes describe the stages in which input and output are
 2855 // referenced by the hardware pipeline.
 2856 
 2857 // Integer ALU reg-reg operation
 2858 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 2859     single_instruction;
 2860     dst   : E(write);
 2861     src1  : R(read);
 2862     src2  : R(read);
 2863     IALU  : R;
 2864 %}
 2865 
 2866 // Integer ALU reg-reg long operation
 2867 pipe_class ialu_reg_reg_2(iRegL dst, iRegL src1, iRegL src2) %{
 2868     instruction_count(2);
 2869     dst   : E(write);
 2870     src1  : R(read);
 2871     src2  : R(read);
 2872     IALU  : R;
 2873     IALU  : R;
 2874 %}
 2875 
 2876 // Integer ALU reg-reg long dependent operation
 2877 pipe_class ialu_reg_reg_2_dep(iRegL dst, iRegL src1, iRegL src2, flagsReg cr) %{
 2878     instruction_count(1); multiple_bundles;
 2879     dst   : E(write);
 2880     src1  : R(read);
 2881     src2  : R(read);
 2882     cr    : E(write);
 2883     IALU  : R(2);
 2884 %}
 2885 
 2886 // Integer ALU reg-imm operaion
 2887 pipe_class ialu_reg_imm(iRegI dst, iRegI src1) %{
 2888     single_instruction;
 2889     dst   : E(write);
 2890     src1  : R(read);
 2891     IALU  : R;
 2892 %}
 2893 
 2894 // Integer ALU reg-reg operation with condition code
 2895 pipe_class ialu_cc_reg_reg(iRegI dst, iRegI src1, iRegI src2, flagsReg cr) %{
 2896     single_instruction;
 2897     dst   : E(write);
 2898     cr    : E(write);
 2899     src1  : R(read);
 2900     src2  : R(read);
 2901     IALU  : R;
 2902 %}
 2903 
 2904 // Integer ALU zero-reg operation
 2905 pipe_class ialu_zero_reg(iRegI dst, immI0 zero, iRegI src2) %{
 2906     single_instruction;
 2907     dst   : E(write);
 2908     src2  : R(read);
 2909     IALU  : R;
 2910 %}
 2911 
 2912 // Integer ALU zero-reg operation with condition code only
 2913 pipe_class ialu_cconly_zero_reg(flagsReg cr, iRegI src) %{
 2914     single_instruction;
 2915     cr    : E(write);
 2916     src   : R(read);
 2917     IALU  : R;
 2918 %}
 2919 
 2920 // Integer ALU reg-reg operation with condition code only
 2921 pipe_class ialu_cconly_reg_reg(flagsReg cr, iRegI src1, iRegI src2) %{
 2922     single_instruction;
 2923     cr    : E(write);
 2924     src1  : R(read);
 2925     src2  : R(read);
 2926     IALU  : R;
 2927 %}
 2928 
 2929 // Integer ALU reg-imm operation with condition code only
 2930 pipe_class ialu_cconly_reg_imm(flagsReg cr, iRegI src1) %{
 2931     single_instruction;
 2932     cr    : E(write);
 2933     src1  : R(read);
 2934     IALU  : R;
 2935 %}
 2936 
 2937 // Integer ALU reg-reg-zero operation with condition code only
 2938 pipe_class ialu_cconly_reg_reg_zero(flagsReg cr, iRegI src1, iRegI src2, immI0 zero) %{
 2939     single_instruction;
 2940     cr    : E(write);
 2941     src1  : R(read);
 2942     src2  : R(read);
 2943     IALU  : R;
 2944 %}
 2945 
 2946 // Integer ALU reg-imm-zero operation with condition code only
 2947 pipe_class ialu_cconly_reg_imm_zero(flagsReg cr, iRegI src1, immI0 zero) %{
 2948     single_instruction;
 2949     cr    : E(write);
 2950     src1  : R(read);
 2951     IALU  : R;
 2952 %}
 2953 
 2954 // Integer ALU reg-reg operation with condition code, src1 modified
 2955 pipe_class ialu_cc_rwreg_reg(flagsReg cr, iRegI src1, iRegI src2) %{
 2956     single_instruction;
 2957     cr    : E(write);
 2958     src1  : E(write);
 2959     src1  : R(read);
 2960     src2  : R(read);
 2961     IALU  : R;
 2962 %}
 2963 
 2964 pipe_class cmpL_reg(iRegI dst, iRegL src1, iRegL src2, flagsReg cr ) %{
 2965     multiple_bundles;
 2966     dst   : E(write)+4;
 2967     cr    : E(write);
 2968     src1  : R(read);
 2969     src2  : R(read);
 2970     IALU  : R(3);
 2971     BR    : R(2);
 2972 %}
 2973 
 2974 // Integer ALU operation
 2975 pipe_class ialu_none(iRegI dst) %{
 2976     single_instruction;
 2977     dst   : E(write);
 2978     IALU  : R;
 2979 %}
 2980 
 2981 // Integer ALU reg operation
 2982 pipe_class ialu_reg(iRegI dst, iRegI src) %{
 2983     single_instruction; may_have_no_code;
 2984     dst   : E(write);
 2985     src   : R(read);
 2986     IALU  : R;
 2987 %}
 2988 
 2989 // Integer ALU reg conditional operation
 2990 // This instruction has a 1 cycle stall, and cannot execute
 2991 // in the same cycle as the instruction setting the condition
 2992 // code. We kludge this by pretending to read the condition code
 2993 // 1 cycle earlier, and by marking the functional units as busy
 2994 // for 2 cycles with the result available 1 cycle later than
 2995 // is really the case.
 2996 pipe_class ialu_reg_flags( iRegI op2_out, iRegI op2_in, iRegI op1, flagsReg cr ) %{
 2997     single_instruction;
 2998     op2_out : C(write);
 2999     op1     : R(read);
 3000     cr      : R(read);       // This is really E, with a 1 cycle stall
 3001     BR      : R(2);
 3002     MS      : R(2);
 3003 %}
 3004 
 3005 // Integer ALU reg operation
 3006 pipe_class ialu_move_reg_L_to_I(iRegI dst, iRegL src) %{
 3007     single_instruction; may_have_no_code;
 3008     dst   : E(write);
 3009     src   : R(read);
 3010     IALU  : R;
 3011 %}
 3012 pipe_class ialu_move_reg_I_to_L(iRegL dst, iRegI src) %{
 3013     single_instruction; may_have_no_code;
 3014     dst   : E(write);
 3015     src   : R(read);
 3016     IALU  : R;
 3017 %}
 3018 
 3019 // Two integer ALU reg operations
 3020 pipe_class ialu_reg_2(iRegL dst, iRegL src) %{
 3021     instruction_count(2);
 3022     dst   : E(write);
 3023     src   : R(read);
 3024     A0    : R;
 3025     A1    : R;
 3026 %}
 3027 
 3028 // Two integer ALU reg operations
 3029 pipe_class ialu_move_reg_L_to_L(iRegL dst, iRegL src) %{
 3030     instruction_count(2); may_have_no_code;
 3031     dst   : E(write);
 3032     src   : R(read);
 3033     A0    : R;
 3034     A1    : R;
 3035 %}
 3036 
 3037 // Integer ALU imm operation
 3038 pipe_class ialu_imm(iRegI dst) %{
 3039     single_instruction;
 3040     dst   : E(write);
 3041     IALU  : R;
 3042 %}
 3043 
 3044 pipe_class ialu_imm_n(iRegI dst) %{
 3045     single_instruction;
 3046     dst   : E(write);
 3047     IALU  : R;
 3048 %}
 3049 
 3050 // Integer ALU reg-reg with carry operation
 3051 pipe_class ialu_reg_reg_cy(iRegI dst, iRegI src1, iRegI src2, iRegI cy) %{
 3052     single_instruction;
 3053     dst   : E(write);
 3054     src1  : R(read);
 3055     src2  : R(read);
 3056     IALU  : R;
 3057 %}
 3058 
 3059 // Integer ALU cc operation
 3060 pipe_class ialu_cc(iRegI dst, flagsReg cc) %{
 3061     single_instruction;
 3062     dst   : E(write);
 3063     cc    : R(read);
 3064     IALU  : R;
 3065 %}
 3066 
 3067 // Integer ALU cc / second IALU operation
 3068 pipe_class ialu_reg_ialu( iRegI dst, iRegI src ) %{
 3069     instruction_count(1); multiple_bundles;
 3070     dst   : E(write)+1;
 3071     src   : R(read);
 3072     IALU  : R;
 3073 %}
 3074 
 3075 // Integer ALU cc / second IALU operation
 3076 pipe_class ialu_reg_reg_ialu( iRegI dst, iRegI p, iRegI q ) %{
 3077     instruction_count(1); multiple_bundles;
 3078     dst   : E(write)+1;
 3079     p     : R(read);
 3080     q     : R(read);
 3081     IALU  : R;
 3082 %}
 3083 
 3084 // Integer ALU hi-lo-reg operation
 3085 pipe_class ialu_hi_lo_reg(iRegI dst, immI src) %{
 3086     instruction_count(1); multiple_bundles;
 3087     dst   : E(write)+1;
 3088     IALU  : R(2);
 3089 %}
 3090 
 3091 // Long Constant
 3092 pipe_class loadConL( iRegL dst, immL src ) %{
 3093     instruction_count(2); multiple_bundles;
 3094     dst   : E(write)+1;
 3095     IALU  : R(2);
 3096     IALU  : R(2);
 3097 %}
 3098 
 3099 // Pointer Constant
 3100 pipe_class loadConP( iRegP dst, immP src ) %{
 3101     instruction_count(0); multiple_bundles;
 3102     fixed_latency(6);
 3103 %}
 3104 
 3105 // Polling Address
 3106 pipe_class loadConP_poll( iRegP dst, immP_poll src ) %{
 3107     dst   : E(write);
 3108     IALU  : R;
 3109 %}
 3110 
 3111 // Long Constant small
 3112 pipe_class loadConLlo( iRegL dst, immL src ) %{
 3113     instruction_count(2);
 3114     dst   : E(write);
 3115     IALU  : R;
 3116     IALU  : R;
 3117 %}
 3118 
 3119 // [PHH] This is wrong for 64-bit.  See LdImmF/D.
 3120 pipe_class loadConFD(regF dst, immF src, iRegP tmp) %{
 3121     instruction_count(1); multiple_bundles;
 3122     src   : R(read);
 3123     dst   : M(write)+1;
 3124     IALU  : R;
 3125     MS    : E;
 3126 %}
 3127 
 3128 // Integer ALU nop operation
 3129 pipe_class ialu_nop() %{
 3130     single_instruction;
 3131     IALU  : R;
 3132 %}
 3133 
 3134 // Integer ALU nop operation
 3135 pipe_class ialu_nop_A0() %{
 3136     single_instruction;
 3137     A0    : R;
 3138 %}
 3139 
 3140 // Integer ALU nop operation
 3141 pipe_class ialu_nop_A1() %{
 3142     single_instruction;
 3143     A1    : R;
 3144 %}
 3145 
 3146 // Integer Multiply reg-reg operation
 3147 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 3148     single_instruction;
 3149     dst   : E(write);
 3150     src1  : R(read);
 3151     src2  : R(read);
 3152     MS    : R(5);
 3153 %}
 3154 
 3155 pipe_class mulL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 3156     single_instruction;
 3157     dst   : E(write)+4;
 3158     src1  : R(read);
 3159     src2  : R(read);
 3160     MS    : R(6);
 3161 %}
 3162 
 3163 // Integer Divide reg-reg
 3164 pipe_class sdiv_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI temp, flagsReg cr) %{
 3165     instruction_count(1); multiple_bundles;
 3166     dst   : E(write);
 3167     temp  : E(write);
 3168     src1  : R(read);
 3169     src2  : R(read);
 3170     temp  : R(read);
 3171     MS    : R(38);
 3172 %}
 3173 
 3174 // Long Divide
 3175 pipe_class divL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 3176     dst  : E(write)+71;
 3177     src1 : R(read);
 3178     src2 : R(read)+1;
 3179     MS   : R(70);
 3180 %}
 3181 
 3182 // Floating Point Add Float
 3183 pipe_class faddF_reg_reg(regF dst, regF src1, regF src2) %{
 3184     single_instruction;
 3185     dst   : X(write);
 3186     src1  : E(read);
 3187     src2  : E(read);
 3188     FA    : R;
 3189 %}
 3190 
 3191 // Floating Point Add Double
 3192 pipe_class faddD_reg_reg(regD dst, regD src1, regD src2) %{
 3193     single_instruction;
 3194     dst   : X(write);
 3195     src1  : E(read);
 3196     src2  : E(read);
 3197     FA    : R;
 3198 %}
 3199 
 3200 // Floating Point Conditional Move based on integer flags
 3201 pipe_class int_conditional_float_move (cmpOp cmp, flagsReg cr, regF dst, regF src) %{
 3202     single_instruction;
 3203     dst   : X(write);
 3204     src   : E(read);
 3205     cr    : R(read);
 3206     FA    : R(2);
 3207     BR    : R(2);
 3208 %}
 3209 
 3210 // Floating Point Conditional Move based on integer flags
 3211 pipe_class int_conditional_double_move (cmpOp cmp, flagsReg cr, regD dst, regD src) %{
 3212     single_instruction;
 3213     dst   : X(write);
 3214     src   : E(read);
 3215     cr    : R(read);
 3216     FA    : R(2);
 3217     BR    : R(2);
 3218 %}
 3219 
 3220 // Floating Point Multiply Float
 3221 pipe_class fmulF_reg_reg(regF dst, regF src1, regF src2) %{
 3222     single_instruction;
 3223     dst   : X(write);
 3224     src1  : E(read);
 3225     src2  : E(read);
 3226     FM    : R;
 3227 %}
 3228 
 3229 // Floating Point Multiply Double
 3230 pipe_class fmulD_reg_reg(regD dst, regD src1, regD src2) %{
 3231     single_instruction;
 3232     dst   : X(write);
 3233     src1  : E(read);
 3234     src2  : E(read);
 3235     FM    : R;
 3236 %}
 3237 
 3238 // Floating Point Divide Float
 3239 pipe_class fdivF_reg_reg(regF dst, regF src1, regF src2) %{
 3240     single_instruction;
 3241     dst   : X(write);
 3242     src1  : E(read);
 3243     src2  : E(read);
 3244     FM    : R;
 3245     FDIV  : C(14);
 3246 %}
 3247 
 3248 // Floating Point Divide Double
 3249 pipe_class fdivD_reg_reg(regD dst, regD src1, regD src2) %{
 3250     single_instruction;
 3251     dst   : X(write);
 3252     src1  : E(read);
 3253     src2  : E(read);
 3254     FM    : R;
 3255     FDIV  : C(17);
 3256 %}
 3257 
 3258 // Floating Point Move/Negate/Abs Float
 3259 pipe_class faddF_reg(regF dst, regF src) %{
 3260     single_instruction;
 3261     dst   : W(write);
 3262     src   : E(read);
 3263     FA    : R(1);
 3264 %}
 3265 
 3266 // Floating Point Move/Negate/Abs Double
 3267 pipe_class faddD_reg(regD dst, regD src) %{
 3268     single_instruction;
 3269     dst   : W(write);
 3270     src   : E(read);
 3271     FA    : R;
 3272 %}
 3273 
 3274 // Floating Point Convert F-&gt;D
 3275 pipe_class fcvtF2D(regD dst, regF src) %{
 3276     single_instruction;
 3277     dst   : X(write);
 3278     src   : E(read);
 3279     FA    : R;
 3280 %}
 3281 
 3282 // Floating Point Convert I-&gt;D
 3283 pipe_class fcvtI2D(regD dst, regF src) %{
 3284     single_instruction;
 3285     dst   : X(write);
 3286     src   : E(read);
 3287     FA    : R;
 3288 %}
 3289 
 3290 // Floating Point Convert LHi-&gt;D
 3291 pipe_class fcvtLHi2D(regD dst, regD src) %{
 3292     single_instruction;
 3293     dst   : X(write);
 3294     src   : E(read);
 3295     FA    : R;
 3296 %}
 3297 
 3298 // Floating Point Convert L-&gt;D
 3299 pipe_class fcvtL2D(regD dst, iRegL src) %{
 3300     single_instruction;
 3301     dst   : X(write);
 3302     src   : E(read);
 3303     FA    : R;
 3304 %}
 3305 
 3306 // Floating Point Convert L-&gt;F
 3307 pipe_class fcvtL2F(regF dst, iRegL src) %{
 3308     single_instruction;
 3309     dst   : X(write);
 3310     src   : E(read);
 3311     FA    : R;
 3312 %}
 3313 
 3314 // Floating Point Convert D-&gt;F
 3315 pipe_class fcvtD2F(regD dst, regF src) %{
 3316     single_instruction;
 3317     dst   : X(write);
 3318     src   : E(read);
 3319     FA    : R;
 3320 %}
 3321 
 3322 // Floating Point Convert I-&gt;L
 3323 pipe_class fcvtI2L(regD dst, regF src) %{
 3324     single_instruction;
 3325     dst   : X(write);
 3326     src   : E(read);
 3327     FA    : R;
 3328 %}
 3329 
 3330 // Floating Point Convert D-&gt;F
 3331 pipe_class fcvtD2I(iRegI dst, regD src, flagsReg cr) %{
 3332     instruction_count(1); multiple_bundles;
 3333     dst   : X(write)+6;
 3334     src   : E(read);
 3335     FA    : R;
 3336 %}
 3337 
 3338 // Floating Point Convert D-&gt;L
 3339 pipe_class fcvtD2L(regD dst, regD src, flagsReg cr) %{
 3340     instruction_count(1); multiple_bundles;
 3341     dst   : X(write)+6;
 3342     src   : E(read);
 3343     FA    : R;
 3344 %}
 3345 
 3346 // Floating Point Convert F-&gt;I
 3347 pipe_class fcvtF2I(regF dst, regF src, flagsReg cr) %{
 3348     instruction_count(1); multiple_bundles;
 3349     dst   : X(write)+6;
 3350     src   : E(read);
 3351     FA    : R;
 3352 %}
 3353 
 3354 // Floating Point Convert F-&gt;L
 3355 pipe_class fcvtF2L(regD dst, regF src, flagsReg cr) %{
 3356     instruction_count(1); multiple_bundles;
 3357     dst   : X(write)+6;
 3358     src   : E(read);
 3359     FA    : R;
 3360 %}
 3361 
 3362 // Floating Point Convert I-&gt;F
 3363 pipe_class fcvtI2F(regF dst, regF src) %{
 3364     single_instruction;
 3365     dst   : X(write);
 3366     src   : E(read);
 3367     FA    : R;
 3368 %}
 3369 
 3370 // Floating Point Compare
 3371 pipe_class faddF_fcc_reg_reg_zero(flagsRegF cr, regF src1, regF src2, immI0 zero) %{
 3372     single_instruction;
 3373     cr    : X(write);
 3374     src1  : E(read);
 3375     src2  : E(read);
 3376     FA    : R;
 3377 %}
 3378 
 3379 // Floating Point Compare
 3380 pipe_class faddD_fcc_reg_reg_zero(flagsRegF cr, regD src1, regD src2, immI0 zero) %{
 3381     single_instruction;
 3382     cr    : X(write);
 3383     src1  : E(read);
 3384     src2  : E(read);
 3385     FA    : R;
 3386 %}
 3387 
 3388 // Floating Add Nop
 3389 pipe_class fadd_nop() %{
 3390     single_instruction;
 3391     FA  : R;
 3392 %}
 3393 
 3394 // Integer Store to Memory
 3395 pipe_class istore_mem_reg(memoryI mem, iRegI src) %{
 3396     single_instruction;
 3397     mem   : R(read);
 3398     src   : C(read);
 3399     MS    : R;
 3400 %}
 3401 
 3402 // Integer Store to Memory
 3403 pipe_class istore_mem_spORreg(memoryI mem, sp_ptr_RegP src) %{
 3404     single_instruction;
 3405     mem   : R(read);
 3406     src   : C(read);
 3407     MS    : R;
 3408 %}
 3409 
 3410 // Float Store
 3411 pipe_class fstoreF_mem_reg(memoryF mem, RegF src) %{
 3412     single_instruction;
 3413     mem : R(read);
 3414     src : C(read);
 3415     MS  : R;
 3416 %}
 3417 
 3418 // Float Store
 3419 pipe_class fstoreF_mem_zero(memoryF mem, immF0 src) %{
 3420     single_instruction;
 3421     mem : R(read);
 3422     MS  : R;
 3423 %}
 3424 
 3425 // Double Store
 3426 pipe_class fstoreD_mem_reg(memoryD mem, RegD src) %{
 3427     instruction_count(1);
 3428     mem : R(read);
 3429     src : C(read);
 3430     MS  : R;
 3431 %}
 3432 
 3433 // Double Store
 3434 pipe_class fstoreD_mem_zero(memoryD mem, immD0 src) %{
 3435     single_instruction;
 3436     mem : R(read);
 3437     MS  : R;
 3438 %}
 3439 
 3440 // Integer Load (when sign bit propagation not needed)
 3441 pipe_class iload_mem(iRegI dst, memoryI mem) %{
 3442     single_instruction;
 3443     mem : R(read);
 3444     dst : C(write);
 3445     MS  : R;
 3446 %}
 3447 
 3448 // Integer Load (when sign bit propagation or masking is needed)
 3449 pipe_class iload_mask_mem(iRegI dst, memoryI mem) %{
 3450     single_instruction;
 3451     mem : R(read);
 3452     dst : M(write);
 3453     MS  : R;
 3454 %}
 3455 
 3456 // Float Load
 3457 pipe_class floadF_mem(regF dst, memoryF mem) %{
 3458     single_instruction;
 3459     mem : R(read);
 3460     dst : M(write);
 3461     MS  : R;
 3462 %}
 3463 
 3464 // Float Load
 3465 pipe_class floadD_mem(regD dst, memoryD mem) %{
 3466     instruction_count(1); multiple_bundles; // Again, unaligned argument is only multiple case
 3467     mem : R(read);
 3468     dst : M(write);
 3469     MS  : R;
 3470 %}
 3471 
 3472 // Memory Nop
 3473 pipe_class mem_nop() %{
 3474     single_instruction;
 3475     MS  : R;
 3476 %}
 3477 
 3478 pipe_class sethi(iRegP dst, immI src) %{
 3479     single_instruction;
 3480     dst  : E(write);
 3481     IALU : R;
 3482 %}
 3483 
 3484 pipe_class loadPollP(iRegP poll) %{
 3485     single_instruction;
 3486     poll : R(read);
 3487     MS   : R;
 3488 %}
 3489 
 3490 pipe_class br(Universe br, label labl) %{
 3491     single_instruction_with_delay_slot;
 3492     BR  : R;
 3493 %}
 3494 
 3495 pipe_class br_cc(Universe br, cmpOp cmp, flagsReg cr, label labl) %{
 3496     single_instruction_with_delay_slot;
 3497     cr    : E(read);
 3498     BR    : R;
 3499 %}
 3500 
 3501 pipe_class br_reg(Universe br, cmpOp cmp, iRegI op1, label labl) %{
 3502     single_instruction_with_delay_slot;
 3503     op1 : E(read);
 3504     BR  : R;
 3505     MS  : R;
 3506 %}
 3507 
 3508 pipe_class br_nop() %{
 3509     single_instruction;
 3510     BR  : R;
 3511 %}
 3512 
 3513 pipe_class simple_call(method meth) %{
 3514     instruction_count(2); multiple_bundles; force_serialization;
 3515     fixed_latency(100);
 3516     BR  : R(1);
 3517     MS  : R(1);
 3518     A0  : R(1);
 3519 %}
 3520 
 3521 pipe_class compiled_call(method meth) %{
 3522     instruction_count(1); multiple_bundles; force_serialization;
 3523     fixed_latency(100);
 3524     MS  : R(1);
 3525 %}
 3526 
 3527 pipe_class call(method meth) %{
 3528     instruction_count(0); multiple_bundles; force_serialization;
 3529     fixed_latency(100);
 3530 %}
 3531 
 3532 pipe_class tail_call(Universe ignore, label labl) %{
 3533     single_instruction; has_delay_slot;
 3534     fixed_latency(100);
 3535     BR  : R(1);
 3536     MS  : R(1);
 3537 %}
 3538 
 3539 pipe_class ret(Universe ignore) %{
 3540     single_instruction; has_delay_slot;
 3541     BR  : R(1);
 3542     MS  : R(1);
 3543 %}
 3544 
 3545 // The real do-nothing guy
 3546 pipe_class empty( ) %{
 3547     instruction_count(0);
 3548 %}
 3549 
 3550 pipe_class long_memory_op() %{
 3551     instruction_count(0); multiple_bundles; force_serialization;
 3552     fixed_latency(25);
 3553     MS  : R(1);
 3554 %}
 3555 
 3556 // Check-cast
 3557 pipe_class partial_subtype_check_pipe(Universe ignore, iRegP array, iRegP match ) %{
 3558     array : R(read);
 3559     match  : R(read);
 3560     IALU   : R(2);
 3561     BR     : R(2);
 3562     MS     : R;
 3563 %}
 3564 
 3565 // Convert FPU flags into +1,0,-1
 3566 pipe_class floating_cmp( iRegI dst, regF src1, regF src2 ) %{
 3567     src1  : E(read);
 3568     src2  : E(read);
 3569     dst   : E(write);
 3570     FA    : R;
 3571     MS    : R(2);
 3572     BR    : R(2);
 3573 %}
 3574 
 3575 // Compare for p &lt; q, and conditionally add y
 3576 pipe_class cadd_cmpltmask( iRegI p, iRegI q, iRegI y ) %{
 3577     p     : E(read);
 3578     q     : E(read);
 3579     y     : E(read);
 3580     IALU  : R(3)
 3581 %}
 3582 
 3583 // Perform a compare, then move conditionally in a branch delay slot.
 3584 pipe_class min_max( iRegI src2, iRegI srcdst ) %{
 3585     src2   : E(read);
 3586     srcdst : E(read);
 3587     IALU   : R;
 3588     BR     : R;
 3589 %}
 3590 
 3591 // Define the class for the Nop node
 3592 define %{
 3593    MachNop = ialu_nop;
 3594 %}
 3595 
 3596 %}
 3597 
 3598 //----------INSTRUCTIONS-------------------------------------------------------
 3599 
 3600 //------------Special Nop instructions for bundling - no match rules-----------
 3601 // Nop using the A0 functional unit
 3602 instruct Nop_A0() %{
 3603   ins_pipe(ialu_nop_A0);
 3604 %}
 3605 
 3606 // Nop using the A1 functional unit
 3607 instruct Nop_A1( ) %{
 3608   ins_pipe(ialu_nop_A1);
 3609 %}
 3610 
 3611 // Nop using the memory functional unit
 3612 instruct Nop_MS( ) %{
 3613   ins_pipe(mem_nop);
 3614 %}
 3615 
 3616 // Nop using the floating add functional unit
 3617 instruct Nop_FA( ) %{
 3618   ins_pipe(fadd_nop);
 3619 %}
 3620 
 3621 // Nop using the branch functional unit
 3622 instruct Nop_BR( ) %{
 3623   ins_pipe(br_nop);
 3624 %}
 3625 
 3626 //----------Load/Store/Move Instructions---------------------------------------
 3627 //----------Load Instructions--------------------------------------------------
 3628 // Load Byte (8bit signed)
 3629 instruct loadB(iRegI dst, memoryB mem) %{
 3630   match(Set dst (LoadB mem));
 3631   ins_cost(MEMORY_REF_COST);
 3632 
 3633   size(4);
 3634   format %{ &quot;LDRSB   $dst,$mem\t! byte -&gt; int&quot; %}
 3635   ins_encode %{
 3636     __ ldrsb($dst$$Register, $mem$$Address);
 3637   %}
 3638   ins_pipe(iload_mask_mem);
 3639 %}
 3640 
 3641 // Load Byte (8bit signed) into a Long Register
 3642 instruct loadB2L(iRegL dst, memoryB mem) %{
 3643   match(Set dst (ConvI2L (LoadB mem)));
 3644   ins_cost(MEMORY_REF_COST);
 3645 
 3646   size(8);
 3647   format %{ &quot;LDRSB $dst.lo,$mem\t! byte -&gt; long\n\t&quot;
 3648             &quot;ASR   $dst.hi,$dst.lo,31&quot; %}
 3649   ins_encode %{
 3650     __ ldrsb($dst$$Register, $mem$$Address);
 3651     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3652   %}
 3653   ins_pipe(iload_mask_mem);
 3654 %}
 3655 
 3656 // Load Unsigned Byte (8bit UNsigned) into an int reg
 3657 instruct loadUB(iRegI dst, memoryB mem) %{
 3658   match(Set dst (LoadUB mem));
 3659   ins_cost(MEMORY_REF_COST);
 3660 
 3661   size(4);
 3662   format %{ &quot;LDRB   $dst,$mem\t! ubyte -&gt; int&quot; %}
 3663   ins_encode %{
 3664     __ ldrb($dst$$Register, $mem$$Address);
 3665   %}
 3666   ins_pipe(iload_mem);
 3667 %}
 3668 
 3669 // Load Unsigned Byte (8bit UNsigned) into a Long Register
 3670 instruct loadUB2L(iRegL dst, memoryB mem) %{
 3671   match(Set dst (ConvI2L (LoadUB mem)));
 3672   ins_cost(MEMORY_REF_COST);
 3673 
 3674   size(8);
 3675   format %{ &quot;LDRB  $dst.lo,$mem\t! ubyte -&gt; long\n\t&quot;
 3676             &quot;MOV   $dst.hi,0&quot; %}
 3677   ins_encode %{
 3678     __ ldrb($dst$$Register, $mem$$Address);
 3679     __ mov($dst$$Register-&gt;successor(), 0);
 3680   %}
 3681   ins_pipe(iload_mem);
 3682 %}
 3683 
 3684 // Load Unsigned Byte (8 bit UNsigned) with immediate mask into Long Register
 3685 instruct loadUB2L_limmI(iRegL dst, memoryB mem, limmIlow8 mask) %{
 3686   match(Set dst (ConvI2L (AndI (LoadUB mem) mask)));
 3687 
 3688   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3689   size(12);
 3690   format %{ &quot;LDRB  $dst.lo,$mem\t! ubyte -&gt; long\n\t&quot;
 3691             &quot;MOV   $dst.hi,0\n\t&quot;
 3692             &quot;AND  $dst.lo,$dst.lo,$mask&quot; %}
 3693   ins_encode %{
 3694     __ ldrb($dst$$Register, $mem$$Address);
 3695     __ mov($dst$$Register-&gt;successor(), 0);
 3696     __ andr($dst$$Register, $dst$$Register, limmI_low($mask$$constant, 8));
 3697   %}
 3698   ins_pipe(iload_mem);
 3699 %}
 3700 
 3701 // Load Short (16bit signed)
 3702 
 3703 instruct loadS(iRegI dst, memoryS mem) %{
 3704   match(Set dst (LoadS mem));
 3705   ins_cost(MEMORY_REF_COST);
 3706 
 3707   size(4);
 3708   format %{ &quot;LDRSH   $dst,$mem\t! short&quot; %}
 3709   ins_encode %{
 3710     __ ldrsh($dst$$Register, $mem$$Address);
 3711   %}
 3712   ins_pipe(iload_mask_mem);
 3713 %}
 3714 
 3715 // Load Short (16 bit signed) to Byte (8 bit signed)
 3716 instruct loadS2B(iRegI dst, memoryS mem, immI_24 twentyfour) %{
 3717   match(Set dst (RShiftI (LShiftI (LoadS mem) twentyfour) twentyfour));
 3718   ins_cost(MEMORY_REF_COST);
 3719 
 3720   size(4);
 3721 
 3722   format %{ &quot;LDRSB   $dst,$mem\t! short -&gt; byte&quot; %}
 3723   ins_encode %{
 3724     __ ldrsb($dst$$Register, $mem$$Address);
 3725   %}
 3726   ins_pipe(iload_mask_mem);
 3727 %}
 3728 
 3729 // Load Short (16bit signed) into a Long Register
 3730 instruct loadS2L(iRegL dst, memoryS mem) %{
 3731   match(Set dst (ConvI2L (LoadS mem)));
 3732   ins_cost(MEMORY_REF_COST);
 3733 
 3734   size(8);
 3735   format %{ &quot;LDRSH $dst.lo,$mem\t! short -&gt; long\n\t&quot;
 3736             &quot;ASR   $dst.hi,$dst.lo,31&quot; %}
 3737   ins_encode %{
 3738     __ ldrsh($dst$$Register, $mem$$Address);
 3739     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3740   %}
 3741   ins_pipe(iload_mask_mem);
 3742 %}
 3743 
 3744 // Load Unsigned Short/Char (16bit UNsigned)
 3745 
 3746 
 3747 instruct loadUS(iRegI dst, memoryS mem) %{
 3748   match(Set dst (LoadUS mem));
 3749   ins_cost(MEMORY_REF_COST);
 3750 
 3751   size(4);
 3752   format %{ &quot;LDRH   $dst,$mem\t! ushort/char&quot; %}
 3753   ins_encode %{
 3754     __ ldrh($dst$$Register, $mem$$Address);
 3755   %}
 3756   ins_pipe(iload_mem);
 3757 %}
 3758 
 3759 // Load Unsigned Short/Char (16 bit UNsigned) to Byte (8 bit signed)
 3760 instruct loadUS2B(iRegI dst, memoryB mem, immI_24 twentyfour) %{
 3761   match(Set dst (RShiftI (LShiftI (LoadUS mem) twentyfour) twentyfour));
 3762   ins_cost(MEMORY_REF_COST);
 3763 
 3764   size(4);
 3765   format %{ &quot;LDRSB   $dst,$mem\t! ushort -&gt; byte&quot; %}
 3766   ins_encode %{
 3767     __ ldrsb($dst$$Register, $mem$$Address);
 3768   %}
 3769   ins_pipe(iload_mask_mem);
 3770 %}
 3771 
 3772 // Load Unsigned Short/Char (16bit UNsigned) into a Long Register
 3773 instruct loadUS2L(iRegL dst, memoryS mem) %{
 3774   match(Set dst (ConvI2L (LoadUS mem)));
 3775   ins_cost(MEMORY_REF_COST);
 3776 
 3777   size(8);
 3778   format %{ &quot;LDRH  $dst.lo,$mem\t! short -&gt; long\n\t&quot;
 3779             &quot;MOV   $dst.hi, 0&quot; %}
 3780   ins_encode %{
 3781     __ ldrh($dst$$Register, $mem$$Address);
 3782     __ mov($dst$$Register-&gt;successor(), 0);
 3783   %}
 3784   ins_pipe(iload_mem);
 3785 %}
 3786 
 3787 // Load Unsigned Short/Char (16bit UNsigned) with mask 0xFF into a Long Register
 3788 instruct loadUS2L_immI_255(iRegL dst, memoryB mem, immI_255 mask) %{
 3789   match(Set dst (ConvI2L (AndI (LoadUS mem) mask)));
 3790   ins_cost(MEMORY_REF_COST);
 3791 
 3792   size(8);
 3793   format %{ &quot;LDRB  $dst.lo,$mem\t! \n\t&quot;
 3794             &quot;MOV   $dst.hi, 0&quot; %}
 3795   ins_encode %{
 3796     __ ldrb($dst$$Register, $mem$$Address);
 3797     __ mov($dst$$Register-&gt;successor(), 0);
 3798   %}
 3799   ins_pipe(iload_mem);
 3800 %}
 3801 
 3802 // Load Unsigned Short/Char (16bit UNsigned) with a immediate mask into a Long Register
 3803 instruct loadUS2L_limmI(iRegL dst, memoryS mem, limmI mask) %{
 3804   match(Set dst (ConvI2L (AndI (LoadUS mem) mask)));
 3805   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3806 
 3807   size(12);
 3808   format %{ &quot;LDRH   $dst,$mem\t! ushort/char &amp; mask -&gt; long\n\t&quot;
 3809             &quot;MOV    $dst.hi, 0\n\t&quot;
 3810             &quot;AND    $dst,$dst,$mask&quot; %}
 3811   ins_encode %{
 3812     __ ldrh($dst$$Register, $mem$$Address);
 3813     __ mov($dst$$Register-&gt;successor(), 0);
 3814     __ andr($dst$$Register, $dst$$Register, $mask$$constant);
 3815   %}
 3816   ins_pipe(iload_mem);
 3817 %}
 3818 
 3819 // Load Integer
 3820 
 3821 
 3822 instruct loadI(iRegI dst, memoryI mem) %{
 3823   match(Set dst (LoadI mem));
 3824   ins_cost(MEMORY_REF_COST);
 3825 
 3826   size(4);
 3827   format %{ &quot;ldr_s32 $dst,$mem\t! int&quot; %}
 3828   ins_encode %{
 3829     __ ldr_s32($dst$$Register, $mem$$Address);
 3830   %}
 3831   ins_pipe(iload_mem);
 3832 %}
 3833 
 3834 // Load Integer to Byte (8 bit signed)
 3835 instruct loadI2B(iRegI dst, memoryS mem, immI_24 twentyfour) %{
 3836   match(Set dst (RShiftI (LShiftI (LoadI mem) twentyfour) twentyfour));
 3837   ins_cost(MEMORY_REF_COST);
 3838 
 3839   size(4);
 3840 
 3841   format %{ &quot;LDRSB   $dst,$mem\t! int -&gt; byte&quot; %}
 3842   ins_encode %{
 3843     __ ldrsb($dst$$Register, $mem$$Address);
 3844   %}
 3845   ins_pipe(iload_mask_mem);
 3846 %}
 3847 
 3848 // Load Integer to Unsigned Byte (8 bit UNsigned)
 3849 instruct loadI2UB(iRegI dst, memoryB mem, immI_255 mask) %{
 3850   match(Set dst (AndI (LoadI mem) mask));
 3851   ins_cost(MEMORY_REF_COST);
 3852 
 3853   size(4);
 3854 
 3855   format %{ &quot;LDRB   $dst,$mem\t! int -&gt; ubyte&quot; %}
 3856   ins_encode %{
 3857     __ ldrb($dst$$Register, $mem$$Address);
 3858   %}
 3859   ins_pipe(iload_mask_mem);
 3860 %}
 3861 
 3862 // Load Integer to Short (16 bit signed)
 3863 instruct loadI2S(iRegI dst, memoryS mem, immI_16 sixteen) %{
 3864   match(Set dst (RShiftI (LShiftI (LoadI mem) sixteen) sixteen));
 3865   ins_cost(MEMORY_REF_COST);
 3866 
 3867   size(4);
 3868   format %{ &quot;LDRSH   $dst,$mem\t! int -&gt; short&quot; %}
 3869   ins_encode %{
 3870     __ ldrsh($dst$$Register, $mem$$Address);
 3871   %}
 3872   ins_pipe(iload_mask_mem);
 3873 %}
 3874 
 3875 // Load Integer to Unsigned Short (16 bit UNsigned)
 3876 instruct loadI2US(iRegI dst, memoryS mem, immI_65535 mask) %{
 3877   match(Set dst (AndI (LoadI mem) mask));
 3878   ins_cost(MEMORY_REF_COST);
 3879 
 3880   size(4);
 3881   format %{ &quot;LDRH   $dst,$mem\t! int -&gt; ushort/char&quot; %}
 3882   ins_encode %{
 3883     __ ldrh($dst$$Register, $mem$$Address);
 3884   %}
 3885   ins_pipe(iload_mask_mem);
 3886 %}
 3887 
 3888 // Load Integer into a Long Register
 3889 instruct loadI2L(iRegL dst, memoryI mem) %{
 3890   match(Set dst (ConvI2L (LoadI mem)));
 3891   ins_cost(MEMORY_REF_COST);
 3892 
 3893   size(8);
 3894   format %{ &quot;LDR   $dst.lo,$mem\t! int -&gt; long\n\t&quot;
 3895             &quot;ASR   $dst.hi,$dst.lo,31\t! int-&gt;long&quot; %}
 3896   ins_encode %{
 3897     __ ldr($dst$$Register, $mem$$Address);
 3898     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3899   %}
 3900   ins_pipe(iload_mask_mem);
 3901 %}
 3902 
 3903 // Load Integer with mask 0xFF into a Long Register
 3904 instruct loadI2L_immI_255(iRegL dst, memoryB mem, immI_255 mask) %{
 3905   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3906   ins_cost(MEMORY_REF_COST);
 3907 
 3908   size(8);
 3909   format %{ &quot;LDRB   $dst.lo,$mem\t! int &amp; 0xFF -&gt; long\n\t&quot;
 3910             &quot;MOV    $dst.hi, 0&quot; %}
 3911   ins_encode %{
 3912     __ ldrb($dst$$Register, $mem$$Address);
 3913     __ mov($dst$$Register-&gt;successor(), 0);
 3914   %}
 3915   ins_pipe(iload_mem);
 3916 %}
 3917 
 3918 // Load Integer with mask 0xFFFF into a Long Register
 3919 instruct loadI2L_immI_65535(iRegL dst, memoryS mem, immI_65535 mask) %{
 3920   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3921   ins_cost(MEMORY_REF_COST);
 3922 
 3923   size(8);
 3924   format %{ &quot;LDRH   $dst,$mem\t! int &amp; 0xFFFF -&gt; long\n\t&quot;
 3925             &quot;MOV    $dst.hi, 0&quot; %}
 3926   ins_encode %{
 3927     __ ldrh($dst$$Register, $mem$$Address);
 3928     __ mov($dst$$Register-&gt;successor(), 0);
 3929   %}
 3930   ins_pipe(iload_mask_mem);
 3931 %}
 3932 
 3933 // Load Integer with a 31-bit immediate mask into a Long Register
 3934 instruct loadI2L_limmU31(iRegL dst, memoryI mem, limmU31 mask) %{
 3935   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3936   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3937 
 3938   size(12);
 3939   format %{ &quot;LDR   $dst.lo,$mem\t! int -&gt; long\n\t&quot;
 3940             &quot;MOV    $dst.hi, 0\n\t&quot;
 3941             &quot;AND   $dst,$dst,$mask&quot; %}
 3942 
 3943   ins_encode %{
 3944     __ ldr($dst$$Register, $mem$$Address);
 3945     __ mov($dst$$Register-&gt;successor(), 0);
 3946     __ andr($dst$$Register, $dst$$Register, $mask$$constant);
 3947   %}
 3948   ins_pipe(iload_mem);
 3949 %}
 3950 
 3951 // Load Integer with a 31-bit mask into a Long Register
 3952 // FIXME: use iRegI mask, remove tmp?
 3953 instruct loadI2L_immU31(iRegL dst, memoryI mem, immU31 mask, iRegI tmp) %{
 3954   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3955   effect(TEMP dst, TEMP tmp);
 3956 
 3957   ins_cost(MEMORY_REF_COST + 4*DEFAULT_COST);
 3958   size(20);
 3959   format %{ &quot;LDR      $mem,$dst\t! int &amp; 31-bit mask -&gt; long\n\t&quot;
 3960             &quot;MOV      $dst.hi, 0\n\t&quot;
 3961             &quot;MOV_SLOW $tmp,$mask\n\t&quot;
 3962             &quot;AND      $dst,$tmp,$dst&quot; %}
 3963   ins_encode %{
 3964     __ ldr($dst$$Register, $mem$$Address);
 3965     __ mov($dst$$Register-&gt;successor(), 0);
 3966     __ mov_slow($tmp$$Register, $mask$$constant);
 3967     __ andr($dst$$Register, $dst$$Register, $tmp$$Register);
 3968   %}
 3969   ins_pipe(iload_mem);
 3970 %}
 3971 
 3972 // Load Unsigned Integer into a Long Register
 3973 instruct loadUI2L(iRegL dst, memoryI mem, immL_32bits mask) %{
 3974   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 3975   ins_cost(MEMORY_REF_COST);
 3976 
 3977   size(8);
 3978   format %{ &quot;LDR   $dst.lo,$mem\t! uint -&gt; long\n\t&quot;
 3979             &quot;MOV   $dst.hi,0&quot; %}
 3980   ins_encode %{
 3981     __ ldr($dst$$Register, $mem$$Address);
 3982     __ mov($dst$$Register-&gt;successor(), 0);
 3983   %}
 3984   ins_pipe(iload_mem);
 3985 %}
 3986 
 3987 // Load Long
 3988 
 3989 
 3990 instruct loadL(iRegLd dst, memoryL mem ) %{
 3991   predicate(!((LoadLNode*)n)-&gt;require_atomic_access());
 3992   match(Set dst (LoadL mem));
 3993   effect(TEMP dst);
 3994   ins_cost(MEMORY_REF_COST);
 3995 
 3996   size(4);
 3997   format %{ &quot;ldr_64  $dst,$mem\t! long&quot; %}
 3998   ins_encode %{
 3999     __ ldr_64($dst$$Register, $mem$$Address);
 4000   %}
 4001   ins_pipe(iload_mem);
 4002 %}
 4003 
 4004 instruct loadL_2instr(iRegL dst, memorylong mem ) %{
 4005   predicate(!((LoadLNode*)n)-&gt;require_atomic_access());
 4006   match(Set dst (LoadL mem));
 4007   ins_cost(MEMORY_REF_COST + DEFAULT_COST);
 4008 
 4009   size(8);
 4010   format %{ &quot;LDR    $dst.lo,$mem \t! long order of instrs reversed if $dst.lo == base($mem)\n\t&quot;
 4011             &quot;LDR    $dst.hi,$mem+4 or $mem&quot; %}
 4012   ins_encode %{
 4013     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4014     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4015 
 4016     if ($dst$$Register == reg_to_register_object($mem$$base)) {
 4017       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4018       __ ldr($dst$$Register, Amemlo);
 4019     } else {
 4020       __ ldr($dst$$Register, Amemlo);
 4021       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4022     }
 4023   %}
 4024   ins_pipe(iload_mem);
 4025 %}
 4026 
 4027 instruct loadL_volatile(iRegL dst, indirect mem ) %{
 4028   predicate(((LoadLNode*)n)-&gt;require_atomic_access());
 4029   match(Set dst (LoadL mem));
 4030   ins_cost(MEMORY_REF_COST);
 4031 
 4032   size(4);
 4033   format %{ &quot;LDMIA    $dst,$mem\t! long&quot; %}
 4034   ins_encode %{
 4035     // FIXME: why is ldmia considered atomic?  Should be ldrexd
 4036     RegisterSet set($dst$$Register);
 4037     set = set | reg_to_register_object($dst$$reg + 1);
 4038     __ ldmia(reg_to_register_object($mem$$base), set);
 4039   %}
 4040   ins_pipe(iload_mem);
 4041 %}
 4042 
 4043 instruct loadL_volatile_fp(iRegL dst, memoryD mem ) %{
 4044   predicate(((LoadLNode*)n)-&gt;require_atomic_access());
 4045   match(Set dst (LoadL mem));
 4046   ins_cost(MEMORY_REF_COST);
 4047 
 4048   size(8);
 4049   format %{ &quot;FLDD      S14, $mem&quot;
 4050             &quot;FMRRD    $dst, S14\t! long \n&#39;t&quot; %}
 4051   ins_encode %{
 4052     __ fldd(S14, $mem$$Address);
 4053     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), S14);
 4054   %}
 4055   ins_pipe(iload_mem);
 4056 %}
 4057 
 4058 instruct loadL_unaligned(iRegL dst, memorylong mem ) %{
 4059   match(Set dst (LoadL_unaligned mem));
 4060   ins_cost(MEMORY_REF_COST);
 4061 
 4062   size(8);
 4063   format %{ &quot;LDR    $dst.lo,$mem\t! long order of instrs reversed if $dst.lo == base($mem)\n\t&quot;
 4064             &quot;LDR    $dst.hi,$mem+4&quot; %}
 4065   ins_encode %{
 4066     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4067     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4068 
 4069     if ($dst$$Register == reg_to_register_object($mem$$base)) {
 4070       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4071       __ ldr($dst$$Register, Amemlo);
 4072     } else {
 4073       __ ldr($dst$$Register, Amemlo);
 4074       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4075     }
 4076   %}
 4077   ins_pipe(iload_mem);
 4078 %}
 4079 
 4080 // Load Range
 4081 instruct loadRange(iRegI dst, memoryI mem) %{
 4082   match(Set dst (LoadRange mem));
 4083   ins_cost(MEMORY_REF_COST);
 4084 
 4085   size(4);
 4086   format %{ &quot;LDR_u32 $dst,$mem\t! range&quot; %}
 4087   ins_encode %{
 4088     __ ldr_u32($dst$$Register, $mem$$Address);
 4089   %}
 4090   ins_pipe(iload_mem);
 4091 %}
 4092 
 4093 // Load Pointer
 4094 
 4095 
 4096 instruct loadP(iRegP dst, memoryP mem) %{
 4097   match(Set dst (LoadP mem));
 4098   ins_cost(MEMORY_REF_COST);
 4099   size(4);
 4100 
 4101   format %{ &quot;LDR   $dst,$mem\t! ptr&quot; %}
 4102   ins_encode %{
 4103     __ ldr($dst$$Register, $mem$$Address);
 4104   %}
 4105   ins_pipe(iload_mem);
 4106 %}
 4107 
 4108 #ifdef XXX
 4109 // FIXME XXXX
 4110 //instruct loadSP(iRegP dst, memoryP mem) %{
 4111 instruct loadSP(SPRegP dst, memoryP mem, iRegP tmp) %{
 4112   match(Set dst (LoadP mem));
 4113   effect(TEMP tmp);
 4114   ins_cost(MEMORY_REF_COST+1);
 4115   size(8);
 4116 
 4117   format %{ &quot;LDR   $tmp,$mem\t! ptr\n\t&quot;
 4118             &quot;MOV   $dst,$tmp\t! ptr&quot; %}
 4119   ins_encode %{
 4120     __ ldr($tmp$$Register, $mem$$Address);
 4121     __ mov($dst$$Register, $tmp$$Register);
 4122   %}
 4123   ins_pipe(iload_mem);
 4124 %}
 4125 #endif
 4126 
 4127 #ifdef _LP64
 4128 // Load Compressed Pointer
 4129 
 4130 // XXX This variant shouldn&#39;t be necessary if 6217251 is implemented
 4131 instruct loadNoff(iRegN dst, memoryScaledI mem, aimmX off, iRegP tmp) %{
 4132   match(Set dst (LoadN (AddP mem off)));
 4133   ins_cost(MEMORY_REF_COST + DEFAULT_COST); // assume shift/sign-extend is free
 4134   effect(TEMP tmp);
 4135   size(4 * 2);
 4136 
 4137   format %{ &quot;ldr_u32 $dst,$mem+$off\t! compressed ptr temp=$tmp&quot; %}
 4138   ins_encode %{
 4139     Register base = reg_to_register_object($mem$$base);
 4140     __ add($tmp$$Register, base, $off$$constant);
 4141     Address nmem = Address::make_raw($tmp$$reg, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4142     __ ldr_u32($dst$$Register, nmem);
 4143   %}
 4144   ins_pipe(iload_mem);
 4145 %}
 4146 
 4147 instruct loadN(iRegN dst, memoryI mem) %{
 4148   match(Set dst (LoadN mem));
 4149   ins_cost(MEMORY_REF_COST);
 4150   size(4);
 4151 
 4152   format %{ &quot;ldr_u32 $dst,$mem\t! compressed ptr&quot; %}
 4153   ins_encode %{
 4154     __ ldr_u32($dst$$Register, $mem$$Address);
 4155   %}
 4156   ins_pipe(iload_mem);
 4157 %}
 4158 #endif
 4159 
 4160 // Load Klass Pointer
 4161 instruct loadKlass(iRegP dst, memoryI mem) %{
 4162   match(Set dst (LoadKlass mem));
 4163   ins_cost(MEMORY_REF_COST);
 4164   size(4);
 4165 
 4166   format %{ &quot;LDR   $dst,$mem\t! klass ptr&quot; %}
 4167   ins_encode %{
 4168     __ ldr($dst$$Register, $mem$$Address);
 4169   %}
 4170   ins_pipe(iload_mem);
 4171 %}
 4172 
 4173 #ifdef _LP64
 4174 // Load narrow Klass Pointer
 4175 instruct loadNKlass(iRegN dst, memoryI mem) %{
 4176   match(Set dst (LoadNKlass mem));
 4177   ins_cost(MEMORY_REF_COST);
 4178   size(4);
 4179 
 4180   format %{ &quot;ldr_u32 $dst,$mem\t! compressed klass ptr&quot; %}
 4181   ins_encode %{
 4182     __ ldr_u32($dst$$Register, $mem$$Address);
 4183   %}
 4184   ins_pipe(iload_mem);
 4185 %}
 4186 #endif
 4187 
 4188 
 4189 instruct loadD(regD dst, memoryD mem) %{
 4190   match(Set dst (LoadD mem));
 4191   ins_cost(MEMORY_REF_COST);
 4192 
 4193   size(4);
 4194   // FIXME: needs to be atomic, but  ARMv7 A.R.M. guarantees
 4195   // only LDREXD and STREXD are 64-bit single-copy atomic
 4196   format %{ &quot;FLDD   $dst,$mem&quot; %}
 4197   ins_encode %{
 4198     __ ldr_double($dst$$FloatRegister, $mem$$Address);
 4199   %}
 4200   ins_pipe(floadD_mem);
 4201 %}
 4202 
 4203 // Load Double - UNaligned
 4204 instruct loadD_unaligned(regD_low dst, memoryF2 mem ) %{
 4205   match(Set dst (LoadD_unaligned mem));
 4206   ins_cost(MEMORY_REF_COST*2+DEFAULT_COST);
 4207   size(8);
 4208   format %{ &quot;FLDS    $dst.lo,$mem\t! misaligned double\n&quot;
 4209           &quot;\tFLDS    $dst.hi,$mem+4\t!&quot; %}
 4210   ins_encode %{
 4211     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4212     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4213       __ flds($dst$$FloatRegister, Amemlo);
 4214       __ flds($dst$$FloatRegister-&gt;successor(), Amemhi);
 4215   %}
 4216   ins_pipe(iload_mem);
 4217 %}
 4218 
 4219 
 4220 instruct loadF(regF dst, memoryF mem) %{
 4221   match(Set dst (LoadF mem));
 4222 
 4223   ins_cost(MEMORY_REF_COST);
 4224   size(4);
 4225   format %{ &quot;FLDS    $dst,$mem&quot; %}
 4226   ins_encode %{
 4227     __ ldr_float($dst$$FloatRegister, $mem$$Address);
 4228   %}
 4229   ins_pipe(floadF_mem);
 4230 %}
 4231 
 4232 
 4233 // // Load Constant
 4234 instruct loadConI( iRegI dst, immI src ) %{
 4235   match(Set dst src);
 4236   ins_cost(DEFAULT_COST * 3/2);
 4237   format %{ &quot;MOV_SLOW    $dst, $src&quot; %}
 4238   ins_encode %{
 4239     __ mov_slow($dst$$Register, $src$$constant);
 4240   %}
 4241   ins_pipe(ialu_hi_lo_reg);
 4242 %}
 4243 
 4244 instruct loadConIMov( iRegI dst, immIMov src ) %{
 4245   match(Set dst src);
 4246   size(4);
 4247   format %{ &quot;MOV    $dst, $src&quot; %}
 4248   ins_encode %{
 4249     __ mov($dst$$Register, $src$$constant);
 4250   %}
 4251   ins_pipe(ialu_imm);
 4252 %}
 4253 
 4254 instruct loadConIMovn( iRegI dst, immIRotn src ) %{
 4255   match(Set dst src);
 4256   size(4);
 4257   format %{ &quot;MVN    $dst, ~$src&quot; %}
 4258   ins_encode %{
 4259     __ mvn($dst$$Register, ~$src$$constant);
 4260   %}
 4261   ins_pipe(ialu_imm_n);
 4262 %}
 4263 
 4264 instruct loadConI16( iRegI dst, immI16 src ) %{
 4265   match(Set dst src);
 4266   size(4);
 4267   format %{ &quot;MOVW    $dst, $src&quot; %}
 4268   ins_encode %{
 4269     __ movw($dst$$Register, $src$$constant);
 4270   %}
 4271   ins_pipe(ialu_imm_n);
 4272 %}
 4273 
 4274 instruct loadConP(iRegP dst, immP src) %{
 4275   match(Set dst src);
 4276   ins_cost(DEFAULT_COST * 3/2);
 4277   format %{ &quot;MOV_SLOW    $dst,$src\t!ptr&quot; %}
 4278   ins_encode %{
 4279     relocInfo::relocType constant_reloc = _opnds[1]-&gt;constant_reloc();
 4280     intptr_t val = $src$$constant;
 4281     if (constant_reloc == relocInfo::oop_type) {
 4282       __ mov_oop($dst$$Register, (jobject)val);
 4283     } else if (constant_reloc == relocInfo::metadata_type) {
 4284       __ mov_metadata($dst$$Register, (Metadata*)val);
 4285     } else {
 4286       __ mov_slow($dst$$Register, val);
 4287     }
 4288   %}
 4289   ins_pipe(loadConP);
 4290 %}
 4291 
 4292 
 4293 instruct loadConP_poll(iRegP dst, immP_poll src) %{
 4294   match(Set dst src);
 4295   ins_cost(DEFAULT_COST);
 4296   format %{ &quot;MOV_SLOW    $dst,$src\t!ptr&quot; %}
 4297   ins_encode %{
 4298       __ mov_slow($dst$$Register, $src$$constant);
 4299   %}
 4300   ins_pipe(loadConP_poll);
 4301 %}
 4302 
 4303 instruct loadConL(iRegL dst, immL src) %{
 4304   match(Set dst src);
 4305   ins_cost(DEFAULT_COST * 4);
 4306   format %{ &quot;MOV_SLOW   $dst.lo, $src &amp; 0x0FFFFFFFFL \t! long\n\t&quot;
 4307             &quot;MOV_SLOW   $dst.hi, $src &gt;&gt; 32&quot; %}
 4308   ins_encode %{
 4309     __ mov_slow(reg_to_register_object($dst$$reg), $src$$constant &amp; 0x0FFFFFFFFL);
 4310     __ mov_slow(reg_to_register_object($dst$$reg + 1), ((julong)($src$$constant)) &gt;&gt; 32);
 4311   %}
 4312   ins_pipe(loadConL);
 4313 %}
 4314 
 4315 instruct loadConL16( iRegL dst, immL16 src ) %{
 4316   match(Set dst src);
 4317   ins_cost(DEFAULT_COST * 2);
 4318 
 4319   size(8);
 4320   format %{ &quot;MOVW    $dst.lo, $src \n\t&quot;
 4321             &quot;MOVW    $dst.hi, 0 \n\t&quot; %}
 4322   ins_encode %{
 4323     __ movw($dst$$Register, $src$$constant);
 4324     __ movw($dst$$Register-&gt;successor(), 0);
 4325   %}
 4326   ins_pipe(ialu_imm);
 4327 %}
 4328 
 4329 instruct loadConF_imm8(regF dst, imm8F src) %{
 4330   match(Set dst src);
 4331   ins_cost(DEFAULT_COST);
 4332   size(4);
 4333 
 4334   format %{ &quot;FCONSTS      $dst, $src&quot;%}
 4335 
 4336   ins_encode %{
 4337     __ fconsts($dst$$FloatRegister, Assembler::float_num($src$$constant).imm8());
 4338   %}
 4339   ins_pipe(loadConFD); // FIXME
 4340 %}
 4341 
 4342 
 4343 instruct loadConF(regF dst, immF src, iRegI tmp) %{
 4344   match(Set dst src);
 4345   ins_cost(DEFAULT_COST * 2);
 4346   effect(TEMP tmp);
 4347   size(3*4);
 4348 
 4349   format %{ &quot;MOV_SLOW  $tmp, $src\n\t&quot;
 4350             &quot;FMSR      $dst, $tmp&quot;%}
 4351 
 4352   ins_encode %{
 4353     // FIXME revisit once 6961697 is in
 4354     union {
 4355       jfloat f;
 4356       int i;
 4357     } v;
 4358     v.f = $src$$constant;
 4359     __ mov_slow($tmp$$Register, v.i);
 4360     __ fmsr($dst$$FloatRegister, $tmp$$Register);
 4361   %}
 4362   ins_pipe(loadConFD); // FIXME
 4363 %}
 4364 
 4365 instruct loadConD_imm8(regD dst, imm8D src) %{
 4366   match(Set dst src);
 4367   ins_cost(DEFAULT_COST);
 4368   size(4);
 4369 
 4370   format %{ &quot;FCONSTD      $dst, $src&quot;%}
 4371 
 4372   ins_encode %{
 4373     __ fconstd($dst$$FloatRegister, Assembler::double_num($src$$constant).imm8());
 4374   %}
 4375   ins_pipe(loadConFD); // FIXME
 4376 %}
 4377 
 4378 instruct loadConD(regD dst, immD src, iRegP tmp) %{
 4379   match(Set dst src);
 4380   effect(TEMP tmp);
 4381   ins_cost(MEMORY_REF_COST);
 4382   format %{ &quot;FLDD  $dst, [$constanttablebase + $constantoffset]\t! load from constant table: double=$src&quot; %}
 4383 
 4384   ins_encode %{
 4385     Register r = $constanttablebase;
 4386     int offset  = $constantoffset($src);
 4387     if (!is_memoryD(offset)) {                // can&#39;t use a predicate
 4388                                               // in load constant instructs
 4389       __ add_slow($tmp$$Register, r, offset);
 4390       r = $tmp$$Register;
 4391       offset = 0;
 4392     }
 4393     __ ldr_double($dst$$FloatRegister, Address(r, offset));
 4394   %}
 4395   ins_pipe(loadConFD);
 4396 %}
 4397 
 4398 // Prefetch instructions.
 4399 // Must be safe to execute with invalid address (cannot fault).
 4400 
 4401 instruct prefetchAlloc_mp( memoryP mem ) %{
 4402   predicate(VM_Version::has_multiprocessing_extensions());
 4403   match( PrefetchAllocation mem );
 4404   ins_cost(MEMORY_REF_COST);
 4405   size(4);
 4406 
 4407   format %{ &quot;PLDW $mem\t! Prefetch allocation&quot; %}
 4408   ins_encode %{
 4409     __ pldw($mem$$Address);
 4410   %}
 4411   ins_pipe(iload_mem);
 4412 %}
 4413 
 4414 instruct prefetchAlloc_sp( memoryP mem ) %{
 4415   predicate(!VM_Version::has_multiprocessing_extensions());
 4416   match( PrefetchAllocation mem );
 4417   ins_cost(MEMORY_REF_COST);
 4418   size(4);
 4419 
 4420   format %{ &quot;PLD $mem\t! Prefetch allocation&quot; %}
 4421   ins_encode %{
 4422     __ pld($mem$$Address);
 4423   %}
 4424   ins_pipe(iload_mem);
 4425 %}
 4426 
 4427 
 4428 //----------Store Instructions-------------------------------------------------
 4429 // Store Byte
 4430 instruct storeB(memoryB mem, store_RegI src) %{
 4431   match(Set mem (StoreB mem src));
 4432   ins_cost(MEMORY_REF_COST);
 4433 
 4434   size(4);
 4435   format %{ &quot;STRB    $src,$mem\t! byte&quot; %}
 4436   ins_encode %{
 4437     __ strb($src$$Register, $mem$$Address);
 4438   %}
 4439   ins_pipe(istore_mem_reg);
 4440 %}
 4441 
 4442 instruct storeCM(memoryB mem, store_RegI src) %{
 4443   match(Set mem (StoreCM mem src));
 4444   ins_cost(MEMORY_REF_COST);
 4445 
 4446   size(4);
 4447   format %{ &quot;STRB    $src,$mem\t! CMS card-mark byte&quot; %}
 4448   ins_encode %{
 4449     __ strb($src$$Register, $mem$$Address);
 4450   %}
 4451   ins_pipe(istore_mem_reg);
 4452 %}
 4453 
 4454 // Store Char/Short
 4455 
 4456 
 4457 instruct storeC(memoryS mem, store_RegI src) %{
 4458   match(Set mem (StoreC mem src));
 4459   ins_cost(MEMORY_REF_COST);
 4460 
 4461   size(4);
 4462   format %{ &quot;STRH    $src,$mem\t! short&quot; %}
 4463   ins_encode %{
 4464     __ strh($src$$Register, $mem$$Address);
 4465   %}
 4466   ins_pipe(istore_mem_reg);
 4467 %}
 4468 
 4469 // Store Integer
 4470 
 4471 
 4472 instruct storeI(memoryI mem, store_RegI src) %{
 4473   match(Set mem (StoreI mem src));
 4474   ins_cost(MEMORY_REF_COST);
 4475 
 4476   size(4);
 4477   format %{ &quot;str_32 $src,$mem&quot; %}
 4478   ins_encode %{
 4479     __ str_32($src$$Register, $mem$$Address);
 4480   %}
 4481   ins_pipe(istore_mem_reg);
 4482 %}
 4483 
 4484 // Store Long
 4485 
 4486 
 4487 instruct storeL(memoryL mem, store_RegLd src) %{
 4488   predicate(!((StoreLNode*)n)-&gt;require_atomic_access());
 4489   match(Set mem (StoreL mem src));
 4490   ins_cost(MEMORY_REF_COST);
 4491 
 4492   size(4);
 4493   format %{ &quot;str_64  $src,$mem\t! long\n\t&quot; %}
 4494 
 4495   ins_encode %{
 4496     __ str_64($src$$Register, $mem$$Address);
 4497   %}
 4498   ins_pipe(istore_mem_reg);
 4499 %}
 4500 
 4501 instruct storeL_2instr(memorylong mem, iRegL src) %{
 4502   predicate(!((StoreLNode*)n)-&gt;require_atomic_access());
 4503   match(Set mem (StoreL mem src));
 4504   ins_cost(MEMORY_REF_COST + DEFAULT_COST);
 4505 
 4506   size(8);
 4507   format %{ &quot;STR    $src.lo,$mem\t! long\n\t&quot;
 4508             &quot;STR    $src.hi,$mem+4&quot; %}
 4509 
 4510   ins_encode %{
 4511     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4512     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4513     __ str($src$$Register, Amemlo);
 4514     __ str($src$$Register-&gt;successor(), Amemhi);
 4515   %}
 4516   ins_pipe(istore_mem_reg);
 4517 %}
 4518 
 4519 instruct storeL_volatile(indirect mem, iRegL src) %{
 4520   predicate(((StoreLNode*)n)-&gt;require_atomic_access());
 4521   match(Set mem (StoreL mem src));
 4522   ins_cost(MEMORY_REF_COST);
 4523   size(4);
 4524   format %{ &quot;STMIA    $src,$mem\t! long&quot; %}
 4525   ins_encode %{
 4526     // FIXME: why is stmia considered atomic?  Should be strexd
 4527     RegisterSet set($src$$Register);
 4528     set = set | reg_to_register_object($src$$reg + 1);
 4529     __ stmia(reg_to_register_object($mem$$base), set);
 4530   %}
 4531   ins_pipe(istore_mem_reg);
 4532 %}
 4533 
 4534 instruct storeL_volatile_fp(memoryD mem, iRegL src) %{
 4535   predicate(((StoreLNode*)n)-&gt;require_atomic_access());
 4536   match(Set mem (StoreL mem src));
 4537   ins_cost(MEMORY_REF_COST);
 4538   size(8);
 4539   format %{ &quot;FMDRR    S14, $src\t! long \n\t&quot;
 4540             &quot;FSTD     S14, $mem&quot; %}
 4541   ins_encode %{
 4542     __ fmdrr(S14, $src$$Register, $src$$Register-&gt;successor());
 4543     __ fstd(S14, $mem$$Address);
 4544   %}
 4545   ins_pipe(istore_mem_reg);
 4546 %}
 4547 
 4548 #ifdef XXX
 4549 // Move SP Pointer
 4550 //instruct movSP(sp_ptr_RegP dst, SPRegP src) %{
 4551 //instruct movSP(iRegP dst, SPRegP src) %{
 4552 instruct movSP(store_ptr_RegP dst, SPRegP src) %{
 4553   match(Set dst src);
 4554 //predicate(!_kids[1]-&gt;_leaf-&gt;is_Proj() || _kids[1]-&gt;_leaf-&gt;as_Proj()-&gt;_con == TypeFunc::FramePtr);
 4555   ins_cost(MEMORY_REF_COST);
 4556   size(4);
 4557 
 4558   format %{ &quot;MOV    $dst,$src\t! SP ptr\n\t&quot; %}
 4559   ins_encode %{
 4560     assert(false, &quot;XXX1 got here&quot;);
 4561     __ mov($dst$$Register, SP);
 4562     __ mov($dst$$Register, $src$$Register);
 4563   %}
 4564   ins_pipe(ialu_reg);
 4565 %}
 4566 #endif
 4567 
 4568 
 4569 // Store Pointer
 4570 
 4571 
 4572 instruct storeP(memoryP mem, store_ptr_RegP src) %{
 4573   match(Set mem (StoreP mem src));
 4574   ins_cost(MEMORY_REF_COST);
 4575   size(4);
 4576 
 4577   format %{ &quot;STR    $src,$mem\t! ptr&quot; %}
 4578   ins_encode %{
 4579     __ str($src$$Register, $mem$$Address);
 4580   %}
 4581   ins_pipe(istore_mem_spORreg);
 4582 %}
 4583 
 4584 
 4585 #ifdef _LP64
 4586 // Store Compressed Pointer
 4587 
 4588 
 4589 instruct storeN(memoryI mem, store_RegN src) %{
 4590   match(Set mem (StoreN mem src));
 4591   ins_cost(MEMORY_REF_COST);
 4592   size(4);
 4593 
 4594   format %{ &quot;str_32 $src,$mem\t! compressed ptr&quot; %}
 4595   ins_encode %{
 4596     __ str_32($src$$Register, $mem$$Address);
 4597   %}
 4598   ins_pipe(istore_mem_reg);
 4599 %}
 4600 
 4601 
 4602 // Store Compressed Klass Pointer
 4603 instruct storeNKlass(memoryI mem, store_RegN src) %{
 4604   match(Set mem (StoreNKlass mem src));
 4605   ins_cost(MEMORY_REF_COST);
 4606   size(4);
 4607 
 4608   format %{ &quot;str_32 $src,$mem\t! compressed klass ptr&quot; %}
 4609   ins_encode %{
 4610     __ str_32($src$$Register, $mem$$Address);
 4611   %}
 4612   ins_pipe(istore_mem_reg);
 4613 %}
 4614 #endif
 4615 
 4616 // Store Double
 4617 
 4618 
 4619 instruct storeD(memoryD mem, regD src) %{
 4620   match(Set mem (StoreD mem src));
 4621   ins_cost(MEMORY_REF_COST);
 4622 
 4623   size(4);
 4624   // FIXME: needs to be atomic, but  ARMv7 A.R.M. guarantees
 4625   // only LDREXD and STREXD are 64-bit single-copy atomic
 4626   format %{ &quot;FSTD   $src,$mem&quot; %}
 4627   ins_encode %{
 4628     __ str_double($src$$FloatRegister, $mem$$Address);
 4629   %}
 4630   ins_pipe(fstoreD_mem_reg);
 4631 %}
 4632 
 4633 
 4634 // Store Float
 4635 
 4636 
 4637 instruct storeF( memoryF mem, regF src) %{
 4638   match(Set mem (StoreF mem src));
 4639   ins_cost(MEMORY_REF_COST);
 4640 
 4641   size(4);
 4642   format %{ &quot;FSTS    $src,$mem&quot; %}
 4643   ins_encode %{
 4644     __ str_float($src$$FloatRegister, $mem$$Address);
 4645   %}
 4646   ins_pipe(fstoreF_mem_reg);
 4647 %}
 4648 
 4649 
 4650 //----------MemBar Instructions-----------------------------------------------
 4651 // Memory barrier flavors
 4652 
 4653 // pattern-match out unnecessary membars
 4654 instruct membar_storestore() %{
 4655   match(MemBarStoreStore);
 4656   ins_cost(4*MEMORY_REF_COST);
 4657 
 4658   size(4);
 4659   format %{ &quot;MEMBAR-storestore&quot; %}
 4660   ins_encode %{
 4661     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::StoreStore), noreg);
 4662   %}
 4663   ins_pipe(long_memory_op);
 4664 %}
 4665 
 4666 instruct membar_acquire() %{
 4667   match(MemBarAcquire);
 4668   match(LoadFence);
 4669   ins_cost(4*MEMORY_REF_COST);
 4670 
 4671   size(4);
 4672   format %{ &quot;MEMBAR-acquire&quot; %}
 4673   ins_encode %{
 4674     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::LoadLoad | MacroAssembler::LoadStore), noreg);
 4675   %}
 4676   ins_pipe(long_memory_op);
 4677 %}
 4678 
 4679 instruct membar_acquire_lock() %{
 4680   match(MemBarAcquireLock);
 4681   ins_cost(0);
 4682 
 4683   size(0);
 4684   format %{ &quot;!MEMBAR-acquire (CAS in prior FastLock so empty encoding)&quot; %}
 4685   ins_encode( );
 4686   ins_pipe(empty);
 4687 %}
 4688 
 4689 instruct membar_release() %{
 4690   match(MemBarRelease);
 4691   match(StoreFence);
 4692   ins_cost(4*MEMORY_REF_COST);
 4693 
 4694   size(4);
 4695   format %{ &quot;MEMBAR-release&quot; %}
 4696   ins_encode %{
 4697     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::StoreStore | MacroAssembler::LoadStore), noreg);
 4698   %}
 4699   ins_pipe(long_memory_op);
 4700 %}
 4701 
 4702 instruct membar_release_lock() %{
 4703   match(MemBarReleaseLock);
 4704   ins_cost(0);
 4705 
 4706   size(0);
 4707   format %{ &quot;!MEMBAR-release (CAS in succeeding FastUnlock so empty encoding)&quot; %}
 4708   ins_encode( );
 4709   ins_pipe(empty);
 4710 %}
 4711 
 4712 instruct membar_volatile() %{
 4713   match(MemBarVolatile);
 4714   ins_cost(4*MEMORY_REF_COST);
 4715 
 4716   size(4);
 4717   format %{ &quot;MEMBAR-volatile&quot; %}
 4718   ins_encode %{
 4719     __ membar(MacroAssembler::StoreLoad, noreg);
 4720   %}
 4721   ins_pipe(long_memory_op);
 4722 %}
 4723 
 4724 instruct unnecessary_membar_volatile() %{
 4725   match(MemBarVolatile);
 4726   predicate(Matcher::post_store_load_barrier(n));
 4727   ins_cost(0);
 4728 
 4729   size(0);
 4730   format %{ &quot;!MEMBAR-volatile (unnecessary so empty encoding)&quot; %}
 4731   ins_encode( );
 4732   ins_pipe(empty);
 4733 %}
 4734 
 4735 //----------Register Move Instructions-----------------------------------------
 4736 // instruct roundDouble_nop(regD dst) %{
 4737 //   match(Set dst (RoundDouble dst));
 4738 //   ins_pipe(empty);
 4739 // %}
 4740 
 4741 
 4742 // instruct roundFloat_nop(regF dst) %{
 4743 //   match(Set dst (RoundFloat dst));
 4744 //   ins_pipe(empty);
 4745 // %}
 4746 
 4747 
 4748 
 4749 // Cast Index to Pointer for unsafe natives
 4750 instruct castX2P(iRegX src, iRegP dst) %{
 4751   match(Set dst (CastX2P src));
 4752 
 4753   format %{ &quot;MOV    $dst,$src\t! IntX-&gt;Ptr if $dst != $src&quot; %}
 4754   ins_encode %{
 4755     if ($dst$$Register !=  $src$$Register) {
 4756       __ mov($dst$$Register, $src$$Register);
 4757     }
 4758   %}
 4759   ins_pipe(ialu_reg);
 4760 %}
 4761 
 4762 // Cast Pointer to Index for unsafe natives
 4763 instruct castP2X(iRegP src, iRegX dst) %{
 4764   match(Set dst (CastP2X src));
 4765 
 4766   format %{ &quot;MOV    $dst,$src\t! Ptr-&gt;IntX if $dst != $src&quot; %}
 4767   ins_encode %{
 4768     if ($dst$$Register !=  $src$$Register) {
 4769       __ mov($dst$$Register, $src$$Register);
 4770     }
 4771   %}
 4772   ins_pipe(ialu_reg);
 4773 %}
 4774 
 4775 //----------Conditional Move---------------------------------------------------
 4776 // Conditional move
 4777 instruct cmovIP_reg(cmpOpP cmp, flagsRegP pcc, iRegI dst, iRegI src) %{
 4778   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4779   ins_cost(150);
 4780   size(4);
 4781   format %{ &quot;MOV$cmp  $dst,$src\t! int&quot; %}
 4782   ins_encode %{
 4783     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4784   %}
 4785   ins_pipe(ialu_reg);
 4786 %}
 4787 
 4788 
 4789 instruct cmovIP_immMov(cmpOpP cmp, flagsRegP pcc, iRegI dst, immIMov src) %{
 4790   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4791   ins_cost(140);
 4792   size(4);
 4793   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4794   ins_encode %{
 4795     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4796   %}
 4797   ins_pipe(ialu_imm);
 4798 %}
 4799 
 4800 instruct cmovIP_imm16(cmpOpP cmp, flagsRegP pcc, iRegI dst, immI16 src) %{
 4801   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4802   ins_cost(140);
 4803   size(4);
 4804   format %{ &quot;MOVw$cmp  $dst,$src&quot; %}
 4805   ins_encode %{
 4806     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4807   %}
 4808   ins_pipe(ialu_imm);
 4809 %}
 4810 
 4811 instruct cmovI_reg(cmpOp cmp, flagsReg icc, iRegI dst, iRegI src) %{
 4812   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4813   ins_cost(150);
 4814   size(4);
 4815   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4816   ins_encode %{
 4817     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4818   %}
 4819   ins_pipe(ialu_reg);
 4820 %}
 4821 
 4822 
 4823 instruct cmovI_immMov(cmpOp cmp, flagsReg icc, iRegI dst, immIMov src) %{
 4824   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4825   ins_cost(140);
 4826   size(4);
 4827   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4828   ins_encode %{
 4829     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4830   %}
 4831   ins_pipe(ialu_imm);
 4832 %}
 4833 
 4834 instruct cmovII_imm16(cmpOp cmp, flagsReg icc, iRegI dst, immI16 src) %{
 4835   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4836   ins_cost(140);
 4837   size(4);
 4838   format %{ &quot;MOVw$cmp  $dst,$src&quot; %}
 4839   ins_encode %{
 4840     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4841   %}
 4842   ins_pipe(ialu_imm);
 4843 %}
 4844 
 4845 instruct cmovII_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, iRegI src) %{
 4846   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4847   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4848             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4849             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4850             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4851   ins_cost(150);
 4852   size(4);
 4853   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4854   ins_encode %{
 4855     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4856   %}
 4857   ins_pipe(ialu_reg);
 4858 %}
 4859 
 4860 instruct cmovII_immMov_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, immIMov src) %{
 4861   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4862   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4863             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4864             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4865             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4866   ins_cost(140);
 4867   size(4);
 4868   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4869   ins_encode %{
 4870     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4871   %}
 4872   ins_pipe(ialu_imm);
 4873 %}
 4874 
 4875 instruct cmovII_imm16_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, immI16 src) %{
 4876   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4877   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4878             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4879             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4880             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4881   ins_cost(140);
 4882   size(4);
 4883   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 4884   ins_encode %{
 4885     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4886   %}
 4887   ins_pipe(ialu_imm);
 4888 %}
 4889 
 4890 instruct cmovIIu_reg(cmpOpU cmp, flagsRegU icc, iRegI dst, iRegI src) %{
 4891   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4892   ins_cost(150);
 4893   size(4);
 4894   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4895   ins_encode %{
 4896     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4897   %}
 4898   ins_pipe(ialu_reg);
 4899 %}
 4900 
 4901 instruct cmovIIu_immMov(cmpOpU cmp, flagsRegU icc, iRegI dst, immIMov src) %{
 4902   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4903   ins_cost(140);
 4904   size(4);
 4905   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4906   ins_encode %{
 4907     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4908   %}
 4909   ins_pipe(ialu_imm);
 4910 %}
 4911 
 4912 instruct cmovIIu_imm16(cmpOpU cmp, flagsRegU icc, iRegI dst, immI16 src) %{
 4913   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4914   ins_cost(140);
 4915   size(4);
 4916   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 4917   ins_encode %{
 4918     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4919   %}
 4920   ins_pipe(ialu_imm);
 4921 %}
 4922 
 4923 // Conditional move
 4924 instruct cmovPP_reg(cmpOpP cmp, flagsRegP pcc, iRegP dst, iRegP src) %{
 4925   match(Set dst (CMoveP (Binary cmp pcc) (Binary dst src)));
 4926   ins_cost(150);
 4927   size(4);
 4928   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4929   ins_encode %{
 4930     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4931   %}
 4932   ins_pipe(ialu_reg);
 4933 %}
 4934 
 4935 instruct cmovPP_imm(cmpOpP cmp, flagsRegP pcc, iRegP dst, immP0 src) %{
 4936   match(Set dst (CMoveP (Binary cmp pcc) (Binary dst src)));
 4937   ins_cost(140);
 4938   size(4);
 4939   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4940   ins_encode %{
 4941     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4942   %}
 4943   ins_pipe(ialu_imm);
 4944 %}
 4945 
 4946 // This instruction also works with CmpN so we don&#39;t need cmovPN_reg.
 4947 instruct cmovPI_reg(cmpOp cmp, flagsReg icc, iRegP dst, iRegP src) %{
 4948   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4949   ins_cost(150);
 4950 
 4951   size(4);
 4952   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4953   ins_encode %{
 4954     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4955   %}
 4956   ins_pipe(ialu_reg);
 4957 %}
 4958 
 4959 instruct cmovPI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegP dst, iRegP src) %{
 4960   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4961   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4962             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4963             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4964             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4965   ins_cost(150);
 4966 
 4967   size(4);
 4968   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4969   ins_encode %{
 4970     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4971   %}
 4972   ins_pipe(ialu_reg);
 4973 %}
 4974 
 4975 instruct cmovPIu_reg(cmpOpU cmp, flagsRegU icc, iRegP dst, iRegP src) %{
 4976   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4977   ins_cost(150);
 4978 
 4979   size(4);
 4980   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4981   ins_encode %{
 4982     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4983   %}
 4984   ins_pipe(ialu_reg);
 4985 %}
 4986 
 4987 instruct cmovPI_imm(cmpOp cmp, flagsReg icc, iRegP dst, immP0 src) %{
 4988   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4989   ins_cost(140);
 4990 
 4991   size(4);
 4992   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4993   ins_encode %{
 4994     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4995   %}
 4996   ins_pipe(ialu_imm);
 4997 %}
 4998 
 4999 instruct cmovPI_imm_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegP dst, immP0 src) %{
 5000   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 5001   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5002             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5003             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5004             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5005   ins_cost(140);
 5006 
 5007   size(4);
 5008   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 5009   ins_encode %{
 5010     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5011   %}
 5012   ins_pipe(ialu_imm);
 5013 %}
 5014 
 5015 instruct cmovPIu_imm(cmpOpU cmp, flagsRegU icc, iRegP dst, immP0 src) %{
 5016   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 5017   ins_cost(140);
 5018 
 5019   size(4);
 5020   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 5021   ins_encode %{
 5022     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5023   %}
 5024   ins_pipe(ialu_imm);
 5025 %}
 5026 
 5027 
 5028 // Conditional move
 5029 instruct cmovFP_reg(cmpOpP cmp, flagsRegP pcc, regF dst, regF src) %{
 5030   match(Set dst (CMoveF (Binary cmp pcc) (Binary dst src)));
 5031   ins_cost(150);
 5032   size(4);
 5033   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5034   ins_encode %{
 5035     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5036   %}
 5037   ins_pipe(int_conditional_float_move);
 5038 %}
 5039 
 5040 instruct cmovFI_reg(cmpOp cmp, flagsReg icc, regF dst, regF src) %{
 5041   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5042   ins_cost(150);
 5043 
 5044   size(4);
 5045   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5046   ins_encode %{
 5047     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5048   %}
 5049   ins_pipe(int_conditional_float_move);
 5050 %}
 5051 
 5052 instruct cmovFI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, regF dst, regF src) %{
 5053   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5054   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5055             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5056             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5057             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5058   ins_cost(150);
 5059 
 5060   size(4);
 5061   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5062   ins_encode %{
 5063     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5064   %}
 5065   ins_pipe(int_conditional_float_move);
 5066 %}
 5067 
 5068 instruct cmovFIu_reg(cmpOpU cmp, flagsRegU icc, regF dst, regF src) %{
 5069   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5070   ins_cost(150);
 5071 
 5072   size(4);
 5073   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5074   ins_encode %{
 5075     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5076   %}
 5077   ins_pipe(int_conditional_float_move);
 5078 %}
 5079 
 5080 // Conditional move
 5081 instruct cmovDP_reg(cmpOpP cmp, flagsRegP pcc, regD dst, regD src) %{
 5082   match(Set dst (CMoveD (Binary cmp pcc) (Binary dst src)));
 5083   ins_cost(150);
 5084   size(4);
 5085   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5086   ins_encode %{
 5087     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5088   %}
 5089   ins_pipe(int_conditional_double_move);
 5090 %}
 5091 
 5092 instruct cmovDI_reg(cmpOp cmp, flagsReg icc, regD dst, regD src) %{
 5093   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5094   ins_cost(150);
 5095 
 5096   size(4);
 5097   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5098   ins_encode %{
 5099     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5100   %}
 5101   ins_pipe(int_conditional_double_move);
 5102 %}
 5103 
 5104 instruct cmovDI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, regD dst, regD src) %{
 5105   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5106   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5107   ins_cost(150);
 5108 
 5109   size(4);
 5110   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5111   ins_encode %{
 5112     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5113   %}
 5114   ins_pipe(int_conditional_double_move);
 5115 %}
 5116 
 5117 instruct cmovDIu_reg(cmpOpU cmp, flagsRegU icc, regD dst, regD src) %{
 5118   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5119   ins_cost(150);
 5120 
 5121   size(4);
 5122   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5123   ins_encode %{
 5124     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5125   %}
 5126   ins_pipe(int_conditional_double_move);
 5127 %}
 5128 
 5129 // Conditional move
 5130 instruct cmovLP_reg(cmpOpP cmp, flagsRegP pcc, iRegL dst, iRegL src) %{
 5131   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5132   ins_cost(150);
 5133 
 5134   size(8);
 5135   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5136             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5137   ins_encode %{
 5138     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5139     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5140   %}
 5141   ins_pipe(ialu_reg);
 5142 %}
 5143 
 5144 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5145 // (hi($con$$constant), lo($con$$constant)) becomes
 5146 instruct cmovLP_immRot(cmpOpP cmp, flagsRegP pcc, iRegL dst, immLlowRot src) %{
 5147   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5148   ins_cost(140);
 5149 
 5150   size(8);
 5151   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5152             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5153   ins_encode %{
 5154     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5155     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5156   %}
 5157   ins_pipe(ialu_imm);
 5158 %}
 5159 
 5160 instruct cmovLP_imm16(cmpOpP cmp, flagsRegP pcc, iRegL dst, immL16 src) %{
 5161   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5162   ins_cost(140);
 5163 
 5164   size(8);
 5165   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5166             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5167   ins_encode %{
 5168     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5169     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5170   %}
 5171   ins_pipe(ialu_imm);
 5172 %}
 5173 
 5174 instruct cmovLI_reg(cmpOp cmp, flagsReg icc, iRegL dst, iRegL src) %{
 5175   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5176   ins_cost(150);
 5177 
 5178   size(8);
 5179   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5180             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5181   ins_encode %{
 5182     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5183     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5184   %}
 5185   ins_pipe(ialu_reg);
 5186 %}
 5187 
 5188 instruct cmovLI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, iRegL src) %{
 5189   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5190   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5191             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5192             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5193             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5194   ins_cost(150);
 5195 
 5196   size(8);
 5197   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5198             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5199   ins_encode %{
 5200     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5201     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5202   %}
 5203   ins_pipe(ialu_reg);
 5204 %}
 5205 
 5206 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5207 // (hi($con$$constant), lo($con$$constant)) becomes
 5208 instruct cmovLI_immRot(cmpOp cmp, flagsReg icc, iRegL dst, immLlowRot src) %{
 5209   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5210   ins_cost(140);
 5211 
 5212   size(8);
 5213   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5214             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5215   ins_encode %{
 5216     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5217     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5218   %}
 5219   ins_pipe(ialu_imm);
 5220 %}
 5221 
 5222 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5223 // (hi($con$$constant), lo($con$$constant)) becomes
 5224 instruct cmovLI_immRot_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, immLlowRot src) %{
 5225   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5226   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5227             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5228             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5229             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5230   ins_cost(140);
 5231 
 5232   size(8);
 5233   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5234             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5235   ins_encode %{
 5236     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5237     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5238   %}
 5239   ins_pipe(ialu_imm);
 5240 %}
 5241 
 5242 instruct cmovLI_imm16(cmpOp cmp, flagsReg icc, iRegL dst, immL16 src) %{
 5243   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5244   ins_cost(140);
 5245 
 5246   size(8);
 5247   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5248             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5249   ins_encode %{
 5250     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5251     __ movw($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5252   %}
 5253   ins_pipe(ialu_imm);
 5254 %}
 5255 
 5256 instruct cmovLI_imm16_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, immL16 src) %{
 5257   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5258   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5259             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5260             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5261             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5262   ins_cost(140);
 5263 
 5264   size(8);
 5265   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5266             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5267   ins_encode %{
 5268     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5269     __ movw($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5270   %}
 5271   ins_pipe(ialu_imm);
 5272 %}
 5273 
 5274 instruct cmovLIu_reg(cmpOpU cmp, flagsRegU icc, iRegL dst, iRegL src) %{
 5275   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5276   ins_cost(150);
 5277 
 5278   size(8);
 5279   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5280             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5281   ins_encode %{
 5282     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5283     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5284   %}
 5285   ins_pipe(ialu_reg);
 5286 %}
 5287 
 5288 
 5289 //----------OS and Locking Instructions----------------------------------------
 5290 
 5291 // This name is KNOWN by the ADLC and cannot be changed.
 5292 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
 5293 // for this guy.
 5294 instruct tlsLoadP(RthreadRegP dst) %{
 5295   match(Set dst (ThreadLocal));
 5296 
 5297   size(0);
 5298   ins_cost(0);
 5299   format %{ &quot;! TLS is in $dst&quot; %}
 5300   ins_encode( /*empty encoding*/ );
 5301   ins_pipe(ialu_none);
 5302 %}
 5303 
 5304 instruct checkCastPP( iRegP dst ) %{
 5305   match(Set dst (CheckCastPP dst));
 5306 
 5307   size(0);
 5308   format %{ &quot;! checkcastPP of $dst&quot; %}
 5309   ins_encode( /*empty encoding*/ );
 5310   ins_pipe(empty);
 5311 %}
 5312 
 5313 
 5314 instruct castPP( iRegP dst ) %{
 5315   match(Set dst (CastPP dst));
 5316   format %{ &quot;! castPP of $dst&quot; %}
 5317   ins_encode( /*empty encoding*/ );
 5318   ins_pipe(empty);
 5319 %}
 5320 
 5321 instruct castII( iRegI dst ) %{
 5322   match(Set dst (CastII dst));
 5323   format %{ &quot;! castII of $dst&quot; %}
 5324   ins_encode( /*empty encoding*/ );
 5325   ins_cost(0);
 5326   ins_pipe(empty);
 5327 %}
 5328 
 5329 instruct castLL( iRegL dst ) %{
 5330   match(Set dst (CastLL dst));
 5331   format %{ &quot;! castLL of $dst&quot; %}
 5332   ins_encode( /*empty encoding*/ );
 5333   ins_cost(0);
 5334   ins_pipe(empty);
 5335 %}
 5336 
 5337 //----------Arithmetic Instructions--------------------------------------------
 5338 // Addition Instructions
 5339 // Register Addition
 5340 instruct addI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 5341   match(Set dst (AddI src1 src2));
 5342 
 5343   size(4);
 5344   format %{ &quot;add_32 $dst,$src1,$src2\t! int&quot; %}
 5345   ins_encode %{
 5346     __ add_32($dst$$Register, $src1$$Register, $src2$$Register);
 5347   %}
 5348   ins_pipe(ialu_reg_reg);
 5349 %}
 5350 
 5351 instruct addshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5352   match(Set dst (AddI (LShiftI src1 src2) src3));
 5353 
 5354   size(4);
 5355   format %{ &quot;add_32 $dst,$src3,$src1&lt;&lt;$src2\t! int&quot; %}
 5356   ins_encode %{
 5357     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 5358   %}
 5359   ins_pipe(ialu_reg_reg);
 5360 %}
 5361 
 5362 
 5363 instruct addshlI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5364   match(Set dst (AddI (LShiftI src1 src2) src3));
 5365 
 5366   size(4);
 5367   format %{ &quot;add_32 $dst,$src3,$src1&lt;&lt;$src2\t! int&quot; %}
 5368   ins_encode %{
 5369     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 5370   %}
 5371   ins_pipe(ialu_reg_reg);
 5372 %}
 5373 
 5374 instruct addsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5375   match(Set dst (AddI (RShiftI src1 src2) src3));
 5376 
 5377   size(4);
 5378   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;$src2\t! int&quot; %}
 5379   ins_encode %{
 5380     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 5381   %}
 5382   ins_pipe(ialu_reg_reg);
 5383 %}
 5384 
 5385 instruct addsarI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5386   match(Set dst (AddI (RShiftI src1 src2) src3));
 5387 
 5388   size(4);
 5389   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;$src2\t! int&quot; %}
 5390   ins_encode %{
 5391     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 5392   %}
 5393   ins_pipe(ialu_reg_reg);
 5394 %}
 5395 
 5396 instruct addshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5397   match(Set dst (AddI (URShiftI src1 src2) src3));
 5398 
 5399   size(4);
 5400   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;&gt;$src2\t! int&quot; %}
 5401   ins_encode %{
 5402     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 5403   %}
 5404   ins_pipe(ialu_reg_reg);
 5405 %}
 5406 
 5407 instruct addshrI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5408   match(Set dst (AddI (URShiftI src1 src2) src3));
 5409 
 5410   size(4);
 5411   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;&gt;$src2\t! int&quot; %}
 5412   ins_encode %{
 5413     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 5414   %}
 5415   ins_pipe(ialu_reg_reg);
 5416 %}
 5417 
 5418 // Immediate Addition
 5419 instruct addI_reg_aimmI(iRegI dst, iRegI src1, aimmI src2) %{
 5420   match(Set dst (AddI src1 src2));
 5421 
 5422   size(4);
 5423   format %{ &quot;add_32 $dst,$src1,$src2\t! int&quot; %}
 5424   ins_encode %{
 5425     __ add_32($dst$$Register, $src1$$Register, $src2$$constant);
 5426   %}
 5427   ins_pipe(ialu_reg_imm);
 5428 %}
 5429 
 5430 // Pointer Register Addition
 5431 instruct addP_reg_reg(iRegP dst, iRegP src1, iRegX src2) %{
 5432   match(Set dst (AddP src1 src2));
 5433 
 5434   size(4);
 5435   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5436   ins_encode %{
 5437     __ add($dst$$Register, $src1$$Register, $src2$$Register);
 5438   %}
 5439   ins_pipe(ialu_reg_reg);
 5440 %}
 5441 
 5442 
 5443 // shifted iRegX operand
 5444 operand shiftedX(iRegX src2, shimmX src3) %{
 5445 //constraint(ALLOC_IN_RC(sp_ptr_reg));
 5446   match(LShiftX src2 src3);
 5447 
 5448   op_cost(1);
 5449   format %{ &quot;$src2 &lt;&lt; $src3&quot; %}
 5450   interface(MEMORY_INTER) %{
 5451     base($src2);
 5452     index(0xff);
 5453     scale($src3);
 5454     disp(0x0);
 5455   %}
 5456 %}
 5457 
 5458 instruct addshlP_reg_reg_imm(iRegP dst, iRegP src1, shiftedX src2) %{
 5459   match(Set dst (AddP src1 src2));
 5460 
 5461   ins_cost(DEFAULT_COST * 3/2);
 5462   size(4);
 5463   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5464   ins_encode %{
 5465     Register base = reg_to_register_object($src2$$base);
 5466     __ add($dst$$Register, $src1$$Register, AsmOperand(base, lsl, $src2$$scale));
 5467   %}
 5468   ins_pipe(ialu_reg_reg);
 5469 %}
 5470 
 5471 // Pointer Immediate Addition
 5472 instruct addP_reg_aimmX(iRegP dst, iRegP src1, aimmX src2) %{
 5473   match(Set dst (AddP src1 src2));
 5474 
 5475   size(4);
 5476   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5477   ins_encode %{
 5478     __ add($dst$$Register, $src1$$Register, $src2$$constant);
 5479   %}
 5480   ins_pipe(ialu_reg_imm);
 5481 %}
 5482 
 5483 // Long Addition
 5484 instruct addL_reg_reg(iRegL dst, iRegL src1, iRegL src2, flagsReg ccr) %{
 5485   match(Set dst (AddL src1 src2));
 5486   effect(KILL ccr);
 5487   size(8);
 5488   format %{ &quot;ADDS    $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 5489             &quot;ADC     $dst.hi,$src1.hi,$src2.hi&quot; %}
 5490   ins_encode %{
 5491     __ adds($dst$$Register, $src1$$Register, $src2$$Register);
 5492     __ adc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 5493   %}
 5494   ins_pipe(ialu_reg_reg);
 5495 %}
 5496 
 5497 // TODO
 5498 
 5499 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5500 // (hi($con$$constant), lo($con$$constant)) becomes
 5501 instruct addL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con, flagsReg ccr) %{
 5502   match(Set dst (AddL src1 con));
 5503   effect(KILL ccr);
 5504   size(8);
 5505   format %{ &quot;ADDS    $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 5506             &quot;ADC     $dst.hi,$src1.hi,0&quot; %}
 5507   ins_encode %{
 5508     __ adds($dst$$Register, $src1$$Register, $con$$constant);
 5509     __ adc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 5510   %}
 5511   ins_pipe(ialu_reg_imm);
 5512 %}
 5513 
 5514 //----------Conditional_store--------------------------------------------------
 5515 // Conditional-store of the updated heap-top.
 5516 // Used during allocation of the shared heap.
 5517 // Sets flags (EQ) on success.
 5518 
 5519 // LoadP-locked.
 5520 instruct loadPLocked(iRegP dst, memoryex mem) %{
 5521   match(Set dst (LoadPLocked mem));
 5522   size(4);
 5523   format %{ &quot;LDREX  $dst,$mem&quot; %}
 5524   ins_encode %{
 5525     __ ldrex($dst$$Register,$mem$$Address);
 5526   %}
 5527   ins_pipe(iload_mem);
 5528 %}
 5529 
 5530 instruct storePConditional( memoryex heap_top_ptr, iRegP oldval, iRegP newval, iRegI tmp, flagsRegP pcc ) %{
 5531   predicate(_kids[1]-&gt;_kids[0]-&gt;_leaf-&gt;Opcode() == Op_LoadPLocked); // only works in conjunction with a LoadPLocked node
 5532   match(Set pcc (StorePConditional heap_top_ptr (Binary oldval newval)));
 5533   effect( TEMP tmp );
 5534   size(8);
 5535   format %{ &quot;STREX  $tmp,$newval,$heap_top_ptr\n\t&quot;
 5536             &quot;CMP    $tmp, 0&quot; %}
 5537   ins_encode %{
 5538     __ strex($tmp$$Register, $newval$$Register, $heap_top_ptr$$Address);
 5539     __ cmp($tmp$$Register, 0);
 5540   %}
 5541   ins_pipe( long_memory_op );
 5542 %}
 5543 
 5544 // Conditional-store of an intx value.
 5545 instruct storeXConditional( memoryex mem, iRegX oldval, iRegX newval, iRegX tmp, flagsReg icc ) %{
 5546   match(Set icc (StoreIConditional mem (Binary oldval newval)));
 5547   effect( TEMP tmp );
 5548   size(28);
 5549   format %{ &quot;loop: \n\t&quot;
 5550             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem], DOESN&#39;T set $newval=[$mem] in any case\n\t&quot;
 5551             &quot;XORS     $tmp,$tmp, $oldval\n\t&quot;
 5552             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5553             &quot;CMP.eq   $tmp, 1 \n\t&quot;
 5554             &quot;B.eq     loop \n\t&quot;
 5555             &quot;TEQ      $tmp, 0\n\t&quot;
 5556             &quot;membar   LoadStore|LoadLoad&quot; %}
 5557   ins_encode %{
 5558     Label loop;
 5559     __ bind(loop);
 5560     __ ldrex($tmp$$Register, $mem$$Address);
 5561     __ eors($tmp$$Register, $tmp$$Register, $oldval$$Register);
 5562     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5563     __ cmp($tmp$$Register, 1, eq);
 5564     __ b(loop, eq);
 5565     __ teq($tmp$$Register, 0);
 5566     // used by biased locking only. Requires a membar.
 5567     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::LoadStore | MacroAssembler::LoadLoad), noreg);
 5568   %}
 5569   ins_pipe( long_memory_op );
 5570 %}
 5571 
 5572 // No flag versions for CompareAndSwap{P,I,L} because matcher can&#39;t match them
 5573 
 5574 instruct compareAndSwapL_bool(memoryex mem, iRegL oldval, iRegLd newval, iRegI res, iRegLd tmp, flagsReg ccr ) %{
 5575   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 5576   effect( KILL ccr, TEMP tmp);
 5577   size(32);
 5578   format %{ &quot;loop: \n\t&quot;
 5579             &quot;LDREXD   $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5580             &quot;CMP      $tmp.lo, $oldval.lo\n\t&quot;
 5581             &quot;CMP.eq   $tmp.hi, $oldval.hi\n\t&quot;
 5582             &quot;STREXD.eq $tmp, $newval, $mem\n\t&quot;
 5583             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5584             &quot;XORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5585             &quot;B.eq     loop \n\t&quot;
 5586             &quot;MOV      $res, $tmp&quot; %}
 5587   ins_encode %{
 5588     Label loop;
 5589     __ bind(loop);
 5590     __ ldrexd($tmp$$Register, $mem$$Address);
 5591     __ cmp($tmp$$Register, $oldval$$Register);
 5592     __ cmp($tmp$$Register-&gt;successor(), $oldval$$Register-&gt;successor(), eq);
 5593     __ strexd($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5594     __ mov($tmp$$Register, 0, ne);
 5595     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5596     __ b(loop, eq);
 5597     __ mov($res$$Register, $tmp$$Register);
 5598   %}
 5599   ins_pipe( long_memory_op );
 5600 %}
 5601 
 5602 
 5603 instruct compareAndSwapI_bool(memoryex mem, iRegI oldval, iRegI newval, iRegI res, iRegI tmp, flagsReg ccr ) %{
 5604   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 5605   effect( KILL ccr, TEMP tmp);
 5606   size(28);
 5607   format %{ &quot;loop: \n\t&quot;
 5608             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5609             &quot;CMP      $tmp, $oldval\n\t&quot;
 5610             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5611             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5612             &quot;XORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5613             &quot;B.eq     loop \n\t&quot;
 5614             &quot;MOV      $res, $tmp&quot; %}
 5615 
 5616   ins_encode %{
 5617     Label loop;
 5618     __ bind(loop);
 5619     __ ldrex($tmp$$Register,$mem$$Address);
 5620     __ cmp($tmp$$Register, $oldval$$Register);
 5621     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5622     __ mov($tmp$$Register, 0, ne);
 5623     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5624     __ b(loop, eq);
 5625     __ mov($res$$Register, $tmp$$Register);
 5626   %}
 5627   ins_pipe( long_memory_op );
 5628 %}
 5629 
 5630 instruct compareAndSwapP_bool(memoryex mem, iRegP oldval, iRegP newval, iRegI res, iRegI tmp, flagsReg ccr ) %{
 5631   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 5632   effect( KILL ccr, TEMP tmp);
 5633   size(28);
 5634   format %{ &quot;loop: \n\t&quot;
 5635             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5636             &quot;CMP      $tmp, $oldval\n\t&quot;
 5637             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5638             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5639             &quot;EORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5640             &quot;B.eq     loop \n\t&quot;
 5641             &quot;MOV      $res, $tmp&quot; %}
 5642 
 5643   ins_encode %{
 5644     Label loop;
 5645     __ bind(loop);
 5646     __ ldrex($tmp$$Register,$mem$$Address);
 5647     __ cmp($tmp$$Register, $oldval$$Register);
 5648     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5649     __ mov($tmp$$Register, 0, ne);
 5650     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5651     __ b(loop, eq);
 5652     __ mov($res$$Register, $tmp$$Register);
 5653   %}
 5654   ins_pipe( long_memory_op );
 5655 %}
 5656 
 5657 instruct xaddI_aimmI_no_res(memoryex mem, aimmI add, Universe dummy, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5658   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5659   match(Set dummy (GetAndAddI mem add));
 5660   effect(KILL ccr, TEMP tmp1, TEMP tmp2);
 5661   size(20);
 5662   format %{ &quot;loop: \n\t&quot;
 5663             &quot;LDREX    $tmp1, $mem\n\t&quot;
 5664             &quot;ADD      $tmp1, $tmp1, $add\n\t&quot;
 5665             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5666             &quot;CMP      $tmp2, 0 \n\t&quot;
 5667             &quot;B.ne     loop \n\t&quot; %}
 5668 
 5669   ins_encode %{
 5670     Label loop;
 5671     __ bind(loop);
 5672     __ ldrex($tmp1$$Register,$mem$$Address);
 5673     __ add($tmp1$$Register, $tmp1$$Register, $add$$constant);
 5674     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5675     __ cmp($tmp2$$Register, 0);
 5676     __ b(loop, ne);
 5677   %}
 5678   ins_pipe( long_memory_op );
 5679 %}
 5680 
 5681 instruct xaddI_reg_no_res(memoryex mem, iRegI add, Universe dummy, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5682   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5683   match(Set dummy (GetAndAddI mem add));
 5684   effect(KILL ccr, TEMP tmp1, TEMP tmp2);
 5685   size(20);
 5686   format %{ &quot;loop: \n\t&quot;
 5687             &quot;LDREX    $tmp1, $mem\n\t&quot;
 5688             &quot;ADD      $tmp1, $tmp1, $add\n\t&quot;
 5689             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5690             &quot;CMP      $tmp2, 0 \n\t&quot;
 5691             &quot;B.ne     loop \n\t&quot; %}
 5692 
 5693   ins_encode %{
 5694     Label loop;
 5695     __ bind(loop);
 5696     __ ldrex($tmp1$$Register,$mem$$Address);
 5697     __ add($tmp1$$Register, $tmp1$$Register, $add$$Register);
 5698     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5699     __ cmp($tmp2$$Register, 0);
 5700     __ b(loop, ne);
 5701   %}
 5702   ins_pipe( long_memory_op );
 5703 %}
 5704 
 5705 instruct xaddI_aimmI(memoryex mem, aimmI add, iRegI res, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5706   match(Set res (GetAndAddI mem add));
 5707   effect(KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5708   size(20);
 5709   format %{ &quot;loop: \n\t&quot;
 5710             &quot;LDREX    $res, $mem\n\t&quot;
 5711             &quot;ADD      $tmp1, $res, $add\n\t&quot;
 5712             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5713             &quot;CMP      $tmp2, 0 \n\t&quot;
 5714             &quot;B.ne     loop \n\t&quot; %}
 5715 
 5716   ins_encode %{
 5717     Label loop;
 5718     __ bind(loop);
 5719     __ ldrex($res$$Register,$mem$$Address);
 5720     __ add($tmp1$$Register, $res$$Register, $add$$constant);
 5721     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5722     __ cmp($tmp2$$Register, 0);
 5723     __ b(loop, ne);
 5724   %}
 5725   ins_pipe( long_memory_op );
 5726 %}
 5727 
 5728 instruct xaddI_reg(memoryex mem, iRegI add, iRegI res, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5729   match(Set res (GetAndAddI mem add));
 5730   effect(KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5731   size(20);
 5732   format %{ &quot;loop: \n\t&quot;
 5733             &quot;LDREX    $res, $mem\n\t&quot;
 5734             &quot;ADD      $tmp1, $res, $add\n\t&quot;
 5735             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5736             &quot;CMP      $tmp2, 0 \n\t&quot;
 5737             &quot;B.ne     loop \n\t&quot; %}
 5738 
 5739   ins_encode %{
 5740     Label loop;
 5741     __ bind(loop);
 5742     __ ldrex($res$$Register,$mem$$Address);
 5743     __ add($tmp1$$Register, $res$$Register, $add$$Register);
 5744     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5745     __ cmp($tmp2$$Register, 0);
 5746     __ b(loop, ne);
 5747   %}
 5748   ins_pipe( long_memory_op );
 5749 %}
 5750 
 5751 instruct xaddL_reg_no_res(memoryex mem, iRegL add, Universe dummy, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5752   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5753   match(Set dummy (GetAndAddL mem add));
 5754   effect( KILL ccr, TEMP tmp1, TEMP tmp2);
 5755   size(24);
 5756   format %{ &quot;loop: \n\t&quot;
 5757             &quot;LDREXD   $tmp1, $mem\n\t&quot;
 5758             &quot;ADDS     $tmp1.lo, $tmp1.lo, $add.lo\n\t&quot;
 5759             &quot;ADC      $tmp1.hi, $tmp1.hi, $add.hi\n\t&quot;
 5760             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5761             &quot;CMP      $tmp2, 0 \n\t&quot;
 5762             &quot;B.ne     loop \n\t&quot; %}
 5763 
 5764   ins_encode %{
 5765     Label loop;
 5766     __ bind(loop);
 5767     __ ldrexd($tmp1$$Register, $mem$$Address);
 5768     __ adds($tmp1$$Register, $tmp1$$Register, $add$$Register);
 5769     __ adc($tmp1$$Register-&gt;successor(), $tmp1$$Register-&gt;successor(), $add$$Register-&gt;successor());
 5770     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5771     __ cmp($tmp2$$Register, 0);
 5772     __ b(loop, ne);
 5773   %}
 5774   ins_pipe( long_memory_op );
 5775 %}
 5776 
 5777 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5778 // (hi($con$$constant), lo($con$$constant)) becomes
 5779 instruct xaddL_immRot_no_res(memoryex mem, immLlowRot add, Universe dummy, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5780   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5781   match(Set dummy (GetAndAddL mem add));
 5782   effect( KILL ccr, TEMP tmp1, TEMP tmp2);
 5783   size(24);
 5784   format %{ &quot;loop: \n\t&quot;
 5785             &quot;LDREXD   $tmp1, $mem\n\t&quot;
 5786             &quot;ADDS     $tmp1.lo, $tmp1.lo, $add\n\t&quot;
 5787             &quot;ADC      $tmp1.hi, $tmp1.hi, 0\n\t&quot;
 5788             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5789             &quot;CMP      $tmp2, 0 \n\t&quot;
 5790             &quot;B.ne     loop \n\t&quot; %}
 5791 
 5792   ins_encode %{
 5793     Label loop;
 5794     __ bind(loop);
 5795     __ ldrexd($tmp1$$Register, $mem$$Address);
 5796     __ adds($tmp1$$Register, $tmp1$$Register, $add$$constant);
 5797     __ adc($tmp1$$Register-&gt;successor(), $tmp1$$Register-&gt;successor(), 0);
 5798     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5799     __ cmp($tmp2$$Register, 0);
 5800     __ b(loop, ne);
 5801   %}
 5802   ins_pipe( long_memory_op );
 5803 %}
 5804 
 5805 instruct xaddL_reg(memoryex mem, iRegL add, iRegLd res, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5806   match(Set res (GetAndAddL mem add));
 5807   effect( KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5808   size(24);
 5809   format %{ &quot;loop: \n\t&quot;
 5810             &quot;LDREXD   $res, $mem\n\t&quot;
 5811             &quot;ADDS     $tmp1.lo, $res.lo, $add.lo\n\t&quot;
 5812             &quot;ADC      $tmp1.hi, $res.hi, $add.hi\n\t&quot;
 5813             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5814             &quot;CMP      $tmp2, 0 \n\t&quot;
 5815             &quot;B.ne     loop \n\t&quot; %}
 5816 
 5817   ins_encode %{
 5818     Label loop;
 5819     __ bind(loop);
 5820     __ ldrexd($res$$Register, $mem$$Address);
 5821     __ adds($tmp1$$Register, $res$$Register, $add$$Register);
 5822     __ adc($tmp1$$Register-&gt;successor(), $res$$Register-&gt;successor(), $add$$Register-&gt;successor());
 5823     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5824     __ cmp($tmp2$$Register, 0);
 5825     __ b(loop, ne);
 5826   %}
 5827   ins_pipe( long_memory_op );
 5828 %}
 5829 
 5830 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5831 // (hi($con$$constant), lo($con$$constant)) becomes
 5832 instruct xaddL_immRot(memoryex mem, immLlowRot add, iRegLd res, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5833   match(Set res (GetAndAddL mem add));
 5834   effect( KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5835   size(24);
 5836   format %{ &quot;loop: \n\t&quot;
 5837             &quot;LDREXD   $res, $mem\n\t&quot;
 5838             &quot;ADDS     $tmp1.lo, $res.lo, $add\n\t&quot;
 5839             &quot;ADC      $tmp1.hi, $res.hi, 0\n\t&quot;
 5840             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5841             &quot;CMP      $tmp2, 0 \n\t&quot;
 5842             &quot;B.ne     loop \n\t&quot; %}
 5843 
 5844   ins_encode %{
 5845     Label loop;
 5846     __ bind(loop);
 5847     __ ldrexd($res$$Register, $mem$$Address);
 5848     __ adds($tmp1$$Register, $res$$Register, $add$$constant);
 5849     __ adc($tmp1$$Register-&gt;successor(), $res$$Register-&gt;successor(), 0);
 5850     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5851     __ cmp($tmp2$$Register, 0);
 5852     __ b(loop, ne);
 5853   %}
 5854   ins_pipe( long_memory_op );
 5855 %}
 5856 
 5857 instruct xchgI(memoryex mem, iRegI newval, iRegI res, iRegI tmp, flagsReg ccr) %{
 5858   match(Set res (GetAndSetI mem newval));
 5859   effect(KILL ccr, TEMP tmp, TEMP res);
 5860   size(16);
 5861   format %{ &quot;loop: \n\t&quot;
 5862             &quot;LDREX    $res, $mem\n\t&quot;
 5863             &quot;STREX    $tmp, $newval, $mem\n\t&quot;
 5864             &quot;CMP      $tmp, 0 \n\t&quot;
 5865             &quot;B.ne     loop \n\t&quot; %}
 5866 
 5867   ins_encode %{
 5868     Label loop;
 5869     __ bind(loop);
 5870     __ ldrex($res$$Register,$mem$$Address);
 5871     __ strex($tmp$$Register, $newval$$Register, $mem$$Address);
 5872     __ cmp($tmp$$Register, 0);
 5873     __ b(loop, ne);
 5874   %}
 5875   ins_pipe( long_memory_op );
 5876 %}
 5877 
 5878 instruct xchgL(memoryex mem, iRegLd newval, iRegLd res, iRegI tmp, flagsReg ccr) %{
 5879   match(Set res (GetAndSetL mem newval));
 5880   effect( KILL ccr, TEMP tmp, TEMP res);
 5881   size(16);
 5882   format %{ &quot;loop: \n\t&quot;
 5883             &quot;LDREXD   $res, $mem\n\t&quot;
 5884             &quot;STREXD   $tmp, $newval, $mem\n\t&quot;
 5885             &quot;CMP      $tmp, 0 \n\t&quot;
 5886             &quot;B.ne     loop \n\t&quot; %}
 5887 
 5888   ins_encode %{
 5889     Label loop;
 5890     __ bind(loop);
 5891     __ ldrexd($res$$Register, $mem$$Address);
 5892     __ strexd($tmp$$Register, $newval$$Register, $mem$$Address);
 5893     __ cmp($tmp$$Register, 0);
 5894     __ b(loop, ne);
 5895   %}
 5896   ins_pipe( long_memory_op );
 5897 %}
 5898 
 5899 instruct xchgP(memoryex mem, iRegP newval, iRegP res, iRegI tmp, flagsReg ccr) %{
 5900   match(Set res (GetAndSetP mem newval));
 5901   effect(KILL ccr, TEMP tmp, TEMP res);
 5902   size(16);
 5903   format %{ &quot;loop: \n\t&quot;
 5904             &quot;LDREX    $res, $mem\n\t&quot;
 5905             &quot;STREX    $tmp, $newval, $mem\n\t&quot;
 5906             &quot;CMP      $tmp, 0 \n\t&quot;
 5907             &quot;B.ne     loop \n\t&quot; %}
 5908 
 5909   ins_encode %{
 5910     Label loop;
 5911     __ bind(loop);
 5912     __ ldrex($res$$Register,$mem$$Address);
 5913     __ strex($tmp$$Register, $newval$$Register, $mem$$Address);
 5914     __ cmp($tmp$$Register, 0);
 5915     __ b(loop, ne);
 5916   %}
 5917   ins_pipe( long_memory_op );
 5918 %}
 5919 
 5920 //---------------------
 5921 // Subtraction Instructions
 5922 // Register Subtraction
 5923 instruct subI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 5924   match(Set dst (SubI src1 src2));
 5925 
 5926   size(4);
 5927   format %{ &quot;sub_32 $dst,$src1,$src2\t! int&quot; %}
 5928   ins_encode %{
 5929     __ sub_32($dst$$Register, $src1$$Register, $src2$$Register);
 5930   %}
 5931   ins_pipe(ialu_reg_reg);
 5932 %}
 5933 
 5934 instruct subshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5935   match(Set dst (SubI src1 (LShiftI src2 src3)));
 5936 
 5937   size(4);
 5938   format %{ &quot;SUB    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 5939   ins_encode %{
 5940     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 5941   %}
 5942   ins_pipe(ialu_reg_reg);
 5943 %}
 5944 
 5945 instruct subshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5946   match(Set dst (SubI src1 (LShiftI src2 src3)));
 5947 
 5948   size(4);
 5949   format %{ &quot;sub_32 $dst,$src1,$src2&lt;&lt;$src3\t! int&quot; %}
 5950   ins_encode %{
 5951     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 5952   %}
 5953   ins_pipe(ialu_reg_reg);
 5954 %}
 5955 
 5956 instruct subsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5957   match(Set dst (SubI src1 (RShiftI src2 src3)));
 5958 
 5959   size(4);
 5960   format %{ &quot;SUB    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 5961   ins_encode %{
 5962     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 5963   %}
 5964   ins_pipe(ialu_reg_reg);
 5965 %}
 5966 
 5967 instruct subsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5968   match(Set dst (SubI src1 (RShiftI src2 src3)));
 5969 
 5970   size(4);
 5971   format %{ &quot;sub_32 $dst,$src1,$src2&gt;&gt;$src3\t! int&quot; %}
 5972   ins_encode %{
 5973     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 5974   %}
 5975   ins_pipe(ialu_reg_reg);
 5976 %}
 5977 
 5978 instruct subshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5979   match(Set dst (SubI src1 (URShiftI src2 src3)));
 5980 
 5981   size(4);
 5982   format %{ &quot;SUB    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 5983   ins_encode %{
 5984     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 5985   %}
 5986   ins_pipe(ialu_reg_reg);
 5987 %}
 5988 
 5989 instruct subshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5990   match(Set dst (SubI src1 (URShiftI src2 src3)));
 5991 
 5992   size(4);
 5993   format %{ &quot;sub_32 $dst,$src1,$src2&gt;&gt;&gt;$src3\t! int&quot; %}
 5994   ins_encode %{
 5995     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 5996   %}
 5997   ins_pipe(ialu_reg_reg);
 5998 %}
 5999 
 6000 instruct rsbshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6001   match(Set dst (SubI (LShiftI src1 src2) src3));
 6002 
 6003   size(4);
 6004   format %{ &quot;RSB    $dst,$src3,$src1&lt;&lt;$src2&quot; %}
 6005   ins_encode %{
 6006     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6007   %}
 6008   ins_pipe(ialu_reg_reg);
 6009 %}
 6010 
 6011 instruct rsbshlI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6012   match(Set dst (SubI (LShiftI src1 src2) src3));
 6013 
 6014   size(4);
 6015   format %{ &quot;RSB    $dst,$src3,$src1&lt;&lt;$src2&quot; %}
 6016   ins_encode %{
 6017     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 6018   %}
 6019   ins_pipe(ialu_reg_reg);
 6020 %}
 6021 
 6022 instruct rsbsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6023   match(Set dst (SubI (RShiftI src1 src2) src3));
 6024 
 6025   size(4);
 6026   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;$src2&quot; %}
 6027   ins_encode %{
 6028     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 6029   %}
 6030   ins_pipe(ialu_reg_reg);
 6031 %}
 6032 
 6033 instruct rsbsarI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6034   match(Set dst (SubI (RShiftI src1 src2) src3));
 6035 
 6036   size(4);
 6037   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;$src2&quot; %}
 6038   ins_encode %{
 6039     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 6040   %}
 6041   ins_pipe(ialu_reg_reg);
 6042 %}
 6043 
 6044 instruct rsbshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6045   match(Set dst (SubI (URShiftI src1 src2) src3));
 6046 
 6047   size(4);
 6048   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;&gt;$src2&quot; %}
 6049   ins_encode %{
 6050     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6051   %}
 6052   ins_pipe(ialu_reg_reg);
 6053 %}
 6054 
 6055 instruct rsbshrI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6056   match(Set dst (SubI (URShiftI src1 src2) src3));
 6057 
 6058   size(4);
 6059   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;&gt;$src2&quot; %}
 6060   ins_encode %{
 6061     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6062   %}
 6063   ins_pipe(ialu_reg_reg);
 6064 %}
 6065 
 6066 // Immediate Subtraction
 6067 instruct subI_reg_aimmI(iRegI dst, iRegI src1, aimmI src2) %{
 6068   match(Set dst (SubI src1 src2));
 6069 
 6070   size(4);
 6071   format %{ &quot;sub_32 $dst,$src1,$src2\t! int&quot; %}
 6072   ins_encode %{
 6073     __ sub_32($dst$$Register, $src1$$Register, $src2$$constant);
 6074   %}
 6075   ins_pipe(ialu_reg_imm);
 6076 %}
 6077 
 6078 instruct subI_reg_immRotneg(iRegI dst, iRegI src1, aimmIneg src2) %{
 6079   match(Set dst (AddI src1 src2));
 6080 
 6081   size(4);
 6082   format %{ &quot;sub_32 $dst,$src1,-($src2)\t! int&quot; %}
 6083   ins_encode %{
 6084     __ sub_32($dst$$Register, $src1$$Register, -$src2$$constant);
 6085   %}
 6086   ins_pipe(ialu_reg_imm);
 6087 %}
 6088 
 6089 instruct subI_immRot_reg(iRegI dst, immIRot src1, iRegI src2) %{
 6090   match(Set dst (SubI src1 src2));
 6091 
 6092   size(4);
 6093   format %{ &quot;RSB    $dst,$src2,src1&quot; %}
 6094   ins_encode %{
 6095     __ rsb($dst$$Register, $src2$$Register, $src1$$constant);
 6096   %}
 6097   ins_pipe(ialu_zero_reg);
 6098 %}
 6099 
 6100 // Register Subtraction
 6101 instruct subL_reg_reg(iRegL dst, iRegL src1, iRegL src2, flagsReg icc ) %{
 6102   match(Set dst (SubL src1 src2));
 6103   effect (KILL icc);
 6104 
 6105   size(8);
 6106   format %{ &quot;SUBS   $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 6107             &quot;SBC    $dst.hi,$src1.hi,$src2.hi&quot; %}
 6108   ins_encode %{
 6109     __ subs($dst$$Register, $src1$$Register, $src2$$Register);
 6110     __ sbc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 6111   %}
 6112   ins_pipe(ialu_reg_reg);
 6113 %}
 6114 
 6115 // TODO
 6116 
 6117 // Immediate Subtraction
 6118 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 6119 // (hi($con$$constant), lo($con$$constant)) becomes
 6120 instruct subL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con, flagsReg icc) %{
 6121   match(Set dst (SubL src1 con));
 6122   effect (KILL icc);
 6123 
 6124   size(8);
 6125   format %{ &quot;SUB    $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 6126             &quot;SBC    $dst.hi,$src1.hi,0&quot; %}
 6127   ins_encode %{
 6128     __ subs($dst$$Register, $src1$$Register, $con$$constant);
 6129     __ sbc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 6130   %}
 6131   ins_pipe(ialu_reg_imm);
 6132 %}
 6133 
 6134 // Long negation
 6135 instruct negL_reg_reg(iRegL dst, immL0 zero, iRegL src2, flagsReg icc) %{
 6136   match(Set dst (SubL zero src2));
 6137   effect (KILL icc);
 6138 
 6139   size(8);
 6140   format %{ &quot;RSBS   $dst.lo,$src2.lo,0\t! long\n\t&quot;
 6141             &quot;RSC    $dst.hi,$src2.hi,0&quot; %}
 6142   ins_encode %{
 6143     __ rsbs($dst$$Register, $src2$$Register, 0);
 6144     __ rsc($dst$$Register-&gt;successor(), $src2$$Register-&gt;successor(), 0);
 6145   %}
 6146   ins_pipe(ialu_zero_reg);
 6147 %}
 6148 
 6149 // Multiplication Instructions
 6150 // Integer Multiplication
 6151 // Register Multiplication
 6152 instruct mulI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6153   match(Set dst (MulI src1 src2));
 6154 
 6155   size(4);
 6156   format %{ &quot;mul_32 $dst,$src1,$src2&quot; %}
 6157   ins_encode %{
 6158     __ mul_32($dst$$Register, $src1$$Register, $src2$$Register);
 6159   %}
 6160   ins_pipe(imul_reg_reg);
 6161 %}
 6162 
 6163 instruct mulL_lo1_hi2(iRegL dst, iRegL src1, iRegL src2) %{
 6164   effect(DEF dst, USE src1, USE src2);
 6165   size(4);
 6166   format %{ &quot;MUL  $dst.hi,$src1.lo,$src2.hi\t! long&quot; %}
 6167   ins_encode %{
 6168     __ mul($dst$$Register-&gt;successor(), $src1$$Register, $src2$$Register-&gt;successor());
 6169   %}
 6170   ins_pipe(imul_reg_reg);
 6171 %}
 6172 
 6173 instruct mulL_hi1_lo2(iRegL dst, iRegL src1, iRegL src2) %{
 6174   effect(USE_DEF dst, USE src1, USE src2);
 6175   size(8);
 6176   format %{ &quot;MLA  $dst.hi,$src1.hi,$src2.lo,$dst.hi\t! long\n\t&quot;
 6177             &quot;MOV  $dst.lo, 0&quot;%}
 6178   ins_encode %{
 6179     __ mla($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register, $dst$$Register-&gt;successor());
 6180     __ mov($dst$$Register, 0);
 6181   %}
 6182   ins_pipe(imul_reg_reg);
 6183 %}
 6184 
 6185 instruct mulL_lo1_lo2(iRegL dst, iRegL src1, iRegL src2) %{
 6186   effect(USE_DEF dst, USE src1, USE src2);
 6187   size(4);
 6188   format %{ &quot;UMLAL  $dst.lo,$dst.hi,$src1,$src2\t! long&quot; %}
 6189   ins_encode %{
 6190     __ umlal($dst$$Register, $dst$$Register-&gt;successor(), $src1$$Register, $src2$$Register);
 6191   %}
 6192   ins_pipe(imul_reg_reg);
 6193 %}
 6194 
 6195 instruct mulL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6196   match(Set dst (MulL src1 src2));
 6197 
 6198   expand %{
 6199     mulL_lo1_hi2(dst, src1, src2);
 6200     mulL_hi1_lo2(dst, src1, src2);
 6201     mulL_lo1_lo2(dst, src1, src2);
 6202   %}
 6203 %}
 6204 
 6205 // Integer Division
 6206 // Register Division
 6207 instruct divI_reg_reg(R1RegI dst, R0RegI src1, R2RegI src2, LRRegP lr, flagsReg ccr) %{
 6208   match(Set dst (DivI src1 src2));
 6209   effect( KILL ccr, KILL src1, KILL src2, KILL lr);
 6210   ins_cost((2+71)*DEFAULT_COST);
 6211 
 6212   format %{ &quot;DIV   $dst,$src1,$src2 ! call to StubRoutines::Arm::idiv_irem_entry()&quot; %}
 6213   ins_encode %{
 6214     __ call(StubRoutines::Arm::idiv_irem_entry(), relocInfo::runtime_call_type);
 6215   %}
 6216   ins_pipe(sdiv_reg_reg);
 6217 %}
 6218 
 6219 // Register Long Division
 6220 instruct divL_reg_reg(R0R1RegL dst, R2R3RegL src1, R0R1RegL src2) %{
 6221   match(Set dst (DivL src1 src2));
 6222   effect(CALL);
 6223   ins_cost(DEFAULT_COST*71);
 6224   format %{ &quot;DIVL  $src1,$src2,$dst\t! long ! call to SharedRuntime::ldiv&quot; %}
 6225   ins_encode %{
 6226     address target = CAST_FROM_FN_PTR(address, SharedRuntime::ldiv);
 6227     __ call(target, relocInfo::runtime_call_type);
 6228   %}
 6229   ins_pipe(divL_reg_reg);
 6230 %}
 6231 
 6232 // Integer Remainder
 6233 // Register Remainder
 6234 instruct modI_reg_reg(R0RegI dst, R0RegI src1, R2RegI src2, R1RegI temp, LRRegP lr, flagsReg ccr ) %{
 6235   match(Set dst (ModI src1 src2));
 6236   effect( KILL ccr, KILL temp, KILL src2, KILL lr);
 6237 
 6238   format %{ &quot;MODI   $dst,$src1,$src2\t ! call to StubRoutines::Arm::idiv_irem_entry&quot; %}
 6239   ins_encode %{
 6240     __ call(StubRoutines::Arm::idiv_irem_entry(), relocInfo::runtime_call_type);
 6241   %}
 6242   ins_pipe(sdiv_reg_reg);
 6243 %}
 6244 
 6245 // Register Long Remainder
 6246 instruct modL_reg_reg(R0R1RegL dst, R2R3RegL src1, R0R1RegL src2) %{
 6247   match(Set dst (ModL src1 src2));
 6248   effect(CALL);
 6249   ins_cost(MEMORY_REF_COST); // FIXME
 6250   format %{ &quot;modL    $dst,$src1,$src2\t ! call to SharedRuntime::lrem&quot; %}
 6251   ins_encode %{
 6252     address target = CAST_FROM_FN_PTR(address, SharedRuntime::lrem);
 6253     __ call(target, relocInfo::runtime_call_type);
 6254   %}
 6255   ins_pipe(divL_reg_reg);
 6256 %}
 6257 
 6258 // Integer Shift Instructions
 6259 
 6260 // Register Shift Left
 6261 instruct shlI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6262   match(Set dst (LShiftI src1 src2));
 6263 
 6264   size(4);
 6265   format %{ &quot;LSL  $dst,$src1,$src2 \n\t&quot; %}
 6266   ins_encode %{
 6267     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6268   %}
 6269   ins_pipe(ialu_reg_reg);
 6270 %}
 6271 
 6272 // Register Shift Left Immediate
 6273 instruct shlI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6274   match(Set dst (LShiftI src1 src2));
 6275 
 6276   size(4);
 6277   format %{ &quot;LSL    $dst,$src1,$src2\t! int&quot; %}
 6278   ins_encode %{
 6279     __ logical_shift_left($dst$$Register, $src1$$Register, $src2$$constant);
 6280   %}
 6281   ins_pipe(ialu_reg_imm);
 6282 %}
 6283 
 6284 instruct shlL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6285   effect(USE_DEF dst, USE src1, USE src2);
 6286   size(4);
 6287   format %{&quot;OR  $dst.hi,$dst.hi,($src1.hi &lt;&lt; $src2)&quot;  %}
 6288   ins_encode %{
 6289     __ orr($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsl, $src2$$Register));
 6290   %}
 6291   ins_pipe(ialu_reg_reg);
 6292 %}
 6293 
 6294 instruct shlL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6295   effect(USE_DEF dst, USE src1, USE src2);
 6296   size(4);
 6297   format %{ &quot;LSL  $dst.lo,$src1.lo,$src2 \n\t&quot; %}
 6298   ins_encode %{
 6299     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6300   %}
 6301   ins_pipe(ialu_reg_reg);
 6302 %}
 6303 
 6304 instruct shlL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6305   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6306   size(16);
 6307   format %{ &quot;SUBS  $dst.hi,$src2,32 \n\t&quot;
 6308             &quot;LSLpl $dst.hi,$src1.lo,$dst.hi \n\t&quot;
 6309             &quot;RSBmi $dst.hi,$dst.hi,0 \n\t&quot;
 6310             &quot;LSRmi $dst.hi,$src1.lo,$dst.hi&quot; %}
 6311 
 6312   ins_encode %{
 6313     // $src1$$Register and $dst$$Register-&gt;successor() can&#39;t be the same
 6314     __ subs($dst$$Register-&gt;successor(), $src2$$Register, 32);
 6315     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsl, $dst$$Register-&gt;successor()), pl);
 6316     __ rsb($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), 0, mi);
 6317     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsr, $dst$$Register-&gt;successor()), mi);
 6318   %}
 6319   ins_pipe(ialu_reg_reg);
 6320 %}
 6321 
 6322 instruct shlL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6323   match(Set dst (LShiftL src1 src2));
 6324 
 6325   expand %{
 6326     flagsReg ccr;
 6327     shlL_reg_reg_overlap(dst, src1, src2, ccr);
 6328     shlL_reg_reg_merge_hi(dst, src1, src2);
 6329     shlL_reg_reg_merge_lo(dst, src1, src2);
 6330   %}
 6331 %}
 6332 
 6333 // Register Shift Left Immediate
 6334 instruct shlL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6335   match(Set dst (LShiftL src1 src2));
 6336 
 6337   size(8);
 6338   format %{ &quot;LSL   $dst.hi,$src1.lo,$src2-32\t! or mov if $src2==32\n\t&quot;
 6339             &quot;MOV   $dst.lo, 0&quot; %}
 6340   ins_encode %{
 6341     if ($src2$$constant == 32) {
 6342       __ mov($dst$$Register-&gt;successor(), $src1$$Register);
 6343     } else {
 6344       __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsl, $src2$$constant-32));
 6345     }
 6346     __ mov($dst$$Register, 0);
 6347   %}
 6348   ins_pipe(ialu_reg_imm);
 6349 %}
 6350 
 6351 instruct shlL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6352   match(Set dst (LShiftL src1 src2));
 6353 
 6354   size(12);
 6355   format %{ &quot;LSL   $dst.hi,$src1.lo,$src2\n\t&quot;
 6356             &quot;OR    $dst.hi, $dst.hi, $src1.lo &gt;&gt; 32-$src2\n\t&quot;
 6357             &quot;LSL   $dst.lo,$src1.lo,$src2&quot; %}
 6358   ins_encode %{
 6359     // The order of the following 3 instructions matters: src1.lo and
 6360     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6361     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsl, $src2$$constant));
 6362     __ orr($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsr, 32-$src2$$constant));
 6363     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 6364   %}
 6365   ins_pipe(ialu_reg_imm);
 6366 %}
 6367 
 6368 // Register Arithmetic Shift Right
 6369 instruct sarI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6370   match(Set dst (RShiftI src1 src2));
 6371   size(4);
 6372   format %{ &quot;ASR    $dst,$src1,$src2\t! int&quot; %}
 6373   ins_encode %{
 6374     __ mov($dst$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 6375   %}
 6376   ins_pipe(ialu_reg_reg);
 6377 %}
 6378 
 6379 // Register Arithmetic Shift Right Immediate
 6380 instruct sarI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6381   match(Set dst (RShiftI src1 src2));
 6382 
 6383   size(4);
 6384   format %{ &quot;ASR    $dst,$src1,$src2&quot; %}
 6385   ins_encode %{
 6386     __ mov($dst$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 6387   %}
 6388   ins_pipe(ialu_reg_imm);
 6389 %}
 6390 
 6391 // Register Shift Right Arithmetic Long
 6392 instruct sarL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6393   effect(USE_DEF dst, USE src1, USE src2);
 6394   size(4);
 6395   format %{ &quot;OR  $dst.lo,$dst.lo,($src1.lo &gt;&gt; $src2)&quot;  %}
 6396   ins_encode %{
 6397     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6398   %}
 6399   ins_pipe(ialu_reg_reg);
 6400 %}
 6401 
 6402 instruct sarL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6403   effect(USE_DEF dst, USE src1, USE src2);
 6404   size(4);
 6405   format %{ &quot;ASR  $dst.hi,$src1.hi,$src2 \n\t&quot; %}
 6406   ins_encode %{
 6407     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$Register));
 6408   %}
 6409   ins_pipe(ialu_reg_reg);
 6410 %}
 6411 
 6412 instruct sarL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6413   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6414   size(16);
 6415   format %{ &quot;SUBS  $dst.lo,$src2,32 \n\t&quot;
 6416             &quot;ASRpl $dst.lo,$src1.hi,$dst.lo \n\t&quot;
 6417             &quot;RSBmi $dst.lo,$dst.lo,0 \n\t&quot;
 6418             &quot;LSLmi $dst.lo,$src1.hi,$dst.lo&quot; %}
 6419 
 6420   ins_encode %{
 6421     // $src1$$Register-&gt;successor() and $dst$$Register can&#39;t be the same
 6422     __ subs($dst$$Register, $src2$$Register, 32);
 6423     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), asr, $dst$$Register), pl);
 6424     __ rsb($dst$$Register, $dst$$Register, 0, mi);
 6425     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, $dst$$Register), mi);
 6426   %}
 6427   ins_pipe(ialu_reg_reg);
 6428 %}
 6429 
 6430 instruct sarL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6431   match(Set dst (RShiftL src1 src2));
 6432 
 6433   expand %{
 6434     flagsReg ccr;
 6435     sarL_reg_reg_overlap(dst, src1, src2, ccr);
 6436     sarL_reg_reg_merge_lo(dst, src1, src2);
 6437     sarL_reg_reg_merge_hi(dst, src1, src2);
 6438   %}
 6439 %}
 6440 
 6441 // Register Shift Left Immediate
 6442 instruct sarL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6443   match(Set dst (RShiftL src1 src2));
 6444 
 6445   size(8);
 6446   format %{ &quot;ASR   $dst.lo,$src1.hi,$src2-32\t! or mov if $src2==32\n\t&quot;
 6447             &quot;ASR   $dst.hi,$src1.hi, $src2&quot; %}
 6448   ins_encode %{
 6449     if ($src2$$constant == 32) {
 6450       __ mov($dst$$Register, $src1$$Register-&gt;successor());
 6451     } else{
 6452       __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$constant-32));
 6453     }
 6454     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, 0));
 6455   %}
 6456 
 6457   ins_pipe(ialu_reg_imm);
 6458 %}
 6459 
 6460 instruct sarL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6461   match(Set dst (RShiftL src1 src2));
 6462   size(12);
 6463   format %{ &quot;LSR   $dst.lo,$src1.lo,$src2\n\t&quot;
 6464             &quot;OR    $dst.lo, $dst.lo, $src1.hi &lt;&lt; 32-$src2\n\t&quot;
 6465             &quot;ASR   $dst.hi,$src1.hi,$src2&quot; %}
 6466   ins_encode %{
 6467     // The order of the following 3 instructions matters: src1.lo and
 6468     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6469     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6470     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, 32-$src2$$constant));
 6471     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$constant));
 6472   %}
 6473   ins_pipe(ialu_reg_imm);
 6474 %}
 6475 
 6476 // Register Shift Right
 6477 instruct shrI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6478   match(Set dst (URShiftI src1 src2));
 6479   size(4);
 6480   format %{ &quot;LSR    $dst,$src1,$src2\t! int&quot; %}
 6481   ins_encode %{
 6482     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6483   %}
 6484   ins_pipe(ialu_reg_reg);
 6485 %}
 6486 
 6487 // Register Shift Right Immediate
 6488 instruct shrI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6489   match(Set dst (URShiftI src1 src2));
 6490 
 6491   size(4);
 6492   format %{ &quot;LSR    $dst,$src1,$src2&quot; %}
 6493   ins_encode %{
 6494     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6495   %}
 6496   ins_pipe(ialu_reg_imm);
 6497 %}
 6498 
 6499 // Register Shift Right
 6500 instruct shrL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6501   effect(USE_DEF dst, USE src1, USE src2);
 6502   size(4);
 6503   format %{ &quot;OR   $dst.lo,$dst,($src1.lo &gt;&gt;&gt; $src2)&quot;  %}
 6504   ins_encode %{
 6505     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6506   %}
 6507   ins_pipe(ialu_reg_reg);
 6508 %}
 6509 
 6510 instruct shrL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6511   effect(USE_DEF dst, USE src1, USE src2);
 6512   size(4);
 6513   format %{ &quot;LSR  $dst.hi,$src1.hi,$src2 \n\t&quot; %}
 6514   ins_encode %{
 6515     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$Register));
 6516   %}
 6517   ins_pipe(ialu_reg_reg);
 6518 %}
 6519 
 6520 instruct shrL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6521   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6522   size(16);
 6523   format %{ &quot;SUBS  $dst,$src2,32 \n\t&quot;
 6524             &quot;LSRpl $dst,$src1.hi,$dst \n\t&quot;
 6525             &quot;RSBmi $dst,$dst,0 \n\t&quot;
 6526             &quot;LSLmi $dst,$src1.hi,$dst&quot; %}
 6527 
 6528   ins_encode %{
 6529     // $src1$$Register-&gt;successor() and $dst$$Register can&#39;t be the same
 6530     __ subs($dst$$Register, $src2$$Register, 32);
 6531     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsr, $dst$$Register), pl);
 6532     __ rsb($dst$$Register, $dst$$Register, 0, mi);
 6533     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, $dst$$Register), mi);
 6534   %}
 6535   ins_pipe(ialu_reg_reg);
 6536 %}
 6537 
 6538 instruct shrL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6539   match(Set dst (URShiftL src1 src2));
 6540 
 6541   expand %{
 6542     flagsReg ccr;
 6543     shrL_reg_reg_overlap(dst, src1, src2, ccr);
 6544     shrL_reg_reg_merge_lo(dst, src1, src2);
 6545     shrL_reg_reg_merge_hi(dst, src1, src2);
 6546   %}
 6547 %}
 6548 
 6549 // Register Shift Right Immediate
 6550 instruct shrL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6551   match(Set dst (URShiftL src1 src2));
 6552 
 6553   size(8);
 6554   format %{ &quot;LSR   $dst.lo,$src1.hi,$src2-32\t! or mov if $src2==32\n\t&quot;
 6555             &quot;MOV   $dst.hi, 0&quot; %}
 6556   ins_encode %{
 6557     if ($src2$$constant == 32) {
 6558       __ mov($dst$$Register, $src1$$Register-&gt;successor());
 6559     } else {
 6560       __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$constant-32));
 6561     }
 6562     __ mov($dst$$Register-&gt;successor(), 0);
 6563   %}
 6564 
 6565   ins_pipe(ialu_reg_imm);
 6566 %}
 6567 
 6568 instruct shrL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6569   match(Set dst (URShiftL src1 src2));
 6570 
 6571   size(12);
 6572   format %{ &quot;LSR   $dst.lo,$src1.lo,$src2\n\t&quot;
 6573             &quot;OR    $dst.lo, $dst.lo, $src1.hi &lt;&lt; 32-$src2\n\t&quot;
 6574             &quot;LSR   $dst.hi,$src1.hi,$src2&quot; %}
 6575   ins_encode %{
 6576     // The order of the following 3 instructions matters: src1.lo and
 6577     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6578     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6579     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, 32-$src2$$constant));
 6580     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$constant));
 6581   %}
 6582   ins_pipe(ialu_reg_imm);
 6583 %}
 6584 
 6585 
 6586 instruct shrP_reg_imm5(iRegX dst, iRegP src1, immU5 src2) %{
 6587   match(Set dst (URShiftI (CastP2X src1) src2));
 6588   size(4);
 6589   format %{ &quot;LSR    $dst,$src1,$src2\t! Cast ptr $src1 to int and shift&quot; %}
 6590   ins_encode %{
 6591     __ logical_shift_right($dst$$Register, $src1$$Register, $src2$$constant);
 6592   %}
 6593   ins_pipe(ialu_reg_imm);
 6594 %}
 6595 
 6596 //----------Floating Point Arithmetic Instructions-----------------------------
 6597 
 6598 //  Add float single precision
 6599 instruct addF_reg_reg(regF dst, regF src1, regF src2) %{
 6600   match(Set dst (AddF src1 src2));
 6601 
 6602   size(4);
 6603   format %{ &quot;FADDS  $dst,$src1,$src2&quot; %}
 6604   ins_encode %{
 6605     __ add_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6606   %}
 6607 
 6608   ins_pipe(faddF_reg_reg);
 6609 %}
 6610 
 6611 //  Add float double precision
 6612 instruct addD_reg_reg(regD dst, regD src1, regD src2) %{
 6613   match(Set dst (AddD src1 src2));
 6614 
 6615   size(4);
 6616   format %{ &quot;FADDD  $dst,$src1,$src2&quot; %}
 6617   ins_encode %{
 6618     __ add_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6619   %}
 6620 
 6621   ins_pipe(faddD_reg_reg);
 6622 %}
 6623 
 6624 //  Sub float single precision
 6625 instruct subF_reg_reg(regF dst, regF src1, regF src2) %{
 6626   match(Set dst (SubF src1 src2));
 6627 
 6628   size(4);
 6629   format %{ &quot;FSUBS  $dst,$src1,$src2&quot; %}
 6630   ins_encode %{
 6631     __ sub_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6632   %}
 6633   ins_pipe(faddF_reg_reg);
 6634 %}
 6635 
 6636 //  Sub float double precision
 6637 instruct subD_reg_reg(regD dst, regD src1, regD src2) %{
 6638   match(Set dst (SubD src1 src2));
 6639 
 6640   size(4);
 6641   format %{ &quot;FSUBD  $dst,$src1,$src2&quot; %}
 6642   ins_encode %{
 6643     __ sub_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6644   %}
 6645   ins_pipe(faddD_reg_reg);
 6646 %}
 6647 
 6648 //  Mul float single precision
 6649 instruct mulF_reg_reg(regF dst, regF src1, regF src2) %{
 6650   match(Set dst (MulF src1 src2));
 6651 
 6652   size(4);
 6653   format %{ &quot;FMULS  $dst,$src1,$src2&quot; %}
 6654   ins_encode %{
 6655     __ mul_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6656   %}
 6657 
 6658   ins_pipe(fmulF_reg_reg);
 6659 %}
 6660 
 6661 //  Mul float double precision
 6662 instruct mulD_reg_reg(regD dst, regD src1, regD src2) %{
 6663   match(Set dst (MulD src1 src2));
 6664 
 6665   size(4);
 6666   format %{ &quot;FMULD  $dst,$src1,$src2&quot; %}
 6667   ins_encode %{
 6668     __ mul_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6669   %}
 6670 
 6671   ins_pipe(fmulD_reg_reg);
 6672 %}
 6673 
 6674 //  Div float single precision
 6675 instruct divF_reg_reg(regF dst, regF src1, regF src2) %{
 6676   match(Set dst (DivF src1 src2));
 6677 
 6678   size(4);
 6679   format %{ &quot;FDIVS  $dst,$src1,$src2&quot; %}
 6680   ins_encode %{
 6681     __ div_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6682   %}
 6683 
 6684   ins_pipe(fdivF_reg_reg);
 6685 %}
 6686 
 6687 //  Div float double precision
 6688 instruct divD_reg_reg(regD dst, regD src1, regD src2) %{
 6689   match(Set dst (DivD src1 src2));
 6690 
 6691   size(4);
 6692   format %{ &quot;FDIVD  $dst,$src1,$src2&quot; %}
 6693   ins_encode %{
 6694     __ div_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6695   %}
 6696 
 6697   ins_pipe(fdivD_reg_reg);
 6698 %}
 6699 
 6700 //  Absolute float double precision
 6701 instruct absD_reg(regD dst, regD src) %{
 6702   match(Set dst (AbsD src));
 6703 
 6704   size(4);
 6705   format %{ &quot;FABSd  $dst,$src&quot; %}
 6706   ins_encode %{
 6707     __ abs_double($dst$$FloatRegister, $src$$FloatRegister);
 6708   %}
 6709   ins_pipe(faddD_reg);
 6710 %}
 6711 
 6712 //  Absolute float single precision
 6713 instruct absF_reg(regF dst, regF src) %{
 6714   match(Set dst (AbsF src));
 6715   format %{ &quot;FABSs  $dst,$src&quot; %}
 6716   ins_encode %{
 6717     __ abs_float($dst$$FloatRegister, $src$$FloatRegister);
 6718   %}
 6719   ins_pipe(faddF_reg);
 6720 %}
 6721 
 6722 instruct negF_reg(regF dst, regF src) %{
 6723   match(Set dst (NegF src));
 6724 
 6725   size(4);
 6726   format %{ &quot;FNEGs  $dst,$src&quot; %}
 6727   ins_encode %{
 6728     __ neg_float($dst$$FloatRegister, $src$$FloatRegister);
 6729   %}
 6730   ins_pipe(faddF_reg);
 6731 %}
 6732 
 6733 instruct negD_reg(regD dst, regD src) %{
 6734   match(Set dst (NegD src));
 6735 
 6736   format %{ &quot;FNEGd  $dst,$src&quot; %}
 6737   ins_encode %{
 6738     __ neg_double($dst$$FloatRegister, $src$$FloatRegister);
 6739   %}
 6740   ins_pipe(faddD_reg);
 6741 %}
 6742 
 6743 //  Sqrt float double precision
 6744 instruct sqrtF_reg_reg(regF dst, regF src) %{
 6745   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
 6746 
 6747   size(4);
 6748   format %{ &quot;FSQRTS $dst,$src&quot; %}
 6749   ins_encode %{
 6750     __ sqrt_float($dst$$FloatRegister, $src$$FloatRegister);
 6751   %}
 6752   ins_pipe(fdivF_reg_reg);
 6753 %}
 6754 
 6755 //  Sqrt float double precision
 6756 instruct sqrtD_reg_reg(regD dst, regD src) %{
 6757   match(Set dst (SqrtD src));
 6758 
 6759   size(4);
 6760   format %{ &quot;FSQRTD $dst,$src&quot; %}
 6761   ins_encode %{
 6762     __ sqrt_double($dst$$FloatRegister, $src$$FloatRegister);
 6763   %}
 6764   ins_pipe(fdivD_reg_reg);
 6765 %}
 6766 
 6767 //----------Logical Instructions-----------------------------------------------
 6768 // And Instructions
 6769 // Register And
 6770 instruct andI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6771   match(Set dst (AndI src1 src2));
 6772 
 6773   size(4);
 6774   format %{ &quot;and_32 $dst,$src1,$src2&quot; %}
 6775   ins_encode %{
 6776     __ and_32($dst$$Register, $src1$$Register, $src2$$Register);
 6777   %}
 6778   ins_pipe(ialu_reg_reg);
 6779 %}
 6780 
 6781 instruct andshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6782   match(Set dst (AndI src1 (LShiftI src2 src3)));
 6783 
 6784   size(4);
 6785   format %{ &quot;AND    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6786   ins_encode %{
 6787     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 6788   %}
 6789   ins_pipe(ialu_reg_reg);
 6790 %}
 6791 
 6792 instruct andshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6793   match(Set dst (AndI src1 (LShiftI src2 src3)));
 6794 
 6795   size(4);
 6796   format %{ &quot;and_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6797   ins_encode %{
 6798     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 6799   %}
 6800   ins_pipe(ialu_reg_reg);
 6801 %}
 6802 
 6803 instruct andsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6804   match(Set dst (AndI src1 (RShiftI src2 src3)));
 6805 
 6806   size(4);
 6807   format %{ &quot;AND    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6808   ins_encode %{
 6809     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 6810   %}
 6811   ins_pipe(ialu_reg_reg);
 6812 %}
 6813 
 6814 instruct andsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6815   match(Set dst (AndI src1 (RShiftI src2 src3)));
 6816 
 6817   size(4);
 6818   format %{ &quot;and_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6819   ins_encode %{
 6820     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 6821   %}
 6822   ins_pipe(ialu_reg_reg);
 6823 %}
 6824 
 6825 instruct andshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6826   match(Set dst (AndI src1 (URShiftI src2 src3)));
 6827 
 6828   size(4);
 6829   format %{ &quot;AND    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6830   ins_encode %{
 6831     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 6832   %}
 6833   ins_pipe(ialu_reg_reg);
 6834 %}
 6835 
 6836 instruct andshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6837   match(Set dst (AndI src1 (URShiftI src2 src3)));
 6838 
 6839   size(4);
 6840   format %{ &quot;and_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6841   ins_encode %{
 6842     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 6843   %}
 6844   ins_pipe(ialu_reg_reg);
 6845 %}
 6846 
 6847 // Immediate And
 6848 instruct andI_reg_limm(iRegI dst, iRegI src1, limmI src2) %{
 6849   match(Set dst (AndI src1 src2));
 6850 
 6851   size(4);
 6852   format %{ &quot;and_32 $dst,$src1,$src2\t! int&quot; %}
 6853   ins_encode %{
 6854     __ and_32($dst$$Register, $src1$$Register, $src2$$constant);
 6855   %}
 6856   ins_pipe(ialu_reg_imm);
 6857 %}
 6858 
 6859 instruct andI_reg_limmn(iRegI dst, iRegI src1, limmIn src2) %{
 6860   match(Set dst (AndI src1 src2));
 6861 
 6862   size(4);
 6863   format %{ &quot;bic    $dst,$src1,~$src2\t! int&quot; %}
 6864   ins_encode %{
 6865     __ bic($dst$$Register, $src1$$Register, ~$src2$$constant);
 6866   %}
 6867   ins_pipe(ialu_reg_imm);
 6868 %}
 6869 
 6870 // Register And Long
 6871 instruct andL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6872   match(Set dst (AndL src1 src2));
 6873 
 6874   ins_cost(DEFAULT_COST);
 6875   size(8);
 6876   format %{ &quot;AND    $dst,$src1,$src2\t! long&quot; %}
 6877   ins_encode %{
 6878     __ andr($dst$$Register, $src1$$Register, $src2$$Register);
 6879     __ andr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 6880   %}
 6881   ins_pipe(ialu_reg_reg);
 6882 %}
 6883 
 6884 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 6885 // (hi($con$$constant), lo($con$$constant)) becomes
 6886 instruct andL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 6887   match(Set dst (AndL src1 con));
 6888   ins_cost(DEFAULT_COST);
 6889   size(8);
 6890   format %{ &quot;AND    $dst,$src1,$con\t! long&quot; %}
 6891   ins_encode %{
 6892     __ andr($dst$$Register, $src1$$Register, $con$$constant);
 6893     __ andr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 6894   %}
 6895   ins_pipe(ialu_reg_imm);
 6896 %}
 6897 
 6898 // Or Instructions
 6899 // Register Or
 6900 instruct orI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6901   match(Set dst (OrI src1 src2));
 6902 
 6903   size(4);
 6904   format %{ &quot;orr_32 $dst,$src1,$src2\t! int&quot; %}
 6905   ins_encode %{
 6906     __ orr_32($dst$$Register, $src1$$Register, $src2$$Register);
 6907   %}
 6908   ins_pipe(ialu_reg_reg);
 6909 %}
 6910 
 6911 instruct orshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6912   match(Set dst (OrI src1 (LShiftI src2 src3)));
 6913 
 6914   size(4);
 6915   format %{ &quot;OR    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6916   ins_encode %{
 6917     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 6918   %}
 6919   ins_pipe(ialu_reg_reg);
 6920 %}
 6921 
 6922 instruct orshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6923   match(Set dst (OrI src1 (LShiftI src2 src3)));
 6924 
 6925   size(4);
 6926   format %{ &quot;orr_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6927   ins_encode %{
 6928     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 6929   %}
 6930   ins_pipe(ialu_reg_reg);
 6931 %}
 6932 
 6933 instruct orsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6934   match(Set dst (OrI src1 (RShiftI src2 src3)));
 6935 
 6936   size(4);
 6937   format %{ &quot;OR    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6938   ins_encode %{
 6939     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 6940   %}
 6941   ins_pipe(ialu_reg_reg);
 6942 %}
 6943 
 6944 instruct orsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6945   match(Set dst (OrI src1 (RShiftI src2 src3)));
 6946 
 6947   size(4);
 6948   format %{ &quot;orr_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6949   ins_encode %{
 6950     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 6951   %}
 6952   ins_pipe(ialu_reg_reg);
 6953 %}
 6954 
 6955 instruct orshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6956   match(Set dst (OrI src1 (URShiftI src2 src3)));
 6957 
 6958   size(4);
 6959   format %{ &quot;OR    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6960   ins_encode %{
 6961     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 6962   %}
 6963   ins_pipe(ialu_reg_reg);
 6964 %}
 6965 
 6966 instruct orshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6967   match(Set dst (OrI src1 (URShiftI src2 src3)));
 6968 
 6969   size(4);
 6970   format %{ &quot;orr_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6971   ins_encode %{
 6972     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 6973   %}
 6974   ins_pipe(ialu_reg_reg);
 6975 %}
 6976 
 6977 // Immediate Or
 6978 instruct orI_reg_limm(iRegI dst, iRegI src1, limmI src2) %{
 6979   match(Set dst (OrI src1 src2));
 6980 
 6981   size(4);
 6982   format %{ &quot;orr_32  $dst,$src1,$src2&quot; %}
 6983   ins_encode %{
 6984     __ orr_32($dst$$Register, $src1$$Register, $src2$$constant);
 6985   %}
 6986   ins_pipe(ialu_reg_imm);
 6987 %}
 6988 // TODO: orn_32 with limmIn
 6989 
 6990 // Register Or Long
 6991 instruct orL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6992   match(Set dst (OrL src1 src2));
 6993 
 6994   ins_cost(DEFAULT_COST);
 6995   size(8);
 6996   format %{ &quot;OR     $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 6997             &quot;OR     $dst.hi,$src1.hi,$src2.hi&quot; %}
 6998   ins_encode %{
 6999     __ orr($dst$$Register, $src1$$Register, $src2$$Register);
 7000     __ orr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 7001   %}
 7002   ins_pipe(ialu_reg_reg);
 7003 %}
 7004 
 7005 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7006 // (hi($con$$constant), lo($con$$constant)) becomes
 7007 instruct orL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 7008   match(Set dst (OrL src1 con));
 7009   ins_cost(DEFAULT_COST);
 7010   size(8);
 7011   format %{ &quot;OR     $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 7012             &quot;OR     $dst.hi,$src1.hi,$con&quot; %}
 7013   ins_encode %{
 7014     __ orr($dst$$Register, $src1$$Register, $con$$constant);
 7015     __ orr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 7016   %}
 7017   ins_pipe(ialu_reg_imm);
 7018 %}
 7019 
 7020 #ifdef TODO
 7021 // Use SPRegP to match Rthread (TLS register) without spilling.
 7022 // Use store_ptr_RegP to match Rthread (TLS register) without spilling.
 7023 // Use sp_ptr_RegP to match Rthread (TLS register) without spilling.
 7024 instruct orI_reg_castP2X(iRegI dst, iRegI src1, sp_ptr_RegP src2) %{
 7025   match(Set dst (OrI src1 (CastP2X src2)));
 7026   size(4);
 7027   format %{ &quot;OR     $dst,$src1,$src2&quot; %}
 7028   ins_encode %{
 7029     __ orr($dst$$Register, $src1$$Register, $src2$$Register);
 7030   %}
 7031   ins_pipe(ialu_reg_reg);
 7032 %}
 7033 #endif
 7034 
 7035 // Xor Instructions
 7036 // Register Xor
 7037 instruct xorI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 7038   match(Set dst (XorI src1 src2));
 7039 
 7040   size(4);
 7041   format %{ &quot;eor_32 $dst,$src1,$src2&quot; %}
 7042   ins_encode %{
 7043     __ eor_32($dst$$Register, $src1$$Register, $src2$$Register);
 7044   %}
 7045   ins_pipe(ialu_reg_reg);
 7046 %}
 7047 
 7048 instruct xorshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7049   match(Set dst (XorI src1 (LShiftI src2 src3)));
 7050 
 7051   size(4);
 7052   format %{ &quot;XOR    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 7053   ins_encode %{
 7054     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 7055   %}
 7056   ins_pipe(ialu_reg_reg);
 7057 %}
 7058 
 7059 instruct xorshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7060   match(Set dst (XorI src1 (LShiftI src2 src3)));
 7061 
 7062   size(4);
 7063   format %{ &quot;eor_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 7064   ins_encode %{
 7065     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 7066   %}
 7067   ins_pipe(ialu_reg_reg);
 7068 %}
 7069 
 7070 instruct xorsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7071   match(Set dst (XorI src1 (RShiftI src2 src3)));
 7072 
 7073   size(4);
 7074   format %{ &quot;XOR    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 7075   ins_encode %{
 7076     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 7077   %}
 7078   ins_pipe(ialu_reg_reg);
 7079 %}
 7080 
 7081 instruct xorsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7082   match(Set dst (XorI src1 (RShiftI src2 src3)));
 7083 
 7084   size(4);
 7085   format %{ &quot;eor_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 7086   ins_encode %{
 7087     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 7088   %}
 7089   ins_pipe(ialu_reg_reg);
 7090 %}
 7091 
 7092 instruct xorshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7093   match(Set dst (XorI src1 (URShiftI src2 src3)));
 7094 
 7095   size(4);
 7096   format %{ &quot;XOR    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 7097   ins_encode %{
 7098     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 7099   %}
 7100   ins_pipe(ialu_reg_reg);
 7101 %}
 7102 
 7103 instruct xorshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7104   match(Set dst (XorI src1 (URShiftI src2 src3)));
 7105 
 7106   size(4);
 7107   format %{ &quot;eor_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 7108   ins_encode %{
 7109     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 7110   %}
 7111   ins_pipe(ialu_reg_reg);
 7112 %}
 7113 
 7114 // Immediate Xor
 7115 instruct xorI_reg_imm(iRegI dst, iRegI src1, limmI src2) %{
 7116   match(Set dst (XorI src1 src2));
 7117 
 7118   size(4);
 7119   format %{ &quot;eor_32 $dst,$src1,$src2&quot; %}
 7120   ins_encode %{
 7121     __ eor_32($dst$$Register, $src1$$Register, $src2$$constant);
 7122   %}
 7123   ins_pipe(ialu_reg_imm);
 7124 %}
 7125 
 7126 // Register Xor Long
 7127 instruct xorL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 7128   match(Set dst (XorL src1 src2));
 7129   ins_cost(DEFAULT_COST);
 7130   size(8);
 7131   format %{ &quot;XOR     $dst.hi,$src1.hi,$src2.hi\t! long\n\t&quot;
 7132             &quot;XOR     $dst.lo,$src1.lo,$src2.lo\t! long&quot; %}
 7133   ins_encode %{
 7134     __ eor($dst$$Register, $src1$$Register, $src2$$Register);
 7135     __ eor($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 7136   %}
 7137   ins_pipe(ialu_reg_reg);
 7138 %}
 7139 
 7140 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7141 // (hi($con$$constant), lo($con$$constant)) becomes
 7142 instruct xorL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 7143   match(Set dst (XorL src1 con));
 7144   ins_cost(DEFAULT_COST);
 7145   size(8);
 7146   format %{ &quot;XOR     $dst.hi,$src1.hi,$con\t! long\n\t&quot;
 7147             &quot;XOR     $dst.lo,$src1.lo,0\t! long&quot; %}
 7148   ins_encode %{
 7149     __ eor($dst$$Register, $src1$$Register, $con$$constant);
 7150     __ eor($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 7151   %}
 7152   ins_pipe(ialu_reg_imm);
 7153 %}
 7154 
 7155 //----------Convert to Boolean-------------------------------------------------
 7156 instruct convI2B( iRegI dst, iRegI src, flagsReg ccr ) %{
 7157   match(Set dst (Conv2B src));
 7158   effect(KILL ccr);
 7159   size(12);
 7160   ins_cost(DEFAULT_COST*2);
 7161   format %{ &quot;TST    $src,$src \n\t&quot;
 7162             &quot;MOV    $dst, 0   \n\t&quot;
 7163             &quot;MOV.ne $dst, 1&quot; %}
 7164   ins_encode %{ // FIXME: can do better?
 7165     __ tst($src$$Register, $src$$Register);
 7166     __ mov($dst$$Register, 0);
 7167     __ mov($dst$$Register, 1, ne);
 7168   %}
 7169   ins_pipe(ialu_reg_ialu);
 7170 %}
 7171 
 7172 instruct convP2B( iRegI dst, iRegP src, flagsReg ccr ) %{
 7173   match(Set dst (Conv2B src));
 7174   effect(KILL ccr);
 7175   size(12);
 7176   ins_cost(DEFAULT_COST*2);
 7177   format %{ &quot;TST    $src,$src \n\t&quot;
 7178             &quot;MOV    $dst, 0   \n\t&quot;
 7179             &quot;MOV.ne $dst, 1&quot; %}
 7180   ins_encode %{
 7181     __ tst($src$$Register, $src$$Register);
 7182     __ mov($dst$$Register, 0);
 7183     __ mov($dst$$Register, 1, ne);
 7184   %}
 7185   ins_pipe(ialu_reg_ialu);
 7186 %}
 7187 
 7188 instruct cmpLTMask_reg_reg( iRegI dst, iRegI p, iRegI q, flagsReg ccr ) %{
 7189   match(Set dst (CmpLTMask p q));
 7190   effect( KILL ccr );
 7191   ins_cost(DEFAULT_COST*3);
 7192   format %{ &quot;CMP    $p,$q\n\t&quot;
 7193             &quot;MOV    $dst, #0\n\t&quot;
 7194             &quot;MOV.lt $dst, #-1&quot; %}
 7195   ins_encode %{
 7196     __ cmp($p$$Register, $q$$Register);
 7197     __ mov($dst$$Register, 0);
 7198     __ mvn($dst$$Register, 0, lt);
 7199   %}
 7200   ins_pipe(ialu_reg_reg_ialu);
 7201 %}
 7202 
 7203 instruct cmpLTMask_reg_imm( iRegI dst, iRegI p, aimmI q, flagsReg ccr ) %{
 7204   match(Set dst (CmpLTMask p q));
 7205   effect( KILL ccr );
 7206   ins_cost(DEFAULT_COST*3);
 7207   format %{ &quot;CMP    $p,$q\n\t&quot;
 7208             &quot;MOV    $dst, #0\n\t&quot;
 7209             &quot;MOV.lt $dst, #-1&quot; %}
 7210   ins_encode %{
 7211     __ cmp($p$$Register, $q$$constant);
 7212     __ mov($dst$$Register, 0);
 7213     __ mvn($dst$$Register, 0, lt);
 7214   %}
 7215   ins_pipe(ialu_reg_reg_ialu);
 7216 %}
 7217 
 7218 instruct cadd_cmpLTMask3( iRegI p, iRegI q, iRegI y, iRegI z, flagsReg ccr ) %{
 7219   match(Set z (AddI (AndI (CmpLTMask p q) y) z));
 7220   effect( KILL ccr );
 7221   ins_cost(DEFAULT_COST*2);
 7222   format %{ &quot;CMP    $p,$q\n\t&quot;
 7223             &quot;ADD.lt $z,$y,$z&quot; %}
 7224   ins_encode %{
 7225     __ cmp($p$$Register, $q$$Register);
 7226     __ add($z$$Register, $y$$Register, $z$$Register, lt);
 7227   %}
 7228   ins_pipe( cadd_cmpltmask );
 7229 %}
 7230 
 7231 // FIXME: remove unused &quot;dst&quot;
 7232 instruct cadd_cmpLTMask4( iRegI dst, iRegI p, aimmI q, iRegI y, iRegI z, flagsReg ccr ) %{
 7233   match(Set z (AddI (AndI (CmpLTMask p q) y) z));
 7234   effect( KILL ccr );
 7235   ins_cost(DEFAULT_COST*2);
 7236   format %{ &quot;CMP    $p,$q\n\t&quot;
 7237             &quot;ADD.lt $z,$y,$z&quot; %}
 7238   ins_encode %{
 7239     __ cmp($p$$Register, $q$$constant);
 7240     __ add($z$$Register, $y$$Register, $z$$Register, lt);
 7241   %}
 7242   ins_pipe( cadd_cmpltmask );
 7243 %}
 7244 
 7245 instruct cadd_cmpLTMask( iRegI p, iRegI q, iRegI y, flagsReg ccr ) %{
 7246   match(Set p (AddI (AndI (CmpLTMask p q) y) (SubI p q)));
 7247   effect( KILL ccr );
 7248   ins_cost(DEFAULT_COST*2);
 7249   format %{ &quot;SUBS   $p,$p,$q\n\t&quot;
 7250             &quot;ADD.lt $p,$y,$p&quot; %}
 7251   ins_encode %{
 7252     __ subs($p$$Register, $p$$Register, $q$$Register);
 7253     __ add($p$$Register, $y$$Register, $p$$Register, lt);
 7254   %}
 7255   ins_pipe( cadd_cmpltmask );
 7256 %}
 7257 
 7258 //----------Arithmetic Conversion Instructions---------------------------------
 7259 // The conversions operations are all Alpha sorted.  Please keep it that way!
 7260 
 7261 instruct convD2F_reg(regF dst, regD src) %{
 7262   match(Set dst (ConvD2F src));
 7263   size(4);
 7264   format %{ &quot;FCVTSD  $dst,$src&quot; %}
 7265   ins_encode %{
 7266     __ convert_d2f($dst$$FloatRegister, $src$$FloatRegister);
 7267   %}
 7268   ins_pipe(fcvtD2F);
 7269 %}
 7270 
 7271 // Convert a double to an int in a float register.
 7272 // If the double is a NAN, stuff a zero in instead.
 7273 
 7274 instruct convD2I_reg_reg(iRegI dst, regD src, regF tmp) %{
 7275   match(Set dst (ConvD2I src));
 7276   effect( TEMP tmp );
 7277   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7278   format %{ &quot;FTOSIZD  $tmp,$src\n\t&quot;
 7279             &quot;FMRS     $dst, $tmp&quot; %}
 7280   ins_encode %{
 7281     __ ftosizd($tmp$$FloatRegister, $src$$FloatRegister);
 7282     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 7283   %}
 7284   ins_pipe(fcvtD2I);
 7285 %}
 7286 
 7287 // Convert a double to a long in a double register.
 7288 // If the double is a NAN, stuff a zero in instead.
 7289 
 7290 // Double to Long conversion
 7291 instruct convD2L_reg(R0R1RegL dst, regD src) %{
 7292   match(Set dst (ConvD2L src));
 7293   effect(CALL);
 7294   ins_cost(MEMORY_REF_COST); // FIXME
 7295   format %{ &quot;convD2L    $dst,$src\t ! call to SharedRuntime::d2l&quot; %}
 7296   ins_encode %{
 7297 #ifndef __ABI_HARD__
 7298     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), $src$$FloatRegister);
 7299 #else
 7300     if ($src$$FloatRegister != D0) {
 7301       __ mov_double(D0, $src$$FloatRegister);
 7302     }
 7303 #endif
 7304     address target = CAST_FROM_FN_PTR(address, SharedRuntime::d2l);
 7305     __ call(target, relocInfo::runtime_call_type);
 7306   %}
 7307   ins_pipe(fcvtD2L);
 7308 %}
 7309 
 7310 instruct convF2D_reg(regD dst, regF src) %{
 7311   match(Set dst (ConvF2D src));
 7312   size(4);
 7313   format %{ &quot;FCVTDS  $dst,$src&quot; %}
 7314   ins_encode %{
 7315     __ convert_f2d($dst$$FloatRegister, $src$$FloatRegister);
 7316   %}
 7317   ins_pipe(fcvtF2D);
 7318 %}
 7319 
 7320 instruct convF2I_reg_reg(iRegI dst, regF src, regF tmp) %{
 7321   match(Set dst (ConvF2I src));
 7322   effect( TEMP tmp );
 7323   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7324   size(8);
 7325   format %{ &quot;FTOSIZS  $tmp,$src\n\t&quot;
 7326             &quot;FMRS     $dst, $tmp&quot; %}
 7327   ins_encode %{
 7328     __ ftosizs($tmp$$FloatRegister, $src$$FloatRegister);
 7329     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 7330   %}
 7331   ins_pipe(fcvtF2I);
 7332 %}
 7333 
 7334 // Float to Long conversion
 7335 instruct convF2L_reg(R0R1RegL dst, regF src, R0RegI arg1) %{
 7336   match(Set dst (ConvF2L src));
 7337   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7338   effect(CALL);
 7339   format %{ &quot;convF2L  $dst,$src\t! call to SharedRuntime::f2l&quot; %}
 7340   ins_encode %{
 7341 #ifndef __ABI_HARD__
 7342     __ fmrs($arg1$$Register, $src$$FloatRegister);
 7343 #else
 7344     if($src$$FloatRegister != S0) {
 7345       __ mov_float(S0, $src$$FloatRegister);
 7346     }
 7347 #endif
 7348     address target = CAST_FROM_FN_PTR(address, SharedRuntime::f2l);
 7349     __ call(target, relocInfo::runtime_call_type);
 7350   %}
 7351   ins_pipe(fcvtF2L);
 7352 %}
 7353 
 7354 instruct convI2D_reg_reg(iRegI src, regD_low dst) %{
 7355   match(Set dst (ConvI2D src));
 7356   ins_cost(DEFAULT_COST + MEMORY_REF_COST); // FIXME
 7357   size(8);
 7358   format %{ &quot;FMSR     $dst,$src \n\t&quot;
 7359             &quot;FSITOD   $dst $dst&quot;%}
 7360   ins_encode %{
 7361       __ fmsr($dst$$FloatRegister, $src$$Register);
 7362       __ fsitod($dst$$FloatRegister, $dst$$FloatRegister);
 7363   %}
 7364   ins_pipe(fcvtI2D);
 7365 %}
 7366 
 7367 instruct convI2F_reg_reg( regF dst, iRegI src ) %{
 7368   match(Set dst (ConvI2F src));
 7369   ins_cost(DEFAULT_COST + MEMORY_REF_COST); // FIXME
 7370   size(8);
 7371   format %{ &quot;FMSR     $dst,$src \n\t&quot;
 7372             &quot;FSITOS   $dst, $dst&quot;%}
 7373   ins_encode %{
 7374       __ fmsr($dst$$FloatRegister, $src$$Register);
 7375       __ fsitos($dst$$FloatRegister, $dst$$FloatRegister);
 7376   %}
 7377   ins_pipe(fcvtI2F);
 7378 %}
 7379 
 7380 instruct convI2L_reg(iRegL dst, iRegI src) %{
 7381   match(Set dst (ConvI2L src));
 7382   size(8);
 7383   format %{ &quot;MOV    $dst.lo, $src \n\t&quot;
 7384             &quot;ASR    $dst.hi,$src,31\t! int-&gt;long&quot; %}
 7385   ins_encode %{
 7386     __ mov($dst$$Register, $src$$Register);
 7387     __ mov($dst$$Register-&gt;successor(), AsmOperand($src$$Register, asr, 31));
 7388   %}
 7389   ins_pipe(ialu_reg_reg);
 7390 %}
 7391 
 7392 // Zero-extend convert int to long
 7393 instruct convI2L_reg_zex(iRegL dst, iRegI src, immL_32bits mask ) %{
 7394   match(Set dst (AndL (ConvI2L src) mask) );
 7395   size(8);
 7396   format %{ &quot;MOV    $dst.lo,$src.lo\t! zero-extend int to long\n\t&quot;
 7397             &quot;MOV    $dst.hi, 0&quot;%}
 7398   ins_encode %{
 7399     __ mov($dst$$Register, $src$$Register);
 7400     __ mov($dst$$Register-&gt;successor(), 0);
 7401   %}
 7402   ins_pipe(ialu_reg_reg);
 7403 %}
 7404 
 7405 // Zero-extend long
 7406 instruct zerox_long(iRegL dst, iRegL src, immL_32bits mask ) %{
 7407   match(Set dst (AndL src mask) );
 7408   size(8);
 7409   format %{ &quot;MOV    $dst.lo,$src.lo\t! zero-extend long\n\t&quot;
 7410             &quot;MOV    $dst.hi, 0&quot;%}
 7411   ins_encode %{
 7412     __ mov($dst$$Register, $src$$Register);
 7413     __ mov($dst$$Register-&gt;successor(), 0);
 7414   %}
 7415   ins_pipe(ialu_reg_reg);
 7416 %}
 7417 
 7418 instruct MoveF2I_reg_reg(iRegI dst, regF src) %{
 7419   match(Set dst (MoveF2I src));
 7420   effect(DEF dst, USE src);
 7421   ins_cost(MEMORY_REF_COST); // FIXME
 7422 
 7423   size(4);
 7424   format %{ &quot;FMRS   $dst,$src\t! MoveF2I&quot; %}
 7425   ins_encode %{
 7426     __ fmrs($dst$$Register, $src$$FloatRegister);
 7427   %}
 7428   ins_pipe(iload_mem); // FIXME
 7429 %}
 7430 
 7431 instruct MoveI2F_reg_reg(regF dst, iRegI src) %{
 7432   match(Set dst (MoveI2F src));
 7433   ins_cost(MEMORY_REF_COST); // FIXME
 7434 
 7435   size(4);
 7436   format %{ &quot;FMSR   $dst,$src\t! MoveI2F&quot; %}
 7437   ins_encode %{
 7438     __ fmsr($dst$$FloatRegister, $src$$Register);
 7439   %}
 7440   ins_pipe(iload_mem); // FIXME
 7441 %}
 7442 
 7443 instruct MoveD2L_reg_reg(iRegL dst, regD src) %{
 7444   match(Set dst (MoveD2L src));
 7445   effect(DEF dst, USE src);
 7446   ins_cost(MEMORY_REF_COST); // FIXME
 7447 
 7448   size(4);
 7449   format %{ &quot;FMRRD    $dst,$src\t! MoveD2L&quot; %}
 7450   ins_encode %{
 7451     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), $src$$FloatRegister);
 7452   %}
 7453   ins_pipe(iload_mem); // FIXME
 7454 %}
 7455 
 7456 instruct MoveL2D_reg_reg(regD dst, iRegL src) %{
 7457   match(Set dst (MoveL2D src));
 7458   effect(DEF dst, USE src);
 7459   ins_cost(MEMORY_REF_COST); // FIXME
 7460 
 7461   size(4);
 7462   format %{ &quot;FMDRR   $dst,$src\t! MoveL2D&quot; %}
 7463   ins_encode %{
 7464     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 7465   %}
 7466   ins_pipe(ialu_reg_reg); // FIXME
 7467 %}
 7468 
 7469 //-----------
 7470 // Long to Double conversion
 7471 
 7472 // Magic constant, 0x43300000
 7473 instruct loadConI_x43300000(iRegI dst) %{
 7474   effect(DEF dst);
 7475   size(8);
 7476   format %{ &quot;MOV_SLOW  $dst,0x43300000\t! 2^52&quot; %}
 7477   ins_encode %{
 7478     __ mov_slow($dst$$Register, 0x43300000);
 7479   %}
 7480   ins_pipe(ialu_none);
 7481 %}
 7482 
 7483 // Magic constant, 0x41f00000
 7484 instruct loadConI_x41f00000(iRegI dst) %{
 7485   effect(DEF dst);
 7486   size(8);
 7487   format %{ &quot;MOV_SLOW  $dst, 0x41f00000\t! 2^32&quot; %}
 7488   ins_encode %{
 7489     __ mov_slow($dst$$Register, 0x41f00000);
 7490   %}
 7491   ins_pipe(ialu_none);
 7492 %}
 7493 
 7494 instruct loadConI_x0(iRegI dst) %{
 7495   effect(DEF dst);
 7496   size(4);
 7497   format %{ &quot;MOV  $dst, 0x0\t! 0&quot; %}
 7498   ins_encode %{
 7499     __ mov($dst$$Register, 0);
 7500   %}
 7501   ins_pipe(ialu_none);
 7502 %}
 7503 
 7504 // Construct a double from two float halves
 7505 instruct regDHi_regDLo_to_regD(regD_low dst, regD_low src1, regD_low src2) %{
 7506   effect(DEF dst, USE src1, USE src2);
 7507   size(8);
 7508   format %{ &quot;FCPYS  $dst.hi,$src1.hi\n\t&quot;
 7509             &quot;FCPYS  $dst.lo,$src2.lo&quot; %}
 7510   ins_encode %{
 7511     __ fcpys($dst$$FloatRegister-&gt;successor(), $src1$$FloatRegister-&gt;successor());
 7512     __ fcpys($dst$$FloatRegister, $src2$$FloatRegister);
 7513   %}
 7514   ins_pipe(faddD_reg_reg);
 7515 %}
 7516 
 7517 // Convert integer in high half of a double register (in the lower half of
 7518 // the double register file) to double
 7519 instruct convI2D_regDHi_regD(regD dst, regD_low src) %{
 7520   effect(DEF dst, USE src);
 7521   size(4);
 7522   format %{ &quot;FSITOD  $dst,$src&quot; %}
 7523   ins_encode %{
 7524     __ fsitod($dst$$FloatRegister, $src$$FloatRegister-&gt;successor());
 7525   %}
 7526   ins_pipe(fcvtLHi2D);
 7527 %}
 7528 
 7529 // Add float double precision
 7530 instruct addD_regD_regD(regD dst, regD src1, regD src2) %{
 7531   effect(DEF dst, USE src1, USE src2);
 7532   size(4);
 7533   format %{ &quot;FADDD  $dst,$src1,$src2&quot; %}
 7534   ins_encode %{
 7535     __ add_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7536   %}
 7537   ins_pipe(faddD_reg_reg);
 7538 %}
 7539 
 7540 // Sub float double precision
 7541 instruct subD_regD_regD(regD dst, regD src1, regD src2) %{
 7542   effect(DEF dst, USE src1, USE src2);
 7543   size(4);
 7544   format %{ &quot;FSUBD  $dst,$src1,$src2&quot; %}
 7545   ins_encode %{
 7546     __ sub_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7547   %}
 7548   ins_pipe(faddD_reg_reg);
 7549 %}
 7550 
 7551 // Mul float double precision
 7552 instruct mulD_regD_regD(regD dst, regD src1, regD src2) %{
 7553   effect(DEF dst, USE src1, USE src2);
 7554   size(4);
 7555   format %{ &quot;FMULD  $dst,$src1,$src2&quot; %}
 7556   ins_encode %{
 7557     __ mul_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7558   %}
 7559   ins_pipe(fmulD_reg_reg);
 7560 %}
 7561 
 7562 instruct regL_to_regD(regD dst, iRegL src) %{
 7563   // No match rule to avoid chain rule match.
 7564   effect(DEF dst, USE src);
 7565   ins_cost(MEMORY_REF_COST);
 7566   size(4);
 7567   format %{ &quot;FMDRR   $dst,$src\t! regL to regD&quot; %}
 7568   ins_encode %{
 7569     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 7570   %}
 7571   ins_pipe(ialu_reg_reg); // FIXME
 7572 %}
 7573 
 7574 instruct regI_regI_to_regD(regD dst, iRegI src1, iRegI src2) %{
 7575   // No match rule to avoid chain rule match.
 7576   effect(DEF dst, USE src1, USE src2);
 7577   ins_cost(MEMORY_REF_COST);
 7578   size(4);
 7579   format %{ &quot;FMDRR   $dst,$src1,$src2\t! regI,regI to regD&quot; %}
 7580   ins_encode %{
 7581     __ fmdrr($dst$$FloatRegister, $src1$$Register, $src2$$Register);
 7582   %}
 7583   ins_pipe(ialu_reg_reg); // FIXME
 7584 %}
 7585 
 7586 instruct convL2D_reg_slow_fxtof(regD dst, iRegL src) %{
 7587   match(Set dst (ConvL2D src));
 7588   ins_cost(DEFAULT_COST*8 + MEMORY_REF_COST*6); // FIXME
 7589 
 7590   expand %{
 7591     regD_low   tmpsrc;
 7592     iRegI      ix43300000;
 7593     iRegI      ix41f00000;
 7594     iRegI      ix0;
 7595     regD_low   dx43300000;
 7596     regD       dx41f00000;
 7597     regD       tmp1;
 7598     regD_low   tmp2;
 7599     regD       tmp3;
 7600     regD       tmp4;
 7601 
 7602     regL_to_regD(tmpsrc, src);
 7603 
 7604     loadConI_x43300000(ix43300000);
 7605     loadConI_x41f00000(ix41f00000);
 7606     loadConI_x0(ix0);
 7607 
 7608     regI_regI_to_regD(dx43300000, ix0, ix43300000);
 7609     regI_regI_to_regD(dx41f00000, ix0, ix41f00000);
 7610 
 7611     convI2D_regDHi_regD(tmp1, tmpsrc);
 7612     regDHi_regDLo_to_regD(tmp2, dx43300000, tmpsrc);
 7613     subD_regD_regD(tmp3, tmp2, dx43300000);
 7614     mulD_regD_regD(tmp4, tmp1, dx41f00000);
 7615     addD_regD_regD(dst, tmp3, tmp4);
 7616   %}
 7617 %}
 7618 
 7619 instruct convL2I_reg(iRegI dst, iRegL src) %{
 7620   match(Set dst (ConvL2I src));
 7621   size(4);
 7622   format %{ &quot;MOV    $dst,$src.lo\t! long-&gt;int&quot; %}
 7623   ins_encode %{
 7624     __ mov($dst$$Register, $src$$Register);
 7625   %}
 7626   ins_pipe(ialu_move_reg_I_to_L);
 7627 %}
 7628 
 7629 // Register Shift Right Immediate
 7630 instruct shrL_reg_imm6_L2I(iRegI dst, iRegL src, immI_32_63 cnt) %{
 7631   match(Set dst (ConvL2I (RShiftL src cnt)));
 7632   size(4);
 7633   format %{ &quot;ASR    $dst,$src.hi,($cnt - 32)\t! long-&gt;int or mov if $cnt==32&quot; %}
 7634   ins_encode %{
 7635     if ($cnt$$constant == 32) {
 7636       __ mov($dst$$Register, $src$$Register-&gt;successor());
 7637     } else {
 7638       __ mov($dst$$Register, AsmOperand($src$$Register-&gt;successor(), asr, $cnt$$constant - 32));
 7639     }
 7640   %}
 7641   ins_pipe(ialu_reg_imm);
 7642 %}
 7643 
 7644 
 7645 //----------Control Flow Instructions------------------------------------------
 7646 // Compare Instructions
 7647 // Compare Integers
 7648 instruct compI_iReg(flagsReg icc, iRegI op1, iRegI op2) %{
 7649   match(Set icc (CmpI op1 op2));
 7650   effect( DEF icc, USE op1, USE op2 );
 7651 
 7652   size(4);
 7653   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7654   ins_encode %{
 7655     __ cmp_32($op1$$Register, $op2$$Register);
 7656   %}
 7657   ins_pipe(ialu_cconly_reg_reg);
 7658 %}
 7659 
 7660 #ifdef _LP64
 7661 // Compare compressed pointers
 7662 instruct compN_reg2(flagsRegU icc, iRegN op1, iRegN op2) %{
 7663   match(Set icc (CmpN op1 op2));
 7664   effect( DEF icc, USE op1, USE op2 );
 7665 
 7666   size(4);
 7667   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7668   ins_encode %{
 7669     __ cmp_32($op1$$Register, $op2$$Register);
 7670   %}
 7671   ins_pipe(ialu_cconly_reg_reg);
 7672 %}
 7673 #endif
 7674 
 7675 instruct compU_iReg(flagsRegU icc, iRegI op1, iRegI op2) %{
 7676   match(Set icc (CmpU op1 op2));
 7677 
 7678   size(4);
 7679   format %{ &quot;cmp_32 $op1,$op2\t! unsigned int&quot; %}
 7680   ins_encode %{
 7681     __ cmp_32($op1$$Register, $op2$$Register);
 7682   %}
 7683   ins_pipe(ialu_cconly_reg_reg);
 7684 %}
 7685 
 7686 instruct compI_iReg_immneg(flagsReg icc, iRegI op1, aimmIneg op2) %{
 7687   match(Set icc (CmpI op1 op2));
 7688   effect( DEF icc, USE op1 );
 7689 
 7690   size(4);
 7691   format %{ &quot;cmn_32 $op1,-$op2\t! int&quot; %}
 7692   ins_encode %{
 7693     __ cmn_32($op1$$Register, -$op2$$constant);
 7694   %}
 7695   ins_pipe(ialu_cconly_reg_imm);
 7696 %}
 7697 
 7698 instruct compI_iReg_imm(flagsReg icc, iRegI op1, aimmI op2) %{
 7699   match(Set icc (CmpI op1 op2));
 7700   effect( DEF icc, USE op1 );
 7701 
 7702   size(4);
 7703   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7704   ins_encode %{
 7705     __ cmp_32($op1$$Register, $op2$$constant);
 7706   %}
 7707   ins_pipe(ialu_cconly_reg_imm);
 7708 %}
 7709 
 7710 instruct testI_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immI0 zero ) %{
 7711   match(Set icc (CmpI (AndI op1 op2) zero));
 7712   size(4);
 7713   format %{ &quot;tst_32 $op2,$op1&quot; %}
 7714 
 7715   ins_encode %{
 7716     __ tst_32($op1$$Register, $op2$$Register);
 7717   %}
 7718   ins_pipe(ialu_cconly_reg_reg_zero);
 7719 %}
 7720 
 7721 instruct testshlI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7722   match(Set icc (CmpI (AndI op1 (LShiftI op2 op3)) zero));
 7723   size(4);
 7724   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7725 
 7726   ins_encode %{
 7727     __ tst($op1$$Register, AsmOperand($op2$$Register, lsl, $op3$$Register));
 7728   %}
 7729   ins_pipe(ialu_cconly_reg_reg_zero);
 7730 %}
 7731 
 7732 instruct testshlI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7733   match(Set icc (CmpI (AndI op1 (LShiftI op2 op3)) zero));
 7734   size(4);
 7735   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7736 
 7737   ins_encode %{
 7738     __ tst_32($op1$$Register, AsmOperand($op2$$Register, lsl, $op3$$constant));
 7739   %}
 7740   ins_pipe(ialu_cconly_reg_reg_zero);
 7741 %}
 7742 
 7743 instruct testsarI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7744   match(Set icc (CmpI (AndI op1 (RShiftI op2 op3)) zero));
 7745   size(4);
 7746   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7747 
 7748   ins_encode %{
 7749     __ tst($op1$$Register, AsmOperand($op2$$Register, asr, $op3$$Register));
 7750   %}
 7751   ins_pipe(ialu_cconly_reg_reg_zero);
 7752 %}
 7753 
 7754 instruct testsarI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7755   match(Set icc (CmpI (AndI op1 (RShiftI op2 op3)) zero));
 7756   size(4);
 7757   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7758 
 7759   ins_encode %{
 7760     __ tst_32($op1$$Register, AsmOperand($op2$$Register, asr, $op3$$constant));
 7761   %}
 7762   ins_pipe(ialu_cconly_reg_reg_zero);
 7763 %}
 7764 
 7765 instruct testshrI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7766   match(Set icc (CmpI (AndI op1 (URShiftI op2 op3)) zero));
 7767   size(4);
 7768   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7769 
 7770   ins_encode %{
 7771     __ tst($op1$$Register, AsmOperand($op2$$Register, lsr, $op3$$Register));
 7772   %}
 7773   ins_pipe(ialu_cconly_reg_reg_zero);
 7774 %}
 7775 
 7776 instruct testshrI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7777   match(Set icc (CmpI (AndI op1 (URShiftI op2 op3)) zero));
 7778   size(4);
 7779   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7780 
 7781   ins_encode %{
 7782     __ tst_32($op1$$Register, AsmOperand($op2$$Register, lsr, $op3$$constant));
 7783   %}
 7784   ins_pipe(ialu_cconly_reg_reg_zero);
 7785 %}
 7786 
 7787 instruct testI_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, limmI op2, immI0 zero ) %{
 7788   match(Set icc (CmpI (AndI op1 op2) zero));
 7789   size(4);
 7790   format %{ &quot;tst_32 $op2,$op1&quot; %}
 7791 
 7792   ins_encode %{
 7793     __ tst_32($op1$$Register, $op2$$constant);
 7794   %}
 7795   ins_pipe(ialu_cconly_reg_imm_zero);
 7796 %}
 7797 
 7798 instruct compL_reg_reg_LTGE(flagsRegL_LTGE xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7799   match(Set xcc (CmpL op1 op2));
 7800   effect( DEF xcc, USE op1, USE op2, TEMP tmp );
 7801 
 7802   size(8);
 7803   format %{ &quot;SUBS    $tmp,$op1.low,$op2.low\t\t! long\n\t&quot;
 7804             &quot;SBCS    $tmp,$op1.hi,$op2.hi&quot; %}
 7805   ins_encode %{
 7806     __ subs($tmp$$Register, $op1$$Register, $op2$$Register);
 7807     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7808   %}
 7809   ins_pipe(ialu_cconly_reg_reg);
 7810 %}
 7811 
 7812 instruct compUL_reg_reg_LTGE(flagsRegUL_LTGE xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7813   match(Set xcc (CmpUL op1 op2));
 7814   effect(DEF xcc, USE op1, USE op2, TEMP tmp);
 7815 
 7816   size(8);
 7817   format %{ &quot;SUBS    $tmp,$op1.low,$op2.low\t\t! unsigned long\n\t&quot;
 7818             &quot;SBCS    $tmp,$op1.hi,$op2.hi&quot; %}
 7819   ins_encode %{
 7820     __ subs($tmp$$Register, $op1$$Register, $op2$$Register);
 7821     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7822   %}
 7823   ins_pipe(ialu_cconly_reg_reg);
 7824 %}
 7825 
 7826 instruct compL_reg_reg_EQNE(flagsRegL_EQNE xcc, iRegL op1, iRegL op2) %{
 7827   match(Set xcc (CmpL op1 op2));
 7828   effect( DEF xcc, USE op1, USE op2 );
 7829 
 7830   size(8);
 7831   format %{ &quot;TEQ    $op1.hi,$op2.hi\t\t! long\n\t&quot;
 7832             &quot;TEQ.eq $op1.lo,$op2.lo&quot; %}
 7833   ins_encode %{
 7834     __ teq($op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7835     __ teq($op1$$Register, $op2$$Register, eq);
 7836   %}
 7837   ins_pipe(ialu_cconly_reg_reg);
 7838 %}
 7839 
 7840 instruct compL_reg_reg_LEGT(flagsRegL_LEGT xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7841   match(Set xcc (CmpL op1 op2));
 7842   effect( DEF xcc, USE op1, USE op2, TEMP tmp );
 7843 
 7844   size(8);
 7845   format %{ &quot;SUBS    $tmp,$op2.low,$op1.low\t\t! long\n\t&quot;
 7846             &quot;SBCS    $tmp,$op2.hi,$op1.hi&quot; %}
 7847   ins_encode %{
 7848     __ subs($tmp$$Register, $op2$$Register, $op1$$Register);
 7849     __ sbcs($tmp$$Register-&gt;successor(), $op2$$Register-&gt;successor(), $op1$$Register-&gt;successor());
 7850   %}
 7851   ins_pipe(ialu_cconly_reg_reg);
 7852 %}
 7853 
 7854 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7855 // (hi($con$$constant), lo($con$$constant)) becomes
 7856 instruct compL_reg_con_LTGE(flagsRegL_LTGE xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7857   match(Set xcc (CmpL op1 con));
 7858   effect( DEF xcc, USE op1, USE con, TEMP tmp );
 7859 
 7860   size(8);
 7861   format %{ &quot;SUBS    $tmp,$op1.low,$con\t\t! long\n\t&quot;
 7862             &quot;SBCS    $tmp,$op1.hi,0&quot; %}
 7863   ins_encode %{
 7864     __ subs($tmp$$Register, $op1$$Register, $con$$constant);
 7865     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7866   %}
 7867 
 7868   ins_pipe(ialu_cconly_reg_reg);
 7869 %}
 7870 
 7871 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7872 // (hi($con$$constant), lo($con$$constant)) becomes
 7873 instruct compL_reg_con_EQNE(flagsRegL_EQNE xcc, iRegL op1, immLlowRot con) %{
 7874   match(Set xcc (CmpL op1 con));
 7875   effect( DEF xcc, USE op1, USE con );
 7876 
 7877   size(8);
 7878   format %{ &quot;TEQ    $op1.hi,0\t\t! long\n\t&quot;
 7879             &quot;TEQ.eq $op1.lo,$con&quot; %}
 7880   ins_encode %{
 7881     __ teq($op1$$Register-&gt;successor(), 0);
 7882     __ teq($op1$$Register, $con$$constant, eq);
 7883   %}
 7884 
 7885   ins_pipe(ialu_cconly_reg_reg);
 7886 %}
 7887 
 7888 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7889 // (hi($con$$constant), lo($con$$constant)) becomes
 7890 instruct compL_reg_con_LEGT(flagsRegL_LEGT xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7891   match(Set xcc (CmpL op1 con));
 7892   effect( DEF xcc, USE op1, USE con, TEMP tmp );
 7893 
 7894   size(8);
 7895   format %{ &quot;RSBS    $tmp,$op1.low,$con\t\t! long\n\t&quot;
 7896             &quot;RSCS    $tmp,$op1.hi,0&quot; %}
 7897   ins_encode %{
 7898     __ rsbs($tmp$$Register, $op1$$Register, $con$$constant);
 7899     __ rscs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7900   %}
 7901 
 7902   ins_pipe(ialu_cconly_reg_reg);
 7903 %}
 7904 
 7905 instruct compUL_reg_reg_EQNE(flagsRegUL_EQNE xcc, iRegL op1, iRegL op2) %{
 7906   match(Set xcc (CmpUL op1 op2));
 7907   effect(DEF xcc, USE op1, USE op2);
 7908 
 7909   size(8);
 7910   format %{ &quot;TEQ    $op1.hi,$op2.hi\t\t! unsigned long\n\t&quot;
 7911             &quot;TEQ.eq $op1.lo,$op2.lo&quot; %}
 7912   ins_encode %{
 7913     __ teq($op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7914     __ teq($op1$$Register, $op2$$Register, eq);
 7915   %}
 7916   ins_pipe(ialu_cconly_reg_reg);
 7917 %}
 7918 
 7919 instruct compUL_reg_reg_LEGT(flagsRegUL_LEGT xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7920   match(Set xcc (CmpUL op1 op2));
 7921   effect(DEF xcc, USE op1, USE op2, TEMP tmp);
 7922 
 7923   size(8);
 7924   format %{ &quot;SUBS    $tmp,$op2.low,$op1.low\t\t! unsigned long\n\t&quot;
 7925             &quot;SBCS    $tmp,$op2.hi,$op1.hi&quot; %}
 7926   ins_encode %{
 7927     __ subs($tmp$$Register, $op2$$Register, $op1$$Register);
 7928     __ sbcs($tmp$$Register-&gt;successor(), $op2$$Register-&gt;successor(), $op1$$Register-&gt;successor());
 7929   %}
 7930   ins_pipe(ialu_cconly_reg_reg);
 7931 %}
 7932 
 7933 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7934 // (hi($con$$constant), lo($con$$constant)) becomes
 7935 instruct compUL_reg_con_LTGE(flagsRegUL_LTGE xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7936   match(Set xcc (CmpUL op1 con));
 7937   effect(DEF xcc, USE op1, USE con, TEMP tmp);
 7938 
 7939   size(8);
 7940   format %{ &quot;SUBS    $tmp,$op1.low,$con\t\t! unsigned long\n\t&quot;
 7941             &quot;SBCS    $tmp,$op1.hi,0&quot; %}
 7942   ins_encode %{
 7943     __ subs($tmp$$Register, $op1$$Register, $con$$constant);
 7944     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7945   %}
 7946 
 7947   ins_pipe(ialu_cconly_reg_reg);
 7948 %}
 7949 
 7950 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7951 // (hi($con$$constant), lo($con$$constant)) becomes
 7952 instruct compUL_reg_con_EQNE(flagsRegUL_EQNE xcc, iRegL op1, immLlowRot con) %{
 7953   match(Set xcc (CmpUL op1 con));
 7954   effect(DEF xcc, USE op1, USE con);
 7955 
 7956   size(8);
 7957   format %{ &quot;TEQ    $op1.hi,0\t\t! unsigned long\n\t&quot;
 7958             &quot;TEQ.eq $op1.lo,$con&quot; %}
 7959   ins_encode %{
 7960     __ teq($op1$$Register-&gt;successor(), 0);
 7961     __ teq($op1$$Register, $con$$constant, eq);
 7962   %}
 7963 
 7964   ins_pipe(ialu_cconly_reg_reg);
 7965 %}
 7966 
 7967 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7968 // (hi($con$$constant), lo($con$$constant)) becomes
 7969 instruct compUL_reg_con_LEGT(flagsRegUL_LEGT xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7970   match(Set xcc (CmpUL op1 con));
 7971   effect(DEF xcc, USE op1, USE con, TEMP tmp);
 7972 
 7973   size(8);
 7974   format %{ &quot;RSBS    $tmp,$op1.low,$con\t\t! unsigned long\n\t&quot;
 7975             &quot;RSCS    $tmp,$op1.hi,0&quot; %}
 7976   ins_encode %{
 7977     __ rsbs($tmp$$Register, $op1$$Register, $con$$constant);
 7978     __ rscs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7979   %}
 7980 
 7981   ins_pipe(ialu_cconly_reg_reg);
 7982 %}
 7983 
 7984 /* instruct testL_reg_reg(flagsRegL xcc, iRegL op1, iRegL op2, immL0 zero) %{ */
 7985 /*   match(Set xcc (CmpL (AndL op1 op2) zero)); */
 7986 /*   ins_encode %{ */
 7987 /*     __ stop(&quot;testL_reg_reg unimplemented&quot;); */
 7988 /*   %} */
 7989 /*   ins_pipe(ialu_cconly_reg_reg); */
 7990 /* %} */
 7991 
 7992 /* // useful for checking the alignment of a pointer: */
 7993 /* instruct testL_reg_con(flagsRegL xcc, iRegL op1, immLlowRot con, immL0 zero) %{ */
 7994 /*   match(Set xcc (CmpL (AndL op1 con) zero)); */
 7995 /*   ins_encode %{ */
 7996 /*     __ stop(&quot;testL_reg_con unimplemented&quot;); */
 7997 /*   %} */
 7998 /*   ins_pipe(ialu_cconly_reg_reg); */
 7999 /* %} */
 8000 
 8001 instruct compU_iReg_imm(flagsRegU icc, iRegI op1, aimmU31 op2 ) %{
 8002   match(Set icc (CmpU op1 op2));
 8003 
 8004   size(4);
 8005   format %{ &quot;cmp_32 $op1,$op2\t! unsigned&quot; %}
 8006   ins_encode %{
 8007     __ cmp_32($op1$$Register, $op2$$constant);
 8008   %}
 8009   ins_pipe(ialu_cconly_reg_imm);
 8010 %}
 8011 
 8012 // Compare Pointers
 8013 instruct compP_iRegP(flagsRegP pcc, iRegP op1, iRegP op2 ) %{
 8014   match(Set pcc (CmpP op1 op2));
 8015 
 8016   size(4);
 8017   format %{ &quot;CMP    $op1,$op2\t! ptr&quot; %}
 8018   ins_encode %{
 8019     __ cmp($op1$$Register, $op2$$Register);
 8020   %}
 8021   ins_pipe(ialu_cconly_reg_reg);
 8022 %}
 8023 
 8024 instruct compP_iRegP_imm(flagsRegP pcc, iRegP op1, aimmP op2 ) %{
 8025   match(Set pcc (CmpP op1 op2));
 8026 
 8027   size(4);
 8028   format %{ &quot;CMP    $op1,$op2\t! ptr&quot; %}
 8029   ins_encode %{
 8030     assert($op2$$constant == 0 || _opnds[2]-&gt;constant_reloc() == relocInfo::none, &quot;reloc in cmp?&quot;);
 8031     __ cmp($op1$$Register, $op2$$constant);
 8032   %}
 8033   ins_pipe(ialu_cconly_reg_imm);
 8034 %}
 8035 
 8036 //----------Max and Min--------------------------------------------------------
 8037 // Min Instructions
 8038 // Conditional move for min
 8039 instruct cmovI_reg_lt( iRegI op2, iRegI op1, flagsReg icc ) %{
 8040   effect( USE_DEF op2, USE op1, USE icc );
 8041 
 8042   size(4);
 8043   format %{ &quot;MOV.lt  $op2,$op1\t! min&quot; %}
 8044   ins_encode %{
 8045     __ mov($op2$$Register, $op1$$Register, lt);
 8046   %}
 8047   ins_pipe(ialu_reg_flags);
 8048 %}
 8049 
 8050 // Min Register with Register.
 8051 instruct minI_eReg(iRegI op1, iRegI op2) %{
 8052   match(Set op2 (MinI op1 op2));
 8053   ins_cost(DEFAULT_COST*2);
 8054   expand %{
 8055     flagsReg icc;
 8056     compI_iReg(icc,op1,op2);
 8057     cmovI_reg_lt(op2,op1,icc);
 8058   %}
 8059 %}
 8060 
 8061 // Max Instructions
 8062 // Conditional move for max
 8063 instruct cmovI_reg_gt( iRegI op2, iRegI op1, flagsReg icc ) %{
 8064   effect( USE_DEF op2, USE op1, USE icc );
 8065   format %{ &quot;MOV.gt  $op2,$op1\t! max&quot; %}
 8066   ins_encode %{
 8067     __ mov($op2$$Register, $op1$$Register, gt);
 8068   %}
 8069   ins_pipe(ialu_reg_flags);
 8070 %}
 8071 
 8072 // Max Register with Register
 8073 instruct maxI_eReg(iRegI op1, iRegI op2) %{
 8074   match(Set op2 (MaxI op1 op2));
 8075   ins_cost(DEFAULT_COST*2);
 8076   expand %{
 8077     flagsReg icc;
 8078     compI_iReg(icc,op1,op2);
 8079     cmovI_reg_gt(op2,op1,icc);
 8080   %}
 8081 %}
 8082 
 8083 
 8084 //----------Float Compares----------------------------------------------------
 8085 // Compare floating, generate condition code
 8086 instruct cmpF_cc(flagsRegF fcc, flagsReg icc, regF src1, regF src2) %{
 8087   match(Set icc (CmpF src1 src2));
 8088   effect(KILL fcc);
 8089 
 8090   size(8);
 8091   format %{ &quot;FCMPs  $src1,$src2\n\t&quot;
 8092             &quot;FMSTAT&quot; %}
 8093   ins_encode %{
 8094     __ fcmps($src1$$FloatRegister, $src2$$FloatRegister);
 8095     __ fmstat();
 8096   %}
 8097   ins_pipe(faddF_fcc_reg_reg_zero);
 8098 %}
 8099 
 8100 instruct cmpF0_cc(flagsRegF fcc, flagsReg icc, regF src1, immF0 src2) %{
 8101   match(Set icc (CmpF src1 src2));
 8102   effect(KILL fcc);
 8103 
 8104   size(8);
 8105   format %{ &quot;FCMPs  $src1,$src2\n\t&quot;
 8106             &quot;FMSTAT&quot; %}
 8107   ins_encode %{
 8108     __ fcmpzs($src1$$FloatRegister);
 8109     __ fmstat();
 8110   %}
 8111   ins_pipe(faddF_fcc_reg_reg_zero);
 8112 %}
 8113 
 8114 instruct cmpD_cc(flagsRegF fcc, flagsReg icc, regD src1, regD src2) %{
 8115   match(Set icc (CmpD src1 src2));
 8116   effect(KILL fcc);
 8117 
 8118   size(8);
 8119   format %{ &quot;FCMPd  $src1,$src2 \n\t&quot;
 8120             &quot;FMSTAT&quot; %}
 8121   ins_encode %{
 8122     __ fcmpd($src1$$FloatRegister, $src2$$FloatRegister);
 8123     __ fmstat();
 8124   %}
 8125   ins_pipe(faddD_fcc_reg_reg_zero);
 8126 %}
 8127 
 8128 instruct cmpD0_cc(flagsRegF fcc, flagsReg icc, regD src1, immD0 src2) %{
 8129   match(Set icc (CmpD src1 src2));
 8130   effect(KILL fcc);
 8131 
 8132   size(8);
 8133   format %{ &quot;FCMPZd  $src1,$src2 \n\t&quot;
 8134             &quot;FMSTAT&quot; %}
 8135   ins_encode %{
 8136     __ fcmpzd($src1$$FloatRegister);
 8137     __ fmstat();
 8138   %}
 8139   ins_pipe(faddD_fcc_reg_reg_zero);
 8140 %}
 8141 
 8142 // Compare floating, generate -1,0,1
 8143 instruct cmpF_reg(iRegI dst, regF src1, regF src2, flagsRegF fcc) %{
 8144   match(Set dst (CmpF3 src1 src2));
 8145   effect(KILL fcc);
 8146   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8147   size(20);
 8148   // same number of instructions as code using conditional moves but
 8149   // doesn&#39;t kill integer condition register
 8150   format %{ &quot;FCMPs  $dst,$src1,$src2 \n\t&quot;
 8151             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8152             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8153             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8154             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8155   ins_encode %{
 8156     __ fcmps($src1$$FloatRegister, $src2$$FloatRegister);
 8157     __ floating_cmp($dst$$Register);
 8158   %}
 8159   ins_pipe( floating_cmp );
 8160 %}
 8161 
 8162 instruct cmpF0_reg(iRegI dst, regF src1, immF0 src2, flagsRegF fcc) %{
 8163   match(Set dst (CmpF3 src1 src2));
 8164   effect(KILL fcc);
 8165   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8166   size(20);
 8167   // same number of instructions as code using conditional moves but
 8168   // doesn&#39;t kill integer condition register
 8169   format %{ &quot;FCMPZs $dst,$src1,$src2 \n\t&quot;
 8170             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8171             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8172             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8173             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8174   ins_encode %{
 8175     __ fcmpzs($src1$$FloatRegister);
 8176     __ floating_cmp($dst$$Register);
 8177   %}
 8178   ins_pipe( floating_cmp );
 8179 %}
 8180 
 8181 instruct cmpD_reg(iRegI dst, regD src1, regD src2, flagsRegF fcc) %{
 8182   match(Set dst (CmpD3 src1 src2));
 8183   effect(KILL fcc);
 8184   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8185   size(20);
 8186   // same number of instructions as code using conditional moves but
 8187   // doesn&#39;t kill integer condition register
 8188   format %{ &quot;FCMPd  $dst,$src1,$src2 \n\t&quot;
 8189             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8190             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8191             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8192             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8193   ins_encode %{
 8194     __ fcmpd($src1$$FloatRegister, $src2$$FloatRegister);
 8195     __ floating_cmp($dst$$Register);
 8196   %}
 8197   ins_pipe( floating_cmp );
 8198 %}
 8199 
 8200 instruct cmpD0_reg(iRegI dst, regD src1, immD0 src2, flagsRegF fcc) %{
 8201   match(Set dst (CmpD3 src1 src2));
 8202   effect(KILL fcc);
 8203   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8204   size(20);
 8205   // same number of instructions as code using conditional moves but
 8206   // doesn&#39;t kill integer condition register
 8207   format %{ &quot;FCMPZd $dst,$src1,$src2 \n\t&quot;
 8208             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8209             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8210             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8211             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8212   ins_encode %{
 8213     __ fcmpzd($src1$$FloatRegister);
 8214     __ floating_cmp($dst$$Register);
 8215   %}
 8216   ins_pipe( floating_cmp );
 8217 %}
 8218 
 8219 //----------Branches---------------------------------------------------------
 8220 // Jump
 8221 // (compare &#39;operand indIndex&#39; and &#39;instruct addP_reg_reg&#39; above)
 8222 // FIXME
 8223 instruct jumpXtnd(iRegX switch_val, iRegP tmp) %{
 8224   match(Jump switch_val);
 8225   effect(TEMP tmp);
 8226   ins_cost(350);
 8227   format %{  &quot;ADD    $tmp, $constanttablebase, $switch_val\n\t&quot;
 8228              &quot;LDR    $tmp,[$tmp + $constantoffset]\n\t&quot;
 8229              &quot;BX     $tmp&quot; %}
 8230   size(20);
 8231   ins_encode %{
 8232     Register table_reg;
 8233     Register label_reg = $tmp$$Register;
 8234     if (constant_offset() == 0) {
 8235       table_reg = $constanttablebase;
 8236       __ ldr(label_reg, Address(table_reg, $switch_val$$Register));
 8237     } else {
 8238       table_reg = $tmp$$Register;
 8239       int offset = $constantoffset;
 8240       if (is_memoryP(offset)) {
 8241         __ add(table_reg, $constanttablebase, $switch_val$$Register);
 8242         __ ldr(label_reg, Address(table_reg, offset));
 8243       } else {
 8244         __ mov_slow(table_reg, $constantoffset);
 8245         __ add(table_reg, $constanttablebase, table_reg);
 8246         __ ldr(label_reg, Address(table_reg, $switch_val$$Register));
 8247       }
 8248     }
 8249     __ jump(label_reg); // ldr + b better than ldr to PC for branch predictor?
 8250     //    __ ldr(PC, Address($table$$Register, $switch_val$$Register));
 8251   %}
 8252   ins_pipe(ialu_reg_reg);
 8253 %}
 8254 
 8255 // // Direct Branch.
 8256 instruct branch(label labl) %{
 8257   match(Goto);
 8258   effect(USE labl);
 8259 
 8260   size(4);
 8261   ins_cost(BRANCH_COST);
 8262   format %{ &quot;B     $labl&quot; %}
 8263   ins_encode %{
 8264     __ b(*($labl$$label));
 8265   %}
 8266   ins_pipe(br);
 8267 %}
 8268 
 8269 // Conditional Direct Branch
 8270 instruct branchCon(cmpOp cmp, flagsReg icc, label labl) %{
 8271   match(If cmp icc);
 8272   effect(USE labl);
 8273 
 8274   size(4);
 8275   ins_cost(BRANCH_COST);
 8276   format %{ &quot;B$cmp   $icc,$labl&quot; %}
 8277   ins_encode %{
 8278     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8279   %}
 8280   ins_pipe(br_cc);
 8281 %}
 8282 
 8283 #ifdef ARM
 8284 instruct branchCon_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, label labl) %{
 8285   match(If cmp icc);
 8286   effect(USE labl);
 8287   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 8288 
 8289   size(4);
 8290   ins_cost(BRANCH_COST);
 8291   format %{ &quot;B$cmp   $icc,$labl&quot; %}
 8292   ins_encode %{
 8293     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8294   %}
 8295   ins_pipe(br_cc);
 8296 %}
 8297 #endif
 8298 
 8299 
 8300 instruct branchConU(cmpOpU cmp, flagsRegU icc, label labl) %{
 8301   match(If cmp icc);
 8302   effect(USE labl);
 8303 
 8304   size(4);
 8305   ins_cost(BRANCH_COST);
 8306   format %{ &quot;B$cmp  $icc,$labl&quot; %}
 8307   ins_encode %{
 8308     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8309   %}
 8310   ins_pipe(br_cc);
 8311 %}
 8312 
 8313 instruct branchConP(cmpOpP cmp, flagsRegP pcc, label labl) %{
 8314   match(If cmp pcc);
 8315   effect(USE labl);
 8316 
 8317   size(4);
 8318   ins_cost(BRANCH_COST);
 8319   format %{ &quot;B$cmp  $pcc,$labl&quot; %}
 8320   ins_encode %{
 8321     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8322   %}
 8323   ins_pipe(br_cc);
 8324 %}
 8325 
 8326 instruct branchConL_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, label labl) %{
 8327   match(If cmp xcc);
 8328   effect(USE labl);
 8329   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8330 
 8331   size(4);
 8332   ins_cost(BRANCH_COST);
 8333   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8334   ins_encode %{
 8335     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8336   %}
 8337   ins_pipe(br_cc);
 8338 %}
 8339 
 8340 instruct branchConL_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, label labl) %{
 8341   match(If cmp xcc);
 8342   effect(USE labl);
 8343   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8344 
 8345   size(4);
 8346   ins_cost(BRANCH_COST);
 8347   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8348   ins_encode %{
 8349     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8350   %}
 8351   ins_pipe(br_cc);
 8352 %}
 8353 
 8354 instruct branchConL_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, label labl) %{
 8355   match(If cmp xcc);
 8356   effect(USE labl);
 8357   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le );
 8358 
 8359   size(4);
 8360   ins_cost(BRANCH_COST);
 8361   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8362   ins_encode %{
 8363     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8364   %}
 8365   ins_pipe(br_cc);
 8366 %}
 8367 
 8368 instruct branchConUL_LTGE(cmpOpUL cmp, flagsRegUL_LTGE xcc, label labl) %{
 8369   match(If cmp xcc);
 8370   effect(USE labl);
 8371   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 8372 
 8373   size(4);
 8374   ins_cost(BRANCH_COST);
 8375   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8376   ins_encode %{
 8377     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8378   %}
 8379   ins_pipe(br_cc);
 8380 %}
 8381 
 8382 instruct branchConUL_EQNE(cmpOpUL cmp, flagsRegUL_EQNE xcc, label labl) %{
 8383   match(If cmp xcc);
 8384   effect(USE labl);
 8385   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne);
 8386 
 8387   size(4);
 8388   ins_cost(BRANCH_COST);
 8389   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8390   ins_encode %{
 8391     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8392   %}
 8393   ins_pipe(br_cc);
 8394 %}
 8395 
 8396 instruct branchConUL_LEGT(cmpOpUL_commute cmp, flagsRegUL_LEGT xcc, label labl) %{
 8397   match(If cmp xcc);
 8398   effect(USE labl);
 8399   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le);
 8400 
 8401   size(4);
 8402   ins_cost(BRANCH_COST);
 8403   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8404   ins_encode %{
 8405     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8406   %}
 8407   ins_pipe(br_cc);
 8408 %}
 8409 
 8410 instruct branchLoopEnd(cmpOp cmp, flagsReg icc, label labl) %{
 8411   match(CountedLoopEnd cmp icc);
 8412   effect(USE labl);
 8413 
 8414   size(4);
 8415   ins_cost(BRANCH_COST);
 8416   format %{ &quot;B$cmp   $icc,$labl\t! Loop end&quot; %}
 8417   ins_encode %{
 8418     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8419   %}
 8420   ins_pipe(br_cc);
 8421 %}
 8422 
 8423 // instruct branchLoopEndU(cmpOpU cmp, flagsRegU icc, label labl) %{
 8424 //   match(CountedLoopEnd cmp icc);
 8425 //   ins_pipe(br_cc);
 8426 // %}
 8427 
 8428 // ============================================================================
 8429 // Long Compare
 8430 //
 8431 // Currently we hold longs in 2 registers.  Comparing such values efficiently
 8432 // is tricky.  The flavor of compare used depends on whether we are testing
 8433 // for LT, LE, or EQ.  For a simple LT test we can check just the sign bit.
 8434 // The GE test is the negated LT test.  The LE test can be had by commuting
 8435 // the operands (yielding a GE test) and then negating; negate again for the
 8436 // GT test.  The EQ test is done by ORcc&#39;ing the high and low halves, and the
 8437 // NE test is negated from that.
 8438 
 8439 // Due to a shortcoming in the ADLC, it mixes up expressions like:
 8440 // (foo (CmpI (CmpL X Y) 0)) and (bar (CmpI (CmpL X 0L) 0)).  Note the
 8441 // difference between &#39;Y&#39; and &#39;0L&#39;.  The tree-matches for the CmpI sections
 8442 // are collapsed internally in the ADLC&#39;s dfa-gen code.  The match for
 8443 // (CmpI (CmpL X Y) 0) is silently replaced with (CmpI (CmpL X 0L) 0) and the
 8444 // foo match ends up with the wrong leaf.  One fix is to not match both
 8445 // reg-reg and reg-zero forms of long-compare.  This is unfortunate because
 8446 // both forms beat the trinary form of long-compare and both are very useful
 8447 // on Intel which has so few registers.
 8448 
 8449 // instruct branchCon_long(cmpOp cmp, flagsRegL xcc, label labl) %{
 8450 //   match(If cmp xcc);
 8451 //   ins_pipe(br_cc);
 8452 // %}
 8453 
 8454 // Manifest a CmpL3 result in an integer register.  Very painful.
 8455 // This is the test to avoid.
 8456 instruct cmpL3_reg_reg(iRegI dst, iRegL src1, iRegL src2, flagsReg ccr ) %{
 8457   match(Set dst (CmpL3 src1 src2) );
 8458   effect( KILL ccr );
 8459   ins_cost(6*DEFAULT_COST); // FIXME
 8460   size(32);
 8461   format %{
 8462       &quot;CMP    $src1.hi, $src2.hi\t\t! long\n&quot;
 8463     &quot;\tMOV.gt $dst, 1\n&quot;
 8464     &quot;\tmvn.lt $dst, 0\n&quot;
 8465     &quot;\tB.ne   done\n&quot;
 8466     &quot;\tSUBS   $dst, $src1.lo, $src2.lo\n&quot;
 8467     &quot;\tMOV.hi $dst, 1\n&quot;
 8468     &quot;\tmvn.lo $dst, 0\n&quot;
 8469     &quot;done:&quot;     %}
 8470   ins_encode %{
 8471     Label done;
 8472     __ cmp($src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 8473     __ mov($dst$$Register, 1, gt);
 8474     __ mvn($dst$$Register, 0, lt);
 8475     __ b(done, ne);
 8476     __ subs($dst$$Register, $src1$$Register, $src2$$Register);
 8477     __ mov($dst$$Register, 1, hi);
 8478     __ mvn($dst$$Register, 0, lo);
 8479     __ bind(done);
 8480   %}
 8481   ins_pipe(cmpL_reg);
 8482 %}
 8483 
 8484 // Conditional move
 8485 instruct cmovLL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegL dst, iRegL src) %{
 8486   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8487   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8488 
 8489   ins_cost(150);
 8490   size(8);
 8491   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8492             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8493   ins_encode %{
 8494     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8495     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8496   %}
 8497   ins_pipe(ialu_reg);
 8498 %}
 8499 
 8500 instruct cmovLL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegL dst, iRegL src) %{
 8501   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8502   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8503 
 8504   ins_cost(150);
 8505   size(8);
 8506   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8507             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8508   ins_encode %{
 8509     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8510     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8511   %}
 8512   ins_pipe(ialu_reg);
 8513 %}
 8514 
 8515 instruct cmovLL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegL dst, iRegL src) %{
 8516   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8517   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8518 
 8519   ins_cost(150);
 8520   size(8);
 8521   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8522             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8523   ins_encode %{
 8524     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8525     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8526   %}
 8527   ins_pipe(ialu_reg);
 8528 %}
 8529 
 8530 instruct cmovLL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegL dst, immL0 src) %{
 8531   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8532   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8533   ins_cost(140);
 8534   size(8);
 8535   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8536             &quot;MOV$cmp  $dst,0&quot; %}
 8537   ins_encode %{
 8538     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8539     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8540   %}
 8541   ins_pipe(ialu_imm);
 8542 %}
 8543 
 8544 instruct cmovLL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegL dst, immL0 src) %{
 8545   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8546   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8547   ins_cost(140);
 8548   size(8);
 8549   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8550             &quot;MOV$cmp  $dst,0&quot; %}
 8551   ins_encode %{
 8552     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8553     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8554   %}
 8555   ins_pipe(ialu_imm);
 8556 %}
 8557 
 8558 instruct cmovLL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegL dst, immL0 src) %{
 8559   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8560   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8561   ins_cost(140);
 8562   size(8);
 8563   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8564             &quot;MOV$cmp  $dst,0&quot; %}
 8565   ins_encode %{
 8566     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8567     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8568   %}
 8569   ins_pipe(ialu_imm);
 8570 %}
 8571 
 8572 instruct cmovIL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegI dst, iRegI src) %{
 8573   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8574   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8575 
 8576   ins_cost(150);
 8577   size(4);
 8578   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8579   ins_encode %{
 8580     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8581   %}
 8582   ins_pipe(ialu_reg);
 8583 %}
 8584 
 8585 instruct cmovIL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegI dst, iRegI src) %{
 8586   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8587   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8588 
 8589   ins_cost(150);
 8590   size(4);
 8591   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8592   ins_encode %{
 8593     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8594   %}
 8595   ins_pipe(ialu_reg);
 8596 %}
 8597 
 8598 instruct cmovIL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegI dst, iRegI src) %{
 8599   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8600   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8601 
 8602   ins_cost(150);
 8603   size(4);
 8604   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8605   ins_encode %{
 8606     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8607   %}
 8608   ins_pipe(ialu_reg);
 8609 %}
 8610 
 8611 instruct cmovIL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegI dst, immI16 src) %{
 8612   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8613   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8614 
 8615   ins_cost(140);
 8616   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8617   ins_encode %{
 8618     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8619   %}
 8620   ins_pipe(ialu_imm);
 8621 %}
 8622 
 8623 instruct cmovIL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegI dst, immI16 src) %{
 8624   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8625   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8626 
 8627   ins_cost(140);
 8628   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8629   ins_encode %{
 8630     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8631   %}
 8632   ins_pipe(ialu_imm);
 8633 %}
 8634 
 8635 instruct cmovIL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegI dst, immI16 src) %{
 8636   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8637   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8638 
 8639   ins_cost(140);
 8640   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8641   ins_encode %{
 8642     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8643   %}
 8644   ins_pipe(ialu_imm);
 8645 %}
 8646 
 8647 instruct cmovPL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegP dst, iRegP src) %{
 8648   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8649   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8650 
 8651   ins_cost(150);
 8652   size(4);
 8653   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8654   ins_encode %{
 8655     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8656   %}
 8657   ins_pipe(ialu_reg);
 8658 %}
 8659 
 8660 instruct cmovPL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegP dst, iRegP src) %{
 8661   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8662   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8663 
 8664   ins_cost(150);
 8665   size(4);
 8666   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8667   ins_encode %{
 8668     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8669   %}
 8670   ins_pipe(ialu_reg);
 8671 %}
 8672 
 8673 instruct cmovPL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegP dst, iRegP src) %{
 8674   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8675   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8676 
 8677   ins_cost(150);
 8678   size(4);
 8679   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8680   ins_encode %{
 8681     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8682   %}
 8683   ins_pipe(ialu_reg);
 8684 %}
 8685 
 8686 instruct cmovPL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegP dst, immP0 src) %{
 8687   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8688   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8689 
 8690   ins_cost(140);
 8691   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8692   ins_encode %{
 8693     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8694   %}
 8695   ins_pipe(ialu_imm);
 8696 %}
 8697 
 8698 instruct cmovPL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegP dst, immP0 src) %{
 8699   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8700   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8701 
 8702   ins_cost(140);
 8703   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8704   ins_encode %{
 8705     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8706   %}
 8707   ins_pipe(ialu_imm);
 8708 %}
 8709 
 8710 instruct cmovPL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegP dst, immP0 src) %{
 8711   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8712   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8713 
 8714   ins_cost(140);
 8715   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8716   ins_encode %{
 8717     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8718   %}
 8719   ins_pipe(ialu_imm);
 8720 %}
 8721 
 8722 instruct cmovFL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, regF dst, regF src) %{
 8723   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8724   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8725   ins_cost(150);
 8726   size(4);
 8727   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8728   ins_encode %{
 8729     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8730   %}
 8731   ins_pipe(int_conditional_float_move);
 8732 %}
 8733 
 8734 instruct cmovFL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, regF dst, regF src) %{
 8735   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8736   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8737   ins_cost(150);
 8738   size(4);
 8739   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8740   ins_encode %{
 8741     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8742   %}
 8743   ins_pipe(int_conditional_float_move);
 8744 %}
 8745 
 8746 instruct cmovFL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, regF dst, regF src) %{
 8747   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8748   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8749   ins_cost(150);
 8750   size(4);
 8751   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8752   ins_encode %{
 8753     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8754   %}
 8755   ins_pipe(int_conditional_float_move);
 8756 %}
 8757 
 8758 instruct cmovDL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, regD dst, regD src) %{
 8759   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8760   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8761 
 8762   ins_cost(150);
 8763   size(4);
 8764   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8765   ins_encode %{
 8766     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8767   %}
 8768   ins_pipe(int_conditional_float_move);
 8769 %}
 8770 
 8771 instruct cmovDL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, regD dst, regD src) %{
 8772   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8773   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8774 
 8775   ins_cost(150);
 8776   size(4);
 8777   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8778   ins_encode %{
 8779     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8780   %}
 8781   ins_pipe(int_conditional_float_move);
 8782 %}
 8783 
 8784 instruct cmovDL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, regD dst, regD src) %{
 8785   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8786   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8787 
 8788   ins_cost(150);
 8789   size(4);
 8790   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8791   ins_encode %{
 8792     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8793   %}
 8794   ins_pipe(int_conditional_float_move);
 8795 %}
 8796 
 8797 // ============================================================================
 8798 // Safepoint Instruction
 8799 // rather than KILL R12, it would be better to use any reg as
 8800 // TEMP. Can&#39;t do that at this point because it crashes the compiler
 8801 instruct safePoint_poll(iRegP poll, R12RegI tmp, flagsReg icc) %{
 8802   match(SafePoint poll);
 8803   effect(USE poll, KILL tmp, KILL icc);
 8804 
 8805   size(4);
 8806   format %{ &quot;LDR   $tmp,[$poll]\t! Safepoint: poll for GC&quot; %}
 8807   ins_encode %{
 8808     __ relocate(relocInfo::poll_type);
 8809     __ ldr($tmp$$Register, Address($poll$$Register));
 8810   %}
 8811   ins_pipe(loadPollP);
 8812 %}
 8813 
 8814 
 8815 // ============================================================================
 8816 // Call Instructions
 8817 // Call Java Static Instruction
 8818 instruct CallStaticJavaDirect( method meth ) %{
 8819   match(CallStaticJava);
 8820   predicate(! ((CallStaticJavaNode*)n)-&gt;is_method_handle_invoke());
 8821   effect(USE meth);
 8822 
 8823   ins_cost(CALL_COST);
 8824   format %{ &quot;CALL,static ==&gt; &quot; %}
 8825   ins_encode( Java_Static_Call( meth ), call_epilog );
 8826   ins_pipe(simple_call);
 8827 %}
 8828 
 8829 // Call Java Static Instruction (method handle version)
 8830 instruct CallStaticJavaHandle( method meth ) %{
 8831   match(CallStaticJava);
 8832   predicate(((CallStaticJavaNode*)n)-&gt;is_method_handle_invoke());
 8833   effect(USE meth);
 8834   // FP is saved by all callees (for interpreter stack correction).
 8835   // We use it here for a similar purpose, in {preserve,restore}_FP.
 8836 
 8837   ins_cost(CALL_COST);
 8838   format %{ &quot;CALL,static/MethodHandle ==&gt; &quot; %}
 8839   ins_encode( preserve_SP, Java_Static_Call( meth ), restore_SP, call_epilog );
 8840   ins_pipe(simple_call);
 8841 %}
 8842 
 8843 // Call Java Dynamic Instruction
 8844 instruct CallDynamicJavaDirect( method meth ) %{
 8845   match(CallDynamicJava);
 8846   effect(USE meth);
 8847 
 8848   ins_cost(CALL_COST);
 8849   format %{ &quot;MOV_OOP    (empty),R_R8\n\t&quot;
 8850             &quot;CALL,dynamic  ; NOP ==&gt; &quot; %}
 8851   ins_encode( Java_Dynamic_Call( meth ), call_epilog );
 8852   ins_pipe(call);
 8853 %}
 8854 
 8855 // Call Runtime Instruction
 8856 instruct CallRuntimeDirect(method meth) %{
 8857   match(CallRuntime);
 8858   effect(USE meth);
 8859   ins_cost(CALL_COST);
 8860   format %{ &quot;CALL,runtime&quot; %}
 8861   ins_encode( Java_To_Runtime( meth ),
 8862               call_epilog );
 8863   ins_pipe(simple_call);
 8864 %}
 8865 
 8866 // Call runtime without safepoint - same as CallRuntime
 8867 instruct CallLeafDirect(method meth) %{
 8868   match(CallLeaf);
 8869   effect(USE meth);
 8870   ins_cost(CALL_COST);
 8871   format %{ &quot;CALL,runtime leaf&quot; %}
 8872   // TODO: ned save_last_PC here?
 8873   ins_encode( Java_To_Runtime( meth ),
 8874               call_epilog );
 8875   ins_pipe(simple_call);
 8876 %}
 8877 
 8878 // Call runtime without safepoint - same as CallLeaf
 8879 instruct CallLeafNoFPDirect(method meth) %{
 8880   match(CallLeafNoFP);
 8881   effect(USE meth);
 8882   ins_cost(CALL_COST);
 8883   format %{ &quot;CALL,runtime leaf nofp&quot; %}
 8884   // TODO: ned save_last_PC here?
 8885   ins_encode( Java_To_Runtime( meth ),
 8886               call_epilog );
 8887   ins_pipe(simple_call);
 8888 %}
 8889 
 8890 // Tail Call; Jump from runtime stub to Java code.
 8891 // Also known as an &#39;interprocedural jump&#39;.
 8892 // Target of jump will eventually return to caller.
 8893 // TailJump below removes the return address.
 8894 instruct TailCalljmpInd(IPRegP jump_target, inline_cache_regP method_oop) %{
 8895   match(TailCall jump_target method_oop );
 8896 
 8897   ins_cost(CALL_COST);
 8898   format %{ &quot;MOV    Rexception_pc, LR\n\t&quot;
 8899             &quot;jump   $jump_target  \t! $method_oop holds method oop&quot; %}
 8900   ins_encode %{
 8901     __ mov(Rexception_pc, LR);   // this is used only to call
 8902                                  // StubRoutines::forward_exception_entry()
 8903                                  // which expects PC of exception in
 8904                                  // R5. FIXME?
 8905     __ jump($jump_target$$Register);
 8906   %}
 8907   ins_pipe(tail_call);
 8908 %}
 8909 
 8910 
 8911 // Return Instruction
 8912 instruct Ret() %{
 8913   match(Return);
 8914 
 8915   format %{ &quot;ret LR&quot; %}
 8916 
 8917   ins_encode %{
 8918     __ ret(LR);
 8919   %}
 8920 
 8921   ins_pipe(br);
 8922 %}
 8923 
 8924 
 8925 // Tail Jump; remove the return address; jump to target.
 8926 // TailCall above leaves the return address around.
 8927 // TailJump is used in only one place, the rethrow_Java stub (fancy_jump=2).
 8928 // ex_oop (Exception Oop) is needed in %o0 at the jump. As there would be a
 8929 // &quot;restore&quot; before this instruction (in Epilogue), we need to materialize it
 8930 // in %i0.
 8931 instruct tailjmpInd(IPRegP jump_target, RExceptionRegP ex_oop) %{
 8932   match( TailJump jump_target ex_oop );
 8933   ins_cost(CALL_COST);
 8934   format %{ &quot;MOV    Rexception_pc, LR\n\t&quot;
 8935             &quot;jump   $jump_target \t! $ex_oop holds exc. oop&quot; %}
 8936   ins_encode %{
 8937     __ mov(Rexception_pc, LR);
 8938     __ jump($jump_target$$Register);
 8939   %}
 8940   ins_pipe(tail_call);
 8941 %}
 8942 
 8943 // Create exception oop: created by stack-crawling runtime code.
 8944 // Created exception is now available to this handler, and is setup
 8945 // just prior to jumping to this handler.  No code emitted.
 8946 instruct CreateException( RExceptionRegP ex_oop )
 8947 %{
 8948   match(Set ex_oop (CreateEx));
 8949   ins_cost(0);
 8950 
 8951   size(0);
 8952   // use the following format syntax
 8953   format %{ &quot;! exception oop is in Rexception_obj; no code emitted&quot; %}
 8954   ins_encode();
 8955   ins_pipe(empty);
 8956 %}
 8957 
 8958 
 8959 // Rethrow exception:
 8960 // The exception oop will come in the first argument position.
 8961 // Then JUMP (not call) to the rethrow stub code.
 8962 instruct RethrowException()
 8963 %{
 8964   match(Rethrow);
 8965   ins_cost(CALL_COST);
 8966 
 8967   // use the following format syntax
 8968   format %{ &quot;b    rethrow_stub&quot; %}
 8969   ins_encode %{
 8970     Register scratch = R1_tmp;
 8971     assert_different_registers(scratch, c_rarg0, LR);
 8972     __ jump(OptoRuntime::rethrow_stub(), relocInfo::runtime_call_type, scratch);
 8973   %}
 8974   ins_pipe(tail_call);
 8975 %}
 8976 
 8977 
 8978 // Die now
 8979 instruct ShouldNotReachHere( )
 8980 %{
 8981   match(Halt);
 8982   ins_cost(CALL_COST);
 8983 
 8984   size(4);
 8985   // Use the following format syntax
 8986   format %{ &quot;ShouldNotReachHere&quot; %}
 8987   ins_encode %{
 8988     __ udf(0xdead);
 8989   %}
 8990   ins_pipe(tail_call);
 8991 %}
 8992 
 8993 // ============================================================================
 8994 // The 2nd slow-half of a subtype check.  Scan the subklass&#39;s 2ndary superklass
 8995 // array for an instance of the superklass.  Set a hidden internal cache on a
 8996 // hit (cache is checked with exposed code in gen_subtype_check()).  Return
 8997 // not zero for a miss or zero for a hit.  The encoding ALSO sets flags.
 8998 instruct partialSubtypeCheck( R0RegP index, R1RegP sub, R2RegP super, flagsRegP pcc, LRRegP lr ) %{
 8999   match(Set index (PartialSubtypeCheck sub super));
 9000   effect( KILL pcc, KILL lr );
 9001   ins_cost(DEFAULT_COST*10);
 9002   format %{ &quot;CALL   PartialSubtypeCheck&quot; %}
 9003   ins_encode %{
 9004     __ call(StubRoutines::Arm::partial_subtype_check(), relocInfo::runtime_call_type);
 9005   %}
 9006   ins_pipe(partial_subtype_check_pipe);
 9007 %}
 9008 
 9009 /* instruct partialSubtypeCheck_vs_zero( flagsRegP pcc, o1RegP sub, o2RegP super, immP0 zero, o0RegP idx, o7RegP o7 ) %{ */
 9010 /*   match(Set pcc (CmpP (PartialSubtypeCheck sub super) zero)); */
 9011 /*   ins_pipe(partial_subtype_check_pipe); */
 9012 /* %} */
 9013 
 9014 
 9015 // ============================================================================
 9016 // inlined locking and unlocking
 9017 
 9018 instruct cmpFastLock(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2, iRegP scratch )
 9019 %{
 9020   match(Set pcc (FastLock object box));
 9021   predicate(!(UseBiasedLocking &amp;&amp; !UseOptoBiasInlining));
 9022 
 9023   effect(TEMP scratch, TEMP scratch2);
 9024   ins_cost(DEFAULT_COST*3);
 9025 
 9026   format %{ &quot;FASTLOCK  $object, $box; KILL $scratch, $scratch2&quot; %}
 9027   ins_encode %{
 9028     __ fast_lock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register);
 9029   %}
 9030   ins_pipe(long_memory_op);
 9031 %}
 9032 
 9033 instruct cmpFastLock_noBiasInline(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2,
 9034                                   iRegP scratch, iRegP scratch3) %{
 9035   match(Set pcc (FastLock object box));
 9036   predicate(UseBiasedLocking &amp;&amp; !UseOptoBiasInlining);
 9037 
 9038   effect(TEMP scratch, TEMP scratch2, TEMP scratch3);
 9039   ins_cost(DEFAULT_COST*5);
 9040 
 9041   format %{ &quot;FASTLOCK  $object, $box; KILL $scratch, $scratch2, $scratch3&quot; %}
 9042   ins_encode %{
 9043     __ fast_lock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register, $scratch3$$Register);
 9044   %}
 9045   ins_pipe(long_memory_op);
 9046 %}
 9047 
 9048 
 9049 instruct cmpFastUnlock(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2, iRegP scratch ) %{
 9050   match(Set pcc (FastUnlock object box));
 9051   effect(TEMP scratch, TEMP scratch2);
 9052   ins_cost(100);
 9053 
 9054   format %{ &quot;FASTUNLOCK  $object, $box; KILL $scratch, $scratch2&quot; %}
 9055   ins_encode %{
 9056     __ fast_unlock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register);
 9057   %}
 9058   ins_pipe(long_memory_op);
 9059 %}
 9060 
 9061 // Count and Base registers are fixed because the allocator cannot
 9062 // kill unknown registers.  The encodings are generic.
 9063 instruct clear_array(iRegX cnt, iRegP base, iRegI temp, iRegX zero, Universe dummy, flagsReg cpsr) %{
 9064   match(Set dummy (ClearArray cnt base));
 9065   effect(TEMP temp, TEMP zero, KILL cpsr);
 9066   ins_cost(300);
 9067   format %{ &quot;MOV    $zero,0\n&quot;
 9068       &quot;        MOV    $temp,$cnt\n&quot;
 9069       &quot;loop:   SUBS   $temp,$temp,4\t! Count down a dword of bytes\n&quot;
 9070       &quot;        STR.ge $zero,[$base+$temp]\t! delay slot&quot;
 9071       &quot;        B.gt   loop\t\t! Clearing loop\n&quot; %}
 9072   ins_encode %{
 9073     __ mov($zero$$Register, 0);
 9074     __ mov($temp$$Register, $cnt$$Register);
 9075     Label(loop);
 9076     __ bind(loop);
 9077     __ subs($temp$$Register, $temp$$Register, 4);
 9078     __ str($zero$$Register, Address($base$$Register, $temp$$Register), ge);
 9079     __ b(loop, gt);
 9080   %}
 9081   ins_pipe(long_memory_op);
 9082 %}
 9083 
 9084 #ifdef XXX
 9085 // FIXME: Why R0/R1/R2/R3?
 9086 instruct string_compare(R0RegP str1, R1RegP str2, R2RegI cnt1, R3RegI cnt2, iRegI result,
 9087                         iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 9088   predicate(!CompactStrings);
 9089   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
 9090   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL ccr, TEMP tmp1, TEMP tmp2);
 9091   ins_cost(300);
 9092   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   // TEMP $tmp1, $tmp2&quot; %}
 9093   ins_encode( enc_String_Compare(str1, str2, cnt1, cnt2, result, tmp1, tmp2) );
 9094 
 9095   ins_pipe(long_memory_op);
 9096 %}
 9097 
 9098 // FIXME: Why R0/R1/R2?
 9099 instruct string_equals(R0RegP str1, R1RegP str2, R2RegI cnt, iRegI result, iRegI tmp1, iRegI tmp2,
 9100                        flagsReg ccr) %{
 9101   predicate(!CompactStrings);
 9102   match(Set result (StrEquals (Binary str1 str2) cnt));
 9103   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, TEMP tmp1, TEMP tmp2, TEMP result, KILL ccr);
 9104 
 9105   ins_cost(300);
 9106   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result   // TEMP $tmp1, $tmp2&quot; %}
 9107   ins_encode( enc_String_Equals(str1, str2, cnt, result, tmp1, tmp2) );
 9108   ins_pipe(long_memory_op);
 9109 %}
 9110 
 9111 // FIXME: Why R0/R1?
 9112 instruct array_equals(R0RegP ary1, R1RegP ary2, iRegI tmp1, iRegI tmp2, iRegI tmp3, iRegI result,
 9113                       flagsReg ccr) %{
 9114   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
 9115   match(Set result (AryEq ary1 ary2));
 9116   effect(USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP result, KILL ccr);
 9117 
 9118   ins_cost(300);
 9119   format %{ &quot;Array Equals $ary1,$ary2 -&gt; $result   // TEMP $tmp1,$tmp2,$tmp3&quot; %}
 9120   ins_encode( enc_Array_Equals(ary1, ary2, tmp1, tmp2, tmp3, result));
 9121   ins_pipe(long_memory_op);
 9122 %}
 9123 #endif
 9124 
 9125 //---------- Zeros Count Instructions ------------------------------------------
 9126 
 9127 instruct countLeadingZerosI(iRegI dst, iRegI src) %{
 9128   match(Set dst (CountLeadingZerosI src));
 9129   size(4);
 9130   format %{ &quot;CLZ_32 $dst,$src&quot; %}
 9131   ins_encode %{
 9132     __ clz_32($dst$$Register, $src$$Register);
 9133   %}
 9134   ins_pipe(ialu_reg);
 9135 %}
 9136 
 9137 instruct countLeadingZerosL(iRegI dst, iRegL src, iRegI tmp, flagsReg ccr) %{
 9138   match(Set dst (CountLeadingZerosL src));
 9139   effect(TEMP tmp, TEMP dst, KILL ccr);
 9140   size(16);
 9141   format %{ &quot;CLZ    $dst,$src.hi\n\t&quot;
 9142             &quot;TEQ    $dst,32\n\t&quot;
 9143             &quot;CLZ.eq $tmp,$src.lo\n\t&quot;
 9144             &quot;ADD.eq $dst, $dst, $tmp\n\t&quot; %}
 9145   ins_encode %{
 9146     __ clz($dst$$Register, $src$$Register-&gt;successor());
 9147     __ teq($dst$$Register, 32);
 9148     __ clz($tmp$$Register, $src$$Register, eq);
 9149     __ add($dst$$Register, $dst$$Register, $tmp$$Register, eq);
 9150   %}
 9151   ins_pipe(ialu_reg);
 9152 %}
 9153 
 9154 instruct countTrailingZerosI(iRegI dst, iRegI src, iRegI tmp) %{
 9155   match(Set dst (CountTrailingZerosI src));
 9156   effect(TEMP tmp);
 9157   size(8);
 9158   format %{ &quot;RBIT_32 $tmp, $src\n\t&quot;
 9159             &quot;CLZ_32  $dst,$tmp&quot; %}
 9160   ins_encode %{
 9161     __ rbit_32($tmp$$Register, $src$$Register);
 9162     __ clz_32($dst$$Register, $tmp$$Register);
 9163   %}
 9164   ins_pipe(ialu_reg);
 9165 %}
 9166 
 9167 instruct countTrailingZerosL(iRegI dst, iRegL src, iRegI tmp, flagsReg ccr) %{
 9168   match(Set dst (CountTrailingZerosL src));
 9169   effect(TEMP tmp, TEMP dst, KILL ccr);
 9170   size(24);
 9171   format %{ &quot;RBIT   $tmp,$src.lo\n\t&quot;
 9172             &quot;CLZ    $dst,$tmp\n\t&quot;
 9173             &quot;TEQ    $dst,32\n\t&quot;
 9174             &quot;RBIT   $tmp,$src.hi\n\t&quot;
 9175             &quot;CLZ.eq $tmp,$tmp\n\t&quot;
 9176             &quot;ADD.eq $dst,$dst,$tmp\n\t&quot; %}
 9177   ins_encode %{
 9178     __ rbit($tmp$$Register, $src$$Register);
 9179     __ clz($dst$$Register, $tmp$$Register);
 9180     __ teq($dst$$Register, 32);
 9181     __ rbit($tmp$$Register, $src$$Register-&gt;successor());
 9182     __ clz($tmp$$Register, $tmp$$Register, eq);
 9183     __ add($dst$$Register, $dst$$Register, $tmp$$Register, eq);
 9184   %}
 9185   ins_pipe(ialu_reg);
 9186 %}
 9187 
 9188 
 9189 //---------- Population Count Instructions -------------------------------------
 9190 
 9191 instruct popCountI(iRegI dst, iRegI src, regD_low tmp) %{
 9192   predicate(UsePopCountInstruction);
 9193   match(Set dst (PopCountI src));
 9194   effect(TEMP tmp);
 9195 
 9196   format %{ &quot;FMSR       $tmp,$src\n\t&quot;
 9197             &quot;VCNT.8     $tmp,$tmp\n\t&quot;
 9198             &quot;VPADDL.U8  $tmp,$tmp\n\t&quot;
 9199             &quot;VPADDL.U16 $tmp,$tmp\n\t&quot;
 9200             &quot;FMRS       $dst,$tmp&quot; %}
 9201   size(20);
 9202 
 9203   ins_encode %{
 9204     __ fmsr($tmp$$FloatRegister, $src$$Register);
 9205     __ vcnt($tmp$$FloatRegister, $tmp$$FloatRegister);
 9206     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 8, 0);
 9207     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 16, 0);
 9208     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 9209   %}
 9210   ins_pipe(ialu_reg); // FIXME
 9211 %}
 9212 
 9213 // Note: Long.bitCount(long) returns an int.
 9214 instruct popCountL(iRegI dst, iRegL src, regD_low tmp) %{
 9215   predicate(UsePopCountInstruction);
 9216   match(Set dst (PopCountL src));
 9217   effect(TEMP tmp);
 9218 
 9219   format %{ &quot;FMDRR       $tmp,$src.lo,$src.hi\n\t&quot;
 9220             &quot;VCNT.8      $tmp,$tmp\n\t&quot;
 9221             &quot;VPADDL.U8   $tmp,$tmp\n\t&quot;
 9222             &quot;VPADDL.U16  $tmp,$tmp\n\t&quot;
 9223             &quot;VPADDL.U32  $tmp,$tmp\n\t&quot;
 9224             &quot;FMRS        $dst,$tmp&quot; %}
 9225 
 9226   size(32);
 9227 
 9228   ins_encode %{
 9229     __ fmdrr($tmp$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 9230     __ vcnt($tmp$$FloatRegister, $tmp$$FloatRegister);
 9231     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 8, 0);
 9232     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 16, 0);
 9233     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 32, 0);
 9234     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 9235   %}
 9236   ins_pipe(ialu_reg);
 9237 %}
 9238 
 9239 
 9240 // ============================================================================
 9241 //------------Bytes reverse--------------------------------------------------
 9242 
 9243 instruct bytes_reverse_int(iRegI dst, iRegI src) %{
 9244   match(Set dst (ReverseBytesI src));
 9245 
 9246   size(4);
 9247   format %{ &quot;REV32 $dst,$src&quot; %}
 9248   ins_encode %{
 9249     __ rev($dst$$Register, $src$$Register);
 9250   %}
 9251   ins_pipe( iload_mem ); // FIXME
 9252 %}
 9253 
 9254 instruct bytes_reverse_long(iRegL dst, iRegL src) %{
 9255   match(Set dst (ReverseBytesL src));
 9256   effect(TEMP dst);
 9257   size(8);
 9258   format %{ &quot;REV $dst.lo,$src.lo\n\t&quot;
 9259             &quot;REV $dst.hi,$src.hi&quot; %}
 9260   ins_encode %{
 9261     __ rev($dst$$Register, $src$$Register-&gt;successor());
 9262     __ rev($dst$$Register-&gt;successor(), $src$$Register);
 9263   %}
 9264   ins_pipe( iload_mem ); // FIXME
 9265 %}
 9266 
 9267 instruct bytes_reverse_unsigned_short(iRegI dst, iRegI src) %{
 9268   match(Set dst (ReverseBytesUS src));
 9269   size(4);
 9270   format %{ &quot;REV16 $dst,$src&quot; %}
 9271   ins_encode %{
 9272     __ rev16($dst$$Register, $src$$Register);
 9273   %}
 9274   ins_pipe( iload_mem ); // FIXME
 9275 %}
 9276 
 9277 instruct bytes_reverse_short(iRegI dst, iRegI src) %{
 9278   match(Set dst (ReverseBytesS src));
 9279   size(4);
 9280   format %{ &quot;REVSH $dst,$src&quot; %}
 9281   ins_encode %{
 9282     __ revsh($dst$$Register, $src$$Register);
 9283   %}
 9284   ins_pipe( iload_mem ); // FIXME
 9285 %}
 9286 
 9287 
 9288 // ====================VECTOR INSTRUCTIONS=====================================
 9289 
 9290 // Load Aligned Packed values into a Double Register
 9291 instruct loadV8(vecD dst, memoryD mem) %{
 9292   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
 9293   match(Set dst (LoadVector mem));
 9294   ins_cost(MEMORY_REF_COST);
 9295   size(4);
 9296   format %{ &quot;FLDD   $mem,$dst\t! load vector (8 bytes)&quot; %}
 9297   ins_encode %{
 9298     __ ldr_double($dst$$FloatRegister, $mem$$Address);
 9299   %}
 9300   ins_pipe(floadD_mem);
 9301 %}
 9302 
 9303 // Load Aligned Packed values into a Double Register Pair
 9304 instruct loadV16(vecX dst, memoryvld mem) %{
 9305   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
 9306   match(Set dst (LoadVector mem));
 9307   ins_cost(MEMORY_REF_COST);
 9308   size(4);
 9309   format %{ &quot;VLD1   $mem,$dst.Q\t! load vector (16 bytes)&quot; %}
 9310   ins_encode %{
 9311     __ vld1($dst$$FloatRegister, $mem$$Address, MacroAssembler::VELEM_SIZE_16, 128);
 9312   %}
 9313   ins_pipe(floadD_mem); // FIXME
 9314 %}
 9315 
 9316 // Store Vector in Double register to memory
 9317 instruct storeV8(memoryD mem, vecD src) %{
 9318   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
 9319   match(Set mem (StoreVector mem src));
 9320   ins_cost(MEMORY_REF_COST);
 9321   size(4);
 9322   format %{ &quot;FSTD   $src,$mem\t! store vector (8 bytes)&quot; %}
 9323   ins_encode %{
 9324     __ str_double($src$$FloatRegister, $mem$$Address);
 9325   %}
 9326   ins_pipe(fstoreD_mem_reg);
 9327 %}
 9328 
 9329 // Store Vector in Double Register Pair to memory
 9330 instruct storeV16(memoryvld mem, vecX src) %{
 9331   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
 9332   match(Set mem (StoreVector mem src));
 9333   ins_cost(MEMORY_REF_COST);
 9334   size(4);
 9335   format %{ &quot;VST1   $src,$mem\t! store vector (16 bytes)&quot; %}
 9336   ins_encode %{
 9337     __ vst1($src$$FloatRegister, $mem$$Address, MacroAssembler::VELEM_SIZE_16, 128);
 9338   %}
 9339   ins_pipe(fstoreD_mem_reg); // FIXME
 9340 %}
 9341 
 9342 // Replicate scalar to packed byte values in Double register
 9343 instruct Repl8B_reg(vecD dst, iRegI src, iRegI tmp) %{
 9344   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9345   match(Set dst (ReplicateB src));
 9346   ins_cost(DEFAULT_COST*4);
 9347   effect(TEMP tmp);
 9348   size(16);
 9349 
 9350   // FIXME: could use PKH instruction instead?
 9351   format %{ &quot;LSL      $tmp, $src, 24 \n\t&quot;
 9352             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 8) \n\t&quot;
 9353             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 16) \n\t&quot;
 9354             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9355   ins_encode %{
 9356     __ mov($tmp$$Register, AsmOperand($src$$Register, lsl, 24));
 9357     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 8));
 9358     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 16));
 9359     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9360   %}
 9361   ins_pipe(ialu_reg); // FIXME
 9362 %}
 9363 
 9364 // Replicate scalar to packed byte values in Double register
 9365 instruct Repl8B_reg_simd(vecD dst, iRegI src) %{
 9366   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9367   match(Set dst (ReplicateB src));
 9368   size(4);
 9369 
 9370   format %{ &quot;VDUP.8 $dst,$src\t&quot; %}
 9371   ins_encode %{
 9372     bool quad = false;
 9373     __ vdupI($dst$$FloatRegister, $src$$Register,
 9374              MacroAssembler::VELEM_SIZE_8, quad);
 9375   %}
 9376   ins_pipe(ialu_reg); // FIXME
 9377 %}
 9378 
 9379 // Replicate scalar to packed byte values in Double register pair
 9380 instruct Repl16B_reg(vecX dst, iRegI src) %{
 9381   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
 9382   match(Set dst (ReplicateB src));
 9383   size(4);
 9384 
 9385   format %{ &quot;VDUP.8 $dst.Q,$src\t&quot; %}
 9386   ins_encode %{
 9387     bool quad = true;
 9388     __ vdupI($dst$$FloatRegister, $src$$Register,
 9389              MacroAssembler::VELEM_SIZE_8, quad);
 9390   %}
 9391   ins_pipe(ialu_reg); // FIXME
 9392 %}
 9393 
 9394 // Replicate scalar constant to packed byte values in Double register
 9395 instruct Repl8B_immI(vecD dst, immI src, iRegI tmp) %{
 9396   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9397   match(Set dst (ReplicateB src));
 9398   ins_cost(DEFAULT_COST*2);
 9399   effect(TEMP tmp);
 9400   size(12);
 9401 
 9402   format %{ &quot;MOV      $tmp, Repl4($src))\n\t&quot;
 9403             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9404   ins_encode( LdReplImmI(src, dst, tmp, (4), (1)) );
 9405   ins_pipe(loadConFD); // FIXME
 9406 %}
 9407 
 9408 // Replicate scalar constant to packed byte values in Double register
 9409 // TODO: support negative constants with MVNI?
 9410 instruct Repl8B_immU8(vecD dst, immU8 src) %{
 9411   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9412   match(Set dst (ReplicateB src));
 9413   size(4);
 9414 
 9415   format %{ &quot;VMOV.U8  $dst,$src&quot; %}
 9416   ins_encode %{
 9417     bool quad = false;
 9418     __ vmovI($dst$$FloatRegister, $src$$constant,
 9419              MacroAssembler::VELEM_SIZE_8, quad);
 9420   %}
 9421   ins_pipe(loadConFD); // FIXME
 9422 %}
 9423 
 9424 // Replicate scalar constant to packed byte values in Double register pair
 9425 instruct Repl16B_immU8(vecX dst, immU8 src) %{
 9426   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9427   match(Set dst (ReplicateB src));
 9428   size(4);
 9429 
 9430   format %{ &quot;VMOV.U8  $dst.Q,$src&quot; %}
 9431   ins_encode %{
 9432     bool quad = true;
 9433     __ vmovI($dst$$FloatRegister, $src$$constant,
 9434              MacroAssembler::VELEM_SIZE_8, quad);
 9435   %}
 9436   ins_pipe(loadConFD); // FIXME
 9437 %}
 9438 
 9439 // Replicate scalar to packed short/char values into Double register
 9440 instruct Repl4S_reg(vecD dst, iRegI src, iRegI tmp) %{
 9441   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9442   match(Set dst (ReplicateS src));
 9443   ins_cost(DEFAULT_COST*3);
 9444   effect(TEMP tmp);
 9445   size(12);
 9446 
 9447   // FIXME: could use PKH instruction instead?
 9448   format %{ &quot;LSL      $tmp, $src, 16 \n\t&quot;
 9449             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 16) \n\t&quot;
 9450             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9451   ins_encode %{
 9452     __ mov($tmp$$Register, AsmOperand($src$$Register, lsl, 16));
 9453     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 16));
 9454     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9455   %}
 9456   ins_pipe(ialu_reg); // FIXME
 9457 %}
 9458 
 9459 // Replicate scalar to packed byte values in Double register
 9460 instruct Repl4S_reg_simd(vecD dst, iRegI src) %{
 9461   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9462   match(Set dst (ReplicateS src));
 9463   size(4);
 9464 
 9465   format %{ &quot;VDUP.16 $dst,$src\t&quot; %}
 9466   ins_encode %{
 9467     bool quad = false;
 9468     __ vdupI($dst$$FloatRegister, $src$$Register,
 9469              MacroAssembler::VELEM_SIZE_16, quad);
 9470   %}
 9471   ins_pipe(ialu_reg); // FIXME
 9472 %}
 9473 
 9474 // Replicate scalar to packed byte values in Double register pair
 9475 instruct Repl8S_reg(vecX dst, iRegI src) %{
 9476   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9477   match(Set dst (ReplicateS src));
 9478   size(4);
 9479 
 9480   format %{ &quot;VDUP.16 $dst.Q,$src\t&quot; %}
 9481   ins_encode %{
 9482     bool quad = true;
 9483     __ vdupI($dst$$FloatRegister, $src$$Register,
 9484              MacroAssembler::VELEM_SIZE_16, quad);
 9485   %}
 9486   ins_pipe(ialu_reg); // FIXME
 9487 %}
 9488 
 9489 
 9490 // Replicate scalar constant to packed short/char values in Double register
 9491 instruct Repl4S_immI(vecD dst, immI src, iRegP tmp) %{
 9492   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9493   match(Set dst (ReplicateS src));
 9494   effect(TEMP tmp);
 9495   size(12);
 9496   ins_cost(DEFAULT_COST*4); // FIXME
 9497 
 9498   format %{ &quot;MOV      $tmp, Repl2($src))\n\t&quot;
 9499             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9500   ins_encode( LdReplImmI(src, dst, tmp, (2), (2)) );
 9501   ins_pipe(loadConFD); // FIXME
 9502 %}
 9503 
 9504 // Replicate scalar constant to packed byte values in Double register
 9505 instruct Repl4S_immU8(vecD dst, immU8 src) %{
 9506   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9507   match(Set dst (ReplicateS src));
 9508   size(4);
 9509 
 9510   format %{ &quot;VMOV.U16  $dst,$src&quot; %}
 9511   ins_encode %{
 9512     bool quad = false;
 9513     __ vmovI($dst$$FloatRegister, $src$$constant,
 9514              MacroAssembler::VELEM_SIZE_16, quad);
 9515   %}
 9516   ins_pipe(loadConFD); // FIXME
 9517 %}
 9518 
 9519 // Replicate scalar constant to packed byte values in Double register pair
 9520 instruct Repl8S_immU8(vecX dst, immU8 src) %{
 9521   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9522   match(Set dst (ReplicateS src));
 9523   size(4);
 9524 
 9525   format %{ &quot;VMOV.U16  $dst.Q,$src&quot; %}
 9526   ins_encode %{
 9527     bool quad = true;
 9528     __ vmovI($dst$$FloatRegister, $src$$constant,
 9529              MacroAssembler::VELEM_SIZE_16, quad);
 9530   %}
 9531   ins_pipe(loadConFD); // FIXME
 9532 %}
 9533 
 9534 // Replicate scalar to packed int values in Double register
 9535 instruct Repl2I_reg(vecD dst, iRegI src) %{
 9536   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9537   match(Set dst (ReplicateI src));
 9538   size(4);
 9539 
 9540   format %{ &quot;FMDRR    $dst,$src,$src\t&quot; %}
 9541   ins_encode %{
 9542     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9543   %}
 9544   ins_pipe(ialu_reg); // FIXME
 9545 %}
 9546 
 9547 // Replicate scalar to packed int values in Double register pair
 9548 instruct Repl4I_reg(vecX dst, iRegI src) %{
 9549   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9550   match(Set dst (ReplicateI src));
 9551   ins_cost(DEFAULT_COST*2);
 9552   size(8);
 9553 
 9554   format %{ &quot;FMDRR    $dst.lo,$src,$src\n\t&quot;
 9555             &quot;FMDRR    $dst.hi,$src,$src&quot; %}
 9556 
 9557   ins_encode %{
 9558     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9559     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9560              $src$$Register, $src$$Register);
 9561   %}
 9562   ins_pipe(ialu_reg); // FIXME
 9563 %}
 9564 
 9565 // Replicate scalar to packed int values in Double register
 9566 instruct Repl2I_reg_simd(vecD dst, iRegI src) %{
 9567   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9568   match(Set dst (ReplicateI src));
 9569   size(4);
 9570 
 9571   format %{ &quot;VDUP.32 $dst.D,$src\t&quot; %}
 9572   ins_encode %{
 9573     bool quad = false;
 9574     __ vdupI($dst$$FloatRegister, $src$$Register,
 9575              MacroAssembler::VELEM_SIZE_32, quad);
 9576   %}
 9577   ins_pipe(ialu_reg); // FIXME
 9578 %}
 9579 
 9580 // Replicate scalar to packed int values in Double register pair
 9581 instruct Repl4I_reg_simd(vecX dst, iRegI src) %{
 9582   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9583   match(Set dst (ReplicateI src));
 9584   size(4);
 9585 
 9586   format %{ &quot;VDUP.32 $dst.Q,$src\t&quot; %}
 9587   ins_encode %{
 9588     bool quad = true;
 9589     __ vdupI($dst$$FloatRegister, $src$$Register,
 9590              MacroAssembler::VELEM_SIZE_32, quad);
 9591   %}
 9592   ins_pipe(ialu_reg); // FIXME
 9593 %}
 9594 
 9595 
 9596 // Replicate scalar zero constant to packed int values in Double register
 9597 instruct Repl2I_immI(vecD dst, immI src, iRegI tmp) %{
 9598   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9599   match(Set dst (ReplicateI src));
 9600   effect(TEMP tmp);
 9601   size(12);
 9602   ins_cost(DEFAULT_COST*4); // FIXME
 9603 
 9604   format %{ &quot;MOV      $tmp, Repl1($src))\n\t&quot;
 9605             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9606   ins_encode( LdReplImmI(src, dst, tmp, (1), (4)) );
 9607   ins_pipe(loadConFD); // FIXME
 9608 %}
 9609 
 9610 // Replicate scalar constant to packed byte values in Double register
 9611 instruct Repl2I_immU8(vecD dst, immU8 src) %{
 9612   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9613   match(Set dst (ReplicateI src));
 9614   size(4);
 9615 
 9616   format %{ &quot;VMOV.I32  $dst.D,$src&quot; %}
 9617   ins_encode %{
 9618     bool quad = false;
 9619     __ vmovI($dst$$FloatRegister, $src$$constant,
 9620              MacroAssembler::VELEM_SIZE_32, quad);
 9621   %}
 9622   ins_pipe(loadConFD); // FIXME
 9623 %}
 9624 
 9625 // Replicate scalar constant to packed byte values in Double register pair
 9626 instruct Repl4I_immU8(vecX dst, immU8 src) %{
 9627   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9628   match(Set dst (ReplicateI src));
 9629   size(4);
 9630 
 9631   format %{ &quot;VMOV.I32  $dst.Q,$src&quot; %}
 9632   ins_encode %{
 9633     bool quad = true;
 9634     __ vmovI($dst$$FloatRegister, $src$$constant,
 9635              MacroAssembler::VELEM_SIZE_32, quad);
 9636   %}
 9637   ins_pipe(loadConFD); // FIXME
 9638 %}
 9639 
 9640 // Replicate scalar to packed byte values in Double register pair
 9641 instruct Repl2L_reg(vecX dst, iRegL src) %{
 9642   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9643   match(Set dst (ReplicateL src));
 9644   size(8);
 9645   ins_cost(DEFAULT_COST*2); // FIXME
 9646 
 9647   format %{ &quot;FMDRR $dst.D,$src.lo,$src.hi\t\n&quot;
 9648             &quot;FMDRR $dst.D.next,$src.lo,$src.hi&quot; %}
 9649   ins_encode %{
 9650     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 9651     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9652              $src$$Register, $src$$Register-&gt;successor());
 9653   %}
 9654   ins_pipe(ialu_reg); // FIXME
 9655 %}
 9656 
 9657 
 9658 // Replicate scalar to packed float values in Double register
 9659 instruct Repl2F_regI(vecD dst, iRegI src) %{
 9660   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9661   match(Set dst (ReplicateF src));
 9662   size(4);
 9663 
 9664   format %{ &quot;FMDRR    $dst.D,$src,$src\t&quot; %}
 9665   ins_encode %{
 9666     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9667   %}
 9668   ins_pipe(ialu_reg); // FIXME
 9669 %}
 9670 
 9671 // Replicate scalar to packed float values in Double register
 9672 instruct Repl2F_reg_vfp(vecD dst, regF src) %{
 9673   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9674   match(Set dst (ReplicateF src));
 9675   size(4*2);
 9676   ins_cost(DEFAULT_COST*2); // FIXME
 9677 
 9678   expand %{
 9679     iRegI tmp;
 9680     MoveF2I_reg_reg(tmp, src);
 9681     Repl2F_regI(dst,tmp);
 9682   %}
 9683 %}
 9684 
 9685 // Replicate scalar to packed float values in Double register
 9686 instruct Repl2F_reg_simd(vecD dst, regF src) %{
 9687   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9688   match(Set dst (ReplicateF src));
 9689   size(4);
 9690   ins_cost(DEFAULT_COST); // FIXME
 9691 
 9692   format %{ &quot;VDUP.32  $dst.D,$src.D\t&quot; %}
 9693   ins_encode %{
 9694     bool quad = false;
 9695     __ vdupF($dst$$FloatRegister, $src$$FloatRegister, quad);
 9696   %}
 9697   ins_pipe(ialu_reg); // FIXME
 9698 %}
 9699 
 9700 // Replicate scalar to packed float values in Double register pair
 9701 instruct Repl4F_reg(vecX dst, regF src, iRegI tmp) %{
 9702   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9703   match(Set dst (ReplicateF src));
 9704   effect(TEMP tmp);
 9705   size(4*3);
 9706   ins_cost(DEFAULT_COST*3); // FIXME
 9707 
 9708   format %{ &quot;FMRS     $tmp,$src\n\t&quot;
 9709             &quot;FMDRR    $dst.D,$tmp,$tmp\n\t&quot;
 9710             &quot;FMDRR    $dst.D.next,$tmp,$tmp\t&quot; %}
 9711   ins_encode %{
 9712     __ fmrs($tmp$$Register, $src$$FloatRegister);
 9713     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9714     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9715              $tmp$$Register, $tmp$$Register);
 9716   %}
 9717   ins_pipe(ialu_reg); // FIXME
 9718 %}
 9719 
 9720 // Replicate scalar to packed float values in Double register pair
 9721 instruct Repl4F_reg_simd(vecX dst, regF src) %{
 9722   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9723   match(Set dst (ReplicateF src));
 9724   size(4);
 9725   ins_cost(DEFAULT_COST); // FIXME
 9726 
 9727   format %{ &quot;VDUP.32  $dst.Q,$src.D\t&quot; %}
 9728   ins_encode %{
 9729     bool quad = true;
 9730     __ vdupF($dst$$FloatRegister, $src$$FloatRegister, quad);
 9731   %}
 9732   ins_pipe(ialu_reg); // FIXME
 9733 %}
 9734 
 9735 // Replicate scalar zero constant to packed float values in Double register
 9736 instruct Repl2F_immI(vecD dst, immF src, iRegI tmp) %{
 9737   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9738   match(Set dst (ReplicateF src));
 9739   effect(TEMP tmp);
 9740   size(12);
 9741   ins_cost(DEFAULT_COST*4); // FIXME
 9742 
 9743   format %{ &quot;MOV      $tmp, Repl1($src))\n\t&quot;
 9744             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9745   ins_encode( LdReplImmF(src, dst, tmp) );
 9746   ins_pipe(loadConFD); // FIXME
 9747 %}
 9748 
 9749 // Replicate scalar to packed double float values in Double register pair
 9750 instruct Repl2D_reg(vecX dst, regD src) %{
 9751   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9752   match(Set dst (ReplicateD src));
 9753   size(4*2);
 9754   ins_cost(DEFAULT_COST*2); // FIXME
 9755 
 9756   format %{ &quot;FCPYD    $dst.D.a,$src\n\t&quot;
 9757             &quot;FCPYD    $dst.D.b,$src\t&quot; %}
 9758   ins_encode %{
 9759     FloatRegister dsta = $dst$$FloatRegister;
 9760     FloatRegister src = $src$$FloatRegister;
 9761     __ fcpyd(dsta, src);
 9762     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
 9763     __ fcpyd(dstb, src);
 9764   %}
 9765   ins_pipe(ialu_reg); // FIXME
 9766 %}
 9767 
 9768 // ====================VECTOR ARITHMETIC=======================================
 9769 
 9770 // --------------------------------- ADD --------------------------------------
 9771 
 9772 // Bytes vector add
 9773 instruct vadd8B_reg(vecD dst, vecD src1, vecD src2) %{
 9774   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9775   match(Set dst (AddVB src1 src2));
 9776   format %{ &quot;VADD.I8 $dst,$src1,$src2\t! add packed8B&quot; %}
 9777   size(4);
 9778   ins_encode %{
 9779     bool quad = false;
 9780     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9781              MacroAssembler::VELEM_SIZE_8, quad);
 9782   %}
 9783   ins_pipe( ialu_reg_reg ); // FIXME
 9784 %}
 9785 
 9786 instruct vadd16B_reg(vecX dst, vecX src1, vecX src2) %{
 9787   predicate(n-&gt;as_Vector()-&gt;length() == 16);
 9788   match(Set dst (AddVB src1 src2));
 9789   size(4);
 9790   format %{ &quot;VADD.I8 $dst.Q,$src1.Q,$src2.Q\t! add packed16B&quot; %}
 9791   ins_encode %{
 9792     bool quad = true;
 9793     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9794              MacroAssembler::VELEM_SIZE_8, quad);
 9795   %}
 9796   ins_pipe( ialu_reg_reg ); // FIXME
 9797 %}
 9798 
 9799 // Shorts/Chars vector add
 9800 instruct vadd4S_reg(vecD dst, vecD src1, vecD src2) %{
 9801   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9802   match(Set dst (AddVS src1 src2));
 9803   size(4);
 9804   format %{ &quot;VADD.I16 $dst,$src1,$src2\t! add packed4S&quot; %}
 9805   ins_encode %{
 9806     bool quad = false;
 9807     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9808              MacroAssembler::VELEM_SIZE_16, quad);
 9809   %}
 9810   ins_pipe( ialu_reg_reg ); // FIXME
 9811 %}
 9812 
 9813 instruct vadd8S_reg(vecX dst, vecX src1, vecX src2) %{
 9814   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9815   match(Set dst (AddVS src1 src2));
 9816   size(4);
 9817   format %{ &quot;VADD.I16 $dst.Q,$src1.Q,$src2.Q\t! add packed8S&quot; %}
 9818   ins_encode %{
 9819     bool quad = true;
 9820     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9821              MacroAssembler::VELEM_SIZE_16, quad);
 9822   %}
 9823   ins_pipe( ialu_reg_reg ); // FIXME
 9824 %}
 9825 
 9826 // Integers vector add
 9827 instruct vadd2I_reg(vecD dst, vecD src1, vecD src2) %{
 9828   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9829   match(Set dst (AddVI src1 src2));
 9830   size(4);
 9831   format %{ &quot;VADD.I32 $dst.D,$src1.D,$src2.D\t! add packed2I&quot; %}
 9832   ins_encode %{
 9833     bool quad = false;
 9834     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9835              MacroAssembler::VELEM_SIZE_32, quad);
 9836   %}
 9837   ins_pipe( ialu_reg_reg ); // FIXME
 9838 %}
 9839 
 9840 instruct vadd4I_reg(vecX dst, vecX src1, vecX src2) %{
 9841   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9842   match(Set dst (AddVI src1 src2));
 9843   size(4);
 9844   format %{ &quot;VADD.I32 $dst.Q,$src1.Q,$src2.Q\t! add packed4I&quot; %}
 9845   ins_encode %{
 9846     bool quad = true;
 9847     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9848              MacroAssembler::VELEM_SIZE_32, quad);
 9849   %}
 9850   ins_pipe( ialu_reg_reg ); // FIXME
 9851 %}
 9852 
 9853 // Longs vector add
 9854 instruct vadd2L_reg(vecX dst, vecX src1, vecX src2) %{
 9855   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9856   match(Set dst (AddVL src1 src2));
 9857   size(4);
 9858   format %{ &quot;VADD.I64 $dst.Q,$src1.Q,$src2.Q\t! add packed2L&quot; %}
 9859   ins_encode %{
 9860     bool quad = true;
 9861     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9862              MacroAssembler::VELEM_SIZE_64, quad);
 9863   %}
 9864   ins_pipe( ialu_reg_reg ); // FIXME
 9865 %}
 9866 
 9867 // Floats vector add
 9868 instruct vadd2F_reg(vecD dst, vecD src1, vecD src2) %{
 9869   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
 9870   match(Set dst (AddVF src1 src2));
 9871   size(4);
 9872   format %{ &quot;VADD.F32 $dst,$src1,$src2\t! add packed2F&quot; %}
 9873   ins_encode %{
 9874     bool quad = false;
 9875     __ vaddF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9876              MacroAssembler::VFA_SIZE_F32, quad);
 9877   %}
 9878   ins_pipe( faddD_reg_reg ); // FIXME
 9879 %}
 9880 
 9881 instruct vadd2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
 9882   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
 9883   match(Set dst (AddVF src1 src2));
 9884   ins_cost(DEFAULT_COST*2); // FIXME
 9885 
 9886   size(4*2);
 9887   format %{ &quot;FADDS  $dst.a,$src1.a,$src2.a\n\t&quot;
 9888             &quot;FADDS  $dst.b,$src1.b,$src2.b&quot; %}
 9889   ins_encode %{
 9890     __ add_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 9891     __ add_float($dst$$FloatRegister-&gt;successor(),
 9892              $src1$$FloatRegister-&gt;successor(),
 9893              $src2$$FloatRegister-&gt;successor());
 9894   %}
 9895 
 9896   ins_pipe(faddF_reg_reg); // FIXME
 9897 %}
 9898 
 9899 instruct vadd4F_reg_simd(vecX dst, vecX src1, vecX src2) %{
 9900   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
 9901   match(Set dst (AddVF src1 src2));
 9902   size(4);
 9903   format %{ &quot;VADD.F32 $dst.Q,$src1.Q,$src2.Q\t! add packed4F&quot; %}
 9904   ins_encode %{
 9905     bool quad = true;
 9906     __ vaddF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9907              MacroAssembler::VFA_SIZE_F32, quad);
 9908   %}
 9909   ins_pipe( faddD_reg_reg ); // FIXME
 9910 %}
 9911 
 9912 instruct vadd4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
 9913   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
 9914   match(Set dst (AddVF src1 src2));
 9915   size(4*4);
 9916   ins_cost(DEFAULT_COST*4); // FIXME
 9917 
 9918   format %{ &quot;FADDS  $dst.a,$src1.a,$src2.a\n\t&quot;
 9919             &quot;FADDS  $dst.b,$src1.b,$src2.b\n\t&quot;
 9920             &quot;FADDS  $dst.c,$src1.c,$src2.c\n\t&quot;
 9921             &quot;FADDS  $dst.d,$src1.d,$src2.d&quot; %}
 9922 
 9923   ins_encode %{
 9924     FloatRegister dsta = $dst$$FloatRegister;
 9925     FloatRegister src1a = $src1$$FloatRegister;
 9926     FloatRegister src2a = $src2$$FloatRegister;
 9927     __ add_float(dsta, src1a, src2a);
 9928     FloatRegister dstb = dsta-&gt;successor();
 9929     FloatRegister src1b = src1a-&gt;successor();
 9930     FloatRegister src2b = src2a-&gt;successor();
 9931     __ add_float(dstb, src1b, src2b);
 9932     FloatRegister dstc = dstb-&gt;successor();
 9933     FloatRegister src1c = src1b-&gt;successor();
 9934     FloatRegister src2c = src2b-&gt;successor();
 9935     __ add_float(dstc, src1c, src2c);
 9936     FloatRegister dstd = dstc-&gt;successor();
 9937     FloatRegister src1d = src1c-&gt;successor();
 9938     FloatRegister src2d = src2c-&gt;successor();
 9939     __ add_float(dstd, src1d, src2d);
 9940   %}
 9941 
 9942   ins_pipe(faddF_reg_reg); // FIXME
 9943 %}
 9944 
 9945 instruct vadd2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
 9946   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9947   match(Set dst (AddVD src1 src2));
 9948   size(4*2);
 9949   ins_cost(DEFAULT_COST*2); // FIXME
 9950 
 9951   format %{ &quot;FADDD  $dst.a,$src1.a,$src2.a\n\t&quot;
 9952             &quot;FADDD  $dst.b,$src1.b,$src2.b&quot; %}
 9953 
 9954   ins_encode %{
 9955     FloatRegister dsta = $dst$$FloatRegister;
 9956     FloatRegister src1a = $src1$$FloatRegister;
 9957     FloatRegister src2a = $src2$$FloatRegister;
 9958     __ add_double(dsta, src1a, src2a);
 9959     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
 9960     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
 9961     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
 9962     __ add_double(dstb, src1b, src2b);
 9963   %}
 9964 
 9965   ins_pipe(faddF_reg_reg); // FIXME
 9966 %}
 9967 
 9968 
 9969 // Bytes vector sub
 9970 instruct vsub8B_reg(vecD dst, vecD src1, vecD src2) %{
 9971   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9972   match(Set dst (SubVB src1 src2));
 9973   size(4);
 9974   format %{ &quot;VSUB.I8 $dst,$src1,$src2\t! sub packed8B&quot; %}
 9975   ins_encode %{
 9976     bool quad = false;
 9977     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9978              MacroAssembler::VELEM_SIZE_8, quad);
 9979   %}
 9980   ins_pipe( ialu_reg_reg ); // FIXME
 9981 %}
 9982 
 9983 instruct vsub16B_reg(vecX dst, vecX src1, vecX src2) %{
 9984   predicate(n-&gt;as_Vector()-&gt;length() == 16);
 9985   match(Set dst (SubVB src1 src2));
 9986   size(4);
 9987   format %{ &quot;VSUB.I8 $dst.Q,$src1.Q,$src2.Q\t! sub packed16B&quot; %}
 9988   ins_encode %{
 9989     bool quad = true;
 9990     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9991              MacroAssembler::VELEM_SIZE_8, quad);
 9992   %}
 9993   ins_pipe( ialu_reg_reg ); // FIXME
 9994 %}
 9995 
 9996 // Shorts/Chars vector sub
 9997 instruct vsub4S_reg(vecD dst, vecD src1, vecD src2) %{
 9998   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9999   match(Set dst (SubVS src1 src2));
10000   size(4);
10001   format %{ &quot;VSUB.I16 $dst,$src1,$src2\t! sub packed4S&quot; %}
10002   ins_encode %{
10003     bool quad = false;
10004     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10005              MacroAssembler::VELEM_SIZE_16, quad);
10006   %}
10007   ins_pipe( ialu_reg_reg ); // FIXME
10008 %}
10009 
10010 instruct vsub16S_reg(vecX dst, vecX src1, vecX src2) %{
10011   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10012   match(Set dst (SubVS src1 src2));
10013   size(4);
10014   format %{ &quot;VSUB.I16 $dst.Q,$src1.Q,$src2.Q\t! sub packed8S&quot; %}
10015   ins_encode %{
10016     bool quad = true;
10017     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10018              MacroAssembler::VELEM_SIZE_16, quad);
10019   %}
10020   ins_pipe( ialu_reg_reg ); // FIXME
10021 %}
10022 
10023 // Integers vector sub
10024 instruct vsub2I_reg(vecD dst, vecD src1, vecD src2) %{
10025   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10026   match(Set dst (SubVI src1 src2));
10027   size(4);
10028   format %{ &quot;VSUB.I32 $dst,$src1,$src2\t! sub packed2I&quot; %}
10029   ins_encode %{
10030     bool quad = false;
10031     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10032              MacroAssembler::VELEM_SIZE_32, quad);
10033   %}
10034   ins_pipe( ialu_reg_reg ); // FIXME
10035 %}
10036 
10037 instruct vsub4I_reg(vecX dst, vecX src1, vecX src2) %{
10038   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10039   match(Set dst (SubVI src1 src2));
10040   size(4);
10041   format %{ &quot;VSUB.I32 $dst.Q,$src1.Q,$src2.Q\t! sub packed4I&quot; %}
10042   ins_encode %{
10043     bool quad = true;
10044     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10045              MacroAssembler::VELEM_SIZE_32, quad);
10046   %}
10047   ins_pipe( ialu_reg_reg ); // FIXME
10048 %}
10049 
10050 // Longs vector sub
10051 instruct vsub2L_reg(vecX dst, vecX src1, vecX src2) %{
10052   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10053   match(Set dst (SubVL src1 src2));
10054   size(4);
10055   format %{ &quot;VSUB.I64 $dst.Q,$src1.Q,$src2.Q\t! sub packed2L&quot; %}
10056   ins_encode %{
10057     bool quad = true;
10058     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10059              MacroAssembler::VELEM_SIZE_64, quad);
10060   %}
10061   ins_pipe( ialu_reg_reg ); // FIXME
10062 %}
10063 
10064 // Floats vector sub
10065 instruct vsub2F_reg(vecD dst, vecD src1, vecD src2) %{
10066   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
10067   match(Set dst (SubVF src1 src2));
10068   size(4);
10069   format %{ &quot;VSUB.F32 $dst,$src1,$src2\t! sub packed2F&quot; %}
10070   ins_encode %{
10071     bool quad = false;
10072     __ vsubF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10073              MacroAssembler::VFA_SIZE_F32, quad);
10074   %}
10075   ins_pipe( faddF_reg_reg ); // FIXME
10076 %}
10077 
10078 instruct vsub2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10079   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
10080   match(Set dst (SubVF src1 src2));
10081   size(4*2);
10082   ins_cost(DEFAULT_COST*2); // FIXME
10083 
10084   format %{ &quot;FSUBS  $dst.a,$src1.a,$src2.a\n\t&quot;
10085             &quot;FSUBS  $dst.b,$src1.b,$src2.b&quot; %}
10086 
10087   ins_encode %{
10088     FloatRegister dsta = $dst$$FloatRegister;
10089     FloatRegister src1a = $src1$$FloatRegister;
10090     FloatRegister src2a = $src2$$FloatRegister;
10091     __ sub_float(dsta, src1a, src2a);
10092     FloatRegister dstb = dsta-&gt;successor();
10093     FloatRegister src1b = src1a-&gt;successor();
10094     FloatRegister src2b = src2a-&gt;successor();
10095     __ sub_float(dstb, src1b, src2b);
10096   %}
10097 
10098   ins_pipe(faddF_reg_reg); // FIXME
10099 %}
10100 
10101 
10102 instruct vsub4F_reg(vecX dst, vecX src1, vecX src2) %{
10103   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
10104   match(Set dst (SubVF src1 src2));
10105   size(4);
10106   format %{ &quot;VSUB.F32 $dst.Q,$src1.Q,$src2.Q\t! sub packed4F&quot; %}
10107   ins_encode %{
10108     bool quad = true;
10109     __ vsubF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10110              MacroAssembler::VFA_SIZE_F32, quad);
10111   %}
10112   ins_pipe( faddF_reg_reg ); // FIXME
10113 %}
10114 
10115 instruct vsub4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10116   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
10117   match(Set dst (SubVF src1 src2));
10118   size(4*4);
10119   ins_cost(DEFAULT_COST*4); // FIXME
10120 
10121   format %{ &quot;FSUBS  $dst.a,$src1.a,$src2.a\n\t&quot;
10122             &quot;FSUBS  $dst.b,$src1.b,$src2.b\n\t&quot;
10123             &quot;FSUBS  $dst.c,$src1.c,$src2.c\n\t&quot;
10124             &quot;FSUBS  $dst.d,$src1.d,$src2.d&quot; %}
10125 
10126   ins_encode %{
10127     FloatRegister dsta = $dst$$FloatRegister;
10128     FloatRegister src1a = $src1$$FloatRegister;
10129     FloatRegister src2a = $src2$$FloatRegister;
10130     __ sub_float(dsta, src1a, src2a);
10131     FloatRegister dstb = dsta-&gt;successor();
10132     FloatRegister src1b = src1a-&gt;successor();
10133     FloatRegister src2b = src2a-&gt;successor();
10134     __ sub_float(dstb, src1b, src2b);
10135     FloatRegister dstc = dstb-&gt;successor();
10136     FloatRegister src1c = src1b-&gt;successor();
10137     FloatRegister src2c = src2b-&gt;successor();
10138     __ sub_float(dstc, src1c, src2c);
10139     FloatRegister dstd = dstc-&gt;successor();
10140     FloatRegister src1d = src1c-&gt;successor();
10141     FloatRegister src2d = src2c-&gt;successor();
10142     __ sub_float(dstd, src1d, src2d);
10143   %}
10144 
10145   ins_pipe(faddF_reg_reg); // FIXME
10146 %}
10147 
10148 instruct vsub2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10149   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10150   match(Set dst (SubVD src1 src2));
10151   size(4*2);
10152   ins_cost(DEFAULT_COST*2); // FIXME
10153 
10154   format %{ &quot;FSUBD  $dst.a,$src1.a,$src2.a\n\t&quot;
10155             &quot;FSUBD  $dst.b,$src1.b,$src2.b&quot; %}
10156 
10157   ins_encode %{
10158     FloatRegister dsta = $dst$$FloatRegister;
10159     FloatRegister src1a = $src1$$FloatRegister;
10160     FloatRegister src2a = $src2$$FloatRegister;
10161     __ sub_double(dsta, src1a, src2a);
10162     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10163     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10164     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10165     __ sub_double(dstb, src1b, src2b);
10166   %}
10167 
10168   ins_pipe(faddF_reg_reg); // FIXME
10169 %}
10170 
10171 // Shorts/Chars vector mul
10172 instruct vmul4S_reg(vecD dst, vecD src1, vecD src2) %{
10173   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10174   match(Set dst (MulVS src1 src2));
10175   size(4);
10176   format %{ &quot;VMUL.I16 $dst,$src1,$src2\t! mul packed4S&quot; %}
10177   ins_encode %{
10178     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10179              MacroAssembler::VELEM_SIZE_16, 0);
10180   %}
10181   ins_pipe( ialu_reg_reg ); // FIXME
10182 %}
10183 
10184 instruct vmul8S_reg(vecX dst, vecX src1, vecX src2) %{
10185   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10186   match(Set dst (MulVS src1 src2));
10187   size(4);
10188   format %{ &quot;VMUL.I16 $dst.Q,$src1.Q,$src2.Q\t! mul packed8S&quot; %}
10189   ins_encode %{
10190     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10191              MacroAssembler::VELEM_SIZE_16, 1);
10192   %}
10193   ins_pipe( ialu_reg_reg ); // FIXME
10194 %}
10195 
10196 // Integers vector mul
10197 instruct vmul2I_reg(vecD dst, vecD src1, vecD src2) %{
10198   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10199   match(Set dst (MulVI src1 src2));
10200   size(4);
10201   format %{ &quot;VMUL.I32 $dst,$src1,$src2\t! mul packed2I&quot; %}
10202   ins_encode %{
10203     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10204              MacroAssembler::VELEM_SIZE_32, 0);
10205   %}
10206   ins_pipe( ialu_reg_reg ); // FIXME
10207 %}
10208 
10209 instruct vmul4I_reg(vecX dst, vecX src1, vecX src2) %{
10210   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10211   match(Set dst (MulVI src1 src2));
10212   size(4);
10213   format %{ &quot;VMUL.I32 $dst.Q,$src1.Q,$src2.Q\t! mul packed4I&quot; %}
10214   ins_encode %{
10215     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10216              MacroAssembler::VELEM_SIZE_32, 1);
10217   %}
10218   ins_pipe( ialu_reg_reg ); // FIXME
10219 %}
10220 
10221 // Floats vector mul
10222 instruct vmul2F_reg(vecD dst, vecD src1, vecD src2) %{
10223   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
10224   match(Set dst (MulVF src1 src2));
10225   size(4);
10226   format %{ &quot;VMUL.F32 $dst,$src1,$src2\t! mul packed2F&quot; %}
10227   ins_encode %{
10228     __ vmulF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10229              MacroAssembler::VFA_SIZE_F32, 0);
10230   %}
10231   ins_pipe( fmulF_reg_reg ); // FIXME
10232 %}
10233 
10234 instruct vmul2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10235   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
10236   match(Set dst (MulVF src1 src2));
10237   size(4*2);
10238   ins_cost(DEFAULT_COST*2); // FIXME
10239 
10240   format %{ &quot;FMULS  $dst.a,$src1.a,$src2.a\n\t&quot;
10241             &quot;FMULS  $dst.b,$src1.b,$src2.b&quot; %}
10242   ins_encode %{
10243     __ mul_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
10244     __ mul_float($dst$$FloatRegister-&gt;successor(),
10245              $src1$$FloatRegister-&gt;successor(),
10246              $src2$$FloatRegister-&gt;successor());
10247   %}
10248 
10249   ins_pipe(fmulF_reg_reg); // FIXME
10250 %}
10251 
10252 instruct vmul4F_reg(vecX dst, vecX src1, vecX src2) %{
10253   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
10254   match(Set dst (MulVF src1 src2));
10255   size(4);
10256   format %{ &quot;VMUL.F32 $dst.Q,$src1.Q,$src2.Q\t! mul packed4F&quot; %}
10257   ins_encode %{
10258     __ vmulF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10259              MacroAssembler::VFA_SIZE_F32, 1);
10260   %}
10261   ins_pipe( fmulF_reg_reg ); // FIXME
10262 %}
10263 
10264 instruct vmul4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10265   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
10266   match(Set dst (MulVF src1 src2));
10267   size(4*4);
10268   ins_cost(DEFAULT_COST*4); // FIXME
10269 
10270   format %{ &quot;FMULS  $dst.a,$src1.a,$src2.a\n\t&quot;
10271             &quot;FMULS  $dst.b,$src1.b,$src2.b\n\t&quot;
10272             &quot;FMULS  $dst.c,$src1.c,$src2.c\n\t&quot;
10273             &quot;FMULS  $dst.d,$src1.d,$src2.d&quot; %}
10274 
10275   ins_encode %{
10276     FloatRegister dsta = $dst$$FloatRegister;
10277     FloatRegister src1a = $src1$$FloatRegister;
10278     FloatRegister src2a = $src2$$FloatRegister;
10279     __ mul_float(dsta, src1a, src2a);
10280     FloatRegister dstb = dsta-&gt;successor();
10281     FloatRegister src1b = src1a-&gt;successor();
10282     FloatRegister src2b = src2a-&gt;successor();
10283     __ mul_float(dstb, src1b, src2b);
10284     FloatRegister dstc = dstb-&gt;successor();
10285     FloatRegister src1c = src1b-&gt;successor();
10286     FloatRegister src2c = src2b-&gt;successor();
10287     __ mul_float(dstc, src1c, src2c);
10288     FloatRegister dstd = dstc-&gt;successor();
10289     FloatRegister src1d = src1c-&gt;successor();
10290     FloatRegister src2d = src2c-&gt;successor();
10291     __ mul_float(dstd, src1d, src2d);
10292   %}
10293 
10294   ins_pipe(fmulF_reg_reg); // FIXME
10295 %}
10296 
10297 instruct vmul2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10298   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10299   match(Set dst (MulVD src1 src2));
10300   size(4*2);
10301   ins_cost(DEFAULT_COST*2); // FIXME
10302 
10303   format %{ &quot;FMULD  $dst.D.a,$src1.D.a,$src2.D.a\n\t&quot;
10304             &quot;FMULD  $dst.D.b,$src1.D.b,$src2.D.b&quot; %}
10305   ins_encode %{
10306     FloatRegister dsta = $dst$$FloatRegister;
10307     FloatRegister src1a = $src1$$FloatRegister;
10308     FloatRegister src2a = $src2$$FloatRegister;
10309     __ mul_double(dsta, src1a, src2a);
10310     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10311     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10312     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10313     __ mul_double(dstb, src1b, src2b);
10314   %}
10315 
10316   ins_pipe(fmulD_reg_reg); // FIXME
10317 %}
10318 
10319 
10320 // Floats vector div
10321 instruct vdiv2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10322   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10323   match(Set dst (DivVF src1 src2));
10324   size(4*2);
10325   ins_cost(DEFAULT_COST*2); // FIXME
10326 
10327   format %{ &quot;FDIVS  $dst.a,$src1.a,$src2.a\n\t&quot;
10328             &quot;FDIVS  $dst.b,$src1.b,$src2.b&quot; %}
10329   ins_encode %{
10330     __ div_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
10331     __ div_float($dst$$FloatRegister-&gt;successor(),
10332              $src1$$FloatRegister-&gt;successor(),
10333              $src2$$FloatRegister-&gt;successor());
10334   %}
10335 
10336   ins_pipe(fdivF_reg_reg); // FIXME
10337 %}
10338 
10339 instruct vdiv4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10340   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10341   match(Set dst (DivVF src1 src2));
10342   size(4*4);
10343   ins_cost(DEFAULT_COST*4); // FIXME
10344 
10345   format %{ &quot;FDIVS  $dst.a,$src1.a,$src2.a\n\t&quot;
10346             &quot;FDIVS  $dst.b,$src1.b,$src2.b\n\t&quot;
10347             &quot;FDIVS  $dst.c,$src1.c,$src2.c\n\t&quot;
10348             &quot;FDIVS  $dst.d,$src1.d,$src2.d&quot; %}
10349 
10350   ins_encode %{
10351     FloatRegister dsta = $dst$$FloatRegister;
10352     FloatRegister src1a = $src1$$FloatRegister;
10353     FloatRegister src2a = $src2$$FloatRegister;
10354     __ div_float(dsta, src1a, src2a);
10355     FloatRegister dstb = dsta-&gt;successor();
10356     FloatRegister src1b = src1a-&gt;successor();
10357     FloatRegister src2b = src2a-&gt;successor();
10358     __ div_float(dstb, src1b, src2b);
10359     FloatRegister dstc = dstb-&gt;successor();
10360     FloatRegister src1c = src1b-&gt;successor();
10361     FloatRegister src2c = src2b-&gt;successor();
10362     __ div_float(dstc, src1c, src2c);
10363     FloatRegister dstd = dstc-&gt;successor();
10364     FloatRegister src1d = src1c-&gt;successor();
10365     FloatRegister src2d = src2c-&gt;successor();
10366     __ div_float(dstd, src1d, src2d);
10367   %}
10368 
10369   ins_pipe(fdivF_reg_reg); // FIXME
10370 %}
10371 
10372 instruct vdiv2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10373   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10374   match(Set dst (DivVD src1 src2));
10375   size(4*2);
10376   ins_cost(DEFAULT_COST*2); // FIXME
10377 
10378   format %{ &quot;FDIVD  $dst.D.a,$src1.D.a,$src2.D.a\n\t&quot;
10379             &quot;FDIVD  $dst.D.b,$src1.D.b,$src2.D.b&quot; %}
10380   ins_encode %{
10381     FloatRegister dsta = $dst$$FloatRegister;
10382     FloatRegister src1a = $src1$$FloatRegister;
10383     FloatRegister src2a = $src2$$FloatRegister;
10384     __ div_double(dsta, src1a, src2a);
10385     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10386     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10387     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10388     __ div_double(dstb, src1b, src2b);
10389   %}
10390 
10391   ins_pipe(fdivD_reg_reg); // FIXME
10392 %}
10393 
10394 // --------------------------------- NEG --------------------------------------
10395 
10396 instruct vneg8B_reg(vecD dst, vecD src) %{
10397   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
10398   effect(DEF dst, USE src);
10399   size(4);
10400   ins_cost(DEFAULT_COST); // FIXME
10401   format %{ &quot;VNEG.S8 $dst.D,$src.D\t! neg packed8B&quot; %}
10402   ins_encode %{
10403     bool quad = false;
10404     __ vnegI($dst$$FloatRegister, $src$$FloatRegister,
10405               MacroAssembler::VELEM_SIZE_8, quad);
10406   %}
10407   ins_pipe( ialu_reg_reg ); // FIXME
10408 %}
10409 
10410 instruct vneg16B_reg(vecX dst, vecX src) %{
10411   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
10412   effect(DEF dst, USE src);
10413   size(4);
10414   ins_cost(DEFAULT_COST); // FIXME
10415   format %{ &quot;VNEG.S8 $dst.Q,$src.Q\t! neg0 packed16B&quot; %}
10416   ins_encode %{
10417     bool _float = false;
10418     bool quad = true;
10419     __ vnegI($dst$$FloatRegister, $src$$FloatRegister,
10420               MacroAssembler::VELEM_SIZE_8, quad);
10421   %}
10422   ins_pipe( ialu_reg_reg ); // FIXME
10423 %}
10424 
10425 // ------------------------------ Shift ---------------------------------------
10426 
10427 instruct vslcntD(vecD dst, iRegI cnt) %{
10428   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
10429   match(Set dst (LShiftCntV cnt));
10430   size(4);
10431   ins_cost(DEFAULT_COST); // FIXME
10432   expand %{
10433     Repl8B_reg_simd(dst, cnt);
10434   %}
10435 %}
10436 
10437 instruct vslcntX(vecX dst, iRegI cnt) %{
10438   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
10439   match(Set dst (LShiftCntV cnt));
10440   size(4);
10441   ins_cost(DEFAULT_COST); // FIXME
10442   expand %{
10443     Repl16B_reg(dst, cnt);
10444   %}
10445 %}
10446 
10447 // Low bits of vector &quot;shift&quot; elements are used, so it
10448 // doesn&#39;t matter if we treat it as ints or bytes here.
10449 instruct vsrcntD(vecD dst, iRegI cnt) %{
10450   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
10451   match(Set dst (RShiftCntV cnt));
10452   size(4*2);
10453   ins_cost(DEFAULT_COST*2); // FIXME
10454 
10455   format %{ &quot;VDUP.8 $dst.D,$cnt\n\t&quot;
10456             &quot;VNEG.S8 $dst.D,$dst.D\t! neg packed8B&quot; %}
10457   ins_encode %{
10458     bool quad = false;
10459     __ vdupI($dst$$FloatRegister, $cnt$$Register,
10460              MacroAssembler::VELEM_SIZE_8, quad);
10461     __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,
10462               MacroAssembler::VELEM_SIZE_8, quad);
10463   %}
10464   ins_pipe( ialu_reg_reg ); // FIXME
10465 %}
10466 
10467 instruct vsrcntX(vecX dst, iRegI cnt) %{
10468   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
10469   match(Set dst (RShiftCntV cnt));
10470   size(4*2);
10471   ins_cost(DEFAULT_COST*2); // FIXME
10472   format %{ &quot;VDUP.8 $dst.Q,$cnt\n\t&quot;
10473             &quot;VNEG.S8 $dst.Q,$dst.Q\t! neg packed16B&quot; %}
10474   ins_encode %{
10475     bool quad = true;
10476     __ vdupI($dst$$FloatRegister, $cnt$$Register,
10477              MacroAssembler::VELEM_SIZE_8, quad);
10478     __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,
10479               MacroAssembler::VELEM_SIZE_8, quad);
10480   %}
10481   ins_pipe( ialu_reg_reg ); // FIXME
10482 %}
10483 
10484 // Byte vector logical left/right shift based on sign
10485 instruct vsh8B_reg(vecD dst, vecD src, vecD shift) %{
10486   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10487   effect(DEF dst, USE src, USE shift);
10488   size(4);
10489   ins_cost(DEFAULT_COST); // FIXME
10490   format %{
10491     &quot;VSHL.U8 $dst.D,$src.D,$shift.D\t! logical left/right shift packed8B&quot;
10492   %}
10493   ins_encode %{
10494     bool quad = false;
10495     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10496               MacroAssembler::VELEM_SIZE_8, quad);
10497   %}
10498   ins_pipe( ialu_reg_reg ); // FIXME
10499 %}
10500 
10501 instruct vsh16B_reg(vecX dst, vecX src, vecX shift) %{
10502   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10503   effect(DEF dst, USE src, USE shift);
10504   size(4);
10505   ins_cost(DEFAULT_COST); // FIXME
10506   format %{
10507     &quot;VSHL.U8 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed16B&quot;
10508   %}
10509   ins_encode %{
10510     bool quad = true;
10511     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10512               MacroAssembler::VELEM_SIZE_8, quad);
10513   %}
10514   ins_pipe( ialu_reg_reg ); // FIXME
10515 %}
10516 
10517 // Shorts/Char vector logical left/right shift based on sign
10518 instruct vsh4S_reg(vecD dst, vecD src, vecD shift) %{
10519   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10520   effect(DEF dst, USE src, USE shift);
10521   size(4);
10522   ins_cost(DEFAULT_COST); // FIXME
10523   format %{
10524     &quot;VSHL.U16 $dst.D,$src.D,$shift.D\t! logical left/right shift packed4S&quot;
10525   %}
10526   ins_encode %{
10527     bool quad = false;
10528     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10529               MacroAssembler::VELEM_SIZE_16, quad);
10530   %}
10531   ins_pipe( ialu_reg_reg ); // FIXME
10532 %}
10533 
10534 instruct vsh8S_reg(vecX dst, vecX src, vecX shift) %{
10535   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10536   effect(DEF dst, USE src, USE shift);
10537   size(4);
10538   ins_cost(DEFAULT_COST); // FIXME
10539   format %{
10540     &quot;VSHL.U16 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed8S&quot;
10541   %}
10542   ins_encode %{
10543     bool quad = true;
10544     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10545               MacroAssembler::VELEM_SIZE_16, quad);
10546   %}
10547   ins_pipe( ialu_reg_reg ); // FIXME
10548 %}
10549 
10550 // Integers vector logical left/right shift based on sign
10551 instruct vsh2I_reg(vecD dst, vecD src, vecD shift) %{
10552   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10553   effect(DEF dst, USE src, USE shift);
10554   size(4);
10555   ins_cost(DEFAULT_COST); // FIXME
10556   format %{
10557     &quot;VSHL.U32 $dst.D,$src.D,$shift.D\t! logical left/right shift packed2I&quot;
10558   %}
10559   ins_encode %{
10560     bool quad = false;
10561     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10562               MacroAssembler::VELEM_SIZE_32, quad);
10563   %}
10564   ins_pipe( ialu_reg_reg ); // FIXME
10565 %}
10566 
10567 instruct vsh4I_reg(vecX dst, vecX src, vecX shift) %{
10568   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10569   effect(DEF dst, USE src, USE shift);
10570   size(4);
10571   ins_cost(DEFAULT_COST); // FIXME
10572   format %{
10573     &quot;VSHL.U32 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed4I&quot;
10574   %}
10575   ins_encode %{
10576     bool quad = true;
10577     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10578               MacroAssembler::VELEM_SIZE_32, quad);
10579   %}
10580   ins_pipe( ialu_reg_reg ); // FIXME
10581 %}
10582 
10583 // Longs vector logical left/right shift based on sign
10584 instruct vsh2L_reg(vecX dst, vecX src, vecX shift) %{
10585   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10586   effect(DEF dst, USE src, USE shift);
10587   size(4);
10588   ins_cost(DEFAULT_COST); // FIXME
10589   format %{
10590     &quot;VSHL.U64 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed2L&quot;
10591   %}
10592   ins_encode %{
10593     bool quad = true;
10594     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10595               MacroAssembler::VELEM_SIZE_64, quad);
10596   %}
10597   ins_pipe( ialu_reg_reg ); // FIXME
10598 %}
10599 
10600 // ------------------------------ LeftShift -----------------------------------
10601 
10602 // Byte vector left shift
10603 instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{
10604   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10605   match(Set dst (LShiftVB src shift));
10606   size(4*1);
10607   ins_cost(DEFAULT_COST*1); // FIXME
10608   expand %{
10609     vsh8B_reg(dst, src, shift);
10610   %}
10611 %}
10612 
10613 instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{
10614   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10615   match(Set dst (LShiftVB src shift));
10616   size(4*1);
10617   ins_cost(DEFAULT_COST*1); // FIXME
10618   expand %{
10619     vsh16B_reg(dst, src, shift);
10620   %}
10621 %}
10622 
10623 instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{
10624   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10625   match(Set dst (LShiftVB src shift));
10626   size(4);
10627   ins_cost(DEFAULT_COST); // FIXME
10628   format %{
10629     &quot;VSHL.I8 $dst.D,$src.D,$shift\t! logical left shift packed8B&quot;
10630   %}
10631   ins_encode %{
10632     bool quad = false;
10633     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10634              quad);
10635   %}
10636   ins_pipe( ialu_reg_reg ); // FIXME
10637 %}
10638 
10639 instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{
10640   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10641   match(Set dst (LShiftVB src shift));
10642   size(4);
10643   ins_cost(DEFAULT_COST); // FIXME
10644   format %{
10645     &quot;VSHL.I8 $dst.Q,$src.Q,$shift\t! logical left shift packed16B&quot;
10646   %}
10647   ins_encode %{
10648     bool quad = true;
10649     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10650              quad);
10651   %}
10652   ins_pipe( ialu_reg_reg ); // FIXME
10653 %}
10654 
10655 // Shorts/Chars vector logical left/right shift
10656 instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{
10657   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10658   match(Set dst (LShiftVS src shift));
10659   match(Set dst (URShiftVS src shift));
10660   size(4*1);
10661   ins_cost(DEFAULT_COST*1); // FIXME
10662   expand %{
10663     vsh4S_reg(dst, src, shift);
10664   %}
10665 %}
10666 
10667 instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{
10668   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10669   match(Set dst (LShiftVS src shift));
10670   match(Set dst (URShiftVS src shift));
10671   size(4*1);
10672   ins_cost(DEFAULT_COST*1); // FIXME
10673   expand %{
10674     vsh8S_reg(dst, src, shift);
10675   %}
10676 %}
10677 
10678 instruct vsl4S_immI(vecD dst, vecD src, immI shift) %{
10679   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10680   match(Set dst (LShiftVS src shift));
10681   size(4);
10682   ins_cost(DEFAULT_COST); // FIXME
10683   format %{
10684     &quot;VSHL.I16 $dst.D,$src.D,$shift\t! logical left shift packed4S&quot;
10685   %}
10686   ins_encode %{
10687     bool quad = false;
10688     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10689              quad);
10690   %}
10691   ins_pipe( ialu_reg_reg ); // FIXME
10692 %}
10693 
10694 instruct vsl8S_immI(vecX dst, vecX src, immI shift) %{
10695   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10696   match(Set dst (LShiftVS src shift));
10697   size(4);
10698   ins_cost(DEFAULT_COST); // FIXME
10699   format %{
10700     &quot;VSHL.I16 $dst.Q,$src.Q,$shift\t! logical left shift packed8S&quot;
10701   %}
10702   ins_encode %{
10703     bool quad = true;
10704     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10705              quad);
10706   %}
10707   ins_pipe( ialu_reg_reg ); // FIXME
10708 %}
10709 
10710 // Integers vector logical left/right shift
10711 instruct vsl2I_reg(vecD dst, vecD src, vecD shift) %{
10712   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10713   match(Set dst (LShiftVI src shift));
10714   match(Set dst (URShiftVI src shift));
10715   size(4*1);
10716   ins_cost(DEFAULT_COST*1); // FIXME
10717   expand %{
10718     vsh2I_reg(dst, src, shift);
10719   %}
10720 %}
10721 
10722 instruct vsl4I_reg(vecX dst, vecX src, vecX shift) %{
10723   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10724   match(Set dst (LShiftVI src shift));
10725   match(Set dst (URShiftVI src shift));
10726   size(4*1);
10727   ins_cost(DEFAULT_COST*1); // FIXME
10728   expand %{
10729     vsh4I_reg(dst, src, shift);
10730   %}
10731 %}
10732 
10733 instruct vsl2I_immI(vecD dst, vecD src, immI shift) %{
10734   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10735   match(Set dst (LShiftVI src shift));
10736   size(4);
10737   ins_cost(DEFAULT_COST); // FIXME
10738   format %{
10739     &quot;VSHL.I32 $dst.D,$src.D,$shift\t! logical left shift packed2I&quot;
10740   %}
10741   ins_encode %{
10742     bool quad = false;
10743     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10744              quad);
10745   %}
10746   ins_pipe( ialu_reg_reg ); // FIXME
10747 %}
10748 
10749 instruct vsl4I_immI(vecX dst, vecX src, immI shift) %{
10750   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10751   match(Set dst (LShiftVI src shift));
10752   size(4);
10753   ins_cost(DEFAULT_COST); // FIXME
10754   format %{
10755     &quot;VSHL.I32 $dst.Q,$src.Q,$shift\t! logical left shift packed4I&quot;
10756   %}
10757   ins_encode %{
10758     bool quad = true;
10759     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10760              quad);
10761   %}
10762   ins_pipe( ialu_reg_reg ); // FIXME
10763 %}
10764 
10765 // Longs vector logical left/right shift
10766 instruct vsl2L_reg(vecX dst, vecX src, vecX shift) %{
10767   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10768   match(Set dst (LShiftVL src shift));
10769   match(Set dst (URShiftVL src shift));
10770   size(4*1);
10771   ins_cost(DEFAULT_COST*1); // FIXME
10772   expand %{
10773     vsh2L_reg(dst, src, shift);
10774   %}
10775 %}
10776 
10777 instruct vsl2L_immI(vecX dst, vecX src, immI shift) %{
10778   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10779   match(Set dst (LShiftVL src shift));
10780   size(4);
10781   ins_cost(DEFAULT_COST); // FIXME
10782   format %{
10783     &quot;VSHL.I64 $dst.Q,$src.Q,$shift\t! logical left shift packed2L&quot;
10784   %}
10785   ins_encode %{
10786     bool quad = true;
10787     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10788              quad);
10789   %}
10790   ins_pipe( ialu_reg_reg ); // FIXME
10791 %}
10792 
10793 // ----------------------- LogicalRightShift -----------------------------------
10794 
10795 // Bytes/Shorts vector logical right shift produces incorrect Java result
10796 // for negative data because java code convert short value into int with
10797 // sign extension before a shift.
10798 
10799 // Chars vector logical right shift
10800 instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{
10801   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10802   match(Set dst (URShiftVS src shift));
10803   size(4);
10804   ins_cost(DEFAULT_COST); // FIXME
10805   format %{
10806     &quot;VSHR.U16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
10807   %}
10808   ins_encode %{
10809     bool quad = false;
10810     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10811              quad);
10812   %}
10813   ins_pipe( ialu_reg_reg ); // FIXME
10814 %}
10815 
10816 instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{
10817   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10818   match(Set dst (URShiftVS src shift));
10819   size(4);
10820   ins_cost(DEFAULT_COST); // FIXME
10821   format %{
10822     &quot;VSHR.U16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
10823   %}
10824   ins_encode %{
10825     bool quad = true;
10826     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10827              quad);
10828   %}
10829   ins_pipe( ialu_reg_reg ); // FIXME
10830 %}
10831 
10832 // Integers vector logical right shift
10833 instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{
10834   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10835   match(Set dst (URShiftVI src shift));
10836   size(4);
10837   ins_cost(DEFAULT_COST); // FIXME
10838   format %{
10839     &quot;VSHR.U32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
10840   %}
10841   ins_encode %{
10842     bool quad = false;
10843     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10844              quad);
10845   %}
10846   ins_pipe( ialu_reg_reg ); // FIXME
10847 %}
10848 
10849 instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{
10850   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10851   match(Set dst (URShiftVI src shift));
10852   size(4);
10853   ins_cost(DEFAULT_COST); // FIXME
10854   format %{
10855     &quot;VSHR.U32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
10856   %}
10857   ins_encode %{
10858     bool quad = true;
10859     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10860              quad);
10861   %}
10862   ins_pipe( ialu_reg_reg ); // FIXME
10863 %}
10864 
10865 // Longs vector logical right shift
10866 instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{
10867   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10868   match(Set dst (URShiftVL src shift));
10869   size(4);
10870   ins_cost(DEFAULT_COST); // FIXME
10871   format %{
10872     &quot;VSHR.U64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
10873   %}
10874   ins_encode %{
10875     bool quad = true;
10876     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10877              quad);
10878   %}
10879   ins_pipe( ialu_reg_reg ); // FIXME
10880 %}
10881 
10882 // ------------------- ArithmeticRightShift -----------------------------------
10883 
10884 // Bytes vector arithmetic left/right shift based on sign
10885 instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{
10886   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10887   effect(DEF dst, USE src, USE shift);
10888   size(4);
10889   ins_cost(DEFAULT_COST); // FIXME
10890   format %{
10891     &quot;VSHL.S8 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed8B&quot;
10892   %}
10893   ins_encode %{
10894     bool quad = false;
10895     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10896               MacroAssembler::VELEM_SIZE_8, quad);
10897   %}
10898   ins_pipe( ialu_reg_reg ); // FIXME
10899 %}
10900 
10901 instruct vsha16B_reg(vecX dst, vecX src, vecX shift) %{
10902   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10903   effect(DEF dst, USE src, USE shift);
10904   size(4);
10905   ins_cost(DEFAULT_COST); // FIXME
10906   format %{
10907     &quot;VSHL.S8 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed16B&quot;
10908   %}
10909   ins_encode %{
10910     bool quad = true;
10911     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10912               MacroAssembler::VELEM_SIZE_8, quad);
10913   %}
10914   ins_pipe( ialu_reg_reg ); // FIXME
10915 %}
10916 
10917 // Shorts vector arithmetic left/right shift based on sign
10918 instruct vsha4S_reg(vecD dst, vecD src, vecD shift) %{
10919   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10920   effect(DEF dst, USE src, USE shift);
10921   size(4);
10922   ins_cost(DEFAULT_COST); // FIXME
10923   format %{
10924     &quot;VSHL.S16 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed4S&quot;
10925   %}
10926   ins_encode %{
10927     bool quad = false;
10928     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10929               MacroAssembler::VELEM_SIZE_16, quad);
10930   %}
10931   ins_pipe( ialu_reg_reg ); // FIXME
10932 %}
10933 
10934 instruct vsha8S_reg(vecX dst, vecX src, vecX shift) %{
10935   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10936   effect(DEF dst, USE src, USE shift);
10937   size(4);
10938   ins_cost(DEFAULT_COST); // FIXME
10939   format %{
10940     &quot;VSHL.S16 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed8S&quot;
10941   %}
10942   ins_encode %{
10943     bool quad = true;
10944     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10945               MacroAssembler::VELEM_SIZE_16, quad);
10946   %}
10947   ins_pipe( ialu_reg_reg ); // FIXME
10948 %}
10949 
10950 // Integers vector arithmetic left/right shift based on sign
10951 instruct vsha2I_reg(vecD dst, vecD src, vecD shift) %{
10952   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10953   effect(DEF dst, USE src, USE shift);
10954   size(4);
10955   ins_cost(DEFAULT_COST); // FIXME
10956   format %{
10957     &quot;VSHL.S32 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed2I&quot;
10958   %}
10959   ins_encode %{
10960     bool quad = false;
10961     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10962               MacroAssembler::VELEM_SIZE_32, quad);
10963   %}
10964   ins_pipe( ialu_reg_reg ); // FIXME
10965 %}
10966 
10967 instruct vsha4I_reg(vecX dst, vecX src, vecX shift) %{
10968   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10969   effect(DEF dst, USE src, USE shift);
10970   size(4);
10971   ins_cost(DEFAULT_COST); // FIXME
10972   format %{
10973     &quot;VSHL.S32 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed4I&quot;
10974   %}
10975   ins_encode %{
10976     bool quad = true;
10977     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10978               MacroAssembler::VELEM_SIZE_32, quad);
10979   %}
10980   ins_pipe( ialu_reg_reg ); // FIXME
10981 %}
10982 
10983 // Longs vector arithmetic left/right shift based on sign
10984 instruct vsha2L_reg(vecX dst, vecX src, vecX shift) %{
10985   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10986   effect(DEF dst, USE src, USE shift);
10987   size(4);
10988   ins_cost(DEFAULT_COST); // FIXME
10989   format %{
10990     &quot;VSHL.S64 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed2L&quot;
10991   %}
10992   ins_encode %{
10993     bool quad = true;
10994     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10995               MacroAssembler::VELEM_SIZE_64, quad);
10996   %}
10997   ins_pipe( ialu_reg_reg ); // FIXME
10998 %}
10999 
11000 // Byte vector arithmetic right shift
11001 
11002 instruct vsra8B_reg(vecD dst, vecD src, vecD shift) %{
11003   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11004   match(Set dst (RShiftVB src shift));
11005   size(4);
11006   ins_cost(DEFAULT_COST); // FIXME
11007   expand %{
11008     vsha8B_reg(dst, src, shift);
11009   %}
11010 %}
11011 
11012 instruct vsrl16B_reg(vecX dst, vecX src, vecX shift) %{
11013   predicate(n-&gt;as_Vector()-&gt;length() == 16);
11014   match(Set dst (RShiftVB src shift));
11015   size(4);
11016   ins_cost(DEFAULT_COST); // FIXME
11017   expand %{
11018     vsha16B_reg(dst, src, shift);
11019   %}
11020 %}
11021 
11022 instruct vsrl8B_immI(vecD dst, vecD src, immI shift) %{
11023   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11024   match(Set dst (RShiftVB src shift));
11025   size(4);
11026   ins_cost(DEFAULT_COST); // FIXME
11027   format %{
11028     &quot;VSHR.S8 $dst.D,$src.D,$shift\t! logical right shift packed8B&quot;
11029   %}
11030   ins_encode %{
11031     bool quad = false;
11032     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
11033              quad);
11034   %}
11035   ins_pipe( ialu_reg_reg ); // FIXME
11036 %}
11037 
11038 instruct vsrl16B_immI(vecX dst, vecX src, immI shift) %{
11039   predicate(n-&gt;as_Vector()-&gt;length() == 16);
11040   match(Set dst (RShiftVB src shift));
11041   size(4);
11042   ins_cost(DEFAULT_COST); // FIXME
11043   format %{
11044     &quot;VSHR.S8 $dst.Q,$src.Q,$shift\t! logical right shift packed16B&quot;
11045   %}
11046   ins_encode %{
11047     bool quad = true;
11048     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
11049              quad);
11050   %}
11051   ins_pipe( ialu_reg_reg ); // FIXME
11052 %}
11053 
11054 // Shorts vector arithmetic right shift
11055 instruct vsra4S_reg(vecD dst, vecD src, vecD shift) %{
11056   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11057   match(Set dst (RShiftVS src shift));
11058   size(4);
11059   ins_cost(DEFAULT_COST); // FIXME
11060   expand %{
11061     vsha4S_reg(dst, src, shift);
11062   %}
11063 %}
11064 
11065 instruct vsra8S_reg(vecX dst, vecX src, vecX shift) %{
11066   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11067   match(Set dst (RShiftVS src shift));
11068   size(4);
11069   ins_cost(DEFAULT_COST); // FIXME
11070   expand %{
11071     vsha8S_reg(dst, src, shift);
11072   %}
11073 %}
11074 
11075 instruct vsra4S_immI(vecD dst, vecD src, immI shift) %{
11076   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11077   match(Set dst (RShiftVS src shift));
11078   size(4);
11079   ins_cost(DEFAULT_COST); // FIXME
11080   format %{
11081     &quot;VSHR.S16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
11082   %}
11083   ins_encode %{
11084     bool quad = false;
11085     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
11086              quad);
11087   %}
11088   ins_pipe( ialu_reg_reg ); // FIXME
11089 %}
11090 
11091 instruct vsra8S_immI(vecX dst, vecX src, immI shift) %{
11092   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11093   match(Set dst (RShiftVS src shift));
11094   size(4);
11095   ins_cost(DEFAULT_COST); // FIXME
11096   format %{
11097     &quot;VSHR.S16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
11098   %}
11099   ins_encode %{
11100     bool quad = true;
11101     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
11102              quad);
11103   %}
11104   ins_pipe( ialu_reg_reg ); // FIXME
11105 %}
11106 
11107 // Integers vector arithmetic right shift
11108 instruct vsra2I_reg(vecD dst, vecD src, vecD shift) %{
11109   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11110   match(Set dst (RShiftVI src shift));
11111   size(4);
11112   ins_cost(DEFAULT_COST); // FIXME
11113   expand %{
11114     vsha2I_reg(dst, src, shift);
11115   %}
11116 %}
11117 
11118 instruct vsra4I_reg(vecX dst, vecX src, vecX shift) %{
11119   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11120   match(Set dst (RShiftVI src shift));
11121   size(4);
11122   ins_cost(DEFAULT_COST); // FIXME
11123   expand %{
11124     vsha4I_reg(dst, src, shift);
11125   %}
11126 %}
11127 
11128 instruct vsra2I_immI(vecD dst, vecD src, immI shift) %{
11129   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11130   match(Set dst (RShiftVI src shift));
11131   size(4);
11132   ins_cost(DEFAULT_COST); // FIXME
11133   format %{
11134     &quot;VSHR.S32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
11135   %}
11136   ins_encode %{
11137     bool quad = false;
11138     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
11139              quad);
11140   %}
11141   ins_pipe( ialu_reg_reg ); // FIXME
11142 %}
11143 
11144 instruct vsra4I_immI(vecX dst, vecX src, immI shift) %{
11145   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11146   match(Set dst (RShiftVI src shift));
11147   size(4);
11148   ins_cost(DEFAULT_COST); // FIXME
11149   format %{
11150     &quot;VSHR.S32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
11151   %}
11152   ins_encode %{
11153     bool quad = true;
11154     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
11155              quad);
11156   %}
11157   ins_pipe( ialu_reg_reg ); // FIXME
11158 %}
11159 
11160 // Longs vector arithmetic right shift
11161 instruct vsra2L_reg(vecX dst, vecX src, vecX shift) %{
11162   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11163   match(Set dst (RShiftVL src shift));
11164   size(4);
11165   ins_cost(DEFAULT_COST); // FIXME
11166   expand %{
11167     vsha2L_reg(dst, src, shift);
11168   %}
11169 %}
11170 
11171 instruct vsra2L_immI(vecX dst, vecX src, immI shift) %{
11172   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11173   match(Set dst (RShiftVL src shift));
11174   size(4);
11175   ins_cost(DEFAULT_COST); // FIXME
11176   format %{
11177     &quot;VSHR.S64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
11178   %}
11179   ins_encode %{
11180     bool quad = true;
11181     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
11182              quad);
11183   %}
11184   ins_pipe( ialu_reg_reg ); // FIXME
11185 %}
11186 
11187 // --------------------------------- AND --------------------------------------
11188 
11189 instruct vandD(vecD dst, vecD src1, vecD src2) %{
11190   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11191   match(Set dst (AndV src1 src2));
11192   format %{ &quot;VAND    $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11193   ins_encode %{
11194     bool quad = false;
11195     __ vandI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11196              quad);
11197   %}
11198   ins_pipe( ialu_reg_reg ); // FIXME
11199 %}
11200 
11201 instruct vandX(vecX dst, vecX src1, vecX src2) %{
11202   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11203   match(Set dst (AndV src1 src2));
11204   format %{ &quot;VAND    $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11205   ins_encode %{
11206     bool quad = true;
11207     __ vandI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11208              quad);
11209   %}
11210   ins_pipe( ialu_reg_reg ); // FIXME
11211 %}
11212 
11213 // --------------------------------- OR ---------------------------------------
11214 
11215 instruct vorD(vecD dst, vecD src1, vecD src2) %{
11216   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11217   match(Set dst (OrV src1 src2));
11218   format %{ &quot;VOR     $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11219   ins_encode %{
11220     bool quad = false;
11221     __ vorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11222             quad);
11223   %}
11224   ins_pipe( ialu_reg_reg ); // FIXME
11225 %}
11226 
11227 instruct vorX(vecX dst, vecX src1, vecX src2) %{
11228   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11229   match(Set dst (OrV src1 src2));
11230   format %{ &quot;VOR     $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11231   ins_encode %{
11232     bool quad = true;
11233     __ vorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11234             quad);
11235   %}
11236   ins_pipe( ialu_reg_reg ); // FIXME
11237 %}
11238 
11239 // --------------------------------- XOR --------------------------------------
11240 
11241 instruct vxorD(vecD dst, vecD src1, vecD src2) %{
11242   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11243   match(Set dst (XorV src1 src2));
11244   format %{ &quot;VXOR    $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11245   ins_encode %{
11246     bool quad = false;
11247     __ vxorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11248              quad);
11249   %}
11250   ins_pipe( ialu_reg_reg ); // FIXME
11251 %}
11252 
11253 instruct vxorX(vecX dst, vecX src1, vecX src2) %{
11254   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11255   match(Set dst (XorV src1 src2));
11256   format %{ &quot;VXOR    $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11257   ins_encode %{
11258     bool quad = true;
11259     __ vxorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11260              quad);
11261   %}
11262   ins_pipe( ialu_reg_reg ); // FIXME
11263 %}
11264 
11265 
11266 //----------PEEPHOLE RULES-----------------------------------------------------
11267 // These must follow all instruction definitions as they use the names
11268 // defined in the instructions definitions.
11269 //
11270 // peepmatch ( root_instr_name [preceding_instruction]* );
11271 //
11272 // peepconstraint %{
11273 // (instruction_number.operand_name relational_op instruction_number.operand_name
11274 //  [, ...] );
11275 // // instruction numbers are zero-based using left to right order in peepmatch
11276 //
11277 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
11278 // // provide an instruction_number.operand_name for each operand that appears
11279 // // in the replacement instruction&#39;s match rule
11280 //
11281 // ---------VM FLAGS---------------------------------------------------------
11282 //
11283 // All peephole optimizations can be turned off using -XX:-OptoPeephole
11284 //
11285 // Each peephole rule is given an identifying number starting with zero and
11286 // increasing by one in the order seen by the parser.  An individual peephole
11287 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
11288 // on the command-line.
11289 //
11290 // ---------CURRENT LIMITATIONS----------------------------------------------
11291 //
11292 // Only match adjacent instructions in same basic block
11293 // Only equality constraints
11294 // Only constraints between operands, not (0.dest_reg == EAX_enc)
11295 // Only one replacement instruction
11296 //
11297 // ---------EXAMPLE----------------------------------------------------------
11298 //
11299 // // pertinent parts of existing instructions in architecture description
11300 // instruct movI(eRegI dst, eRegI src) %{
11301 //   match(Set dst (CopyI src));
11302 // %}
11303 //
11304 // instruct incI_eReg(eRegI dst, immI1 src, eFlagsReg cr) %{
11305 //   match(Set dst (AddI dst src));
11306 //   effect(KILL cr);
11307 // %}
11308 //
11309 // // Change (inc mov) to lea
11310 // peephole %{
11311 //   // increment preceeded by register-register move
11312 //   peepmatch ( incI_eReg movI );
11313 //   // require that the destination register of the increment
11314 //   // match the destination register of the move
11315 //   peepconstraint ( 0.dst == 1.dst );
11316 //   // construct a replacement instruction that sets
11317 //   // the destination to ( move&#39;s source register + one )
11318 //   peepreplace ( incI_eReg_immI1( 0.dst 1.src 0.src ) );
11319 // %}
11320 //
11321 
11322 // // Change load of spilled value to only a spill
11323 // instruct storeI(memory mem, eRegI src) %{
11324 //   match(Set mem (StoreI mem src));
11325 // %}
11326 //
11327 // instruct loadI(eRegI dst, memory mem) %{
11328 //   match(Set dst (LoadI mem));
11329 // %}
11330 //
11331 // peephole %{
11332 //   peepmatch ( loadI storeI );
11333 //   peepconstraint ( 1.src == 0.dst, 1.mem == 0.mem );
11334 //   peepreplace ( storeI( 1.mem 1.mem 1.src ) );
11335 // %}
11336 
11337 //----------SMARTSPILL RULES---------------------------------------------------
11338 // These must follow all instruction definitions as they use the names
11339 // defined in the instructions definitions.
11340 //
11341 // ARM will probably not have any of these rules due to RISC instruction set.
11342 
11343 //----------PIPELINE-----------------------------------------------------------
11344 // Rules which define the behavior of the target architectures pipeline.
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>