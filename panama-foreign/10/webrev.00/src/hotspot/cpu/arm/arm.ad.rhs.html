<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>Frames src/hotspot/cpu/arm/arm.ad</title>
    <link rel="stylesheet" href="../../../../style.css" />
    <script type="text/javascript" src="../../../../navigation.js"></script>
  </head>
<body onkeypress="keypress(event);">
<a name="0"></a>
<hr />
<pre>    1 //
<a name="1" id="anc1"></a><span class="line-modified">    2 // Copyright (c) 2008, 2020, Oracle and/or its affiliates. All rights reserved.</span>
    3 // DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
    4 //
    5 // This code is free software; you can redistribute it and/or modify it
    6 // under the terms of the GNU General Public License version 2 only, as
    7 // published by the Free Software Foundation.
    8 //
    9 // This code is distributed in the hope that it will be useful, but WITHOUT
   10 // ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
   11 // FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
   12 // version 2 for more details (a copy is included in the LICENSE file that
   13 // accompanied this code).
   14 //
   15 // You should have received a copy of the GNU General Public License version
   16 // 2 along with this work; if not, write to the Free Software Foundation,
   17 // Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
   18 //
   19 // Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
   20 // or visit www.oracle.com if you need additional information or have any
   21 // questions.
   22 //
   23 
   24 // ARM Architecture Description File
   25 
   26 //----------DEFINITION BLOCK---------------------------------------------------
   27 // Define name --&gt; value mappings to inform the ADLC of an integer valued name
   28 // Current support includes integer values in the range [0, 0x7FFFFFFF]
   29 // Format:
   30 //        int_def  &lt;name&gt;         ( &lt;int_value&gt;, &lt;expression&gt;);
   31 // Generated Code in ad_&lt;arch&gt;.hpp
   32 //        #define  &lt;name&gt;   (&lt;expression&gt;)
   33 //        // value == &lt;int_value&gt;
   34 // Generated code in ad_&lt;arch&gt;.cpp adlc_verification()
   35 //        assert( &lt;name&gt; == &lt;int_value&gt;, &quot;Expect (&lt;expression&gt;) to equal &lt;int_value&gt;&quot;);
   36 //
   37 definitions %{
   38 // The default cost (of an ALU instruction).
   39   int_def DEFAULT_COST      (    100,     100);
   40   int_def HUGE_COST         (1000000, 1000000);
   41 
   42 // Memory refs are twice as expensive as run-of-the-mill.
   43   int_def MEMORY_REF_COST   (    200, DEFAULT_COST * 2);
   44 
   45 // Branches are even more expensive.
   46   int_def BRANCH_COST       (    300, DEFAULT_COST * 3);
   47   int_def CALL_COST         (    300, DEFAULT_COST * 3);
   48 %}
   49 
   50 
   51 //----------SOURCE BLOCK-------------------------------------------------------
   52 // This is a block of C++ code which provides values, functions, and
   53 // definitions necessary in the rest of the architecture description
   54 source_hpp %{
   55 // Header information of the source block.
   56 // Method declarations/definitions which are used outside
   57 // the ad-scope can conveniently be defined here.
   58 //
   59 // To keep related declarations/definitions/uses close together,
   60 // we switch between source %{ }% and source_hpp %{ }% freely as needed.
   61 
   62 // Does destination need to be loaded in a register then passed to a
   63 // branch instruction?
   64 extern bool maybe_far_call(const CallNode *n);
   65 extern bool maybe_far_call(const MachCallNode *n);
   66 static inline bool cache_reachable() {
   67   return MacroAssembler::_cache_fully_reachable();
   68 }
   69 
   70 #define ldr_32 ldr
   71 #define str_32 str
   72 #define tst_32 tst
   73 #define teq_32 teq
   74 #if 1
   75 extern bool PrintOptoAssembly;
   76 #endif
   77 
   78 class c2 {
   79 public:
   80   static OptoRegPair return_value(int ideal_reg);
   81 };
   82 
   83 class CallStubImpl {
   84 
   85   //--------------------------------------------------------------
   86   //---&lt;  Used for optimization in Compile::Shorten_branches  &gt;---
   87   //--------------------------------------------------------------
   88 
   89  public:
   90   // Size of call trampoline stub.
   91   static uint size_call_trampoline() {
   92     return 0; // no call trampolines on this platform
   93   }
   94 
   95   // number of relocations needed by a call trampoline stub
   96   static uint reloc_call_trampoline() {
   97     return 0; // no call trampolines on this platform
   98   }
   99 };
  100 
  101 class HandlerImpl {
  102 
  103  public:
  104 
  105   static int emit_exception_handler(CodeBuffer &amp;cbuf);
  106   static int emit_deopt_handler(CodeBuffer&amp; cbuf);
  107 
  108   static uint size_exception_handler() {
  109     return ( 3 * 4 );
  110   }
  111 
  112 
  113   static uint size_deopt_handler() {
  114     return ( 9 * 4 );
  115   }
  116 
  117 };
  118 
  119 %}
  120 
  121 source %{
  122 #define __ _masm.
  123 
  124 static FloatRegister reg_to_FloatRegister_object(int register_encoding);
  125 static Register reg_to_register_object(int register_encoding);
  126 
  127 
  128 // ****************************************************************************
  129 
  130 // REQUIRED FUNCTIONALITY
  131 
  132 // Indicate if the safepoint node needs the polling page as an input.
  133 // Since ARM does not have absolute addressing, it does.
  134 bool SafePointNode::needs_polling_address_input() {
  135   return true;
  136 }
  137 
  138 // emit an interrupt that is caught by the debugger (for debugging compiler)
  139 void emit_break(CodeBuffer &amp;cbuf) {
  140   MacroAssembler _masm(&amp;cbuf);
  141   __ breakpoint();
  142 }
  143 
  144 #ifndef PRODUCT
  145 void MachBreakpointNode::format( PhaseRegAlloc *, outputStream *st ) const {
  146   st-&gt;print(&quot;TA&quot;);
  147 }
  148 #endif
  149 
  150 void MachBreakpointNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  151   emit_break(cbuf);
  152 }
  153 
  154 uint MachBreakpointNode::size(PhaseRegAlloc *ra_) const {
  155   return MachNode::size(ra_);
  156 }
  157 
  158 
  159 void emit_nop(CodeBuffer &amp;cbuf) {
  160   MacroAssembler _masm(&amp;cbuf);
  161   __ nop();
  162 }
  163 
  164 
  165 void emit_call_reloc(CodeBuffer &amp;cbuf, const MachCallNode *n, MachOper *m, RelocationHolder const&amp; rspec) {
  166   int ret_addr_offset0 = n-&gt;as_MachCall()-&gt;ret_addr_offset();
  167   int call_site_offset = cbuf.insts()-&gt;mark_off();
  168   MacroAssembler _masm(&amp;cbuf);
  169   __ set_inst_mark(); // needed in emit_to_interp_stub() to locate the call
  170   address target = (address)m-&gt;method();
  171   assert(n-&gt;as_MachCall()-&gt;entry_point() == target, &quot;sanity&quot;);
  172   assert(maybe_far_call(n) == !__ reachable_from_cache(target), &quot;sanity&quot;);
  173   assert(cache_reachable() == __ cache_fully_reachable(), &quot;sanity&quot;);
  174 
  175   assert(target != NULL, &quot;need real address&quot;);
  176 
  177   int ret_addr_offset = -1;
  178   if (rspec.type() == relocInfo::runtime_call_type) {
  179     __ call(target, rspec);
  180     ret_addr_offset = __ offset();
  181   } else {
  182     // scratches Rtemp
  183     ret_addr_offset = __ patchable_call(target, rspec, true);
  184   }
  185   assert(ret_addr_offset - call_site_offset == ret_addr_offset0, &quot;fix ret_addr_offset()&quot;);
  186 }
  187 
  188 //=============================================================================
  189 // REQUIRED FUNCTIONALITY for encoding
  190 void emit_lo(CodeBuffer &amp;cbuf, int val) {  }
  191 void emit_hi(CodeBuffer &amp;cbuf, int val) {  }
  192 
  193 
  194 //=============================================================================
  195 const RegMask&amp; MachConstantBaseNode::_out_RegMask = PTR_REG_mask();
  196 
  197 int Compile::ConstantTable::calculate_table_base_offset() const {
  198   int offset = -(size() / 2);
  199   // flds, fldd: 8-bit  offset multiplied by 4: +/- 1024
  200   // ldr, ldrb : 12-bit offset:                 +/- 4096
  201   if (!Assembler::is_simm10(offset)) {
  202     offset = Assembler::min_simm10();
  203   }
  204   return offset;
  205 }
  206 
  207 bool MachConstantBaseNode::requires_postalloc_expand() const { return false; }
  208 void MachConstantBaseNode::postalloc_expand(GrowableArray &lt;Node *&gt; *nodes, PhaseRegAlloc *ra_) {
  209   ShouldNotReachHere();
  210 }
  211 
  212 void MachConstantBaseNode::emit(CodeBuffer&amp; cbuf, PhaseRegAlloc* ra_) const {
  213   Compile* C = ra_-&gt;C;
  214   Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();
  215   MacroAssembler _masm(&amp;cbuf);
  216 
  217   Register r = as_Register(ra_-&gt;get_encode(this));
  218   CodeSection* consts_section = __ code()-&gt;consts();
  219   int consts_size = consts_section-&gt;align_at_start(consts_section-&gt;size());
  220   assert(constant_table.size() == consts_size, &quot;must be: %d == %d&quot;, constant_table.size(), consts_size);
  221 
  222   // Materialize the constant table base.
  223   address baseaddr = consts_section-&gt;start() + -(constant_table.table_base_offset());
  224   RelocationHolder rspec = internal_word_Relocation::spec(baseaddr);
  225   __ mov_address(r, baseaddr, rspec);
  226 }
  227 
  228 uint MachConstantBaseNode::size(PhaseRegAlloc*) const {
  229   return 8;
  230 }
  231 
  232 #ifndef PRODUCT
  233 void MachConstantBaseNode::format(PhaseRegAlloc* ra_, outputStream* st) const {
  234   char reg[128];
  235   ra_-&gt;dump_register(this, reg);
  236   st-&gt;print(&quot;MOV_SLOW    &amp;constanttable,%s\t! constant table base&quot;, reg);
  237 }
  238 #endif
  239 
  240 #ifndef PRODUCT
  241 void MachPrologNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  242   Compile* C = ra_-&gt;C;
  243 
  244   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  245     st-&gt;print_cr(&quot;NOP&quot;); st-&gt;print(&quot;\t&quot;);
  246   }
  247 
  248   size_t framesize = C-&gt;frame_size_in_bytes();
  249   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
  250   int bangsize = C-&gt;bang_size_in_bytes();
  251   // Remove two words for return addr and rbp,
  252   framesize -= 2*wordSize;
  253   bangsize -= 2*wordSize;
  254 
  255   // Calls to C2R adapters often do not accept exceptional returns.
  256   // We require that their callers must bang for them.  But be careful, because
  257   // some VM calls (such as call site linkage) can use several kilobytes of
  258   // stack.  But the stack safety zone should account for that.
  259   // See bugs 4446381, 4468289, 4497237.
  260   if (C-&gt;need_stack_bang(bangsize)) {
  261     st-&gt;print_cr(&quot;! stack bang (%d bytes)&quot;, bangsize); st-&gt;print(&quot;\t&quot;);
  262   }
  263   st-&gt;print_cr(&quot;PUSH   R_FP|R_LR_LR&quot;); st-&gt;print(&quot;\t&quot;);
  264   if (framesize != 0) {
  265     st-&gt;print   (&quot;SUB    R_SP, R_SP, &quot; SIZE_FORMAT,framesize);
  266   }
  267 }
  268 #endif
  269 
  270 void MachPrologNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  271   Compile* C = ra_-&gt;C;
  272   MacroAssembler _masm(&amp;cbuf);
  273 
  274   for (int i = 0; i &lt; OptoPrologueNops; i++) {
  275     __ nop();
  276   }
  277 
  278   size_t framesize = C-&gt;frame_size_in_bytes();
  279   assert((framesize &amp; (StackAlignmentInBytes-1)) == 0, &quot;frame size not aligned&quot;);
  280   int bangsize = C-&gt;bang_size_in_bytes();
  281   // Remove two words for return addr and fp,
  282   framesize -= 2*wordSize;
  283   bangsize -= 2*wordSize;
  284 
  285   // Calls to C2R adapters often do not accept exceptional returns.
  286   // We require that their callers must bang for them.  But be careful, because
  287   // some VM calls (such as call site linkage) can use several kilobytes of
  288   // stack.  But the stack safety zone should account for that.
  289   // See bugs 4446381, 4468289, 4497237.
  290   if (C-&gt;need_stack_bang(bangsize)) {
  291     __ arm_stack_overflow_check(bangsize, Rtemp);
  292   }
  293 
  294   __ raw_push(FP, LR);
  295   if (framesize != 0) {
  296     __ sub_slow(SP, SP, framesize);
  297   }
  298 
  299   // offset from scratch buffer is not valid
  300   if (strcmp(cbuf.name(), &quot;Compile::Fill_buffer&quot;) == 0) {
  301     C-&gt;set_frame_complete( __ offset() );
  302   }
  303 
  304   if (C-&gt;has_mach_constant_base_node()) {
  305     // NOTE: We set the table base offset here because users might be
  306     // emitted before MachConstantBaseNode.
  307     Compile::ConstantTable&amp; constant_table = C-&gt;constant_table();
  308     constant_table.set_table_base_offset(constant_table.calculate_table_base_offset());
  309   }
  310 }
  311 
  312 uint MachPrologNode::size(PhaseRegAlloc *ra_) const {
  313   return MachNode::size(ra_);
  314 }
  315 
  316 int MachPrologNode::reloc() const {
  317   return 10; // a large enough number
  318 }
  319 
  320 //=============================================================================
  321 #ifndef PRODUCT
  322 void MachEpilogNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  323   Compile* C = ra_-&gt;C;
  324 
  325   size_t framesize = C-&gt;frame_size_in_bytes();
  326   framesize -= 2*wordSize;
  327 
  328   if (framesize != 0) {
  329     st-&gt;print(&quot;ADD    R_SP, R_SP, &quot; SIZE_FORMAT &quot;\n\t&quot;,framesize);
  330   }
  331   st-&gt;print(&quot;POP    R_FP|R_LR_LR&quot;);
  332 
  333   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
  334     st-&gt;print(&quot;\n\t&quot;);
  335     st-&gt;print(&quot;MOV    Rtemp, #PollAddr\t! Load Polling address\n\t&quot;);
  336     st-&gt;print(&quot;LDR    Rtemp,[Rtemp]\t!Poll for Safepointing&quot;);
  337   }
  338 }
  339 #endif
  340 
  341 void MachEpilogNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  342   MacroAssembler _masm(&amp;cbuf);
  343   Compile* C = ra_-&gt;C;
  344 
  345   size_t framesize = C-&gt;frame_size_in_bytes();
  346   framesize -= 2*wordSize;
  347   if (framesize != 0) {
  348     __ add_slow(SP, SP, framesize);
  349   }
  350   __ raw_pop(FP, LR);
  351 
  352   // If this does safepoint polling, then do it here
  353   if (do_polling() &amp;&amp; ra_-&gt;C-&gt;is_method_compilation()) {
<a name="2" id="anc2"></a><span class="line-modified">  354     __ read_polling_page(Rtemp, relocInfo::poll_return_type);</span>



  355   }
  356 }
  357 
  358 uint MachEpilogNode::size(PhaseRegAlloc *ra_) const {
  359   return MachNode::size(ra_);
  360 }
  361 
  362 int MachEpilogNode::reloc() const {
  363   return 16; // a large enough number
  364 }
  365 
  366 const Pipeline * MachEpilogNode::pipeline() const {
  367   return MachNode::pipeline_class();
  368 }
  369 
  370 int MachEpilogNode::safepoint_offset() const {
  371   assert( do_polling(), &quot;no return for this epilog node&quot;);
  372   //  return MacroAssembler::size_of_sethi(os::get_polling_page());
  373   Unimplemented();
  374   return 0;
  375 }
  376 
  377 //=============================================================================
  378 
  379 // Figure out which register class each belongs in: rc_int, rc_float, rc_stack
  380 enum RC { rc_bad, rc_int, rc_float, rc_stack };
  381 static enum RC rc_class( OptoReg::Name reg ) {
  382   if (!OptoReg::is_valid(reg)) return rc_bad;
  383   if (OptoReg::is_stack(reg)) return rc_stack;
  384   VMReg r = OptoReg::as_VMReg(reg);
  385   if (r-&gt;is_Register()) return rc_int;
  386   assert(r-&gt;is_FloatRegister(), &quot;must be&quot;);
  387   return rc_float;
  388 }
  389 
  390 static inline bool is_iRegLd_memhd(OptoReg::Name src_first, OptoReg::Name src_second, int offset) {
  391   int rlo = Matcher::_regEncode[src_first];
  392   int rhi = Matcher::_regEncode[src_second];
  393   if (!((rlo&amp;1)==0 &amp;&amp; (rlo+1 == rhi))) {
  394     tty-&gt;print_cr(&quot;CAUGHT BAD LDRD/STRD&quot;);
  395   }
  396   return (rlo&amp;1)==0 &amp;&amp; (rlo+1 == rhi) &amp;&amp; is_memoryHD(offset);
  397 }
  398 
  399 uint MachSpillCopyNode::implementation( CodeBuffer *cbuf,
  400                                         PhaseRegAlloc *ra_,
  401                                         bool do_size,
  402                                         outputStream* st ) const {
  403   // Get registers to move
  404   OptoReg::Name src_second = ra_-&gt;get_reg_second(in(1));
  405   OptoReg::Name src_first = ra_-&gt;get_reg_first(in(1));
  406   OptoReg::Name dst_second = ra_-&gt;get_reg_second(this );
  407   OptoReg::Name dst_first = ra_-&gt;get_reg_first(this );
  408 
  409   enum RC src_second_rc = rc_class(src_second);
  410   enum RC src_first_rc = rc_class(src_first);
  411   enum RC dst_second_rc = rc_class(dst_second);
  412   enum RC dst_first_rc = rc_class(dst_first);
  413 
  414   assert( OptoReg::is_valid(src_first) &amp;&amp; OptoReg::is_valid(dst_first), &quot;must move at least 1 register&quot; );
  415 
  416   // Generate spill code!
  417   int size = 0;
  418 
  419   if (src_first == dst_first &amp;&amp; src_second == dst_second)
  420     return size;            // Self copy, no move
  421 
  422 #ifdef TODO
  423   if (bottom_type()-&gt;isa_vect() != NULL) {
  424   }
  425 #endif
  426 
  427   // Shared code does not expect instruction set capability based bailouts here.
  428   // Handle offset unreachable bailout with minimal change in shared code.
  429   // Bailout only for real instruction emit.
  430   // This requires a single comment change in shared code. ( see output.cpp &quot;Normal&quot; instruction case )
  431 
  432   MacroAssembler _masm(cbuf);
  433 
  434   // --------------------------------------
  435   // Check for mem-mem move.  Load into unused float registers and fall into
  436   // the float-store case.
  437   if (src_first_rc == rc_stack &amp;&amp; dst_first_rc == rc_stack) {
  438     int offset = ra_-&gt;reg2offset(src_first);
  439     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  440       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  441       return 0;
  442     } else {
  443       if (src_second_rc != rc_bad) {
  444         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  445         src_first     = OptoReg::Name(R_mem_copy_lo_num);
  446         src_second    = OptoReg::Name(R_mem_copy_hi_num);
  447         src_first_rc  = rc_float;
  448         src_second_rc = rc_float;
  449         if (cbuf) {
  450           __ ldr_double(Rmemcopy, Address(SP, offset));
  451         } else if (!do_size) {
  452           st-&gt;print(LDR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  453         }
  454       } else {
  455         src_first     = OptoReg::Name(R_mem_copy_lo_num);
  456         src_first_rc  = rc_float;
  457         if (cbuf) {
  458           __ ldr_float(Rmemcopy, Address(SP, offset));
  459         } else if (!do_size) {
  460           st-&gt;print(LDR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  461         }
  462       }
  463       size += 4;
  464     }
  465   }
  466 
  467   if (src_second_rc == rc_stack &amp;&amp; dst_second_rc == rc_stack) {
  468     Unimplemented();
  469   }
  470 
  471   // --------------------------------------
  472   // Check for integer reg-reg copy
  473   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_int) {
  474     // Else normal reg-reg copy
  475     assert( src_second != dst_first, &quot;smashed second before evacuating it&quot; );
  476     if (cbuf) {
  477       __ mov(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]));
  478 #ifndef PRODUCT
  479     } else if (!do_size) {
  480       st-&gt;print(&quot;MOV    R_%s, R_%s\t# spill&quot;,
  481                 Matcher::regName[dst_first],
  482                 Matcher::regName[src_first]);
  483 #endif
  484     }
  485     size += 4;
  486   }
  487 
  488   // Check for integer store
  489   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_stack) {
  490     int offset = ra_-&gt;reg2offset(dst_first);
  491     if (cbuf &amp;&amp; !is_memoryI(offset)) {
  492       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  493       return 0;
  494     } else {
  495       if (src_second_rc != rc_bad &amp;&amp; is_iRegLd_memhd(src_first, src_second, offset)) {
  496         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  497         if (cbuf) {
  498           __ str_64(reg_to_register_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  499 #ifndef PRODUCT
  500         } else if (!do_size) {
  501           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  502           st-&gt;print(STR_64 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first), offset);
  503 #endif
  504         }
  505         return size + 4;
  506       } else {
  507         if (cbuf) {
  508           __ str_32(reg_to_register_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  509 #ifndef PRODUCT
  510         } else if (!do_size) {
  511           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  512           st-&gt;print(STR_32 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first), offset);
  513 #endif
  514         }
  515       }
  516     }
  517     size += 4;
  518   }
  519 
  520   // Check for integer load
  521   if (dst_first_rc == rc_int &amp;&amp; src_first_rc == rc_stack) {
  522     int offset = ra_-&gt;reg2offset(src_first);
  523     if (cbuf &amp;&amp; !is_memoryI(offset)) {
  524       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  525       return 0;
  526     } else {
  527       if (src_second_rc != rc_bad &amp;&amp; is_iRegLd_memhd(dst_first, dst_second, offset)) {
  528         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pair of registers must be aligned/contiguous&quot;);
  529         if (cbuf) {
  530           __ ldr_64(reg_to_register_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  531 #ifndef PRODUCT
  532         } else if (!do_size) {
  533           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  534           st-&gt;print(LDR_64 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first), offset);
  535 #endif
  536         }
  537         return size + 4;
  538       } else {
  539         if (cbuf) {
  540           __ ldr_32(reg_to_register_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  541 #ifndef PRODUCT
  542         } else if (!do_size) {
  543           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  544           st-&gt;print(LDR_32 &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first), offset);
  545 #endif
  546         }
  547       }
  548     }
  549     size += 4;
  550   }
  551 
  552   // Check for float reg-reg copy
  553   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_float) {
  554     if (src_second_rc != rc_bad) {
  555       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  556       if (cbuf) {
  557       __ mov_double(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  558 #ifndef PRODUCT
  559       } else if (!do_size) {
  560         st-&gt;print(MOV_DOUBLE &quot;    R_%s, R_%s\t# spill&quot;,
  561                   Matcher::regName[dst_first],
  562                   Matcher::regName[src_first]);
  563 #endif
  564       }
  565       return 4;
  566     }
  567     if (cbuf) {
  568       __ mov_float(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  569 #ifndef PRODUCT
  570     } else if (!do_size) {
  571       st-&gt;print(MOV_FLOAT &quot;    R_%s, R_%s\t# spill&quot;,
  572                 Matcher::regName[dst_first],
  573                 Matcher::regName[src_first]);
  574 #endif
  575     }
  576     size = 4;
  577   }
  578 
  579   // Check for float store
  580   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_stack) {
  581     int offset = ra_-&gt;reg2offset(dst_first);
  582     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  583       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  584       return 0;
  585     } else {
  586       // Further check for aligned-adjacent pair, so we can use a double store
  587       if (src_second_rc != rc_bad) {
  588         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers and stack slots must be aligned/contiguous&quot;);
  589         if (cbuf) {
  590           __ str_double(reg_to_FloatRegister_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  591 #ifndef PRODUCT
  592         } else if (!do_size) {
  593           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  594           st-&gt;print(STR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  595 #endif
  596         }
  597         return size + 4;
  598       } else {
  599         if (cbuf) {
  600           __ str_float(reg_to_FloatRegister_object(Matcher::_regEncode[src_first]), Address(SP, offset));
  601 #ifndef PRODUCT
  602         } else if (!do_size) {
  603           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  604           st-&gt;print(STR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_first),offset);
  605 #endif
  606         }
  607       }
  608     }
  609     size += 4;
  610   }
  611 
  612   // Check for float load
  613   if (dst_first_rc == rc_float &amp;&amp; src_first_rc == rc_stack) {
  614     int offset = ra_-&gt;reg2offset(src_first);
  615     if (cbuf &amp;&amp; !is_memoryfp(offset)) {
  616       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  617       return 0;
  618     } else {
  619       // Further check for aligned-adjacent pair, so we can use a double store
  620       if (src_second_rc != rc_bad) {
  621         assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second &amp;&amp; (dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers and stack slots must be aligned/contiguous&quot;);
  622         if (cbuf) {
  623           __ ldr_double(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  624 #ifndef PRODUCT
  625         } else if (!do_size) {
  626           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  627           st-&gt;print(LDR_DOUBLE &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first),offset);
  628 #endif
  629         }
  630         return size + 4;
  631       } else {
  632         if (cbuf) {
  633           __ ldr_float(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), Address(SP, offset));
  634 #ifndef PRODUCT
  635         } else if (!do_size) {
  636           if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  637           st-&gt;print(LDR_FLOAT &quot;   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_first),offset);
  638 #endif
  639         }
  640       }
  641     }
  642     size += 4;
  643   }
  644 
  645   // check for int reg -&gt; float reg move
  646   if (src_first_rc == rc_int &amp;&amp; dst_first_rc == rc_float) {
  647     // Further check for aligned-adjacent pair, so we can use a single instruction
  648     if (src_second_rc != rc_bad) {
  649       assert((dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  650       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  651       assert(src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_float, &quot;unsupported&quot;);
  652       if (cbuf) {
  653         __ fmdrr(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]), reg_to_register_object(Matcher::_regEncode[src_second]));
  654 #ifndef PRODUCT
  655       } else if (!do_size) {
  656         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  657         st-&gt;print(&quot;FMDRR   R_%s, R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first), OptoReg::regname(src_second));
  658 #endif
  659       }
  660       return size + 4;
  661     } else {
  662       if (cbuf) {
  663         __ fmsr(reg_to_FloatRegister_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[src_first]));
  664 #ifndef PRODUCT
  665       } else if (!do_size) {
  666         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  667         st-&gt;print(FMSR &quot;   R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first));
  668 #endif
  669       }
  670       size += 4;
  671     }
  672   }
  673 
  674   // check for float reg -&gt; int reg move
  675   if (src_first_rc == rc_float &amp;&amp; dst_first_rc == rc_int) {
  676     // Further check for aligned-adjacent pair, so we can use a single instruction
  677     if (src_second_rc != rc_bad) {
  678       assert((src_first&amp;1)==0 &amp;&amp; src_first+1 == src_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  679       assert((dst_first&amp;1)==0 &amp;&amp; dst_first+1 == dst_second, &quot;pairs of registers must be aligned/contiguous&quot;);
  680       assert(src_second_rc == rc_float &amp;&amp; dst_second_rc == rc_int, &quot;unsupported&quot;);
  681       if (cbuf) {
  682         __ fmrrd(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_register_object(Matcher::_regEncode[dst_second]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  683 #ifndef PRODUCT
  684       } else if (!do_size) {
  685         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  686         st-&gt;print(&quot;FMRRD   R_%s, R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(dst_second), OptoReg::regname(src_first));
  687 #endif
  688       }
  689       return size + 4;
  690     } else {
  691       if (cbuf) {
  692         __ fmrs(reg_to_register_object(Matcher::_regEncode[dst_first]), reg_to_FloatRegister_object(Matcher::_regEncode[src_first]));
  693 #ifndef PRODUCT
  694       } else if (!do_size) {
  695         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  696         st-&gt;print(FMRS &quot;   R_%s, R_%s\t! spill&quot;,OptoReg::regname(dst_first), OptoReg::regname(src_first));
  697 #endif
  698       }
  699       size += 4;
  700     }
  701   }
  702 
  703   // --------------------------------------------------------------------
  704   // Check for hi bits still needing moving.  Only happens for misaligned
  705   // arguments to native calls.
  706   if (src_second == dst_second)
  707     return size;               // Self copy; no move
  708   assert( src_second_rc != rc_bad &amp;&amp; dst_second_rc != rc_bad, &quot;src_second &amp; dst_second cannot be Bad&quot; );
  709 
  710   // Check for integer reg-reg copy.  Hi bits are stuck up in the top
  711   // 32-bits of a 64-bit register, but are needed in low bits of another
  712   // register (else it&#39;s a hi-bits-to-hi-bits copy which should have
  713   // happened already as part of a 64-bit move)
  714   if (src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_int) {
  715     if (cbuf) {
  716       __ mov(reg_to_register_object(Matcher::_regEncode[dst_second]), reg_to_register_object(Matcher::_regEncode[src_second]));
  717 #ifndef PRODUCT
  718     } else if (!do_size) {
  719       if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  720       st-&gt;print(&quot;MOV    R_%s, R_%s\t# spill high&quot;,
  721                 Matcher::regName[dst_second],
  722                 Matcher::regName[src_second]);
  723 #endif
  724     }
  725     return size+4;
  726   }
  727 
  728   // Check for high word integer store
  729   if (src_second_rc == rc_int &amp;&amp; dst_second_rc == rc_stack) {
  730     int offset = ra_-&gt;reg2offset(dst_second);
  731 
  732     if (cbuf &amp;&amp; !is_memoryP(offset)) {
  733       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  734       return 0;
  735     } else {
  736       if (cbuf) {
  737         __ str(reg_to_register_object(Matcher::_regEncode[src_second]), Address(SP, offset));
  738 #ifndef PRODUCT
  739       } else if (!do_size) {
  740         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  741         st-&gt;print(&quot;STR   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(src_second), offset);
  742 #endif
  743       }
  744     }
  745     return size + 4;
  746   }
  747 
  748   // Check for high word integer load
  749   if (dst_second_rc == rc_int &amp;&amp; src_second_rc == rc_stack) {
  750     int offset = ra_-&gt;reg2offset(src_second);
  751     if (cbuf &amp;&amp; !is_memoryP(offset)) {
  752       ra_-&gt;C-&gt;record_method_not_compilable(&quot;unable to handle large constant offsets&quot;);
  753       return 0;
  754     } else {
  755       if (cbuf) {
  756         __ ldr(reg_to_register_object(Matcher::_regEncode[dst_second]), Address(SP, offset));
  757 #ifndef PRODUCT
  758       } else if (!do_size) {
  759         if (size != 0) st-&gt;print(&quot;\n\t&quot;);
  760         st-&gt;print(&quot;LDR   R_%s,[R_SP + #%d]\t! spill&quot;,OptoReg::regname(dst_second), offset);
  761 #endif
  762       }
  763     }
  764     return size + 4;
  765   }
  766 
  767   Unimplemented();
  768   return 0; // Mute compiler
  769 }
  770 
  771 #ifndef PRODUCT
  772 void MachSpillCopyNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  773   implementation( NULL, ra_, false, st );
  774 }
  775 #endif
  776 
  777 void MachSpillCopyNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  778   implementation( &amp;cbuf, ra_, false, NULL );
  779 }
  780 
  781 uint MachSpillCopyNode::size(PhaseRegAlloc *ra_) const {
  782   return implementation( NULL, ra_, true, NULL );
  783 }
  784 
  785 //=============================================================================
  786 #ifndef PRODUCT
  787 void MachNopNode::format( PhaseRegAlloc *, outputStream *st ) const {
  788   st-&gt;print(&quot;NOP \t# %d bytes pad for loops and calls&quot;, 4 * _count);
  789 }
  790 #endif
  791 
  792 void MachNopNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc * ) const {
  793   MacroAssembler _masm(&amp;cbuf);
  794   for(int i = 0; i &lt; _count; i += 1) {
  795     __ nop();
  796   }
  797 }
  798 
  799 uint MachNopNode::size(PhaseRegAlloc *ra_) const {
  800   return 4 * _count;
  801 }
  802 
  803 
  804 //=============================================================================
  805 #ifndef PRODUCT
  806 void BoxLockNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  807   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
  808   int reg = ra_-&gt;get_reg_first(this);
  809   st-&gt;print(&quot;ADD    %s,R_SP+#%d&quot;,Matcher::regName[reg], offset);
  810 }
  811 #endif
  812 
  813 void BoxLockNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  814   MacroAssembler _masm(&amp;cbuf);
  815   int offset = ra_-&gt;reg2offset(in_RegMask(0).find_first_elem());
  816   int reg = ra_-&gt;get_encode(this);
  817   Register dst = reg_to_register_object(reg);
  818 
  819   if (is_aimm(offset)) {
  820     __ add(dst, SP, offset);
  821   } else {
  822     __ mov_slow(dst, offset);
  823     __ add(dst, SP, dst);
  824   }
  825 }
  826 
  827 uint BoxLockNode::size(PhaseRegAlloc *ra_) const {
  828   // BoxLockNode is not a MachNode, so we can&#39;t just call MachNode::size(ra_)
  829   assert(ra_ == ra_-&gt;C-&gt;regalloc(), &quot;sanity&quot;);
  830   return ra_-&gt;C-&gt;scratch_emit_size(this);
  831 }
  832 
  833 //=============================================================================
  834 #ifndef PRODUCT
  835 #define R_RTEMP &quot;R_R12&quot;
  836 void MachUEPNode::format( PhaseRegAlloc *ra_, outputStream *st ) const {
  837   st-&gt;print_cr(&quot;\nUEP:&quot;);
  838   if (UseCompressedClassPointers) {
  839     st-&gt;print_cr(&quot;\tLDR_w &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  840     st-&gt;print_cr(&quot;\tdecode_klass &quot; R_RTEMP);
  841   } else {
  842     st-&gt;print_cr(&quot;\tLDR   &quot; R_RTEMP &quot;,[R_R0 + oopDesc::klass_offset_in_bytes]\t! Inline cache check&quot;);
  843   }
  844   st-&gt;print_cr(&quot;\tCMP   &quot; R_RTEMP &quot;,R_R8&quot; );
  845   st-&gt;print   (&quot;\tB.NE  SharedRuntime::handle_ic_miss_stub&quot;);
  846 }
  847 #endif
  848 
  849 void MachUEPNode::emit(CodeBuffer &amp;cbuf, PhaseRegAlloc *ra_) const {
  850   MacroAssembler _masm(&amp;cbuf);
  851   Register iCache  = reg_to_register_object(Matcher::inline_cache_reg_encode());
  852   assert(iCache == Ricklass, &quot;should be&quot;);
  853   Register receiver = R0;
  854 
  855   __ load_klass(Rtemp, receiver);
  856   __ cmp(Rtemp, iCache);
  857   __ jump(SharedRuntime::get_ic_miss_stub(), relocInfo::runtime_call_type, noreg, ne);
  858 }
  859 
  860 uint MachUEPNode::size(PhaseRegAlloc *ra_) const {
  861   return MachNode::size(ra_);
  862 }
  863 
  864 
  865 //=============================================================================
  866 
  867 // Emit exception handler code.
  868 int HandlerImpl::emit_exception_handler(CodeBuffer&amp; cbuf) {
  869   MacroAssembler _masm(&amp;cbuf);
  870 
  871   address base = __ start_a_stub(size_exception_handler());
  872   if (base == NULL) {
  873     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
  874     return 0;  // CodeBuffer::expand failed
  875   }
  876 
  877   int offset = __ offset();
  878 
  879   // OK to trash LR, because exception blob will kill it
  880   __ jump(OptoRuntime::exception_blob()-&gt;entry_point(), relocInfo::runtime_call_type, LR_tmp);
  881 
  882   assert(__ offset() - offset &lt;= (int) size_exception_handler(), &quot;overflow&quot;);
  883 
  884   __ end_a_stub();
  885 
  886   return offset;
  887 }
  888 
  889 int HandlerImpl::emit_deopt_handler(CodeBuffer&amp; cbuf) {
  890   // Can&#39;t use any of the current frame&#39;s registers as we may have deopted
  891   // at a poll and everything can be live.
  892   MacroAssembler _masm(&amp;cbuf);
  893 
  894   address base = __ start_a_stub(size_deopt_handler());
  895   if (base == NULL) {
  896     ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
  897     return 0;  // CodeBuffer::expand failed
  898   }
  899 
  900   int offset = __ offset();
  901   address deopt_pc = __ pc();
  902 
  903   __ sub(SP, SP, wordSize); // make room for saved PC
  904   __ push(LR); // save LR that may be live when we get here
  905   __ mov_relative_address(LR, deopt_pc);
  906   __ str(LR, Address(SP, wordSize)); // save deopt PC
  907   __ pop(LR); // restore LR
  908   __ jump(SharedRuntime::deopt_blob()-&gt;unpack(), relocInfo::runtime_call_type, noreg);
  909 
  910   assert(__ offset() - offset &lt;= (int) size_deopt_handler(), &quot;overflow&quot;);
  911 
  912   __ end_a_stub();
  913   return offset;
  914 }
  915 
  916 const bool Matcher::match_rule_supported(int opcode) {
  917   if (!has_match_rule(opcode))
  918     return false;
  919 
  920   switch (opcode) {
  921   case Op_PopCountI:
  922   case Op_PopCountL:
  923     if (!UsePopCountInstruction)
  924       return false;
  925     break;
  926   case Op_LShiftCntV:
  927   case Op_RShiftCntV:
  928   case Op_AddVB:
  929   case Op_AddVS:
  930   case Op_AddVI:
  931   case Op_AddVL:
  932   case Op_SubVB:
  933   case Op_SubVS:
  934   case Op_SubVI:
  935   case Op_SubVL:
  936   case Op_MulVS:
  937   case Op_MulVI:
  938   case Op_LShiftVB:
  939   case Op_LShiftVS:
  940   case Op_LShiftVI:
  941   case Op_LShiftVL:
  942   case Op_RShiftVB:
  943   case Op_RShiftVS:
  944   case Op_RShiftVI:
  945   case Op_RShiftVL:
  946   case Op_URShiftVB:
  947   case Op_URShiftVS:
  948   case Op_URShiftVI:
  949   case Op_URShiftVL:
  950   case Op_AndV:
  951   case Op_OrV:
  952   case Op_XorV:
  953     return VM_Version::has_simd();
  954   case Op_LoadVector:
  955   case Op_StoreVector:
  956   case Op_AddVF:
  957   case Op_SubVF:
  958   case Op_MulVF:
  959     return VM_Version::has_vfp() || VM_Version::has_simd();
  960   case Op_AddVD:
  961   case Op_SubVD:
  962   case Op_MulVD:
  963   case Op_DivVF:
  964   case Op_DivVD:
  965     return VM_Version::has_vfp();
  966   }
  967 
  968   return true;  // Per default match rules are supported.
  969 }
  970 
  971 const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {
  972 
  973   // TODO
  974   // identify extra cases that we might want to provide match rules for
  975   // e.g. Op_ vector nodes and other intrinsics while guarding with vlen
  976   bool ret_value = match_rule_supported(opcode);
  977   // Add rules here.
  978 
  979   return ret_value;  // Per default match rules are supported.
  980 }
  981 
  982 const bool Matcher::has_predicated_vectors(void) {
  983   return false;
  984 }
  985 
  986 const int Matcher::float_pressure(int default_pressure_threshold) {
  987   return default_pressure_threshold;
  988 }
  989 
  990 int Matcher::regnum_to_fpu_offset(int regnum) {
  991   return regnum - 32; // The FP registers are in the second chunk
  992 }
  993 
  994 // Vector width in bytes
  995 const int Matcher::vector_width_in_bytes(BasicType bt) {
  996   return MaxVectorSize;
  997 }
  998 
  999 // Vector ideal reg corresponding to specified size in bytes
 1000 const uint Matcher::vector_ideal_reg(int size) {
 1001   assert(MaxVectorSize &gt;= size, &quot;&quot;);
 1002   switch(size) {
 1003     case  8: return Op_VecD;
 1004     case 16: return Op_VecX;
 1005   }
 1006   ShouldNotReachHere();
 1007   return 0;
 1008 }
 1009 
 1010 const uint Matcher::vector_shift_count_ideal_reg(int size) {
 1011   return vector_ideal_reg(size);
 1012 }
 1013 
 1014 // Limits on vector size (number of elements) loaded into vector.
 1015 const int Matcher::max_vector_size(const BasicType bt) {
 1016   assert(is_java_primitive(bt), &quot;only primitive type vectors&quot;);
 1017   return vector_width_in_bytes(bt)/type2aelembytes(bt);
 1018 }
 1019 
 1020 const int Matcher::min_vector_size(const BasicType bt) {
 1021   assert(is_java_primitive(bt), &quot;only primitive type vectors&quot;);
 1022   return 8/type2aelembytes(bt);
 1023 }
 1024 
 1025 // ARM doesn&#39;t support misaligned vectors store/load.
 1026 const bool Matcher::misaligned_vectors_ok() {
 1027   return false;
 1028 }
 1029 
 1030 // ARM doesn&#39;t support AES intrinsics
 1031 const bool Matcher::pass_original_key_for_aes() {
 1032   return false;
 1033 }
 1034 
 1035 const bool Matcher::convL2FSupported(void) {
 1036   return false;
 1037 }
 1038 
 1039 // Is this branch offset short enough that a short branch can be used?
 1040 //
 1041 // NOTE: If the platform does not provide any short branch variants, then
 1042 //       this method should return false for offset 0.
 1043 bool Matcher::is_short_branch_offset(int rule, int br_size, int offset) {
 1044   // The passed offset is relative to address of the branch.
 1045   // On ARM a branch displacement is calculated relative to address
 1046   // of the branch + 8.
 1047   //
 1048   // offset -= 8;
 1049   // return (Assembler::is_simm24(offset));
 1050   return false;
 1051 }
 1052 
 1053 const bool Matcher::isSimpleConstant64(jlong value) {
 1054   // Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.
 1055   return false;
 1056 }
 1057 
 1058 // No scaling for the parameter the ClearArray node.
 1059 const bool Matcher::init_array_count_is_in_bytes = true;
 1060 
 1061 // Needs 2 CMOV&#39;s for longs.
 1062 const int Matcher::long_cmove_cost() { return 2; }
 1063 
 1064 // CMOVF/CMOVD are expensive on ARM.
 1065 const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }
 1066 
 1067 // Does the CPU require late expand (see block.cpp for description of late expand)?
 1068 const bool Matcher::require_postalloc_expand = false;
 1069 
 1070 // Do we need to mask the count passed to shift instructions or does
 1071 // the cpu only look at the lower 5/6 bits anyway?
 1072 // FIXME: does this handle vector shifts as well?
 1073 const bool Matcher::need_masked_shift_count = true;
 1074 
 1075 const bool Matcher::convi2l_type_required = true;
 1076 
 1077 // No support for generic vector operands.
 1078 const bool Matcher::supports_generic_vector_operands  = false;
 1079 
 1080 MachOper* Matcher::specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {
 1081   ShouldNotReachHere(); // generic vector operands not supported
 1082   return NULL;
 1083 }
 1084 
 1085 bool Matcher::is_generic_reg2reg_move(MachNode* m) {
 1086   ShouldNotReachHere();  // generic vector operands not supported
 1087   return false;
 1088 }
 1089 
 1090 bool Matcher::is_generic_vector(MachOper* opnd)  {
 1091   ShouldNotReachHere();  // generic vector operands not supported
 1092   return false;
 1093 }
 1094 
 1095 // Should the Matcher clone shifts on addressing modes, expecting them
 1096 // to be subsumed into complex addressing expressions or compute them
 1097 // into registers?
 1098 bool Matcher::clone_address_expressions(AddPNode* m, Matcher::MStack&amp; mstack, VectorSet&amp; address_visited) {
 1099   return clone_base_plus_offset_address(m, mstack, address_visited);
 1100 }
 1101 
 1102 void Compile::reshape_address(AddPNode* addp) {
 1103 }
 1104 
 1105 bool Matcher::narrow_oop_use_complex_address() {
 1106   NOT_LP64(ShouldNotCallThis());
 1107   assert(UseCompressedOops, &quot;only for compressed oops code&quot;);
 1108   return false;
 1109 }
 1110 
 1111 bool Matcher::narrow_klass_use_complex_address() {
 1112   NOT_LP64(ShouldNotCallThis());
 1113   assert(UseCompressedClassPointers, &quot;only for compressed klass code&quot;);
 1114   return false;
 1115 }
 1116 
 1117 bool Matcher::const_oop_prefer_decode() {
 1118   NOT_LP64(ShouldNotCallThis());
 1119   return true;
 1120 }
 1121 
 1122 bool Matcher::const_klass_prefer_decode() {
 1123   NOT_LP64(ShouldNotCallThis());
 1124   return true;
 1125 }
 1126 
 1127 // Is it better to copy float constants, or load them directly from memory?
 1128 // Intel can load a float constant from a direct address, requiring no
 1129 // extra registers.  Most RISCs will have to materialize an address into a
 1130 // register first, so they would do better to copy the constant from stack.
 1131 const bool Matcher::rematerialize_float_constants = false;
 1132 
 1133 // If CPU can load and store mis-aligned doubles directly then no fixup is
 1134 // needed.  Else we split the double into 2 integer pieces and move it
 1135 // piece-by-piece.  Only happens when passing doubles into C code as the
 1136 // Java calling convention forces doubles to be aligned.
 1137 const bool Matcher::misaligned_doubles_ok = false;
 1138 
 1139 // No-op on ARM.
 1140 void Matcher::pd_implicit_null_fixup(MachNode *node, uint idx) {
 1141 }
 1142 
 1143 // Advertise here if the CPU requires explicit rounding operations
 1144 // to implement the UseStrictFP mode.
 1145 const bool Matcher::strict_fp_requires_explicit_rounding = false;
 1146 
 1147 // Are floats converted to double when stored to stack during deoptimization?
 1148 // ARM does not handle callee-save floats.
 1149 bool Matcher::float_in_double() {
 1150   return false;
 1151 }
 1152 
 1153 // Do ints take an entire long register or just half?
 1154 // Note that we if-def off of _LP64.
 1155 // The relevant question is how the int is callee-saved.  In _LP64
 1156 // the whole long is written but de-opt&#39;ing will have to extract
 1157 // the relevant 32 bits, in not-_LP64 only the low 32 bits is written.
 1158 #ifdef _LP64
 1159 const bool Matcher::int_in_long = true;
 1160 #else
 1161 const bool Matcher::int_in_long = false;
 1162 #endif
 1163 
 1164 // Return whether or not this register is ever used as an argument.  This
 1165 // function is used on startup to build the trampoline stubs in generateOptoStub.
 1166 // Registers not mentioned will be killed by the VM call in the trampoline, and
 1167 // arguments in those registers not be available to the callee.
 1168 bool Matcher::can_be_java_arg( int reg ) {
 1169   if (reg == R_R0_num ||
 1170       reg == R_R1_num ||
 1171       reg == R_R2_num ||
 1172       reg == R_R3_num) return true;
 1173 
 1174   if (reg &gt;= R_S0_num &amp;&amp;
 1175       reg &lt;= R_S13_num) return true;
 1176   return false;
 1177 }
 1178 
 1179 bool Matcher::is_spillable_arg( int reg ) {
 1180   return can_be_java_arg(reg);
 1181 }
 1182 
 1183 bool Matcher::use_asm_for_ldiv_by_con( jlong divisor ) {
 1184   return false;
 1185 }
 1186 
 1187 // Register for DIVI projection of divmodI
 1188 RegMask Matcher::divI_proj_mask() {
 1189   ShouldNotReachHere();
 1190   return RegMask();
 1191 }
 1192 
 1193 // Register for MODI projection of divmodI
 1194 RegMask Matcher::modI_proj_mask() {
 1195   ShouldNotReachHere();
 1196   return RegMask();
 1197 }
 1198 
 1199 // Register for DIVL projection of divmodL
 1200 RegMask Matcher::divL_proj_mask() {
 1201   ShouldNotReachHere();
 1202   return RegMask();
 1203 }
 1204 
 1205 // Register for MODL projection of divmodL
 1206 RegMask Matcher::modL_proj_mask() {
 1207   ShouldNotReachHere();
 1208   return RegMask();
 1209 }
 1210 
 1211 const RegMask Matcher::method_handle_invoke_SP_save_mask() {
 1212   return FP_REGP_mask();
 1213 }
 1214 
 1215 bool maybe_far_call(const CallNode *n) {
 1216   return !MacroAssembler::_reachable_from_cache(n-&gt;as_Call()-&gt;entry_point());
 1217 }
 1218 
 1219 bool maybe_far_call(const MachCallNode *n) {
 1220   return !MacroAssembler::_reachable_from_cache(n-&gt;as_MachCall()-&gt;entry_point());
 1221 }
 1222 
 1223 %}
 1224 
 1225 //----------ENCODING BLOCK-----------------------------------------------------
 1226 // This block specifies the encoding classes used by the compiler to output
 1227 // byte streams.  Encoding classes are parameterized macros used by
 1228 // Machine Instruction Nodes in order to generate the bit encoding of the
 1229 // instruction.  Operands specify their base encoding interface with the
 1230 // interface keyword.  There are currently supported four interfaces,
 1231 // REG_INTER, CONST_INTER, MEMORY_INTER, &amp; COND_INTER.  REG_INTER causes an
 1232 // operand to generate a function which returns its register number when
 1233 // queried.   CONST_INTER causes an operand to generate a function which
 1234 // returns the value of the constant when queried.  MEMORY_INTER causes an
 1235 // operand to generate four functions which return the Base Register, the
 1236 // Index Register, the Scale Value, and the Offset Value of the operand when
 1237 // queried.  COND_INTER causes an operand to generate six functions which
 1238 // return the encoding code (ie - encoding bits for the instruction)
 1239 // associated with each basic boolean condition for a conditional instruction.
 1240 //
 1241 // Instructions specify two basic values for encoding.  Again, a function
 1242 // is available to check if the constant displacement is an oop. They use the
 1243 // ins_encode keyword to specify their encoding classes (which must be
 1244 // a sequence of enc_class names, and their parameters, specified in
 1245 // the encoding block), and they use the
 1246 // opcode keyword to specify, in order, their primary, secondary, and
 1247 // tertiary opcode.  Only the opcode sections which a particular instruction
 1248 // needs for encoding need to be specified.
 1249 encode %{
 1250   enc_class call_epilog %{
 1251     // nothing
 1252   %}
 1253 
 1254   enc_class Java_To_Runtime (method meth) %{
 1255     // CALL directly to the runtime
 1256     emit_call_reloc(cbuf, as_MachCall(), $meth, runtime_call_Relocation::spec());
 1257   %}
 1258 
 1259   enc_class Java_Static_Call (method meth) %{
 1260     // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
 1261     // who we intended to call.
 1262 
 1263     if ( !_method) {
 1264       emit_call_reloc(cbuf, as_MachCall(), $meth, runtime_call_Relocation::spec());
 1265     } else {
 1266       int method_index = resolved_method_index(cbuf);
 1267       RelocationHolder rspec = _optimized_virtual ? opt_virtual_call_Relocation::spec(method_index)
 1268                                                   : static_call_Relocation::spec(method_index);
 1269       emit_call_reloc(cbuf, as_MachCall(), $meth, rspec);
 1270 
 1271       // Emit stubs for static call.
 1272       address stub = CompiledStaticCall::emit_to_interp_stub(cbuf);
 1273       if (stub == NULL) {
 1274         ciEnv::current()-&gt;record_failure(&quot;CodeCache is full&quot;);
 1275         return;
 1276       }
 1277     }
 1278   %}
 1279 
 1280   enc_class save_last_PC %{
 1281     // preserve mark
 1282     address mark = cbuf.insts()-&gt;mark();
 1283     debug_only(int off0 = cbuf.insts_size());
 1284     MacroAssembler _masm(&amp;cbuf);
 1285     int ret_addr_offset = as_MachCall()-&gt;ret_addr_offset();
 1286     __ adr(LR, mark + ret_addr_offset);
 1287     __ str(LR, Address(Rthread, JavaThread::last_Java_pc_offset()));
 1288     debug_only(int off1 = cbuf.insts_size());
 1289     assert(off1 - off0 == 2 * Assembler::InstructionSize, &quot;correct size prediction&quot;);
 1290     // restore mark
 1291     cbuf.insts()-&gt;set_mark(mark);
 1292   %}
 1293 
 1294   enc_class preserve_SP %{
 1295     // preserve mark
 1296     address mark = cbuf.insts()-&gt;mark();
 1297     debug_only(int off0 = cbuf.insts_size());
 1298     MacroAssembler _masm(&amp;cbuf);
 1299     // FP is preserved across all calls, even compiled calls.
 1300     // Use it to preserve SP in places where the callee might change the SP.
 1301     __ mov(Rmh_SP_save, SP);
 1302     debug_only(int off1 = cbuf.insts_size());
 1303     assert(off1 - off0 == 4, &quot;correct size prediction&quot;);
 1304     // restore mark
 1305     cbuf.insts()-&gt;set_mark(mark);
 1306   %}
 1307 
 1308   enc_class restore_SP %{
 1309     MacroAssembler _masm(&amp;cbuf);
 1310     __ mov(SP, Rmh_SP_save);
 1311   %}
 1312 
 1313   enc_class Java_Dynamic_Call (method meth) %{
 1314     MacroAssembler _masm(&amp;cbuf);
 1315     Register R8_ic_reg = reg_to_register_object(Matcher::inline_cache_reg_encode());
 1316     assert(R8_ic_reg == Ricklass, &quot;should be&quot;);
 1317     __ set_inst_mark();
 1318     __ movw(R8_ic_reg, ((unsigned int)Universe::non_oop_word()) &amp; 0xffff);
 1319     __ movt(R8_ic_reg, ((unsigned int)Universe::non_oop_word()) &gt;&gt; 16);
 1320     address  virtual_call_oop_addr = __ inst_mark();
 1321     // CALL to fixup routine.  Fixup routine uses ScopeDesc info to determine
 1322     // who we intended to call.
 1323     int method_index = resolved_method_index(cbuf);
 1324     __ relocate(virtual_call_Relocation::spec(virtual_call_oop_addr, method_index));
 1325     emit_call_reloc(cbuf, as_MachCall(), $meth, RelocationHolder::none);
 1326   %}
 1327 
 1328   enc_class LdReplImmI(immI src, regD dst, iRegI tmp, int cnt, int wth) %{
 1329     // FIXME: load from constant table?
 1330     // Load a constant replicated &quot;count&quot; times with width &quot;width&quot;
 1331     int count = $cnt$$constant;
 1332     int width = $wth$$constant;
 1333     assert(count*width == 4, &quot;sanity&quot;);
 1334     int val = $src$$constant;
 1335     if (width &lt; 4) {
 1336       int bit_width = width * 8;
 1337       val &amp;= (((int)1) &lt;&lt; bit_width) - 1; // mask off sign bits
 1338       for (int i = 0; i &lt; count - 1; i++) {
 1339         val |= (val &lt;&lt; bit_width);
 1340       }
 1341     }
 1342     MacroAssembler _masm(&amp;cbuf);
 1343 
 1344     if (val == -1) {
 1345       __ mvn($tmp$$Register, 0);
 1346     } else if (val == 0) {
 1347       __ mov($tmp$$Register, 0);
 1348     } else {
 1349       __ movw($tmp$$Register, val &amp; 0xffff);
 1350       __ movt($tmp$$Register, (unsigned int)val &gt;&gt; 16);
 1351     }
 1352     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 1353   %}
 1354 
 1355   enc_class LdReplImmF(immF src, regD dst, iRegI tmp) %{
 1356     // Replicate float con 2 times and pack into vector (8 bytes) in regD.
 1357     float fval = $src$$constant;
 1358     int val = *((int*)&amp;fval);
 1359     MacroAssembler _masm(&amp;cbuf);
 1360 
 1361     if (val == -1) {
 1362       __ mvn($tmp$$Register, 0);
 1363     } else if (val == 0) {
 1364       __ mov($tmp$$Register, 0);
 1365     } else {
 1366       __ movw($tmp$$Register, val &amp; 0xffff);
 1367       __ movt($tmp$$Register, (unsigned int)val &gt;&gt; 16);
 1368     }
 1369     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 1370   %}
 1371 
 1372   enc_class enc_String_Compare(R0RegP str1, R1RegP str2, R2RegI cnt1, R3RegI cnt2, iRegI result, iRegI tmp1, iRegI tmp2) %{
 1373     Label Ldone, Lloop;
 1374     MacroAssembler _masm(&amp;cbuf);
 1375 
 1376     Register   str1_reg = $str1$$Register;
 1377     Register   str2_reg = $str2$$Register;
 1378     Register   cnt1_reg = $cnt1$$Register; // int
 1379     Register   cnt2_reg = $cnt2$$Register; // int
 1380     Register   tmp1_reg = $tmp1$$Register;
 1381     Register   tmp2_reg = $tmp2$$Register;
 1382     Register result_reg = $result$$Register;
 1383 
 1384     assert_different_registers(str1_reg, str2_reg, cnt1_reg, cnt2_reg, tmp1_reg, tmp2_reg);
 1385 
 1386     // Compute the minimum of the string lengths(str1_reg) and the
 1387     // difference of the string lengths (stack)
 1388 
 1389     // See if the lengths are different, and calculate min in str1_reg.
 1390     // Stash diff in tmp2 in case we need it for a tie-breaker.
 1391     __ subs_32(tmp2_reg, cnt1_reg, cnt2_reg);
 1392     __ mov(cnt1_reg, AsmOperand(cnt1_reg, lsl, exact_log2(sizeof(jchar)))); // scale the limit
 1393     __ mov(cnt1_reg, AsmOperand(cnt2_reg, lsl, exact_log2(sizeof(jchar))), pl); // scale the limit
 1394 
 1395     // reallocate cnt1_reg, cnt2_reg, result_reg
 1396     // Note:  limit_reg holds the string length pre-scaled by 2
 1397     Register limit_reg = cnt1_reg;
 1398     Register  chr2_reg = cnt2_reg;
 1399     Register  chr1_reg = tmp1_reg;
 1400     // str{12} are the base pointers
 1401 
 1402     // Is the minimum length zero?
 1403     __ cmp_32(limit_reg, 0);
 1404     if (result_reg != tmp2_reg) {
 1405       __ mov(result_reg, tmp2_reg, eq);
 1406     }
 1407     __ b(Ldone, eq);
 1408 
 1409     // Load first characters
 1410     __ ldrh(chr1_reg, Address(str1_reg, 0));
 1411     __ ldrh(chr2_reg, Address(str2_reg, 0));
 1412 
 1413     // Compare first characters
 1414     __ subs(chr1_reg, chr1_reg, chr2_reg);
 1415     if (result_reg != chr1_reg) {
 1416       __ mov(result_reg, chr1_reg, ne);
 1417     }
 1418     __ b(Ldone, ne);
 1419 
 1420     {
 1421       // Check after comparing first character to see if strings are equivalent
 1422       // Check if the strings start at same location
 1423       __ cmp(str1_reg, str2_reg);
 1424       // Check if the length difference is zero
 1425       __ cond_cmp(tmp2_reg, 0, eq);
 1426       __ mov(result_reg, 0, eq); // result is zero
 1427       __ b(Ldone, eq);
 1428       // Strings might not be equal
 1429     }
 1430 
 1431     __ subs(chr1_reg, limit_reg, 1 * sizeof(jchar));
 1432     if (result_reg != tmp2_reg) {
 1433       __ mov(result_reg, tmp2_reg, eq);
 1434     }
 1435     __ b(Ldone, eq);
 1436 
 1437     // Shift str1_reg and str2_reg to the end of the arrays, negate limit
 1438     __ add(str1_reg, str1_reg, limit_reg);
 1439     __ add(str2_reg, str2_reg, limit_reg);
 1440     __ neg(limit_reg, chr1_reg);  // limit = -(limit-2)
 1441 
 1442     // Compare the rest of the characters
 1443     __ bind(Lloop);
 1444     __ ldrh(chr1_reg, Address(str1_reg, limit_reg));
 1445     __ ldrh(chr2_reg, Address(str2_reg, limit_reg));
 1446     __ subs(chr1_reg, chr1_reg, chr2_reg);
 1447     if (result_reg != chr1_reg) {
 1448       __ mov(result_reg, chr1_reg, ne);
 1449     }
 1450     __ b(Ldone, ne);
 1451 
 1452     __ adds(limit_reg, limit_reg, sizeof(jchar));
 1453     __ b(Lloop, ne);
 1454 
 1455     // If strings are equal up to min length, return the length difference.
 1456     if (result_reg != tmp2_reg) {
 1457       __ mov(result_reg, tmp2_reg);
 1458     }
 1459 
 1460     // Otherwise, return the difference between the first mismatched chars.
 1461     __ bind(Ldone);
 1462   %}
 1463 
 1464   enc_class enc_String_Equals(R0RegP str1, R1RegP str2, R2RegI cnt, iRegI result, iRegI tmp1, iRegI tmp2) %{
 1465     Label Lchar, Lchar_loop, Ldone, Lequal;
 1466     MacroAssembler _masm(&amp;cbuf);
 1467 
 1468     Register   str1_reg = $str1$$Register;
 1469     Register   str2_reg = $str2$$Register;
 1470     Register    cnt_reg = $cnt$$Register; // int
 1471     Register   tmp1_reg = $tmp1$$Register;
 1472     Register   tmp2_reg = $tmp2$$Register;
 1473     Register result_reg = $result$$Register;
 1474 
 1475     assert_different_registers(str1_reg, str2_reg, cnt_reg, tmp1_reg, tmp2_reg, result_reg);
 1476 
 1477     __ cmp(str1_reg, str2_reg); //same char[] ?
 1478     __ b(Lequal, eq);
 1479 
 1480     __ cbz_32(cnt_reg, Lequal); // count == 0
 1481 
 1482     //rename registers
 1483     Register limit_reg = cnt_reg;
 1484     Register  chr1_reg = tmp1_reg;
 1485     Register  chr2_reg = tmp2_reg;
 1486 
 1487     __ logical_shift_left(limit_reg, limit_reg, exact_log2(sizeof(jchar)));
 1488 
 1489     //check for alignment and position the pointers to the ends
 1490     __ orr(chr1_reg, str1_reg, str2_reg);
 1491     __ tst(chr1_reg, 0x3);
 1492 
 1493     // notZero means at least one not 4-byte aligned.
 1494     // We could optimize the case when both arrays are not aligned
 1495     // but it is not frequent case and it requires additional checks.
 1496     __ b(Lchar, ne);
 1497 
 1498     // Compare char[] arrays aligned to 4 bytes.
 1499     __ char_arrays_equals(str1_reg, str2_reg, limit_reg, result_reg,
 1500                           chr1_reg, chr2_reg, Ldone);
 1501 
 1502     __ b(Lequal); // equal
 1503 
 1504     // char by char compare
 1505     __ bind(Lchar);
 1506     __ mov(result_reg, 0);
 1507     __ add(str1_reg, limit_reg, str1_reg);
 1508     __ add(str2_reg, limit_reg, str2_reg);
 1509     __ neg(limit_reg, limit_reg); //negate count
 1510 
 1511     // Lchar_loop
 1512     __ bind(Lchar_loop);
 1513     __ ldrh(chr1_reg, Address(str1_reg, limit_reg));
 1514     __ ldrh(chr2_reg, Address(str2_reg, limit_reg));
 1515     __ cmp(chr1_reg, chr2_reg);
 1516     __ b(Ldone, ne);
 1517     __ adds(limit_reg, limit_reg, sizeof(jchar));
 1518     __ b(Lchar_loop, ne);
 1519 
 1520     __ bind(Lequal);
 1521     __ mov(result_reg, 1);  //equal
 1522 
 1523     __ bind(Ldone);
 1524   %}
 1525 
 1526   enc_class enc_Array_Equals(R0RegP ary1, R1RegP ary2, iRegI tmp1, iRegI tmp2, iRegI tmp3, iRegI result) %{
 1527     Label Ldone, Lloop, Lequal;
 1528     MacroAssembler _masm(&amp;cbuf);
 1529 
 1530     Register   ary1_reg = $ary1$$Register;
 1531     Register   ary2_reg = $ary2$$Register;
 1532     Register   tmp1_reg = $tmp1$$Register;
 1533     Register   tmp2_reg = $tmp2$$Register;
 1534     Register   tmp3_reg = $tmp3$$Register;
 1535     Register result_reg = $result$$Register;
 1536 
 1537     assert_different_registers(ary1_reg, ary2_reg, tmp1_reg, tmp2_reg, tmp3_reg, result_reg);
 1538 
 1539     int length_offset  = arrayOopDesc::length_offset_in_bytes();
 1540     int base_offset    = arrayOopDesc::base_offset_in_bytes(T_CHAR);
 1541 
 1542     // return true if the same array
 1543     __ teq(ary1_reg, ary2_reg);
 1544     __ mov(result_reg, 1, eq);
 1545     __ b(Ldone, eq); // equal
 1546 
 1547     __ tst(ary1_reg, ary1_reg);
 1548     __ mov(result_reg, 0, eq);
 1549     __ b(Ldone, eq);    // not equal
 1550 
 1551     __ tst(ary2_reg, ary2_reg);
 1552     __ mov(result_reg, 0, eq);
 1553     __ b(Ldone, eq);    // not equal
 1554 
 1555     //load the lengths of arrays
 1556     __ ldr_s32(tmp1_reg, Address(ary1_reg, length_offset)); // int
 1557     __ ldr_s32(tmp2_reg, Address(ary2_reg, length_offset)); // int
 1558 
 1559     // return false if the two arrays are not equal length
 1560     __ teq_32(tmp1_reg, tmp2_reg);
 1561     __ mov(result_reg, 0, ne);
 1562     __ b(Ldone, ne);    // not equal
 1563 
 1564     __ tst(tmp1_reg, tmp1_reg);
 1565     __ mov(result_reg, 1, eq);
 1566     __ b(Ldone, eq);    // zero-length arrays are equal
 1567 
 1568     // load array addresses
 1569     __ add(ary1_reg, ary1_reg, base_offset);
 1570     __ add(ary2_reg, ary2_reg, base_offset);
 1571 
 1572     // renaming registers
 1573     Register chr1_reg  =  tmp3_reg;   // for characters in ary1
 1574     Register chr2_reg  =  tmp2_reg;   // for characters in ary2
 1575     Register limit_reg =  tmp1_reg;   // length
 1576 
 1577     // set byte count
 1578     __ logical_shift_left_32(limit_reg, limit_reg, exact_log2(sizeof(jchar)));
 1579 
 1580     // Compare char[] arrays aligned to 4 bytes.
 1581     __ char_arrays_equals(ary1_reg, ary2_reg, limit_reg, result_reg,
 1582                           chr1_reg, chr2_reg, Ldone);
 1583     __ bind(Lequal);
 1584     __ mov(result_reg, 1);  //equal
 1585 
 1586     __ bind(Ldone);
 1587     %}
 1588 %}
 1589 
 1590 //----------FRAME--------------------------------------------------------------
 1591 // Definition of frame structure and management information.
 1592 //
 1593 //  S T A C K   L A Y O U T    Allocators stack-slot number
 1594 //                             |   (to get allocators register number
 1595 //  G  Owned by    |        |  v    add VMRegImpl::stack0)
 1596 //  r   CALLER     |        |
 1597 //  o     |        +--------+      pad to even-align allocators stack-slot
 1598 //  w     V        |  pad0  |        numbers; owned by CALLER
 1599 //  t   -----------+--------+----&gt; Matcher::_in_arg_limit, unaligned
 1600 //  h     ^        |   in   |  5
 1601 //        |        |  args  |  4   Holes in incoming args owned by SELF
 1602 //  |     |        |        |  3
 1603 //  |     |        +--------+
 1604 //  V     |        | old out|      Empty on Intel, window on Sparc
 1605 //        |    old |preserve|      Must be even aligned.
 1606 //        |     SP-+--------+----&gt; Matcher::_old_SP, 8 (or 16 in LP64)-byte aligned
 1607 //        |        |   in   |  3   area for Intel ret address
 1608 //     Owned by    |preserve|      Empty on Sparc.
 1609 //       SELF      +--------+
 1610 //        |        |  pad2  |  2   pad to align old SP
 1611 //        |        +--------+  1
 1612 //        |        | locks  |  0
 1613 //        |        +--------+----&gt; VMRegImpl::stack0, 8 (or 16 in LP64)-byte aligned
 1614 //        |        |  pad1  | 11   pad to align new SP
 1615 //        |        +--------+
 1616 //        |        |        | 10
 1617 //        |        | spills |  9   spills
 1618 //        V        |        |  8   (pad0 slot for callee)
 1619 //      -----------+--------+----&gt; Matcher::_out_arg_limit, unaligned
 1620 //        ^        |  out   |  7
 1621 //        |        |  args  |  6   Holes in outgoing args owned by CALLEE
 1622 //     Owned by    +--------+
 1623 //      CALLEE     | new out|  6   Empty on Intel, window on Sparc
 1624 //        |    new |preserve|      Must be even-aligned.
 1625 //        |     SP-+--------+----&gt; Matcher::_new_SP, even aligned
 1626 //        |        |        |
 1627 //
 1628 // Note 1: Only region 8-11 is determined by the allocator.  Region 0-5 is
 1629 //         known from SELF&#39;s arguments and the Java calling convention.
 1630 //         Region 6-7 is determined per call site.
 1631 // Note 2: If the calling convention leaves holes in the incoming argument
 1632 //         area, those holes are owned by SELF.  Holes in the outgoing area
 1633 //         are owned by the CALLEE.  Holes should not be nessecary in the
 1634 //         incoming area, as the Java calling convention is completely under
 1635 //         the control of the AD file.  Doubles can be sorted and packed to
 1636 //         avoid holes.  Holes in the outgoing arguments may be nessecary for
 1637 //         varargs C calling conventions.
 1638 // Note 3: Region 0-3 is even aligned, with pad2 as needed.  Region 3-5 is
 1639 //         even aligned with pad0 as needed.
 1640 //         Region 6 is even aligned.  Region 6-7 is NOT even aligned;
 1641 //         region 6-11 is even aligned; it may be padded out more so that
 1642 //         the region from SP to FP meets the minimum stack alignment.
 1643 
 1644 frame %{
 1645   // What direction does stack grow in (assumed to be same for native &amp; Java)
 1646   stack_direction(TOWARDS_LOW);
 1647 
 1648   // These two registers define part of the calling convention
 1649   // between compiled code and the interpreter.
 1650   inline_cache_reg(R_Ricklass);          // Inline Cache Register or Method* for I2C
 1651   interpreter_method_oop_reg(R_Rmethod); // Method Oop Register when calling interpreter
 1652 
 1653   // Optional: name the operand used by cisc-spilling to access [stack_pointer + offset]
 1654   cisc_spilling_operand_name(indOffset);
 1655 
 1656   // Number of stack slots consumed by a Monitor enter
 1657   sync_stack_slots(1 * VMRegImpl::slots_per_word);
 1658 
 1659   // Compiled code&#39;s Frame Pointer
 1660   frame_pointer(R_R13);
 1661 
 1662   // Stack alignment requirement
 1663   stack_alignment(StackAlignmentInBytes);
 1664   //  LP64: Alignment size in bytes (128-bit -&gt; 16 bytes)
 1665   // !LP64: Alignment size in bytes (64-bit  -&gt;  8 bytes)
 1666 
 1667   // Number of stack slots between incoming argument block and the start of
 1668   // a new frame.  The PROLOG must add this many slots to the stack.  The
 1669   // EPILOG must remove this many slots.
 1670   // FP + LR
 1671   in_preserve_stack_slots(2 * VMRegImpl::slots_per_word);
 1672 
 1673   // Number of outgoing stack slots killed above the out_preserve_stack_slots
 1674   // for calls to C.  Supports the var-args backing area for register parms.
 1675   // ADLC doesn&#39;t support parsing expressions, so I folded the math by hand.
 1676   varargs_C_out_slots_killed( 0);
 1677 
 1678   // The after-PROLOG location of the return address.  Location of
 1679   // return address specifies a type (REG or STACK) and a number
 1680   // representing the register number (i.e. - use a register name) or
 1681   // stack slot.
 1682   // Ret Addr is on stack in slot 0 if no locks or verification or alignment.
 1683   // Otherwise, it is above the locks and verification slot and alignment word
 1684   return_addr(STACK - 1*VMRegImpl::slots_per_word +
 1685               align_up((Compile::current()-&gt;in_preserve_stack_slots() +
 1686                         Compile::current()-&gt;fixed_slots()),
 1687                        stack_alignment_in_slots()));
 1688 
 1689   // Body of function which returns an OptoRegs array locating
 1690   // arguments either in registers or in stack slots for calling
 1691   // java
 1692   calling_convention %{
 1693     (void) SharedRuntime::java_calling_convention(sig_bt, regs, length, is_outgoing);
 1694 
 1695   %}
 1696 
 1697   // Body of function which returns an OptoRegs array locating
 1698   // arguments either in registers or in stack slots for callin
 1699   // C.
 1700   c_calling_convention %{
 1701     // This is obviously always outgoing
 1702     (void) SharedRuntime::c_calling_convention(sig_bt, regs, /*regs2=*/NULL, length);
 1703   %}
 1704 
 1705   // Location of compiled Java return values.  Same as C
 1706   return_value %{
 1707     return c2::return_value(ideal_reg);
 1708   %}
 1709 
 1710 %}
 1711 
 1712 //----------ATTRIBUTES---------------------------------------------------------
 1713 //----------Instruction Attributes---------------------------------------------
 1714 ins_attrib ins_cost(DEFAULT_COST); // Required cost attribute
 1715 ins_attrib ins_size(32);           // Required size attribute (in bits)
 1716 ins_attrib ins_short_branch(0);    // Required flag: is this instruction a
 1717                                    // non-matching short branch variant of some
 1718                                                             // long branch?
 1719 
 1720 //----------OPERANDS-----------------------------------------------------------
 1721 // Operand definitions must precede instruction definitions for correct parsing
 1722 // in the ADLC because operands constitute user defined types which are used in
 1723 // instruction definitions.
 1724 
 1725 //----------Simple Operands----------------------------------------------------
 1726 // Immediate Operands
 1727 // Integer Immediate: 32-bit
 1728 operand immI() %{
 1729   match(ConI);
 1730 
 1731   op_cost(0);
 1732   // formats are generated automatically for constants and base registers
 1733   format %{ %}
 1734   interface(CONST_INTER);
 1735 %}
 1736 
 1737 // Integer Immediate: 8-bit unsigned - for VMOV
 1738 operand immU8() %{
 1739   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 255));
 1740   match(ConI);
 1741   op_cost(0);
 1742 
 1743   format %{ %}
 1744   interface(CONST_INTER);
 1745 %}
 1746 
 1747 // Integer Immediate: 16-bit
 1748 operand immI16() %{
 1749   predicate((n-&gt;get_int() &gt;&gt; 16) == 0 &amp;&amp; VM_Version::supports_movw());
 1750   match(ConI);
 1751   op_cost(0);
 1752 
 1753   format %{ %}
 1754   interface(CONST_INTER);
 1755 %}
 1756 
 1757 // Integer Immediate: offset for half and double word loads and stores
 1758 operand immIHD() %{
 1759   predicate(is_memoryHD(n-&gt;get_int()));
 1760   match(ConI);
 1761   op_cost(0);
 1762   format %{ %}
 1763   interface(CONST_INTER);
 1764 %}
 1765 
 1766 // Integer Immediate: offset for fp loads and stores
 1767 operand immIFP() %{
 1768   predicate(is_memoryfp(n-&gt;get_int()) &amp;&amp; ((n-&gt;get_int() &amp; 3) == 0));
 1769   match(ConI);
 1770   op_cost(0);
 1771 
 1772   format %{ %}
 1773   interface(CONST_INTER);
 1774 %}
 1775 
 1776 // Valid scale values for addressing modes and shifts
 1777 operand immU5() %{
 1778   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; (n-&gt;get_int() &lt;= 31));
 1779   match(ConI);
 1780   op_cost(0);
 1781 
 1782   format %{ %}
 1783   interface(CONST_INTER);
 1784 %}
 1785 
 1786 // Integer Immediate: 6-bit
 1787 operand immU6Big() %{
 1788   predicate(n-&gt;get_int() &gt;= 32 &amp;&amp; n-&gt;get_int() &lt;= 63);
 1789   match(ConI);
 1790   op_cost(0);
 1791   format %{ %}
 1792   interface(CONST_INTER);
 1793 %}
 1794 
 1795 // Integer Immediate: 0-bit
 1796 operand immI0() %{
 1797   predicate(n-&gt;get_int() == 0);
 1798   match(ConI);
 1799   op_cost(0);
 1800 
 1801   format %{ %}
 1802   interface(CONST_INTER);
 1803 %}
 1804 
 1805 // Integer Immediate: the value 1
 1806 operand immI_1() %{
 1807   predicate(n-&gt;get_int() == 1);
 1808   match(ConI);
 1809   op_cost(0);
 1810 
 1811   format %{ %}
 1812   interface(CONST_INTER);
 1813 %}
 1814 
 1815 // Integer Immediate: the value 2
 1816 operand immI_2() %{
 1817   predicate(n-&gt;get_int() == 2);
 1818   match(ConI);
 1819   op_cost(0);
 1820 
 1821   format %{ %}
 1822   interface(CONST_INTER);
 1823 %}
 1824 
 1825 // Integer Immediate: the value 3
 1826 operand immI_3() %{
 1827   predicate(n-&gt;get_int() == 3);
 1828   match(ConI);
 1829   op_cost(0);
 1830 
 1831   format %{ %}
 1832   interface(CONST_INTER);
 1833 %}
 1834 
 1835 // Integer Immediate: the value 4
 1836 operand immI_4() %{
 1837   predicate(n-&gt;get_int() == 4);
 1838   match(ConI);
 1839   op_cost(0);
 1840 
 1841   format %{ %}
 1842   interface(CONST_INTER);
 1843 %}
 1844 
 1845 // Integer Immediate: the value 8
 1846 operand immI_8() %{
 1847   predicate(n-&gt;get_int() == 8);
 1848   match(ConI);
 1849   op_cost(0);
 1850 
 1851   format %{ %}
 1852   interface(CONST_INTER);
 1853 %}
 1854 
 1855 // Int Immediate non-negative
 1856 operand immU31()
 1857 %{
 1858   predicate(n-&gt;get_int() &gt;= 0);
 1859   match(ConI);
 1860 
 1861   op_cost(0);
 1862   format %{ %}
 1863   interface(CONST_INTER);
 1864 %}
 1865 
 1866 // Integer Immediate: the values 32-63
 1867 operand immI_32_63() %{
 1868   predicate(n-&gt;get_int() &gt;= 32 &amp;&amp; n-&gt;get_int() &lt;= 63);
 1869   match(ConI);
 1870   op_cost(0);
 1871 
 1872   format %{ %}
 1873   interface(CONST_INTER);
 1874 %}
 1875 
 1876 // Immediates for special shifts (sign extend)
 1877 
 1878 // Integer Immediate: the value 16
 1879 operand immI_16() %{
 1880   predicate(n-&gt;get_int() == 16);
 1881   match(ConI);
 1882   op_cost(0);
 1883 
 1884   format %{ %}
 1885   interface(CONST_INTER);
 1886 %}
 1887 
 1888 // Integer Immediate: the value 24
 1889 operand immI_24() %{
 1890   predicate(n-&gt;get_int() == 24);
 1891   match(ConI);
 1892   op_cost(0);
 1893 
 1894   format %{ %}
 1895   interface(CONST_INTER);
 1896 %}
 1897 
 1898 // Integer Immediate: the value 255
 1899 operand immI_255() %{
 1900   predicate( n-&gt;get_int() == 255 );
 1901   match(ConI);
 1902   op_cost(0);
 1903 
 1904   format %{ %}
 1905   interface(CONST_INTER);
 1906 %}
 1907 
 1908 // Integer Immediate: the value 65535
 1909 operand immI_65535() %{
 1910   predicate(n-&gt;get_int() == 65535);
 1911   match(ConI);
 1912   op_cost(0);
 1913 
 1914   format %{ %}
 1915   interface(CONST_INTER);
 1916 %}
 1917 
 1918 // Integer Immediates for arithmetic instructions
 1919 
 1920 operand aimmI() %{
 1921   predicate(is_aimm(n-&gt;get_int()));
 1922   match(ConI);
 1923   op_cost(0);
 1924 
 1925   format %{ %}
 1926   interface(CONST_INTER);
 1927 %}
 1928 
 1929 operand aimmIneg() %{
 1930   predicate(is_aimm(-n-&gt;get_int()));
 1931   match(ConI);
 1932   op_cost(0);
 1933 
 1934   format %{ %}
 1935   interface(CONST_INTER);
 1936 %}
 1937 
 1938 operand aimmU31() %{
 1939   predicate((0 &lt;= n-&gt;get_int()) &amp;&amp; is_aimm(n-&gt;get_int()));
 1940   match(ConI);
 1941   op_cost(0);
 1942 
 1943   format %{ %}
 1944   interface(CONST_INTER);
 1945 %}
 1946 
 1947 // Integer Immediates for logical instructions
 1948 
 1949 operand limmI() %{
 1950   predicate(is_limmI(n-&gt;get_int()));
 1951   match(ConI);
 1952   op_cost(0);
 1953 
 1954   format %{ %}
 1955   interface(CONST_INTER);
 1956 %}
 1957 
 1958 operand limmIlow8() %{
 1959   predicate(is_limmI_low(n-&gt;get_int(), 8));
 1960   match(ConI);
 1961   op_cost(0);
 1962 
 1963   format %{ %}
 1964   interface(CONST_INTER);
 1965 %}
 1966 
 1967 operand limmU31() %{
 1968   predicate(0 &lt;= n-&gt;get_int() &amp;&amp; is_limmI(n-&gt;get_int()));
 1969   match(ConI);
 1970   op_cost(0);
 1971 
 1972   format %{ %}
 1973   interface(CONST_INTER);
 1974 %}
 1975 
 1976 operand limmIn() %{
 1977   predicate(is_limmI(~n-&gt;get_int()));
 1978   match(ConI);
 1979   op_cost(0);
 1980 
 1981   format %{ %}
 1982   interface(CONST_INTER);
 1983 %}
 1984 
 1985 
 1986 // Long Immediate: the value FF
 1987 operand immL_FF() %{
 1988   predicate( n-&gt;get_long() == 0xFFL );
 1989   match(ConL);
 1990   op_cost(0);
 1991 
 1992   format %{ %}
 1993   interface(CONST_INTER);
 1994 %}
 1995 
 1996 // Long Immediate: the value FFFF
 1997 operand immL_FFFF() %{
 1998   predicate( n-&gt;get_long() == 0xFFFFL );
 1999   match(ConL);
 2000   op_cost(0);
 2001 
 2002   format %{ %}
 2003   interface(CONST_INTER);
 2004 %}
 2005 
 2006 // Pointer Immediate: 32 or 64-bit
 2007 operand immP() %{
 2008   match(ConP);
 2009 
 2010   op_cost(5);
 2011   // formats are generated automatically for constants and base registers
 2012   format %{ %}
 2013   interface(CONST_INTER);
 2014 %}
 2015 
 2016 operand immP0() %{
 2017   predicate(n-&gt;get_ptr() == 0);
 2018   match(ConP);
 2019   op_cost(0);
 2020 
 2021   format %{ %}
 2022   interface(CONST_INTER);
 2023 %}
 2024 
 2025 operand immP_poll() %{
 2026   predicate(n-&gt;get_ptr() != 0 &amp;&amp; n-&gt;get_ptr() == (intptr_t)os::get_polling_page());
 2027   match(ConP);
 2028 
 2029   // formats are generated automatically for constants and base registers
 2030   format %{ %}
 2031   interface(CONST_INTER);
 2032 %}
 2033 
 2034 // Pointer Immediate
 2035 operand immN()
 2036 %{
 2037   match(ConN);
 2038 
 2039   op_cost(10);
 2040   format %{ %}
 2041   interface(CONST_INTER);
 2042 %}
 2043 
 2044 operand immNKlass()
 2045 %{
 2046   match(ConNKlass);
 2047 
 2048   op_cost(10);
 2049   format %{ %}
 2050   interface(CONST_INTER);
 2051 %}
 2052 
 2053 // NULL Pointer Immediate
 2054 operand immN0()
 2055 %{
 2056   predicate(n-&gt;get_narrowcon() == 0);
 2057   match(ConN);
 2058 
 2059   op_cost(0);
 2060   format %{ %}
 2061   interface(CONST_INTER);
 2062 %}
 2063 
 2064 operand immL() %{
 2065   match(ConL);
 2066   op_cost(40);
 2067   // formats are generated automatically for constants and base registers
 2068   format %{ %}
 2069   interface(CONST_INTER);
 2070 %}
 2071 
 2072 operand immL0() %{
 2073   predicate(n-&gt;get_long() == 0L);
 2074   match(ConL);
 2075   op_cost(0);
 2076   // formats are generated automatically for constants and base registers
 2077   format %{ %}
 2078   interface(CONST_INTER);
 2079 %}
 2080 
 2081 // Long Immediate: 16-bit
 2082 operand immL16() %{
 2083   predicate(n-&gt;get_long() &gt;= 0 &amp;&amp; n-&gt;get_long() &lt; (1&lt;&lt;16)  &amp;&amp; VM_Version::supports_movw());
 2084   match(ConL);
 2085   op_cost(0);
 2086 
 2087   format %{ %}
 2088   interface(CONST_INTER);
 2089 %}
 2090 
 2091 // Long Immediate: low 32-bit mask
 2092 operand immL_32bits() %{
 2093   predicate(n-&gt;get_long() == 0xFFFFFFFFL);
 2094   match(ConL);
 2095   op_cost(0);
 2096 
 2097   format %{ %}
 2098   interface(CONST_INTER);
 2099 %}
 2100 
 2101 // Double Immediate
 2102 operand immD() %{
 2103   match(ConD);
 2104 
 2105   op_cost(40);
 2106   format %{ %}
 2107   interface(CONST_INTER);
 2108 %}
 2109 
 2110 // Double Immediate: +0.0d.
 2111 operand immD0() %{
 2112   predicate(jlong_cast(n-&gt;getd()) == 0);
 2113 
 2114   match(ConD);
 2115   op_cost(0);
 2116   format %{ %}
 2117   interface(CONST_INTER);
 2118 %}
 2119 
 2120 operand imm8D() %{
 2121   predicate(Assembler::double_num(n-&gt;getd()).can_be_imm8());
 2122   match(ConD);
 2123 
 2124   op_cost(0);
 2125   format %{ %}
 2126   interface(CONST_INTER);
 2127 %}
 2128 
 2129 // Float Immediate
 2130 operand immF() %{
 2131   match(ConF);
 2132 
 2133   op_cost(20);
 2134   format %{ %}
 2135   interface(CONST_INTER);
 2136 %}
 2137 
 2138 // Float Immediate: +0.0f
 2139 operand immF0() %{
 2140   predicate(jint_cast(n-&gt;getf()) == 0);
 2141   match(ConF);
 2142 
 2143   op_cost(0);
 2144   format %{ %}
 2145   interface(CONST_INTER);
 2146 %}
 2147 
 2148 // Float Immediate: encoded as 8 bits
 2149 operand imm8F() %{
 2150   predicate(Assembler::float_num(n-&gt;getf()).can_be_imm8());
 2151   match(ConF);
 2152 
 2153   op_cost(0);
 2154   format %{ %}
 2155   interface(CONST_INTER);
 2156 %}
 2157 
 2158 // Integer Register Operands
 2159 // Integer Register
 2160 operand iRegI() %{
 2161   constraint(ALLOC_IN_RC(int_reg));
 2162   match(RegI);
 2163   match(R0RegI);
 2164   match(R1RegI);
 2165   match(R2RegI);
 2166   match(R3RegI);
 2167   match(R12RegI);
 2168 
 2169   format %{ %}
 2170   interface(REG_INTER);
 2171 %}
 2172 
 2173 // Pointer Register
 2174 operand iRegP() %{
 2175   constraint(ALLOC_IN_RC(ptr_reg));
 2176   match(RegP);
 2177   match(R0RegP);
 2178   match(R1RegP);
 2179   match(R2RegP);
 2180   match(RExceptionRegP);
 2181   match(R8RegP);
 2182   match(R9RegP);
 2183   match(RthreadRegP); // FIXME: move to sp_ptr_RegP?
 2184   match(R12RegP);
 2185   match(LRRegP);
 2186 
 2187   match(sp_ptr_RegP);
 2188   match(store_ptr_RegP);
 2189 
 2190   format %{ %}
 2191   interface(REG_INTER);
 2192 %}
 2193 
 2194 // GPRs + Rthread + SP
 2195 operand sp_ptr_RegP() %{
 2196   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2197   match(RegP);
 2198   match(iRegP);
 2199   match(SPRegP); // FIXME: check cost
 2200 
 2201   format %{ %}
 2202   interface(REG_INTER);
 2203 %}
 2204 
 2205 
 2206 operand R0RegP() %{
 2207   constraint(ALLOC_IN_RC(R0_regP));
 2208   match(iRegP);
 2209 
 2210   format %{ %}
 2211   interface(REG_INTER);
 2212 %}
 2213 
 2214 operand R1RegP() %{
 2215   constraint(ALLOC_IN_RC(R1_regP));
 2216   match(iRegP);
 2217 
 2218   format %{ %}
 2219   interface(REG_INTER);
 2220 %}
 2221 
 2222 operand R8RegP() %{
 2223   constraint(ALLOC_IN_RC(R8_regP));
 2224   match(iRegP);
 2225 
 2226   format %{ %}
 2227   interface(REG_INTER);
 2228 %}
 2229 
 2230 operand R9RegP() %{
 2231   constraint(ALLOC_IN_RC(R9_regP));
 2232   match(iRegP);
 2233 
 2234   format %{ %}
 2235   interface(REG_INTER);
 2236 %}
 2237 
 2238 operand R12RegP() %{
 2239   constraint(ALLOC_IN_RC(R12_regP));
 2240   match(iRegP);
 2241 
 2242   format %{ %}
 2243   interface(REG_INTER);
 2244 %}
 2245 
 2246 operand R2RegP() %{
 2247   constraint(ALLOC_IN_RC(R2_regP));
 2248   match(iRegP);
 2249 
 2250   format %{ %}
 2251   interface(REG_INTER);
 2252 %}
 2253 
 2254 operand RExceptionRegP() %{
 2255   constraint(ALLOC_IN_RC(Rexception_regP));
 2256   match(iRegP);
 2257 
 2258   format %{ %}
 2259   interface(REG_INTER);
 2260 %}
 2261 
 2262 operand RthreadRegP() %{
 2263   constraint(ALLOC_IN_RC(Rthread_regP));
 2264   match(iRegP);
 2265 
 2266   format %{ %}
 2267   interface(REG_INTER);
 2268 %}
 2269 
 2270 operand IPRegP() %{
 2271   constraint(ALLOC_IN_RC(IP_regP));
 2272   match(iRegP);
 2273 
 2274   format %{ %}
 2275   interface(REG_INTER);
 2276 %}
 2277 
 2278 operand SPRegP() %{
 2279   constraint(ALLOC_IN_RC(SP_regP));
 2280   match(iRegP);
 2281 
 2282   format %{ %}
 2283   interface(REG_INTER);
 2284 %}
 2285 
 2286 operand LRRegP() %{
 2287   constraint(ALLOC_IN_RC(LR_regP));
 2288   match(iRegP);
 2289 
 2290   format %{ %}
 2291   interface(REG_INTER);
 2292 %}
 2293 
 2294 operand R0RegI() %{
 2295   constraint(ALLOC_IN_RC(R0_regI));
 2296   match(iRegI);
 2297 
 2298   format %{ %}
 2299   interface(REG_INTER);
 2300 %}
 2301 
 2302 operand R1RegI() %{
 2303   constraint(ALLOC_IN_RC(R1_regI));
 2304   match(iRegI);
 2305 
 2306   format %{ %}
 2307   interface(REG_INTER);
 2308 %}
 2309 
 2310 operand R2RegI() %{
 2311   constraint(ALLOC_IN_RC(R2_regI));
 2312   match(iRegI);
 2313 
 2314   format %{ %}
 2315   interface(REG_INTER);
 2316 %}
 2317 
 2318 operand R3RegI() %{
 2319   constraint(ALLOC_IN_RC(R3_regI));
 2320   match(iRegI);
 2321 
 2322   format %{ %}
 2323   interface(REG_INTER);
 2324 %}
 2325 
 2326 operand R12RegI() %{
 2327   constraint(ALLOC_IN_RC(R12_regI));
 2328   match(iRegI);
 2329 
 2330   format %{ %}
 2331   interface(REG_INTER);
 2332 %}
 2333 
 2334 // Long Register
 2335 operand iRegL() %{
 2336   constraint(ALLOC_IN_RC(long_reg));
 2337   match(RegL);
 2338   match(R0R1RegL);
 2339   match(R2R3RegL);
 2340 //match(iRegLex);
 2341 
 2342   format %{ %}
 2343   interface(REG_INTER);
 2344 %}
 2345 
 2346 operand iRegLd() %{
 2347   constraint(ALLOC_IN_RC(long_reg_align));
 2348   match(iRegL); // FIXME: allows unaligned R11/R12?
 2349 
 2350   format %{ %}
 2351   interface(REG_INTER);
 2352 %}
 2353 
 2354 // first long arg, or return value
 2355 operand R0R1RegL() %{
 2356   constraint(ALLOC_IN_RC(R0R1_regL));
 2357   match(iRegL);
 2358 
 2359   format %{ %}
 2360   interface(REG_INTER);
 2361 %}
 2362 
 2363 operand R2R3RegL() %{
 2364   constraint(ALLOC_IN_RC(R2R3_regL));
 2365   match(iRegL);
 2366 
 2367   format %{ %}
 2368   interface(REG_INTER);
 2369 %}
 2370 
 2371 // Condition Code Flag Register
 2372 operand flagsReg() %{
 2373   constraint(ALLOC_IN_RC(int_flags));
 2374   match(RegFlags);
 2375 
 2376   format %{ &quot;apsr&quot; %}
 2377   interface(REG_INTER);
 2378 %}
 2379 
 2380 // Result of compare to 0 (TST)
 2381 operand flagsReg_EQNELTGE() %{
 2382   constraint(ALLOC_IN_RC(int_flags));
 2383   match(RegFlags);
 2384 
 2385   format %{ &quot;apsr_EQNELTGE&quot; %}
 2386   interface(REG_INTER);
 2387 %}
 2388 
 2389 // Condition Code Register, unsigned comparisons.
 2390 operand flagsRegU() %{
 2391   constraint(ALLOC_IN_RC(int_flags));
 2392   match(RegFlags);
 2393 #ifdef TODO
 2394   match(RegFlagsP);
 2395 #endif
 2396 
 2397   format %{ &quot;apsr_U&quot; %}
 2398   interface(REG_INTER);
 2399 %}
 2400 
 2401 // Condition Code Register, pointer comparisons.
 2402 operand flagsRegP() %{
 2403   constraint(ALLOC_IN_RC(int_flags));
 2404   match(RegFlags);
 2405 
 2406   format %{ &quot;apsr_P&quot; %}
 2407   interface(REG_INTER);
 2408 %}
 2409 
 2410 // Condition Code Register, long comparisons.
 2411 operand flagsRegL_LTGE() %{
 2412   constraint(ALLOC_IN_RC(int_flags));
 2413   match(RegFlags);
 2414 
 2415   format %{ &quot;apsr_L_LTGE&quot; %}
 2416   interface(REG_INTER);
 2417 %}
 2418 
 2419 operand flagsRegL_EQNE() %{
 2420   constraint(ALLOC_IN_RC(int_flags));
 2421   match(RegFlags);
 2422 
 2423   format %{ &quot;apsr_L_EQNE&quot; %}
 2424   interface(REG_INTER);
 2425 %}
 2426 
 2427 operand flagsRegL_LEGT() %{
 2428   constraint(ALLOC_IN_RC(int_flags));
 2429   match(RegFlags);
 2430 
 2431   format %{ &quot;apsr_L_LEGT&quot; %}
 2432   interface(REG_INTER);
 2433 %}
 2434 
 2435 operand flagsRegUL_LTGE() %{
 2436   constraint(ALLOC_IN_RC(int_flags));
 2437   match(RegFlags);
 2438 
 2439   format %{ &quot;apsr_UL_LTGE&quot; %}
 2440   interface(REG_INTER);
 2441 %}
 2442 
 2443 operand flagsRegUL_EQNE() %{
 2444   constraint(ALLOC_IN_RC(int_flags));
 2445   match(RegFlags);
 2446 
 2447   format %{ &quot;apsr_UL_EQNE&quot; %}
 2448   interface(REG_INTER);
 2449 %}
 2450 
 2451 operand flagsRegUL_LEGT() %{
 2452   constraint(ALLOC_IN_RC(int_flags));
 2453   match(RegFlags);
 2454 
 2455   format %{ &quot;apsr_UL_LEGT&quot; %}
 2456   interface(REG_INTER);
 2457 %}
 2458 
 2459 // Condition Code Register, floating comparisons, unordered same as &quot;less&quot;.
 2460 operand flagsRegF() %{
 2461   constraint(ALLOC_IN_RC(float_flags));
 2462   match(RegFlags);
 2463 
 2464   format %{ &quot;fpscr_F&quot; %}
 2465   interface(REG_INTER);
 2466 %}
 2467 
 2468 // Vectors
 2469 operand vecD() %{
 2470   constraint(ALLOC_IN_RC(actual_dflt_reg));
 2471   match(VecD);
 2472 
 2473   format %{ %}
 2474   interface(REG_INTER);
 2475 %}
 2476 
 2477 operand vecX() %{
 2478   constraint(ALLOC_IN_RC(vectorx_reg));
 2479   match(VecX);
 2480 
 2481   format %{ %}
 2482   interface(REG_INTER);
 2483 %}
 2484 
 2485 operand regD() %{
 2486   constraint(ALLOC_IN_RC(actual_dflt_reg));
 2487   match(RegD);
 2488   match(regD_low);
 2489 
 2490   format %{ %}
 2491   interface(REG_INTER);
 2492 %}
 2493 
 2494 operand regF() %{
 2495   constraint(ALLOC_IN_RC(sflt_reg));
 2496   match(RegF);
 2497 
 2498   format %{ %}
 2499   interface(REG_INTER);
 2500 %}
 2501 
 2502 operand regD_low() %{
 2503   constraint(ALLOC_IN_RC(dflt_low_reg));
 2504   match(RegD);
 2505 
 2506   format %{ %}
 2507   interface(REG_INTER);
 2508 %}
 2509 
 2510 // Special Registers
 2511 
 2512 // Method Register
 2513 operand inline_cache_regP(iRegP reg) %{
 2514   constraint(ALLOC_IN_RC(Ricklass_regP));
 2515   match(reg);
 2516   format %{ %}
 2517   interface(REG_INTER);
 2518 %}
 2519 
 2520 operand interpreter_method_oop_regP(iRegP reg) %{
 2521   constraint(ALLOC_IN_RC(Rmethod_regP));
 2522   match(reg);
 2523   format %{ %}
 2524   interface(REG_INTER);
 2525 %}
 2526 
 2527 
 2528 //----------Complex Operands---------------------------------------------------
 2529 // Indirect Memory Reference
 2530 operand indirect(sp_ptr_RegP reg) %{
 2531   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2532   match(reg);
 2533 
 2534   op_cost(100);
 2535   format %{ &quot;[$reg]&quot; %}
 2536   interface(MEMORY_INTER) %{
 2537     base($reg);
 2538     index(0xf); // PC =&gt; no index
 2539     scale(0x0);
 2540     disp(0x0);
 2541   %}
 2542 %}
 2543 
 2544 
 2545 // Indirect with Offset in ]-4096, 4096[
 2546 operand indOffset12(sp_ptr_RegP reg, immI12 offset) %{
 2547   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2548   match(AddP reg offset);
 2549 
 2550   op_cost(100);
 2551   format %{ &quot;[$reg + $offset]&quot; %}
 2552   interface(MEMORY_INTER) %{
 2553     base($reg);
 2554     index(0xf); // PC =&gt; no index
 2555     scale(0x0);
 2556     disp($offset);
 2557   %}
 2558 %}
 2559 
 2560 // Indirect with offset for float load/store
 2561 operand indOffsetFP(sp_ptr_RegP reg, immIFP offset) %{
 2562   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2563   match(AddP reg offset);
 2564 
 2565   op_cost(100);
 2566   format %{ &quot;[$reg + $offset]&quot; %}
 2567   interface(MEMORY_INTER) %{
 2568     base($reg);
 2569     index(0xf); // PC =&gt; no index
 2570     scale(0x0);
 2571     disp($offset);
 2572   %}
 2573 %}
 2574 
 2575 // Indirect with Offset for half and double words
 2576 operand indOffsetHD(sp_ptr_RegP reg, immIHD offset) %{
 2577   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2578   match(AddP reg offset);
 2579 
 2580   op_cost(100);
 2581   format %{ &quot;[$reg + $offset]&quot; %}
 2582   interface(MEMORY_INTER) %{
 2583     base($reg);
 2584     index(0xf); // PC =&gt; no index
 2585     scale(0x0);
 2586     disp($offset);
 2587   %}
 2588 %}
 2589 
 2590 // Indirect with Offset and Offset+4 in ]-1024, 1024[
 2591 operand indOffsetFPx2(sp_ptr_RegP reg, immX10x2 offset) %{
 2592   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2593   match(AddP reg offset);
 2594 
 2595   op_cost(100);
 2596   format %{ &quot;[$reg + $offset]&quot; %}
 2597   interface(MEMORY_INTER) %{
 2598     base($reg);
 2599     index(0xf); // PC =&gt; no index
 2600     scale(0x0);
 2601     disp($offset);
 2602   %}
 2603 %}
 2604 
 2605 // Indirect with Offset and Offset+4 in ]-4096, 4096[
 2606 operand indOffset12x2(sp_ptr_RegP reg, immI12x2 offset) %{
 2607   constraint(ALLOC_IN_RC(sp_ptr_reg));
 2608   match(AddP reg offset);
 2609 
 2610   op_cost(100);
 2611   format %{ &quot;[$reg + $offset]&quot; %}
 2612   interface(MEMORY_INTER) %{
 2613     base($reg);
 2614     index(0xf); // PC =&gt; no index
 2615     scale(0x0);
 2616     disp($offset);
 2617   %}
 2618 %}
 2619 
 2620 // Indirect with Register Index
 2621 operand indIndex(iRegP addr, iRegX index) %{
 2622   constraint(ALLOC_IN_RC(ptr_reg));
 2623   match(AddP addr index);
 2624 
 2625   op_cost(100);
 2626   format %{ &quot;[$addr + $index]&quot; %}
 2627   interface(MEMORY_INTER) %{
 2628     base($addr);
 2629     index($index);
 2630     scale(0x0);
 2631     disp(0x0);
 2632   %}
 2633 %}
 2634 
 2635 // Indirect Memory Times Scale Plus Index Register
 2636 operand indIndexScale(iRegP addr, iRegX index, immU5 scale) %{
 2637   constraint(ALLOC_IN_RC(ptr_reg));
 2638   match(AddP addr (LShiftX index scale));
 2639 
 2640   op_cost(100);
 2641   format %{&quot;[$addr + $index &lt;&lt; $scale]&quot; %}
 2642   interface(MEMORY_INTER) %{
 2643     base($addr);
 2644     index($index);
 2645     scale($scale);
 2646     disp(0x0);
 2647   %}
 2648 %}
 2649 
 2650 // Operands for expressing Control Flow
 2651 // NOTE:  Label is a predefined operand which should not be redefined in
 2652 //        the AD file.  It is generically handled within the ADLC.
 2653 
 2654 //----------Conditional Branch Operands----------------------------------------
 2655 // Comparison Op  - This is the operation of the comparison, and is limited to
 2656 //                  the following set of codes:
 2657 //                  L (&lt;), LE (&lt;=), G (&gt;), GE (&gt;=), E (==), NE (!=)
 2658 //
 2659 // Other attributes of the comparison, such as unsignedness, are specified
 2660 // by the comparison instruction that sets a condition code flags register.
 2661 // That result is represented by a flags operand whose subtype is appropriate
 2662 // to the unsignedness (etc.) of the comparison.
 2663 //
 2664 // Later, the instruction which matches both the Comparison Op (a Bool) and
 2665 // the flags (produced by the Cmp) specifies the coding of the comparison op
 2666 // by matching a specific subtype of Bool operand below, such as cmpOpU.
 2667 
 2668 operand cmpOp() %{
 2669   match(Bool);
 2670 
 2671   format %{ &quot;&quot; %}
 2672   interface(COND_INTER) %{
 2673     equal(0x0);
 2674     not_equal(0x1);
 2675     less(0xb);
 2676     greater_equal(0xa);
 2677     less_equal(0xd);
 2678     greater(0xc);
 2679     overflow(0x0); // unsupported/unimplemented
 2680     no_overflow(0x0); // unsupported/unimplemented
 2681   %}
 2682 %}
 2683 
 2684 // integer comparison with 0, signed
 2685 operand cmpOp0() %{
 2686   match(Bool);
 2687 
 2688   format %{ &quot;&quot; %}
 2689   interface(COND_INTER) %{
 2690     equal(0x0);
 2691     not_equal(0x1);
 2692     less(0x4);
 2693     greater_equal(0x5);
 2694     less_equal(0xd); // unsupported
 2695     greater(0xc); // unsupported
 2696     overflow(0x0); // unsupported/unimplemented
 2697     no_overflow(0x0); // unsupported/unimplemented
 2698   %}
 2699 %}
 2700 
 2701 // Comparison Op, unsigned
 2702 operand cmpOpU() %{
 2703   match(Bool);
 2704 
 2705   format %{ &quot;u&quot; %}
 2706   interface(COND_INTER) %{
 2707     equal(0x0);
 2708     not_equal(0x1);
 2709     less(0x3);
 2710     greater_equal(0x2);
 2711     less_equal(0x9);
 2712     greater(0x8);
 2713     overflow(0x0); // unsupported/unimplemented
 2714     no_overflow(0x0); // unsupported/unimplemented
 2715   %}
 2716 %}
 2717 
 2718 // Comparison Op, pointer (same as unsigned)
 2719 operand cmpOpP() %{
 2720   match(Bool);
 2721 
 2722   format %{ &quot;p&quot; %}
 2723   interface(COND_INTER) %{
 2724     equal(0x0);
 2725     not_equal(0x1);
 2726     less(0x3);
 2727     greater_equal(0x2);
 2728     less_equal(0x9);
 2729     greater(0x8);
 2730     overflow(0x0); // unsupported/unimplemented
 2731     no_overflow(0x0); // unsupported/unimplemented
 2732   %}
 2733 %}
 2734 
 2735 operand cmpOpL() %{
 2736   match(Bool);
 2737 
 2738   format %{ &quot;L&quot; %}
 2739   interface(COND_INTER) %{
 2740     equal(0x0);
 2741     not_equal(0x1);
 2742     less(0xb);
 2743     greater_equal(0xa);
 2744     less_equal(0xd);
 2745     greater(0xc);
 2746     overflow(0x0); // unsupported/unimplemented
 2747     no_overflow(0x0); // unsupported/unimplemented
 2748   %}
 2749 %}
 2750 
 2751 operand cmpOpL_commute() %{
 2752   match(Bool);
 2753 
 2754   format %{ &quot;L&quot; %}
 2755   interface(COND_INTER) %{
 2756     equal(0x0);
 2757     not_equal(0x1);
 2758     less(0xc);
 2759     greater_equal(0xd);
 2760     less_equal(0xa);
 2761     greater(0xb);
 2762     overflow(0x0); // unsupported/unimplemented
 2763     no_overflow(0x0); // unsupported/unimplemented
 2764   %}
 2765 %}
 2766 
 2767 operand cmpOpUL() %{
 2768   match(Bool);
 2769 
 2770   format %{ &quot;UL&quot; %}
 2771   interface(COND_INTER) %{
 2772     equal(0x0);
 2773     not_equal(0x1);
 2774     less(0x3);
 2775     greater_equal(0x2);
 2776     less_equal(0x9);
 2777     greater(0x8);
 2778     overflow(0x0); // unsupported/unimplemented
 2779     no_overflow(0x0); // unsupported/unimplemented
 2780   %}
 2781 %}
 2782 
 2783 operand cmpOpUL_commute() %{
 2784   match(Bool);
 2785 
 2786   format %{ &quot;UL&quot; %}
 2787   interface(COND_INTER) %{
 2788     equal(0x0);
 2789     not_equal(0x1);
 2790     less(0x8);
 2791     greater_equal(0x9);
 2792     less_equal(0x2);
 2793     greater(0x3);
 2794     overflow(0x0); // unsupported/unimplemented
 2795     no_overflow(0x0); // unsupported/unimplemented
 2796   %}
 2797 %}
 2798 
 2799 
 2800 //----------OPERAND CLASSES----------------------------------------------------
 2801 // Operand Classes are groups of operands that are used to simplify
 2802 // instruction definitions by not requiring the AD writer to specify separate
 2803 // instructions for every form of operand when the instruction accepts
 2804 // multiple operand types with the same basic encoding and format.  The classic
 2805 // case of this is memory operands.
 2806 
 2807 opclass memoryI ( indirect, indOffset12, indIndex, indIndexScale );
 2808 opclass memoryP ( indirect, indOffset12, indIndex, indIndexScale );
 2809 opclass memoryF ( indirect, indOffsetFP );
 2810 opclass memoryF2 ( indirect, indOffsetFPx2 );
 2811 opclass memoryD ( indirect, indOffsetFP );
 2812 opclass memoryfp( indirect, indOffsetFP );
 2813 opclass memoryB ( indirect, indIndex, indOffsetHD );
 2814 opclass memoryS ( indirect, indIndex, indOffsetHD );
 2815 opclass memoryL ( indirect, indIndex, indOffsetHD );
 2816 
 2817 opclass memoryScaledI(indIndexScale);
 2818 opclass memoryScaledP(indIndexScale);
 2819 
 2820 // when ldrex/strex is used:
 2821 opclass memoryex ( indirect );
 2822 opclass indIndexMemory( indIndex );
 2823 opclass memorylong ( indirect, indOffset12x2 );
 2824 opclass memoryvld ( indirect /* , write back mode not implemented */ );
 2825 
 2826 //----------PIPELINE-----------------------------------------------------------
 2827 pipeline %{
 2828 
 2829 //----------ATTRIBUTES---------------------------------------------------------
 2830 attributes %{
 2831   fixed_size_instructions;           // Fixed size instructions
 2832   max_instructions_per_bundle = 4;   // Up to 4 instructions per bundle
 2833   instruction_unit_size = 4;         // An instruction is 4 bytes long
 2834   instruction_fetch_unit_size = 16;  // The processor fetches one line
 2835   instruction_fetch_units = 1;       // of 16 bytes
 2836 
 2837   // List of nop instructions
 2838   nops( Nop_A0, Nop_A1, Nop_MS, Nop_FA, Nop_BR );
 2839 %}
 2840 
 2841 //----------RESOURCES----------------------------------------------------------
 2842 // Resources are the functional units available to the machine
 2843 resources(A0, A1, MS, BR, FA, FM, IDIV, FDIV, IALU = A0 | A1);
 2844 
 2845 //----------PIPELINE DESCRIPTION-----------------------------------------------
 2846 // Pipeline Description specifies the stages in the machine&#39;s pipeline
 2847 
 2848 pipe_desc(A, P, F, B, I, J, S, R, E, C, M, W, X, T, D);
 2849 
 2850 //----------PIPELINE CLASSES---------------------------------------------------
 2851 // Pipeline Classes describe the stages in which input and output are
 2852 // referenced by the hardware pipeline.
 2853 
 2854 // Integer ALU reg-reg operation
 2855 pipe_class ialu_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 2856     single_instruction;
 2857     dst   : E(write);
 2858     src1  : R(read);
 2859     src2  : R(read);
 2860     IALU  : R;
 2861 %}
 2862 
 2863 // Integer ALU reg-reg long operation
 2864 pipe_class ialu_reg_reg_2(iRegL dst, iRegL src1, iRegL src2) %{
 2865     instruction_count(2);
 2866     dst   : E(write);
 2867     src1  : R(read);
 2868     src2  : R(read);
 2869     IALU  : R;
 2870     IALU  : R;
 2871 %}
 2872 
 2873 // Integer ALU reg-reg long dependent operation
 2874 pipe_class ialu_reg_reg_2_dep(iRegL dst, iRegL src1, iRegL src2, flagsReg cr) %{
 2875     instruction_count(1); multiple_bundles;
 2876     dst   : E(write);
 2877     src1  : R(read);
 2878     src2  : R(read);
 2879     cr    : E(write);
 2880     IALU  : R(2);
 2881 %}
 2882 
 2883 // Integer ALU reg-imm operaion
 2884 pipe_class ialu_reg_imm(iRegI dst, iRegI src1) %{
 2885     single_instruction;
 2886     dst   : E(write);
 2887     src1  : R(read);
 2888     IALU  : R;
 2889 %}
 2890 
 2891 // Integer ALU reg-reg operation with condition code
 2892 pipe_class ialu_cc_reg_reg(iRegI dst, iRegI src1, iRegI src2, flagsReg cr) %{
 2893     single_instruction;
 2894     dst   : E(write);
 2895     cr    : E(write);
 2896     src1  : R(read);
 2897     src2  : R(read);
 2898     IALU  : R;
 2899 %}
 2900 
 2901 // Integer ALU zero-reg operation
 2902 pipe_class ialu_zero_reg(iRegI dst, immI0 zero, iRegI src2) %{
 2903     single_instruction;
 2904     dst   : E(write);
 2905     src2  : R(read);
 2906     IALU  : R;
 2907 %}
 2908 
 2909 // Integer ALU zero-reg operation with condition code only
 2910 pipe_class ialu_cconly_zero_reg(flagsReg cr, iRegI src) %{
 2911     single_instruction;
 2912     cr    : E(write);
 2913     src   : R(read);
 2914     IALU  : R;
 2915 %}
 2916 
 2917 // Integer ALU reg-reg operation with condition code only
 2918 pipe_class ialu_cconly_reg_reg(flagsReg cr, iRegI src1, iRegI src2) %{
 2919     single_instruction;
 2920     cr    : E(write);
 2921     src1  : R(read);
 2922     src2  : R(read);
 2923     IALU  : R;
 2924 %}
 2925 
 2926 // Integer ALU reg-imm operation with condition code only
 2927 pipe_class ialu_cconly_reg_imm(flagsReg cr, iRegI src1) %{
 2928     single_instruction;
 2929     cr    : E(write);
 2930     src1  : R(read);
 2931     IALU  : R;
 2932 %}
 2933 
 2934 // Integer ALU reg-reg-zero operation with condition code only
 2935 pipe_class ialu_cconly_reg_reg_zero(flagsReg cr, iRegI src1, iRegI src2, immI0 zero) %{
 2936     single_instruction;
 2937     cr    : E(write);
 2938     src1  : R(read);
 2939     src2  : R(read);
 2940     IALU  : R;
 2941 %}
 2942 
 2943 // Integer ALU reg-imm-zero operation with condition code only
 2944 pipe_class ialu_cconly_reg_imm_zero(flagsReg cr, iRegI src1, immI0 zero) %{
 2945     single_instruction;
 2946     cr    : E(write);
 2947     src1  : R(read);
 2948     IALU  : R;
 2949 %}
 2950 
 2951 // Integer ALU reg-reg operation with condition code, src1 modified
 2952 pipe_class ialu_cc_rwreg_reg(flagsReg cr, iRegI src1, iRegI src2) %{
 2953     single_instruction;
 2954     cr    : E(write);
 2955     src1  : E(write);
 2956     src1  : R(read);
 2957     src2  : R(read);
 2958     IALU  : R;
 2959 %}
 2960 
 2961 pipe_class cmpL_reg(iRegI dst, iRegL src1, iRegL src2, flagsReg cr ) %{
 2962     multiple_bundles;
 2963     dst   : E(write)+4;
 2964     cr    : E(write);
 2965     src1  : R(read);
 2966     src2  : R(read);
 2967     IALU  : R(3);
 2968     BR    : R(2);
 2969 %}
 2970 
 2971 // Integer ALU operation
 2972 pipe_class ialu_none(iRegI dst) %{
 2973     single_instruction;
 2974     dst   : E(write);
 2975     IALU  : R;
 2976 %}
 2977 
 2978 // Integer ALU reg operation
 2979 pipe_class ialu_reg(iRegI dst, iRegI src) %{
 2980     single_instruction; may_have_no_code;
 2981     dst   : E(write);
 2982     src   : R(read);
 2983     IALU  : R;
 2984 %}
 2985 
 2986 // Integer ALU reg conditional operation
 2987 // This instruction has a 1 cycle stall, and cannot execute
 2988 // in the same cycle as the instruction setting the condition
 2989 // code. We kludge this by pretending to read the condition code
 2990 // 1 cycle earlier, and by marking the functional units as busy
 2991 // for 2 cycles with the result available 1 cycle later than
 2992 // is really the case.
 2993 pipe_class ialu_reg_flags( iRegI op2_out, iRegI op2_in, iRegI op1, flagsReg cr ) %{
 2994     single_instruction;
 2995     op2_out : C(write);
 2996     op1     : R(read);
 2997     cr      : R(read);       // This is really E, with a 1 cycle stall
 2998     BR      : R(2);
 2999     MS      : R(2);
 3000 %}
 3001 
 3002 // Integer ALU reg operation
 3003 pipe_class ialu_move_reg_L_to_I(iRegI dst, iRegL src) %{
 3004     single_instruction; may_have_no_code;
 3005     dst   : E(write);
 3006     src   : R(read);
 3007     IALU  : R;
 3008 %}
 3009 pipe_class ialu_move_reg_I_to_L(iRegL dst, iRegI src) %{
 3010     single_instruction; may_have_no_code;
 3011     dst   : E(write);
 3012     src   : R(read);
 3013     IALU  : R;
 3014 %}
 3015 
 3016 // Two integer ALU reg operations
 3017 pipe_class ialu_reg_2(iRegL dst, iRegL src) %{
 3018     instruction_count(2);
 3019     dst   : E(write);
 3020     src   : R(read);
 3021     A0    : R;
 3022     A1    : R;
 3023 %}
 3024 
 3025 // Two integer ALU reg operations
 3026 pipe_class ialu_move_reg_L_to_L(iRegL dst, iRegL src) %{
 3027     instruction_count(2); may_have_no_code;
 3028     dst   : E(write);
 3029     src   : R(read);
 3030     A0    : R;
 3031     A1    : R;
 3032 %}
 3033 
 3034 // Integer ALU imm operation
 3035 pipe_class ialu_imm(iRegI dst) %{
 3036     single_instruction;
 3037     dst   : E(write);
 3038     IALU  : R;
 3039 %}
 3040 
 3041 pipe_class ialu_imm_n(iRegI dst) %{
 3042     single_instruction;
 3043     dst   : E(write);
 3044     IALU  : R;
 3045 %}
 3046 
 3047 // Integer ALU reg-reg with carry operation
 3048 pipe_class ialu_reg_reg_cy(iRegI dst, iRegI src1, iRegI src2, iRegI cy) %{
 3049     single_instruction;
 3050     dst   : E(write);
 3051     src1  : R(read);
 3052     src2  : R(read);
 3053     IALU  : R;
 3054 %}
 3055 
 3056 // Integer ALU cc operation
 3057 pipe_class ialu_cc(iRegI dst, flagsReg cc) %{
 3058     single_instruction;
 3059     dst   : E(write);
 3060     cc    : R(read);
 3061     IALU  : R;
 3062 %}
 3063 
 3064 // Integer ALU cc / second IALU operation
 3065 pipe_class ialu_reg_ialu( iRegI dst, iRegI src ) %{
 3066     instruction_count(1); multiple_bundles;
 3067     dst   : E(write)+1;
 3068     src   : R(read);
 3069     IALU  : R;
 3070 %}
 3071 
 3072 // Integer ALU cc / second IALU operation
 3073 pipe_class ialu_reg_reg_ialu( iRegI dst, iRegI p, iRegI q ) %{
 3074     instruction_count(1); multiple_bundles;
 3075     dst   : E(write)+1;
 3076     p     : R(read);
 3077     q     : R(read);
 3078     IALU  : R;
 3079 %}
 3080 
 3081 // Integer ALU hi-lo-reg operation
 3082 pipe_class ialu_hi_lo_reg(iRegI dst, immI src) %{
 3083     instruction_count(1); multiple_bundles;
 3084     dst   : E(write)+1;
 3085     IALU  : R(2);
 3086 %}
 3087 
 3088 // Long Constant
 3089 pipe_class loadConL( iRegL dst, immL src ) %{
 3090     instruction_count(2); multiple_bundles;
 3091     dst   : E(write)+1;
 3092     IALU  : R(2);
 3093     IALU  : R(2);
 3094 %}
 3095 
 3096 // Pointer Constant
 3097 pipe_class loadConP( iRegP dst, immP src ) %{
 3098     instruction_count(0); multiple_bundles;
 3099     fixed_latency(6);
 3100 %}
 3101 
 3102 // Polling Address
 3103 pipe_class loadConP_poll( iRegP dst, immP_poll src ) %{
 3104     dst   : E(write);
 3105     IALU  : R;
 3106 %}
 3107 
 3108 // Long Constant small
 3109 pipe_class loadConLlo( iRegL dst, immL src ) %{
 3110     instruction_count(2);
 3111     dst   : E(write);
 3112     IALU  : R;
 3113     IALU  : R;
 3114 %}
 3115 
 3116 // [PHH] This is wrong for 64-bit.  See LdImmF/D.
 3117 pipe_class loadConFD(regF dst, immF src, iRegP tmp) %{
 3118     instruction_count(1); multiple_bundles;
 3119     src   : R(read);
 3120     dst   : M(write)+1;
 3121     IALU  : R;
 3122     MS    : E;
 3123 %}
 3124 
 3125 // Integer ALU nop operation
 3126 pipe_class ialu_nop() %{
 3127     single_instruction;
 3128     IALU  : R;
 3129 %}
 3130 
 3131 // Integer ALU nop operation
 3132 pipe_class ialu_nop_A0() %{
 3133     single_instruction;
 3134     A0    : R;
 3135 %}
 3136 
 3137 // Integer ALU nop operation
 3138 pipe_class ialu_nop_A1() %{
 3139     single_instruction;
 3140     A1    : R;
 3141 %}
 3142 
 3143 // Integer Multiply reg-reg operation
 3144 pipe_class imul_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 3145     single_instruction;
 3146     dst   : E(write);
 3147     src1  : R(read);
 3148     src2  : R(read);
 3149     MS    : R(5);
 3150 %}
 3151 
 3152 pipe_class mulL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 3153     single_instruction;
 3154     dst   : E(write)+4;
 3155     src1  : R(read);
 3156     src2  : R(read);
 3157     MS    : R(6);
 3158 %}
 3159 
 3160 // Integer Divide reg-reg
 3161 pipe_class sdiv_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI temp, flagsReg cr) %{
 3162     instruction_count(1); multiple_bundles;
 3163     dst   : E(write);
 3164     temp  : E(write);
 3165     src1  : R(read);
 3166     src2  : R(read);
 3167     temp  : R(read);
 3168     MS    : R(38);
 3169 %}
 3170 
 3171 // Long Divide
 3172 pipe_class divL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 3173     dst  : E(write)+71;
 3174     src1 : R(read);
 3175     src2 : R(read)+1;
 3176     MS   : R(70);
 3177 %}
 3178 
 3179 // Floating Point Add Float
 3180 pipe_class faddF_reg_reg(regF dst, regF src1, regF src2) %{
 3181     single_instruction;
 3182     dst   : X(write);
 3183     src1  : E(read);
 3184     src2  : E(read);
 3185     FA    : R;
 3186 %}
 3187 
 3188 // Floating Point Add Double
 3189 pipe_class faddD_reg_reg(regD dst, regD src1, regD src2) %{
 3190     single_instruction;
 3191     dst   : X(write);
 3192     src1  : E(read);
 3193     src2  : E(read);
 3194     FA    : R;
 3195 %}
 3196 
 3197 // Floating Point Conditional Move based on integer flags
 3198 pipe_class int_conditional_float_move (cmpOp cmp, flagsReg cr, regF dst, regF src) %{
 3199     single_instruction;
 3200     dst   : X(write);
 3201     src   : E(read);
 3202     cr    : R(read);
 3203     FA    : R(2);
 3204     BR    : R(2);
 3205 %}
 3206 
 3207 // Floating Point Conditional Move based on integer flags
 3208 pipe_class int_conditional_double_move (cmpOp cmp, flagsReg cr, regD dst, regD src) %{
 3209     single_instruction;
 3210     dst   : X(write);
 3211     src   : E(read);
 3212     cr    : R(read);
 3213     FA    : R(2);
 3214     BR    : R(2);
 3215 %}
 3216 
 3217 // Floating Point Multiply Float
 3218 pipe_class fmulF_reg_reg(regF dst, regF src1, regF src2) %{
 3219     single_instruction;
 3220     dst   : X(write);
 3221     src1  : E(read);
 3222     src2  : E(read);
 3223     FM    : R;
 3224 %}
 3225 
 3226 // Floating Point Multiply Double
 3227 pipe_class fmulD_reg_reg(regD dst, regD src1, regD src2) %{
 3228     single_instruction;
 3229     dst   : X(write);
 3230     src1  : E(read);
 3231     src2  : E(read);
 3232     FM    : R;
 3233 %}
 3234 
 3235 // Floating Point Divide Float
 3236 pipe_class fdivF_reg_reg(regF dst, regF src1, regF src2) %{
 3237     single_instruction;
 3238     dst   : X(write);
 3239     src1  : E(read);
 3240     src2  : E(read);
 3241     FM    : R;
 3242     FDIV  : C(14);
 3243 %}
 3244 
 3245 // Floating Point Divide Double
 3246 pipe_class fdivD_reg_reg(regD dst, regD src1, regD src2) %{
 3247     single_instruction;
 3248     dst   : X(write);
 3249     src1  : E(read);
 3250     src2  : E(read);
 3251     FM    : R;
 3252     FDIV  : C(17);
 3253 %}
 3254 
 3255 // Floating Point Move/Negate/Abs Float
 3256 pipe_class faddF_reg(regF dst, regF src) %{
 3257     single_instruction;
 3258     dst   : W(write);
 3259     src   : E(read);
 3260     FA    : R(1);
 3261 %}
 3262 
 3263 // Floating Point Move/Negate/Abs Double
 3264 pipe_class faddD_reg(regD dst, regD src) %{
 3265     single_instruction;
 3266     dst   : W(write);
 3267     src   : E(read);
 3268     FA    : R;
 3269 %}
 3270 
 3271 // Floating Point Convert F-&gt;D
 3272 pipe_class fcvtF2D(regD dst, regF src) %{
 3273     single_instruction;
 3274     dst   : X(write);
 3275     src   : E(read);
 3276     FA    : R;
 3277 %}
 3278 
 3279 // Floating Point Convert I-&gt;D
 3280 pipe_class fcvtI2D(regD dst, regF src) %{
 3281     single_instruction;
 3282     dst   : X(write);
 3283     src   : E(read);
 3284     FA    : R;
 3285 %}
 3286 
 3287 // Floating Point Convert LHi-&gt;D
 3288 pipe_class fcvtLHi2D(regD dst, regD src) %{
 3289     single_instruction;
 3290     dst   : X(write);
 3291     src   : E(read);
 3292     FA    : R;
 3293 %}
 3294 
 3295 // Floating Point Convert L-&gt;D
 3296 pipe_class fcvtL2D(regD dst, iRegL src) %{
 3297     single_instruction;
 3298     dst   : X(write);
 3299     src   : E(read);
 3300     FA    : R;
 3301 %}
 3302 
 3303 // Floating Point Convert L-&gt;F
 3304 pipe_class fcvtL2F(regF dst, iRegL src) %{
 3305     single_instruction;
 3306     dst   : X(write);
 3307     src   : E(read);
 3308     FA    : R;
 3309 %}
 3310 
 3311 // Floating Point Convert D-&gt;F
 3312 pipe_class fcvtD2F(regD dst, regF src) %{
 3313     single_instruction;
 3314     dst   : X(write);
 3315     src   : E(read);
 3316     FA    : R;
 3317 %}
 3318 
 3319 // Floating Point Convert I-&gt;L
 3320 pipe_class fcvtI2L(regD dst, regF src) %{
 3321     single_instruction;
 3322     dst   : X(write);
 3323     src   : E(read);
 3324     FA    : R;
 3325 %}
 3326 
 3327 // Floating Point Convert D-&gt;F
 3328 pipe_class fcvtD2I(iRegI dst, regD src, flagsReg cr) %{
 3329     instruction_count(1); multiple_bundles;
 3330     dst   : X(write)+6;
 3331     src   : E(read);
 3332     FA    : R;
 3333 %}
 3334 
 3335 // Floating Point Convert D-&gt;L
 3336 pipe_class fcvtD2L(regD dst, regD src, flagsReg cr) %{
 3337     instruction_count(1); multiple_bundles;
 3338     dst   : X(write)+6;
 3339     src   : E(read);
 3340     FA    : R;
 3341 %}
 3342 
 3343 // Floating Point Convert F-&gt;I
 3344 pipe_class fcvtF2I(regF dst, regF src, flagsReg cr) %{
 3345     instruction_count(1); multiple_bundles;
 3346     dst   : X(write)+6;
 3347     src   : E(read);
 3348     FA    : R;
 3349 %}
 3350 
 3351 // Floating Point Convert F-&gt;L
 3352 pipe_class fcvtF2L(regD dst, regF src, flagsReg cr) %{
 3353     instruction_count(1); multiple_bundles;
 3354     dst   : X(write)+6;
 3355     src   : E(read);
 3356     FA    : R;
 3357 %}
 3358 
 3359 // Floating Point Convert I-&gt;F
 3360 pipe_class fcvtI2F(regF dst, regF src) %{
 3361     single_instruction;
 3362     dst   : X(write);
 3363     src   : E(read);
 3364     FA    : R;
 3365 %}
 3366 
 3367 // Floating Point Compare
 3368 pipe_class faddF_fcc_reg_reg_zero(flagsRegF cr, regF src1, regF src2, immI0 zero) %{
 3369     single_instruction;
 3370     cr    : X(write);
 3371     src1  : E(read);
 3372     src2  : E(read);
 3373     FA    : R;
 3374 %}
 3375 
 3376 // Floating Point Compare
 3377 pipe_class faddD_fcc_reg_reg_zero(flagsRegF cr, regD src1, regD src2, immI0 zero) %{
 3378     single_instruction;
 3379     cr    : X(write);
 3380     src1  : E(read);
 3381     src2  : E(read);
 3382     FA    : R;
 3383 %}
 3384 
 3385 // Floating Add Nop
 3386 pipe_class fadd_nop() %{
 3387     single_instruction;
 3388     FA  : R;
 3389 %}
 3390 
 3391 // Integer Store to Memory
 3392 pipe_class istore_mem_reg(memoryI mem, iRegI src) %{
 3393     single_instruction;
 3394     mem   : R(read);
 3395     src   : C(read);
 3396     MS    : R;
 3397 %}
 3398 
 3399 // Integer Store to Memory
 3400 pipe_class istore_mem_spORreg(memoryI mem, sp_ptr_RegP src) %{
 3401     single_instruction;
 3402     mem   : R(read);
 3403     src   : C(read);
 3404     MS    : R;
 3405 %}
 3406 
 3407 // Float Store
 3408 pipe_class fstoreF_mem_reg(memoryF mem, RegF src) %{
 3409     single_instruction;
 3410     mem : R(read);
 3411     src : C(read);
 3412     MS  : R;
 3413 %}
 3414 
 3415 // Float Store
 3416 pipe_class fstoreF_mem_zero(memoryF mem, immF0 src) %{
 3417     single_instruction;
 3418     mem : R(read);
 3419     MS  : R;
 3420 %}
 3421 
 3422 // Double Store
 3423 pipe_class fstoreD_mem_reg(memoryD mem, RegD src) %{
 3424     instruction_count(1);
 3425     mem : R(read);
 3426     src : C(read);
 3427     MS  : R;
 3428 %}
 3429 
 3430 // Double Store
 3431 pipe_class fstoreD_mem_zero(memoryD mem, immD0 src) %{
 3432     single_instruction;
 3433     mem : R(read);
 3434     MS  : R;
 3435 %}
 3436 
 3437 // Integer Load (when sign bit propagation not needed)
 3438 pipe_class iload_mem(iRegI dst, memoryI mem) %{
 3439     single_instruction;
 3440     mem : R(read);
 3441     dst : C(write);
 3442     MS  : R;
 3443 %}
 3444 
 3445 // Integer Load (when sign bit propagation or masking is needed)
 3446 pipe_class iload_mask_mem(iRegI dst, memoryI mem) %{
 3447     single_instruction;
 3448     mem : R(read);
 3449     dst : M(write);
 3450     MS  : R;
 3451 %}
 3452 
 3453 // Float Load
 3454 pipe_class floadF_mem(regF dst, memoryF mem) %{
 3455     single_instruction;
 3456     mem : R(read);
 3457     dst : M(write);
 3458     MS  : R;
 3459 %}
 3460 
 3461 // Float Load
 3462 pipe_class floadD_mem(regD dst, memoryD mem) %{
 3463     instruction_count(1); multiple_bundles; // Again, unaligned argument is only multiple case
 3464     mem : R(read);
 3465     dst : M(write);
 3466     MS  : R;
 3467 %}
 3468 
 3469 // Memory Nop
 3470 pipe_class mem_nop() %{
 3471     single_instruction;
 3472     MS  : R;
 3473 %}
 3474 
 3475 pipe_class sethi(iRegP dst, immI src) %{
 3476     single_instruction;
 3477     dst  : E(write);
 3478     IALU : R;
 3479 %}
 3480 
 3481 pipe_class loadPollP(iRegP poll) %{
 3482     single_instruction;
 3483     poll : R(read);
 3484     MS   : R;
 3485 %}
 3486 
 3487 pipe_class br(Universe br, label labl) %{
 3488     single_instruction_with_delay_slot;
 3489     BR  : R;
 3490 %}
 3491 
 3492 pipe_class br_cc(Universe br, cmpOp cmp, flagsReg cr, label labl) %{
 3493     single_instruction_with_delay_slot;
 3494     cr    : E(read);
 3495     BR    : R;
 3496 %}
 3497 
 3498 pipe_class br_reg(Universe br, cmpOp cmp, iRegI op1, label labl) %{
 3499     single_instruction_with_delay_slot;
 3500     op1 : E(read);
 3501     BR  : R;
 3502     MS  : R;
 3503 %}
 3504 
 3505 pipe_class br_nop() %{
 3506     single_instruction;
 3507     BR  : R;
 3508 %}
 3509 
 3510 pipe_class simple_call(method meth) %{
 3511     instruction_count(2); multiple_bundles; force_serialization;
 3512     fixed_latency(100);
 3513     BR  : R(1);
 3514     MS  : R(1);
 3515     A0  : R(1);
 3516 %}
 3517 
 3518 pipe_class compiled_call(method meth) %{
 3519     instruction_count(1); multiple_bundles; force_serialization;
 3520     fixed_latency(100);
 3521     MS  : R(1);
 3522 %}
 3523 
 3524 pipe_class call(method meth) %{
 3525     instruction_count(0); multiple_bundles; force_serialization;
 3526     fixed_latency(100);
 3527 %}
 3528 
 3529 pipe_class tail_call(Universe ignore, label labl) %{
 3530     single_instruction; has_delay_slot;
 3531     fixed_latency(100);
 3532     BR  : R(1);
 3533     MS  : R(1);
 3534 %}
 3535 
 3536 pipe_class ret(Universe ignore) %{
 3537     single_instruction; has_delay_slot;
 3538     BR  : R(1);
 3539     MS  : R(1);
 3540 %}
 3541 
 3542 // The real do-nothing guy
 3543 pipe_class empty( ) %{
 3544     instruction_count(0);
 3545 %}
 3546 
 3547 pipe_class long_memory_op() %{
 3548     instruction_count(0); multiple_bundles; force_serialization;
 3549     fixed_latency(25);
 3550     MS  : R(1);
 3551 %}
 3552 
 3553 // Check-cast
 3554 pipe_class partial_subtype_check_pipe(Universe ignore, iRegP array, iRegP match ) %{
 3555     array : R(read);
 3556     match  : R(read);
 3557     IALU   : R(2);
 3558     BR     : R(2);
 3559     MS     : R;
 3560 %}
 3561 
 3562 // Convert FPU flags into +1,0,-1
 3563 pipe_class floating_cmp( iRegI dst, regF src1, regF src2 ) %{
 3564     src1  : E(read);
 3565     src2  : E(read);
 3566     dst   : E(write);
 3567     FA    : R;
 3568     MS    : R(2);
 3569     BR    : R(2);
 3570 %}
 3571 
 3572 // Compare for p &lt; q, and conditionally add y
 3573 pipe_class cadd_cmpltmask( iRegI p, iRegI q, iRegI y ) %{
 3574     p     : E(read);
 3575     q     : E(read);
 3576     y     : E(read);
 3577     IALU  : R(3)
 3578 %}
 3579 
 3580 // Perform a compare, then move conditionally in a branch delay slot.
 3581 pipe_class min_max( iRegI src2, iRegI srcdst ) %{
 3582     src2   : E(read);
 3583     srcdst : E(read);
 3584     IALU   : R;
 3585     BR     : R;
 3586 %}
 3587 
 3588 // Define the class for the Nop node
 3589 define %{
 3590    MachNop = ialu_nop;
 3591 %}
 3592 
 3593 %}
 3594 
 3595 //----------INSTRUCTIONS-------------------------------------------------------
 3596 
 3597 //------------Special Nop instructions for bundling - no match rules-----------
 3598 // Nop using the A0 functional unit
 3599 instruct Nop_A0() %{
 3600   ins_pipe(ialu_nop_A0);
 3601 %}
 3602 
 3603 // Nop using the A1 functional unit
 3604 instruct Nop_A1( ) %{
 3605   ins_pipe(ialu_nop_A1);
 3606 %}
 3607 
 3608 // Nop using the memory functional unit
 3609 instruct Nop_MS( ) %{
 3610   ins_pipe(mem_nop);
 3611 %}
 3612 
 3613 // Nop using the floating add functional unit
 3614 instruct Nop_FA( ) %{
 3615   ins_pipe(fadd_nop);
 3616 %}
 3617 
 3618 // Nop using the branch functional unit
 3619 instruct Nop_BR( ) %{
 3620   ins_pipe(br_nop);
 3621 %}
 3622 
 3623 //----------Load/Store/Move Instructions---------------------------------------
 3624 //----------Load Instructions--------------------------------------------------
 3625 // Load Byte (8bit signed)
 3626 instruct loadB(iRegI dst, memoryB mem) %{
 3627   match(Set dst (LoadB mem));
 3628   ins_cost(MEMORY_REF_COST);
 3629 
 3630   size(4);
 3631   format %{ &quot;LDRSB   $dst,$mem\t! byte -&gt; int&quot; %}
 3632   ins_encode %{
 3633     __ ldrsb($dst$$Register, $mem$$Address);
 3634   %}
 3635   ins_pipe(iload_mask_mem);
 3636 %}
 3637 
 3638 // Load Byte (8bit signed) into a Long Register
 3639 instruct loadB2L(iRegL dst, memoryB mem) %{
 3640   match(Set dst (ConvI2L (LoadB mem)));
 3641   ins_cost(MEMORY_REF_COST);
 3642 
 3643   size(8);
 3644   format %{ &quot;LDRSB $dst.lo,$mem\t! byte -&gt; long\n\t&quot;
 3645             &quot;ASR   $dst.hi,$dst.lo,31&quot; %}
 3646   ins_encode %{
 3647     __ ldrsb($dst$$Register, $mem$$Address);
 3648     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3649   %}
 3650   ins_pipe(iload_mask_mem);
 3651 %}
 3652 
 3653 // Load Unsigned Byte (8bit UNsigned) into an int reg
 3654 instruct loadUB(iRegI dst, memoryB mem) %{
 3655   match(Set dst (LoadUB mem));
 3656   ins_cost(MEMORY_REF_COST);
 3657 
 3658   size(4);
 3659   format %{ &quot;LDRB   $dst,$mem\t! ubyte -&gt; int&quot; %}
 3660   ins_encode %{
 3661     __ ldrb($dst$$Register, $mem$$Address);
 3662   %}
 3663   ins_pipe(iload_mem);
 3664 %}
 3665 
 3666 // Load Unsigned Byte (8bit UNsigned) into a Long Register
 3667 instruct loadUB2L(iRegL dst, memoryB mem) %{
 3668   match(Set dst (ConvI2L (LoadUB mem)));
 3669   ins_cost(MEMORY_REF_COST);
 3670 
 3671   size(8);
 3672   format %{ &quot;LDRB  $dst.lo,$mem\t! ubyte -&gt; long\n\t&quot;
 3673             &quot;MOV   $dst.hi,0&quot; %}
 3674   ins_encode %{
 3675     __ ldrb($dst$$Register, $mem$$Address);
 3676     __ mov($dst$$Register-&gt;successor(), 0);
 3677   %}
 3678   ins_pipe(iload_mem);
 3679 %}
 3680 
 3681 // Load Unsigned Byte (8 bit UNsigned) with immediate mask into Long Register
 3682 instruct loadUB2L_limmI(iRegL dst, memoryB mem, limmIlow8 mask) %{
 3683   match(Set dst (ConvI2L (AndI (LoadUB mem) mask)));
 3684 
 3685   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3686   size(12);
 3687   format %{ &quot;LDRB  $dst.lo,$mem\t! ubyte -&gt; long\n\t&quot;
 3688             &quot;MOV   $dst.hi,0\n\t&quot;
 3689             &quot;AND  $dst.lo,$dst.lo,$mask&quot; %}
 3690   ins_encode %{
 3691     __ ldrb($dst$$Register, $mem$$Address);
 3692     __ mov($dst$$Register-&gt;successor(), 0);
 3693     __ andr($dst$$Register, $dst$$Register, limmI_low($mask$$constant, 8));
 3694   %}
 3695   ins_pipe(iload_mem);
 3696 %}
 3697 
 3698 // Load Short (16bit signed)
 3699 
 3700 instruct loadS(iRegI dst, memoryS mem) %{
 3701   match(Set dst (LoadS mem));
 3702   ins_cost(MEMORY_REF_COST);
 3703 
 3704   size(4);
 3705   format %{ &quot;LDRSH   $dst,$mem\t! short&quot; %}
 3706   ins_encode %{
 3707     __ ldrsh($dst$$Register, $mem$$Address);
 3708   %}
 3709   ins_pipe(iload_mask_mem);
 3710 %}
 3711 
 3712 // Load Short (16 bit signed) to Byte (8 bit signed)
 3713 instruct loadS2B(iRegI dst, memoryS mem, immI_24 twentyfour) %{
 3714   match(Set dst (RShiftI (LShiftI (LoadS mem) twentyfour) twentyfour));
 3715   ins_cost(MEMORY_REF_COST);
 3716 
 3717   size(4);
 3718 
 3719   format %{ &quot;LDRSB   $dst,$mem\t! short -&gt; byte&quot; %}
 3720   ins_encode %{
 3721     __ ldrsb($dst$$Register, $mem$$Address);
 3722   %}
 3723   ins_pipe(iload_mask_mem);
 3724 %}
 3725 
 3726 // Load Short (16bit signed) into a Long Register
 3727 instruct loadS2L(iRegL dst, memoryS mem) %{
 3728   match(Set dst (ConvI2L (LoadS mem)));
 3729   ins_cost(MEMORY_REF_COST);
 3730 
 3731   size(8);
 3732   format %{ &quot;LDRSH $dst.lo,$mem\t! short -&gt; long\n\t&quot;
 3733             &quot;ASR   $dst.hi,$dst.lo,31&quot; %}
 3734   ins_encode %{
 3735     __ ldrsh($dst$$Register, $mem$$Address);
 3736     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3737   %}
 3738   ins_pipe(iload_mask_mem);
 3739 %}
 3740 
 3741 // Load Unsigned Short/Char (16bit UNsigned)
 3742 
 3743 
 3744 instruct loadUS(iRegI dst, memoryS mem) %{
 3745   match(Set dst (LoadUS mem));
 3746   ins_cost(MEMORY_REF_COST);
 3747 
 3748   size(4);
 3749   format %{ &quot;LDRH   $dst,$mem\t! ushort/char&quot; %}
 3750   ins_encode %{
 3751     __ ldrh($dst$$Register, $mem$$Address);
 3752   %}
 3753   ins_pipe(iload_mem);
 3754 %}
 3755 
 3756 // Load Unsigned Short/Char (16 bit UNsigned) to Byte (8 bit signed)
 3757 instruct loadUS2B(iRegI dst, memoryB mem, immI_24 twentyfour) %{
 3758   match(Set dst (RShiftI (LShiftI (LoadUS mem) twentyfour) twentyfour));
 3759   ins_cost(MEMORY_REF_COST);
 3760 
 3761   size(4);
 3762   format %{ &quot;LDRSB   $dst,$mem\t! ushort -&gt; byte&quot; %}
 3763   ins_encode %{
 3764     __ ldrsb($dst$$Register, $mem$$Address);
 3765   %}
 3766   ins_pipe(iload_mask_mem);
 3767 %}
 3768 
 3769 // Load Unsigned Short/Char (16bit UNsigned) into a Long Register
 3770 instruct loadUS2L(iRegL dst, memoryS mem) %{
 3771   match(Set dst (ConvI2L (LoadUS mem)));
 3772   ins_cost(MEMORY_REF_COST);
 3773 
 3774   size(8);
 3775   format %{ &quot;LDRH  $dst.lo,$mem\t! short -&gt; long\n\t&quot;
 3776             &quot;MOV   $dst.hi, 0&quot; %}
 3777   ins_encode %{
 3778     __ ldrh($dst$$Register, $mem$$Address);
 3779     __ mov($dst$$Register-&gt;successor(), 0);
 3780   %}
 3781   ins_pipe(iload_mem);
 3782 %}
 3783 
 3784 // Load Unsigned Short/Char (16bit UNsigned) with mask 0xFF into a Long Register
 3785 instruct loadUS2L_immI_255(iRegL dst, memoryB mem, immI_255 mask) %{
 3786   match(Set dst (ConvI2L (AndI (LoadUS mem) mask)));
 3787   ins_cost(MEMORY_REF_COST);
 3788 
 3789   size(8);
 3790   format %{ &quot;LDRB  $dst.lo,$mem\t! \n\t&quot;
 3791             &quot;MOV   $dst.hi, 0&quot; %}
 3792   ins_encode %{
 3793     __ ldrb($dst$$Register, $mem$$Address);
 3794     __ mov($dst$$Register-&gt;successor(), 0);
 3795   %}
 3796   ins_pipe(iload_mem);
 3797 %}
 3798 
 3799 // Load Unsigned Short/Char (16bit UNsigned) with a immediate mask into a Long Register
 3800 instruct loadUS2L_limmI(iRegL dst, memoryS mem, limmI mask) %{
 3801   match(Set dst (ConvI2L (AndI (LoadUS mem) mask)));
 3802   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3803 
 3804   size(12);
 3805   format %{ &quot;LDRH   $dst,$mem\t! ushort/char &amp; mask -&gt; long\n\t&quot;
 3806             &quot;MOV    $dst.hi, 0\n\t&quot;
 3807             &quot;AND    $dst,$dst,$mask&quot; %}
 3808   ins_encode %{
 3809     __ ldrh($dst$$Register, $mem$$Address);
 3810     __ mov($dst$$Register-&gt;successor(), 0);
 3811     __ andr($dst$$Register, $dst$$Register, $mask$$constant);
 3812   %}
 3813   ins_pipe(iload_mem);
 3814 %}
 3815 
 3816 // Load Integer
 3817 
 3818 
 3819 instruct loadI(iRegI dst, memoryI mem) %{
 3820   match(Set dst (LoadI mem));
 3821   ins_cost(MEMORY_REF_COST);
 3822 
 3823   size(4);
 3824   format %{ &quot;ldr_s32 $dst,$mem\t! int&quot; %}
 3825   ins_encode %{
 3826     __ ldr_s32($dst$$Register, $mem$$Address);
 3827   %}
 3828   ins_pipe(iload_mem);
 3829 %}
 3830 
 3831 // Load Integer to Byte (8 bit signed)
 3832 instruct loadI2B(iRegI dst, memoryS mem, immI_24 twentyfour) %{
 3833   match(Set dst (RShiftI (LShiftI (LoadI mem) twentyfour) twentyfour));
 3834   ins_cost(MEMORY_REF_COST);
 3835 
 3836   size(4);
 3837 
 3838   format %{ &quot;LDRSB   $dst,$mem\t! int -&gt; byte&quot; %}
 3839   ins_encode %{
 3840     __ ldrsb($dst$$Register, $mem$$Address);
 3841   %}
 3842   ins_pipe(iload_mask_mem);
 3843 %}
 3844 
 3845 // Load Integer to Unsigned Byte (8 bit UNsigned)
 3846 instruct loadI2UB(iRegI dst, memoryB mem, immI_255 mask) %{
 3847   match(Set dst (AndI (LoadI mem) mask));
 3848   ins_cost(MEMORY_REF_COST);
 3849 
 3850   size(4);
 3851 
 3852   format %{ &quot;LDRB   $dst,$mem\t! int -&gt; ubyte&quot; %}
 3853   ins_encode %{
 3854     __ ldrb($dst$$Register, $mem$$Address);
 3855   %}
 3856   ins_pipe(iload_mask_mem);
 3857 %}
 3858 
 3859 // Load Integer to Short (16 bit signed)
 3860 instruct loadI2S(iRegI dst, memoryS mem, immI_16 sixteen) %{
 3861   match(Set dst (RShiftI (LShiftI (LoadI mem) sixteen) sixteen));
 3862   ins_cost(MEMORY_REF_COST);
 3863 
 3864   size(4);
 3865   format %{ &quot;LDRSH   $dst,$mem\t! int -&gt; short&quot; %}
 3866   ins_encode %{
 3867     __ ldrsh($dst$$Register, $mem$$Address);
 3868   %}
 3869   ins_pipe(iload_mask_mem);
 3870 %}
 3871 
 3872 // Load Integer to Unsigned Short (16 bit UNsigned)
 3873 instruct loadI2US(iRegI dst, memoryS mem, immI_65535 mask) %{
 3874   match(Set dst (AndI (LoadI mem) mask));
 3875   ins_cost(MEMORY_REF_COST);
 3876 
 3877   size(4);
 3878   format %{ &quot;LDRH   $dst,$mem\t! int -&gt; ushort/char&quot; %}
 3879   ins_encode %{
 3880     __ ldrh($dst$$Register, $mem$$Address);
 3881   %}
 3882   ins_pipe(iload_mask_mem);
 3883 %}
 3884 
 3885 // Load Integer into a Long Register
 3886 instruct loadI2L(iRegL dst, memoryI mem) %{
 3887   match(Set dst (ConvI2L (LoadI mem)));
 3888   ins_cost(MEMORY_REF_COST);
 3889 
 3890   size(8);
 3891   format %{ &quot;LDR   $dst.lo,$mem\t! int -&gt; long\n\t&quot;
 3892             &quot;ASR   $dst.hi,$dst.lo,31\t! int-&gt;long&quot; %}
 3893   ins_encode %{
 3894     __ ldr($dst$$Register, $mem$$Address);
 3895     __ mov($dst$$Register-&gt;successor(), AsmOperand($dst$$Register, asr, 31));
 3896   %}
 3897   ins_pipe(iload_mask_mem);
 3898 %}
 3899 
 3900 // Load Integer with mask 0xFF into a Long Register
 3901 instruct loadI2L_immI_255(iRegL dst, memoryB mem, immI_255 mask) %{
 3902   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3903   ins_cost(MEMORY_REF_COST);
 3904 
 3905   size(8);
 3906   format %{ &quot;LDRB   $dst.lo,$mem\t! int &amp; 0xFF -&gt; long\n\t&quot;
 3907             &quot;MOV    $dst.hi, 0&quot; %}
 3908   ins_encode %{
 3909     __ ldrb($dst$$Register, $mem$$Address);
 3910     __ mov($dst$$Register-&gt;successor(), 0);
 3911   %}
 3912   ins_pipe(iload_mem);
 3913 %}
 3914 
 3915 // Load Integer with mask 0xFFFF into a Long Register
 3916 instruct loadI2L_immI_65535(iRegL dst, memoryS mem, immI_65535 mask) %{
 3917   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3918   ins_cost(MEMORY_REF_COST);
 3919 
 3920   size(8);
 3921   format %{ &quot;LDRH   $dst,$mem\t! int &amp; 0xFFFF -&gt; long\n\t&quot;
 3922             &quot;MOV    $dst.hi, 0&quot; %}
 3923   ins_encode %{
 3924     __ ldrh($dst$$Register, $mem$$Address);
 3925     __ mov($dst$$Register-&gt;successor(), 0);
 3926   %}
 3927   ins_pipe(iload_mask_mem);
 3928 %}
 3929 
 3930 // Load Integer with a 31-bit immediate mask into a Long Register
 3931 instruct loadI2L_limmU31(iRegL dst, memoryI mem, limmU31 mask) %{
 3932   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3933   ins_cost(MEMORY_REF_COST + 2*DEFAULT_COST);
 3934 
 3935   size(12);
 3936   format %{ &quot;LDR   $dst.lo,$mem\t! int -&gt; long\n\t&quot;
 3937             &quot;MOV    $dst.hi, 0\n\t&quot;
 3938             &quot;AND   $dst,$dst,$mask&quot; %}
 3939 
 3940   ins_encode %{
 3941     __ ldr($dst$$Register, $mem$$Address);
 3942     __ mov($dst$$Register-&gt;successor(), 0);
 3943     __ andr($dst$$Register, $dst$$Register, $mask$$constant);
 3944   %}
 3945   ins_pipe(iload_mem);
 3946 %}
 3947 
 3948 // Load Integer with a 31-bit mask into a Long Register
 3949 // FIXME: use iRegI mask, remove tmp?
 3950 instruct loadI2L_immU31(iRegL dst, memoryI mem, immU31 mask, iRegI tmp) %{
 3951   match(Set dst (ConvI2L (AndI (LoadI mem) mask)));
 3952   effect(TEMP dst, TEMP tmp);
 3953 
 3954   ins_cost(MEMORY_REF_COST + 4*DEFAULT_COST);
 3955   size(20);
 3956   format %{ &quot;LDR      $mem,$dst\t! int &amp; 31-bit mask -&gt; long\n\t&quot;
 3957             &quot;MOV      $dst.hi, 0\n\t&quot;
 3958             &quot;MOV_SLOW $tmp,$mask\n\t&quot;
 3959             &quot;AND      $dst,$tmp,$dst&quot; %}
 3960   ins_encode %{
 3961     __ ldr($dst$$Register, $mem$$Address);
 3962     __ mov($dst$$Register-&gt;successor(), 0);
 3963     __ mov_slow($tmp$$Register, $mask$$constant);
 3964     __ andr($dst$$Register, $dst$$Register, $tmp$$Register);
 3965   %}
 3966   ins_pipe(iload_mem);
 3967 %}
 3968 
 3969 // Load Unsigned Integer into a Long Register
 3970 instruct loadUI2L(iRegL dst, memoryI mem, immL_32bits mask) %{
 3971   match(Set dst (AndL (ConvI2L (LoadI mem)) mask));
 3972   ins_cost(MEMORY_REF_COST);
 3973 
 3974   size(8);
 3975   format %{ &quot;LDR   $dst.lo,$mem\t! uint -&gt; long\n\t&quot;
 3976             &quot;MOV   $dst.hi,0&quot; %}
 3977   ins_encode %{
 3978     __ ldr($dst$$Register, $mem$$Address);
 3979     __ mov($dst$$Register-&gt;successor(), 0);
 3980   %}
 3981   ins_pipe(iload_mem);
 3982 %}
 3983 
 3984 // Load Long
 3985 
 3986 
 3987 instruct loadL(iRegLd dst, memoryL mem ) %{
 3988   predicate(!((LoadLNode*)n)-&gt;require_atomic_access());
 3989   match(Set dst (LoadL mem));
 3990   effect(TEMP dst);
 3991   ins_cost(MEMORY_REF_COST);
 3992 
 3993   size(4);
 3994   format %{ &quot;ldr_64  $dst,$mem\t! long&quot; %}
 3995   ins_encode %{
 3996     __ ldr_64($dst$$Register, $mem$$Address);
 3997   %}
 3998   ins_pipe(iload_mem);
 3999 %}
 4000 
 4001 instruct loadL_2instr(iRegL dst, memorylong mem ) %{
 4002   predicate(!((LoadLNode*)n)-&gt;require_atomic_access());
 4003   match(Set dst (LoadL mem));
 4004   ins_cost(MEMORY_REF_COST + DEFAULT_COST);
 4005 
 4006   size(8);
 4007   format %{ &quot;LDR    $dst.lo,$mem \t! long order of instrs reversed if $dst.lo == base($mem)\n\t&quot;
 4008             &quot;LDR    $dst.hi,$mem+4 or $mem&quot; %}
 4009   ins_encode %{
 4010     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4011     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4012 
 4013     if ($dst$$Register == reg_to_register_object($mem$$base)) {
 4014       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4015       __ ldr($dst$$Register, Amemlo);
 4016     } else {
 4017       __ ldr($dst$$Register, Amemlo);
 4018       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4019     }
 4020   %}
 4021   ins_pipe(iload_mem);
 4022 %}
 4023 
 4024 instruct loadL_volatile(iRegL dst, indirect mem ) %{
 4025   predicate(((LoadLNode*)n)-&gt;require_atomic_access());
 4026   match(Set dst (LoadL mem));
 4027   ins_cost(MEMORY_REF_COST);
 4028 
 4029   size(4);
 4030   format %{ &quot;LDMIA    $dst,$mem\t! long&quot; %}
 4031   ins_encode %{
 4032     // FIXME: why is ldmia considered atomic?  Should be ldrexd
 4033     RegisterSet set($dst$$Register);
 4034     set = set | reg_to_register_object($dst$$reg + 1);
 4035     __ ldmia(reg_to_register_object($mem$$base), set);
 4036   %}
 4037   ins_pipe(iload_mem);
 4038 %}
 4039 
 4040 instruct loadL_volatile_fp(iRegL dst, memoryD mem ) %{
 4041   predicate(((LoadLNode*)n)-&gt;require_atomic_access());
 4042   match(Set dst (LoadL mem));
 4043   ins_cost(MEMORY_REF_COST);
 4044 
 4045   size(8);
 4046   format %{ &quot;FLDD      S14, $mem&quot;
 4047             &quot;FMRRD    $dst, S14\t! long \n&#39;t&quot; %}
 4048   ins_encode %{
 4049     __ fldd(S14, $mem$$Address);
 4050     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), S14);
 4051   %}
 4052   ins_pipe(iload_mem);
 4053 %}
 4054 
 4055 instruct loadL_unaligned(iRegL dst, memorylong mem ) %{
 4056   match(Set dst (LoadL_unaligned mem));
 4057   ins_cost(MEMORY_REF_COST);
 4058 
 4059   size(8);
 4060   format %{ &quot;LDR    $dst.lo,$mem\t! long order of instrs reversed if $dst.lo == base($mem)\n\t&quot;
 4061             &quot;LDR    $dst.hi,$mem+4&quot; %}
 4062   ins_encode %{
 4063     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4064     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4065 
 4066     if ($dst$$Register == reg_to_register_object($mem$$base)) {
 4067       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4068       __ ldr($dst$$Register, Amemlo);
 4069     } else {
 4070       __ ldr($dst$$Register, Amemlo);
 4071       __ ldr($dst$$Register-&gt;successor(), Amemhi);
 4072     }
 4073   %}
 4074   ins_pipe(iload_mem);
 4075 %}
 4076 
 4077 // Load Range
 4078 instruct loadRange(iRegI dst, memoryI mem) %{
 4079   match(Set dst (LoadRange mem));
 4080   ins_cost(MEMORY_REF_COST);
 4081 
 4082   size(4);
 4083   format %{ &quot;LDR_u32 $dst,$mem\t! range&quot; %}
 4084   ins_encode %{
 4085     __ ldr_u32($dst$$Register, $mem$$Address);
 4086   %}
 4087   ins_pipe(iload_mem);
 4088 %}
 4089 
 4090 // Load Pointer
 4091 
 4092 
 4093 instruct loadP(iRegP dst, memoryP mem) %{
 4094   match(Set dst (LoadP mem));
 4095   ins_cost(MEMORY_REF_COST);
 4096   size(4);
 4097 
 4098   format %{ &quot;LDR   $dst,$mem\t! ptr&quot; %}
 4099   ins_encode %{
 4100     __ ldr($dst$$Register, $mem$$Address);
 4101   %}
 4102   ins_pipe(iload_mem);
 4103 %}
 4104 
 4105 #ifdef XXX
 4106 // FIXME XXXX
 4107 //instruct loadSP(iRegP dst, memoryP mem) %{
 4108 instruct loadSP(SPRegP dst, memoryP mem, iRegP tmp) %{
 4109   match(Set dst (LoadP mem));
 4110   effect(TEMP tmp);
 4111   ins_cost(MEMORY_REF_COST+1);
 4112   size(8);
 4113 
 4114   format %{ &quot;LDR   $tmp,$mem\t! ptr\n\t&quot;
 4115             &quot;MOV   $dst,$tmp\t! ptr&quot; %}
 4116   ins_encode %{
 4117     __ ldr($tmp$$Register, $mem$$Address);
 4118     __ mov($dst$$Register, $tmp$$Register);
 4119   %}
 4120   ins_pipe(iload_mem);
 4121 %}
 4122 #endif
 4123 
 4124 #ifdef _LP64
 4125 // Load Compressed Pointer
 4126 
 4127 // XXX This variant shouldn&#39;t be necessary if 6217251 is implemented
 4128 instruct loadNoff(iRegN dst, memoryScaledI mem, aimmX off, iRegP tmp) %{
 4129   match(Set dst (LoadN (AddP mem off)));
 4130   ins_cost(MEMORY_REF_COST + DEFAULT_COST); // assume shift/sign-extend is free
 4131   effect(TEMP tmp);
 4132   size(4 * 2);
 4133 
 4134   format %{ &quot;ldr_u32 $dst,$mem+$off\t! compressed ptr temp=$tmp&quot; %}
 4135   ins_encode %{
 4136     Register base = reg_to_register_object($mem$$base);
 4137     __ add($tmp$$Register, base, $off$$constant);
 4138     Address nmem = Address::make_raw($tmp$$reg, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4139     __ ldr_u32($dst$$Register, nmem);
 4140   %}
 4141   ins_pipe(iload_mem);
 4142 %}
 4143 
 4144 instruct loadN(iRegN dst, memoryI mem) %{
 4145   match(Set dst (LoadN mem));
 4146   ins_cost(MEMORY_REF_COST);
 4147   size(4);
 4148 
 4149   format %{ &quot;ldr_u32 $dst,$mem\t! compressed ptr&quot; %}
 4150   ins_encode %{
 4151     __ ldr_u32($dst$$Register, $mem$$Address);
 4152   %}
 4153   ins_pipe(iload_mem);
 4154 %}
 4155 #endif
 4156 
 4157 // Load Klass Pointer
 4158 instruct loadKlass(iRegP dst, memoryI mem) %{
 4159   match(Set dst (LoadKlass mem));
 4160   ins_cost(MEMORY_REF_COST);
 4161   size(4);
 4162 
 4163   format %{ &quot;LDR   $dst,$mem\t! klass ptr&quot; %}
 4164   ins_encode %{
 4165     __ ldr($dst$$Register, $mem$$Address);
 4166   %}
 4167   ins_pipe(iload_mem);
 4168 %}
 4169 
 4170 #ifdef _LP64
 4171 // Load narrow Klass Pointer
 4172 instruct loadNKlass(iRegN dst, memoryI mem) %{
 4173   match(Set dst (LoadNKlass mem));
 4174   ins_cost(MEMORY_REF_COST);
 4175   size(4);
 4176 
 4177   format %{ &quot;ldr_u32 $dst,$mem\t! compressed klass ptr&quot; %}
 4178   ins_encode %{
 4179     __ ldr_u32($dst$$Register, $mem$$Address);
 4180   %}
 4181   ins_pipe(iload_mem);
 4182 %}
 4183 #endif
 4184 
 4185 
 4186 instruct loadD(regD dst, memoryD mem) %{
 4187   match(Set dst (LoadD mem));
 4188   ins_cost(MEMORY_REF_COST);
 4189 
 4190   size(4);
 4191   // FIXME: needs to be atomic, but  ARMv7 A.R.M. guarantees
 4192   // only LDREXD and STREXD are 64-bit single-copy atomic
 4193   format %{ &quot;FLDD   $dst,$mem&quot; %}
 4194   ins_encode %{
 4195     __ ldr_double($dst$$FloatRegister, $mem$$Address);
 4196   %}
 4197   ins_pipe(floadD_mem);
 4198 %}
 4199 
 4200 // Load Double - UNaligned
 4201 instruct loadD_unaligned(regD_low dst, memoryF2 mem ) %{
 4202   match(Set dst (LoadD_unaligned mem));
 4203   ins_cost(MEMORY_REF_COST*2+DEFAULT_COST);
 4204   size(8);
 4205   format %{ &quot;FLDS    $dst.lo,$mem\t! misaligned double\n&quot;
 4206           &quot;\tFLDS    $dst.hi,$mem+4\t!&quot; %}
 4207   ins_encode %{
 4208     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4209     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4210       __ flds($dst$$FloatRegister, Amemlo);
 4211       __ flds($dst$$FloatRegister-&gt;successor(), Amemhi);
 4212   %}
 4213   ins_pipe(iload_mem);
 4214 %}
 4215 
 4216 
 4217 instruct loadF(regF dst, memoryF mem) %{
 4218   match(Set dst (LoadF mem));
 4219 
 4220   ins_cost(MEMORY_REF_COST);
 4221   size(4);
 4222   format %{ &quot;FLDS    $dst,$mem&quot; %}
 4223   ins_encode %{
 4224     __ ldr_float($dst$$FloatRegister, $mem$$Address);
 4225   %}
 4226   ins_pipe(floadF_mem);
 4227 %}
 4228 
 4229 
 4230 // // Load Constant
 4231 instruct loadConI( iRegI dst, immI src ) %{
 4232   match(Set dst src);
 4233   ins_cost(DEFAULT_COST * 3/2);
 4234   format %{ &quot;MOV_SLOW    $dst, $src&quot; %}
 4235   ins_encode %{
 4236     __ mov_slow($dst$$Register, $src$$constant);
 4237   %}
 4238   ins_pipe(ialu_hi_lo_reg);
 4239 %}
 4240 
 4241 instruct loadConIMov( iRegI dst, immIMov src ) %{
 4242   match(Set dst src);
 4243   size(4);
 4244   format %{ &quot;MOV    $dst, $src&quot; %}
 4245   ins_encode %{
 4246     __ mov($dst$$Register, $src$$constant);
 4247   %}
 4248   ins_pipe(ialu_imm);
 4249 %}
 4250 
 4251 instruct loadConIMovn( iRegI dst, immIRotn src ) %{
 4252   match(Set dst src);
 4253   size(4);
 4254   format %{ &quot;MVN    $dst, ~$src&quot; %}
 4255   ins_encode %{
 4256     __ mvn($dst$$Register, ~$src$$constant);
 4257   %}
 4258   ins_pipe(ialu_imm_n);
 4259 %}
 4260 
 4261 instruct loadConI16( iRegI dst, immI16 src ) %{
 4262   match(Set dst src);
 4263   size(4);
 4264   format %{ &quot;MOVW    $dst, $src&quot; %}
 4265   ins_encode %{
 4266     __ movw($dst$$Register, $src$$constant);
 4267   %}
 4268   ins_pipe(ialu_imm_n);
 4269 %}
 4270 
 4271 instruct loadConP(iRegP dst, immP src) %{
 4272   match(Set dst src);
 4273   ins_cost(DEFAULT_COST * 3/2);
 4274   format %{ &quot;MOV_SLOW    $dst,$src\t!ptr&quot; %}
 4275   ins_encode %{
 4276     relocInfo::relocType constant_reloc = _opnds[1]-&gt;constant_reloc();
 4277     intptr_t val = $src$$constant;
 4278     if (constant_reloc == relocInfo::oop_type) {
 4279       __ mov_oop($dst$$Register, (jobject)val);
 4280     } else if (constant_reloc == relocInfo::metadata_type) {
 4281       __ mov_metadata($dst$$Register, (Metadata*)val);
 4282     } else {
 4283       __ mov_slow($dst$$Register, val);
 4284     }
 4285   %}
 4286   ins_pipe(loadConP);
 4287 %}
 4288 
 4289 
 4290 instruct loadConP_poll(iRegP dst, immP_poll src) %{
 4291   match(Set dst src);
 4292   ins_cost(DEFAULT_COST);
 4293   format %{ &quot;MOV_SLOW    $dst,$src\t!ptr&quot; %}
 4294   ins_encode %{
 4295       __ mov_slow($dst$$Register, $src$$constant);
 4296   %}
 4297   ins_pipe(loadConP_poll);
 4298 %}
 4299 
 4300 instruct loadConL(iRegL dst, immL src) %{
 4301   match(Set dst src);
 4302   ins_cost(DEFAULT_COST * 4);
 4303   format %{ &quot;MOV_SLOW   $dst.lo, $src &amp; 0x0FFFFFFFFL \t! long\n\t&quot;
 4304             &quot;MOV_SLOW   $dst.hi, $src &gt;&gt; 32&quot; %}
 4305   ins_encode %{
 4306     __ mov_slow(reg_to_register_object($dst$$reg), $src$$constant &amp; 0x0FFFFFFFFL);
 4307     __ mov_slow(reg_to_register_object($dst$$reg + 1), ((julong)($src$$constant)) &gt;&gt; 32);
 4308   %}
 4309   ins_pipe(loadConL);
 4310 %}
 4311 
 4312 instruct loadConL16( iRegL dst, immL16 src ) %{
 4313   match(Set dst src);
 4314   ins_cost(DEFAULT_COST * 2);
 4315 
 4316   size(8);
 4317   format %{ &quot;MOVW    $dst.lo, $src \n\t&quot;
 4318             &quot;MOVW    $dst.hi, 0 \n\t&quot; %}
 4319   ins_encode %{
 4320     __ movw($dst$$Register, $src$$constant);
 4321     __ movw($dst$$Register-&gt;successor(), 0);
 4322   %}
 4323   ins_pipe(ialu_imm);
 4324 %}
 4325 
 4326 instruct loadConF_imm8(regF dst, imm8F src) %{
 4327   match(Set dst src);
 4328   ins_cost(DEFAULT_COST);
 4329   size(4);
 4330 
 4331   format %{ &quot;FCONSTS      $dst, $src&quot;%}
 4332 
 4333   ins_encode %{
 4334     __ fconsts($dst$$FloatRegister, Assembler::float_num($src$$constant).imm8());
 4335   %}
 4336   ins_pipe(loadConFD); // FIXME
 4337 %}
 4338 
 4339 
 4340 instruct loadConF(regF dst, immF src, iRegI tmp) %{
 4341   match(Set dst src);
 4342   ins_cost(DEFAULT_COST * 2);
 4343   effect(TEMP tmp);
 4344   size(3*4);
 4345 
 4346   format %{ &quot;MOV_SLOW  $tmp, $src\n\t&quot;
 4347             &quot;FMSR      $dst, $tmp&quot;%}
 4348 
 4349   ins_encode %{
 4350     // FIXME revisit once 6961697 is in
 4351     union {
 4352       jfloat f;
 4353       int i;
 4354     } v;
 4355     v.f = $src$$constant;
 4356     __ mov_slow($tmp$$Register, v.i);
 4357     __ fmsr($dst$$FloatRegister, $tmp$$Register);
 4358   %}
 4359   ins_pipe(loadConFD); // FIXME
 4360 %}
 4361 
 4362 instruct loadConD_imm8(regD dst, imm8D src) %{
 4363   match(Set dst src);
 4364   ins_cost(DEFAULT_COST);
 4365   size(4);
 4366 
 4367   format %{ &quot;FCONSTD      $dst, $src&quot;%}
 4368 
 4369   ins_encode %{
 4370     __ fconstd($dst$$FloatRegister, Assembler::double_num($src$$constant).imm8());
 4371   %}
 4372   ins_pipe(loadConFD); // FIXME
 4373 %}
 4374 
 4375 instruct loadConD(regD dst, immD src, iRegP tmp) %{
 4376   match(Set dst src);
 4377   effect(TEMP tmp);
 4378   ins_cost(MEMORY_REF_COST);
 4379   format %{ &quot;FLDD  $dst, [$constanttablebase + $constantoffset]\t! load from constant table: double=$src&quot; %}
 4380 
 4381   ins_encode %{
 4382     Register r = $constanttablebase;
 4383     int offset  = $constantoffset($src);
 4384     if (!is_memoryD(offset)) {                // can&#39;t use a predicate
 4385                                               // in load constant instructs
 4386       __ add_slow($tmp$$Register, r, offset);
 4387       r = $tmp$$Register;
 4388       offset = 0;
 4389     }
 4390     __ ldr_double($dst$$FloatRegister, Address(r, offset));
 4391   %}
 4392   ins_pipe(loadConFD);
 4393 %}
 4394 
 4395 // Prefetch instructions.
 4396 // Must be safe to execute with invalid address (cannot fault).
 4397 
 4398 instruct prefetchAlloc_mp( memoryP mem ) %{
 4399   predicate(VM_Version::has_multiprocessing_extensions());
 4400   match( PrefetchAllocation mem );
 4401   ins_cost(MEMORY_REF_COST);
 4402   size(4);
 4403 
 4404   format %{ &quot;PLDW $mem\t! Prefetch allocation&quot; %}
 4405   ins_encode %{
 4406     __ pldw($mem$$Address);
 4407   %}
 4408   ins_pipe(iload_mem);
 4409 %}
 4410 
 4411 instruct prefetchAlloc_sp( memoryP mem ) %{
 4412   predicate(!VM_Version::has_multiprocessing_extensions());
 4413   match( PrefetchAllocation mem );
 4414   ins_cost(MEMORY_REF_COST);
 4415   size(4);
 4416 
 4417   format %{ &quot;PLD $mem\t! Prefetch allocation&quot; %}
 4418   ins_encode %{
 4419     __ pld($mem$$Address);
 4420   %}
 4421   ins_pipe(iload_mem);
 4422 %}
 4423 
 4424 
 4425 //----------Store Instructions-------------------------------------------------
 4426 // Store Byte
 4427 instruct storeB(memoryB mem, store_RegI src) %{
 4428   match(Set mem (StoreB mem src));
 4429   ins_cost(MEMORY_REF_COST);
 4430 
 4431   size(4);
 4432   format %{ &quot;STRB    $src,$mem\t! byte&quot; %}
 4433   ins_encode %{
 4434     __ strb($src$$Register, $mem$$Address);
 4435   %}
 4436   ins_pipe(istore_mem_reg);
 4437 %}
 4438 
 4439 instruct storeCM(memoryB mem, store_RegI src) %{
 4440   match(Set mem (StoreCM mem src));
 4441   ins_cost(MEMORY_REF_COST);
 4442 
 4443   size(4);
 4444   format %{ &quot;STRB    $src,$mem\t! CMS card-mark byte&quot; %}
 4445   ins_encode %{
 4446     __ strb($src$$Register, $mem$$Address);
 4447   %}
 4448   ins_pipe(istore_mem_reg);
 4449 %}
 4450 
 4451 // Store Char/Short
 4452 
 4453 
 4454 instruct storeC(memoryS mem, store_RegI src) %{
 4455   match(Set mem (StoreC mem src));
 4456   ins_cost(MEMORY_REF_COST);
 4457 
 4458   size(4);
 4459   format %{ &quot;STRH    $src,$mem\t! short&quot; %}
 4460   ins_encode %{
 4461     __ strh($src$$Register, $mem$$Address);
 4462   %}
 4463   ins_pipe(istore_mem_reg);
 4464 %}
 4465 
 4466 // Store Integer
 4467 
 4468 
 4469 instruct storeI(memoryI mem, store_RegI src) %{
 4470   match(Set mem (StoreI mem src));
 4471   ins_cost(MEMORY_REF_COST);
 4472 
 4473   size(4);
 4474   format %{ &quot;str_32 $src,$mem&quot; %}
 4475   ins_encode %{
 4476     __ str_32($src$$Register, $mem$$Address);
 4477   %}
 4478   ins_pipe(istore_mem_reg);
 4479 %}
 4480 
 4481 // Store Long
 4482 
 4483 
 4484 instruct storeL(memoryL mem, store_RegLd src) %{
 4485   predicate(!((StoreLNode*)n)-&gt;require_atomic_access());
 4486   match(Set mem (StoreL mem src));
 4487   ins_cost(MEMORY_REF_COST);
 4488 
 4489   size(4);
 4490   format %{ &quot;str_64  $src,$mem\t! long\n\t&quot; %}
 4491 
 4492   ins_encode %{
 4493     __ str_64($src$$Register, $mem$$Address);
 4494   %}
 4495   ins_pipe(istore_mem_reg);
 4496 %}
 4497 
 4498 instruct storeL_2instr(memorylong mem, iRegL src) %{
 4499   predicate(!((StoreLNode*)n)-&gt;require_atomic_access());
 4500   match(Set mem (StoreL mem src));
 4501   ins_cost(MEMORY_REF_COST + DEFAULT_COST);
 4502 
 4503   size(8);
 4504   format %{ &quot;STR    $src.lo,$mem\t! long\n\t&quot;
 4505             &quot;STR    $src.hi,$mem+4&quot; %}
 4506 
 4507   ins_encode %{
 4508     Address Amemlo = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp, relocInfo::none);
 4509     Address Amemhi = Address::make_raw($mem$$base, $mem$$index, $mem$$scale, $mem$$disp + 4, relocInfo::none);
 4510     __ str($src$$Register, Amemlo);
 4511     __ str($src$$Register-&gt;successor(), Amemhi);
 4512   %}
 4513   ins_pipe(istore_mem_reg);
 4514 %}
 4515 
 4516 instruct storeL_volatile(indirect mem, iRegL src) %{
 4517   predicate(((StoreLNode*)n)-&gt;require_atomic_access());
 4518   match(Set mem (StoreL mem src));
 4519   ins_cost(MEMORY_REF_COST);
 4520   size(4);
 4521   format %{ &quot;STMIA    $src,$mem\t! long&quot; %}
 4522   ins_encode %{
 4523     // FIXME: why is stmia considered atomic?  Should be strexd
 4524     RegisterSet set($src$$Register);
 4525     set = set | reg_to_register_object($src$$reg + 1);
 4526     __ stmia(reg_to_register_object($mem$$base), set);
 4527   %}
 4528   ins_pipe(istore_mem_reg);
 4529 %}
 4530 
 4531 instruct storeL_volatile_fp(memoryD mem, iRegL src) %{
 4532   predicate(((StoreLNode*)n)-&gt;require_atomic_access());
 4533   match(Set mem (StoreL mem src));
 4534   ins_cost(MEMORY_REF_COST);
 4535   size(8);
 4536   format %{ &quot;FMDRR    S14, $src\t! long \n\t&quot;
 4537             &quot;FSTD     S14, $mem&quot; %}
 4538   ins_encode %{
 4539     __ fmdrr(S14, $src$$Register, $src$$Register-&gt;successor());
 4540     __ fstd(S14, $mem$$Address);
 4541   %}
 4542   ins_pipe(istore_mem_reg);
 4543 %}
 4544 
 4545 #ifdef XXX
 4546 // Move SP Pointer
 4547 //instruct movSP(sp_ptr_RegP dst, SPRegP src) %{
 4548 //instruct movSP(iRegP dst, SPRegP src) %{
 4549 instruct movSP(store_ptr_RegP dst, SPRegP src) %{
 4550   match(Set dst src);
 4551 //predicate(!_kids[1]-&gt;_leaf-&gt;is_Proj() || _kids[1]-&gt;_leaf-&gt;as_Proj()-&gt;_con == TypeFunc::FramePtr);
 4552   ins_cost(MEMORY_REF_COST);
 4553   size(4);
 4554 
 4555   format %{ &quot;MOV    $dst,$src\t! SP ptr\n\t&quot; %}
 4556   ins_encode %{
 4557     assert(false, &quot;XXX1 got here&quot;);
 4558     __ mov($dst$$Register, SP);
 4559     __ mov($dst$$Register, $src$$Register);
 4560   %}
 4561   ins_pipe(ialu_reg);
 4562 %}
 4563 #endif
 4564 
 4565 
 4566 // Store Pointer
 4567 
 4568 
 4569 instruct storeP(memoryP mem, store_ptr_RegP src) %{
 4570   match(Set mem (StoreP mem src));
 4571   ins_cost(MEMORY_REF_COST);
 4572   size(4);
 4573 
 4574   format %{ &quot;STR    $src,$mem\t! ptr&quot; %}
 4575   ins_encode %{
 4576     __ str($src$$Register, $mem$$Address);
 4577   %}
 4578   ins_pipe(istore_mem_spORreg);
 4579 %}
 4580 
 4581 
 4582 #ifdef _LP64
 4583 // Store Compressed Pointer
 4584 
 4585 
 4586 instruct storeN(memoryI mem, store_RegN src) %{
 4587   match(Set mem (StoreN mem src));
 4588   ins_cost(MEMORY_REF_COST);
 4589   size(4);
 4590 
 4591   format %{ &quot;str_32 $src,$mem\t! compressed ptr&quot; %}
 4592   ins_encode %{
 4593     __ str_32($src$$Register, $mem$$Address);
 4594   %}
 4595   ins_pipe(istore_mem_reg);
 4596 %}
 4597 
 4598 
 4599 // Store Compressed Klass Pointer
 4600 instruct storeNKlass(memoryI mem, store_RegN src) %{
 4601   match(Set mem (StoreNKlass mem src));
 4602   ins_cost(MEMORY_REF_COST);
 4603   size(4);
 4604 
 4605   format %{ &quot;str_32 $src,$mem\t! compressed klass ptr&quot; %}
 4606   ins_encode %{
 4607     __ str_32($src$$Register, $mem$$Address);
 4608   %}
 4609   ins_pipe(istore_mem_reg);
 4610 %}
 4611 #endif
 4612 
 4613 // Store Double
 4614 
 4615 
 4616 instruct storeD(memoryD mem, regD src) %{
 4617   match(Set mem (StoreD mem src));
 4618   ins_cost(MEMORY_REF_COST);
 4619 
 4620   size(4);
 4621   // FIXME: needs to be atomic, but  ARMv7 A.R.M. guarantees
 4622   // only LDREXD and STREXD are 64-bit single-copy atomic
 4623   format %{ &quot;FSTD   $src,$mem&quot; %}
 4624   ins_encode %{
 4625     __ str_double($src$$FloatRegister, $mem$$Address);
 4626   %}
 4627   ins_pipe(fstoreD_mem_reg);
 4628 %}
 4629 
 4630 
 4631 // Store Float
 4632 
 4633 
 4634 instruct storeF( memoryF mem, regF src) %{
 4635   match(Set mem (StoreF mem src));
 4636   ins_cost(MEMORY_REF_COST);
 4637 
 4638   size(4);
 4639   format %{ &quot;FSTS    $src,$mem&quot; %}
 4640   ins_encode %{
 4641     __ str_float($src$$FloatRegister, $mem$$Address);
 4642   %}
 4643   ins_pipe(fstoreF_mem_reg);
 4644 %}
 4645 
 4646 
 4647 //----------MemBar Instructions-----------------------------------------------
 4648 // Memory barrier flavors
 4649 
 4650 // pattern-match out unnecessary membars
 4651 instruct membar_storestore() %{
 4652   match(MemBarStoreStore);
 4653   ins_cost(4*MEMORY_REF_COST);
 4654 
 4655   size(4);
 4656   format %{ &quot;MEMBAR-storestore&quot; %}
 4657   ins_encode %{
 4658     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::StoreStore), noreg);
 4659   %}
 4660   ins_pipe(long_memory_op);
 4661 %}
 4662 
 4663 instruct membar_acquire() %{
 4664   match(MemBarAcquire);
 4665   match(LoadFence);
 4666   ins_cost(4*MEMORY_REF_COST);
 4667 
 4668   size(4);
 4669   format %{ &quot;MEMBAR-acquire&quot; %}
 4670   ins_encode %{
 4671     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::LoadLoad | MacroAssembler::LoadStore), noreg);
 4672   %}
 4673   ins_pipe(long_memory_op);
 4674 %}
 4675 
 4676 instruct membar_acquire_lock() %{
 4677   match(MemBarAcquireLock);
 4678   ins_cost(0);
 4679 
 4680   size(0);
 4681   format %{ &quot;!MEMBAR-acquire (CAS in prior FastLock so empty encoding)&quot; %}
 4682   ins_encode( );
 4683   ins_pipe(empty);
 4684 %}
 4685 
 4686 instruct membar_release() %{
 4687   match(MemBarRelease);
 4688   match(StoreFence);
 4689   ins_cost(4*MEMORY_REF_COST);
 4690 
 4691   size(4);
 4692   format %{ &quot;MEMBAR-release&quot; %}
 4693   ins_encode %{
 4694     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::StoreStore | MacroAssembler::LoadStore), noreg);
 4695   %}
 4696   ins_pipe(long_memory_op);
 4697 %}
 4698 
 4699 instruct membar_release_lock() %{
 4700   match(MemBarReleaseLock);
 4701   ins_cost(0);
 4702 
 4703   size(0);
 4704   format %{ &quot;!MEMBAR-release (CAS in succeeding FastUnlock so empty encoding)&quot; %}
 4705   ins_encode( );
 4706   ins_pipe(empty);
 4707 %}
 4708 
 4709 instruct membar_volatile() %{
 4710   match(MemBarVolatile);
 4711   ins_cost(4*MEMORY_REF_COST);
 4712 
 4713   size(4);
 4714   format %{ &quot;MEMBAR-volatile&quot; %}
 4715   ins_encode %{
 4716     __ membar(MacroAssembler::StoreLoad, noreg);
 4717   %}
 4718   ins_pipe(long_memory_op);
 4719 %}
 4720 
 4721 instruct unnecessary_membar_volatile() %{
 4722   match(MemBarVolatile);
 4723   predicate(Matcher::post_store_load_barrier(n));
 4724   ins_cost(0);
 4725 
 4726   size(0);
 4727   format %{ &quot;!MEMBAR-volatile (unnecessary so empty encoding)&quot; %}
 4728   ins_encode( );
 4729   ins_pipe(empty);
 4730 %}
 4731 
 4732 //----------Register Move Instructions-----------------------------------------
 4733 // instruct roundDouble_nop(regD dst) %{
 4734 //   match(Set dst (RoundDouble dst));
 4735 //   ins_pipe(empty);
 4736 // %}
 4737 
 4738 
 4739 // instruct roundFloat_nop(regF dst) %{
 4740 //   match(Set dst (RoundFloat dst));
 4741 //   ins_pipe(empty);
 4742 // %}
 4743 
 4744 
 4745 
 4746 // Cast Index to Pointer for unsafe natives
 4747 instruct castX2P(iRegX src, iRegP dst) %{
 4748   match(Set dst (CastX2P src));
 4749 
 4750   format %{ &quot;MOV    $dst,$src\t! IntX-&gt;Ptr if $dst != $src&quot; %}
 4751   ins_encode %{
 4752     if ($dst$$Register !=  $src$$Register) {
 4753       __ mov($dst$$Register, $src$$Register);
 4754     }
 4755   %}
 4756   ins_pipe(ialu_reg);
 4757 %}
 4758 
 4759 // Cast Pointer to Index for unsafe natives
 4760 instruct castP2X(iRegP src, iRegX dst) %{
 4761   match(Set dst (CastP2X src));
 4762 
 4763   format %{ &quot;MOV    $dst,$src\t! Ptr-&gt;IntX if $dst != $src&quot; %}
 4764   ins_encode %{
 4765     if ($dst$$Register !=  $src$$Register) {
 4766       __ mov($dst$$Register, $src$$Register);
 4767     }
 4768   %}
 4769   ins_pipe(ialu_reg);
 4770 %}
 4771 
 4772 //----------Conditional Move---------------------------------------------------
 4773 // Conditional move
 4774 instruct cmovIP_reg(cmpOpP cmp, flagsRegP pcc, iRegI dst, iRegI src) %{
 4775   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4776   ins_cost(150);
 4777   size(4);
 4778   format %{ &quot;MOV$cmp  $dst,$src\t! int&quot; %}
 4779   ins_encode %{
 4780     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4781   %}
 4782   ins_pipe(ialu_reg);
 4783 %}
 4784 
 4785 
 4786 instruct cmovIP_immMov(cmpOpP cmp, flagsRegP pcc, iRegI dst, immIMov src) %{
 4787   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4788   ins_cost(140);
 4789   size(4);
 4790   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4791   ins_encode %{
 4792     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4793   %}
 4794   ins_pipe(ialu_imm);
 4795 %}
 4796 
 4797 instruct cmovIP_imm16(cmpOpP cmp, flagsRegP pcc, iRegI dst, immI16 src) %{
 4798   match(Set dst (CMoveI (Binary cmp pcc) (Binary dst src)));
 4799   ins_cost(140);
 4800   size(4);
 4801   format %{ &quot;MOVw$cmp  $dst,$src&quot; %}
 4802   ins_encode %{
 4803     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4804   %}
 4805   ins_pipe(ialu_imm);
 4806 %}
 4807 
 4808 instruct cmovI_reg(cmpOp cmp, flagsReg icc, iRegI dst, iRegI src) %{
 4809   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4810   ins_cost(150);
 4811   size(4);
 4812   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4813   ins_encode %{
 4814     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4815   %}
 4816   ins_pipe(ialu_reg);
 4817 %}
 4818 
 4819 
 4820 instruct cmovI_immMov(cmpOp cmp, flagsReg icc, iRegI dst, immIMov src) %{
 4821   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4822   ins_cost(140);
 4823   size(4);
 4824   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4825   ins_encode %{
 4826     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4827   %}
 4828   ins_pipe(ialu_imm);
 4829 %}
 4830 
 4831 instruct cmovII_imm16(cmpOp cmp, flagsReg icc, iRegI dst, immI16 src) %{
 4832   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4833   ins_cost(140);
 4834   size(4);
 4835   format %{ &quot;MOVw$cmp  $dst,$src&quot; %}
 4836   ins_encode %{
 4837     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4838   %}
 4839   ins_pipe(ialu_imm);
 4840 %}
 4841 
 4842 instruct cmovII_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, iRegI src) %{
 4843   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4844   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4845             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4846             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4847             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4848   ins_cost(150);
 4849   size(4);
 4850   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4851   ins_encode %{
 4852     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4853   %}
 4854   ins_pipe(ialu_reg);
 4855 %}
 4856 
 4857 instruct cmovII_immMov_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, immIMov src) %{
 4858   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4859   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4860             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4861             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4862             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4863   ins_cost(140);
 4864   size(4);
 4865   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4866   ins_encode %{
 4867     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4868   %}
 4869   ins_pipe(ialu_imm);
 4870 %}
 4871 
 4872 instruct cmovII_imm16_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegI dst, immI16 src) %{
 4873   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4874   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4875             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4876             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4877             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4878   ins_cost(140);
 4879   size(4);
 4880   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 4881   ins_encode %{
 4882     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4883   %}
 4884   ins_pipe(ialu_imm);
 4885 %}
 4886 
 4887 instruct cmovIIu_reg(cmpOpU cmp, flagsRegU icc, iRegI dst, iRegI src) %{
 4888   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4889   ins_cost(150);
 4890   size(4);
 4891   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4892   ins_encode %{
 4893     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4894   %}
 4895   ins_pipe(ialu_reg);
 4896 %}
 4897 
 4898 instruct cmovIIu_immMov(cmpOpU cmp, flagsRegU icc, iRegI dst, immIMov src) %{
 4899   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4900   ins_cost(140);
 4901   size(4);
 4902   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4903   ins_encode %{
 4904     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4905   %}
 4906   ins_pipe(ialu_imm);
 4907 %}
 4908 
 4909 instruct cmovIIu_imm16(cmpOpU cmp, flagsRegU icc, iRegI dst, immI16 src) %{
 4910   match(Set dst (CMoveI (Binary cmp icc) (Binary dst src)));
 4911   ins_cost(140);
 4912   size(4);
 4913   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 4914   ins_encode %{
 4915     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4916   %}
 4917   ins_pipe(ialu_imm);
 4918 %}
 4919 
 4920 // Conditional move
 4921 instruct cmovPP_reg(cmpOpP cmp, flagsRegP pcc, iRegP dst, iRegP src) %{
 4922   match(Set dst (CMoveP (Binary cmp pcc) (Binary dst src)));
 4923   ins_cost(150);
 4924   size(4);
 4925   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4926   ins_encode %{
 4927     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4928   %}
 4929   ins_pipe(ialu_reg);
 4930 %}
 4931 
 4932 instruct cmovPP_imm(cmpOpP cmp, flagsRegP pcc, iRegP dst, immP0 src) %{
 4933   match(Set dst (CMoveP (Binary cmp pcc) (Binary dst src)));
 4934   ins_cost(140);
 4935   size(4);
 4936   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 4937   ins_encode %{
 4938     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4939   %}
 4940   ins_pipe(ialu_imm);
 4941 %}
 4942 
 4943 // This instruction also works with CmpN so we don&#39;t need cmovPN_reg.
 4944 instruct cmovPI_reg(cmpOp cmp, flagsReg icc, iRegP dst, iRegP src) %{
 4945   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4946   ins_cost(150);
 4947 
 4948   size(4);
 4949   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4950   ins_encode %{
 4951     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4952   %}
 4953   ins_pipe(ialu_reg);
 4954 %}
 4955 
 4956 instruct cmovPI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegP dst, iRegP src) %{
 4957   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4958   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4959             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 4960             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 4961             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 4962   ins_cost(150);
 4963 
 4964   size(4);
 4965   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4966   ins_encode %{
 4967     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4968   %}
 4969   ins_pipe(ialu_reg);
 4970 %}
 4971 
 4972 instruct cmovPIu_reg(cmpOpU cmp, flagsRegU icc, iRegP dst, iRegP src) %{
 4973   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4974   ins_cost(150);
 4975 
 4976   size(4);
 4977   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4978   ins_encode %{
 4979     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 4980   %}
 4981   ins_pipe(ialu_reg);
 4982 %}
 4983 
 4984 instruct cmovPI_imm(cmpOp cmp, flagsReg icc, iRegP dst, immP0 src) %{
 4985   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4986   ins_cost(140);
 4987 
 4988   size(4);
 4989   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 4990   ins_encode %{
 4991     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 4992   %}
 4993   ins_pipe(ialu_imm);
 4994 %}
 4995 
 4996 instruct cmovPI_imm_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegP dst, immP0 src) %{
 4997   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 4998   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 4999             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5000             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5001             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5002   ins_cost(140);
 5003 
 5004   size(4);
 5005   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 5006   ins_encode %{
 5007     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5008   %}
 5009   ins_pipe(ialu_imm);
 5010 %}
 5011 
 5012 instruct cmovPIu_imm(cmpOpU cmp, flagsRegU icc, iRegP dst, immP0 src) %{
 5013   match(Set dst (CMoveP (Binary cmp icc) (Binary dst src)));
 5014   ins_cost(140);
 5015 
 5016   size(4);
 5017   format %{ &quot;MOV$cmp  $dst,$src\t! ptr&quot; %}
 5018   ins_encode %{
 5019     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5020   %}
 5021   ins_pipe(ialu_imm);
 5022 %}
 5023 
 5024 
 5025 // Conditional move
 5026 instruct cmovFP_reg(cmpOpP cmp, flagsRegP pcc, regF dst, regF src) %{
 5027   match(Set dst (CMoveF (Binary cmp pcc) (Binary dst src)));
 5028   ins_cost(150);
 5029   size(4);
 5030   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5031   ins_encode %{
 5032     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5033   %}
 5034   ins_pipe(int_conditional_float_move);
 5035 %}
 5036 
 5037 instruct cmovFI_reg(cmpOp cmp, flagsReg icc, regF dst, regF src) %{
 5038   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5039   ins_cost(150);
 5040 
 5041   size(4);
 5042   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5043   ins_encode %{
 5044     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5045   %}
 5046   ins_pipe(int_conditional_float_move);
 5047 %}
 5048 
 5049 instruct cmovFI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, regF dst, regF src) %{
 5050   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5051   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5052             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5053             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5054             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5055   ins_cost(150);
 5056 
 5057   size(4);
 5058   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5059   ins_encode %{
 5060     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5061   %}
 5062   ins_pipe(int_conditional_float_move);
 5063 %}
 5064 
 5065 instruct cmovFIu_reg(cmpOpU cmp, flagsRegU icc, regF dst, regF src) %{
 5066   match(Set dst (CMoveF (Binary cmp icc) (Binary dst src)));
 5067   ins_cost(150);
 5068 
 5069   size(4);
 5070   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 5071   ins_encode %{
 5072     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5073   %}
 5074   ins_pipe(int_conditional_float_move);
 5075 %}
 5076 
 5077 // Conditional move
 5078 instruct cmovDP_reg(cmpOpP cmp, flagsRegP pcc, regD dst, regD src) %{
 5079   match(Set dst (CMoveD (Binary cmp pcc) (Binary dst src)));
 5080   ins_cost(150);
 5081   size(4);
 5082   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5083   ins_encode %{
 5084     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5085   %}
 5086   ins_pipe(int_conditional_double_move);
 5087 %}
 5088 
 5089 instruct cmovDI_reg(cmpOp cmp, flagsReg icc, regD dst, regD src) %{
 5090   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5091   ins_cost(150);
 5092 
 5093   size(4);
 5094   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5095   ins_encode %{
 5096     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5097   %}
 5098   ins_pipe(int_conditional_double_move);
 5099 %}
 5100 
 5101 instruct cmovDI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, regD dst, regD src) %{
 5102   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5103   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5104   ins_cost(150);
 5105 
 5106   size(4);
 5107   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5108   ins_encode %{
 5109     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5110   %}
 5111   ins_pipe(int_conditional_double_move);
 5112 %}
 5113 
 5114 instruct cmovDIu_reg(cmpOpU cmp, flagsRegU icc, regD dst, regD src) %{
 5115   match(Set dst (CMoveD (Binary cmp icc) (Binary dst src)));
 5116   ins_cost(150);
 5117 
 5118   size(4);
 5119   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 5120   ins_encode %{
 5121     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 5122   %}
 5123   ins_pipe(int_conditional_double_move);
 5124 %}
 5125 
 5126 // Conditional move
 5127 instruct cmovLP_reg(cmpOpP cmp, flagsRegP pcc, iRegL dst, iRegL src) %{
 5128   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5129   ins_cost(150);
 5130 
 5131   size(8);
 5132   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5133             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5134   ins_encode %{
 5135     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5136     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5137   %}
 5138   ins_pipe(ialu_reg);
 5139 %}
 5140 
 5141 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5142 // (hi($con$$constant), lo($con$$constant)) becomes
 5143 instruct cmovLP_immRot(cmpOpP cmp, flagsRegP pcc, iRegL dst, immLlowRot src) %{
 5144   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5145   ins_cost(140);
 5146 
 5147   size(8);
 5148   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5149             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5150   ins_encode %{
 5151     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5152     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5153   %}
 5154   ins_pipe(ialu_imm);
 5155 %}
 5156 
 5157 instruct cmovLP_imm16(cmpOpP cmp, flagsRegP pcc, iRegL dst, immL16 src) %{
 5158   match(Set dst (CMoveL (Binary cmp pcc) (Binary dst src)));
 5159   ins_cost(140);
 5160 
 5161   size(8);
 5162   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5163             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5164   ins_encode %{
 5165     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5166     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5167   %}
 5168   ins_pipe(ialu_imm);
 5169 %}
 5170 
 5171 instruct cmovLI_reg(cmpOp cmp, flagsReg icc, iRegL dst, iRegL src) %{
 5172   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5173   ins_cost(150);
 5174 
 5175   size(8);
 5176   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5177             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5178   ins_encode %{
 5179     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5180     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5181   %}
 5182   ins_pipe(ialu_reg);
 5183 %}
 5184 
 5185 instruct cmovLI_reg_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, iRegL src) %{
 5186   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5187   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5188             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5189             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5190             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5191   ins_cost(150);
 5192 
 5193   size(8);
 5194   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5195             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5196   ins_encode %{
 5197     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5198     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5199   %}
 5200   ins_pipe(ialu_reg);
 5201 %}
 5202 
 5203 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5204 // (hi($con$$constant), lo($con$$constant)) becomes
 5205 instruct cmovLI_immRot(cmpOp cmp, flagsReg icc, iRegL dst, immLlowRot src) %{
 5206   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5207   ins_cost(140);
 5208 
 5209   size(8);
 5210   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5211             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5212   ins_encode %{
 5213     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5214     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5215   %}
 5216   ins_pipe(ialu_imm);
 5217 %}
 5218 
 5219 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5220 // (hi($con$$constant), lo($con$$constant)) becomes
 5221 instruct cmovLI_immRot_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, immLlowRot src) %{
 5222   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5223   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5224             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5225             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5226             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5227   ins_cost(140);
 5228 
 5229   size(8);
 5230   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5231             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5232   ins_encode %{
 5233     __ mov($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5234     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5235   %}
 5236   ins_pipe(ialu_imm);
 5237 %}
 5238 
 5239 instruct cmovLI_imm16(cmpOp cmp, flagsReg icc, iRegL dst, immL16 src) %{
 5240   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5241   ins_cost(140);
 5242 
 5243   size(8);
 5244   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5245             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5246   ins_encode %{
 5247     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5248     __ movw($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5249   %}
 5250   ins_pipe(ialu_imm);
 5251 %}
 5252 
 5253 instruct cmovLI_imm16_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, iRegL dst, immL16 src) %{
 5254   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5255   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq ||
 5256             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne ||
 5257             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt ||
 5258             _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 5259   ins_cost(140);
 5260 
 5261   size(8);
 5262   format %{ &quot;MOV$cmp  $dst.lo,$src\t! long\n\t&quot;
 5263             &quot;MOV$cmp  $dst.hi,0&quot; %}
 5264   ins_encode %{
 5265     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 5266     __ movw($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 5267   %}
 5268   ins_pipe(ialu_imm);
 5269 %}
 5270 
 5271 instruct cmovLIu_reg(cmpOpU cmp, flagsRegU icc, iRegL dst, iRegL src) %{
 5272   match(Set dst (CMoveL (Binary cmp icc) (Binary dst src)));
 5273   ins_cost(150);
 5274 
 5275   size(8);
 5276   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 5277             &quot;MOV$cmp  $dst.hi,$src.hi&quot; %}
 5278   ins_encode %{
 5279     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 5280     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 5281   %}
 5282   ins_pipe(ialu_reg);
 5283 %}
 5284 
 5285 
 5286 //----------OS and Locking Instructions----------------------------------------
 5287 
 5288 // This name is KNOWN by the ADLC and cannot be changed.
 5289 // The ADLC forces a &#39;TypeRawPtr::BOTTOM&#39; output type
 5290 // for this guy.
 5291 instruct tlsLoadP(RthreadRegP dst) %{
 5292   match(Set dst (ThreadLocal));
 5293 
 5294   size(0);
 5295   ins_cost(0);
 5296   format %{ &quot;! TLS is in $dst&quot; %}
 5297   ins_encode( /*empty encoding*/ );
 5298   ins_pipe(ialu_none);
 5299 %}
 5300 
 5301 instruct checkCastPP( iRegP dst ) %{
 5302   match(Set dst (CheckCastPP dst));
 5303 
 5304   size(0);
 5305   format %{ &quot;! checkcastPP of $dst&quot; %}
 5306   ins_encode( /*empty encoding*/ );
 5307   ins_pipe(empty);
 5308 %}
 5309 
 5310 
 5311 instruct castPP( iRegP dst ) %{
 5312   match(Set dst (CastPP dst));
 5313   format %{ &quot;! castPP of $dst&quot; %}
 5314   ins_encode( /*empty encoding*/ );
 5315   ins_pipe(empty);
 5316 %}
 5317 
 5318 instruct castII( iRegI dst ) %{
 5319   match(Set dst (CastII dst));
 5320   format %{ &quot;! castII of $dst&quot; %}
 5321   ins_encode( /*empty encoding*/ );
 5322   ins_cost(0);
 5323   ins_pipe(empty);
 5324 %}
 5325 
 5326 instruct castLL( iRegL dst ) %{
 5327   match(Set dst (CastLL dst));
 5328   format %{ &quot;! castLL of $dst&quot; %}
 5329   ins_encode( /*empty encoding*/ );
 5330   ins_cost(0);
 5331   ins_pipe(empty);
 5332 %}
 5333 
 5334 //----------Arithmetic Instructions--------------------------------------------
 5335 // Addition Instructions
 5336 // Register Addition
 5337 instruct addI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 5338   match(Set dst (AddI src1 src2));
 5339 
 5340   size(4);
 5341   format %{ &quot;add_32 $dst,$src1,$src2\t! int&quot; %}
 5342   ins_encode %{
 5343     __ add_32($dst$$Register, $src1$$Register, $src2$$Register);
 5344   %}
 5345   ins_pipe(ialu_reg_reg);
 5346 %}
 5347 
 5348 instruct addshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5349   match(Set dst (AddI (LShiftI src1 src2) src3));
 5350 
 5351   size(4);
 5352   format %{ &quot;add_32 $dst,$src3,$src1&lt;&lt;$src2\t! int&quot; %}
 5353   ins_encode %{
 5354     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 5355   %}
 5356   ins_pipe(ialu_reg_reg);
 5357 %}
 5358 
 5359 
 5360 instruct addshlI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5361   match(Set dst (AddI (LShiftI src1 src2) src3));
 5362 
 5363   size(4);
 5364   format %{ &quot;add_32 $dst,$src3,$src1&lt;&lt;$src2\t! int&quot; %}
 5365   ins_encode %{
 5366     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 5367   %}
 5368   ins_pipe(ialu_reg_reg);
 5369 %}
 5370 
 5371 instruct addsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5372   match(Set dst (AddI (RShiftI src1 src2) src3));
 5373 
 5374   size(4);
 5375   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;$src2\t! int&quot; %}
 5376   ins_encode %{
 5377     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 5378   %}
 5379   ins_pipe(ialu_reg_reg);
 5380 %}
 5381 
 5382 instruct addsarI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5383   match(Set dst (AddI (RShiftI src1 src2) src3));
 5384 
 5385   size(4);
 5386   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;$src2\t! int&quot; %}
 5387   ins_encode %{
 5388     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 5389   %}
 5390   ins_pipe(ialu_reg_reg);
 5391 %}
 5392 
 5393 instruct addshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5394   match(Set dst (AddI (URShiftI src1 src2) src3));
 5395 
 5396   size(4);
 5397   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;&gt;$src2\t! int&quot; %}
 5398   ins_encode %{
 5399     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 5400   %}
 5401   ins_pipe(ialu_reg_reg);
 5402 %}
 5403 
 5404 instruct addshrI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 5405   match(Set dst (AddI (URShiftI src1 src2) src3));
 5406 
 5407   size(4);
 5408   format %{ &quot;add_32 $dst,$src3,$src1&gt;&gt;&gt;$src2\t! int&quot; %}
 5409   ins_encode %{
 5410     __ add_32($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 5411   %}
 5412   ins_pipe(ialu_reg_reg);
 5413 %}
 5414 
 5415 // Immediate Addition
 5416 instruct addI_reg_aimmI(iRegI dst, iRegI src1, aimmI src2) %{
 5417   match(Set dst (AddI src1 src2));
 5418 
 5419   size(4);
 5420   format %{ &quot;add_32 $dst,$src1,$src2\t! int&quot; %}
 5421   ins_encode %{
 5422     __ add_32($dst$$Register, $src1$$Register, $src2$$constant);
 5423   %}
 5424   ins_pipe(ialu_reg_imm);
 5425 %}
 5426 
 5427 // Pointer Register Addition
 5428 instruct addP_reg_reg(iRegP dst, iRegP src1, iRegX src2) %{
 5429   match(Set dst (AddP src1 src2));
 5430 
 5431   size(4);
 5432   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5433   ins_encode %{
 5434     __ add($dst$$Register, $src1$$Register, $src2$$Register);
 5435   %}
 5436   ins_pipe(ialu_reg_reg);
 5437 %}
 5438 
 5439 
 5440 // shifted iRegX operand
 5441 operand shiftedX(iRegX src2, shimmX src3) %{
 5442 //constraint(ALLOC_IN_RC(sp_ptr_reg));
 5443   match(LShiftX src2 src3);
 5444 
 5445   op_cost(1);
 5446   format %{ &quot;$src2 &lt;&lt; $src3&quot; %}
 5447   interface(MEMORY_INTER) %{
 5448     base($src2);
 5449     index(0xff);
 5450     scale($src3);
 5451     disp(0x0);
 5452   %}
 5453 %}
 5454 
 5455 instruct addshlP_reg_reg_imm(iRegP dst, iRegP src1, shiftedX src2) %{
 5456   match(Set dst (AddP src1 src2));
 5457 
 5458   ins_cost(DEFAULT_COST * 3/2);
 5459   size(4);
 5460   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5461   ins_encode %{
 5462     Register base = reg_to_register_object($src2$$base);
 5463     __ add($dst$$Register, $src1$$Register, AsmOperand(base, lsl, $src2$$scale));
 5464   %}
 5465   ins_pipe(ialu_reg_reg);
 5466 %}
 5467 
 5468 // Pointer Immediate Addition
 5469 instruct addP_reg_aimmX(iRegP dst, iRegP src1, aimmX src2) %{
 5470   match(Set dst (AddP src1 src2));
 5471 
 5472   size(4);
 5473   format %{ &quot;ADD    $dst,$src1,$src2\t! ptr&quot; %}
 5474   ins_encode %{
 5475     __ add($dst$$Register, $src1$$Register, $src2$$constant);
 5476   %}
 5477   ins_pipe(ialu_reg_imm);
 5478 %}
 5479 
 5480 // Long Addition
 5481 instruct addL_reg_reg(iRegL dst, iRegL src1, iRegL src2, flagsReg ccr) %{
 5482   match(Set dst (AddL src1 src2));
 5483   effect(KILL ccr);
 5484   size(8);
 5485   format %{ &quot;ADDS    $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 5486             &quot;ADC     $dst.hi,$src1.hi,$src2.hi&quot; %}
 5487   ins_encode %{
 5488     __ adds($dst$$Register, $src1$$Register, $src2$$Register);
 5489     __ adc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 5490   %}
 5491   ins_pipe(ialu_reg_reg);
 5492 %}
 5493 
 5494 // TODO
 5495 
 5496 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5497 // (hi($con$$constant), lo($con$$constant)) becomes
 5498 instruct addL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con, flagsReg ccr) %{
 5499   match(Set dst (AddL src1 con));
 5500   effect(KILL ccr);
 5501   size(8);
 5502   format %{ &quot;ADDS    $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 5503             &quot;ADC     $dst.hi,$src1.hi,0&quot; %}
 5504   ins_encode %{
 5505     __ adds($dst$$Register, $src1$$Register, $con$$constant);
 5506     __ adc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 5507   %}
 5508   ins_pipe(ialu_reg_imm);
 5509 %}
 5510 
 5511 //----------Conditional_store--------------------------------------------------
 5512 // Conditional-store of the updated heap-top.
 5513 // Used during allocation of the shared heap.
 5514 // Sets flags (EQ) on success.
 5515 
 5516 // LoadP-locked.
 5517 instruct loadPLocked(iRegP dst, memoryex mem) %{
 5518   match(Set dst (LoadPLocked mem));
 5519   size(4);
 5520   format %{ &quot;LDREX  $dst,$mem&quot; %}
 5521   ins_encode %{
 5522     __ ldrex($dst$$Register,$mem$$Address);
 5523   %}
 5524   ins_pipe(iload_mem);
 5525 %}
 5526 
 5527 instruct storePConditional( memoryex heap_top_ptr, iRegP oldval, iRegP newval, iRegI tmp, flagsRegP pcc ) %{
 5528   predicate(_kids[1]-&gt;_kids[0]-&gt;_leaf-&gt;Opcode() == Op_LoadPLocked); // only works in conjunction with a LoadPLocked node
 5529   match(Set pcc (StorePConditional heap_top_ptr (Binary oldval newval)));
 5530   effect( TEMP tmp );
 5531   size(8);
 5532   format %{ &quot;STREX  $tmp,$newval,$heap_top_ptr\n\t&quot;
 5533             &quot;CMP    $tmp, 0&quot; %}
 5534   ins_encode %{
 5535     __ strex($tmp$$Register, $newval$$Register, $heap_top_ptr$$Address);
 5536     __ cmp($tmp$$Register, 0);
 5537   %}
 5538   ins_pipe( long_memory_op );
 5539 %}
 5540 
 5541 // Conditional-store of an intx value.
 5542 instruct storeXConditional( memoryex mem, iRegX oldval, iRegX newval, iRegX tmp, flagsReg icc ) %{
 5543   match(Set icc (StoreIConditional mem (Binary oldval newval)));
 5544   effect( TEMP tmp );
 5545   size(28);
 5546   format %{ &quot;loop: \n\t&quot;
 5547             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem], DOESN&#39;T set $newval=[$mem] in any case\n\t&quot;
 5548             &quot;XORS     $tmp,$tmp, $oldval\n\t&quot;
 5549             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5550             &quot;CMP.eq   $tmp, 1 \n\t&quot;
 5551             &quot;B.eq     loop \n\t&quot;
 5552             &quot;TEQ      $tmp, 0\n\t&quot;
 5553             &quot;membar   LoadStore|LoadLoad&quot; %}
 5554   ins_encode %{
 5555     Label loop;
 5556     __ bind(loop);
 5557     __ ldrex($tmp$$Register, $mem$$Address);
 5558     __ eors($tmp$$Register, $tmp$$Register, $oldval$$Register);
 5559     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5560     __ cmp($tmp$$Register, 1, eq);
 5561     __ b(loop, eq);
 5562     __ teq($tmp$$Register, 0);
 5563     // used by biased locking only. Requires a membar.
 5564     __ membar(MacroAssembler::Membar_mask_bits(MacroAssembler::LoadStore | MacroAssembler::LoadLoad), noreg);
 5565   %}
 5566   ins_pipe( long_memory_op );
 5567 %}
 5568 
 5569 // No flag versions for CompareAndSwap{P,I,L} because matcher can&#39;t match them
 5570 
 5571 instruct compareAndSwapL_bool(memoryex mem, iRegL oldval, iRegLd newval, iRegI res, iRegLd tmp, flagsReg ccr ) %{
 5572   match(Set res (CompareAndSwapL mem (Binary oldval newval)));
 5573   effect( KILL ccr, TEMP tmp);
 5574   size(32);
 5575   format %{ &quot;loop: \n\t&quot;
 5576             &quot;LDREXD   $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5577             &quot;CMP      $tmp.lo, $oldval.lo\n\t&quot;
 5578             &quot;CMP.eq   $tmp.hi, $oldval.hi\n\t&quot;
 5579             &quot;STREXD.eq $tmp, $newval, $mem\n\t&quot;
 5580             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5581             &quot;XORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5582             &quot;B.eq     loop \n\t&quot;
 5583             &quot;MOV      $res, $tmp&quot; %}
 5584   ins_encode %{
 5585     Label loop;
 5586     __ bind(loop);
 5587     __ ldrexd($tmp$$Register, $mem$$Address);
 5588     __ cmp($tmp$$Register, $oldval$$Register);
 5589     __ cmp($tmp$$Register-&gt;successor(), $oldval$$Register-&gt;successor(), eq);
 5590     __ strexd($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5591     __ mov($tmp$$Register, 0, ne);
 5592     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5593     __ b(loop, eq);
 5594     __ mov($res$$Register, $tmp$$Register);
 5595   %}
 5596   ins_pipe( long_memory_op );
 5597 %}
 5598 
 5599 
 5600 instruct compareAndSwapI_bool(memoryex mem, iRegI oldval, iRegI newval, iRegI res, iRegI tmp, flagsReg ccr ) %{
 5601   match(Set res (CompareAndSwapI mem (Binary oldval newval)));
 5602   effect( KILL ccr, TEMP tmp);
 5603   size(28);
 5604   format %{ &quot;loop: \n\t&quot;
 5605             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5606             &quot;CMP      $tmp, $oldval\n\t&quot;
 5607             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5608             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5609             &quot;XORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5610             &quot;B.eq     loop \n\t&quot;
 5611             &quot;MOV      $res, $tmp&quot; %}
 5612 
 5613   ins_encode %{
 5614     Label loop;
 5615     __ bind(loop);
 5616     __ ldrex($tmp$$Register,$mem$$Address);
 5617     __ cmp($tmp$$Register, $oldval$$Register);
 5618     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5619     __ mov($tmp$$Register, 0, ne);
 5620     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5621     __ b(loop, eq);
 5622     __ mov($res$$Register, $tmp$$Register);
 5623   %}
 5624   ins_pipe( long_memory_op );
 5625 %}
 5626 
 5627 instruct compareAndSwapP_bool(memoryex mem, iRegP oldval, iRegP newval, iRegI res, iRegI tmp, flagsReg ccr ) %{
 5628   match(Set res (CompareAndSwapP mem (Binary oldval newval)));
 5629   effect( KILL ccr, TEMP tmp);
 5630   size(28);
 5631   format %{ &quot;loop: \n\t&quot;
 5632             &quot;LDREX    $tmp, $mem\t! If $oldval==[$mem] Then store $newval into [$mem]\n\t&quot;
 5633             &quot;CMP      $tmp, $oldval\n\t&quot;
 5634             &quot;STREX.eq $tmp, $newval, $mem\n\t&quot;
 5635             &quot;MOV.ne   $tmp, 0 \n\t&quot;
 5636             &quot;EORS.eq  $tmp,$tmp, 1 \n\t&quot;
 5637             &quot;B.eq     loop \n\t&quot;
 5638             &quot;MOV      $res, $tmp&quot; %}
 5639 
 5640   ins_encode %{
 5641     Label loop;
 5642     __ bind(loop);
 5643     __ ldrex($tmp$$Register,$mem$$Address);
 5644     __ cmp($tmp$$Register, $oldval$$Register);
 5645     __ strex($tmp$$Register, $newval$$Register, $mem$$Address, eq);
 5646     __ mov($tmp$$Register, 0, ne);
 5647     __ eors($tmp$$Register, $tmp$$Register, 1, eq);
 5648     __ b(loop, eq);
 5649     __ mov($res$$Register, $tmp$$Register);
 5650   %}
 5651   ins_pipe( long_memory_op );
 5652 %}
 5653 
 5654 instruct xaddI_aimmI_no_res(memoryex mem, aimmI add, Universe dummy, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5655   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5656   match(Set dummy (GetAndAddI mem add));
 5657   effect(KILL ccr, TEMP tmp1, TEMP tmp2);
 5658   size(20);
 5659   format %{ &quot;loop: \n\t&quot;
 5660             &quot;LDREX    $tmp1, $mem\n\t&quot;
 5661             &quot;ADD      $tmp1, $tmp1, $add\n\t&quot;
 5662             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5663             &quot;CMP      $tmp2, 0 \n\t&quot;
 5664             &quot;B.ne     loop \n\t&quot; %}
 5665 
 5666   ins_encode %{
 5667     Label loop;
 5668     __ bind(loop);
 5669     __ ldrex($tmp1$$Register,$mem$$Address);
 5670     __ add($tmp1$$Register, $tmp1$$Register, $add$$constant);
 5671     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5672     __ cmp($tmp2$$Register, 0);
 5673     __ b(loop, ne);
 5674   %}
 5675   ins_pipe( long_memory_op );
 5676 %}
 5677 
 5678 instruct xaddI_reg_no_res(memoryex mem, iRegI add, Universe dummy, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5679   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5680   match(Set dummy (GetAndAddI mem add));
 5681   effect(KILL ccr, TEMP tmp1, TEMP tmp2);
 5682   size(20);
 5683   format %{ &quot;loop: \n\t&quot;
 5684             &quot;LDREX    $tmp1, $mem\n\t&quot;
 5685             &quot;ADD      $tmp1, $tmp1, $add\n\t&quot;
 5686             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5687             &quot;CMP      $tmp2, 0 \n\t&quot;
 5688             &quot;B.ne     loop \n\t&quot; %}
 5689 
 5690   ins_encode %{
 5691     Label loop;
 5692     __ bind(loop);
 5693     __ ldrex($tmp1$$Register,$mem$$Address);
 5694     __ add($tmp1$$Register, $tmp1$$Register, $add$$Register);
 5695     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5696     __ cmp($tmp2$$Register, 0);
 5697     __ b(loop, ne);
 5698   %}
 5699   ins_pipe( long_memory_op );
 5700 %}
 5701 
 5702 instruct xaddI_aimmI(memoryex mem, aimmI add, iRegI res, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5703   match(Set res (GetAndAddI mem add));
 5704   effect(KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5705   size(20);
 5706   format %{ &quot;loop: \n\t&quot;
 5707             &quot;LDREX    $res, $mem\n\t&quot;
 5708             &quot;ADD      $tmp1, $res, $add\n\t&quot;
 5709             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5710             &quot;CMP      $tmp2, 0 \n\t&quot;
 5711             &quot;B.ne     loop \n\t&quot; %}
 5712 
 5713   ins_encode %{
 5714     Label loop;
 5715     __ bind(loop);
 5716     __ ldrex($res$$Register,$mem$$Address);
 5717     __ add($tmp1$$Register, $res$$Register, $add$$constant);
 5718     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5719     __ cmp($tmp2$$Register, 0);
 5720     __ b(loop, ne);
 5721   %}
 5722   ins_pipe( long_memory_op );
 5723 %}
 5724 
 5725 instruct xaddI_reg(memoryex mem, iRegI add, iRegI res, iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 5726   match(Set res (GetAndAddI mem add));
 5727   effect(KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5728   size(20);
 5729   format %{ &quot;loop: \n\t&quot;
 5730             &quot;LDREX    $res, $mem\n\t&quot;
 5731             &quot;ADD      $tmp1, $res, $add\n\t&quot;
 5732             &quot;STREX    $tmp2, $tmp1, $mem\n\t&quot;
 5733             &quot;CMP      $tmp2, 0 \n\t&quot;
 5734             &quot;B.ne     loop \n\t&quot; %}
 5735 
 5736   ins_encode %{
 5737     Label loop;
 5738     __ bind(loop);
 5739     __ ldrex($res$$Register,$mem$$Address);
 5740     __ add($tmp1$$Register, $res$$Register, $add$$Register);
 5741     __ strex($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5742     __ cmp($tmp2$$Register, 0);
 5743     __ b(loop, ne);
 5744   %}
 5745   ins_pipe( long_memory_op );
 5746 %}
 5747 
 5748 instruct xaddL_reg_no_res(memoryex mem, iRegL add, Universe dummy, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5749   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5750   match(Set dummy (GetAndAddL mem add));
 5751   effect( KILL ccr, TEMP tmp1, TEMP tmp2);
 5752   size(24);
 5753   format %{ &quot;loop: \n\t&quot;
 5754             &quot;LDREXD   $tmp1, $mem\n\t&quot;
 5755             &quot;ADDS     $tmp1.lo, $tmp1.lo, $add.lo\n\t&quot;
 5756             &quot;ADC      $tmp1.hi, $tmp1.hi, $add.hi\n\t&quot;
 5757             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5758             &quot;CMP      $tmp2, 0 \n\t&quot;
 5759             &quot;B.ne     loop \n\t&quot; %}
 5760 
 5761   ins_encode %{
 5762     Label loop;
 5763     __ bind(loop);
 5764     __ ldrexd($tmp1$$Register, $mem$$Address);
 5765     __ adds($tmp1$$Register, $tmp1$$Register, $add$$Register);
 5766     __ adc($tmp1$$Register-&gt;successor(), $tmp1$$Register-&gt;successor(), $add$$Register-&gt;successor());
 5767     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5768     __ cmp($tmp2$$Register, 0);
 5769     __ b(loop, ne);
 5770   %}
 5771   ins_pipe( long_memory_op );
 5772 %}
 5773 
 5774 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5775 // (hi($con$$constant), lo($con$$constant)) becomes
 5776 instruct xaddL_immRot_no_res(memoryex mem, immLlowRot add, Universe dummy, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5777   predicate(n-&gt;as_LoadStore()-&gt;result_not_used());
 5778   match(Set dummy (GetAndAddL mem add));
 5779   effect( KILL ccr, TEMP tmp1, TEMP tmp2);
 5780   size(24);
 5781   format %{ &quot;loop: \n\t&quot;
 5782             &quot;LDREXD   $tmp1, $mem\n\t&quot;
 5783             &quot;ADDS     $tmp1.lo, $tmp1.lo, $add\n\t&quot;
 5784             &quot;ADC      $tmp1.hi, $tmp1.hi, 0\n\t&quot;
 5785             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5786             &quot;CMP      $tmp2, 0 \n\t&quot;
 5787             &quot;B.ne     loop \n\t&quot; %}
 5788 
 5789   ins_encode %{
 5790     Label loop;
 5791     __ bind(loop);
 5792     __ ldrexd($tmp1$$Register, $mem$$Address);
 5793     __ adds($tmp1$$Register, $tmp1$$Register, $add$$constant);
 5794     __ adc($tmp1$$Register-&gt;successor(), $tmp1$$Register-&gt;successor(), 0);
 5795     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5796     __ cmp($tmp2$$Register, 0);
 5797     __ b(loop, ne);
 5798   %}
 5799   ins_pipe( long_memory_op );
 5800 %}
 5801 
 5802 instruct xaddL_reg(memoryex mem, iRegL add, iRegLd res, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5803   match(Set res (GetAndAddL mem add));
 5804   effect( KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5805   size(24);
 5806   format %{ &quot;loop: \n\t&quot;
 5807             &quot;LDREXD   $res, $mem\n\t&quot;
 5808             &quot;ADDS     $tmp1.lo, $res.lo, $add.lo\n\t&quot;
 5809             &quot;ADC      $tmp1.hi, $res.hi, $add.hi\n\t&quot;
 5810             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5811             &quot;CMP      $tmp2, 0 \n\t&quot;
 5812             &quot;B.ne     loop \n\t&quot; %}
 5813 
 5814   ins_encode %{
 5815     Label loop;
 5816     __ bind(loop);
 5817     __ ldrexd($res$$Register, $mem$$Address);
 5818     __ adds($tmp1$$Register, $res$$Register, $add$$Register);
 5819     __ adc($tmp1$$Register-&gt;successor(), $res$$Register-&gt;successor(), $add$$Register-&gt;successor());
 5820     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5821     __ cmp($tmp2$$Register, 0);
 5822     __ b(loop, ne);
 5823   %}
 5824   ins_pipe( long_memory_op );
 5825 %}
 5826 
 5827 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 5828 // (hi($con$$constant), lo($con$$constant)) becomes
 5829 instruct xaddL_immRot(memoryex mem, immLlowRot add, iRegLd res, iRegLd tmp1, iRegI tmp2, flagsReg ccr) %{
 5830   match(Set res (GetAndAddL mem add));
 5831   effect( KILL ccr, TEMP tmp1, TEMP tmp2, TEMP res);
 5832   size(24);
 5833   format %{ &quot;loop: \n\t&quot;
 5834             &quot;LDREXD   $res, $mem\n\t&quot;
 5835             &quot;ADDS     $tmp1.lo, $res.lo, $add\n\t&quot;
 5836             &quot;ADC      $tmp1.hi, $res.hi, 0\n\t&quot;
 5837             &quot;STREXD   $tmp2, $tmp1, $mem\n\t&quot;
 5838             &quot;CMP      $tmp2, 0 \n\t&quot;
 5839             &quot;B.ne     loop \n\t&quot; %}
 5840 
 5841   ins_encode %{
 5842     Label loop;
 5843     __ bind(loop);
 5844     __ ldrexd($res$$Register, $mem$$Address);
 5845     __ adds($tmp1$$Register, $res$$Register, $add$$constant);
 5846     __ adc($tmp1$$Register-&gt;successor(), $res$$Register-&gt;successor(), 0);
 5847     __ strexd($tmp2$$Register, $tmp1$$Register, $mem$$Address);
 5848     __ cmp($tmp2$$Register, 0);
 5849     __ b(loop, ne);
 5850   %}
 5851   ins_pipe( long_memory_op );
 5852 %}
 5853 
 5854 instruct xchgI(memoryex mem, iRegI newval, iRegI res, iRegI tmp, flagsReg ccr) %{
 5855   match(Set res (GetAndSetI mem newval));
 5856   effect(KILL ccr, TEMP tmp, TEMP res);
 5857   size(16);
 5858   format %{ &quot;loop: \n\t&quot;
 5859             &quot;LDREX    $res, $mem\n\t&quot;
 5860             &quot;STREX    $tmp, $newval, $mem\n\t&quot;
 5861             &quot;CMP      $tmp, 0 \n\t&quot;
 5862             &quot;B.ne     loop \n\t&quot; %}
 5863 
 5864   ins_encode %{
 5865     Label loop;
 5866     __ bind(loop);
 5867     __ ldrex($res$$Register,$mem$$Address);
 5868     __ strex($tmp$$Register, $newval$$Register, $mem$$Address);
 5869     __ cmp($tmp$$Register, 0);
 5870     __ b(loop, ne);
 5871   %}
 5872   ins_pipe( long_memory_op );
 5873 %}
 5874 
 5875 instruct xchgL(memoryex mem, iRegLd newval, iRegLd res, iRegI tmp, flagsReg ccr) %{
 5876   match(Set res (GetAndSetL mem newval));
 5877   effect( KILL ccr, TEMP tmp, TEMP res);
 5878   size(16);
 5879   format %{ &quot;loop: \n\t&quot;
 5880             &quot;LDREXD   $res, $mem\n\t&quot;
 5881             &quot;STREXD   $tmp, $newval, $mem\n\t&quot;
 5882             &quot;CMP      $tmp, 0 \n\t&quot;
 5883             &quot;B.ne     loop \n\t&quot; %}
 5884 
 5885   ins_encode %{
 5886     Label loop;
 5887     __ bind(loop);
 5888     __ ldrexd($res$$Register, $mem$$Address);
 5889     __ strexd($tmp$$Register, $newval$$Register, $mem$$Address);
 5890     __ cmp($tmp$$Register, 0);
 5891     __ b(loop, ne);
 5892   %}
 5893   ins_pipe( long_memory_op );
 5894 %}
 5895 
 5896 instruct xchgP(memoryex mem, iRegP newval, iRegP res, iRegI tmp, flagsReg ccr) %{
 5897   match(Set res (GetAndSetP mem newval));
 5898   effect(KILL ccr, TEMP tmp, TEMP res);
 5899   size(16);
 5900   format %{ &quot;loop: \n\t&quot;
 5901             &quot;LDREX    $res, $mem\n\t&quot;
 5902             &quot;STREX    $tmp, $newval, $mem\n\t&quot;
 5903             &quot;CMP      $tmp, 0 \n\t&quot;
 5904             &quot;B.ne     loop \n\t&quot; %}
 5905 
 5906   ins_encode %{
 5907     Label loop;
 5908     __ bind(loop);
 5909     __ ldrex($res$$Register,$mem$$Address);
 5910     __ strex($tmp$$Register, $newval$$Register, $mem$$Address);
 5911     __ cmp($tmp$$Register, 0);
 5912     __ b(loop, ne);
 5913   %}
 5914   ins_pipe( long_memory_op );
 5915 %}
 5916 
 5917 //---------------------
 5918 // Subtraction Instructions
 5919 // Register Subtraction
 5920 instruct subI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 5921   match(Set dst (SubI src1 src2));
 5922 
 5923   size(4);
 5924   format %{ &quot;sub_32 $dst,$src1,$src2\t! int&quot; %}
 5925   ins_encode %{
 5926     __ sub_32($dst$$Register, $src1$$Register, $src2$$Register);
 5927   %}
 5928   ins_pipe(ialu_reg_reg);
 5929 %}
 5930 
 5931 instruct subshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5932   match(Set dst (SubI src1 (LShiftI src2 src3)));
 5933 
 5934   size(4);
 5935   format %{ &quot;SUB    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 5936   ins_encode %{
 5937     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 5938   %}
 5939   ins_pipe(ialu_reg_reg);
 5940 %}
 5941 
 5942 instruct subshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5943   match(Set dst (SubI src1 (LShiftI src2 src3)));
 5944 
 5945   size(4);
 5946   format %{ &quot;sub_32 $dst,$src1,$src2&lt;&lt;$src3\t! int&quot; %}
 5947   ins_encode %{
 5948     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 5949   %}
 5950   ins_pipe(ialu_reg_reg);
 5951 %}
 5952 
 5953 instruct subsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5954   match(Set dst (SubI src1 (RShiftI src2 src3)));
 5955 
 5956   size(4);
 5957   format %{ &quot;SUB    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 5958   ins_encode %{
 5959     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 5960   %}
 5961   ins_pipe(ialu_reg_reg);
 5962 %}
 5963 
 5964 instruct subsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5965   match(Set dst (SubI src1 (RShiftI src2 src3)));
 5966 
 5967   size(4);
 5968   format %{ &quot;sub_32 $dst,$src1,$src2&gt;&gt;$src3\t! int&quot; %}
 5969   ins_encode %{
 5970     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 5971   %}
 5972   ins_pipe(ialu_reg_reg);
 5973 %}
 5974 
 5975 instruct subshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5976   match(Set dst (SubI src1 (URShiftI src2 src3)));
 5977 
 5978   size(4);
 5979   format %{ &quot;SUB    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 5980   ins_encode %{
 5981     __ sub($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 5982   %}
 5983   ins_pipe(ialu_reg_reg);
 5984 %}
 5985 
 5986 instruct subshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 5987   match(Set dst (SubI src1 (URShiftI src2 src3)));
 5988 
 5989   size(4);
 5990   format %{ &quot;sub_32 $dst,$src1,$src2&gt;&gt;&gt;$src3\t! int&quot; %}
 5991   ins_encode %{
 5992     __ sub_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 5993   %}
 5994   ins_pipe(ialu_reg_reg);
 5995 %}
 5996 
 5997 instruct rsbshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 5998   match(Set dst (SubI (LShiftI src1 src2) src3));
 5999 
 6000   size(4);
 6001   format %{ &quot;RSB    $dst,$src3,$src1&lt;&lt;$src2&quot; %}
 6002   ins_encode %{
 6003     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6004   %}
 6005   ins_pipe(ialu_reg_reg);
 6006 %}
 6007 
 6008 instruct rsbshlI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6009   match(Set dst (SubI (LShiftI src1 src2) src3));
 6010 
 6011   size(4);
 6012   format %{ &quot;RSB    $dst,$src3,$src1&lt;&lt;$src2&quot; %}
 6013   ins_encode %{
 6014     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 6015   %}
 6016   ins_pipe(ialu_reg_reg);
 6017 %}
 6018 
 6019 instruct rsbsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6020   match(Set dst (SubI (RShiftI src1 src2) src3));
 6021 
 6022   size(4);
 6023   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;$src2&quot; %}
 6024   ins_encode %{
 6025     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 6026   %}
 6027   ins_pipe(ialu_reg_reg);
 6028 %}
 6029 
 6030 instruct rsbsarI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6031   match(Set dst (SubI (RShiftI src1 src2) src3));
 6032 
 6033   size(4);
 6034   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;$src2&quot; %}
 6035   ins_encode %{
 6036     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 6037   %}
 6038   ins_pipe(ialu_reg_reg);
 6039 %}
 6040 
 6041 instruct rsbshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6042   match(Set dst (SubI (URShiftI src1 src2) src3));
 6043 
 6044   size(4);
 6045   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;&gt;$src2&quot; %}
 6046   ins_encode %{
 6047     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6048   %}
 6049   ins_pipe(ialu_reg_reg);
 6050 %}
 6051 
 6052 instruct rsbshrI_reg_imm_reg(iRegI dst, iRegI src1, immU5 src2, iRegI src3) %{
 6053   match(Set dst (SubI (URShiftI src1 src2) src3));
 6054 
 6055   size(4);
 6056   format %{ &quot;RSB    $dst,$src3,$src1&gt;&gt;&gt;$src2&quot; %}
 6057   ins_encode %{
 6058     __ rsb($dst$$Register, $src3$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6059   %}
 6060   ins_pipe(ialu_reg_reg);
 6061 %}
 6062 
 6063 // Immediate Subtraction
 6064 instruct subI_reg_aimmI(iRegI dst, iRegI src1, aimmI src2) %{
 6065   match(Set dst (SubI src1 src2));
 6066 
 6067   size(4);
 6068   format %{ &quot;sub_32 $dst,$src1,$src2\t! int&quot; %}
 6069   ins_encode %{
 6070     __ sub_32($dst$$Register, $src1$$Register, $src2$$constant);
 6071   %}
 6072   ins_pipe(ialu_reg_imm);
 6073 %}
 6074 
 6075 instruct subI_reg_immRotneg(iRegI dst, iRegI src1, aimmIneg src2) %{
 6076   match(Set dst (AddI src1 src2));
 6077 
 6078   size(4);
 6079   format %{ &quot;sub_32 $dst,$src1,-($src2)\t! int&quot; %}
 6080   ins_encode %{
 6081     __ sub_32($dst$$Register, $src1$$Register, -$src2$$constant);
 6082   %}
 6083   ins_pipe(ialu_reg_imm);
 6084 %}
 6085 
 6086 instruct subI_immRot_reg(iRegI dst, immIRot src1, iRegI src2) %{
 6087   match(Set dst (SubI src1 src2));
 6088 
 6089   size(4);
 6090   format %{ &quot;RSB    $dst,$src2,src1&quot; %}
 6091   ins_encode %{
 6092     __ rsb($dst$$Register, $src2$$Register, $src1$$constant);
 6093   %}
 6094   ins_pipe(ialu_zero_reg);
 6095 %}
 6096 
 6097 // Register Subtraction
 6098 instruct subL_reg_reg(iRegL dst, iRegL src1, iRegL src2, flagsReg icc ) %{
 6099   match(Set dst (SubL src1 src2));
 6100   effect (KILL icc);
 6101 
 6102   size(8);
 6103   format %{ &quot;SUBS   $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 6104             &quot;SBC    $dst.hi,$src1.hi,$src2.hi&quot; %}
 6105   ins_encode %{
 6106     __ subs($dst$$Register, $src1$$Register, $src2$$Register);
 6107     __ sbc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 6108   %}
 6109   ins_pipe(ialu_reg_reg);
 6110 %}
 6111 
 6112 // TODO
 6113 
 6114 // Immediate Subtraction
 6115 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 6116 // (hi($con$$constant), lo($con$$constant)) becomes
 6117 instruct subL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con, flagsReg icc) %{
 6118   match(Set dst (SubL src1 con));
 6119   effect (KILL icc);
 6120 
 6121   size(8);
 6122   format %{ &quot;SUB    $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 6123             &quot;SBC    $dst.hi,$src1.hi,0&quot; %}
 6124   ins_encode %{
 6125     __ subs($dst$$Register, $src1$$Register, $con$$constant);
 6126     __ sbc($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 6127   %}
 6128   ins_pipe(ialu_reg_imm);
 6129 %}
 6130 
 6131 // Long negation
 6132 instruct negL_reg_reg(iRegL dst, immL0 zero, iRegL src2, flagsReg icc) %{
 6133   match(Set dst (SubL zero src2));
 6134   effect (KILL icc);
 6135 
 6136   size(8);
 6137   format %{ &quot;RSBS   $dst.lo,$src2.lo,0\t! long\n\t&quot;
 6138             &quot;RSC    $dst.hi,$src2.hi,0&quot; %}
 6139   ins_encode %{
 6140     __ rsbs($dst$$Register, $src2$$Register, 0);
 6141     __ rsc($dst$$Register-&gt;successor(), $src2$$Register-&gt;successor(), 0);
 6142   %}
 6143   ins_pipe(ialu_zero_reg);
 6144 %}
 6145 
 6146 // Multiplication Instructions
 6147 // Integer Multiplication
 6148 // Register Multiplication
 6149 instruct mulI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6150   match(Set dst (MulI src1 src2));
 6151 
 6152   size(4);
 6153   format %{ &quot;mul_32 $dst,$src1,$src2&quot; %}
 6154   ins_encode %{
 6155     __ mul_32($dst$$Register, $src1$$Register, $src2$$Register);
 6156   %}
 6157   ins_pipe(imul_reg_reg);
 6158 %}
 6159 
 6160 instruct mulL_lo1_hi2(iRegL dst, iRegL src1, iRegL src2) %{
 6161   effect(DEF dst, USE src1, USE src2);
 6162   size(4);
 6163   format %{ &quot;MUL  $dst.hi,$src1.lo,$src2.hi\t! long&quot; %}
 6164   ins_encode %{
 6165     __ mul($dst$$Register-&gt;successor(), $src1$$Register, $src2$$Register-&gt;successor());
 6166   %}
 6167   ins_pipe(imul_reg_reg);
 6168 %}
 6169 
 6170 instruct mulL_hi1_lo2(iRegL dst, iRegL src1, iRegL src2) %{
 6171   effect(USE_DEF dst, USE src1, USE src2);
 6172   size(8);
 6173   format %{ &quot;MLA  $dst.hi,$src1.hi,$src2.lo,$dst.hi\t! long\n\t&quot;
 6174             &quot;MOV  $dst.lo, 0&quot;%}
 6175   ins_encode %{
 6176     __ mla($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register, $dst$$Register-&gt;successor());
 6177     __ mov($dst$$Register, 0);
 6178   %}
 6179   ins_pipe(imul_reg_reg);
 6180 %}
 6181 
 6182 instruct mulL_lo1_lo2(iRegL dst, iRegL src1, iRegL src2) %{
 6183   effect(USE_DEF dst, USE src1, USE src2);
 6184   size(4);
 6185   format %{ &quot;UMLAL  $dst.lo,$dst.hi,$src1,$src2\t! long&quot; %}
 6186   ins_encode %{
 6187     __ umlal($dst$$Register, $dst$$Register-&gt;successor(), $src1$$Register, $src2$$Register);
 6188   %}
 6189   ins_pipe(imul_reg_reg);
 6190 %}
 6191 
 6192 instruct mulL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6193   match(Set dst (MulL src1 src2));
 6194 
 6195   expand %{
 6196     mulL_lo1_hi2(dst, src1, src2);
 6197     mulL_hi1_lo2(dst, src1, src2);
 6198     mulL_lo1_lo2(dst, src1, src2);
 6199   %}
 6200 %}
 6201 
 6202 // Integer Division
 6203 // Register Division
 6204 instruct divI_reg_reg(R1RegI dst, R0RegI src1, R2RegI src2, LRRegP lr, flagsReg ccr) %{
 6205   match(Set dst (DivI src1 src2));
 6206   effect( KILL ccr, KILL src1, KILL src2, KILL lr);
 6207   ins_cost((2+71)*DEFAULT_COST);
 6208 
 6209   format %{ &quot;DIV   $dst,$src1,$src2 ! call to StubRoutines::Arm::idiv_irem_entry()&quot; %}
 6210   ins_encode %{
 6211     __ call(StubRoutines::Arm::idiv_irem_entry(), relocInfo::runtime_call_type);
 6212   %}
 6213   ins_pipe(sdiv_reg_reg);
 6214 %}
 6215 
 6216 // Register Long Division
 6217 instruct divL_reg_reg(R0R1RegL dst, R2R3RegL src1, R0R1RegL src2) %{
 6218   match(Set dst (DivL src1 src2));
 6219   effect(CALL);
 6220   ins_cost(DEFAULT_COST*71);
 6221   format %{ &quot;DIVL  $src1,$src2,$dst\t! long ! call to SharedRuntime::ldiv&quot; %}
 6222   ins_encode %{
 6223     address target = CAST_FROM_FN_PTR(address, SharedRuntime::ldiv);
 6224     __ call(target, relocInfo::runtime_call_type);
 6225   %}
 6226   ins_pipe(divL_reg_reg);
 6227 %}
 6228 
 6229 // Integer Remainder
 6230 // Register Remainder
 6231 instruct modI_reg_reg(R0RegI dst, R0RegI src1, R2RegI src2, R1RegI temp, LRRegP lr, flagsReg ccr ) %{
 6232   match(Set dst (ModI src1 src2));
 6233   effect( KILL ccr, KILL temp, KILL src2, KILL lr);
 6234 
 6235   format %{ &quot;MODI   $dst,$src1,$src2\t ! call to StubRoutines::Arm::idiv_irem_entry&quot; %}
 6236   ins_encode %{
 6237     __ call(StubRoutines::Arm::idiv_irem_entry(), relocInfo::runtime_call_type);
 6238   %}
 6239   ins_pipe(sdiv_reg_reg);
 6240 %}
 6241 
 6242 // Register Long Remainder
 6243 instruct modL_reg_reg(R0R1RegL dst, R2R3RegL src1, R0R1RegL src2) %{
 6244   match(Set dst (ModL src1 src2));
 6245   effect(CALL);
 6246   ins_cost(MEMORY_REF_COST); // FIXME
 6247   format %{ &quot;modL    $dst,$src1,$src2\t ! call to SharedRuntime::lrem&quot; %}
 6248   ins_encode %{
 6249     address target = CAST_FROM_FN_PTR(address, SharedRuntime::lrem);
 6250     __ call(target, relocInfo::runtime_call_type);
 6251   %}
 6252   ins_pipe(divL_reg_reg);
 6253 %}
 6254 
 6255 // Integer Shift Instructions
 6256 
 6257 // Register Shift Left
 6258 instruct shlI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6259   match(Set dst (LShiftI src1 src2));
 6260 
 6261   size(4);
 6262   format %{ &quot;LSL  $dst,$src1,$src2 \n\t&quot; %}
 6263   ins_encode %{
 6264     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6265   %}
 6266   ins_pipe(ialu_reg_reg);
 6267 %}
 6268 
 6269 // Register Shift Left Immediate
 6270 instruct shlI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6271   match(Set dst (LShiftI src1 src2));
 6272 
 6273   size(4);
 6274   format %{ &quot;LSL    $dst,$src1,$src2\t! int&quot; %}
 6275   ins_encode %{
 6276     __ logical_shift_left($dst$$Register, $src1$$Register, $src2$$constant);
 6277   %}
 6278   ins_pipe(ialu_reg_imm);
 6279 %}
 6280 
 6281 instruct shlL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6282   effect(USE_DEF dst, USE src1, USE src2);
 6283   size(4);
 6284   format %{&quot;OR  $dst.hi,$dst.hi,($src1.hi &lt;&lt; $src2)&quot;  %}
 6285   ins_encode %{
 6286     __ orr($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsl, $src2$$Register));
 6287   %}
 6288   ins_pipe(ialu_reg_reg);
 6289 %}
 6290 
 6291 instruct shlL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6292   effect(USE_DEF dst, USE src1, USE src2);
 6293   size(4);
 6294   format %{ &quot;LSL  $dst.lo,$src1.lo,$src2 \n\t&quot; %}
 6295   ins_encode %{
 6296     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$Register));
 6297   %}
 6298   ins_pipe(ialu_reg_reg);
 6299 %}
 6300 
 6301 instruct shlL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6302   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6303   size(16);
 6304   format %{ &quot;SUBS  $dst.hi,$src2,32 \n\t&quot;
 6305             &quot;LSLpl $dst.hi,$src1.lo,$dst.hi \n\t&quot;
 6306             &quot;RSBmi $dst.hi,$dst.hi,0 \n\t&quot;
 6307             &quot;LSRmi $dst.hi,$src1.lo,$dst.hi&quot; %}
 6308 
 6309   ins_encode %{
 6310     // $src1$$Register and $dst$$Register-&gt;successor() can&#39;t be the same
 6311     __ subs($dst$$Register-&gt;successor(), $src2$$Register, 32);
 6312     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsl, $dst$$Register-&gt;successor()), pl);
 6313     __ rsb($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), 0, mi);
 6314     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsr, $dst$$Register-&gt;successor()), mi);
 6315   %}
 6316   ins_pipe(ialu_reg_reg);
 6317 %}
 6318 
 6319 instruct shlL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6320   match(Set dst (LShiftL src1 src2));
 6321 
 6322   expand %{
 6323     flagsReg ccr;
 6324     shlL_reg_reg_overlap(dst, src1, src2, ccr);
 6325     shlL_reg_reg_merge_hi(dst, src1, src2);
 6326     shlL_reg_reg_merge_lo(dst, src1, src2);
 6327   %}
 6328 %}
 6329 
 6330 // Register Shift Left Immediate
 6331 instruct shlL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6332   match(Set dst (LShiftL src1 src2));
 6333 
 6334   size(8);
 6335   format %{ &quot;LSL   $dst.hi,$src1.lo,$src2-32\t! or mov if $src2==32\n\t&quot;
 6336             &quot;MOV   $dst.lo, 0&quot; %}
 6337   ins_encode %{
 6338     if ($src2$$constant == 32) {
 6339       __ mov($dst$$Register-&gt;successor(), $src1$$Register);
 6340     } else {
 6341       __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsl, $src2$$constant-32));
 6342     }
 6343     __ mov($dst$$Register, 0);
 6344   %}
 6345   ins_pipe(ialu_reg_imm);
 6346 %}
 6347 
 6348 instruct shlL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6349   match(Set dst (LShiftL src1 src2));
 6350 
 6351   size(12);
 6352   format %{ &quot;LSL   $dst.hi,$src1.lo,$src2\n\t&quot;
 6353             &quot;OR    $dst.hi, $dst.hi, $src1.lo &gt;&gt; 32-$src2\n\t&quot;
 6354             &quot;LSL   $dst.lo,$src1.lo,$src2&quot; %}
 6355   ins_encode %{
 6356     // The order of the following 3 instructions matters: src1.lo and
 6357     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6358     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsl, $src2$$constant));
 6359     __ orr($dst$$Register-&gt;successor(), $dst$$Register-&gt;successor(), AsmOperand($src1$$Register, lsr, 32-$src2$$constant));
 6360     __ mov($dst$$Register, AsmOperand($src1$$Register, lsl, $src2$$constant));
 6361   %}
 6362   ins_pipe(ialu_reg_imm);
 6363 %}
 6364 
 6365 // Register Arithmetic Shift Right
 6366 instruct sarI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6367   match(Set dst (RShiftI src1 src2));
 6368   size(4);
 6369   format %{ &quot;ASR    $dst,$src1,$src2\t! int&quot; %}
 6370   ins_encode %{
 6371     __ mov($dst$$Register, AsmOperand($src1$$Register, asr, $src2$$Register));
 6372   %}
 6373   ins_pipe(ialu_reg_reg);
 6374 %}
 6375 
 6376 // Register Arithmetic Shift Right Immediate
 6377 instruct sarI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6378   match(Set dst (RShiftI src1 src2));
 6379 
 6380   size(4);
 6381   format %{ &quot;ASR    $dst,$src1,$src2&quot; %}
 6382   ins_encode %{
 6383     __ mov($dst$$Register, AsmOperand($src1$$Register, asr, $src2$$constant));
 6384   %}
 6385   ins_pipe(ialu_reg_imm);
 6386 %}
 6387 
 6388 // Register Shift Right Arithmetic Long
 6389 instruct sarL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6390   effect(USE_DEF dst, USE src1, USE src2);
 6391   size(4);
 6392   format %{ &quot;OR  $dst.lo,$dst.lo,($src1.lo &gt;&gt; $src2)&quot;  %}
 6393   ins_encode %{
 6394     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6395   %}
 6396   ins_pipe(ialu_reg_reg);
 6397 %}
 6398 
 6399 instruct sarL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6400   effect(USE_DEF dst, USE src1, USE src2);
 6401   size(4);
 6402   format %{ &quot;ASR  $dst.hi,$src1.hi,$src2 \n\t&quot; %}
 6403   ins_encode %{
 6404     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$Register));
 6405   %}
 6406   ins_pipe(ialu_reg_reg);
 6407 %}
 6408 
 6409 instruct sarL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6410   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6411   size(16);
 6412   format %{ &quot;SUBS  $dst.lo,$src2,32 \n\t&quot;
 6413             &quot;ASRpl $dst.lo,$src1.hi,$dst.lo \n\t&quot;
 6414             &quot;RSBmi $dst.lo,$dst.lo,0 \n\t&quot;
 6415             &quot;LSLmi $dst.lo,$src1.hi,$dst.lo&quot; %}
 6416 
 6417   ins_encode %{
 6418     // $src1$$Register-&gt;successor() and $dst$$Register can&#39;t be the same
 6419     __ subs($dst$$Register, $src2$$Register, 32);
 6420     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), asr, $dst$$Register), pl);
 6421     __ rsb($dst$$Register, $dst$$Register, 0, mi);
 6422     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, $dst$$Register), mi);
 6423   %}
 6424   ins_pipe(ialu_reg_reg);
 6425 %}
 6426 
 6427 instruct sarL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6428   match(Set dst (RShiftL src1 src2));
 6429 
 6430   expand %{
 6431     flagsReg ccr;
 6432     sarL_reg_reg_overlap(dst, src1, src2, ccr);
 6433     sarL_reg_reg_merge_lo(dst, src1, src2);
 6434     sarL_reg_reg_merge_hi(dst, src1, src2);
 6435   %}
 6436 %}
 6437 
 6438 // Register Shift Left Immediate
 6439 instruct sarL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6440   match(Set dst (RShiftL src1 src2));
 6441 
 6442   size(8);
 6443   format %{ &quot;ASR   $dst.lo,$src1.hi,$src2-32\t! or mov if $src2==32\n\t&quot;
 6444             &quot;ASR   $dst.hi,$src1.hi, $src2&quot; %}
 6445   ins_encode %{
 6446     if ($src2$$constant == 32) {
 6447       __ mov($dst$$Register, $src1$$Register-&gt;successor());
 6448     } else{
 6449       __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$constant-32));
 6450     }
 6451     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, 0));
 6452   %}
 6453 
 6454   ins_pipe(ialu_reg_imm);
 6455 %}
 6456 
 6457 instruct sarL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6458   match(Set dst (RShiftL src1 src2));
 6459   size(12);
 6460   format %{ &quot;LSR   $dst.lo,$src1.lo,$src2\n\t&quot;
 6461             &quot;OR    $dst.lo, $dst.lo, $src1.hi &lt;&lt; 32-$src2\n\t&quot;
 6462             &quot;ASR   $dst.hi,$src1.hi,$src2&quot; %}
 6463   ins_encode %{
 6464     // The order of the following 3 instructions matters: src1.lo and
 6465     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6466     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6467     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, 32-$src2$$constant));
 6468     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), asr, $src2$$constant));
 6469   %}
 6470   ins_pipe(ialu_reg_imm);
 6471 %}
 6472 
 6473 // Register Shift Right
 6474 instruct shrI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6475   match(Set dst (URShiftI src1 src2));
 6476   size(4);
 6477   format %{ &quot;LSR    $dst,$src1,$src2\t! int&quot; %}
 6478   ins_encode %{
 6479     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6480   %}
 6481   ins_pipe(ialu_reg_reg);
 6482 %}
 6483 
 6484 // Register Shift Right Immediate
 6485 instruct shrI_reg_imm5(iRegI dst, iRegI src1, immU5 src2) %{
 6486   match(Set dst (URShiftI src1 src2));
 6487 
 6488   size(4);
 6489   format %{ &quot;LSR    $dst,$src1,$src2&quot; %}
 6490   ins_encode %{
 6491     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6492   %}
 6493   ins_pipe(ialu_reg_imm);
 6494 %}
 6495 
 6496 // Register Shift Right
 6497 instruct shrL_reg_reg_merge_lo(iRegL dst, iRegL src1, iRegI src2) %{
 6498   effect(USE_DEF dst, USE src1, USE src2);
 6499   size(4);
 6500   format %{ &quot;OR   $dst.lo,$dst,($src1.lo &gt;&gt;&gt; $src2)&quot;  %}
 6501   ins_encode %{
 6502     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$Register));
 6503   %}
 6504   ins_pipe(ialu_reg_reg);
 6505 %}
 6506 
 6507 instruct shrL_reg_reg_merge_hi(iRegL dst, iRegL src1, iRegI src2) %{
 6508   effect(USE_DEF dst, USE src1, USE src2);
 6509   size(4);
 6510   format %{ &quot;LSR  $dst.hi,$src1.hi,$src2 \n\t&quot; %}
 6511   ins_encode %{
 6512     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$Register));
 6513   %}
 6514   ins_pipe(ialu_reg_reg);
 6515 %}
 6516 
 6517 instruct shrL_reg_reg_overlap(iRegL dst, iRegL src1, iRegI src2, flagsReg ccr) %{
 6518   effect(DEF dst, USE src1, USE src2, KILL ccr);
 6519   size(16);
 6520   format %{ &quot;SUBS  $dst,$src2,32 \n\t&quot;
 6521             &quot;LSRpl $dst,$src1.hi,$dst \n\t&quot;
 6522             &quot;RSBmi $dst,$dst,0 \n\t&quot;
 6523             &quot;LSLmi $dst,$src1.hi,$dst&quot; %}
 6524 
 6525   ins_encode %{
 6526     // $src1$$Register-&gt;successor() and $dst$$Register can&#39;t be the same
 6527     __ subs($dst$$Register, $src2$$Register, 32);
 6528     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsr, $dst$$Register), pl);
 6529     __ rsb($dst$$Register, $dst$$Register, 0, mi);
 6530     __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, $dst$$Register), mi);
 6531   %}
 6532   ins_pipe(ialu_reg_reg);
 6533 %}
 6534 
 6535 instruct shrL_reg_reg(iRegL dst, iRegL src1, iRegI src2) %{
 6536   match(Set dst (URShiftL src1 src2));
 6537 
 6538   expand %{
 6539     flagsReg ccr;
 6540     shrL_reg_reg_overlap(dst, src1, src2, ccr);
 6541     shrL_reg_reg_merge_lo(dst, src1, src2);
 6542     shrL_reg_reg_merge_hi(dst, src1, src2);
 6543   %}
 6544 %}
 6545 
 6546 // Register Shift Right Immediate
 6547 instruct shrL_reg_imm6(iRegL dst, iRegL src1, immU6Big src2) %{
 6548   match(Set dst (URShiftL src1 src2));
 6549 
 6550   size(8);
 6551   format %{ &quot;LSR   $dst.lo,$src1.hi,$src2-32\t! or mov if $src2==32\n\t&quot;
 6552             &quot;MOV   $dst.hi, 0&quot; %}
 6553   ins_encode %{
 6554     if ($src2$$constant == 32) {
 6555       __ mov($dst$$Register, $src1$$Register-&gt;successor());
 6556     } else {
 6557       __ mov($dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$constant-32));
 6558     }
 6559     __ mov($dst$$Register-&gt;successor(), 0);
 6560   %}
 6561 
 6562   ins_pipe(ialu_reg_imm);
 6563 %}
 6564 
 6565 instruct shrL_reg_imm5(iRegL dst, iRegL src1, immU5 src2) %{
 6566   match(Set dst (URShiftL src1 src2));
 6567 
 6568   size(12);
 6569   format %{ &quot;LSR   $dst.lo,$src1.lo,$src2\n\t&quot;
 6570             &quot;OR    $dst.lo, $dst.lo, $src1.hi &lt;&lt; 32-$src2\n\t&quot;
 6571             &quot;LSR   $dst.hi,$src1.hi,$src2&quot; %}
 6572   ins_encode %{
 6573     // The order of the following 3 instructions matters: src1.lo and
 6574     // dst.hi can&#39;t overlap but src.hi and dst.hi can.
 6575     __ mov($dst$$Register, AsmOperand($src1$$Register, lsr, $src2$$constant));
 6576     __ orr($dst$$Register, $dst$$Register, AsmOperand($src1$$Register-&gt;successor(), lsl, 32-$src2$$constant));
 6577     __ mov($dst$$Register-&gt;successor(), AsmOperand($src1$$Register-&gt;successor(), lsr, $src2$$constant));
 6578   %}
 6579   ins_pipe(ialu_reg_imm);
 6580 %}
 6581 
 6582 
 6583 instruct shrP_reg_imm5(iRegX dst, iRegP src1, immU5 src2) %{
 6584   match(Set dst (URShiftI (CastP2X src1) src2));
 6585   size(4);
 6586   format %{ &quot;LSR    $dst,$src1,$src2\t! Cast ptr $src1 to int and shift&quot; %}
 6587   ins_encode %{
 6588     __ logical_shift_right($dst$$Register, $src1$$Register, $src2$$constant);
 6589   %}
 6590   ins_pipe(ialu_reg_imm);
 6591 %}
 6592 
 6593 //----------Floating Point Arithmetic Instructions-----------------------------
 6594 
 6595 //  Add float single precision
 6596 instruct addF_reg_reg(regF dst, regF src1, regF src2) %{
 6597   match(Set dst (AddF src1 src2));
 6598 
 6599   size(4);
 6600   format %{ &quot;FADDS  $dst,$src1,$src2&quot; %}
 6601   ins_encode %{
 6602     __ add_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6603   %}
 6604 
 6605   ins_pipe(faddF_reg_reg);
 6606 %}
 6607 
 6608 //  Add float double precision
 6609 instruct addD_reg_reg(regD dst, regD src1, regD src2) %{
 6610   match(Set dst (AddD src1 src2));
 6611 
 6612   size(4);
 6613   format %{ &quot;FADDD  $dst,$src1,$src2&quot; %}
 6614   ins_encode %{
 6615     __ add_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6616   %}
 6617 
 6618   ins_pipe(faddD_reg_reg);
 6619 %}
 6620 
 6621 //  Sub float single precision
 6622 instruct subF_reg_reg(regF dst, regF src1, regF src2) %{
 6623   match(Set dst (SubF src1 src2));
 6624 
 6625   size(4);
 6626   format %{ &quot;FSUBS  $dst,$src1,$src2&quot; %}
 6627   ins_encode %{
 6628     __ sub_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6629   %}
 6630   ins_pipe(faddF_reg_reg);
 6631 %}
 6632 
 6633 //  Sub float double precision
 6634 instruct subD_reg_reg(regD dst, regD src1, regD src2) %{
 6635   match(Set dst (SubD src1 src2));
 6636 
 6637   size(4);
 6638   format %{ &quot;FSUBD  $dst,$src1,$src2&quot; %}
 6639   ins_encode %{
 6640     __ sub_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6641   %}
 6642   ins_pipe(faddD_reg_reg);
 6643 %}
 6644 
 6645 //  Mul float single precision
 6646 instruct mulF_reg_reg(regF dst, regF src1, regF src2) %{
 6647   match(Set dst (MulF src1 src2));
 6648 
 6649   size(4);
 6650   format %{ &quot;FMULS  $dst,$src1,$src2&quot; %}
 6651   ins_encode %{
 6652     __ mul_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6653   %}
 6654 
 6655   ins_pipe(fmulF_reg_reg);
 6656 %}
 6657 
 6658 //  Mul float double precision
 6659 instruct mulD_reg_reg(regD dst, regD src1, regD src2) %{
 6660   match(Set dst (MulD src1 src2));
 6661 
 6662   size(4);
 6663   format %{ &quot;FMULD  $dst,$src1,$src2&quot; %}
 6664   ins_encode %{
 6665     __ mul_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6666   %}
 6667 
 6668   ins_pipe(fmulD_reg_reg);
 6669 %}
 6670 
 6671 //  Div float single precision
 6672 instruct divF_reg_reg(regF dst, regF src1, regF src2) %{
 6673   match(Set dst (DivF src1 src2));
 6674 
 6675   size(4);
 6676   format %{ &quot;FDIVS  $dst,$src1,$src2&quot; %}
 6677   ins_encode %{
 6678     __ div_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6679   %}
 6680 
 6681   ins_pipe(fdivF_reg_reg);
 6682 %}
 6683 
 6684 //  Div float double precision
 6685 instruct divD_reg_reg(regD dst, regD src1, regD src2) %{
 6686   match(Set dst (DivD src1 src2));
 6687 
 6688   size(4);
 6689   format %{ &quot;FDIVD  $dst,$src1,$src2&quot; %}
 6690   ins_encode %{
 6691     __ div_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 6692   %}
 6693 
 6694   ins_pipe(fdivD_reg_reg);
 6695 %}
 6696 
 6697 //  Absolute float double precision
 6698 instruct absD_reg(regD dst, regD src) %{
 6699   match(Set dst (AbsD src));
 6700 
 6701   size(4);
 6702   format %{ &quot;FABSd  $dst,$src&quot; %}
 6703   ins_encode %{
 6704     __ abs_double($dst$$FloatRegister, $src$$FloatRegister);
 6705   %}
 6706   ins_pipe(faddD_reg);
 6707 %}
 6708 
 6709 //  Absolute float single precision
 6710 instruct absF_reg(regF dst, regF src) %{
 6711   match(Set dst (AbsF src));
 6712   format %{ &quot;FABSs  $dst,$src&quot; %}
 6713   ins_encode %{
 6714     __ abs_float($dst$$FloatRegister, $src$$FloatRegister);
 6715   %}
 6716   ins_pipe(faddF_reg);
 6717 %}
 6718 
 6719 instruct negF_reg(regF dst, regF src) %{
 6720   match(Set dst (NegF src));
 6721 
 6722   size(4);
 6723   format %{ &quot;FNEGs  $dst,$src&quot; %}
 6724   ins_encode %{
 6725     __ neg_float($dst$$FloatRegister, $src$$FloatRegister);
 6726   %}
 6727   ins_pipe(faddF_reg);
 6728 %}
 6729 
 6730 instruct negD_reg(regD dst, regD src) %{
 6731   match(Set dst (NegD src));
 6732 
 6733   format %{ &quot;FNEGd  $dst,$src&quot; %}
 6734   ins_encode %{
 6735     __ neg_double($dst$$FloatRegister, $src$$FloatRegister);
 6736   %}
 6737   ins_pipe(faddD_reg);
 6738 %}
 6739 
 6740 //  Sqrt float double precision
 6741 instruct sqrtF_reg_reg(regF dst, regF src) %{
 6742   match(Set dst (ConvD2F (SqrtD (ConvF2D src))));
 6743 
 6744   size(4);
 6745   format %{ &quot;FSQRTS $dst,$src&quot; %}
 6746   ins_encode %{
 6747     __ sqrt_float($dst$$FloatRegister, $src$$FloatRegister);
 6748   %}
 6749   ins_pipe(fdivF_reg_reg);
 6750 %}
 6751 
 6752 //  Sqrt float double precision
 6753 instruct sqrtD_reg_reg(regD dst, regD src) %{
 6754   match(Set dst (SqrtD src));
 6755 
 6756   size(4);
 6757   format %{ &quot;FSQRTD $dst,$src&quot; %}
 6758   ins_encode %{
 6759     __ sqrt_double($dst$$FloatRegister, $src$$FloatRegister);
 6760   %}
 6761   ins_pipe(fdivD_reg_reg);
 6762 %}
 6763 
 6764 //----------Logical Instructions-----------------------------------------------
 6765 // And Instructions
 6766 // Register And
 6767 instruct andI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6768   match(Set dst (AndI src1 src2));
 6769 
 6770   size(4);
 6771   format %{ &quot;and_32 $dst,$src1,$src2&quot; %}
 6772   ins_encode %{
 6773     __ and_32($dst$$Register, $src1$$Register, $src2$$Register);
 6774   %}
 6775   ins_pipe(ialu_reg_reg);
 6776 %}
 6777 
 6778 instruct andshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6779   match(Set dst (AndI src1 (LShiftI src2 src3)));
 6780 
 6781   size(4);
 6782   format %{ &quot;AND    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6783   ins_encode %{
 6784     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 6785   %}
 6786   ins_pipe(ialu_reg_reg);
 6787 %}
 6788 
 6789 instruct andshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6790   match(Set dst (AndI src1 (LShiftI src2 src3)));
 6791 
 6792   size(4);
 6793   format %{ &quot;and_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6794   ins_encode %{
 6795     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 6796   %}
 6797   ins_pipe(ialu_reg_reg);
 6798 %}
 6799 
 6800 instruct andsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6801   match(Set dst (AndI src1 (RShiftI src2 src3)));
 6802 
 6803   size(4);
 6804   format %{ &quot;AND    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6805   ins_encode %{
 6806     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 6807   %}
 6808   ins_pipe(ialu_reg_reg);
 6809 %}
 6810 
 6811 instruct andsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6812   match(Set dst (AndI src1 (RShiftI src2 src3)));
 6813 
 6814   size(4);
 6815   format %{ &quot;and_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6816   ins_encode %{
 6817     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 6818   %}
 6819   ins_pipe(ialu_reg_reg);
 6820 %}
 6821 
 6822 instruct andshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6823   match(Set dst (AndI src1 (URShiftI src2 src3)));
 6824 
 6825   size(4);
 6826   format %{ &quot;AND    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6827   ins_encode %{
 6828     __ andr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 6829   %}
 6830   ins_pipe(ialu_reg_reg);
 6831 %}
 6832 
 6833 instruct andshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6834   match(Set dst (AndI src1 (URShiftI src2 src3)));
 6835 
 6836   size(4);
 6837   format %{ &quot;and_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6838   ins_encode %{
 6839     __ and_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 6840   %}
 6841   ins_pipe(ialu_reg_reg);
 6842 %}
 6843 
 6844 // Immediate And
 6845 instruct andI_reg_limm(iRegI dst, iRegI src1, limmI src2) %{
 6846   match(Set dst (AndI src1 src2));
 6847 
 6848   size(4);
 6849   format %{ &quot;and_32 $dst,$src1,$src2\t! int&quot; %}
 6850   ins_encode %{
 6851     __ and_32($dst$$Register, $src1$$Register, $src2$$constant);
 6852   %}
 6853   ins_pipe(ialu_reg_imm);
 6854 %}
 6855 
 6856 instruct andI_reg_limmn(iRegI dst, iRegI src1, limmIn src2) %{
 6857   match(Set dst (AndI src1 src2));
 6858 
 6859   size(4);
 6860   format %{ &quot;bic    $dst,$src1,~$src2\t! int&quot; %}
 6861   ins_encode %{
 6862     __ bic($dst$$Register, $src1$$Register, ~$src2$$constant);
 6863   %}
 6864   ins_pipe(ialu_reg_imm);
 6865 %}
 6866 
 6867 // Register And Long
 6868 instruct andL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6869   match(Set dst (AndL src1 src2));
 6870 
 6871   ins_cost(DEFAULT_COST);
 6872   size(8);
 6873   format %{ &quot;AND    $dst,$src1,$src2\t! long&quot; %}
 6874   ins_encode %{
 6875     __ andr($dst$$Register, $src1$$Register, $src2$$Register);
 6876     __ andr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 6877   %}
 6878   ins_pipe(ialu_reg_reg);
 6879 %}
 6880 
 6881 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 6882 // (hi($con$$constant), lo($con$$constant)) becomes
 6883 instruct andL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 6884   match(Set dst (AndL src1 con));
 6885   ins_cost(DEFAULT_COST);
 6886   size(8);
 6887   format %{ &quot;AND    $dst,$src1,$con\t! long&quot; %}
 6888   ins_encode %{
 6889     __ andr($dst$$Register, $src1$$Register, $con$$constant);
 6890     __ andr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 6891   %}
 6892   ins_pipe(ialu_reg_imm);
 6893 %}
 6894 
 6895 // Or Instructions
 6896 // Register Or
 6897 instruct orI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 6898   match(Set dst (OrI src1 src2));
 6899 
 6900   size(4);
 6901   format %{ &quot;orr_32 $dst,$src1,$src2\t! int&quot; %}
 6902   ins_encode %{
 6903     __ orr_32($dst$$Register, $src1$$Register, $src2$$Register);
 6904   %}
 6905   ins_pipe(ialu_reg_reg);
 6906 %}
 6907 
 6908 instruct orshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6909   match(Set dst (OrI src1 (LShiftI src2 src3)));
 6910 
 6911   size(4);
 6912   format %{ &quot;OR    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6913   ins_encode %{
 6914     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 6915   %}
 6916   ins_pipe(ialu_reg_reg);
 6917 %}
 6918 
 6919 instruct orshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6920   match(Set dst (OrI src1 (LShiftI src2 src3)));
 6921 
 6922   size(4);
 6923   format %{ &quot;orr_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 6924   ins_encode %{
 6925     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 6926   %}
 6927   ins_pipe(ialu_reg_reg);
 6928 %}
 6929 
 6930 instruct orsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6931   match(Set dst (OrI src1 (RShiftI src2 src3)));
 6932 
 6933   size(4);
 6934   format %{ &quot;OR    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6935   ins_encode %{
 6936     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 6937   %}
 6938   ins_pipe(ialu_reg_reg);
 6939 %}
 6940 
 6941 instruct orsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6942   match(Set dst (OrI src1 (RShiftI src2 src3)));
 6943 
 6944   size(4);
 6945   format %{ &quot;orr_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 6946   ins_encode %{
 6947     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 6948   %}
 6949   ins_pipe(ialu_reg_reg);
 6950 %}
 6951 
 6952 instruct orshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 6953   match(Set dst (OrI src1 (URShiftI src2 src3)));
 6954 
 6955   size(4);
 6956   format %{ &quot;OR    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6957   ins_encode %{
 6958     __ orr($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 6959   %}
 6960   ins_pipe(ialu_reg_reg);
 6961 %}
 6962 
 6963 instruct orshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 6964   match(Set dst (OrI src1 (URShiftI src2 src3)));
 6965 
 6966   size(4);
 6967   format %{ &quot;orr_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 6968   ins_encode %{
 6969     __ orr_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 6970   %}
 6971   ins_pipe(ialu_reg_reg);
 6972 %}
 6973 
 6974 // Immediate Or
 6975 instruct orI_reg_limm(iRegI dst, iRegI src1, limmI src2) %{
 6976   match(Set dst (OrI src1 src2));
 6977 
 6978   size(4);
 6979   format %{ &quot;orr_32  $dst,$src1,$src2&quot; %}
 6980   ins_encode %{
 6981     __ orr_32($dst$$Register, $src1$$Register, $src2$$constant);
 6982   %}
 6983   ins_pipe(ialu_reg_imm);
 6984 %}
 6985 // TODO: orn_32 with limmIn
 6986 
 6987 // Register Or Long
 6988 instruct orL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 6989   match(Set dst (OrL src1 src2));
 6990 
 6991   ins_cost(DEFAULT_COST);
 6992   size(8);
 6993   format %{ &quot;OR     $dst.lo,$src1.lo,$src2.lo\t! long\n\t&quot;
 6994             &quot;OR     $dst.hi,$src1.hi,$src2.hi&quot; %}
 6995   ins_encode %{
 6996     __ orr($dst$$Register, $src1$$Register, $src2$$Register);
 6997     __ orr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 6998   %}
 6999   ins_pipe(ialu_reg_reg);
 7000 %}
 7001 
 7002 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7003 // (hi($con$$constant), lo($con$$constant)) becomes
 7004 instruct orL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 7005   match(Set dst (OrL src1 con));
 7006   ins_cost(DEFAULT_COST);
 7007   size(8);
 7008   format %{ &quot;OR     $dst.lo,$src1.lo,$con\t! long\n\t&quot;
 7009             &quot;OR     $dst.hi,$src1.hi,$con&quot; %}
 7010   ins_encode %{
 7011     __ orr($dst$$Register, $src1$$Register, $con$$constant);
 7012     __ orr($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 7013   %}
 7014   ins_pipe(ialu_reg_imm);
 7015 %}
 7016 
 7017 #ifdef TODO
 7018 // Use SPRegP to match Rthread (TLS register) without spilling.
 7019 // Use store_ptr_RegP to match Rthread (TLS register) without spilling.
 7020 // Use sp_ptr_RegP to match Rthread (TLS register) without spilling.
 7021 instruct orI_reg_castP2X(iRegI dst, iRegI src1, sp_ptr_RegP src2) %{
 7022   match(Set dst (OrI src1 (CastP2X src2)));
 7023   size(4);
 7024   format %{ &quot;OR     $dst,$src1,$src2&quot; %}
 7025   ins_encode %{
 7026     __ orr($dst$$Register, $src1$$Register, $src2$$Register);
 7027   %}
 7028   ins_pipe(ialu_reg_reg);
 7029 %}
 7030 #endif
 7031 
 7032 // Xor Instructions
 7033 // Register Xor
 7034 instruct xorI_reg_reg(iRegI dst, iRegI src1, iRegI src2) %{
 7035   match(Set dst (XorI src1 src2));
 7036 
 7037   size(4);
 7038   format %{ &quot;eor_32 $dst,$src1,$src2&quot; %}
 7039   ins_encode %{
 7040     __ eor_32($dst$$Register, $src1$$Register, $src2$$Register);
 7041   %}
 7042   ins_pipe(ialu_reg_reg);
 7043 %}
 7044 
 7045 instruct xorshlI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7046   match(Set dst (XorI src1 (LShiftI src2 src3)));
 7047 
 7048   size(4);
 7049   format %{ &quot;XOR    $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 7050   ins_encode %{
 7051     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$Register));
 7052   %}
 7053   ins_pipe(ialu_reg_reg);
 7054 %}
 7055 
 7056 instruct xorshlI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7057   match(Set dst (XorI src1 (LShiftI src2 src3)));
 7058 
 7059   size(4);
 7060   format %{ &quot;eor_32 $dst,$src1,$src2&lt;&lt;$src3&quot; %}
 7061   ins_encode %{
 7062     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsl, $src3$$constant));
 7063   %}
 7064   ins_pipe(ialu_reg_reg);
 7065 %}
 7066 
 7067 instruct xorsarI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7068   match(Set dst (XorI src1 (RShiftI src2 src3)));
 7069 
 7070   size(4);
 7071   format %{ &quot;XOR    $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 7072   ins_encode %{
 7073     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$Register));
 7074   %}
 7075   ins_pipe(ialu_reg_reg);
 7076 %}
 7077 
 7078 instruct xorsarI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7079   match(Set dst (XorI src1 (RShiftI src2 src3)));
 7080 
 7081   size(4);
 7082   format %{ &quot;eor_32 $dst,$src1,$src2&gt;&gt;$src3&quot; %}
 7083   ins_encode %{
 7084     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, asr, $src3$$constant));
 7085   %}
 7086   ins_pipe(ialu_reg_reg);
 7087 %}
 7088 
 7089 instruct xorshrI_reg_reg_reg(iRegI dst, iRegI src1, iRegI src2, iRegI src3) %{
 7090   match(Set dst (XorI src1 (URShiftI src2 src3)));
 7091 
 7092   size(4);
 7093   format %{ &quot;XOR    $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 7094   ins_encode %{
 7095     __ eor($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$Register));
 7096   %}
 7097   ins_pipe(ialu_reg_reg);
 7098 %}
 7099 
 7100 instruct xorshrI_reg_reg_imm(iRegI dst, iRegI src1, iRegI src2, immU5 src3) %{
 7101   match(Set dst (XorI src1 (URShiftI src2 src3)));
 7102 
 7103   size(4);
 7104   format %{ &quot;eor_32 $dst,$src1,$src2&gt;&gt;&gt;$src3&quot; %}
 7105   ins_encode %{
 7106     __ eor_32($dst$$Register, $src1$$Register, AsmOperand($src2$$Register, lsr, $src3$$constant));
 7107   %}
 7108   ins_pipe(ialu_reg_reg);
 7109 %}
 7110 
 7111 // Immediate Xor
 7112 instruct xorI_reg_imm(iRegI dst, iRegI src1, limmI src2) %{
 7113   match(Set dst (XorI src1 src2));
 7114 
 7115   size(4);
 7116   format %{ &quot;eor_32 $dst,$src1,$src2&quot; %}
 7117   ins_encode %{
 7118     __ eor_32($dst$$Register, $src1$$Register, $src2$$constant);
 7119   %}
 7120   ins_pipe(ialu_reg_imm);
 7121 %}
 7122 
 7123 // Register Xor Long
 7124 instruct xorL_reg_reg(iRegL dst, iRegL src1, iRegL src2) %{
 7125   match(Set dst (XorL src1 src2));
 7126   ins_cost(DEFAULT_COST);
 7127   size(8);
 7128   format %{ &quot;XOR     $dst.hi,$src1.hi,$src2.hi\t! long\n\t&quot;
 7129             &quot;XOR     $dst.lo,$src1.lo,$src2.lo\t! long&quot; %}
 7130   ins_encode %{
 7131     __ eor($dst$$Register, $src1$$Register, $src2$$Register);
 7132     __ eor($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 7133   %}
 7134   ins_pipe(ialu_reg_reg);
 7135 %}
 7136 
 7137 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7138 // (hi($con$$constant), lo($con$$constant)) becomes
 7139 instruct xorL_reg_immRot(iRegL dst, iRegL src1, immLlowRot con) %{
 7140   match(Set dst (XorL src1 con));
 7141   ins_cost(DEFAULT_COST);
 7142   size(8);
 7143   format %{ &quot;XOR     $dst.hi,$src1.hi,$con\t! long\n\t&quot;
 7144             &quot;XOR     $dst.lo,$src1.lo,0\t! long&quot; %}
 7145   ins_encode %{
 7146     __ eor($dst$$Register, $src1$$Register, $con$$constant);
 7147     __ eor($dst$$Register-&gt;successor(), $src1$$Register-&gt;successor(), 0);
 7148   %}
 7149   ins_pipe(ialu_reg_imm);
 7150 %}
 7151 
 7152 //----------Convert to Boolean-------------------------------------------------
 7153 instruct convI2B( iRegI dst, iRegI src, flagsReg ccr ) %{
 7154   match(Set dst (Conv2B src));
 7155   effect(KILL ccr);
 7156   size(12);
 7157   ins_cost(DEFAULT_COST*2);
 7158   format %{ &quot;TST    $src,$src \n\t&quot;
 7159             &quot;MOV    $dst, 0   \n\t&quot;
 7160             &quot;MOV.ne $dst, 1&quot; %}
 7161   ins_encode %{ // FIXME: can do better?
 7162     __ tst($src$$Register, $src$$Register);
 7163     __ mov($dst$$Register, 0);
 7164     __ mov($dst$$Register, 1, ne);
 7165   %}
 7166   ins_pipe(ialu_reg_ialu);
 7167 %}
 7168 
 7169 instruct convP2B( iRegI dst, iRegP src, flagsReg ccr ) %{
 7170   match(Set dst (Conv2B src));
 7171   effect(KILL ccr);
 7172   size(12);
 7173   ins_cost(DEFAULT_COST*2);
 7174   format %{ &quot;TST    $src,$src \n\t&quot;
 7175             &quot;MOV    $dst, 0   \n\t&quot;
 7176             &quot;MOV.ne $dst, 1&quot; %}
 7177   ins_encode %{
 7178     __ tst($src$$Register, $src$$Register);
 7179     __ mov($dst$$Register, 0);
 7180     __ mov($dst$$Register, 1, ne);
 7181   %}
 7182   ins_pipe(ialu_reg_ialu);
 7183 %}
 7184 
 7185 instruct cmpLTMask_reg_reg( iRegI dst, iRegI p, iRegI q, flagsReg ccr ) %{
 7186   match(Set dst (CmpLTMask p q));
 7187   effect( KILL ccr );
 7188   ins_cost(DEFAULT_COST*3);
 7189   format %{ &quot;CMP    $p,$q\n\t&quot;
 7190             &quot;MOV    $dst, #0\n\t&quot;
 7191             &quot;MOV.lt $dst, #-1&quot; %}
 7192   ins_encode %{
 7193     __ cmp($p$$Register, $q$$Register);
 7194     __ mov($dst$$Register, 0);
 7195     __ mvn($dst$$Register, 0, lt);
 7196   %}
 7197   ins_pipe(ialu_reg_reg_ialu);
 7198 %}
 7199 
 7200 instruct cmpLTMask_reg_imm( iRegI dst, iRegI p, aimmI q, flagsReg ccr ) %{
 7201   match(Set dst (CmpLTMask p q));
 7202   effect( KILL ccr );
 7203   ins_cost(DEFAULT_COST*3);
 7204   format %{ &quot;CMP    $p,$q\n\t&quot;
 7205             &quot;MOV    $dst, #0\n\t&quot;
 7206             &quot;MOV.lt $dst, #-1&quot; %}
 7207   ins_encode %{
 7208     __ cmp($p$$Register, $q$$constant);
 7209     __ mov($dst$$Register, 0);
 7210     __ mvn($dst$$Register, 0, lt);
 7211   %}
 7212   ins_pipe(ialu_reg_reg_ialu);
 7213 %}
 7214 
 7215 instruct cadd_cmpLTMask3( iRegI p, iRegI q, iRegI y, iRegI z, flagsReg ccr ) %{
 7216   match(Set z (AddI (AndI (CmpLTMask p q) y) z));
 7217   effect( KILL ccr );
 7218   ins_cost(DEFAULT_COST*2);
 7219   format %{ &quot;CMP    $p,$q\n\t&quot;
 7220             &quot;ADD.lt $z,$y,$z&quot; %}
 7221   ins_encode %{
 7222     __ cmp($p$$Register, $q$$Register);
 7223     __ add($z$$Register, $y$$Register, $z$$Register, lt);
 7224   %}
 7225   ins_pipe( cadd_cmpltmask );
 7226 %}
 7227 
 7228 // FIXME: remove unused &quot;dst&quot;
 7229 instruct cadd_cmpLTMask4( iRegI dst, iRegI p, aimmI q, iRegI y, iRegI z, flagsReg ccr ) %{
 7230   match(Set z (AddI (AndI (CmpLTMask p q) y) z));
 7231   effect( KILL ccr );
 7232   ins_cost(DEFAULT_COST*2);
 7233   format %{ &quot;CMP    $p,$q\n\t&quot;
 7234             &quot;ADD.lt $z,$y,$z&quot; %}
 7235   ins_encode %{
 7236     __ cmp($p$$Register, $q$$constant);
 7237     __ add($z$$Register, $y$$Register, $z$$Register, lt);
 7238   %}
 7239   ins_pipe( cadd_cmpltmask );
 7240 %}
 7241 
 7242 instruct cadd_cmpLTMask( iRegI p, iRegI q, iRegI y, flagsReg ccr ) %{
 7243   match(Set p (AddI (AndI (CmpLTMask p q) y) (SubI p q)));
 7244   effect( KILL ccr );
 7245   ins_cost(DEFAULT_COST*2);
 7246   format %{ &quot;SUBS   $p,$p,$q\n\t&quot;
 7247             &quot;ADD.lt $p,$y,$p&quot; %}
 7248   ins_encode %{
 7249     __ subs($p$$Register, $p$$Register, $q$$Register);
 7250     __ add($p$$Register, $y$$Register, $p$$Register, lt);
 7251   %}
 7252   ins_pipe( cadd_cmpltmask );
 7253 %}
 7254 
 7255 //----------Arithmetic Conversion Instructions---------------------------------
 7256 // The conversions operations are all Alpha sorted.  Please keep it that way!
 7257 
 7258 instruct convD2F_reg(regF dst, regD src) %{
 7259   match(Set dst (ConvD2F src));
 7260   size(4);
 7261   format %{ &quot;FCVTSD  $dst,$src&quot; %}
 7262   ins_encode %{
 7263     __ convert_d2f($dst$$FloatRegister, $src$$FloatRegister);
 7264   %}
 7265   ins_pipe(fcvtD2F);
 7266 %}
 7267 
 7268 // Convert a double to an int in a float register.
 7269 // If the double is a NAN, stuff a zero in instead.
 7270 
 7271 instruct convD2I_reg_reg(iRegI dst, regD src, regF tmp) %{
 7272   match(Set dst (ConvD2I src));
 7273   effect( TEMP tmp );
 7274   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7275   format %{ &quot;FTOSIZD  $tmp,$src\n\t&quot;
 7276             &quot;FMRS     $dst, $tmp&quot; %}
 7277   ins_encode %{
 7278     __ ftosizd($tmp$$FloatRegister, $src$$FloatRegister);
 7279     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 7280   %}
 7281   ins_pipe(fcvtD2I);
 7282 %}
 7283 
 7284 // Convert a double to a long in a double register.
 7285 // If the double is a NAN, stuff a zero in instead.
 7286 
 7287 // Double to Long conversion
 7288 instruct convD2L_reg(R0R1RegL dst, regD src) %{
 7289   match(Set dst (ConvD2L src));
 7290   effect(CALL);
 7291   ins_cost(MEMORY_REF_COST); // FIXME
 7292   format %{ &quot;convD2L    $dst,$src\t ! call to SharedRuntime::d2l&quot; %}
 7293   ins_encode %{
 7294 #ifndef __ABI_HARD__
 7295     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), $src$$FloatRegister);
 7296 #else
 7297     if ($src$$FloatRegister != D0) {
 7298       __ mov_double(D0, $src$$FloatRegister);
 7299     }
 7300 #endif
 7301     address target = CAST_FROM_FN_PTR(address, SharedRuntime::d2l);
 7302     __ call(target, relocInfo::runtime_call_type);
 7303   %}
 7304   ins_pipe(fcvtD2L);
 7305 %}
 7306 
 7307 instruct convF2D_reg(regD dst, regF src) %{
 7308   match(Set dst (ConvF2D src));
 7309   size(4);
 7310   format %{ &quot;FCVTDS  $dst,$src&quot; %}
 7311   ins_encode %{
 7312     __ convert_f2d($dst$$FloatRegister, $src$$FloatRegister);
 7313   %}
 7314   ins_pipe(fcvtF2D);
 7315 %}
 7316 
 7317 instruct convF2I_reg_reg(iRegI dst, regF src, regF tmp) %{
 7318   match(Set dst (ConvF2I src));
 7319   effect( TEMP tmp );
 7320   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7321   size(8);
 7322   format %{ &quot;FTOSIZS  $tmp,$src\n\t&quot;
 7323             &quot;FMRS     $dst, $tmp&quot; %}
 7324   ins_encode %{
 7325     __ ftosizs($tmp$$FloatRegister, $src$$FloatRegister);
 7326     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 7327   %}
 7328   ins_pipe(fcvtF2I);
 7329 %}
 7330 
 7331 // Float to Long conversion
 7332 instruct convF2L_reg(R0R1RegL dst, regF src, R0RegI arg1) %{
 7333   match(Set dst (ConvF2L src));
 7334   ins_cost(DEFAULT_COST*2 + MEMORY_REF_COST*2 + BRANCH_COST); // FIXME
 7335   effect(CALL);
 7336   format %{ &quot;convF2L  $dst,$src\t! call to SharedRuntime::f2l&quot; %}
 7337   ins_encode %{
 7338 #ifndef __ABI_HARD__
 7339     __ fmrs($arg1$$Register, $src$$FloatRegister);
 7340 #else
 7341     if($src$$FloatRegister != S0) {
 7342       __ mov_float(S0, $src$$FloatRegister);
 7343     }
 7344 #endif
 7345     address target = CAST_FROM_FN_PTR(address, SharedRuntime::f2l);
 7346     __ call(target, relocInfo::runtime_call_type);
 7347   %}
 7348   ins_pipe(fcvtF2L);
 7349 %}
 7350 
 7351 instruct convI2D_reg_reg(iRegI src, regD_low dst) %{
 7352   match(Set dst (ConvI2D src));
 7353   ins_cost(DEFAULT_COST + MEMORY_REF_COST); // FIXME
 7354   size(8);
 7355   format %{ &quot;FMSR     $dst,$src \n\t&quot;
 7356             &quot;FSITOD   $dst $dst&quot;%}
 7357   ins_encode %{
 7358       __ fmsr($dst$$FloatRegister, $src$$Register);
 7359       __ fsitod($dst$$FloatRegister, $dst$$FloatRegister);
 7360   %}
 7361   ins_pipe(fcvtI2D);
 7362 %}
 7363 
 7364 instruct convI2F_reg_reg( regF dst, iRegI src ) %{
 7365   match(Set dst (ConvI2F src));
 7366   ins_cost(DEFAULT_COST + MEMORY_REF_COST); // FIXME
 7367   size(8);
 7368   format %{ &quot;FMSR     $dst,$src \n\t&quot;
 7369             &quot;FSITOS   $dst, $dst&quot;%}
 7370   ins_encode %{
 7371       __ fmsr($dst$$FloatRegister, $src$$Register);
 7372       __ fsitos($dst$$FloatRegister, $dst$$FloatRegister);
 7373   %}
 7374   ins_pipe(fcvtI2F);
 7375 %}
 7376 
 7377 instruct convI2L_reg(iRegL dst, iRegI src) %{
 7378   match(Set dst (ConvI2L src));
 7379   size(8);
 7380   format %{ &quot;MOV    $dst.lo, $src \n\t&quot;
 7381             &quot;ASR    $dst.hi,$src,31\t! int-&gt;long&quot; %}
 7382   ins_encode %{
 7383     __ mov($dst$$Register, $src$$Register);
 7384     __ mov($dst$$Register-&gt;successor(), AsmOperand($src$$Register, asr, 31));
 7385   %}
 7386   ins_pipe(ialu_reg_reg);
 7387 %}
 7388 
 7389 // Zero-extend convert int to long
 7390 instruct convI2L_reg_zex(iRegL dst, iRegI src, immL_32bits mask ) %{
 7391   match(Set dst (AndL (ConvI2L src) mask) );
 7392   size(8);
 7393   format %{ &quot;MOV    $dst.lo,$src.lo\t! zero-extend int to long\n\t&quot;
 7394             &quot;MOV    $dst.hi, 0&quot;%}
 7395   ins_encode %{
 7396     __ mov($dst$$Register, $src$$Register);
 7397     __ mov($dst$$Register-&gt;successor(), 0);
 7398   %}
 7399   ins_pipe(ialu_reg_reg);
 7400 %}
 7401 
 7402 // Zero-extend long
 7403 instruct zerox_long(iRegL dst, iRegL src, immL_32bits mask ) %{
 7404   match(Set dst (AndL src mask) );
 7405   size(8);
 7406   format %{ &quot;MOV    $dst.lo,$src.lo\t! zero-extend long\n\t&quot;
 7407             &quot;MOV    $dst.hi, 0&quot;%}
 7408   ins_encode %{
 7409     __ mov($dst$$Register, $src$$Register);
 7410     __ mov($dst$$Register-&gt;successor(), 0);
 7411   %}
 7412   ins_pipe(ialu_reg_reg);
 7413 %}
 7414 
 7415 instruct MoveF2I_reg_reg(iRegI dst, regF src) %{
 7416   match(Set dst (MoveF2I src));
 7417   effect(DEF dst, USE src);
 7418   ins_cost(MEMORY_REF_COST); // FIXME
 7419 
 7420   size(4);
 7421   format %{ &quot;FMRS   $dst,$src\t! MoveF2I&quot; %}
 7422   ins_encode %{
 7423     __ fmrs($dst$$Register, $src$$FloatRegister);
 7424   %}
 7425   ins_pipe(iload_mem); // FIXME
 7426 %}
 7427 
 7428 instruct MoveI2F_reg_reg(regF dst, iRegI src) %{
 7429   match(Set dst (MoveI2F src));
 7430   ins_cost(MEMORY_REF_COST); // FIXME
 7431 
 7432   size(4);
 7433   format %{ &quot;FMSR   $dst,$src\t! MoveI2F&quot; %}
 7434   ins_encode %{
 7435     __ fmsr($dst$$FloatRegister, $src$$Register);
 7436   %}
 7437   ins_pipe(iload_mem); // FIXME
 7438 %}
 7439 
 7440 instruct MoveD2L_reg_reg(iRegL dst, regD src) %{
 7441   match(Set dst (MoveD2L src));
 7442   effect(DEF dst, USE src);
 7443   ins_cost(MEMORY_REF_COST); // FIXME
 7444 
 7445   size(4);
 7446   format %{ &quot;FMRRD    $dst,$src\t! MoveD2L&quot; %}
 7447   ins_encode %{
 7448     __ fmrrd($dst$$Register, $dst$$Register-&gt;successor(), $src$$FloatRegister);
 7449   %}
 7450   ins_pipe(iload_mem); // FIXME
 7451 %}
 7452 
 7453 instruct MoveL2D_reg_reg(regD dst, iRegL src) %{
 7454   match(Set dst (MoveL2D src));
 7455   effect(DEF dst, USE src);
 7456   ins_cost(MEMORY_REF_COST); // FIXME
 7457 
 7458   size(4);
 7459   format %{ &quot;FMDRR   $dst,$src\t! MoveL2D&quot; %}
 7460   ins_encode %{
 7461     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 7462   %}
 7463   ins_pipe(ialu_reg_reg); // FIXME
 7464 %}
 7465 
 7466 //-----------
 7467 // Long to Double conversion
 7468 
 7469 // Magic constant, 0x43300000
 7470 instruct loadConI_x43300000(iRegI dst) %{
 7471   effect(DEF dst);
 7472   size(8);
 7473   format %{ &quot;MOV_SLOW  $dst,0x43300000\t! 2^52&quot; %}
 7474   ins_encode %{
 7475     __ mov_slow($dst$$Register, 0x43300000);
 7476   %}
 7477   ins_pipe(ialu_none);
 7478 %}
 7479 
 7480 // Magic constant, 0x41f00000
 7481 instruct loadConI_x41f00000(iRegI dst) %{
 7482   effect(DEF dst);
 7483   size(8);
 7484   format %{ &quot;MOV_SLOW  $dst, 0x41f00000\t! 2^32&quot; %}
 7485   ins_encode %{
 7486     __ mov_slow($dst$$Register, 0x41f00000);
 7487   %}
 7488   ins_pipe(ialu_none);
 7489 %}
 7490 
 7491 instruct loadConI_x0(iRegI dst) %{
 7492   effect(DEF dst);
 7493   size(4);
 7494   format %{ &quot;MOV  $dst, 0x0\t! 0&quot; %}
 7495   ins_encode %{
 7496     __ mov($dst$$Register, 0);
 7497   %}
 7498   ins_pipe(ialu_none);
 7499 %}
 7500 
 7501 // Construct a double from two float halves
 7502 instruct regDHi_regDLo_to_regD(regD_low dst, regD_low src1, regD_low src2) %{
 7503   effect(DEF dst, USE src1, USE src2);
 7504   size(8);
 7505   format %{ &quot;FCPYS  $dst.hi,$src1.hi\n\t&quot;
 7506             &quot;FCPYS  $dst.lo,$src2.lo&quot; %}
 7507   ins_encode %{
 7508     __ fcpys($dst$$FloatRegister-&gt;successor(), $src1$$FloatRegister-&gt;successor());
 7509     __ fcpys($dst$$FloatRegister, $src2$$FloatRegister);
 7510   %}
 7511   ins_pipe(faddD_reg_reg);
 7512 %}
 7513 
 7514 // Convert integer in high half of a double register (in the lower half of
 7515 // the double register file) to double
 7516 instruct convI2D_regDHi_regD(regD dst, regD_low src) %{
 7517   effect(DEF dst, USE src);
 7518   size(4);
 7519   format %{ &quot;FSITOD  $dst,$src&quot; %}
 7520   ins_encode %{
 7521     __ fsitod($dst$$FloatRegister, $src$$FloatRegister-&gt;successor());
 7522   %}
 7523   ins_pipe(fcvtLHi2D);
 7524 %}
 7525 
 7526 // Add float double precision
 7527 instruct addD_regD_regD(regD dst, regD src1, regD src2) %{
 7528   effect(DEF dst, USE src1, USE src2);
 7529   size(4);
 7530   format %{ &quot;FADDD  $dst,$src1,$src2&quot; %}
 7531   ins_encode %{
 7532     __ add_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7533   %}
 7534   ins_pipe(faddD_reg_reg);
 7535 %}
 7536 
 7537 // Sub float double precision
 7538 instruct subD_regD_regD(regD dst, regD src1, regD src2) %{
 7539   effect(DEF dst, USE src1, USE src2);
 7540   size(4);
 7541   format %{ &quot;FSUBD  $dst,$src1,$src2&quot; %}
 7542   ins_encode %{
 7543     __ sub_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7544   %}
 7545   ins_pipe(faddD_reg_reg);
 7546 %}
 7547 
 7548 // Mul float double precision
 7549 instruct mulD_regD_regD(regD dst, regD src1, regD src2) %{
 7550   effect(DEF dst, USE src1, USE src2);
 7551   size(4);
 7552   format %{ &quot;FMULD  $dst,$src1,$src2&quot; %}
 7553   ins_encode %{
 7554     __ mul_double($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 7555   %}
 7556   ins_pipe(fmulD_reg_reg);
 7557 %}
 7558 
 7559 instruct regL_to_regD(regD dst, iRegL src) %{
 7560   // No match rule to avoid chain rule match.
 7561   effect(DEF dst, USE src);
 7562   ins_cost(MEMORY_REF_COST);
 7563   size(4);
 7564   format %{ &quot;FMDRR   $dst,$src\t! regL to regD&quot; %}
 7565   ins_encode %{
 7566     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 7567   %}
 7568   ins_pipe(ialu_reg_reg); // FIXME
 7569 %}
 7570 
 7571 instruct regI_regI_to_regD(regD dst, iRegI src1, iRegI src2) %{
 7572   // No match rule to avoid chain rule match.
 7573   effect(DEF dst, USE src1, USE src2);
 7574   ins_cost(MEMORY_REF_COST);
 7575   size(4);
 7576   format %{ &quot;FMDRR   $dst,$src1,$src2\t! regI,regI to regD&quot; %}
 7577   ins_encode %{
 7578     __ fmdrr($dst$$FloatRegister, $src1$$Register, $src2$$Register);
 7579   %}
 7580   ins_pipe(ialu_reg_reg); // FIXME
 7581 %}
 7582 
 7583 instruct convL2D_reg_slow_fxtof(regD dst, iRegL src) %{
 7584   match(Set dst (ConvL2D src));
 7585   ins_cost(DEFAULT_COST*8 + MEMORY_REF_COST*6); // FIXME
 7586 
 7587   expand %{
 7588     regD_low   tmpsrc;
 7589     iRegI      ix43300000;
 7590     iRegI      ix41f00000;
 7591     iRegI      ix0;
 7592     regD_low   dx43300000;
 7593     regD       dx41f00000;
 7594     regD       tmp1;
 7595     regD_low   tmp2;
 7596     regD       tmp3;
 7597     regD       tmp4;
 7598 
 7599     regL_to_regD(tmpsrc, src);
 7600 
 7601     loadConI_x43300000(ix43300000);
 7602     loadConI_x41f00000(ix41f00000);
 7603     loadConI_x0(ix0);
 7604 
 7605     regI_regI_to_regD(dx43300000, ix0, ix43300000);
 7606     regI_regI_to_regD(dx41f00000, ix0, ix41f00000);
 7607 
 7608     convI2D_regDHi_regD(tmp1, tmpsrc);
 7609     regDHi_regDLo_to_regD(tmp2, dx43300000, tmpsrc);
 7610     subD_regD_regD(tmp3, tmp2, dx43300000);
 7611     mulD_regD_regD(tmp4, tmp1, dx41f00000);
 7612     addD_regD_regD(dst, tmp3, tmp4);
 7613   %}
 7614 %}
 7615 
 7616 instruct convL2I_reg(iRegI dst, iRegL src) %{
 7617   match(Set dst (ConvL2I src));
 7618   size(4);
 7619   format %{ &quot;MOV    $dst,$src.lo\t! long-&gt;int&quot; %}
 7620   ins_encode %{
 7621     __ mov($dst$$Register, $src$$Register);
 7622   %}
 7623   ins_pipe(ialu_move_reg_I_to_L);
 7624 %}
 7625 
 7626 // Register Shift Right Immediate
 7627 instruct shrL_reg_imm6_L2I(iRegI dst, iRegL src, immI_32_63 cnt) %{
 7628   match(Set dst (ConvL2I (RShiftL src cnt)));
 7629   size(4);
 7630   format %{ &quot;ASR    $dst,$src.hi,($cnt - 32)\t! long-&gt;int or mov if $cnt==32&quot; %}
 7631   ins_encode %{
 7632     if ($cnt$$constant == 32) {
 7633       __ mov($dst$$Register, $src$$Register-&gt;successor());
 7634     } else {
 7635       __ mov($dst$$Register, AsmOperand($src$$Register-&gt;successor(), asr, $cnt$$constant - 32));
 7636     }
 7637   %}
 7638   ins_pipe(ialu_reg_imm);
 7639 %}
 7640 
 7641 
 7642 //----------Control Flow Instructions------------------------------------------
 7643 // Compare Instructions
 7644 // Compare Integers
 7645 instruct compI_iReg(flagsReg icc, iRegI op1, iRegI op2) %{
 7646   match(Set icc (CmpI op1 op2));
 7647   effect( DEF icc, USE op1, USE op2 );
 7648 
 7649   size(4);
 7650   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7651   ins_encode %{
 7652     __ cmp_32($op1$$Register, $op2$$Register);
 7653   %}
 7654   ins_pipe(ialu_cconly_reg_reg);
 7655 %}
 7656 
 7657 #ifdef _LP64
 7658 // Compare compressed pointers
 7659 instruct compN_reg2(flagsRegU icc, iRegN op1, iRegN op2) %{
 7660   match(Set icc (CmpN op1 op2));
 7661   effect( DEF icc, USE op1, USE op2 );
 7662 
 7663   size(4);
 7664   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7665   ins_encode %{
 7666     __ cmp_32($op1$$Register, $op2$$Register);
 7667   %}
 7668   ins_pipe(ialu_cconly_reg_reg);
 7669 %}
 7670 #endif
 7671 
 7672 instruct compU_iReg(flagsRegU icc, iRegI op1, iRegI op2) %{
 7673   match(Set icc (CmpU op1 op2));
 7674 
 7675   size(4);
 7676   format %{ &quot;cmp_32 $op1,$op2\t! unsigned int&quot; %}
 7677   ins_encode %{
 7678     __ cmp_32($op1$$Register, $op2$$Register);
 7679   %}
 7680   ins_pipe(ialu_cconly_reg_reg);
 7681 %}
 7682 
 7683 instruct compI_iReg_immneg(flagsReg icc, iRegI op1, aimmIneg op2) %{
 7684   match(Set icc (CmpI op1 op2));
 7685   effect( DEF icc, USE op1 );
 7686 
 7687   size(4);
 7688   format %{ &quot;cmn_32 $op1,-$op2\t! int&quot; %}
 7689   ins_encode %{
 7690     __ cmn_32($op1$$Register, -$op2$$constant);
 7691   %}
 7692   ins_pipe(ialu_cconly_reg_imm);
 7693 %}
 7694 
 7695 instruct compI_iReg_imm(flagsReg icc, iRegI op1, aimmI op2) %{
 7696   match(Set icc (CmpI op1 op2));
 7697   effect( DEF icc, USE op1 );
 7698 
 7699   size(4);
 7700   format %{ &quot;cmp_32 $op1,$op2\t! int&quot; %}
 7701   ins_encode %{
 7702     __ cmp_32($op1$$Register, $op2$$constant);
 7703   %}
 7704   ins_pipe(ialu_cconly_reg_imm);
 7705 %}
 7706 
 7707 instruct testI_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immI0 zero ) %{
 7708   match(Set icc (CmpI (AndI op1 op2) zero));
 7709   size(4);
 7710   format %{ &quot;tst_32 $op2,$op1&quot; %}
 7711 
 7712   ins_encode %{
 7713     __ tst_32($op1$$Register, $op2$$Register);
 7714   %}
 7715   ins_pipe(ialu_cconly_reg_reg_zero);
 7716 %}
 7717 
 7718 instruct testshlI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7719   match(Set icc (CmpI (AndI op1 (LShiftI op2 op3)) zero));
 7720   size(4);
 7721   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7722 
 7723   ins_encode %{
 7724     __ tst($op1$$Register, AsmOperand($op2$$Register, lsl, $op3$$Register));
 7725   %}
 7726   ins_pipe(ialu_cconly_reg_reg_zero);
 7727 %}
 7728 
 7729 instruct testshlI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7730   match(Set icc (CmpI (AndI op1 (LShiftI op2 op3)) zero));
 7731   size(4);
 7732   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7733 
 7734   ins_encode %{
 7735     __ tst_32($op1$$Register, AsmOperand($op2$$Register, lsl, $op3$$constant));
 7736   %}
 7737   ins_pipe(ialu_cconly_reg_reg_zero);
 7738 %}
 7739 
 7740 instruct testsarI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7741   match(Set icc (CmpI (AndI op1 (RShiftI op2 op3)) zero));
 7742   size(4);
 7743   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7744 
 7745   ins_encode %{
 7746     __ tst($op1$$Register, AsmOperand($op2$$Register, asr, $op3$$Register));
 7747   %}
 7748   ins_pipe(ialu_cconly_reg_reg_zero);
 7749 %}
 7750 
 7751 instruct testsarI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7752   match(Set icc (CmpI (AndI op1 (RShiftI op2 op3)) zero));
 7753   size(4);
 7754   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7755 
 7756   ins_encode %{
 7757     __ tst_32($op1$$Register, AsmOperand($op2$$Register, asr, $op3$$constant));
 7758   %}
 7759   ins_pipe(ialu_cconly_reg_reg_zero);
 7760 %}
 7761 
 7762 instruct testshrI_reg_reg_reg( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, iRegI op3, immI0 zero ) %{
 7763   match(Set icc (CmpI (AndI op1 (URShiftI op2 op3)) zero));
 7764   size(4);
 7765   format %{ &quot;TST   $op2,$op1&lt;&lt;$op3&quot; %}
 7766 
 7767   ins_encode %{
 7768     __ tst($op1$$Register, AsmOperand($op2$$Register, lsr, $op3$$Register));
 7769   %}
 7770   ins_pipe(ialu_cconly_reg_reg_zero);
 7771 %}
 7772 
 7773 instruct testshrI_reg_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, iRegI op2, immU5 op3, immI0 zero ) %{
 7774   match(Set icc (CmpI (AndI op1 (URShiftI op2 op3)) zero));
 7775   size(4);
 7776   format %{ &quot;tst_32 $op2,$op1&lt;&lt;$op3&quot; %}
 7777 
 7778   ins_encode %{
 7779     __ tst_32($op1$$Register, AsmOperand($op2$$Register, lsr, $op3$$constant));
 7780   %}
 7781   ins_pipe(ialu_cconly_reg_reg_zero);
 7782 %}
 7783 
 7784 instruct testI_reg_imm( flagsReg_EQNELTGE icc, iRegI op1, limmI op2, immI0 zero ) %{
 7785   match(Set icc (CmpI (AndI op1 op2) zero));
 7786   size(4);
 7787   format %{ &quot;tst_32 $op2,$op1&quot; %}
 7788 
 7789   ins_encode %{
 7790     __ tst_32($op1$$Register, $op2$$constant);
 7791   %}
 7792   ins_pipe(ialu_cconly_reg_imm_zero);
 7793 %}
 7794 
 7795 instruct compL_reg_reg_LTGE(flagsRegL_LTGE xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7796   match(Set xcc (CmpL op1 op2));
 7797   effect( DEF xcc, USE op1, USE op2, TEMP tmp );
 7798 
 7799   size(8);
 7800   format %{ &quot;SUBS    $tmp,$op1.low,$op2.low\t\t! long\n\t&quot;
 7801             &quot;SBCS    $tmp,$op1.hi,$op2.hi&quot; %}
 7802   ins_encode %{
 7803     __ subs($tmp$$Register, $op1$$Register, $op2$$Register);
 7804     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7805   %}
 7806   ins_pipe(ialu_cconly_reg_reg);
 7807 %}
 7808 
 7809 instruct compUL_reg_reg_LTGE(flagsRegUL_LTGE xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7810   match(Set xcc (CmpUL op1 op2));
 7811   effect(DEF xcc, USE op1, USE op2, TEMP tmp);
 7812 
 7813   size(8);
 7814   format %{ &quot;SUBS    $tmp,$op1.low,$op2.low\t\t! unsigned long\n\t&quot;
 7815             &quot;SBCS    $tmp,$op1.hi,$op2.hi&quot; %}
 7816   ins_encode %{
 7817     __ subs($tmp$$Register, $op1$$Register, $op2$$Register);
 7818     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7819   %}
 7820   ins_pipe(ialu_cconly_reg_reg);
 7821 %}
 7822 
 7823 instruct compL_reg_reg_EQNE(flagsRegL_EQNE xcc, iRegL op1, iRegL op2) %{
 7824   match(Set xcc (CmpL op1 op2));
 7825   effect( DEF xcc, USE op1, USE op2 );
 7826 
 7827   size(8);
 7828   format %{ &quot;TEQ    $op1.hi,$op2.hi\t\t! long\n\t&quot;
 7829             &quot;TEQ.eq $op1.lo,$op2.lo&quot; %}
 7830   ins_encode %{
 7831     __ teq($op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7832     __ teq($op1$$Register, $op2$$Register, eq);
 7833   %}
 7834   ins_pipe(ialu_cconly_reg_reg);
 7835 %}
 7836 
 7837 instruct compL_reg_reg_LEGT(flagsRegL_LEGT xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7838   match(Set xcc (CmpL op1 op2));
 7839   effect( DEF xcc, USE op1, USE op2, TEMP tmp );
 7840 
 7841   size(8);
 7842   format %{ &quot;SUBS    $tmp,$op2.low,$op1.low\t\t! long\n\t&quot;
 7843             &quot;SBCS    $tmp,$op2.hi,$op1.hi&quot; %}
 7844   ins_encode %{
 7845     __ subs($tmp$$Register, $op2$$Register, $op1$$Register);
 7846     __ sbcs($tmp$$Register-&gt;successor(), $op2$$Register-&gt;successor(), $op1$$Register-&gt;successor());
 7847   %}
 7848   ins_pipe(ialu_cconly_reg_reg);
 7849 %}
 7850 
 7851 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7852 // (hi($con$$constant), lo($con$$constant)) becomes
 7853 instruct compL_reg_con_LTGE(flagsRegL_LTGE xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7854   match(Set xcc (CmpL op1 con));
 7855   effect( DEF xcc, USE op1, USE con, TEMP tmp );
 7856 
 7857   size(8);
 7858   format %{ &quot;SUBS    $tmp,$op1.low,$con\t\t! long\n\t&quot;
 7859             &quot;SBCS    $tmp,$op1.hi,0&quot; %}
 7860   ins_encode %{
 7861     __ subs($tmp$$Register, $op1$$Register, $con$$constant);
 7862     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7863   %}
 7864 
 7865   ins_pipe(ialu_cconly_reg_reg);
 7866 %}
 7867 
 7868 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7869 // (hi($con$$constant), lo($con$$constant)) becomes
 7870 instruct compL_reg_con_EQNE(flagsRegL_EQNE xcc, iRegL op1, immLlowRot con) %{
 7871   match(Set xcc (CmpL op1 con));
 7872   effect( DEF xcc, USE op1, USE con );
 7873 
 7874   size(8);
 7875   format %{ &quot;TEQ    $op1.hi,0\t\t! long\n\t&quot;
 7876             &quot;TEQ.eq $op1.lo,$con&quot; %}
 7877   ins_encode %{
 7878     __ teq($op1$$Register-&gt;successor(), 0);
 7879     __ teq($op1$$Register, $con$$constant, eq);
 7880   %}
 7881 
 7882   ins_pipe(ialu_cconly_reg_reg);
 7883 %}
 7884 
 7885 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7886 // (hi($con$$constant), lo($con$$constant)) becomes
 7887 instruct compL_reg_con_LEGT(flagsRegL_LEGT xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7888   match(Set xcc (CmpL op1 con));
 7889   effect( DEF xcc, USE op1, USE con, TEMP tmp );
 7890 
 7891   size(8);
 7892   format %{ &quot;RSBS    $tmp,$op1.low,$con\t\t! long\n\t&quot;
 7893             &quot;RSCS    $tmp,$op1.hi,0&quot; %}
 7894   ins_encode %{
 7895     __ rsbs($tmp$$Register, $op1$$Register, $con$$constant);
 7896     __ rscs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7897   %}
 7898 
 7899   ins_pipe(ialu_cconly_reg_reg);
 7900 %}
 7901 
 7902 instruct compUL_reg_reg_EQNE(flagsRegUL_EQNE xcc, iRegL op1, iRegL op2) %{
 7903   match(Set xcc (CmpUL op1 op2));
 7904   effect(DEF xcc, USE op1, USE op2);
 7905 
 7906   size(8);
 7907   format %{ &quot;TEQ    $op1.hi,$op2.hi\t\t! unsigned long\n\t&quot;
 7908             &quot;TEQ.eq $op1.lo,$op2.lo&quot; %}
 7909   ins_encode %{
 7910     __ teq($op1$$Register-&gt;successor(), $op2$$Register-&gt;successor());
 7911     __ teq($op1$$Register, $op2$$Register, eq);
 7912   %}
 7913   ins_pipe(ialu_cconly_reg_reg);
 7914 %}
 7915 
 7916 instruct compUL_reg_reg_LEGT(flagsRegUL_LEGT xcc, iRegL op1, iRegL op2, iRegL tmp) %{
 7917   match(Set xcc (CmpUL op1 op2));
 7918   effect(DEF xcc, USE op1, USE op2, TEMP tmp);
 7919 
 7920   size(8);
 7921   format %{ &quot;SUBS    $tmp,$op2.low,$op1.low\t\t! unsigned long\n\t&quot;
 7922             &quot;SBCS    $tmp,$op2.hi,$op1.hi&quot; %}
 7923   ins_encode %{
 7924     __ subs($tmp$$Register, $op2$$Register, $op1$$Register);
 7925     __ sbcs($tmp$$Register-&gt;successor(), $op2$$Register-&gt;successor(), $op1$$Register-&gt;successor());
 7926   %}
 7927   ins_pipe(ialu_cconly_reg_reg);
 7928 %}
 7929 
 7930 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7931 // (hi($con$$constant), lo($con$$constant)) becomes
 7932 instruct compUL_reg_con_LTGE(flagsRegUL_LTGE xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7933   match(Set xcc (CmpUL op1 con));
 7934   effect(DEF xcc, USE op1, USE con, TEMP tmp);
 7935 
 7936   size(8);
 7937   format %{ &quot;SUBS    $tmp,$op1.low,$con\t\t! unsigned long\n\t&quot;
 7938             &quot;SBCS    $tmp,$op1.hi,0&quot; %}
 7939   ins_encode %{
 7940     __ subs($tmp$$Register, $op1$$Register, $con$$constant);
 7941     __ sbcs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7942   %}
 7943 
 7944   ins_pipe(ialu_cconly_reg_reg);
 7945 %}
 7946 
 7947 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7948 // (hi($con$$constant), lo($con$$constant)) becomes
 7949 instruct compUL_reg_con_EQNE(flagsRegUL_EQNE xcc, iRegL op1, immLlowRot con) %{
 7950   match(Set xcc (CmpUL op1 con));
 7951   effect(DEF xcc, USE op1, USE con);
 7952 
 7953   size(8);
 7954   format %{ &quot;TEQ    $op1.hi,0\t\t! unsigned long\n\t&quot;
 7955             &quot;TEQ.eq $op1.lo,$con&quot; %}
 7956   ins_encode %{
 7957     __ teq($op1$$Register-&gt;successor(), 0);
 7958     __ teq($op1$$Register, $con$$constant, eq);
 7959   %}
 7960 
 7961   ins_pipe(ialu_cconly_reg_reg);
 7962 %}
 7963 
 7964 // TODO: try immLRot2 instead, (0, $con$$constant) becomes
 7965 // (hi($con$$constant), lo($con$$constant)) becomes
 7966 instruct compUL_reg_con_LEGT(flagsRegUL_LEGT xcc, iRegL op1, immLlowRot con, iRegL tmp) %{
 7967   match(Set xcc (CmpUL op1 con));
 7968   effect(DEF xcc, USE op1, USE con, TEMP tmp);
 7969 
 7970   size(8);
 7971   format %{ &quot;RSBS    $tmp,$op1.low,$con\t\t! unsigned long\n\t&quot;
 7972             &quot;RSCS    $tmp,$op1.hi,0&quot; %}
 7973   ins_encode %{
 7974     __ rsbs($tmp$$Register, $op1$$Register, $con$$constant);
 7975     __ rscs($tmp$$Register-&gt;successor(), $op1$$Register-&gt;successor(), 0);
 7976   %}
 7977 
 7978   ins_pipe(ialu_cconly_reg_reg);
 7979 %}
 7980 
 7981 /* instruct testL_reg_reg(flagsRegL xcc, iRegL op1, iRegL op2, immL0 zero) %{ */
 7982 /*   match(Set xcc (CmpL (AndL op1 op2) zero)); */
 7983 /*   ins_encode %{ */
 7984 /*     __ stop(&quot;testL_reg_reg unimplemented&quot;); */
 7985 /*   %} */
 7986 /*   ins_pipe(ialu_cconly_reg_reg); */
 7987 /* %} */
 7988 
 7989 /* // useful for checking the alignment of a pointer: */
 7990 /* instruct testL_reg_con(flagsRegL xcc, iRegL op1, immLlowRot con, immL0 zero) %{ */
 7991 /*   match(Set xcc (CmpL (AndL op1 con) zero)); */
 7992 /*   ins_encode %{ */
 7993 /*     __ stop(&quot;testL_reg_con unimplemented&quot;); */
 7994 /*   %} */
 7995 /*   ins_pipe(ialu_cconly_reg_reg); */
 7996 /* %} */
 7997 
 7998 instruct compU_iReg_imm(flagsRegU icc, iRegI op1, aimmU31 op2 ) %{
 7999   match(Set icc (CmpU op1 op2));
 8000 
 8001   size(4);
 8002   format %{ &quot;cmp_32 $op1,$op2\t! unsigned&quot; %}
 8003   ins_encode %{
 8004     __ cmp_32($op1$$Register, $op2$$constant);
 8005   %}
 8006   ins_pipe(ialu_cconly_reg_imm);
 8007 %}
 8008 
 8009 // Compare Pointers
 8010 instruct compP_iRegP(flagsRegP pcc, iRegP op1, iRegP op2 ) %{
 8011   match(Set pcc (CmpP op1 op2));
 8012 
 8013   size(4);
 8014   format %{ &quot;CMP    $op1,$op2\t! ptr&quot; %}
 8015   ins_encode %{
 8016     __ cmp($op1$$Register, $op2$$Register);
 8017   %}
 8018   ins_pipe(ialu_cconly_reg_reg);
 8019 %}
 8020 
 8021 instruct compP_iRegP_imm(flagsRegP pcc, iRegP op1, aimmP op2 ) %{
 8022   match(Set pcc (CmpP op1 op2));
 8023 
 8024   size(4);
 8025   format %{ &quot;CMP    $op1,$op2\t! ptr&quot; %}
 8026   ins_encode %{
 8027     assert($op2$$constant == 0 || _opnds[2]-&gt;constant_reloc() == relocInfo::none, &quot;reloc in cmp?&quot;);
 8028     __ cmp($op1$$Register, $op2$$constant);
 8029   %}
 8030   ins_pipe(ialu_cconly_reg_imm);
 8031 %}
 8032 
 8033 //----------Max and Min--------------------------------------------------------
 8034 // Min Instructions
 8035 // Conditional move for min
 8036 instruct cmovI_reg_lt( iRegI op2, iRegI op1, flagsReg icc ) %{
 8037   effect( USE_DEF op2, USE op1, USE icc );
 8038 
 8039   size(4);
 8040   format %{ &quot;MOV.lt  $op2,$op1\t! min&quot; %}
 8041   ins_encode %{
 8042     __ mov($op2$$Register, $op1$$Register, lt);
 8043   %}
 8044   ins_pipe(ialu_reg_flags);
 8045 %}
 8046 
 8047 // Min Register with Register.
 8048 instruct minI_eReg(iRegI op1, iRegI op2) %{
 8049   match(Set op2 (MinI op1 op2));
 8050   ins_cost(DEFAULT_COST*2);
 8051   expand %{
 8052     flagsReg icc;
 8053     compI_iReg(icc,op1,op2);
 8054     cmovI_reg_lt(op2,op1,icc);
 8055   %}
 8056 %}
 8057 
 8058 // Max Instructions
 8059 // Conditional move for max
 8060 instruct cmovI_reg_gt( iRegI op2, iRegI op1, flagsReg icc ) %{
 8061   effect( USE_DEF op2, USE op1, USE icc );
 8062   format %{ &quot;MOV.gt  $op2,$op1\t! max&quot; %}
 8063   ins_encode %{
 8064     __ mov($op2$$Register, $op1$$Register, gt);
 8065   %}
 8066   ins_pipe(ialu_reg_flags);
 8067 %}
 8068 
 8069 // Max Register with Register
 8070 instruct maxI_eReg(iRegI op1, iRegI op2) %{
 8071   match(Set op2 (MaxI op1 op2));
 8072   ins_cost(DEFAULT_COST*2);
 8073   expand %{
 8074     flagsReg icc;
 8075     compI_iReg(icc,op1,op2);
 8076     cmovI_reg_gt(op2,op1,icc);
 8077   %}
 8078 %}
 8079 
 8080 
 8081 //----------Float Compares----------------------------------------------------
 8082 // Compare floating, generate condition code
 8083 instruct cmpF_cc(flagsRegF fcc, flagsReg icc, regF src1, regF src2) %{
 8084   match(Set icc (CmpF src1 src2));
 8085   effect(KILL fcc);
 8086 
 8087   size(8);
 8088   format %{ &quot;FCMPs  $src1,$src2\n\t&quot;
 8089             &quot;FMSTAT&quot; %}
 8090   ins_encode %{
 8091     __ fcmps($src1$$FloatRegister, $src2$$FloatRegister);
 8092     __ fmstat();
 8093   %}
 8094   ins_pipe(faddF_fcc_reg_reg_zero);
 8095 %}
 8096 
 8097 instruct cmpF0_cc(flagsRegF fcc, flagsReg icc, regF src1, immF0 src2) %{
 8098   match(Set icc (CmpF src1 src2));
 8099   effect(KILL fcc);
 8100 
 8101   size(8);
 8102   format %{ &quot;FCMPs  $src1,$src2\n\t&quot;
 8103             &quot;FMSTAT&quot; %}
 8104   ins_encode %{
 8105     __ fcmpzs($src1$$FloatRegister);
 8106     __ fmstat();
 8107   %}
 8108   ins_pipe(faddF_fcc_reg_reg_zero);
 8109 %}
 8110 
 8111 instruct cmpD_cc(flagsRegF fcc, flagsReg icc, regD src1, regD src2) %{
 8112   match(Set icc (CmpD src1 src2));
 8113   effect(KILL fcc);
 8114 
 8115   size(8);
 8116   format %{ &quot;FCMPd  $src1,$src2 \n\t&quot;
 8117             &quot;FMSTAT&quot; %}
 8118   ins_encode %{
 8119     __ fcmpd($src1$$FloatRegister, $src2$$FloatRegister);
 8120     __ fmstat();
 8121   %}
 8122   ins_pipe(faddD_fcc_reg_reg_zero);
 8123 %}
 8124 
 8125 instruct cmpD0_cc(flagsRegF fcc, flagsReg icc, regD src1, immD0 src2) %{
 8126   match(Set icc (CmpD src1 src2));
 8127   effect(KILL fcc);
 8128 
 8129   size(8);
 8130   format %{ &quot;FCMPZd  $src1,$src2 \n\t&quot;
 8131             &quot;FMSTAT&quot; %}
 8132   ins_encode %{
 8133     __ fcmpzd($src1$$FloatRegister);
 8134     __ fmstat();
 8135   %}
 8136   ins_pipe(faddD_fcc_reg_reg_zero);
 8137 %}
 8138 
 8139 // Compare floating, generate -1,0,1
 8140 instruct cmpF_reg(iRegI dst, regF src1, regF src2, flagsRegF fcc) %{
 8141   match(Set dst (CmpF3 src1 src2));
 8142   effect(KILL fcc);
 8143   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8144   size(20);
 8145   // same number of instructions as code using conditional moves but
 8146   // doesn&#39;t kill integer condition register
 8147   format %{ &quot;FCMPs  $dst,$src1,$src2 \n\t&quot;
 8148             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8149             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8150             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8151             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8152   ins_encode %{
 8153     __ fcmps($src1$$FloatRegister, $src2$$FloatRegister);
 8154     __ floating_cmp($dst$$Register);
 8155   %}
 8156   ins_pipe( floating_cmp );
 8157 %}
 8158 
 8159 instruct cmpF0_reg(iRegI dst, regF src1, immF0 src2, flagsRegF fcc) %{
 8160   match(Set dst (CmpF3 src1 src2));
 8161   effect(KILL fcc);
 8162   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8163   size(20);
 8164   // same number of instructions as code using conditional moves but
 8165   // doesn&#39;t kill integer condition register
 8166   format %{ &quot;FCMPZs $dst,$src1,$src2 \n\t&quot;
 8167             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8168             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8169             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8170             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8171   ins_encode %{
 8172     __ fcmpzs($src1$$FloatRegister);
 8173     __ floating_cmp($dst$$Register);
 8174   %}
 8175   ins_pipe( floating_cmp );
 8176 %}
 8177 
 8178 instruct cmpD_reg(iRegI dst, regD src1, regD src2, flagsRegF fcc) %{
 8179   match(Set dst (CmpD3 src1 src2));
 8180   effect(KILL fcc);
 8181   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8182   size(20);
 8183   // same number of instructions as code using conditional moves but
 8184   // doesn&#39;t kill integer condition register
 8185   format %{ &quot;FCMPd  $dst,$src1,$src2 \n\t&quot;
 8186             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8187             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8188             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8189             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8190   ins_encode %{
 8191     __ fcmpd($src1$$FloatRegister, $src2$$FloatRegister);
 8192     __ floating_cmp($dst$$Register);
 8193   %}
 8194   ins_pipe( floating_cmp );
 8195 %}
 8196 
 8197 instruct cmpD0_reg(iRegI dst, regD src1, immD0 src2, flagsRegF fcc) %{
 8198   match(Set dst (CmpD3 src1 src2));
 8199   effect(KILL fcc);
 8200   ins_cost(DEFAULT_COST*3+BRANCH_COST*3); // FIXME
 8201   size(20);
 8202   // same number of instructions as code using conditional moves but
 8203   // doesn&#39;t kill integer condition register
 8204   format %{ &quot;FCMPZd $dst,$src1,$src2 \n\t&quot;
 8205             &quot;VMRS   $dst, FPSCR \n\t&quot;
 8206             &quot;OR     $dst, $dst, 0x08000000 \n\t&quot;
 8207             &quot;EOR    $dst, $dst, $dst &lt;&lt; 3 \n\t&quot;
 8208             &quot;MOV    $dst, $dst &gt;&gt; 30&quot; %}
 8209   ins_encode %{
 8210     __ fcmpzd($src1$$FloatRegister);
 8211     __ floating_cmp($dst$$Register);
 8212   %}
 8213   ins_pipe( floating_cmp );
 8214 %}
 8215 
 8216 //----------Branches---------------------------------------------------------
 8217 // Jump
 8218 // (compare &#39;operand indIndex&#39; and &#39;instruct addP_reg_reg&#39; above)
 8219 // FIXME
 8220 instruct jumpXtnd(iRegX switch_val, iRegP tmp) %{
 8221   match(Jump switch_val);
 8222   effect(TEMP tmp);
 8223   ins_cost(350);
 8224   format %{  &quot;ADD    $tmp, $constanttablebase, $switch_val\n\t&quot;
 8225              &quot;LDR    $tmp,[$tmp + $constantoffset]\n\t&quot;
 8226              &quot;BX     $tmp&quot; %}
 8227   size(20);
 8228   ins_encode %{
 8229     Register table_reg;
 8230     Register label_reg = $tmp$$Register;
 8231     if (constant_offset() == 0) {
 8232       table_reg = $constanttablebase;
 8233       __ ldr(label_reg, Address(table_reg, $switch_val$$Register));
 8234     } else {
 8235       table_reg = $tmp$$Register;
 8236       int offset = $constantoffset;
 8237       if (is_memoryP(offset)) {
 8238         __ add(table_reg, $constanttablebase, $switch_val$$Register);
 8239         __ ldr(label_reg, Address(table_reg, offset));
 8240       } else {
 8241         __ mov_slow(table_reg, $constantoffset);
 8242         __ add(table_reg, $constanttablebase, table_reg);
 8243         __ ldr(label_reg, Address(table_reg, $switch_val$$Register));
 8244       }
 8245     }
 8246     __ jump(label_reg); // ldr + b better than ldr to PC for branch predictor?
 8247     //    __ ldr(PC, Address($table$$Register, $switch_val$$Register));
 8248   %}
 8249   ins_pipe(ialu_reg_reg);
 8250 %}
 8251 
 8252 // // Direct Branch.
 8253 instruct branch(label labl) %{
 8254   match(Goto);
 8255   effect(USE labl);
 8256 
 8257   size(4);
 8258   ins_cost(BRANCH_COST);
 8259   format %{ &quot;B     $labl&quot; %}
 8260   ins_encode %{
 8261     __ b(*($labl$$label));
 8262   %}
 8263   ins_pipe(br);
 8264 %}
 8265 
 8266 // Conditional Direct Branch
 8267 instruct branchCon(cmpOp cmp, flagsReg icc, label labl) %{
 8268   match(If cmp icc);
 8269   effect(USE labl);
 8270 
 8271   size(4);
 8272   ins_cost(BRANCH_COST);
 8273   format %{ &quot;B$cmp   $icc,$labl&quot; %}
 8274   ins_encode %{
 8275     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8276   %}
 8277   ins_pipe(br_cc);
 8278 %}
 8279 
 8280 #ifdef ARM
 8281 instruct branchCon_EQNELTGE(cmpOp0 cmp, flagsReg_EQNELTGE icc, label labl) %{
 8282   match(If cmp icc);
 8283   effect(USE labl);
 8284   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 8285 
 8286   size(4);
 8287   ins_cost(BRANCH_COST);
 8288   format %{ &quot;B$cmp   $icc,$labl&quot; %}
 8289   ins_encode %{
 8290     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8291   %}
 8292   ins_pipe(br_cc);
 8293 %}
 8294 #endif
 8295 
 8296 
 8297 instruct branchConU(cmpOpU cmp, flagsRegU icc, label labl) %{
 8298   match(If cmp icc);
 8299   effect(USE labl);
 8300 
 8301   size(4);
 8302   ins_cost(BRANCH_COST);
 8303   format %{ &quot;B$cmp  $icc,$labl&quot; %}
 8304   ins_encode %{
 8305     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8306   %}
 8307   ins_pipe(br_cc);
 8308 %}
 8309 
 8310 instruct branchConP(cmpOpP cmp, flagsRegP pcc, label labl) %{
 8311   match(If cmp pcc);
 8312   effect(USE labl);
 8313 
 8314   size(4);
 8315   ins_cost(BRANCH_COST);
 8316   format %{ &quot;B$cmp  $pcc,$labl&quot; %}
 8317   ins_encode %{
 8318     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8319   %}
 8320   ins_pipe(br_cc);
 8321 %}
 8322 
 8323 instruct branchConL_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, label labl) %{
 8324   match(If cmp xcc);
 8325   effect(USE labl);
 8326   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8327 
 8328   size(4);
 8329   ins_cost(BRANCH_COST);
 8330   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8331   ins_encode %{
 8332     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8333   %}
 8334   ins_pipe(br_cc);
 8335 %}
 8336 
 8337 instruct branchConL_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, label labl) %{
 8338   match(If cmp xcc);
 8339   effect(USE labl);
 8340   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8341 
 8342   size(4);
 8343   ins_cost(BRANCH_COST);
 8344   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8345   ins_encode %{
 8346     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8347   %}
 8348   ins_pipe(br_cc);
 8349 %}
 8350 
 8351 instruct branchConL_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, label labl) %{
 8352   match(If cmp xcc);
 8353   effect(USE labl);
 8354   predicate( _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le );
 8355 
 8356   size(4);
 8357   ins_cost(BRANCH_COST);
 8358   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8359   ins_encode %{
 8360     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8361   %}
 8362   ins_pipe(br_cc);
 8363 %}
 8364 
 8365 instruct branchConUL_LTGE(cmpOpUL cmp, flagsRegUL_LTGE xcc, label labl) %{
 8366   match(If cmp xcc);
 8367   effect(USE labl);
 8368   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge);
 8369 
 8370   size(4);
 8371   ins_cost(BRANCH_COST);
 8372   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8373   ins_encode %{
 8374     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8375   %}
 8376   ins_pipe(br_cc);
 8377 %}
 8378 
 8379 instruct branchConUL_EQNE(cmpOpUL cmp, flagsRegUL_EQNE xcc, label labl) %{
 8380   match(If cmp xcc);
 8381   effect(USE labl);
 8382   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne);
 8383 
 8384   size(4);
 8385   ins_cost(BRANCH_COST);
 8386   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8387   ins_encode %{
 8388     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8389   %}
 8390   ins_pipe(br_cc);
 8391 %}
 8392 
 8393 instruct branchConUL_LEGT(cmpOpUL_commute cmp, flagsRegUL_LEGT xcc, label labl) %{
 8394   match(If cmp xcc);
 8395   effect(USE labl);
 8396   predicate(_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt || _kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le);
 8397 
 8398   size(4);
 8399   ins_cost(BRANCH_COST);
 8400   format %{ &quot;B$cmp  $xcc,$labl&quot; %}
 8401   ins_encode %{
 8402     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8403   %}
 8404   ins_pipe(br_cc);
 8405 %}
 8406 
 8407 instruct branchLoopEnd(cmpOp cmp, flagsReg icc, label labl) %{
 8408   match(CountedLoopEnd cmp icc);
 8409   effect(USE labl);
 8410 
 8411   size(4);
 8412   ins_cost(BRANCH_COST);
 8413   format %{ &quot;B$cmp   $icc,$labl\t! Loop end&quot; %}
 8414   ins_encode %{
 8415     __ b(*($labl$$label), (AsmCondition)($cmp$$cmpcode));
 8416   %}
 8417   ins_pipe(br_cc);
 8418 %}
 8419 
 8420 // instruct branchLoopEndU(cmpOpU cmp, flagsRegU icc, label labl) %{
 8421 //   match(CountedLoopEnd cmp icc);
 8422 //   ins_pipe(br_cc);
 8423 // %}
 8424 
 8425 // ============================================================================
 8426 // Long Compare
 8427 //
 8428 // Currently we hold longs in 2 registers.  Comparing such values efficiently
 8429 // is tricky.  The flavor of compare used depends on whether we are testing
 8430 // for LT, LE, or EQ.  For a simple LT test we can check just the sign bit.
 8431 // The GE test is the negated LT test.  The LE test can be had by commuting
 8432 // the operands (yielding a GE test) and then negating; negate again for the
 8433 // GT test.  The EQ test is done by ORcc&#39;ing the high and low halves, and the
 8434 // NE test is negated from that.
 8435 
 8436 // Due to a shortcoming in the ADLC, it mixes up expressions like:
 8437 // (foo (CmpI (CmpL X Y) 0)) and (bar (CmpI (CmpL X 0L) 0)).  Note the
 8438 // difference between &#39;Y&#39; and &#39;0L&#39;.  The tree-matches for the CmpI sections
 8439 // are collapsed internally in the ADLC&#39;s dfa-gen code.  The match for
 8440 // (CmpI (CmpL X Y) 0) is silently replaced with (CmpI (CmpL X 0L) 0) and the
 8441 // foo match ends up with the wrong leaf.  One fix is to not match both
 8442 // reg-reg and reg-zero forms of long-compare.  This is unfortunate because
 8443 // both forms beat the trinary form of long-compare and both are very useful
 8444 // on Intel which has so few registers.
 8445 
 8446 // instruct branchCon_long(cmpOp cmp, flagsRegL xcc, label labl) %{
 8447 //   match(If cmp xcc);
 8448 //   ins_pipe(br_cc);
 8449 // %}
 8450 
 8451 // Manifest a CmpL3 result in an integer register.  Very painful.
 8452 // This is the test to avoid.
 8453 instruct cmpL3_reg_reg(iRegI dst, iRegL src1, iRegL src2, flagsReg ccr ) %{
 8454   match(Set dst (CmpL3 src1 src2) );
 8455   effect( KILL ccr );
 8456   ins_cost(6*DEFAULT_COST); // FIXME
 8457   size(32);
 8458   format %{
 8459       &quot;CMP    $src1.hi, $src2.hi\t\t! long\n&quot;
 8460     &quot;\tMOV.gt $dst, 1\n&quot;
 8461     &quot;\tmvn.lt $dst, 0\n&quot;
 8462     &quot;\tB.ne   done\n&quot;
 8463     &quot;\tSUBS   $dst, $src1.lo, $src2.lo\n&quot;
 8464     &quot;\tMOV.hi $dst, 1\n&quot;
 8465     &quot;\tmvn.lo $dst, 0\n&quot;
 8466     &quot;done:&quot;     %}
 8467   ins_encode %{
 8468     Label done;
 8469     __ cmp($src1$$Register-&gt;successor(), $src2$$Register-&gt;successor());
 8470     __ mov($dst$$Register, 1, gt);
 8471     __ mvn($dst$$Register, 0, lt);
 8472     __ b(done, ne);
 8473     __ subs($dst$$Register, $src1$$Register, $src2$$Register);
 8474     __ mov($dst$$Register, 1, hi);
 8475     __ mvn($dst$$Register, 0, lo);
 8476     __ bind(done);
 8477   %}
 8478   ins_pipe(cmpL_reg);
 8479 %}
 8480 
 8481 // Conditional move
 8482 instruct cmovLL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegL dst, iRegL src) %{
 8483   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8484   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8485 
 8486   ins_cost(150);
 8487   size(8);
 8488   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8489             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8490   ins_encode %{
 8491     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8492     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8493   %}
 8494   ins_pipe(ialu_reg);
 8495 %}
 8496 
 8497 instruct cmovLL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegL dst, iRegL src) %{
 8498   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8499   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8500 
 8501   ins_cost(150);
 8502   size(8);
 8503   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8504             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8505   ins_encode %{
 8506     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8507     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8508   %}
 8509   ins_pipe(ialu_reg);
 8510 %}
 8511 
 8512 instruct cmovLL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegL dst, iRegL src) %{
 8513   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8514   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8515 
 8516   ins_cost(150);
 8517   size(8);
 8518   format %{ &quot;MOV$cmp  $dst.lo,$src.lo\t! long\n\t&quot;
 8519             &quot;MOV$cmp  $dst,$src.hi&quot; %}
 8520   ins_encode %{
 8521     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8522     __ mov($dst$$Register-&gt;successor(), $src$$Register-&gt;successor(), (AsmCondition)($cmp$$cmpcode));
 8523   %}
 8524   ins_pipe(ialu_reg);
 8525 %}
 8526 
 8527 instruct cmovLL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegL dst, immL0 src) %{
 8528   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8529   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8530   ins_cost(140);
 8531   size(8);
 8532   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8533             &quot;MOV$cmp  $dst,0&quot; %}
 8534   ins_encode %{
 8535     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8536     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8537   %}
 8538   ins_pipe(ialu_imm);
 8539 %}
 8540 
 8541 instruct cmovLL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegL dst, immL0 src) %{
 8542   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8543   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8544   ins_cost(140);
 8545   size(8);
 8546   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8547             &quot;MOV$cmp  $dst,0&quot; %}
 8548   ins_encode %{
 8549     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8550     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8551   %}
 8552   ins_pipe(ialu_imm);
 8553 %}
 8554 
 8555 instruct cmovLL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegL dst, immL0 src) %{
 8556   match(Set dst (CMoveL (Binary cmp xcc) (Binary dst src)));
 8557   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8558   ins_cost(140);
 8559   size(8);
 8560   format %{ &quot;MOV$cmp  $dst.lo,0\t! long\n\t&quot;
 8561             &quot;MOV$cmp  $dst,0&quot; %}
 8562   ins_encode %{
 8563     __ mov($dst$$Register, 0, (AsmCondition)($cmp$$cmpcode));
 8564     __ mov($dst$$Register-&gt;successor(), 0, (AsmCondition)($cmp$$cmpcode));
 8565   %}
 8566   ins_pipe(ialu_imm);
 8567 %}
 8568 
 8569 instruct cmovIL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegI dst, iRegI src) %{
 8570   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8571   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8572 
 8573   ins_cost(150);
 8574   size(4);
 8575   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8576   ins_encode %{
 8577     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8578   %}
 8579   ins_pipe(ialu_reg);
 8580 %}
 8581 
 8582 instruct cmovIL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegI dst, iRegI src) %{
 8583   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8584   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8585 
 8586   ins_cost(150);
 8587   size(4);
 8588   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8589   ins_encode %{
 8590     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8591   %}
 8592   ins_pipe(ialu_reg);
 8593 %}
 8594 
 8595 instruct cmovIL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegI dst, iRegI src) %{
 8596   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8597   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8598 
 8599   ins_cost(150);
 8600   size(4);
 8601   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8602   ins_encode %{
 8603     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8604   %}
 8605   ins_pipe(ialu_reg);
 8606 %}
 8607 
 8608 instruct cmovIL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegI dst, immI16 src) %{
 8609   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8610   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8611 
 8612   ins_cost(140);
 8613   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8614   ins_encode %{
 8615     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8616   %}
 8617   ins_pipe(ialu_imm);
 8618 %}
 8619 
 8620 instruct cmovIL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegI dst, immI16 src) %{
 8621   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8622   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8623 
 8624   ins_cost(140);
 8625   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8626   ins_encode %{
 8627     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8628   %}
 8629   ins_pipe(ialu_imm);
 8630 %}
 8631 
 8632 instruct cmovIL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegI dst, immI16 src) %{
 8633   match(Set dst (CMoveI (Binary cmp xcc) (Binary dst src)));
 8634   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8635 
 8636   ins_cost(140);
 8637   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8638   ins_encode %{
 8639     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8640   %}
 8641   ins_pipe(ialu_imm);
 8642 %}
 8643 
 8644 instruct cmovPL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegP dst, iRegP src) %{
 8645   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8646   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8647 
 8648   ins_cost(150);
 8649   size(4);
 8650   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8651   ins_encode %{
 8652     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8653   %}
 8654   ins_pipe(ialu_reg);
 8655 %}
 8656 
 8657 instruct cmovPL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegP dst, iRegP src) %{
 8658   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8659   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8660 
 8661   ins_cost(150);
 8662   size(4);
 8663   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8664   ins_encode %{
 8665     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8666   %}
 8667   ins_pipe(ialu_reg);
 8668 %}
 8669 
 8670 instruct cmovPL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegP dst, iRegP src) %{
 8671   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8672   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8673 
 8674   ins_cost(150);
 8675   size(4);
 8676   format %{ &quot;MOV$cmp  $dst,$src&quot; %}
 8677   ins_encode %{
 8678     __ mov($dst$$Register, $src$$Register, (AsmCondition)($cmp$$cmpcode));
 8679   %}
 8680   ins_pipe(ialu_reg);
 8681 %}
 8682 
 8683 instruct cmovPL_imm_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, iRegP dst, immP0 src) %{
 8684   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8685   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8686 
 8687   ins_cost(140);
 8688   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8689   ins_encode %{
 8690     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8691   %}
 8692   ins_pipe(ialu_imm);
 8693 %}
 8694 
 8695 instruct cmovPL_imm_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, iRegP dst, immP0 src) %{
 8696   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8697   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8698 
 8699   ins_cost(140);
 8700   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8701   ins_encode %{
 8702     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8703   %}
 8704   ins_pipe(ialu_imm);
 8705 %}
 8706 
 8707 instruct cmovPL_imm_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, iRegP dst, immP0 src) %{
 8708   match(Set dst (CMoveP (Binary cmp xcc) (Binary dst src)));
 8709   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8710 
 8711   ins_cost(140);
 8712   format %{ &quot;MOVW$cmp  $dst,$src&quot; %}
 8713   ins_encode %{
 8714     __ movw($dst$$Register, $src$$constant, (AsmCondition)($cmp$$cmpcode));
 8715   %}
 8716   ins_pipe(ialu_imm);
 8717 %}
 8718 
 8719 instruct cmovFL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, regF dst, regF src) %{
 8720   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8721   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8722   ins_cost(150);
 8723   size(4);
 8724   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8725   ins_encode %{
 8726     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8727   %}
 8728   ins_pipe(int_conditional_float_move);
 8729 %}
 8730 
 8731 instruct cmovFL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, regF dst, regF src) %{
 8732   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8733   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8734   ins_cost(150);
 8735   size(4);
 8736   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8737   ins_encode %{
 8738     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8739   %}
 8740   ins_pipe(int_conditional_float_move);
 8741 %}
 8742 
 8743 instruct cmovFL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, regF dst, regF src) %{
 8744   match(Set dst (CMoveF (Binary cmp xcc) (Binary dst src)));
 8745   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8746   ins_cost(150);
 8747   size(4);
 8748   format %{ &quot;FCPYS$cmp $dst,$src&quot; %}
 8749   ins_encode %{
 8750     __ fcpys($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8751   %}
 8752   ins_pipe(int_conditional_float_move);
 8753 %}
 8754 
 8755 instruct cmovDL_reg_LTGE(cmpOpL cmp, flagsRegL_LTGE xcc, regD dst, regD src) %{
 8756   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8757   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::lt || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ge );
 8758 
 8759   ins_cost(150);
 8760   size(4);
 8761   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8762   ins_encode %{
 8763     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8764   %}
 8765   ins_pipe(int_conditional_float_move);
 8766 %}
 8767 
 8768 instruct cmovDL_reg_EQNE(cmpOpL cmp, flagsRegL_EQNE xcc, regD dst, regD src) %{
 8769   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8770   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::eq || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::ne );
 8771 
 8772   ins_cost(150);
 8773   size(4);
 8774   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8775   ins_encode %{
 8776     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8777   %}
 8778   ins_pipe(int_conditional_float_move);
 8779 %}
 8780 
 8781 instruct cmovDL_reg_LEGT(cmpOpL_commute cmp, flagsRegL_LEGT xcc, regD dst, regD src) %{
 8782   match(Set dst (CMoveD (Binary cmp xcc) (Binary dst src)));
 8783   predicate(_kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::le || _kids[0]-&gt;_kids[0]-&gt;_leaf-&gt;as_Bool()-&gt;_test._test == BoolTest::gt );
 8784 
 8785   ins_cost(150);
 8786   size(4);
 8787   format %{ &quot;FCPYD$cmp $dst,$src&quot; %}
 8788   ins_encode %{
 8789     __ fcpyd($dst$$FloatRegister, $src$$FloatRegister, (AsmCondition)($cmp$$cmpcode));
 8790   %}
 8791   ins_pipe(int_conditional_float_move);
 8792 %}
 8793 
 8794 // ============================================================================
 8795 // Safepoint Instruction
 8796 // rather than KILL R12, it would be better to use any reg as
 8797 // TEMP. Can&#39;t do that at this point because it crashes the compiler
 8798 instruct safePoint_poll(iRegP poll, R12RegI tmp, flagsReg icc) %{
 8799   match(SafePoint poll);
 8800   effect(USE poll, KILL tmp, KILL icc);
 8801 
 8802   size(4);
 8803   format %{ &quot;LDR   $tmp,[$poll]\t! Safepoint: poll for GC&quot; %}
 8804   ins_encode %{
 8805     __ relocate(relocInfo::poll_type);
 8806     __ ldr($tmp$$Register, Address($poll$$Register));
 8807   %}
 8808   ins_pipe(loadPollP);
 8809 %}
 8810 
 8811 
 8812 // ============================================================================
 8813 // Call Instructions
 8814 // Call Java Static Instruction
 8815 instruct CallStaticJavaDirect( method meth ) %{
 8816   match(CallStaticJava);
 8817   predicate(! ((CallStaticJavaNode*)n)-&gt;is_method_handle_invoke());
 8818   effect(USE meth);
 8819 
 8820   ins_cost(CALL_COST);
 8821   format %{ &quot;CALL,static ==&gt; &quot; %}
 8822   ins_encode( Java_Static_Call( meth ), call_epilog );
 8823   ins_pipe(simple_call);
 8824 %}
 8825 
 8826 // Call Java Static Instruction (method handle version)
 8827 instruct CallStaticJavaHandle( method meth ) %{
 8828   match(CallStaticJava);
 8829   predicate(((CallStaticJavaNode*)n)-&gt;is_method_handle_invoke());
 8830   effect(USE meth);
 8831   // FP is saved by all callees (for interpreter stack correction).
 8832   // We use it here for a similar purpose, in {preserve,restore}_FP.
 8833 
 8834   ins_cost(CALL_COST);
 8835   format %{ &quot;CALL,static/MethodHandle ==&gt; &quot; %}
 8836   ins_encode( preserve_SP, Java_Static_Call( meth ), restore_SP, call_epilog );
 8837   ins_pipe(simple_call);
 8838 %}
 8839 
 8840 // Call Java Dynamic Instruction
 8841 instruct CallDynamicJavaDirect( method meth ) %{
 8842   match(CallDynamicJava);
 8843   effect(USE meth);
 8844 
 8845   ins_cost(CALL_COST);
 8846   format %{ &quot;MOV_OOP    (empty),R_R8\n\t&quot;
 8847             &quot;CALL,dynamic  ; NOP ==&gt; &quot; %}
 8848   ins_encode( Java_Dynamic_Call( meth ), call_epilog );
 8849   ins_pipe(call);
 8850 %}
 8851 
 8852 // Call Runtime Instruction
 8853 instruct CallRuntimeDirect(method meth) %{
 8854   match(CallRuntime);
 8855   effect(USE meth);
 8856   ins_cost(CALL_COST);
 8857   format %{ &quot;CALL,runtime&quot; %}
 8858   ins_encode( Java_To_Runtime( meth ),
 8859               call_epilog );
 8860   ins_pipe(simple_call);
 8861 %}
 8862 
 8863 // Call runtime without safepoint - same as CallRuntime
 8864 instruct CallLeafDirect(method meth) %{
 8865   match(CallLeaf);
 8866   effect(USE meth);
 8867   ins_cost(CALL_COST);
 8868   format %{ &quot;CALL,runtime leaf&quot; %}
 8869   // TODO: ned save_last_PC here?
 8870   ins_encode( Java_To_Runtime( meth ),
 8871               call_epilog );
 8872   ins_pipe(simple_call);
 8873 %}
 8874 
 8875 // Call runtime without safepoint - same as CallLeaf
 8876 instruct CallLeafNoFPDirect(method meth) %{
 8877   match(CallLeafNoFP);
 8878   effect(USE meth);
 8879   ins_cost(CALL_COST);
 8880   format %{ &quot;CALL,runtime leaf nofp&quot; %}
 8881   // TODO: ned save_last_PC here?
 8882   ins_encode( Java_To_Runtime( meth ),
 8883               call_epilog );
 8884   ins_pipe(simple_call);
 8885 %}
 8886 
 8887 // Tail Call; Jump from runtime stub to Java code.
 8888 // Also known as an &#39;interprocedural jump&#39;.
 8889 // Target of jump will eventually return to caller.
 8890 // TailJump below removes the return address.
 8891 instruct TailCalljmpInd(IPRegP jump_target, inline_cache_regP method_oop) %{
 8892   match(TailCall jump_target method_oop );
 8893 
 8894   ins_cost(CALL_COST);
 8895   format %{ &quot;MOV    Rexception_pc, LR\n\t&quot;
 8896             &quot;jump   $jump_target  \t! $method_oop holds method oop&quot; %}
 8897   ins_encode %{
 8898     __ mov(Rexception_pc, LR);   // this is used only to call
 8899                                  // StubRoutines::forward_exception_entry()
 8900                                  // which expects PC of exception in
 8901                                  // R5. FIXME?
 8902     __ jump($jump_target$$Register);
 8903   %}
 8904   ins_pipe(tail_call);
 8905 %}
 8906 
 8907 
 8908 // Return Instruction
 8909 instruct Ret() %{
 8910   match(Return);
 8911 
 8912   format %{ &quot;ret LR&quot; %}
 8913 
 8914   ins_encode %{
 8915     __ ret(LR);
 8916   %}
 8917 
 8918   ins_pipe(br);
 8919 %}
 8920 
 8921 
 8922 // Tail Jump; remove the return address; jump to target.
 8923 // TailCall above leaves the return address around.
 8924 // TailJump is used in only one place, the rethrow_Java stub (fancy_jump=2).
 8925 // ex_oop (Exception Oop) is needed in %o0 at the jump. As there would be a
 8926 // &quot;restore&quot; before this instruction (in Epilogue), we need to materialize it
 8927 // in %i0.
 8928 instruct tailjmpInd(IPRegP jump_target, RExceptionRegP ex_oop) %{
 8929   match( TailJump jump_target ex_oop );
 8930   ins_cost(CALL_COST);
 8931   format %{ &quot;MOV    Rexception_pc, LR\n\t&quot;
 8932             &quot;jump   $jump_target \t! $ex_oop holds exc. oop&quot; %}
 8933   ins_encode %{
 8934     __ mov(Rexception_pc, LR);
 8935     __ jump($jump_target$$Register);
 8936   %}
 8937   ins_pipe(tail_call);
 8938 %}
 8939 
 8940 // Create exception oop: created by stack-crawling runtime code.
 8941 // Created exception is now available to this handler, and is setup
 8942 // just prior to jumping to this handler.  No code emitted.
 8943 instruct CreateException( RExceptionRegP ex_oop )
 8944 %{
 8945   match(Set ex_oop (CreateEx));
 8946   ins_cost(0);
 8947 
 8948   size(0);
 8949   // use the following format syntax
 8950   format %{ &quot;! exception oop is in Rexception_obj; no code emitted&quot; %}
 8951   ins_encode();
 8952   ins_pipe(empty);
 8953 %}
 8954 
 8955 
 8956 // Rethrow exception:
 8957 // The exception oop will come in the first argument position.
 8958 // Then JUMP (not call) to the rethrow stub code.
 8959 instruct RethrowException()
 8960 %{
 8961   match(Rethrow);
 8962   ins_cost(CALL_COST);
 8963 
 8964   // use the following format syntax
 8965   format %{ &quot;b    rethrow_stub&quot; %}
 8966   ins_encode %{
 8967     Register scratch = R1_tmp;
 8968     assert_different_registers(scratch, c_rarg0, LR);
 8969     __ jump(OptoRuntime::rethrow_stub(), relocInfo::runtime_call_type, scratch);
 8970   %}
 8971   ins_pipe(tail_call);
 8972 %}
 8973 
 8974 
 8975 // Die now
 8976 instruct ShouldNotReachHere( )
 8977 %{
 8978   match(Halt);
 8979   ins_cost(CALL_COST);
 8980 
 8981   size(4);
 8982   // Use the following format syntax
 8983   format %{ &quot;ShouldNotReachHere&quot; %}
 8984   ins_encode %{
 8985     __ udf(0xdead);
 8986   %}
 8987   ins_pipe(tail_call);
 8988 %}
 8989 
 8990 // ============================================================================
 8991 // The 2nd slow-half of a subtype check.  Scan the subklass&#39;s 2ndary superklass
 8992 // array for an instance of the superklass.  Set a hidden internal cache on a
 8993 // hit (cache is checked with exposed code in gen_subtype_check()).  Return
 8994 // not zero for a miss or zero for a hit.  The encoding ALSO sets flags.
 8995 instruct partialSubtypeCheck( R0RegP index, R1RegP sub, R2RegP super, flagsRegP pcc, LRRegP lr ) %{
 8996   match(Set index (PartialSubtypeCheck sub super));
 8997   effect( KILL pcc, KILL lr );
 8998   ins_cost(DEFAULT_COST*10);
 8999   format %{ &quot;CALL   PartialSubtypeCheck&quot; %}
 9000   ins_encode %{
 9001     __ call(StubRoutines::Arm::partial_subtype_check(), relocInfo::runtime_call_type);
 9002   %}
 9003   ins_pipe(partial_subtype_check_pipe);
 9004 %}
 9005 
 9006 /* instruct partialSubtypeCheck_vs_zero( flagsRegP pcc, o1RegP sub, o2RegP super, immP0 zero, o0RegP idx, o7RegP o7 ) %{ */
 9007 /*   match(Set pcc (CmpP (PartialSubtypeCheck sub super) zero)); */
 9008 /*   ins_pipe(partial_subtype_check_pipe); */
 9009 /* %} */
 9010 
 9011 
 9012 // ============================================================================
 9013 // inlined locking and unlocking
 9014 
 9015 instruct cmpFastLock(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2, iRegP scratch )
 9016 %{
 9017   match(Set pcc (FastLock object box));
 9018   predicate(!(UseBiasedLocking &amp;&amp; !UseOptoBiasInlining));
 9019 
 9020   effect(TEMP scratch, TEMP scratch2);
 9021   ins_cost(DEFAULT_COST*3);
 9022 
 9023   format %{ &quot;FASTLOCK  $object, $box; KILL $scratch, $scratch2&quot; %}
 9024   ins_encode %{
 9025     __ fast_lock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register);
 9026   %}
 9027   ins_pipe(long_memory_op);
 9028 %}
 9029 
 9030 instruct cmpFastLock_noBiasInline(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2,
 9031                                   iRegP scratch, iRegP scratch3) %{
 9032   match(Set pcc (FastLock object box));
 9033   predicate(UseBiasedLocking &amp;&amp; !UseOptoBiasInlining);
 9034 
 9035   effect(TEMP scratch, TEMP scratch2, TEMP scratch3);
 9036   ins_cost(DEFAULT_COST*5);
 9037 
 9038   format %{ &quot;FASTLOCK  $object, $box; KILL $scratch, $scratch2, $scratch3&quot; %}
 9039   ins_encode %{
 9040     __ fast_lock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register, $scratch3$$Register);
 9041   %}
 9042   ins_pipe(long_memory_op);
 9043 %}
 9044 
 9045 
 9046 instruct cmpFastUnlock(flagsRegP pcc, iRegP object, iRegP box, iRegP scratch2, iRegP scratch ) %{
 9047   match(Set pcc (FastUnlock object box));
 9048   effect(TEMP scratch, TEMP scratch2);
 9049   ins_cost(100);
 9050 
 9051   format %{ &quot;FASTUNLOCK  $object, $box; KILL $scratch, $scratch2&quot; %}
 9052   ins_encode %{
 9053     __ fast_unlock($object$$Register, $box$$Register, $scratch$$Register, $scratch2$$Register);
 9054   %}
 9055   ins_pipe(long_memory_op);
 9056 %}
 9057 
 9058 // Count and Base registers are fixed because the allocator cannot
 9059 // kill unknown registers.  The encodings are generic.
 9060 instruct clear_array(iRegX cnt, iRegP base, iRegI temp, iRegX zero, Universe dummy, flagsReg cpsr) %{
 9061   match(Set dummy (ClearArray cnt base));
 9062   effect(TEMP temp, TEMP zero, KILL cpsr);
 9063   ins_cost(300);
 9064   format %{ &quot;MOV    $zero,0\n&quot;
 9065       &quot;        MOV    $temp,$cnt\n&quot;
 9066       &quot;loop:   SUBS   $temp,$temp,4\t! Count down a dword of bytes\n&quot;
 9067       &quot;        STR.ge $zero,[$base+$temp]\t! delay slot&quot;
 9068       &quot;        B.gt   loop\t\t! Clearing loop\n&quot; %}
 9069   ins_encode %{
 9070     __ mov($zero$$Register, 0);
 9071     __ mov($temp$$Register, $cnt$$Register);
 9072     Label(loop);
 9073     __ bind(loop);
 9074     __ subs($temp$$Register, $temp$$Register, 4);
 9075     __ str($zero$$Register, Address($base$$Register, $temp$$Register), ge);
 9076     __ b(loop, gt);
 9077   %}
 9078   ins_pipe(long_memory_op);
 9079 %}
 9080 
 9081 #ifdef XXX
 9082 // FIXME: Why R0/R1/R2/R3?
 9083 instruct string_compare(R0RegP str1, R1RegP str2, R2RegI cnt1, R3RegI cnt2, iRegI result,
 9084                         iRegI tmp1, iRegI tmp2, flagsReg ccr) %{
 9085   predicate(!CompactStrings);
 9086   match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));
 9087   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL ccr, TEMP tmp1, TEMP tmp2);
 9088   ins_cost(300);
 9089   format %{ &quot;String Compare $str1,$cnt1,$str2,$cnt2 -&gt; $result   // TEMP $tmp1, $tmp2&quot; %}
 9090   ins_encode( enc_String_Compare(str1, str2, cnt1, cnt2, result, tmp1, tmp2) );
 9091 
 9092   ins_pipe(long_memory_op);
 9093 %}
 9094 
 9095 // FIXME: Why R0/R1/R2?
 9096 instruct string_equals(R0RegP str1, R1RegP str2, R2RegI cnt, iRegI result, iRegI tmp1, iRegI tmp2,
 9097                        flagsReg ccr) %{
 9098   predicate(!CompactStrings);
 9099   match(Set result (StrEquals (Binary str1 str2) cnt));
 9100   effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, TEMP tmp1, TEMP tmp2, TEMP result, KILL ccr);
 9101 
 9102   ins_cost(300);
 9103   format %{ &quot;String Equals $str1,$str2,$cnt -&gt; $result   // TEMP $tmp1, $tmp2&quot; %}
 9104   ins_encode( enc_String_Equals(str1, str2, cnt, result, tmp1, tmp2) );
 9105   ins_pipe(long_memory_op);
 9106 %}
 9107 
 9108 // FIXME: Why R0/R1?
 9109 instruct array_equals(R0RegP ary1, R1RegP ary2, iRegI tmp1, iRegI tmp2, iRegI tmp3, iRegI result,
 9110                       flagsReg ccr) %{
 9111   predicate(((AryEqNode*)n)-&gt;encoding() == StrIntrinsicNode::UU);
 9112   match(Set result (AryEq ary1 ary2));
 9113   effect(USE_KILL ary1, USE_KILL ary2, TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP result, KILL ccr);
 9114 
 9115   ins_cost(300);
 9116   format %{ &quot;Array Equals $ary1,$ary2 -&gt; $result   // TEMP $tmp1,$tmp2,$tmp3&quot; %}
 9117   ins_encode( enc_Array_Equals(ary1, ary2, tmp1, tmp2, tmp3, result));
 9118   ins_pipe(long_memory_op);
 9119 %}
 9120 #endif
 9121 
 9122 //---------- Zeros Count Instructions ------------------------------------------
 9123 
 9124 instruct countLeadingZerosI(iRegI dst, iRegI src) %{
 9125   match(Set dst (CountLeadingZerosI src));
 9126   size(4);
 9127   format %{ &quot;CLZ_32 $dst,$src&quot; %}
 9128   ins_encode %{
 9129     __ clz_32($dst$$Register, $src$$Register);
 9130   %}
 9131   ins_pipe(ialu_reg);
 9132 %}
 9133 
 9134 instruct countLeadingZerosL(iRegI dst, iRegL src, iRegI tmp, flagsReg ccr) %{
 9135   match(Set dst (CountLeadingZerosL src));
 9136   effect(TEMP tmp, TEMP dst, KILL ccr);
 9137   size(16);
 9138   format %{ &quot;CLZ    $dst,$src.hi\n\t&quot;
 9139             &quot;TEQ    $dst,32\n\t&quot;
 9140             &quot;CLZ.eq $tmp,$src.lo\n\t&quot;
 9141             &quot;ADD.eq $dst, $dst, $tmp\n\t&quot; %}
 9142   ins_encode %{
 9143     __ clz($dst$$Register, $src$$Register-&gt;successor());
 9144     __ teq($dst$$Register, 32);
 9145     __ clz($tmp$$Register, $src$$Register, eq);
 9146     __ add($dst$$Register, $dst$$Register, $tmp$$Register, eq);
 9147   %}
 9148   ins_pipe(ialu_reg);
 9149 %}
 9150 
 9151 instruct countTrailingZerosI(iRegI dst, iRegI src, iRegI tmp) %{
 9152   match(Set dst (CountTrailingZerosI src));
 9153   effect(TEMP tmp);
 9154   size(8);
 9155   format %{ &quot;RBIT_32 $tmp, $src\n\t&quot;
 9156             &quot;CLZ_32  $dst,$tmp&quot; %}
 9157   ins_encode %{
 9158     __ rbit_32($tmp$$Register, $src$$Register);
 9159     __ clz_32($dst$$Register, $tmp$$Register);
 9160   %}
 9161   ins_pipe(ialu_reg);
 9162 %}
 9163 
 9164 instruct countTrailingZerosL(iRegI dst, iRegL src, iRegI tmp, flagsReg ccr) %{
 9165   match(Set dst (CountTrailingZerosL src));
 9166   effect(TEMP tmp, TEMP dst, KILL ccr);
 9167   size(24);
 9168   format %{ &quot;RBIT   $tmp,$src.lo\n\t&quot;
 9169             &quot;CLZ    $dst,$tmp\n\t&quot;
 9170             &quot;TEQ    $dst,32\n\t&quot;
 9171             &quot;RBIT   $tmp,$src.hi\n\t&quot;
 9172             &quot;CLZ.eq $tmp,$tmp\n\t&quot;
 9173             &quot;ADD.eq $dst,$dst,$tmp\n\t&quot; %}
 9174   ins_encode %{
 9175     __ rbit($tmp$$Register, $src$$Register);
 9176     __ clz($dst$$Register, $tmp$$Register);
 9177     __ teq($dst$$Register, 32);
 9178     __ rbit($tmp$$Register, $src$$Register-&gt;successor());
 9179     __ clz($tmp$$Register, $tmp$$Register, eq);
 9180     __ add($dst$$Register, $dst$$Register, $tmp$$Register, eq);
 9181   %}
 9182   ins_pipe(ialu_reg);
 9183 %}
 9184 
 9185 
 9186 //---------- Population Count Instructions -------------------------------------
 9187 
 9188 instruct popCountI(iRegI dst, iRegI src, regD_low tmp) %{
 9189   predicate(UsePopCountInstruction);
 9190   match(Set dst (PopCountI src));
 9191   effect(TEMP tmp);
 9192 
 9193   format %{ &quot;FMSR       $tmp,$src\n\t&quot;
 9194             &quot;VCNT.8     $tmp,$tmp\n\t&quot;
 9195             &quot;VPADDL.U8  $tmp,$tmp\n\t&quot;
 9196             &quot;VPADDL.U16 $tmp,$tmp\n\t&quot;
 9197             &quot;FMRS       $dst,$tmp&quot; %}
 9198   size(20);
 9199 
 9200   ins_encode %{
 9201     __ fmsr($tmp$$FloatRegister, $src$$Register);
 9202     __ vcnt($tmp$$FloatRegister, $tmp$$FloatRegister);
 9203     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 8, 0);
 9204     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 16, 0);
 9205     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 9206   %}
 9207   ins_pipe(ialu_reg); // FIXME
 9208 %}
 9209 
 9210 // Note: Long.bitCount(long) returns an int.
 9211 instruct popCountL(iRegI dst, iRegL src, regD_low tmp) %{
 9212   predicate(UsePopCountInstruction);
 9213   match(Set dst (PopCountL src));
 9214   effect(TEMP tmp);
 9215 
 9216   format %{ &quot;FMDRR       $tmp,$src.lo,$src.hi\n\t&quot;
 9217             &quot;VCNT.8      $tmp,$tmp\n\t&quot;
 9218             &quot;VPADDL.U8   $tmp,$tmp\n\t&quot;
 9219             &quot;VPADDL.U16  $tmp,$tmp\n\t&quot;
 9220             &quot;VPADDL.U32  $tmp,$tmp\n\t&quot;
 9221             &quot;FMRS        $dst,$tmp&quot; %}
 9222 
 9223   size(32);
 9224 
 9225   ins_encode %{
 9226     __ fmdrr($tmp$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 9227     __ vcnt($tmp$$FloatRegister, $tmp$$FloatRegister);
 9228     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 8, 0);
 9229     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 16, 0);
 9230     __ vpaddl($tmp$$FloatRegister, $tmp$$FloatRegister, 32, 0);
 9231     __ fmrs($dst$$Register, $tmp$$FloatRegister);
 9232   %}
 9233   ins_pipe(ialu_reg);
 9234 %}
 9235 
 9236 
 9237 // ============================================================================
 9238 //------------Bytes reverse--------------------------------------------------
 9239 
 9240 instruct bytes_reverse_int(iRegI dst, iRegI src) %{
 9241   match(Set dst (ReverseBytesI src));
 9242 
 9243   size(4);
 9244   format %{ &quot;REV32 $dst,$src&quot; %}
 9245   ins_encode %{
 9246     __ rev($dst$$Register, $src$$Register);
 9247   %}
 9248   ins_pipe( iload_mem ); // FIXME
 9249 %}
 9250 
 9251 instruct bytes_reverse_long(iRegL dst, iRegL src) %{
 9252   match(Set dst (ReverseBytesL src));
 9253   effect(TEMP dst);
 9254   size(8);
 9255   format %{ &quot;REV $dst.lo,$src.lo\n\t&quot;
 9256             &quot;REV $dst.hi,$src.hi&quot; %}
 9257   ins_encode %{
 9258     __ rev($dst$$Register, $src$$Register-&gt;successor());
 9259     __ rev($dst$$Register-&gt;successor(), $src$$Register);
 9260   %}
 9261   ins_pipe( iload_mem ); // FIXME
 9262 %}
 9263 
 9264 instruct bytes_reverse_unsigned_short(iRegI dst, iRegI src) %{
 9265   match(Set dst (ReverseBytesUS src));
 9266   size(4);
 9267   format %{ &quot;REV16 $dst,$src&quot; %}
 9268   ins_encode %{
 9269     __ rev16($dst$$Register, $src$$Register);
 9270   %}
 9271   ins_pipe( iload_mem ); // FIXME
 9272 %}
 9273 
 9274 instruct bytes_reverse_short(iRegI dst, iRegI src) %{
 9275   match(Set dst (ReverseBytesS src));
 9276   size(4);
 9277   format %{ &quot;REVSH $dst,$src&quot; %}
 9278   ins_encode %{
 9279     __ revsh($dst$$Register, $src$$Register);
 9280   %}
 9281   ins_pipe( iload_mem ); // FIXME
 9282 %}
 9283 
 9284 
 9285 // ====================VECTOR INSTRUCTIONS=====================================
 9286 
 9287 // Load Aligned Packed values into a Double Register
 9288 instruct loadV8(vecD dst, memoryD mem) %{
 9289   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 8);
 9290   match(Set dst (LoadVector mem));
 9291   ins_cost(MEMORY_REF_COST);
 9292   size(4);
 9293   format %{ &quot;FLDD   $mem,$dst\t! load vector (8 bytes)&quot; %}
 9294   ins_encode %{
 9295     __ ldr_double($dst$$FloatRegister, $mem$$Address);
 9296   %}
 9297   ins_pipe(floadD_mem);
 9298 %}
 9299 
 9300 // Load Aligned Packed values into a Double Register Pair
 9301 instruct loadV16(vecX dst, memoryvld mem) %{
 9302   predicate(n-&gt;as_LoadVector()-&gt;memory_size() == 16);
 9303   match(Set dst (LoadVector mem));
 9304   ins_cost(MEMORY_REF_COST);
 9305   size(4);
 9306   format %{ &quot;VLD1   $mem,$dst.Q\t! load vector (16 bytes)&quot; %}
 9307   ins_encode %{
 9308     __ vld1($dst$$FloatRegister, $mem$$Address, MacroAssembler::VELEM_SIZE_16, 128);
 9309   %}
 9310   ins_pipe(floadD_mem); // FIXME
 9311 %}
 9312 
 9313 // Store Vector in Double register to memory
 9314 instruct storeV8(memoryD mem, vecD src) %{
 9315   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 8);
 9316   match(Set mem (StoreVector mem src));
 9317   ins_cost(MEMORY_REF_COST);
 9318   size(4);
 9319   format %{ &quot;FSTD   $src,$mem\t! store vector (8 bytes)&quot; %}
 9320   ins_encode %{
 9321     __ str_double($src$$FloatRegister, $mem$$Address);
 9322   %}
 9323   ins_pipe(fstoreD_mem_reg);
 9324 %}
 9325 
 9326 // Store Vector in Double Register Pair to memory
 9327 instruct storeV16(memoryvld mem, vecX src) %{
 9328   predicate(n-&gt;as_StoreVector()-&gt;memory_size() == 16);
 9329   match(Set mem (StoreVector mem src));
 9330   ins_cost(MEMORY_REF_COST);
 9331   size(4);
 9332   format %{ &quot;VST1   $src,$mem\t! store vector (16 bytes)&quot; %}
 9333   ins_encode %{
 9334     __ vst1($src$$FloatRegister, $mem$$Address, MacroAssembler::VELEM_SIZE_16, 128);
 9335   %}
 9336   ins_pipe(fstoreD_mem_reg); // FIXME
 9337 %}
 9338 
 9339 // Replicate scalar to packed byte values in Double register
 9340 instruct Repl8B_reg(vecD dst, iRegI src, iRegI tmp) %{
 9341   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9342   match(Set dst (ReplicateB src));
 9343   ins_cost(DEFAULT_COST*4);
 9344   effect(TEMP tmp);
 9345   size(16);
 9346 
 9347   // FIXME: could use PKH instruction instead?
 9348   format %{ &quot;LSL      $tmp, $src, 24 \n\t&quot;
 9349             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 8) \n\t&quot;
 9350             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 16) \n\t&quot;
 9351             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9352   ins_encode %{
 9353     __ mov($tmp$$Register, AsmOperand($src$$Register, lsl, 24));
 9354     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 8));
 9355     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 16));
 9356     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9357   %}
 9358   ins_pipe(ialu_reg); // FIXME
 9359 %}
 9360 
 9361 // Replicate scalar to packed byte values in Double register
 9362 instruct Repl8B_reg_simd(vecD dst, iRegI src) %{
 9363   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9364   match(Set dst (ReplicateB src));
 9365   size(4);
 9366 
 9367   format %{ &quot;VDUP.8 $dst,$src\t&quot; %}
 9368   ins_encode %{
 9369     bool quad = false;
 9370     __ vdupI($dst$$FloatRegister, $src$$Register,
 9371              MacroAssembler::VELEM_SIZE_8, quad);
 9372   %}
 9373   ins_pipe(ialu_reg); // FIXME
 9374 %}
 9375 
 9376 // Replicate scalar to packed byte values in Double register pair
 9377 instruct Repl16B_reg(vecX dst, iRegI src) %{
 9378   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
 9379   match(Set dst (ReplicateB src));
 9380   size(4);
 9381 
 9382   format %{ &quot;VDUP.8 $dst.Q,$src\t&quot; %}
 9383   ins_encode %{
 9384     bool quad = true;
 9385     __ vdupI($dst$$FloatRegister, $src$$Register,
 9386              MacroAssembler::VELEM_SIZE_8, quad);
 9387   %}
 9388   ins_pipe(ialu_reg); // FIXME
 9389 %}
 9390 
 9391 // Replicate scalar constant to packed byte values in Double register
 9392 instruct Repl8B_immI(vecD dst, immI src, iRegI tmp) %{
 9393   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9394   match(Set dst (ReplicateB src));
 9395   ins_cost(DEFAULT_COST*2);
 9396   effect(TEMP tmp);
 9397   size(12);
 9398 
 9399   format %{ &quot;MOV      $tmp, Repl4($src))\n\t&quot;
 9400             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9401   ins_encode( LdReplImmI(src, dst, tmp, (4), (1)) );
 9402   ins_pipe(loadConFD); // FIXME
 9403 %}
 9404 
 9405 // Replicate scalar constant to packed byte values in Double register
 9406 // TODO: support negative constants with MVNI?
 9407 instruct Repl8B_immU8(vecD dst, immU8 src) %{
 9408   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9409   match(Set dst (ReplicateB src));
 9410   size(4);
 9411 
 9412   format %{ &quot;VMOV.U8  $dst,$src&quot; %}
 9413   ins_encode %{
 9414     bool quad = false;
 9415     __ vmovI($dst$$FloatRegister, $src$$constant,
 9416              MacroAssembler::VELEM_SIZE_8, quad);
 9417   %}
 9418   ins_pipe(loadConFD); // FIXME
 9419 %}
 9420 
 9421 // Replicate scalar constant to packed byte values in Double register pair
 9422 instruct Repl16B_immU8(vecX dst, immU8 src) %{
 9423   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9424   match(Set dst (ReplicateB src));
 9425   size(4);
 9426 
 9427   format %{ &quot;VMOV.U8  $dst.Q,$src&quot; %}
 9428   ins_encode %{
 9429     bool quad = true;
 9430     __ vmovI($dst$$FloatRegister, $src$$constant,
 9431              MacroAssembler::VELEM_SIZE_8, quad);
 9432   %}
 9433   ins_pipe(loadConFD); // FIXME
 9434 %}
 9435 
 9436 // Replicate scalar to packed short/char values into Double register
 9437 instruct Repl4S_reg(vecD dst, iRegI src, iRegI tmp) %{
 9438   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9439   match(Set dst (ReplicateS src));
 9440   ins_cost(DEFAULT_COST*3);
 9441   effect(TEMP tmp);
 9442   size(12);
 9443 
 9444   // FIXME: could use PKH instruction instead?
 9445   format %{ &quot;LSL      $tmp, $src, 16 \n\t&quot;
 9446             &quot;OR       $tmp, $tmp, ($tmp &gt;&gt; 16) \n\t&quot;
 9447             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9448   ins_encode %{
 9449     __ mov($tmp$$Register, AsmOperand($src$$Register, lsl, 16));
 9450     __ orr($tmp$$Register, $tmp$$Register, AsmOperand($tmp$$Register, lsr, 16));
 9451     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9452   %}
 9453   ins_pipe(ialu_reg); // FIXME
 9454 %}
 9455 
 9456 // Replicate scalar to packed byte values in Double register
 9457 instruct Repl4S_reg_simd(vecD dst, iRegI src) %{
 9458   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9459   match(Set dst (ReplicateS src));
 9460   size(4);
 9461 
 9462   format %{ &quot;VDUP.16 $dst,$src\t&quot; %}
 9463   ins_encode %{
 9464     bool quad = false;
 9465     __ vdupI($dst$$FloatRegister, $src$$Register,
 9466              MacroAssembler::VELEM_SIZE_16, quad);
 9467   %}
 9468   ins_pipe(ialu_reg); // FIXME
 9469 %}
 9470 
 9471 // Replicate scalar to packed byte values in Double register pair
 9472 instruct Repl8S_reg(vecX dst, iRegI src) %{
 9473   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9474   match(Set dst (ReplicateS src));
 9475   size(4);
 9476 
 9477   format %{ &quot;VDUP.16 $dst.Q,$src\t&quot; %}
 9478   ins_encode %{
 9479     bool quad = true;
 9480     __ vdupI($dst$$FloatRegister, $src$$Register,
 9481              MacroAssembler::VELEM_SIZE_16, quad);
 9482   %}
 9483   ins_pipe(ialu_reg); // FIXME
 9484 %}
 9485 
 9486 
 9487 // Replicate scalar constant to packed short/char values in Double register
 9488 instruct Repl4S_immI(vecD dst, immI src, iRegP tmp) %{
 9489   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9490   match(Set dst (ReplicateS src));
 9491   effect(TEMP tmp);
 9492   size(12);
 9493   ins_cost(DEFAULT_COST*4); // FIXME
 9494 
 9495   format %{ &quot;MOV      $tmp, Repl2($src))\n\t&quot;
 9496             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9497   ins_encode( LdReplImmI(src, dst, tmp, (2), (2)) );
 9498   ins_pipe(loadConFD); // FIXME
 9499 %}
 9500 
 9501 // Replicate scalar constant to packed byte values in Double register
 9502 instruct Repl4S_immU8(vecD dst, immU8 src) %{
 9503   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9504   match(Set dst (ReplicateS src));
 9505   size(4);
 9506 
 9507   format %{ &quot;VMOV.U16  $dst,$src&quot; %}
 9508   ins_encode %{
 9509     bool quad = false;
 9510     __ vmovI($dst$$FloatRegister, $src$$constant,
 9511              MacroAssembler::VELEM_SIZE_16, quad);
 9512   %}
 9513   ins_pipe(loadConFD); // FIXME
 9514 %}
 9515 
 9516 // Replicate scalar constant to packed byte values in Double register pair
 9517 instruct Repl8S_immU8(vecX dst, immU8 src) %{
 9518   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9519   match(Set dst (ReplicateS src));
 9520   size(4);
 9521 
 9522   format %{ &quot;VMOV.U16  $dst.Q,$src&quot; %}
 9523   ins_encode %{
 9524     bool quad = true;
 9525     __ vmovI($dst$$FloatRegister, $src$$constant,
 9526              MacroAssembler::VELEM_SIZE_16, quad);
 9527   %}
 9528   ins_pipe(loadConFD); // FIXME
 9529 %}
 9530 
 9531 // Replicate scalar to packed int values in Double register
 9532 instruct Repl2I_reg(vecD dst, iRegI src) %{
 9533   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9534   match(Set dst (ReplicateI src));
 9535   size(4);
 9536 
 9537   format %{ &quot;FMDRR    $dst,$src,$src\t&quot; %}
 9538   ins_encode %{
 9539     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9540   %}
 9541   ins_pipe(ialu_reg); // FIXME
 9542 %}
 9543 
 9544 // Replicate scalar to packed int values in Double register pair
 9545 instruct Repl4I_reg(vecX dst, iRegI src) %{
 9546   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9547   match(Set dst (ReplicateI src));
 9548   ins_cost(DEFAULT_COST*2);
 9549   size(8);
 9550 
 9551   format %{ &quot;FMDRR    $dst.lo,$src,$src\n\t&quot;
 9552             &quot;FMDRR    $dst.hi,$src,$src&quot; %}
 9553 
 9554   ins_encode %{
 9555     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9556     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9557              $src$$Register, $src$$Register);
 9558   %}
 9559   ins_pipe(ialu_reg); // FIXME
 9560 %}
 9561 
 9562 // Replicate scalar to packed int values in Double register
 9563 instruct Repl2I_reg_simd(vecD dst, iRegI src) %{
 9564   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9565   match(Set dst (ReplicateI src));
 9566   size(4);
 9567 
 9568   format %{ &quot;VDUP.32 $dst.D,$src\t&quot; %}
 9569   ins_encode %{
 9570     bool quad = false;
 9571     __ vdupI($dst$$FloatRegister, $src$$Register,
 9572              MacroAssembler::VELEM_SIZE_32, quad);
 9573   %}
 9574   ins_pipe(ialu_reg); // FIXME
 9575 %}
 9576 
 9577 // Replicate scalar to packed int values in Double register pair
 9578 instruct Repl4I_reg_simd(vecX dst, iRegI src) %{
 9579   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9580   match(Set dst (ReplicateI src));
 9581   size(4);
 9582 
 9583   format %{ &quot;VDUP.32 $dst.Q,$src\t&quot; %}
 9584   ins_encode %{
 9585     bool quad = true;
 9586     __ vdupI($dst$$FloatRegister, $src$$Register,
 9587              MacroAssembler::VELEM_SIZE_32, quad);
 9588   %}
 9589   ins_pipe(ialu_reg); // FIXME
 9590 %}
 9591 
 9592 
 9593 // Replicate scalar zero constant to packed int values in Double register
 9594 instruct Repl2I_immI(vecD dst, immI src, iRegI tmp) %{
 9595   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9596   match(Set dst (ReplicateI src));
 9597   effect(TEMP tmp);
 9598   size(12);
 9599   ins_cost(DEFAULT_COST*4); // FIXME
 9600 
 9601   format %{ &quot;MOV      $tmp, Repl1($src))\n\t&quot;
 9602             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9603   ins_encode( LdReplImmI(src, dst, tmp, (1), (4)) );
 9604   ins_pipe(loadConFD); // FIXME
 9605 %}
 9606 
 9607 // Replicate scalar constant to packed byte values in Double register
 9608 instruct Repl2I_immU8(vecD dst, immU8 src) %{
 9609   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9610   match(Set dst (ReplicateI src));
 9611   size(4);
 9612 
 9613   format %{ &quot;VMOV.I32  $dst.D,$src&quot; %}
 9614   ins_encode %{
 9615     bool quad = false;
 9616     __ vmovI($dst$$FloatRegister, $src$$constant,
 9617              MacroAssembler::VELEM_SIZE_32, quad);
 9618   %}
 9619   ins_pipe(loadConFD); // FIXME
 9620 %}
 9621 
 9622 // Replicate scalar constant to packed byte values in Double register pair
 9623 instruct Repl4I_immU8(vecX dst, immU8 src) %{
 9624   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9625   match(Set dst (ReplicateI src));
 9626   size(4);
 9627 
 9628   format %{ &quot;VMOV.I32  $dst.Q,$src&quot; %}
 9629   ins_encode %{
 9630     bool quad = true;
 9631     __ vmovI($dst$$FloatRegister, $src$$constant,
 9632              MacroAssembler::VELEM_SIZE_32, quad);
 9633   %}
 9634   ins_pipe(loadConFD); // FIXME
 9635 %}
 9636 
 9637 // Replicate scalar to packed byte values in Double register pair
 9638 instruct Repl2L_reg(vecX dst, iRegL src) %{
 9639   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9640   match(Set dst (ReplicateL src));
 9641   size(8);
 9642   ins_cost(DEFAULT_COST*2); // FIXME
 9643 
 9644   format %{ &quot;FMDRR $dst.D,$src.lo,$src.hi\t\n&quot;
 9645             &quot;FMDRR $dst.D.next,$src.lo,$src.hi&quot; %}
 9646   ins_encode %{
 9647     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register-&gt;successor());
 9648     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9649              $src$$Register, $src$$Register-&gt;successor());
 9650   %}
 9651   ins_pipe(ialu_reg); // FIXME
 9652 %}
 9653 
 9654 
 9655 // Replicate scalar to packed float values in Double register
 9656 instruct Repl2F_regI(vecD dst, iRegI src) %{
 9657   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9658   match(Set dst (ReplicateF src));
 9659   size(4);
 9660 
 9661   format %{ &quot;FMDRR    $dst.D,$src,$src\t&quot; %}
 9662   ins_encode %{
 9663     __ fmdrr($dst$$FloatRegister, $src$$Register, $src$$Register);
 9664   %}
 9665   ins_pipe(ialu_reg); // FIXME
 9666 %}
 9667 
 9668 // Replicate scalar to packed float values in Double register
 9669 instruct Repl2F_reg_vfp(vecD dst, regF src) %{
 9670   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9671   match(Set dst (ReplicateF src));
 9672   size(4*2);
 9673   ins_cost(DEFAULT_COST*2); // FIXME
 9674 
 9675   expand %{
 9676     iRegI tmp;
 9677     MoveF2I_reg_reg(tmp, src);
 9678     Repl2F_regI(dst,tmp);
 9679   %}
 9680 %}
 9681 
 9682 // Replicate scalar to packed float values in Double register
 9683 instruct Repl2F_reg_simd(vecD dst, regF src) %{
 9684   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
 9685   match(Set dst (ReplicateF src));
 9686   size(4);
 9687   ins_cost(DEFAULT_COST); // FIXME
 9688 
 9689   format %{ &quot;VDUP.32  $dst.D,$src.D\t&quot; %}
 9690   ins_encode %{
 9691     bool quad = false;
 9692     __ vdupF($dst$$FloatRegister, $src$$FloatRegister, quad);
 9693   %}
 9694   ins_pipe(ialu_reg); // FIXME
 9695 %}
 9696 
 9697 // Replicate scalar to packed float values in Double register pair
 9698 instruct Repl4F_reg(vecX dst, regF src, iRegI tmp) %{
 9699   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9700   match(Set dst (ReplicateF src));
 9701   effect(TEMP tmp);
 9702   size(4*3);
 9703   ins_cost(DEFAULT_COST*3); // FIXME
 9704 
 9705   format %{ &quot;FMRS     $tmp,$src\n\t&quot;
 9706             &quot;FMDRR    $dst.D,$tmp,$tmp\n\t&quot;
 9707             &quot;FMDRR    $dst.D.next,$tmp,$tmp\t&quot; %}
 9708   ins_encode %{
 9709     __ fmrs($tmp$$Register, $src$$FloatRegister);
 9710     __ fmdrr($dst$$FloatRegister, $tmp$$Register, $tmp$$Register);
 9711     __ fmdrr($dst$$FloatRegister-&gt;successor()-&gt;successor(),
 9712              $tmp$$Register, $tmp$$Register);
 9713   %}
 9714   ins_pipe(ialu_reg); // FIXME
 9715 %}
 9716 
 9717 // Replicate scalar to packed float values in Double register pair
 9718 instruct Repl4F_reg_simd(vecX dst, regF src) %{
 9719   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
 9720   match(Set dst (ReplicateF src));
 9721   size(4);
 9722   ins_cost(DEFAULT_COST); // FIXME
 9723 
 9724   format %{ &quot;VDUP.32  $dst.Q,$src.D\t&quot; %}
 9725   ins_encode %{
 9726     bool quad = true;
 9727     __ vdupF($dst$$FloatRegister, $src$$FloatRegister, quad);
 9728   %}
 9729   ins_pipe(ialu_reg); // FIXME
 9730 %}
 9731 
 9732 // Replicate scalar zero constant to packed float values in Double register
 9733 instruct Repl2F_immI(vecD dst, immF src, iRegI tmp) %{
 9734   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9735   match(Set dst (ReplicateF src));
 9736   effect(TEMP tmp);
 9737   size(12);
 9738   ins_cost(DEFAULT_COST*4); // FIXME
 9739 
 9740   format %{ &quot;MOV      $tmp, Repl1($src))\n\t&quot;
 9741             &quot;FMDRR    $dst,$tmp,$tmp\t&quot; %}
 9742   ins_encode( LdReplImmF(src, dst, tmp) );
 9743   ins_pipe(loadConFD); // FIXME
 9744 %}
 9745 
 9746 // Replicate scalar to packed double float values in Double register pair
 9747 instruct Repl2D_reg(vecX dst, regD src) %{
 9748   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9749   match(Set dst (ReplicateD src));
 9750   size(4*2);
 9751   ins_cost(DEFAULT_COST*2); // FIXME
 9752 
 9753   format %{ &quot;FCPYD    $dst.D.a,$src\n\t&quot;
 9754             &quot;FCPYD    $dst.D.b,$src\t&quot; %}
 9755   ins_encode %{
 9756     FloatRegister dsta = $dst$$FloatRegister;
 9757     FloatRegister src = $src$$FloatRegister;
 9758     __ fcpyd(dsta, src);
 9759     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
 9760     __ fcpyd(dstb, src);
 9761   %}
 9762   ins_pipe(ialu_reg); // FIXME
 9763 %}
 9764 
 9765 // ====================VECTOR ARITHMETIC=======================================
 9766 
 9767 // --------------------------------- ADD --------------------------------------
 9768 
 9769 // Bytes vector add
 9770 instruct vadd8B_reg(vecD dst, vecD src1, vecD src2) %{
 9771   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9772   match(Set dst (AddVB src1 src2));
 9773   format %{ &quot;VADD.I8 $dst,$src1,$src2\t! add packed8B&quot; %}
 9774   size(4);
 9775   ins_encode %{
 9776     bool quad = false;
 9777     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9778              MacroAssembler::VELEM_SIZE_8, quad);
 9779   %}
 9780   ins_pipe( ialu_reg_reg ); // FIXME
 9781 %}
 9782 
 9783 instruct vadd16B_reg(vecX dst, vecX src1, vecX src2) %{
 9784   predicate(n-&gt;as_Vector()-&gt;length() == 16);
 9785   match(Set dst (AddVB src1 src2));
 9786   size(4);
 9787   format %{ &quot;VADD.I8 $dst.Q,$src1.Q,$src2.Q\t! add packed16B&quot; %}
 9788   ins_encode %{
 9789     bool quad = true;
 9790     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9791              MacroAssembler::VELEM_SIZE_8, quad);
 9792   %}
 9793   ins_pipe( ialu_reg_reg ); // FIXME
 9794 %}
 9795 
 9796 // Shorts/Chars vector add
 9797 instruct vadd4S_reg(vecD dst, vecD src1, vecD src2) %{
 9798   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9799   match(Set dst (AddVS src1 src2));
 9800   size(4);
 9801   format %{ &quot;VADD.I16 $dst,$src1,$src2\t! add packed4S&quot; %}
 9802   ins_encode %{
 9803     bool quad = false;
 9804     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9805              MacroAssembler::VELEM_SIZE_16, quad);
 9806   %}
 9807   ins_pipe( ialu_reg_reg ); // FIXME
 9808 %}
 9809 
 9810 instruct vadd8S_reg(vecX dst, vecX src1, vecX src2) %{
 9811   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9812   match(Set dst (AddVS src1 src2));
 9813   size(4);
 9814   format %{ &quot;VADD.I16 $dst.Q,$src1.Q,$src2.Q\t! add packed8S&quot; %}
 9815   ins_encode %{
 9816     bool quad = true;
 9817     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9818              MacroAssembler::VELEM_SIZE_16, quad);
 9819   %}
 9820   ins_pipe( ialu_reg_reg ); // FIXME
 9821 %}
 9822 
 9823 // Integers vector add
 9824 instruct vadd2I_reg(vecD dst, vecD src1, vecD src2) %{
 9825   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9826   match(Set dst (AddVI src1 src2));
 9827   size(4);
 9828   format %{ &quot;VADD.I32 $dst.D,$src1.D,$src2.D\t! add packed2I&quot; %}
 9829   ins_encode %{
 9830     bool quad = false;
 9831     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9832              MacroAssembler::VELEM_SIZE_32, quad);
 9833   %}
 9834   ins_pipe( ialu_reg_reg ); // FIXME
 9835 %}
 9836 
 9837 instruct vadd4I_reg(vecX dst, vecX src1, vecX src2) %{
 9838   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9839   match(Set dst (AddVI src1 src2));
 9840   size(4);
 9841   format %{ &quot;VADD.I32 $dst.Q,$src1.Q,$src2.Q\t! add packed4I&quot; %}
 9842   ins_encode %{
 9843     bool quad = true;
 9844     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9845              MacroAssembler::VELEM_SIZE_32, quad);
 9846   %}
 9847   ins_pipe( ialu_reg_reg ); // FIXME
 9848 %}
 9849 
 9850 // Longs vector add
 9851 instruct vadd2L_reg(vecX dst, vecX src1, vecX src2) %{
 9852   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9853   match(Set dst (AddVL src1 src2));
 9854   size(4);
 9855   format %{ &quot;VADD.I64 $dst.Q,$src1.Q,$src2.Q\t! add packed2L&quot; %}
 9856   ins_encode %{
 9857     bool quad = true;
 9858     __ vaddI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9859              MacroAssembler::VELEM_SIZE_64, quad);
 9860   %}
 9861   ins_pipe( ialu_reg_reg ); // FIXME
 9862 %}
 9863 
 9864 // Floats vector add
 9865 instruct vadd2F_reg(vecD dst, vecD src1, vecD src2) %{
 9866   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
 9867   match(Set dst (AddVF src1 src2));
 9868   size(4);
 9869   format %{ &quot;VADD.F32 $dst,$src1,$src2\t! add packed2F&quot; %}
 9870   ins_encode %{
 9871     bool quad = false;
 9872     __ vaddF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9873              MacroAssembler::VFA_SIZE_F32, quad);
 9874   %}
 9875   ins_pipe( faddD_reg_reg ); // FIXME
 9876 %}
 9877 
 9878 instruct vadd2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
 9879   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
 9880   match(Set dst (AddVF src1 src2));
 9881   ins_cost(DEFAULT_COST*2); // FIXME
 9882 
 9883   size(4*2);
 9884   format %{ &quot;FADDS  $dst.a,$src1.a,$src2.a\n\t&quot;
 9885             &quot;FADDS  $dst.b,$src1.b,$src2.b&quot; %}
 9886   ins_encode %{
 9887     __ add_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
 9888     __ add_float($dst$$FloatRegister-&gt;successor(),
 9889              $src1$$FloatRegister-&gt;successor(),
 9890              $src2$$FloatRegister-&gt;successor());
 9891   %}
 9892 
 9893   ins_pipe(faddF_reg_reg); // FIXME
 9894 %}
 9895 
 9896 instruct vadd4F_reg_simd(vecX dst, vecX src1, vecX src2) %{
 9897   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
 9898   match(Set dst (AddVF src1 src2));
 9899   size(4);
 9900   format %{ &quot;VADD.F32 $dst.Q,$src1.Q,$src2.Q\t! add packed4F&quot; %}
 9901   ins_encode %{
 9902     bool quad = true;
 9903     __ vaddF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9904              MacroAssembler::VFA_SIZE_F32, quad);
 9905   %}
 9906   ins_pipe( faddD_reg_reg ); // FIXME
 9907 %}
 9908 
 9909 instruct vadd4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
 9910   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
 9911   match(Set dst (AddVF src1 src2));
 9912   size(4*4);
 9913   ins_cost(DEFAULT_COST*4); // FIXME
 9914 
 9915   format %{ &quot;FADDS  $dst.a,$src1.a,$src2.a\n\t&quot;
 9916             &quot;FADDS  $dst.b,$src1.b,$src2.b\n\t&quot;
 9917             &quot;FADDS  $dst.c,$src1.c,$src2.c\n\t&quot;
 9918             &quot;FADDS  $dst.d,$src1.d,$src2.d&quot; %}
 9919 
 9920   ins_encode %{
 9921     FloatRegister dsta = $dst$$FloatRegister;
 9922     FloatRegister src1a = $src1$$FloatRegister;
 9923     FloatRegister src2a = $src2$$FloatRegister;
 9924     __ add_float(dsta, src1a, src2a);
 9925     FloatRegister dstb = dsta-&gt;successor();
 9926     FloatRegister src1b = src1a-&gt;successor();
 9927     FloatRegister src2b = src2a-&gt;successor();
 9928     __ add_float(dstb, src1b, src2b);
 9929     FloatRegister dstc = dstb-&gt;successor();
 9930     FloatRegister src1c = src1b-&gt;successor();
 9931     FloatRegister src2c = src2b-&gt;successor();
 9932     __ add_float(dstc, src1c, src2c);
 9933     FloatRegister dstd = dstc-&gt;successor();
 9934     FloatRegister src1d = src1c-&gt;successor();
 9935     FloatRegister src2d = src2c-&gt;successor();
 9936     __ add_float(dstd, src1d, src2d);
 9937   %}
 9938 
 9939   ins_pipe(faddF_reg_reg); // FIXME
 9940 %}
 9941 
 9942 instruct vadd2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
 9943   predicate(n-&gt;as_Vector()-&gt;length() == 2);
 9944   match(Set dst (AddVD src1 src2));
 9945   size(4*2);
 9946   ins_cost(DEFAULT_COST*2); // FIXME
 9947 
 9948   format %{ &quot;FADDD  $dst.a,$src1.a,$src2.a\n\t&quot;
 9949             &quot;FADDD  $dst.b,$src1.b,$src2.b&quot; %}
 9950 
 9951   ins_encode %{
 9952     FloatRegister dsta = $dst$$FloatRegister;
 9953     FloatRegister src1a = $src1$$FloatRegister;
 9954     FloatRegister src2a = $src2$$FloatRegister;
 9955     __ add_double(dsta, src1a, src2a);
 9956     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
 9957     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
 9958     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
 9959     __ add_double(dstb, src1b, src2b);
 9960   %}
 9961 
 9962   ins_pipe(faddF_reg_reg); // FIXME
 9963 %}
 9964 
 9965 
 9966 // Bytes vector sub
 9967 instruct vsub8B_reg(vecD dst, vecD src1, vecD src2) %{
 9968   predicate(n-&gt;as_Vector()-&gt;length() == 8);
 9969   match(Set dst (SubVB src1 src2));
 9970   size(4);
 9971   format %{ &quot;VSUB.I8 $dst,$src1,$src2\t! sub packed8B&quot; %}
 9972   ins_encode %{
 9973     bool quad = false;
 9974     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9975              MacroAssembler::VELEM_SIZE_8, quad);
 9976   %}
 9977   ins_pipe( ialu_reg_reg ); // FIXME
 9978 %}
 9979 
 9980 instruct vsub16B_reg(vecX dst, vecX src1, vecX src2) %{
 9981   predicate(n-&gt;as_Vector()-&gt;length() == 16);
 9982   match(Set dst (SubVB src1 src2));
 9983   size(4);
 9984   format %{ &quot;VSUB.I8 $dst.Q,$src1.Q,$src2.Q\t! sub packed16B&quot; %}
 9985   ins_encode %{
 9986     bool quad = true;
 9987     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
 9988              MacroAssembler::VELEM_SIZE_8, quad);
 9989   %}
 9990   ins_pipe( ialu_reg_reg ); // FIXME
 9991 %}
 9992 
 9993 // Shorts/Chars vector sub
 9994 instruct vsub4S_reg(vecD dst, vecD src1, vecD src2) %{
 9995   predicate(n-&gt;as_Vector()-&gt;length() == 4);
 9996   match(Set dst (SubVS src1 src2));
 9997   size(4);
 9998   format %{ &quot;VSUB.I16 $dst,$src1,$src2\t! sub packed4S&quot; %}
 9999   ins_encode %{
10000     bool quad = false;
10001     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10002              MacroAssembler::VELEM_SIZE_16, quad);
10003   %}
10004   ins_pipe( ialu_reg_reg ); // FIXME
10005 %}
10006 
10007 instruct vsub16S_reg(vecX dst, vecX src1, vecX src2) %{
10008   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10009   match(Set dst (SubVS src1 src2));
10010   size(4);
10011   format %{ &quot;VSUB.I16 $dst.Q,$src1.Q,$src2.Q\t! sub packed8S&quot; %}
10012   ins_encode %{
10013     bool quad = true;
10014     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10015              MacroAssembler::VELEM_SIZE_16, quad);
10016   %}
10017   ins_pipe( ialu_reg_reg ); // FIXME
10018 %}
10019 
10020 // Integers vector sub
10021 instruct vsub2I_reg(vecD dst, vecD src1, vecD src2) %{
10022   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10023   match(Set dst (SubVI src1 src2));
10024   size(4);
10025   format %{ &quot;VSUB.I32 $dst,$src1,$src2\t! sub packed2I&quot; %}
10026   ins_encode %{
10027     bool quad = false;
10028     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10029              MacroAssembler::VELEM_SIZE_32, quad);
10030   %}
10031   ins_pipe( ialu_reg_reg ); // FIXME
10032 %}
10033 
10034 instruct vsub4I_reg(vecX dst, vecX src1, vecX src2) %{
10035   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10036   match(Set dst (SubVI src1 src2));
10037   size(4);
10038   format %{ &quot;VSUB.I32 $dst.Q,$src1.Q,$src2.Q\t! sub packed4I&quot; %}
10039   ins_encode %{
10040     bool quad = true;
10041     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10042              MacroAssembler::VELEM_SIZE_32, quad);
10043   %}
10044   ins_pipe( ialu_reg_reg ); // FIXME
10045 %}
10046 
10047 // Longs vector sub
10048 instruct vsub2L_reg(vecX dst, vecX src1, vecX src2) %{
10049   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10050   match(Set dst (SubVL src1 src2));
10051   size(4);
10052   format %{ &quot;VSUB.I64 $dst.Q,$src1.Q,$src2.Q\t! sub packed2L&quot; %}
10053   ins_encode %{
10054     bool quad = true;
10055     __ vsubI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10056              MacroAssembler::VELEM_SIZE_64, quad);
10057   %}
10058   ins_pipe( ialu_reg_reg ); // FIXME
10059 %}
10060 
10061 // Floats vector sub
10062 instruct vsub2F_reg(vecD dst, vecD src1, vecD src2) %{
10063   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
10064   match(Set dst (SubVF src1 src2));
10065   size(4);
10066   format %{ &quot;VSUB.F32 $dst,$src1,$src2\t! sub packed2F&quot; %}
10067   ins_encode %{
10068     bool quad = false;
10069     __ vsubF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10070              MacroAssembler::VFA_SIZE_F32, quad);
10071   %}
10072   ins_pipe( faddF_reg_reg ); // FIXME
10073 %}
10074 
10075 instruct vsub2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10076   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
10077   match(Set dst (SubVF src1 src2));
10078   size(4*2);
10079   ins_cost(DEFAULT_COST*2); // FIXME
10080 
10081   format %{ &quot;FSUBS  $dst.a,$src1.a,$src2.a\n\t&quot;
10082             &quot;FSUBS  $dst.b,$src1.b,$src2.b&quot; %}
10083 
10084   ins_encode %{
10085     FloatRegister dsta = $dst$$FloatRegister;
10086     FloatRegister src1a = $src1$$FloatRegister;
10087     FloatRegister src2a = $src2$$FloatRegister;
10088     __ sub_float(dsta, src1a, src2a);
10089     FloatRegister dstb = dsta-&gt;successor();
10090     FloatRegister src1b = src1a-&gt;successor();
10091     FloatRegister src2b = src2a-&gt;successor();
10092     __ sub_float(dstb, src1b, src2b);
10093   %}
10094 
10095   ins_pipe(faddF_reg_reg); // FIXME
10096 %}
10097 
10098 
10099 instruct vsub4F_reg(vecX dst, vecX src1, vecX src2) %{
10100   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
10101   match(Set dst (SubVF src1 src2));
10102   size(4);
10103   format %{ &quot;VSUB.F32 $dst.Q,$src1.Q,$src2.Q\t! sub packed4F&quot; %}
10104   ins_encode %{
10105     bool quad = true;
10106     __ vsubF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10107              MacroAssembler::VFA_SIZE_F32, quad);
10108   %}
10109   ins_pipe( faddF_reg_reg ); // FIXME
10110 %}
10111 
10112 instruct vsub4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10113   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
10114   match(Set dst (SubVF src1 src2));
10115   size(4*4);
10116   ins_cost(DEFAULT_COST*4); // FIXME
10117 
10118   format %{ &quot;FSUBS  $dst.a,$src1.a,$src2.a\n\t&quot;
10119             &quot;FSUBS  $dst.b,$src1.b,$src2.b\n\t&quot;
10120             &quot;FSUBS  $dst.c,$src1.c,$src2.c\n\t&quot;
10121             &quot;FSUBS  $dst.d,$src1.d,$src2.d&quot; %}
10122 
10123   ins_encode %{
10124     FloatRegister dsta = $dst$$FloatRegister;
10125     FloatRegister src1a = $src1$$FloatRegister;
10126     FloatRegister src2a = $src2$$FloatRegister;
10127     __ sub_float(dsta, src1a, src2a);
10128     FloatRegister dstb = dsta-&gt;successor();
10129     FloatRegister src1b = src1a-&gt;successor();
10130     FloatRegister src2b = src2a-&gt;successor();
10131     __ sub_float(dstb, src1b, src2b);
10132     FloatRegister dstc = dstb-&gt;successor();
10133     FloatRegister src1c = src1b-&gt;successor();
10134     FloatRegister src2c = src2b-&gt;successor();
10135     __ sub_float(dstc, src1c, src2c);
10136     FloatRegister dstd = dstc-&gt;successor();
10137     FloatRegister src1d = src1c-&gt;successor();
10138     FloatRegister src2d = src2c-&gt;successor();
10139     __ sub_float(dstd, src1d, src2d);
10140   %}
10141 
10142   ins_pipe(faddF_reg_reg); // FIXME
10143 %}
10144 
10145 instruct vsub2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10146   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10147   match(Set dst (SubVD src1 src2));
10148   size(4*2);
10149   ins_cost(DEFAULT_COST*2); // FIXME
10150 
10151   format %{ &quot;FSUBD  $dst.a,$src1.a,$src2.a\n\t&quot;
10152             &quot;FSUBD  $dst.b,$src1.b,$src2.b&quot; %}
10153 
10154   ins_encode %{
10155     FloatRegister dsta = $dst$$FloatRegister;
10156     FloatRegister src1a = $src1$$FloatRegister;
10157     FloatRegister src2a = $src2$$FloatRegister;
10158     __ sub_double(dsta, src1a, src2a);
10159     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10160     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10161     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10162     __ sub_double(dstb, src1b, src2b);
10163   %}
10164 
10165   ins_pipe(faddF_reg_reg); // FIXME
10166 %}
10167 
10168 // Shorts/Chars vector mul
10169 instruct vmul4S_reg(vecD dst, vecD src1, vecD src2) %{
10170   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10171   match(Set dst (MulVS src1 src2));
10172   size(4);
10173   format %{ &quot;VMUL.I16 $dst,$src1,$src2\t! mul packed4S&quot; %}
10174   ins_encode %{
10175     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10176              MacroAssembler::VELEM_SIZE_16, 0);
10177   %}
10178   ins_pipe( ialu_reg_reg ); // FIXME
10179 %}
10180 
10181 instruct vmul8S_reg(vecX dst, vecX src1, vecX src2) %{
10182   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10183   match(Set dst (MulVS src1 src2));
10184   size(4);
10185   format %{ &quot;VMUL.I16 $dst.Q,$src1.Q,$src2.Q\t! mul packed8S&quot; %}
10186   ins_encode %{
10187     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10188              MacroAssembler::VELEM_SIZE_16, 1);
10189   %}
10190   ins_pipe( ialu_reg_reg ); // FIXME
10191 %}
10192 
10193 // Integers vector mul
10194 instruct vmul2I_reg(vecD dst, vecD src1, vecD src2) %{
10195   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10196   match(Set dst (MulVI src1 src2));
10197   size(4);
10198   format %{ &quot;VMUL.I32 $dst,$src1,$src2\t! mul packed2I&quot; %}
10199   ins_encode %{
10200     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10201              MacroAssembler::VELEM_SIZE_32, 0);
10202   %}
10203   ins_pipe( ialu_reg_reg ); // FIXME
10204 %}
10205 
10206 instruct vmul4I_reg(vecX dst, vecX src1, vecX src2) %{
10207   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10208   match(Set dst (MulVI src1 src2));
10209   size(4);
10210   format %{ &quot;VMUL.I32 $dst.Q,$src1.Q,$src2.Q\t! mul packed4I&quot; %}
10211   ins_encode %{
10212     __ vmulI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10213              MacroAssembler::VELEM_SIZE_32, 1);
10214   %}
10215   ins_pipe( ialu_reg_reg ); // FIXME
10216 %}
10217 
10218 // Floats vector mul
10219 instruct vmul2F_reg(vecD dst, vecD src1, vecD src2) %{
10220   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::simd_math_is_compliant());
10221   match(Set dst (MulVF src1 src2));
10222   size(4);
10223   format %{ &quot;VMUL.F32 $dst,$src1,$src2\t! mul packed2F&quot; %}
10224   ins_encode %{
10225     __ vmulF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10226              MacroAssembler::VFA_SIZE_F32, 0);
10227   %}
10228   ins_pipe( fmulF_reg_reg ); // FIXME
10229 %}
10230 
10231 instruct vmul2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10232   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; !VM_Version::simd_math_is_compliant());
10233   match(Set dst (MulVF src1 src2));
10234   size(4*2);
10235   ins_cost(DEFAULT_COST*2); // FIXME
10236 
10237   format %{ &quot;FMULS  $dst.a,$src1.a,$src2.a\n\t&quot;
10238             &quot;FMULS  $dst.b,$src1.b,$src2.b&quot; %}
10239   ins_encode %{
10240     __ mul_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
10241     __ mul_float($dst$$FloatRegister-&gt;successor(),
10242              $src1$$FloatRegister-&gt;successor(),
10243              $src2$$FloatRegister-&gt;successor());
10244   %}
10245 
10246   ins_pipe(fmulF_reg_reg); // FIXME
10247 %}
10248 
10249 instruct vmul4F_reg(vecX dst, vecX src1, vecX src2) %{
10250   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::simd_math_is_compliant());
10251   match(Set dst (MulVF src1 src2));
10252   size(4);
10253   format %{ &quot;VMUL.F32 $dst.Q,$src1.Q,$src2.Q\t! mul packed4F&quot; %}
10254   ins_encode %{
10255     __ vmulF($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
10256              MacroAssembler::VFA_SIZE_F32, 1);
10257   %}
10258   ins_pipe( fmulF_reg_reg ); // FIXME
10259 %}
10260 
10261 instruct vmul4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10262   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; !VM_Version::simd_math_is_compliant());
10263   match(Set dst (MulVF src1 src2));
10264   size(4*4);
10265   ins_cost(DEFAULT_COST*4); // FIXME
10266 
10267   format %{ &quot;FMULS  $dst.a,$src1.a,$src2.a\n\t&quot;
10268             &quot;FMULS  $dst.b,$src1.b,$src2.b\n\t&quot;
10269             &quot;FMULS  $dst.c,$src1.c,$src2.c\n\t&quot;
10270             &quot;FMULS  $dst.d,$src1.d,$src2.d&quot; %}
10271 
10272   ins_encode %{
10273     FloatRegister dsta = $dst$$FloatRegister;
10274     FloatRegister src1a = $src1$$FloatRegister;
10275     FloatRegister src2a = $src2$$FloatRegister;
10276     __ mul_float(dsta, src1a, src2a);
10277     FloatRegister dstb = dsta-&gt;successor();
10278     FloatRegister src1b = src1a-&gt;successor();
10279     FloatRegister src2b = src2a-&gt;successor();
10280     __ mul_float(dstb, src1b, src2b);
10281     FloatRegister dstc = dstb-&gt;successor();
10282     FloatRegister src1c = src1b-&gt;successor();
10283     FloatRegister src2c = src2b-&gt;successor();
10284     __ mul_float(dstc, src1c, src2c);
10285     FloatRegister dstd = dstc-&gt;successor();
10286     FloatRegister src1d = src1c-&gt;successor();
10287     FloatRegister src2d = src2c-&gt;successor();
10288     __ mul_float(dstd, src1d, src2d);
10289   %}
10290 
10291   ins_pipe(fmulF_reg_reg); // FIXME
10292 %}
10293 
10294 instruct vmul2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10295   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10296   match(Set dst (MulVD src1 src2));
10297   size(4*2);
10298   ins_cost(DEFAULT_COST*2); // FIXME
10299 
10300   format %{ &quot;FMULD  $dst.D.a,$src1.D.a,$src2.D.a\n\t&quot;
10301             &quot;FMULD  $dst.D.b,$src1.D.b,$src2.D.b&quot; %}
10302   ins_encode %{
10303     FloatRegister dsta = $dst$$FloatRegister;
10304     FloatRegister src1a = $src1$$FloatRegister;
10305     FloatRegister src2a = $src2$$FloatRegister;
10306     __ mul_double(dsta, src1a, src2a);
10307     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10308     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10309     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10310     __ mul_double(dstb, src1b, src2b);
10311   %}
10312 
10313   ins_pipe(fmulD_reg_reg); // FIXME
10314 %}
10315 
10316 
10317 // Floats vector div
10318 instruct vdiv2F_reg_vfp(vecD dst, vecD src1, vecD src2) %{
10319   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10320   match(Set dst (DivVF src1 src2));
10321   size(4*2);
10322   ins_cost(DEFAULT_COST*2); // FIXME
10323 
10324   format %{ &quot;FDIVS  $dst.a,$src1.a,$src2.a\n\t&quot;
10325             &quot;FDIVS  $dst.b,$src1.b,$src2.b&quot; %}
10326   ins_encode %{
10327     __ div_float($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);
10328     __ div_float($dst$$FloatRegister-&gt;successor(),
10329              $src1$$FloatRegister-&gt;successor(),
10330              $src2$$FloatRegister-&gt;successor());
10331   %}
10332 
10333   ins_pipe(fdivF_reg_reg); // FIXME
10334 %}
10335 
10336 instruct vdiv4F_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10337   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10338   match(Set dst (DivVF src1 src2));
10339   size(4*4);
10340   ins_cost(DEFAULT_COST*4); // FIXME
10341 
10342   format %{ &quot;FDIVS  $dst.a,$src1.a,$src2.a\n\t&quot;
10343             &quot;FDIVS  $dst.b,$src1.b,$src2.b\n\t&quot;
10344             &quot;FDIVS  $dst.c,$src1.c,$src2.c\n\t&quot;
10345             &quot;FDIVS  $dst.d,$src1.d,$src2.d&quot; %}
10346 
10347   ins_encode %{
10348     FloatRegister dsta = $dst$$FloatRegister;
10349     FloatRegister src1a = $src1$$FloatRegister;
10350     FloatRegister src2a = $src2$$FloatRegister;
10351     __ div_float(dsta, src1a, src2a);
10352     FloatRegister dstb = dsta-&gt;successor();
10353     FloatRegister src1b = src1a-&gt;successor();
10354     FloatRegister src2b = src2a-&gt;successor();
10355     __ div_float(dstb, src1b, src2b);
10356     FloatRegister dstc = dstb-&gt;successor();
10357     FloatRegister src1c = src1b-&gt;successor();
10358     FloatRegister src2c = src2b-&gt;successor();
10359     __ div_float(dstc, src1c, src2c);
10360     FloatRegister dstd = dstc-&gt;successor();
10361     FloatRegister src1d = src1c-&gt;successor();
10362     FloatRegister src2d = src2c-&gt;successor();
10363     __ div_float(dstd, src1d, src2d);
10364   %}
10365 
10366   ins_pipe(fdivF_reg_reg); // FIXME
10367 %}
10368 
10369 instruct vdiv2D_reg_vfp(vecX dst, vecX src1, vecX src2) %{
10370   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10371   match(Set dst (DivVD src1 src2));
10372   size(4*2);
10373   ins_cost(DEFAULT_COST*2); // FIXME
10374 
10375   format %{ &quot;FDIVD  $dst.D.a,$src1.D.a,$src2.D.a\n\t&quot;
10376             &quot;FDIVD  $dst.D.b,$src1.D.b,$src2.D.b&quot; %}
10377   ins_encode %{
10378     FloatRegister dsta = $dst$$FloatRegister;
10379     FloatRegister src1a = $src1$$FloatRegister;
10380     FloatRegister src2a = $src2$$FloatRegister;
10381     __ div_double(dsta, src1a, src2a);
10382     FloatRegister dstb = dsta-&gt;successor()-&gt;successor();
10383     FloatRegister src1b = src1a-&gt;successor()-&gt;successor();
10384     FloatRegister src2b = src2a-&gt;successor()-&gt;successor();
10385     __ div_double(dstb, src1b, src2b);
10386   %}
10387 
10388   ins_pipe(fdivD_reg_reg); // FIXME
10389 %}
10390 
10391 // --------------------------------- NEG --------------------------------------
10392 
10393 instruct vneg8B_reg(vecD dst, vecD src) %{
10394   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
10395   effect(DEF dst, USE src);
10396   size(4);
10397   ins_cost(DEFAULT_COST); // FIXME
10398   format %{ &quot;VNEG.S8 $dst.D,$src.D\t! neg packed8B&quot; %}
10399   ins_encode %{
10400     bool quad = false;
10401     __ vnegI($dst$$FloatRegister, $src$$FloatRegister,
10402               MacroAssembler::VELEM_SIZE_8, quad);
10403   %}
10404   ins_pipe( ialu_reg_reg ); // FIXME
10405 %}
10406 
10407 instruct vneg16B_reg(vecX dst, vecX src) %{
10408   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
10409   effect(DEF dst, USE src);
10410   size(4);
10411   ins_cost(DEFAULT_COST); // FIXME
10412   format %{ &quot;VNEG.S8 $dst.Q,$src.Q\t! neg0 packed16B&quot; %}
10413   ins_encode %{
10414     bool _float = false;
10415     bool quad = true;
10416     __ vnegI($dst$$FloatRegister, $src$$FloatRegister,
10417               MacroAssembler::VELEM_SIZE_8, quad);
10418   %}
10419   ins_pipe( ialu_reg_reg ); // FIXME
10420 %}
10421 
10422 // ------------------------------ Shift ---------------------------------------
10423 
10424 instruct vslcntD(vecD dst, iRegI cnt) %{
10425   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
10426   match(Set dst (LShiftCntV cnt));
10427   size(4);
10428   ins_cost(DEFAULT_COST); // FIXME
10429   expand %{
10430     Repl8B_reg_simd(dst, cnt);
10431   %}
10432 %}
10433 
10434 instruct vslcntX(vecX dst, iRegI cnt) %{
10435   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
10436   match(Set dst (LShiftCntV cnt));
10437   size(4);
10438   ins_cost(DEFAULT_COST); // FIXME
10439   expand %{
10440     Repl16B_reg(dst, cnt);
10441   %}
10442 %}
10443 
10444 // Low bits of vector &quot;shift&quot; elements are used, so it
10445 // doesn&#39;t matter if we treat it as ints or bytes here.
10446 instruct vsrcntD(vecD dst, iRegI cnt) %{
10447   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8 &amp;&amp; VM_Version::has_simd());
10448   match(Set dst (RShiftCntV cnt));
10449   size(4*2);
10450   ins_cost(DEFAULT_COST*2); // FIXME
10451 
10452   format %{ &quot;VDUP.8 $dst.D,$cnt\n\t&quot;
10453             &quot;VNEG.S8 $dst.D,$dst.D\t! neg packed8B&quot; %}
10454   ins_encode %{
10455     bool quad = false;
10456     __ vdupI($dst$$FloatRegister, $cnt$$Register,
10457              MacroAssembler::VELEM_SIZE_8, quad);
10458     __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,
10459               MacroAssembler::VELEM_SIZE_8, quad);
10460   %}
10461   ins_pipe( ialu_reg_reg ); // FIXME
10462 %}
10463 
10464 instruct vsrcntX(vecX dst, iRegI cnt) %{
10465   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16 &amp;&amp; VM_Version::has_simd());
10466   match(Set dst (RShiftCntV cnt));
10467   size(4*2);
10468   ins_cost(DEFAULT_COST*2); // FIXME
10469   format %{ &quot;VDUP.8 $dst.Q,$cnt\n\t&quot;
10470             &quot;VNEG.S8 $dst.Q,$dst.Q\t! neg packed16B&quot; %}
10471   ins_encode %{
10472     bool quad = true;
10473     __ vdupI($dst$$FloatRegister, $cnt$$Register,
10474              MacroAssembler::VELEM_SIZE_8, quad);
10475     __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,
10476               MacroAssembler::VELEM_SIZE_8, quad);
10477   %}
10478   ins_pipe( ialu_reg_reg ); // FIXME
10479 %}
10480 
10481 // Byte vector logical left/right shift based on sign
10482 instruct vsh8B_reg(vecD dst, vecD src, vecD shift) %{
10483   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10484   effect(DEF dst, USE src, USE shift);
10485   size(4);
10486   ins_cost(DEFAULT_COST); // FIXME
10487   format %{
10488     &quot;VSHL.U8 $dst.D,$src.D,$shift.D\t! logical left/right shift packed8B&quot;
10489   %}
10490   ins_encode %{
10491     bool quad = false;
10492     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10493               MacroAssembler::VELEM_SIZE_8, quad);
10494   %}
10495   ins_pipe( ialu_reg_reg ); // FIXME
10496 %}
10497 
10498 instruct vsh16B_reg(vecX dst, vecX src, vecX shift) %{
10499   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10500   effect(DEF dst, USE src, USE shift);
10501   size(4);
10502   ins_cost(DEFAULT_COST); // FIXME
10503   format %{
10504     &quot;VSHL.U8 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed16B&quot;
10505   %}
10506   ins_encode %{
10507     bool quad = true;
10508     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10509               MacroAssembler::VELEM_SIZE_8, quad);
10510   %}
10511   ins_pipe( ialu_reg_reg ); // FIXME
10512 %}
10513 
10514 // Shorts/Char vector logical left/right shift based on sign
10515 instruct vsh4S_reg(vecD dst, vecD src, vecD shift) %{
10516   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10517   effect(DEF dst, USE src, USE shift);
10518   size(4);
10519   ins_cost(DEFAULT_COST); // FIXME
10520   format %{
10521     &quot;VSHL.U16 $dst.D,$src.D,$shift.D\t! logical left/right shift packed4S&quot;
10522   %}
10523   ins_encode %{
10524     bool quad = false;
10525     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10526               MacroAssembler::VELEM_SIZE_16, quad);
10527   %}
10528   ins_pipe( ialu_reg_reg ); // FIXME
10529 %}
10530 
10531 instruct vsh8S_reg(vecX dst, vecX src, vecX shift) %{
10532   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10533   effect(DEF dst, USE src, USE shift);
10534   size(4);
10535   ins_cost(DEFAULT_COST); // FIXME
10536   format %{
10537     &quot;VSHL.U16 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed8S&quot;
10538   %}
10539   ins_encode %{
10540     bool quad = true;
10541     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10542               MacroAssembler::VELEM_SIZE_16, quad);
10543   %}
10544   ins_pipe( ialu_reg_reg ); // FIXME
10545 %}
10546 
10547 // Integers vector logical left/right shift based on sign
10548 instruct vsh2I_reg(vecD dst, vecD src, vecD shift) %{
10549   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10550   effect(DEF dst, USE src, USE shift);
10551   size(4);
10552   ins_cost(DEFAULT_COST); // FIXME
10553   format %{
10554     &quot;VSHL.U32 $dst.D,$src.D,$shift.D\t! logical left/right shift packed2I&quot;
10555   %}
10556   ins_encode %{
10557     bool quad = false;
10558     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10559               MacroAssembler::VELEM_SIZE_32, quad);
10560   %}
10561   ins_pipe( ialu_reg_reg ); // FIXME
10562 %}
10563 
10564 instruct vsh4I_reg(vecX dst, vecX src, vecX shift) %{
10565   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10566   effect(DEF dst, USE src, USE shift);
10567   size(4);
10568   ins_cost(DEFAULT_COST); // FIXME
10569   format %{
10570     &quot;VSHL.U32 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed4I&quot;
10571   %}
10572   ins_encode %{
10573     bool quad = true;
10574     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10575               MacroAssembler::VELEM_SIZE_32, quad);
10576   %}
10577   ins_pipe( ialu_reg_reg ); // FIXME
10578 %}
10579 
10580 // Longs vector logical left/right shift based on sign
10581 instruct vsh2L_reg(vecX dst, vecX src, vecX shift) %{
10582   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10583   effect(DEF dst, USE src, USE shift);
10584   size(4);
10585   ins_cost(DEFAULT_COST); // FIXME
10586   format %{
10587     &quot;VSHL.U64 $dst.Q,$src.Q,$shift.Q\t! logical left/right shift packed2L&quot;
10588   %}
10589   ins_encode %{
10590     bool quad = true;
10591     __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10592               MacroAssembler::VELEM_SIZE_64, quad);
10593   %}
10594   ins_pipe( ialu_reg_reg ); // FIXME
10595 %}
10596 
10597 // ------------------------------ LeftShift -----------------------------------
10598 
10599 // Byte vector left shift
10600 instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{
10601   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10602   match(Set dst (LShiftVB src shift));
10603   size(4*1);
10604   ins_cost(DEFAULT_COST*1); // FIXME
10605   expand %{
10606     vsh8B_reg(dst, src, shift);
10607   %}
10608 %}
10609 
10610 instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{
10611   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10612   match(Set dst (LShiftVB src shift));
10613   size(4*1);
10614   ins_cost(DEFAULT_COST*1); // FIXME
10615   expand %{
10616     vsh16B_reg(dst, src, shift);
10617   %}
10618 %}
10619 
10620 instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{
10621   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10622   match(Set dst (LShiftVB src shift));
10623   size(4);
10624   ins_cost(DEFAULT_COST); // FIXME
10625   format %{
10626     &quot;VSHL.I8 $dst.D,$src.D,$shift\t! logical left shift packed8B&quot;
10627   %}
10628   ins_encode %{
10629     bool quad = false;
10630     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10631              quad);
10632   %}
10633   ins_pipe( ialu_reg_reg ); // FIXME
10634 %}
10635 
10636 instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{
10637   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10638   match(Set dst (LShiftVB src shift));
10639   size(4);
10640   ins_cost(DEFAULT_COST); // FIXME
10641   format %{
10642     &quot;VSHL.I8 $dst.Q,$src.Q,$shift\t! logical left shift packed16B&quot;
10643   %}
10644   ins_encode %{
10645     bool quad = true;
10646     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
10647              quad);
10648   %}
10649   ins_pipe( ialu_reg_reg ); // FIXME
10650 %}
10651 
10652 // Shorts/Chars vector logical left/right shift
10653 instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{
10654   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10655   match(Set dst (LShiftVS src shift));
10656   match(Set dst (URShiftVS src shift));
10657   size(4*1);
10658   ins_cost(DEFAULT_COST*1); // FIXME
10659   expand %{
10660     vsh4S_reg(dst, src, shift);
10661   %}
10662 %}
10663 
10664 instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{
10665   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10666   match(Set dst (LShiftVS src shift));
10667   match(Set dst (URShiftVS src shift));
10668   size(4*1);
10669   ins_cost(DEFAULT_COST*1); // FIXME
10670   expand %{
10671     vsh8S_reg(dst, src, shift);
10672   %}
10673 %}
10674 
10675 instruct vsl4S_immI(vecD dst, vecD src, immI shift) %{
10676   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10677   match(Set dst (LShiftVS src shift));
10678   size(4);
10679   ins_cost(DEFAULT_COST); // FIXME
10680   format %{
10681     &quot;VSHL.I16 $dst.D,$src.D,$shift\t! logical left shift packed4S&quot;
10682   %}
10683   ins_encode %{
10684     bool quad = false;
10685     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10686              quad);
10687   %}
10688   ins_pipe( ialu_reg_reg ); // FIXME
10689 %}
10690 
10691 instruct vsl8S_immI(vecX dst, vecX src, immI shift) %{
10692   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10693   match(Set dst (LShiftVS src shift));
10694   size(4);
10695   ins_cost(DEFAULT_COST); // FIXME
10696   format %{
10697     &quot;VSHL.I16 $dst.Q,$src.Q,$shift\t! logical left shift packed8S&quot;
10698   %}
10699   ins_encode %{
10700     bool quad = true;
10701     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10702              quad);
10703   %}
10704   ins_pipe( ialu_reg_reg ); // FIXME
10705 %}
10706 
10707 // Integers vector logical left/right shift
10708 instruct vsl2I_reg(vecD dst, vecD src, vecD shift) %{
10709   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10710   match(Set dst (LShiftVI src shift));
10711   match(Set dst (URShiftVI src shift));
10712   size(4*1);
10713   ins_cost(DEFAULT_COST*1); // FIXME
10714   expand %{
10715     vsh2I_reg(dst, src, shift);
10716   %}
10717 %}
10718 
10719 instruct vsl4I_reg(vecX dst, vecX src, vecX shift) %{
10720   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10721   match(Set dst (LShiftVI src shift));
10722   match(Set dst (URShiftVI src shift));
10723   size(4*1);
10724   ins_cost(DEFAULT_COST*1); // FIXME
10725   expand %{
10726     vsh4I_reg(dst, src, shift);
10727   %}
10728 %}
10729 
10730 instruct vsl2I_immI(vecD dst, vecD src, immI shift) %{
10731   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10732   match(Set dst (LShiftVI src shift));
10733   size(4);
10734   ins_cost(DEFAULT_COST); // FIXME
10735   format %{
10736     &quot;VSHL.I32 $dst.D,$src.D,$shift\t! logical left shift packed2I&quot;
10737   %}
10738   ins_encode %{
10739     bool quad = false;
10740     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10741              quad);
10742   %}
10743   ins_pipe( ialu_reg_reg ); // FIXME
10744 %}
10745 
10746 instruct vsl4I_immI(vecX dst, vecX src, immI shift) %{
10747   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10748   match(Set dst (LShiftVI src shift));
10749   size(4);
10750   ins_cost(DEFAULT_COST); // FIXME
10751   format %{
10752     &quot;VSHL.I32 $dst.Q,$src.Q,$shift\t! logical left shift packed4I&quot;
10753   %}
10754   ins_encode %{
10755     bool quad = true;
10756     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10757              quad);
10758   %}
10759   ins_pipe( ialu_reg_reg ); // FIXME
10760 %}
10761 
10762 // Longs vector logical left/right shift
10763 instruct vsl2L_reg(vecX dst, vecX src, vecX shift) %{
10764   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10765   match(Set dst (LShiftVL src shift));
10766   match(Set dst (URShiftVL src shift));
10767   size(4*1);
10768   ins_cost(DEFAULT_COST*1); // FIXME
10769   expand %{
10770     vsh2L_reg(dst, src, shift);
10771   %}
10772 %}
10773 
10774 instruct vsl2L_immI(vecX dst, vecX src, immI shift) %{
10775   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10776   match(Set dst (LShiftVL src shift));
10777   size(4);
10778   ins_cost(DEFAULT_COST); // FIXME
10779   format %{
10780     &quot;VSHL.I64 $dst.Q,$src.Q,$shift\t! logical left shift packed2L&quot;
10781   %}
10782   ins_encode %{
10783     bool quad = true;
10784     __ vshli($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10785              quad);
10786   %}
10787   ins_pipe( ialu_reg_reg ); // FIXME
10788 %}
10789 
10790 // ----------------------- LogicalRightShift -----------------------------------
10791 
10792 // Bytes/Shorts vector logical right shift produces incorrect Java result
10793 // for negative data because java code convert short value into int with
10794 // sign extension before a shift.
10795 
10796 // Chars vector logical right shift
10797 instruct vsrl4S_immI(vecD dst, vecD src, immI shift) %{
10798   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10799   match(Set dst (URShiftVS src shift));
10800   size(4);
10801   ins_cost(DEFAULT_COST); // FIXME
10802   format %{
10803     &quot;VSHR.U16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
10804   %}
10805   ins_encode %{
10806     bool quad = false;
10807     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10808              quad);
10809   %}
10810   ins_pipe( ialu_reg_reg ); // FIXME
10811 %}
10812 
10813 instruct vsrl8S_immI(vecX dst, vecX src, immI shift) %{
10814   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10815   match(Set dst (URShiftVS src shift));
10816   size(4);
10817   ins_cost(DEFAULT_COST); // FIXME
10818   format %{
10819     &quot;VSHR.U16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
10820   %}
10821   ins_encode %{
10822     bool quad = true;
10823     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
10824              quad);
10825   %}
10826   ins_pipe( ialu_reg_reg ); // FIXME
10827 %}
10828 
10829 // Integers vector logical right shift
10830 instruct vsrl2I_immI(vecD dst, vecD src, immI shift) %{
10831   predicate(n-&gt;as_Vector()-&gt;length() == 2 &amp;&amp; VM_Version::has_simd());
10832   match(Set dst (URShiftVI src shift));
10833   size(4);
10834   ins_cost(DEFAULT_COST); // FIXME
10835   format %{
10836     &quot;VSHR.U32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
10837   %}
10838   ins_encode %{
10839     bool quad = false;
10840     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10841              quad);
10842   %}
10843   ins_pipe( ialu_reg_reg ); // FIXME
10844 %}
10845 
10846 instruct vsrl4I_immI(vecX dst, vecX src, immI shift) %{
10847   predicate(n-&gt;as_Vector()-&gt;length() == 4 &amp;&amp; VM_Version::has_simd());
10848   match(Set dst (URShiftVI src shift));
10849   size(4);
10850   ins_cost(DEFAULT_COST); // FIXME
10851   format %{
10852     &quot;VSHR.U32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
10853   %}
10854   ins_encode %{
10855     bool quad = true;
10856     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
10857              quad);
10858   %}
10859   ins_pipe( ialu_reg_reg ); // FIXME
10860 %}
10861 
10862 // Longs vector logical right shift
10863 instruct vsrl2L_immI(vecX dst, vecX src, immI shift) %{
10864   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10865   match(Set dst (URShiftVL src shift));
10866   size(4);
10867   ins_cost(DEFAULT_COST); // FIXME
10868   format %{
10869     &quot;VSHR.U64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
10870   %}
10871   ins_encode %{
10872     bool quad = true;
10873     __ vshrUI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
10874              quad);
10875   %}
10876   ins_pipe( ialu_reg_reg ); // FIXME
10877 %}
10878 
10879 // ------------------- ArithmeticRightShift -----------------------------------
10880 
10881 // Bytes vector arithmetic left/right shift based on sign
10882 instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{
10883   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10884   effect(DEF dst, USE src, USE shift);
10885   size(4);
10886   ins_cost(DEFAULT_COST); // FIXME
10887   format %{
10888     &quot;VSHL.S8 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed8B&quot;
10889   %}
10890   ins_encode %{
10891     bool quad = false;
10892     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10893               MacroAssembler::VELEM_SIZE_8, quad);
10894   %}
10895   ins_pipe( ialu_reg_reg ); // FIXME
10896 %}
10897 
10898 instruct vsha16B_reg(vecX dst, vecX src, vecX shift) %{
10899   predicate(n-&gt;as_Vector()-&gt;length() == 16);
10900   effect(DEF dst, USE src, USE shift);
10901   size(4);
10902   ins_cost(DEFAULT_COST); // FIXME
10903   format %{
10904     &quot;VSHL.S8 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed16B&quot;
10905   %}
10906   ins_encode %{
10907     bool quad = true;
10908     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10909               MacroAssembler::VELEM_SIZE_8, quad);
10910   %}
10911   ins_pipe( ialu_reg_reg ); // FIXME
10912 %}
10913 
10914 // Shorts vector arithmetic left/right shift based on sign
10915 instruct vsha4S_reg(vecD dst, vecD src, vecD shift) %{
10916   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10917   effect(DEF dst, USE src, USE shift);
10918   size(4);
10919   ins_cost(DEFAULT_COST); // FIXME
10920   format %{
10921     &quot;VSHL.S16 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed4S&quot;
10922   %}
10923   ins_encode %{
10924     bool quad = false;
10925     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10926               MacroAssembler::VELEM_SIZE_16, quad);
10927   %}
10928   ins_pipe( ialu_reg_reg ); // FIXME
10929 %}
10930 
10931 instruct vsha8S_reg(vecX dst, vecX src, vecX shift) %{
10932   predicate(n-&gt;as_Vector()-&gt;length() == 8);
10933   effect(DEF dst, USE src, USE shift);
10934   size(4);
10935   ins_cost(DEFAULT_COST); // FIXME
10936   format %{
10937     &quot;VSHL.S16 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed8S&quot;
10938   %}
10939   ins_encode %{
10940     bool quad = true;
10941     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10942               MacroAssembler::VELEM_SIZE_16, quad);
10943   %}
10944   ins_pipe( ialu_reg_reg ); // FIXME
10945 %}
10946 
10947 // Integers vector arithmetic left/right shift based on sign
10948 instruct vsha2I_reg(vecD dst, vecD src, vecD shift) %{
10949   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10950   effect(DEF dst, USE src, USE shift);
10951   size(4);
10952   ins_cost(DEFAULT_COST); // FIXME
10953   format %{
10954     &quot;VSHL.S32 $dst.D,$src.D,$shift.D\t! arithmetic right shift packed2I&quot;
10955   %}
10956   ins_encode %{
10957     bool quad = false;
10958     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10959               MacroAssembler::VELEM_SIZE_32, quad);
10960   %}
10961   ins_pipe( ialu_reg_reg ); // FIXME
10962 %}
10963 
10964 instruct vsha4I_reg(vecX dst, vecX src, vecX shift) %{
10965   predicate(n-&gt;as_Vector()-&gt;length() == 4);
10966   effect(DEF dst, USE src, USE shift);
10967   size(4);
10968   ins_cost(DEFAULT_COST); // FIXME
10969   format %{
10970     &quot;VSHL.S32 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed4I&quot;
10971   %}
10972   ins_encode %{
10973     bool quad = true;
10974     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10975               MacroAssembler::VELEM_SIZE_32, quad);
10976   %}
10977   ins_pipe( ialu_reg_reg ); // FIXME
10978 %}
10979 
10980 // Longs vector arithmetic left/right shift based on sign
10981 instruct vsha2L_reg(vecX dst, vecX src, vecX shift) %{
10982   predicate(n-&gt;as_Vector()-&gt;length() == 2);
10983   effect(DEF dst, USE src, USE shift);
10984   size(4);
10985   ins_cost(DEFAULT_COST); // FIXME
10986   format %{
10987     &quot;VSHL.S64 $dst.Q,$src.Q,$shift.Q\t! arithmetic right shift packed2L&quot;
10988   %}
10989   ins_encode %{
10990     bool quad = true;
10991     __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,
10992               MacroAssembler::VELEM_SIZE_64, quad);
10993   %}
10994   ins_pipe( ialu_reg_reg ); // FIXME
10995 %}
10996 
10997 // Byte vector arithmetic right shift
10998 
10999 instruct vsra8B_reg(vecD dst, vecD src, vecD shift) %{
11000   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11001   match(Set dst (RShiftVB src shift));
11002   size(4);
11003   ins_cost(DEFAULT_COST); // FIXME
11004   expand %{
11005     vsha8B_reg(dst, src, shift);
11006   %}
11007 %}
11008 
11009 instruct vsrl16B_reg(vecX dst, vecX src, vecX shift) %{
11010   predicate(n-&gt;as_Vector()-&gt;length() == 16);
11011   match(Set dst (RShiftVB src shift));
11012   size(4);
11013   ins_cost(DEFAULT_COST); // FIXME
11014   expand %{
11015     vsha16B_reg(dst, src, shift);
11016   %}
11017 %}
11018 
11019 instruct vsrl8B_immI(vecD dst, vecD src, immI shift) %{
11020   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11021   match(Set dst (RShiftVB src shift));
11022   size(4);
11023   ins_cost(DEFAULT_COST); // FIXME
11024   format %{
11025     &quot;VSHR.S8 $dst.D,$src.D,$shift\t! logical right shift packed8B&quot;
11026   %}
11027   ins_encode %{
11028     bool quad = false;
11029     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
11030              quad);
11031   %}
11032   ins_pipe( ialu_reg_reg ); // FIXME
11033 %}
11034 
11035 instruct vsrl16B_immI(vecX dst, vecX src, immI shift) %{
11036   predicate(n-&gt;as_Vector()-&gt;length() == 16);
11037   match(Set dst (RShiftVB src shift));
11038   size(4);
11039   ins_cost(DEFAULT_COST); // FIXME
11040   format %{
11041     &quot;VSHR.S8 $dst.Q,$src.Q,$shift\t! logical right shift packed16B&quot;
11042   %}
11043   ins_encode %{
11044     bool quad = true;
11045     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,
11046              quad);
11047   %}
11048   ins_pipe( ialu_reg_reg ); // FIXME
11049 %}
11050 
11051 // Shorts vector arithmetic right shift
11052 instruct vsra4S_reg(vecD dst, vecD src, vecD shift) %{
11053   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11054   match(Set dst (RShiftVS src shift));
11055   size(4);
11056   ins_cost(DEFAULT_COST); // FIXME
11057   expand %{
11058     vsha4S_reg(dst, src, shift);
11059   %}
11060 %}
11061 
11062 instruct vsra8S_reg(vecX dst, vecX src, vecX shift) %{
11063   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11064   match(Set dst (RShiftVS src shift));
11065   size(4);
11066   ins_cost(DEFAULT_COST); // FIXME
11067   expand %{
11068     vsha8S_reg(dst, src, shift);
11069   %}
11070 %}
11071 
11072 instruct vsra4S_immI(vecD dst, vecD src, immI shift) %{
11073   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11074   match(Set dst (RShiftVS src shift));
11075   size(4);
11076   ins_cost(DEFAULT_COST); // FIXME
11077   format %{
11078     &quot;VSHR.S16 $dst.D,$src.D,$shift\t! logical right shift packed4S&quot;
11079   %}
11080   ins_encode %{
11081     bool quad = false;
11082     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
11083              quad);
11084   %}
11085   ins_pipe( ialu_reg_reg ); // FIXME
11086 %}
11087 
11088 instruct vsra8S_immI(vecX dst, vecX src, immI shift) %{
11089   predicate(n-&gt;as_Vector()-&gt;length() == 8);
11090   match(Set dst (RShiftVS src shift));
11091   size(4);
11092   ins_cost(DEFAULT_COST); // FIXME
11093   format %{
11094     &quot;VSHR.S16 $dst.Q,$src.Q,$shift\t! logical right shift packed8S&quot;
11095   %}
11096   ins_encode %{
11097     bool quad = true;
11098     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 16, $shift$$constant,
11099              quad);
11100   %}
11101   ins_pipe( ialu_reg_reg ); // FIXME
11102 %}
11103 
11104 // Integers vector arithmetic right shift
11105 instruct vsra2I_reg(vecD dst, vecD src, vecD shift) %{
11106   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11107   match(Set dst (RShiftVI src shift));
11108   size(4);
11109   ins_cost(DEFAULT_COST); // FIXME
11110   expand %{
11111     vsha2I_reg(dst, src, shift);
11112   %}
11113 %}
11114 
11115 instruct vsra4I_reg(vecX dst, vecX src, vecX shift) %{
11116   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11117   match(Set dst (RShiftVI src shift));
11118   size(4);
11119   ins_cost(DEFAULT_COST); // FIXME
11120   expand %{
11121     vsha4I_reg(dst, src, shift);
11122   %}
11123 %}
11124 
11125 instruct vsra2I_immI(vecD dst, vecD src, immI shift) %{
11126   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11127   match(Set dst (RShiftVI src shift));
11128   size(4);
11129   ins_cost(DEFAULT_COST); // FIXME
11130   format %{
11131     &quot;VSHR.S32 $dst.D,$src.D,$shift\t! logical right shift packed2I&quot;
11132   %}
11133   ins_encode %{
11134     bool quad = false;
11135     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
11136              quad);
11137   %}
11138   ins_pipe( ialu_reg_reg ); // FIXME
11139 %}
11140 
11141 instruct vsra4I_immI(vecX dst, vecX src, immI shift) %{
11142   predicate(n-&gt;as_Vector()-&gt;length() == 4);
11143   match(Set dst (RShiftVI src shift));
11144   size(4);
11145   ins_cost(DEFAULT_COST); // FIXME
11146   format %{
11147     &quot;VSHR.S32 $dst.Q,$src.Q,$shift\t! logical right shift packed4I&quot;
11148   %}
11149   ins_encode %{
11150     bool quad = true;
11151     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 32, $shift$$constant,
11152              quad);
11153   %}
11154   ins_pipe( ialu_reg_reg ); // FIXME
11155 %}
11156 
11157 // Longs vector arithmetic right shift
11158 instruct vsra2L_reg(vecX dst, vecX src, vecX shift) %{
11159   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11160   match(Set dst (RShiftVL src shift));
11161   size(4);
11162   ins_cost(DEFAULT_COST); // FIXME
11163   expand %{
11164     vsha2L_reg(dst, src, shift);
11165   %}
11166 %}
11167 
11168 instruct vsra2L_immI(vecX dst, vecX src, immI shift) %{
11169   predicate(n-&gt;as_Vector()-&gt;length() == 2);
11170   match(Set dst (RShiftVL src shift));
11171   size(4);
11172   ins_cost(DEFAULT_COST); // FIXME
11173   format %{
11174     &quot;VSHR.S64 $dst.Q,$src.Q,$shift\t! logical right shift packed2L&quot;
11175   %}
11176   ins_encode %{
11177     bool quad = true;
11178     __ vshrSI($dst$$FloatRegister, $src$$FloatRegister, 64, $shift$$constant,
11179              quad);
11180   %}
11181   ins_pipe( ialu_reg_reg ); // FIXME
11182 %}
11183 
11184 // --------------------------------- AND --------------------------------------
11185 
11186 instruct vandD(vecD dst, vecD src1, vecD src2) %{
11187   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11188   match(Set dst (AndV src1 src2));
11189   format %{ &quot;VAND    $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11190   ins_encode %{
11191     bool quad = false;
11192     __ vandI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11193              quad);
11194   %}
11195   ins_pipe( ialu_reg_reg ); // FIXME
11196 %}
11197 
11198 instruct vandX(vecX dst, vecX src1, vecX src2) %{
11199   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11200   match(Set dst (AndV src1 src2));
11201   format %{ &quot;VAND    $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11202   ins_encode %{
11203     bool quad = true;
11204     __ vandI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11205              quad);
11206   %}
11207   ins_pipe( ialu_reg_reg ); // FIXME
11208 %}
11209 
11210 // --------------------------------- OR ---------------------------------------
11211 
11212 instruct vorD(vecD dst, vecD src1, vecD src2) %{
11213   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11214   match(Set dst (OrV src1 src2));
11215   format %{ &quot;VOR     $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11216   ins_encode %{
11217     bool quad = false;
11218     __ vorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11219             quad);
11220   %}
11221   ins_pipe( ialu_reg_reg ); // FIXME
11222 %}
11223 
11224 instruct vorX(vecX dst, vecX src1, vecX src2) %{
11225   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11226   match(Set dst (OrV src1 src2));
11227   format %{ &quot;VOR     $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11228   ins_encode %{
11229     bool quad = true;
11230     __ vorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11231             quad);
11232   %}
11233   ins_pipe( ialu_reg_reg ); // FIXME
11234 %}
11235 
11236 // --------------------------------- XOR --------------------------------------
11237 
11238 instruct vxorD(vecD dst, vecD src1, vecD src2) %{
11239   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 8);
11240   match(Set dst (XorV src1 src2));
11241   format %{ &quot;VXOR    $dst.D,$src1.D,$src2.D\t! and vectors (8 bytes)&quot; %}
11242   ins_encode %{
11243     bool quad = false;
11244     __ vxorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11245              quad);
11246   %}
11247   ins_pipe( ialu_reg_reg ); // FIXME
11248 %}
11249 
11250 instruct vxorX(vecX dst, vecX src1, vecX src2) %{
11251   predicate(n-&gt;as_Vector()-&gt;length_in_bytes() == 16);
11252   match(Set dst (XorV src1 src2));
11253   format %{ &quot;VXOR    $dst.Q,$src1.Q,$src2.Q\t! and vectors (16 bytes)&quot; %}
11254   ins_encode %{
11255     bool quad = true;
11256     __ vxorI($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister,
11257              quad);
11258   %}
11259   ins_pipe( ialu_reg_reg ); // FIXME
11260 %}
11261 
11262 
11263 //----------PEEPHOLE RULES-----------------------------------------------------
11264 // These must follow all instruction definitions as they use the names
11265 // defined in the instructions definitions.
11266 //
11267 // peepmatch ( root_instr_name [preceding_instruction]* );
11268 //
11269 // peepconstraint %{
11270 // (instruction_number.operand_name relational_op instruction_number.operand_name
11271 //  [, ...] );
11272 // // instruction numbers are zero-based using left to right order in peepmatch
11273 //
11274 // peepreplace ( instr_name  ( [instruction_number.operand_name]* ) );
11275 // // provide an instruction_number.operand_name for each operand that appears
11276 // // in the replacement instruction&#39;s match rule
11277 //
11278 // ---------VM FLAGS---------------------------------------------------------
11279 //
11280 // All peephole optimizations can be turned off using -XX:-OptoPeephole
11281 //
11282 // Each peephole rule is given an identifying number starting with zero and
11283 // increasing by one in the order seen by the parser.  An individual peephole
11284 // can be enabled, and all others disabled, by using -XX:OptoPeepholeAt=#
11285 // on the command-line.
11286 //
11287 // ---------CURRENT LIMITATIONS----------------------------------------------
11288 //
11289 // Only match adjacent instructions in same basic block
11290 // Only equality constraints
11291 // Only constraints between operands, not (0.dest_reg == EAX_enc)
11292 // Only one replacement instruction
11293 //
11294 // ---------EXAMPLE----------------------------------------------------------
11295 //
11296 // // pertinent parts of existing instructions in architecture description
11297 // instruct movI(eRegI dst, eRegI src) %{
11298 //   match(Set dst (CopyI src));
11299 // %}
11300 //
11301 // instruct incI_eReg(eRegI dst, immI1 src, eFlagsReg cr) %{
11302 //   match(Set dst (AddI dst src));
11303 //   effect(KILL cr);
11304 // %}
11305 //
11306 // // Change (inc mov) to lea
11307 // peephole %{
11308 //   // increment preceeded by register-register move
11309 //   peepmatch ( incI_eReg movI );
11310 //   // require that the destination register of the increment
11311 //   // match the destination register of the move
11312 //   peepconstraint ( 0.dst == 1.dst );
11313 //   // construct a replacement instruction that sets
11314 //   // the destination to ( move&#39;s source register + one )
11315 //   peepreplace ( incI_eReg_immI1( 0.dst 1.src 0.src ) );
11316 // %}
11317 //
11318 
11319 // // Change load of spilled value to only a spill
11320 // instruct storeI(memory mem, eRegI src) %{
11321 //   match(Set mem (StoreI mem src));
11322 // %}
11323 //
11324 // instruct loadI(eRegI dst, memory mem) %{
11325 //   match(Set dst (LoadI mem));
11326 // %}
11327 //
11328 // peephole %{
11329 //   peepmatch ( loadI storeI );
11330 //   peepconstraint ( 1.src == 0.dst, 1.mem == 0.mem );
11331 //   peepreplace ( storeI( 1.mem 1.mem 1.src ) );
11332 // %}
11333 
11334 //----------SMARTSPILL RULES---------------------------------------------------
11335 // These must follow all instruction definitions as they use the names
11336 // defined in the instructions definitions.
11337 //
11338 // ARM will probably not have any of these rules due to RISC instruction set.
11339 
11340 //----------PIPELINE-----------------------------------------------------------
11341 // Rules which define the behavior of the target architectures pipeline.
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>
















































































</pre>
<input id="eof" value="3" type="hidden" />
</body>
</html>